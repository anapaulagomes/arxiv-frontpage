{"created":"2024-11-06 18:59:41","title":"Community Forensics: Using Thousands of Generators to Train Fake Image Detectors","abstract":"One of the key challenges of detecting AI-generated images is spotting images that have been created by previously unseen generative models. We argue that the limited diversity of the training data is a major obstacle to addressing this problem, and we propose a new dataset that is significantly larger and more diverse than prior work. As part of creating this dataset, we systematically download thousands of text-to-image latent diffusion models and sample images from them. We also collect images from dozens of popular open source and commercial models. The resulting dataset contains 2.7M images that have been sampled from 4803 different models. These images collectively capture a wide range of scene content, generator architectures, and image processing settings. Using this dataset, we study the generalization abilities of fake image detectors. Our experiments suggest that detection performance improves as the number of models in the training set increases, even when these models have similar architectures. We also find that detection performance improves as the diversity of the models increases, and that our trained detectors generalize better than those trained on other datasets.","sentences":["One of the key challenges of detecting AI-generated images is spotting images that have been created by previously unseen generative models.","We argue that the limited diversity of the training data is a major obstacle to addressing this problem, and we propose a new dataset that is significantly larger and more diverse than prior work.","As part of creating this dataset, we systematically download thousands of text-to-image latent diffusion models and sample images from them.","We also collect images from dozens of popular open source and commercial models.","The resulting dataset contains 2.7M images that have been sampled from 4803 different models.","These images collectively capture a wide range of scene content, generator architectures, and image processing settings.","Using this dataset, we study the generalization abilities of fake image detectors.","Our experiments suggest that detection performance improves as the number of models in the training set increases, even when these models have similar architectures.","We also find that detection performance improves as the diversity of the models increases, and that our trained detectors generalize better than those trained on other datasets."],"url":"http://arxiv.org/abs/2411.04125v1"}
{"created":"2024-11-06 18:58:17","title":"On the (Classical and Quantum) Fine-Grained Complexity of Log-Approximate CVP and Max-Cut","abstract":"We show a linear sized reduction from the Maximum Cut Problem (Max-Cut) with completeness $1 - \\varepsilon$ and soundness $1 - \\varepsilon^{1/2}$ to the $\\gamma$-Approximate Closest Vector Problem under any finite $\\ell_p$-norm including $p = 2$.   This reduction implies two headline results: (i) We show that any sub-exponential time (classical or quantum) algorithm for the $o(\\sqrt{\\log n}^{\\frac{1}{p}})$-Approximate Closest Vector Problem in any finite $\\ell_p$-norm implies a faster than the state-of-the-art (by Arora, Barak, and Steurer [\\textit{Journal of the ACM}, 2015]) sub-exponential time (classical or quantum) algorithm for Max-Cut. This fills the gap between the results by Bennett, Golovnev, and Stephens-Davidowitz [\\textit{FOCS} 2017] which had an almost optimal runtime lower bound but a very small approximation factor and the results by Dinur, Kindler, Raz, and Safra [\\textit{Combinatorica}, 2003] which had an almost optimal approximation factor but small runtime lower bound, albeit using a different underlying hard problem; (ii) in combination with the classical results of Aggarwal and Kumar [\\textit{FOCS} 2023] and our quantization of those results, there are no fine-grained reductions from $k$-SAT to Max-Cut with one-sided error, nor are there non-adaptive fine-grained (classical or quantum) reductions with two-sided error, unless the polynomial hierarchy collapses (or unless $\\mathrm{NP} \\subseteq \\mathrm{pr} \\text{-} \\mathrm{QSZK}$ in the quantum case). The second result poses a significant barrier against proving the fine-grained complexity of Max-Cut using the Strong Exponential Time Hypothesis (or the Quantum Strong Exponential Time Hypothesis).","sentences":["We show a linear sized reduction from the Maximum Cut Problem (Max-Cut) with completeness $1 - \\varepsilon$ and soundness $1 - \\varepsilon^{1/2}$ to the $\\gamma$-Approximate Closest Vector Problem under any finite $\\ell_p$-norm including $p = 2$.   This reduction implies two headline results: (i) We show that any sub-exponential time (classical or quantum) algorithm for the $o(\\sqrt{\\log n}^{\\frac{1}{p}})$-Approximate Closest Vector Problem in any finite $\\ell_p$-norm implies a faster than the state-of-the-art (by Arora, Barak, and","Steurer","[\\textit{Journal of the ACM}, 2015]) sub-exponential time (classical or quantum) algorithm for Max-Cut.","This fills the gap between the results by Bennett, Golovnev, and Stephens-Davidowitz [\\textit{FOCS} 2017] which had an almost optimal runtime lower bound but a very small approximation factor and the results by Dinur, Kindler, Raz, and Safra","[\\textit{Combinatorica}, 2003] which had an almost optimal approximation factor but small runtime lower bound, albeit using a different underlying hard problem; (ii) in combination with the classical results of Aggarwal and Kumar [\\textit{FOCS} 2023] and our quantization of those results, there are no fine-grained reductions from $k$-SAT to Max-Cut with one-sided error, nor are there non-adaptive fine-grained (classical or quantum) reductions with two-sided error, unless the polynomial hierarchy collapses (or unless $\\mathrm{NP} \\subseteq \\mathrm{pr} \\text{-} \\mathrm{QSZK}$ in the quantum case).","The second result poses a significant barrier against proving the fine-grained complexity of Max-Cut using the Strong Exponential Time Hypothesis (or the Quantum Strong Exponential Time Hypothesis)."],"url":"http://arxiv.org/abs/2411.04124v1"}
{"created":"2024-11-06 18:51:02","title":"Medical Adaptation of Large Language and Vision-Language Models: Are We Making Progress?","abstract":"Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions. In this paper, we compare seven public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting regime for medical question-answering (QA) tasks. For instance, across the tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 12.1% of cases, reach a (statistical) tie in 49.8% of cases, and are significantly worse than their base models in the remaining 38.2% of cases. Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately; and (iii) accounting for statistical uncertainty in comparisons. While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.","sentences":["Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora.","These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions.","In this paper, we compare seven public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting regime for medical question-answering (QA) tasks.","For instance, across the tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 12.1% of cases, reach a (statistical) tie in 49.8% of cases, and are significantly worse than their base models in the remaining 38.2% of cases.","Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately; and (iii) accounting for statistical uncertainty in comparisons.","While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions.","Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies."],"url":"http://arxiv.org/abs/2411.04118v1"}
{"created":"2024-11-06 18:46:57","title":"Condensing Against Online Adversaries","abstract":"We investigate the task of deterministically condensing randomness from Online Non-Oblivious Symbol Fixing (oNOSF) sources, a natural model for which extraction is impossible [AORSV, EUROCRYPT'20]. A $(g,\\ell)$-oNOSF source is a sequence of $\\ell$ blocks where at least $g$ of the blocks are good (independent and have some min-entropy) and the remaining bad blocks are controlled by an online adversary where each bad block can be arbitrarily correlated with any block that appears before it.   The existence of condensers was studied in [CGR, FOCS'24]. They proved condensing impossibility results for various values of $g, \\ell$ and showed the existence of condensers matching the impossibility results in the case when $n$ is extremely large compared to $\\ell$.   In this work, we make significant progress on proving the existence of condensers with strong parameters in almost all parameter regimes, even when $n$ is a large enough constant and $\\ell$ is growing. This almost resolves the question of the existence of condensers for oNOSF sources, except when $n$ is a small constant.   We construct the first explicit condensers for oNOSF sources, achieve parameters that match the existential results of [CGR, FOCS'24], and obtain an improved construction for transforming low-entropy oNOSF sources into uniform ones.   We find applications of our results to collective coin flipping and sampling, well-studied problems in fault-tolerant distributed computing. We use our condensers to provide simple protocols for these problems.   To understand the case of small $n$, we focus on $n=1$ which corresponds to online non-oblivious bit-fixing (oNOBF) sources. We initiate a study of a new, natural notion of influence of Boolean functions which we call online influence. We establish tight bounds on the total online influence of Boolean functions, implying extraction lower bounds.","sentences":["We investigate the task of deterministically condensing randomness from Online Non-Oblivious Symbol Fixing (oNOSF) sources, a natural model for which extraction is impossible [AORSV, EUROCRYPT'20].","A $(g,\\ell)$-oNOSF source is a sequence of $\\ell$ blocks where at least $g$ of the blocks are good (independent and have some min-entropy) and the remaining bad blocks are controlled by an online adversary where each bad block can be arbitrarily correlated with any block that appears before it.   ","The existence of condensers was studied in [CGR, FOCS'24].","They proved condensing impossibility results for various values of $g, \\ell$ and showed the existence of condensers matching the impossibility results in the case when $n$ is extremely large compared to $\\ell$.   In this work, we make significant progress on proving the existence of condensers with strong parameters in almost all parameter regimes, even when $n$ is a large enough constant and $\\ell$ is growing.","This almost resolves the question of the existence of condensers for oNOSF sources, except when $n$ is a small constant.   ","We construct the first explicit condensers for oNOSF sources, achieve parameters that match the existential results of [CGR, FOCS'24], and obtain an improved construction for transforming low-entropy oNOSF sources into uniform ones.   ","We find applications of our results to collective coin flipping and sampling, well-studied problems in fault-tolerant distributed computing.","We use our condensers to provide simple protocols for these problems.   ","To understand the case of small $n$, we focus on $n=1$ which corresponds to online non-oblivious bit-fixing (oNOBF) sources.","We initiate a study of a new, natural notion of influence of Boolean functions which we call online influence.","We establish tight bounds on the total online influence of Boolean functions, implying extraction lower bounds."],"url":"http://arxiv.org/abs/2411.04115v1"}
{"created":"2024-11-06 18:45:46","title":"Age of Gossip With Time-Varying Topologies","abstract":"We consider a gossiping network, where a source node sends updates to a network of $n$ gossiping nodes. Meanwhile, the connectivity topology of the gossiping network changes over time, among a finite number of connectivity ''states,'' such as the fully connected graph, the ring graph, the grid graph, etc. The transition of the connectivity graph among the possible options is governed by a finite state continuous time Markov chain (CTMC). When the CTMC is in a particular state, the associated graph topology of the gossiping network is in the way indicated by that state. We evaluate the impact of time-varying graph topologies on the freshness of information for nodes in the network. We use the version age of information metric to quantify the freshness of information at the nodes. Using a method similar to the first passage percolation method, we show that, if one of the states of the CTMC is the fully connected graph and the transition rates of the CTMC are constant, then the version age of a typical node in the network scales logarithmically with the number of nodes, as in the case if the network was always fully connected. That is, there is no loss in the age scaling, even if the network topology deviates from full connectivity, in this setting. We perform numerical simulations and analyze more generally how having different topologies and different CTMC rates (that might depend on the number of nodes) affect the average version age scaling of a node in the gossiping network.","sentences":["We consider a gossiping network, where a source node sends updates to a network of $n$ gossiping nodes.","Meanwhile, the connectivity topology of the gossiping network changes over time, among a finite number of connectivity ''states,'' such as the fully connected graph, the ring graph, the grid graph, etc.","The transition of the connectivity graph among the possible options is governed by a finite state continuous time Markov chain (CTMC).","When the CTMC is in a particular state, the associated graph topology of the gossiping network is in the way indicated by that state.","We evaluate the impact of time-varying graph topologies on the freshness of information for nodes in the network.","We use the version age of information metric to quantify the freshness of information at the nodes.","Using a method similar to the first passage percolation method, we show that, if one of the states of the CTMC is the fully connected graph and the transition rates of the CTMC are constant, then the version age of a typical node in the network scales logarithmically with the number of nodes, as in the case if the network was always fully connected.","That is, there is no loss in the age scaling, even if the network topology deviates from full connectivity, in this setting.","We perform numerical simulations and analyze more generally how having different topologies and different CTMC rates (that might depend on the number of nodes) affect the average version age scaling of a node in the gossiping network."],"url":"http://arxiv.org/abs/2411.04114v1"}
{"created":"2024-11-06 18:44:09","title":"Fed-EC: Bandwidth-Efficient Clustering-Based Federated Learning For Autonomous Visual Robot Navigation","abstract":"Centralized learning requires data to be aggregated at a central server, which poses significant challenges in terms of data privacy and bandwidth consumption. Federated learning presents a compelling alternative, however, vanilla federated learning methods deployed in robotics aim to learn a single global model across robots that works ideally for all. But in practice one model may not be well suited for robots deployed in various environments. This paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated learning framework that is deployed with vision based autonomous robot navigation in diverse outdoor environments. The framework addresses the key federated learning challenge of deteriorating model performance of a single global model due to the presence of non-IID data across real-world robots. Extensive real-world experiments validate that Fed-EC reduces the communication size by 23x for each robot while matching the performance of centralized learning for goal-oriented navigation and outperforms local learning. Fed-EC can transfer previously learnt models to new robots that join the cluster.","sentences":["Centralized learning requires data to be aggregated at a central server, which poses significant challenges in terms of data privacy and bandwidth consumption.","Federated learning presents a compelling alternative, however, vanilla federated learning methods deployed in robotics aim to learn a single global model across robots that works ideally for all.","But in practice one model may not be well suited for robots deployed in various environments.","This paper proposes Federated-EmbedCluster (Fed-EC), a clustering-based federated learning framework that is deployed with vision based autonomous robot navigation in diverse outdoor environments.","The framework addresses the key federated learning challenge of deteriorating model performance of a single global model due to the presence of non-IID data across real-world robots.","Extensive real-world experiments validate that Fed-EC reduces the communication size by 23x for each robot while matching the performance of centralized learning for goal-oriented navigation and outperforms local learning.","Fed-EC can transfer previously learnt models to new robots that join the cluster."],"url":"http://arxiv.org/abs/2411.04112v1"}
{"created":"2024-11-06 18:36:22","title":"Self-Consistency Preference Optimization","abstract":"Self-alignment, whereby models learn to improve themselves without human annotation, is a rapidly growing research area. However, existing techniques often fail to improve complex reasoning tasks due to the difficulty of assigning correct rewards. An orthogonal approach that is known to improve correctness is self-consistency, a method applied at inference time based on multiple sampling in order to find the most consistent answer. In this work, we extend the self-consistency concept to help train models. We thus introduce self-consistency preference optimization (ScPO), which iteratively trains consistent answers to be preferred over inconsistent ones on unsupervised new problems. We show ScPO leads to large improvements over conventional reward model training on reasoning tasks such as GSM8K and MATH, closing the gap with supervised training with gold answers or preferences, and that combining ScPO with standard supervised learning improves results even further. On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku.","sentences":["Self-alignment, whereby models learn to improve themselves without human annotation, is a rapidly growing research area.","However, existing techniques often fail to improve complex reasoning tasks due to the difficulty of assigning correct rewards.","An orthogonal approach that is known to improve correctness is self-consistency, a method applied at inference time based on multiple sampling in order to find the most consistent answer.","In this work, we extend the self-consistency concept to help train models.","We thus introduce self-consistency preference optimization (ScPO), which iteratively trains consistent answers to be preferred over inconsistent ones on unsupervised new problems.","We show ScPO leads to large improvements over conventional reward model training on reasoning tasks such as GSM8K and MATH, closing the gap with supervised training with gold answers or preferences, and that combining ScPO with standard supervised learning improves results even further.","On ZebraLogic, ScPO finetunes Llama-3 8B to be superior to Llama-3 70B, Gemma-2 27B, and Claude-3 Haiku."],"url":"http://arxiv.org/abs/2411.04109v1"}
{"created":"2024-11-06 18:36:21","title":"Weighted Sobolev Approximation Rates for Neural Networks on Unbounded Domains","abstract":"In this work, we consider the approximation capabilities of shallow neural networks in weighted Sobolev spaces for functions in the spectral Barron space. The existing literature already covers several cases, in which the spectral Barron space can be approximated well, i.e., without curse of dimensionality, by shallow networks and several different classes of activation function. The limitations of the existing results are mostly on the error measures that were considered, in which the results are restricted to Sobolev spaces over a bounded domain. We will here treat two cases that extend upon the existing results. Namely, we treat the case with bounded domain and Muckenhoupt weights and the case, where the domain is allowed to be unbounded and the weights are required to decay. We first present embedding results for the more general weighted Fourier-Lebesgue spaces in the weighted Sobolev spaces and then we establish asymptotic approximation rates for shallow neural networks that come without curse of dimensionality.","sentences":["In this work, we consider the approximation capabilities of shallow neural networks in weighted Sobolev spaces for functions in the spectral Barron space.","The existing literature already covers several cases, in which the spectral Barron space can be approximated well, i.e., without curse of dimensionality, by shallow networks and several different classes of activation function.","The limitations of the existing results are mostly on the error measures that were considered, in which the results are restricted to Sobolev spaces over a bounded domain.","We will here treat two cases that extend upon the existing results.","Namely, we treat the case with bounded domain and Muckenhoupt weights and the case, where the domain is allowed to be unbounded and the weights are required to decay.","We first present embedding results for the more general weighted Fourier-Lebesgue spaces in the weighted Sobolev spaces and then we establish asymptotic approximation rates for shallow neural networks that come without curse of dimensionality."],"url":"http://arxiv.org/abs/2411.04108v1"}
{"created":"2024-11-06 18:35:32","title":"How Transformers Solve Propositional Logic Problems: A Mechanistic Analysis","abstract":"Large language models (LLMs) have shown amazing performance on tasks that require planning and reasoning. Motivated by this, we investigate the internal mechanisms that underpin a network's ability to perform complex logical reasoning. We first construct a synthetic propositional logic problem that serves as a concrete test-bed for network training and evaluation. Crucially, this problem demands nontrivial planning to solve, but we can train a small transformer to achieve perfect accuracy. Building on our set-up, we then pursue an understanding of precisely how a three-layer transformer, trained from scratch, solves this problem. We are able to identify certain \"planning\" and \"reasoning\" circuits in the network that necessitate cooperation between the attention blocks to implement the desired logic. To expand our findings, we then study a larger model, Mistral 7B. Using activation patching, we characterize internal components that are critical in solving our logic problem. Overall, our work systemically uncovers novel aspects of small and large transformers, and continues the study of how they plan and reason.","sentences":["Large language models (LLMs) have shown amazing performance on tasks that require planning and reasoning.","Motivated by this, we investigate the internal mechanisms that underpin a network's ability to perform complex logical reasoning.","We first construct a synthetic propositional logic problem that serves as a concrete test-bed for network training and evaluation.","Crucially, this problem demands nontrivial planning to solve, but we can train a small transformer to achieve perfect accuracy.","Building on our set-up, we then pursue an understanding of precisely how a three-layer transformer, trained from scratch, solves this problem.","We are able to identify certain \"planning\" and \"reasoning\" circuits in the network that necessitate cooperation between the attention blocks to implement the desired logic.","To expand our findings, we then study a larger model, Mistral 7B. Using activation patching, we characterize internal components that are critical in solving our logic problem.","Overall, our work systemically uncovers novel aspects of small and large transformers, and continues the study of how they plan and reason."],"url":"http://arxiv.org/abs/2411.04105v1"}
{"created":"2024-11-06 18:34:35","title":"Optimizing Quantum Circuits, Fast and Slow","abstract":"Optimizing quantum circuits is critical: the number of quantum operations needs to be minimized for a successful evaluation of a circuit on a quantum processor. In this paper we unify two disparate ideas for optimizing quantum circuits, rewrite rules, which are fast standard optimizer passes, and unitary synthesis, which is slow, requiring a search through the space of circuits. We present a clean, unifying framework for thinking of rewriting and resynthesis as abstract circuit transformations. We then present a radically simple algorithm, GUOQ, for optimizing quantum circuits that exploits the synergies of rewriting and resynthesis. Our extensive evaluation demonstrates the ability of GUOQ to strongly outperform existing optimizers on a wide range of benchmarks.","sentences":["Optimizing quantum circuits is critical: the number of quantum operations needs to be minimized for a successful evaluation of a circuit on a quantum processor.","In this paper we unify two disparate ideas for optimizing quantum circuits, rewrite rules, which are fast standard optimizer passes, and unitary synthesis, which is slow, requiring a search through the space of circuits.","We present a clean, unifying framework for thinking of rewriting and resynthesis as abstract circuit transformations.","We then present a radically simple algorithm, GUOQ, for optimizing quantum circuits that exploits the synergies of rewriting and resynthesis.","Our extensive evaluation demonstrates the ability of GUOQ to strongly outperform existing optimizers on a wide range of benchmarks."],"url":"http://arxiv.org/abs/2411.04104v1"}
{"created":"2024-11-06 18:26:19","title":"Interpretable and Efficient Data-driven Discovery and Control of Distributed Systems","abstract":"Effectively controlling systems governed by Partial Differential Equations (PDEs) is crucial in several fields of Applied Sciences and Engineering. These systems usually yield significant challenges to conventional control schemes due to their nonlinear dynamics, partial observability, high-dimensionality once discretized, distributed nature, and the requirement for low-latency feedback control. Reinforcement Learning (RL), particularly Deep RL (DRL), has recently emerged as a promising control paradigm for such systems, demonstrating exceptional capabilities in managing high-dimensional, nonlinear dynamics. However, DRL faces challenges including sample inefficiency, robustness issues, and an overall lack of interpretability. To address these issues, we propose a data-efficient, interpretable, and scalable Dyna-style Model-Based RL framework for PDE control, combining the Sparse Identification of Nonlinear Dynamics with Control (SINDy-C) algorithm and an autoencoder (AE) framework for the sake of dimensionality reduction of PDE states and actions. This novel approach enables fast rollouts, reducing the need for extensive environment interactions, and provides an interpretable latent space representation of the PDE forward dynamics. We validate our method on two PDE problems describing fluid flows - namely, the 1D Burgers equation and 2D Navier-Stokes equations - comparing it against a model-free baseline, and carrying out an extensive analysis of the learned dynamics.","sentences":["Effectively controlling systems governed by Partial Differential Equations (PDEs) is crucial in several fields of Applied Sciences and Engineering.","These systems usually yield significant challenges to conventional control schemes due to their nonlinear dynamics, partial observability, high-dimensionality once discretized, distributed nature, and the requirement for low-latency feedback control.","Reinforcement Learning (RL), particularly Deep RL (DRL), has recently emerged as a promising control paradigm for such systems, demonstrating exceptional capabilities in managing high-dimensional, nonlinear dynamics.","However, DRL faces challenges including sample inefficiency, robustness issues, and an overall lack of interpretability.","To address these issues, we propose a data-efficient, interpretable, and scalable Dyna-style Model-Based RL framework for PDE control, combining the Sparse Identification of Nonlinear Dynamics with Control (SINDy-C) algorithm and an autoencoder (AE) framework for the sake of dimensionality reduction of PDE states and actions.","This novel approach enables fast rollouts, reducing the need for extensive environment interactions, and provides an interpretable latent space representation of the PDE forward dynamics.","We validate our method on two PDE problems describing fluid flows - namely, the 1D Burgers equation and 2D Navier-Stokes equations - comparing it against a model-free baseline, and carrying out an extensive analysis of the learned dynamics."],"url":"http://arxiv.org/abs/2411.04098v1"}
{"created":"2024-11-06 18:25:00","title":"RaVL: Discovering and Mitigating Spurious Correlations in Fine-Tuned Vision-Language Models","abstract":"Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time. Existing approaches for addressing spurious correlations (i) primarily operate at the global image-level rather than intervening directly on fine-grained image features and (ii) are predominantly designed for unimodal settings. In this work, we present RaVL, which takes a fine-grained perspective on VLM robustness by discovering and mitigating spurious correlations using local image features rather than operating at the global image level. Given a fine-tuned VLM, RaVL first discovers spurious correlations by leveraging a region-level clustering approach to identify precise image features contributing to zero-shot classification errors. Then, RaVL mitigates the identified spurious correlation with a novel region-aware loss function that enables the VLM to focus on relevant regions and ignore spurious relationships during fine-tuning. We evaluate RaVL on 654 VLMs with various model architectures, data domains, and learned spurious correlations. Our results show that RaVL accurately discovers (191% improvement over the closest baseline) and mitigates (8.2% improvement on worst-group image classification accuracy) spurious correlations. Qualitative evaluations on general-domain and medical-domain VLMs confirm our findings.","sentences":["Fine-tuned vision-language models (VLMs) often capture spurious correlations between image features and textual attributes, resulting in degraded zero-shot performance at test time.","Existing approaches for addressing spurious correlations (i) primarily operate at the global image-level rather than intervening directly on fine-grained image features and (ii) are predominantly designed for unimodal settings.","In this work, we present RaVL, which takes a fine-grained perspective on VLM robustness by discovering and mitigating spurious correlations using local image features rather than operating at the global image level.","Given a fine-tuned VLM, RaVL first discovers spurious correlations by leveraging a region-level clustering approach to identify precise image features contributing to zero-shot classification errors.","Then, RaVL mitigates the identified spurious correlation with a novel region-aware loss function that enables the VLM to focus on relevant regions and ignore spurious relationships during fine-tuning.","We evaluate RaVL on 654 VLMs with various model architectures, data domains, and learned spurious correlations.","Our results show that RaVL accurately discovers (191% improvement over the closest baseline) and mitigates (8.2% improvement on worst-group image classification accuracy) spurious correlations.","Qualitative evaluations on general-domain and medical-domain VLMs confirm our findings."],"url":"http://arxiv.org/abs/2411.04097v1"}
{"created":"2024-11-06 18:14:48","title":"Summarization of Opinionated Political Documents with Varied Perspectives","abstract":"Global partisan hostility and polarization has increased, and this polarization is heightened around presidential elections. Models capable of generating accurate summaries of diverse perspectives can help reduce such polarization by exposing users to alternative perspectives. In this work, we introduce a novel dataset and task for independently summarizing each political perspective in a set of passages from opinionated news articles. For this task, we propose a framework for evaluating different dimensions of perspective summary performance. We benchmark 10 models of varying sizes and architectures through both automatic and human evaluation. While recent models like GPT-4o perform well on this task, we find that all models struggle to generate summaries faithful to the intended perspective. Our analysis of summaries focuses on how extraction behavior depends on the features of the input documents.","sentences":["Global partisan hostility and polarization has increased, and this polarization is heightened around presidential elections.","Models capable of generating accurate summaries of diverse perspectives can help reduce such polarization by exposing users to alternative perspectives.","In this work, we introduce a novel dataset and task for independently summarizing each political perspective in a set of passages from opinionated news articles.","For this task, we propose a framework for evaluating different dimensions of perspective summary performance.","We benchmark 10 models of varying sizes and architectures through both automatic and human evaluation.","While recent models like GPT-4o perform well on this task, we find that all models struggle to generate summaries faithful to the intended perspective.","Our analysis of summaries focuses on how extraction behavior depends on the features of the input documents."],"url":"http://arxiv.org/abs/2411.04093v1"}
{"created":"2024-11-06 18:08:57","title":"A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement","abstract":"Content moderation typically combines the efforts of human moderators and machine learning models.However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception.Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered.In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement. Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task.Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review.We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods.","sentences":["Content moderation typically combines the efforts of human moderators and machine learning models.","However, these systems often rely on data where significant disagreement occurs during moderation, reflecting the subjective nature of toxicity perception.","Rather than dismissing this disagreement as noise, we interpret it as a valuable signal that highlights the inherent ambiguity of the content,an insight missed when only the majority label is considered.","In this work, we introduce a novel content moderation framework that emphasizes the importance of capturing annotation disagreement.","Our approach uses multitask learning, where toxicity classification serves as the primary task and annotation disagreement is addressed as an auxiliary task.","Additionally, we leverage uncertainty estimation techniques, specifically Conformal Prediction, to account for both the ambiguity in comment annotations and the model's inherent uncertainty in predicting toxicity and disagreement.","The framework also allows moderators to adjust thresholds for annotation disagreement, offering flexibility in determining when ambiguity should trigger a review.","We demonstrate that our joint approach enhances model performance, calibration, and uncertainty estimation, while offering greater parameter efficiency and improving the review process in comparison to single-task methods."],"url":"http://arxiv.org/abs/2411.04090v1"}
{"created":"2024-11-06 18:02:30","title":"Learned codes for broadcast channels with feedback","abstract":"We focus on designing error-correcting codes for the symmetric Gaussian broadcast channel with feedback. Feedback not only expands the capacity region of the broadcast channel but also enhances transmission reliability. In this work, we study the construction of learned finite blocklength codes for broadcast channels with feedback. Learned error-correcting codes, in which both the encoder and decoder are jointly trained, have shown impressive performance in point-to-point channels, particularly with noisy feedback. However, few learned schemes exist for multi-user channels. Here, we develop a lightweight code for the broadcast channel with feedback that outperforms existing schemes and operates effectively at short blocklengths.","sentences":["We focus on designing error-correcting codes for the symmetric Gaussian broadcast channel with feedback.","Feedback not only expands the capacity region of the broadcast channel but also enhances transmission reliability.","In this work, we study the construction of learned finite blocklength codes for broadcast channels with feedback.","Learned error-correcting codes, in which both the encoder and decoder are jointly trained, have shown impressive performance in point-to-point channels, particularly with noisy feedback.","However, few learned schemes exist for multi-user channels.","Here, we develop a lightweight code for the broadcast channel with feedback that outperforms existing schemes and operates effectively at short blocklengths."],"url":"http://arxiv.org/abs/2411.04083v1"}
{"created":"2024-11-06 17:57:43","title":"Textual Decomposition Then Sub-motion-space Scattering for Open-Vocabulary Motion Generation","abstract":"Text-to-motion generation is a crucial task in computer vision, which generates the target 3D motion by the given text. The existing annotated datasets are limited in scale, resulting in most existing methods overfitting to the small datasets and unable to generalize to the motions of the open domain. Some methods attempt to solve the open-vocabulary motion generation problem by aligning to the CLIP space or using the Pretrain-then-Finetuning paradigm. However, the current annotated dataset's limited scale only allows them to achieve mapping from sub-text-space to sub-motion-space, instead of mapping between full-text-space and full-motion-space (full mapping), which is the key to attaining open-vocabulary motion generation. To this end, this paper proposes to leverage the atomic motion (simple body part motions over a short time period) as an intermediate representation, and leverage two orderly coupled steps, i.e., Textual Decomposition and Sub-motion-space Scattering, to address the full mapping problem. For Textual Decomposition, we design a fine-grained description conversion algorithm, and combine it with the generalization ability of a large language model to convert any given motion text into atomic texts. Sub-motion-space Scattering learns the compositional process from atomic motions to the target motions, to make the learned sub-motion-space scattered to form the full-motion-space. For a given motion of the open domain, it transforms the extrapolation into interpolation and thereby significantly improves generalization. Our network, $DSO$-Net, combines textual $d$ecomposition and sub-motion-space $s$cattering to solve the $o$pen-vocabulary motion generation. Extensive experiments demonstrate that our DSO-Net achieves significant improvements over the state-of-the-art methods on open-vocabulary motion generation. Code is available at https://vankouf.github.io/DSONet/.","sentences":["Text-to-motion generation is a crucial task in computer vision, which generates the target 3D motion by the given text.","The existing annotated datasets are limited in scale, resulting in most existing methods overfitting to the small datasets and unable to generalize to the motions of the open domain.","Some methods attempt to solve the open-vocabulary motion generation problem by aligning to the CLIP space or using the Pretrain-then-Finetuning paradigm.","However, the current annotated dataset's limited scale only allows them to achieve mapping from sub-text-space to sub-motion-space, instead of mapping between full-text-space and full-motion-space (full mapping), which is the key to attaining open-vocabulary motion generation.","To this end, this paper proposes to leverage the atomic motion (simple body part motions over a short time period) as an intermediate representation, and leverage two orderly coupled steps, i.e., Textual Decomposition and Sub-motion-space Scattering, to address the full mapping problem.","For Textual Decomposition, we design a fine-grained description conversion algorithm, and combine it with the generalization ability of a large language model to convert any given motion text into atomic texts.","Sub-motion-space Scattering learns the compositional process from atomic motions to the target motions, to make the learned sub-motion-space scattered to form the full-motion-space.","For a given motion of the open domain, it transforms the extrapolation into interpolation and thereby significantly improves generalization.","Our network, $DSO$-Net, combines textual $d$ecomposition and sub-motion-space $s$cattering to solve the $o$pen-vocabulary motion generation.","Extensive experiments demonstrate that our DSO-Net achieves significant improvements over the state-of-the-art methods on open-vocabulary motion generation.","Code is available at https://vankouf.github.io/DSONet/."],"url":"http://arxiv.org/abs/2411.04079v1"}
{"created":"2024-11-06 17:55:37","title":"H-POPE: Hierarchical Polling-based Probing Evaluation of Hallucinations in Large Vision-Language Models","abstract":"By leveraging both texts and images, large vision language models (LVLMs) have shown significant progress in various multi-modal tasks. Nevertheless, these models often suffer from hallucinations, e.g., they exhibit inconsistencies between the visual input and the textual output. To address this, we propose H-POPE, a coarse-to-fine-grained benchmark that systematically assesses hallucination in object existence and attributes. Our evaluation shows that models are prone to hallucinations on object existence, and even more so on fine-grained attributes. We further investigate whether these models rely on visual input to formulate the output texts.","sentences":["By leveraging both texts and images, large vision language models (LVLMs) have shown significant progress in various multi-modal tasks.","Nevertheless, these models often suffer from hallucinations, e.g., they exhibit inconsistencies between the visual input and the textual output.","To address this, we propose H-POPE, a coarse-to-fine-grained benchmark that systematically assesses hallucination in object existence and attributes.","Our evaluation shows that models are prone to hallucinations on object existence, and even more so on fine-grained attributes.","We further investigate whether these models rely on visual input to formulate the output texts."],"url":"http://arxiv.org/abs/2411.04077v1"}
{"created":"2024-11-06 17:52:01","title":"M3SciQA: A Multi-Modal Multi-Document Scientific QA Benchmark for Evaluating Foundation Models","abstract":"Existing benchmarks for evaluating foundation models mainly focus on single-document, text-only tasks. However, they often fail to fully capture the complexity of research workflows, which typically involve interpreting non-textual data and gathering information across multiple documents. To address this gap, we introduce M3SciQA, a multi-modal, multi-document scientific question answering benchmark designed for a more comprehensive evaluation of foundation models. M3SciQA consists of 1,452 expert-annotated questions spanning 70 natural language processing paper clusters, where each cluster represents a primary paper along with all its cited documents, mirroring the workflow of comprehending a single paper by requiring multi-modal and multi-document data. With M3SciQA, we conduct a comprehensive evaluation of 18 foundation models. Our results indicate that current foundation models still significantly underperform compared to human experts in multi-modal information retrieval and in reasoning across multiple scientific documents. Additionally, we explore the implications of these findings for the future advancement of applying foundation models in multi-modal scientific literature analysis.","sentences":["Existing benchmarks for evaluating foundation models mainly focus on single-document, text-only tasks.","However, they often fail to fully capture the complexity of research workflows, which typically involve interpreting non-textual data and gathering information across multiple documents.","To address this gap, we introduce M3SciQA, a multi-modal, multi-document scientific question answering benchmark designed for a more comprehensive evaluation of foundation models.","M3SciQA consists of 1,452 expert-annotated questions spanning 70 natural language processing paper clusters, where each cluster represents a primary paper along with all its cited documents, mirroring the workflow of comprehending a single paper by requiring multi-modal and multi-document data.","With M3SciQA, we conduct a comprehensive evaluation of 18 foundation models.","Our results indicate that current foundation models still significantly underperform compared to human experts in multi-modal information retrieval and in reasoning across multiple scientific documents.","Additionally, we explore the implications of these findings for the future advancement of applying foundation models in multi-modal scientific literature analysis."],"url":"http://arxiv.org/abs/2411.04075v1"}
{"created":"2024-11-06 17:50:32","title":"Rescheduling after vehicle failures in the multi-depot rural postman problem with rechargeable and reusable vehicles","abstract":"We present a centralized auction algorithm to solve the Multi-Depot Rural Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing on rescheduling arc routing after vehicle failures. The problem involves finding heuristically obtained best feasible routes for multiple rechargeable and reusable vehicles with capacity constraints capable of performing multiple trips from multiple depots, with the possibility of vehicle failures. Our algorithm auctions the failed trips to active (non-failed) vehicles through local auctioning, modifying initial routes to handle dynamic vehicle failures efficiently. When a failure occurs, the algorithm searches for the best active vehicle to perform the failed trip and inserts the trip into that vehicle's route, which avoids a complete rescheduling and reduces the computational effort. We compare the algorithm's solutions against offline optimal solutions obtained from solving a Mixed Integer Linear Programming (MILP) formulation using the Gurobi solver; this formulation assumes that perfect information about the vehicle failures and failure times is given. The results demonstrate that the centralized auction algorithm produces solutions that are, in some cases, near optimal; moreover, the execution time for the proposed approach is much more consistent and is, for some instances, orders of magnitude less than the execution time of the Gurobi solver. The theoretical analysis provides an upper bound for the competitive ratio and computational complexity of our algorithm, offering a formal performance guarantee in dynamic failure scenarios.","sentences":["We present a centralized auction algorithm to solve the Multi-Depot Rural Postman Problem with Rechargeable and Reusable Vehicles (MD-RPP-RRV), focusing on rescheduling arc routing after vehicle failures.","The problem involves finding heuristically obtained best feasible routes for multiple rechargeable and reusable vehicles with capacity constraints capable of performing multiple trips from multiple depots, with the possibility of vehicle failures.","Our algorithm auctions the failed trips to active (non-failed) vehicles through local auctioning, modifying initial routes to handle dynamic vehicle failures efficiently.","When a failure occurs, the algorithm searches for the best active vehicle to perform the failed trip and inserts the trip into that vehicle's route, which avoids a complete rescheduling and reduces the computational effort.","We compare the algorithm's solutions against offline optimal solutions obtained from solving a Mixed Integer Linear Programming (MILP) formulation using the Gurobi solver; this formulation assumes that perfect information about the vehicle failures and failure times is given.","The results demonstrate that the centralized auction algorithm produces solutions that are, in some cases, near optimal; moreover, the execution time for the proposed approach is much more consistent and is, for some instances, orders of magnitude less than the execution time of the Gurobi solver.","The theoretical analysis provides an upper bound for the competitive ratio and computational complexity of our algorithm, offering a formal performance guarantee in dynamic failure scenarios."],"url":"http://arxiv.org/abs/2411.04073v1"}
{"created":"2024-11-06 17:43:31","title":"Security Assessment of Mobile Banking Apps in West African Economic and Monetary Union","abstract":"The West African Economic and Monetary Union (WAEMU) states, characterized by widespread smartphone usage, have witnessed banks and financial institutions introducing mobile banking applications (MBAs). These apps empower users to perform transactions such as money transfers, bill payments, and account inquiries anytime, anywhere. However, this proliferation of MBAs also raises significant security concerns. Poorly implemented security measures during app development can expose users and financial institutions to substantial financial risks through increased vulnerability to cyberattacks. Our study evaluated fifty-nine WAEMU MBAs using static analysis techniques. These MBAs were collected from the 160 banks and financial institutions of the eight WAEMU countries listed on the Central Bank of West African States (BCEAO) website. We identified security-related code issues that could be exploited by malicious actors. We investigated the issues found in the older versions to track their evolution across updates. Additionally, we identified some banks from regions such as Europe, the United States, and other developing countries and analyzed their mobile apps for a security comparison with WAEMU MBAs. Key findings include: (1) WAEMU apps exhibit security issues introduced during development, posing significant risks of exploitation; (2) Despite frequent updates, underlying security issues often persist; (3) Compared to MBAs from developed and developing countries, WAEMU apps exhibit fewer critical security issues; and (4) Apps from banks that are branches of other non-WAEMU banks often inherit security concerns from their parent apps while also introducing additional issues unique to their context. Our research underscores the need for robust security practices in WAEMU MBAs development to enhance user safety and trust in financial services.","sentences":["The West African Economic and Monetary Union (WAEMU) states, characterized by widespread smartphone usage, have witnessed banks and financial institutions introducing mobile banking applications (MBAs).","These apps empower users to perform transactions such as money transfers, bill payments, and account inquiries anytime, anywhere.","However, this proliferation of MBAs also raises significant security concerns.","Poorly implemented security measures during app development can expose users and financial institutions to substantial financial risks through increased vulnerability to cyberattacks.","Our study evaluated fifty-nine WAEMU MBAs using static analysis techniques.","These MBAs were collected from the 160 banks and financial institutions of the eight WAEMU countries listed on the Central Bank of West African States (BCEAO) website.","We identified security-related code issues that could be exploited by malicious actors.","We investigated the issues found in the older versions to track their evolution across updates.","Additionally, we identified some banks from regions such as Europe, the United States, and other developing countries and analyzed their mobile apps for a security comparison with WAEMU MBAs.","Key findings include: (1) WAEMU apps exhibit security issues introduced during development, posing significant risks of exploitation; (2) Despite frequent updates, underlying security issues often persist; (3) Compared to MBAs from developed and developing countries, WAEMU apps exhibit fewer critical security issues; and (4) Apps from banks that are branches of other non-WAEMU banks often inherit security concerns from their parent apps while also introducing additional issues unique to their context.","Our research underscores the need for robust security practices in WAEMU MBAs development to enhance user safety and trust in financial services."],"url":"http://arxiv.org/abs/2411.04068v1"}
{"created":"2024-11-06 17:28:28","title":"Soft Reverse Reconciliation for Discrete Modulations","abstract":"The performance of the information reconciliation phase is crucial for quantum key distribution (QKD). Reverse reconciliation (RR) is typically preferred over direct reconciliation (DR) because it yields higher secure key rates. However, a significant challenge in continuous-variable (CV) QKD with discrete modulations (such as QAM) is that Alice lacks soft information about the symbol decisions made by Bob. This limitation restricts error correction to hard-decoding methods, with low reconciliation efficiency. This work introduces a reverse reconciliation softening (RRS) procedure designed for CV-QKD scenarios employing discrete modulations. This procedure generates a soft metric that Bob can share with Alice over a public channel, enabling her to perform soft-decoding error correction without disclosing any information to a potential eavesdropper. After detailing the RRS procedure, we investigate how the mutual information between Alice's and Bob's variables changes when the additional metric is shared. We show numerically that RRS improves the mutual information with respect to RR with hard decoding, practically achieving the same mutual information as DR with soft decoding. Finally, we test the proposed RRS for PAM-4 signalling with a rate 1/2 binary LDPC code and bit-wise decoding through numerical simulations, obtaining more than 1dB SNR improvement compared to hard-decoding RR.","sentences":["The performance of the information reconciliation phase is crucial for quantum key distribution (QKD).","Reverse reconciliation (RR) is typically preferred over direct reconciliation (DR) because it yields higher secure key rates.","However, a significant challenge in continuous-variable (CV) QKD with discrete modulations (such as QAM) is that Alice lacks soft information about the symbol decisions made by Bob.","This limitation restricts error correction to hard-decoding methods, with low reconciliation efficiency.","This work introduces a reverse reconciliation softening (RRS) procedure designed for CV-QKD scenarios employing discrete modulations.","This procedure generates a soft metric that Bob can share with Alice over a public channel, enabling her to perform soft-decoding error correction without disclosing any information to a potential eavesdropper.","After detailing the RRS procedure, we investigate how the mutual information between Alice's and Bob's variables changes when the additional metric is shared.","We show numerically that RRS improves the mutual information with respect to RR with hard decoding, practically achieving the same mutual information as DR with soft decoding.","Finally, we test the proposed RRS for PAM-4 signalling with a rate 1/2 binary LDPC code and bit-wise decoding through numerical simulations, obtaining more than 1dB SNR improvement compared to hard-decoding RR."],"url":"http://arxiv.org/abs/2411.04063v1"}
{"created":"2024-11-06 17:11:44","title":"Pseudo-labeling with Keyword Refining for Few-Supervised Video Captioning","abstract":"Video captioning generate a sentence that describes the video content. Existing methods always require a number of captions (\\eg, 10 or 20) per video to train the model, which is quite costly. In this work, we explore the possibility of using only one or very few ground-truth sentences, and introduce a new task named few-supervised video captioning. Specifically, we propose a few-supervised video captioning framework that consists of lexically constrained pseudo-labeling module and keyword-refined captioning module. Unlike the random sampling in natural language processing that may cause invalid modifications (\\ie, edit words), the former module guides the model to edit words using some actions (\\eg, copy, replace, insert, and delete) by a pretrained token-level classifier, and then fine-tunes candidate sentences by a pretrained language model. Meanwhile, the former employs the repetition penalized sampling to encourage the model to yield concise pseudo-labeled sentences with less repetition, and selects the most relevant sentences upon a pretrained video-text model. Moreover, to keep semantic consistency between pseudo-labeled sentences and video content, we develop the transformer-based keyword refiner with the video-keyword gated fusion strategy to emphasize more on relevant words. Extensive experiments on several benchmarks demonstrate the advantages of the proposed approach in both few-supervised and fully-supervised scenarios. The code implementation is available at https://github.com/mlvccn/PKG_VidCap","sentences":["Video captioning generate a sentence that describes the video content.","Existing methods always require a number of captions (\\eg, 10 or 20) per video to train the model, which is quite costly.","In this work, we explore the possibility of using only one or very few ground-truth sentences, and introduce a new task named few-supervised video captioning.","Specifically, we propose a few-supervised video captioning framework that consists of lexically constrained pseudo-labeling module and keyword-refined captioning module.","Unlike the random sampling in natural language processing that may cause invalid modifications (\\ie, edit words), the former module guides the model to edit words using some actions (\\eg, copy, replace, insert, and delete) by a pretrained token-level classifier, and then fine-tunes candidate sentences by a pretrained language model.","Meanwhile, the former employs the repetition penalized sampling to encourage the model to yield concise pseudo-labeled sentences with less repetition, and selects the most relevant sentences upon a pretrained video-text model.","Moreover, to keep semantic consistency between pseudo-labeled sentences and video content, we develop the transformer-based keyword refiner with the video-keyword gated fusion strategy to emphasize more on relevant words.","Extensive experiments on several benchmarks demonstrate the advantages of the proposed approach in both few-supervised and fully-supervised scenarios.","The code implementation is available at https://github.com/mlvccn/PKG_VidCap"],"url":"http://arxiv.org/abs/2411.04059v1"}
{"created":"2024-11-06 17:05:58","title":"Problem Space Transformations for Generalisation in Behavioural Cloning","abstract":"The combination of behavioural cloning and neural networks has driven significant progress in robotic manipulation. As these algorithms may require a large number of demonstrations for each task of interest, they remain fundamentally inefficient in complex scenarios. This issue is aggravated when the system is treated as a black-box, ignoring its physical properties. This work characterises widespread properties of robotic manipulation, such as pose equivariance and locality. We empirically demonstrate that transformations arising from each of these properties allow neural policies trained with behavioural cloning to better generalise to out-of-distribution problem instances.","sentences":["The combination of behavioural cloning and neural networks has driven significant progress in robotic manipulation.","As these algorithms may require a large number of demonstrations for each task of interest, they remain fundamentally inefficient in complex scenarios.","This issue is aggravated when the system is treated as a black-box, ignoring its physical properties.","This work characterises widespread properties of robotic manipulation, such as pose equivariance and locality.","We empirically demonstrate that transformations arising from each of these properties allow neural policies trained with behavioural cloning to better generalise to out-of-distribution problem instances."],"url":"http://arxiv.org/abs/2411.04056v1"}
{"created":"2024-11-06 16:59:51","title":"Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice Layer Thickness Prediction","abstract":"Understanding spatio-temporal patterns in polar ice layers is essential for tracking changes in ice sheet balance and assessing ice dynamics. While convolutional neural networks are widely used in learning ice layer patterns from raw echogram images captured by airborne snow radar sensors, noise in the echogram images prevents researchers from getting high-quality results. Instead, we focus on geometric deep learning using graph neural networks, aiming to build a spatio-temporal graph neural network that learns from thickness information of the top ice layers and predicts for deeper layers. In this paper, we developed a novel multi-branch spatio-temporal graph neural network that used the GraphSAGE framework for spatio features learning and a temporal convolution operation to capture temporal changes, enabling different branches of the network to be more specialized and focusing on a single learning task. We found that our proposed multi-branch network can consistently outperform the current fused spatio-temporal graph neural network in both accuracy and efficiency.","sentences":["Understanding spatio-temporal patterns in polar ice layers is essential for tracking changes in ice sheet balance and assessing ice dynamics.","While convolutional neural networks are widely used in learning ice layer patterns from raw echogram images captured by airborne snow radar sensors, noise in the echogram images prevents researchers from getting high-quality results.","Instead, we focus on geometric deep learning using graph neural networks, aiming to build a spatio-temporal graph neural network that learns from thickness information of the top ice layers and predicts for deeper layers.","In this paper, we developed a novel multi-branch spatio-temporal graph neural network that used the GraphSAGE framework for spatio features learning and a temporal convolution operation to capture temporal changes, enabling different branches of the network to be more specialized and focusing on a single learning task.","We found that our proposed multi-branch network can consistently outperform the current fused spatio-temporal graph neural network in both accuracy and efficiency."],"url":"http://arxiv.org/abs/2411.04055v1"}
{"created":"2024-11-06 16:57:55","title":"Reproducible Hybrid Time-Travel Retrieval in Evolving Corpora","abstract":"There are settings in which reproducibility of ranked lists is desirable, such as when extracting a subset of an evolving document corpus for downstream research tasks or in domains such as patent retrieval or in medical systematic reviews, with high reproducibility expectations. However, as global term statistics change when documents change or are added to a corpus, queries using typical ranked retrieval models are not even reproducible for the parts of the document corpus that have not changed. Thus, Boolean retrieval frequently remains the mechanism of choice in such settings.   We present a hybrid retrieval system combining Lucene for fast retrieval with a column-store-based retrieval system maintaining a versioned and time-stamped index. The latter component allows re-execution of previously posed queries resulting in the same ranked list and further allows for time-travel queries over evolving collection, as web archives, while maintaining the original ranking. Thus, retrieval results in evolving document collections are fully reproducible even when document collections and thus term statistics change.","sentences":["There are settings in which reproducibility of ranked lists is desirable, such as when extracting a subset of an evolving document corpus for downstream research tasks or in domains such as patent retrieval or in medical systematic reviews, with high reproducibility expectations.","However, as global term statistics change when documents change or are added to a corpus, queries using typical ranked retrieval models are not even reproducible for the parts of the document corpus that have not changed.","Thus, Boolean retrieval frequently remains the mechanism of choice in such settings.   ","We present a hybrid retrieval system combining Lucene for fast retrieval with a column-store-based retrieval system maintaining a versioned and time-stamped index.","The latter component allows re-execution of previously posed queries resulting in the same ranked list and further allows for time-travel queries over evolving collection, as web archives, while maintaining the original ranking.","Thus, retrieval results in evolving document collections are fully reproducible even when document collections and thus term statistics change."],"url":"http://arxiv.org/abs/2411.04051v1"}
{"created":"2024-11-06 16:57:36","title":"Memorized action chunking with Transformers: Imitation learning for vision-based tissue surface scanning","abstract":"Optical sensing technologies are emerging technologies used in cancer surgeries to ensure the complete removal of cancerous tissue. While point-wise assessment has many potential applications, incorporating automated large area scanning would enable holistic tissue sampling. However, such scanning tasks are challenging due to their long-horizon dependency and the requirement for fine-grained motion. To address these issues, we introduce Memorized Action Chunking with Transformers (MACT), an intuitive yet efficient imitation learning method for tissue surface scanning tasks. It utilizes a sequence of past images as historical information to predict near-future action sequences. In addition, hybrid temporal-spatial positional embeddings were employed to facilitate learning. In various simulation settings, MACT demonstrated significant improvements in contour scanning and area scanning over the baseline model. In real-world testing, with only 50 demonstration trajectories, MACT surpassed the baseline model by achieving a 60-80% success rate on all scanning tasks. Our findings suggest that MACT is a promising model for adaptive scanning in surgical settings.","sentences":["Optical sensing technologies are emerging technologies used in cancer surgeries to ensure the complete removal of cancerous tissue.","While point-wise assessment has many potential applications, incorporating automated large area scanning would enable holistic tissue sampling.","However, such scanning tasks are challenging due to their long-horizon dependency and the requirement for fine-grained motion.","To address these issues, we introduce Memorized Action Chunking with Transformers (MACT), an intuitive yet efficient imitation learning method for tissue surface scanning tasks.","It utilizes a sequence of past images as historical information to predict near-future action sequences.","In addition, hybrid temporal-spatial positional embeddings were employed to facilitate learning.","In various simulation settings, MACT demonstrated significant improvements in contour scanning and area scanning over the baseline model.","In real-world testing, with only 50 demonstration trajectories, MACT surpassed the baseline model by achieving a 60-80% success rate on all scanning tasks.","Our findings suggest that MACT is a promising model for adaptive scanning in surgical settings."],"url":"http://arxiv.org/abs/2411.04050v1"}
{"created":"2024-11-06 16:51:30","title":"Design and control of a robotic payload stabilization mechanism for rocket flights","abstract":"The use of parallel manipulators in aerospace engineering has gained significant attention due to their ability to provide improved stability and precision. This paper presents the design, control, and analysis of 'STEWIE', which is a three-degree-of-freedom (DoF) parallel manipulator robot developed by members of the thrustMIT rocketry team, as a payload stabilization mechanism for their sounding rocket, 'Altair'. The goal of the robot was to demonstrate the attitude control of the parallel plate against the continuous change in orientation experienced by the rocket during its flight, stabilizing the payloads. At the same time, the high gravitational forces (G-forces) and vibrations experienced by the sounding rocket are counteracted. A novel design of the mechanism, inspired by a standard Stewart platform, is proposed which was down-scaled to fit inside a 4U CubeSat within its space constraints. The robot uses three micro servo motors to actuate the links that control the alignment of the parallel plate. In addition to the actuation mechanism, a robust control system for its manipulation was developed for the robot. The robot represents a significant advancement in the field of space robotics in the aerospace industry by demonstrating the successful implementation of complex robotic mechanisms in small, confined spaces such as CubeSats, which are standard form factors for large payloads in the aerospace industry.","sentences":["The use of parallel manipulators in aerospace engineering has gained significant attention due to their ability to provide improved stability and precision.","This paper presents the design, control, and analysis of 'STEWIE', which is a three-degree-of-freedom (DoF)","parallel manipulator robot developed by members of the thrustMIT rocketry team, as a payload stabilization mechanism for their sounding rocket, 'Altair'.","The goal of the robot was to demonstrate the attitude control of the parallel plate against the continuous change in orientation experienced by the rocket during its flight, stabilizing the payloads.","At the same time, the high gravitational forces (G-forces) and vibrations experienced by the sounding rocket are counteracted.","A novel design of the mechanism, inspired by a standard Stewart platform, is proposed which was down-scaled to fit inside a 4U CubeSat within its space constraints.","The robot uses three micro servo motors to actuate the links that control the alignment of the parallel plate.","In addition to the actuation mechanism, a robust control system for its manipulation was developed for the robot.","The robot represents a significant advancement in the field of space robotics in the aerospace industry by demonstrating the successful implementation of complex robotic mechanisms in small, confined spaces such as CubeSats, which are standard form factors for large payloads in the aerospace industry."],"url":"http://arxiv.org/abs/2411.04046v1"}
{"created":"2024-11-06 16:41:41","title":"Instance-Optimal Acyclic Join Processing Without Regret: Engineering the Yannakakis Algorithm in Column Stores","abstract":"Acyclic join queries can be evaluated instance-optimally using Yannakakis' algorithm, which avoids needlessly large intermediate results through semi-join passes. Recent work proposes to address the significant hidden constant factors arising from a naive implementation of Yannakakis by decomposing the hash join operator into two suboperators, called Lookup and Expand. In this paper, we present a novel method for integrating Lookup and Expand plans in interpreted environments, like column stores, formalizing them using Nested Semijoin Algebra (NSA) and implementing them through a shredding approach. We characterize the class of NSA expressions that can be evaluated instance-optimally as those that are 2-phase: no `shrinking' operator is applied after an unnest (i.e., expand). We introduce Shredded Yannakakis (SYA), an evaluation algorithm for acyclic joins that, starting from a binary join plan, transforms it into a 2-phase NSA plan, and then evaluates it through the shredding technique. We show that SYA is provably robust (i.e., never produces large intermediate results) and without regret (i.e., is never worse than the binary join plan under a suitable cost model) on the class of well-behaved binary join plans. Our experiments on a suite of 1,849 queries show that SYA improves performance for 88.7% of the queries with speedups up to 188x, while remaining competitive on the other queries. We hope this approach offers a fresh perspective on Yannakakis' algorithm, helping system engineers better understand its practical benefits and facilitating its adoption into a broader spectrum of query engines.","sentences":["Acyclic join queries can be evaluated instance-optimally using Yannakakis' algorithm, which avoids needlessly large intermediate results through semi-join passes.","Recent work proposes to address the significant hidden constant factors arising from a naive implementation of Yannakakis by decomposing the hash join operator into two suboperators, called Lookup and Expand.","In this paper, we present a novel method for integrating Lookup and Expand plans in interpreted environments, like column stores, formalizing them using Nested Semijoin Algebra (NSA) and implementing them through a shredding approach.","We characterize the class of NSA expressions that can be evaluated instance-optimally as those that are 2-phase: no `shrinking' operator is applied after an unnest (i.e., expand).","We introduce Shredded Yannakakis (SYA), an evaluation algorithm for acyclic joins that, starting from a binary join plan, transforms it into a 2-phase NSA plan, and then evaluates it through the shredding technique.","We show that SYA is provably robust (i.e., never produces large intermediate results) and without regret (i.e., is never worse than the binary join plan under a suitable cost model) on the class of well-behaved binary join plans.","Our experiments on a suite of 1,849 queries show that SYA improves performance for 88.7% of the queries with speedups up to 188x, while remaining competitive on the other queries.","We hope this approach offers a fresh perspective on Yannakakis' algorithm, helping system engineers better understand its practical benefits and facilitating its adoption into a broader spectrum of query engines."],"url":"http://arxiv.org/abs/2411.04042v1"}
{"created":"2024-11-06 16:34:59","title":"Taming Toxicity or Fueling It? The Great Ban Role in Shifting Toxic User Behavior and Engagement","abstract":"In today's online environments users experience harm and abuse on a daily basis. Therefore, content moderation is crucial to ensure their safety and well-being. However, the effectiveness of many moderation interventions is still uncertain. We evaluate the effectiveness of The Great Ban, one of the largest deplatforming interventions carried out by Reddit that affected almost 2,000 communities. We analyze 53M comments shared by nearly 34K users, providing in-depth results on both the intended and unintended consequences of this ban. We found that 15.6\\% of the moderated users abandoned the platform while the remaining ones decreased their overall toxicity by 4.1\\%. Nonetheless, a subset of those users increased their toxicity by 70\\% after the intervention. In any case, increases in toxicity did not lead to marked increases in activity or engagement, meaning that the most toxic users had overall a limited impact. Our findings bring to light new insights on the effectiveness of deplatforming. Furthermore, they also contribute to informing future content moderation strategies.","sentences":["In today's online environments users experience harm and abuse on a daily basis.","Therefore, content moderation is crucial to ensure their safety and well-being.","However, the effectiveness of many moderation interventions is still uncertain.","We evaluate the effectiveness of The Great Ban, one of the largest deplatforming interventions carried out by Reddit that affected almost 2,000 communities.","We analyze 53M comments shared by nearly 34K users, providing in-depth results on both the intended and unintended consequences of this ban.","We found that 15.6\\% of the moderated users abandoned the platform while the remaining ones decreased their overall toxicity by 4.1\\%.","Nonetheless, a subset of those users increased their toxicity by 70\\% after the intervention.","In any case, increases in toxicity did not lead to marked increases in activity or engagement, meaning that the most toxic users had overall a limited impact.","Our findings bring to light new insights on the effectiveness of deplatforming.","Furthermore, they also contribute to informing future content moderation strategies."],"url":"http://arxiv.org/abs/2411.04037v1"}
{"created":"2024-11-06 16:33:21","title":"Stepping Forward on the Last Mile","abstract":"Continuously adapting pre-trained models to local data on resource constrained edge devices is the $\\emph{last mile}$ for model deployment. However, as models increase in size and depth, backpropagation requires a large amount of memory, which becomes prohibitive for edge devices. In addition, most existing low power neural processing engines (e.g., NPUs, DSPs, MCUs, etc.) are designed as fixed-point inference accelerators, without training capabilities. Forward gradients, solely based on directional derivatives computed from two forward calls, have been recently used for model training, with substantial savings in computation and memory. However, the performance of quantized training with fixed-point forward gradients remains unclear. In this paper, we investigate the feasibility of on-device training using fixed-point forward gradients, by conducting comprehensive experiments across a variety of deep learning benchmark tasks in both vision and audio domains. We propose a series of algorithm enhancements that further reduce the memory footprint, and the accuracy gap compared to backpropagation. An empirical study on how training with forward gradients navigates in the loss landscape is further explored. Our results demonstrate that on the last mile of model customization on edge devices, training with fixed-point forward gradients is a feasible and practical approach.","sentences":["Continuously adapting pre-trained models to local data on resource constrained edge devices is the $\\emph{last mile}$ for model deployment.","However, as models increase in size and depth, backpropagation requires a large amount of memory, which becomes prohibitive for edge devices.","In addition, most existing low power neural processing engines (e.g., NPUs, DSPs, MCUs, etc.) are designed as fixed-point inference accelerators, without training capabilities.","Forward gradients, solely based on directional derivatives computed from two forward calls, have been recently used for model training, with substantial savings in computation and memory.","However, the performance of quantized training with fixed-point forward gradients remains unclear.","In this paper, we investigate the feasibility of on-device training using fixed-point forward gradients, by conducting comprehensive experiments across a variety of deep learning benchmark tasks in both vision and audio domains.","We propose a series of algorithm enhancements that further reduce the memory footprint, and the accuracy gap compared to backpropagation.","An empirical study on how training with forward gradients navigates in the loss landscape is further explored.","Our results demonstrate that on the last mile of model customization on edge devices, training with fixed-point forward gradients is a feasible and practical approach."],"url":"http://arxiv.org/abs/2411.04036v1"}
{"created":"2024-11-06 16:32:40","title":"Non-Stationary Learning of Neural Networks with Automatic Soft Parameter Reset","abstract":"Neural networks are traditionally trained under the assumption that data come from a stationary distribution. However, settings which violate this assumption are becoming more popular; examples include supervised learning under distributional shifts, reinforcement learning, continual learning and non-stationary contextual bandits. In this work we introduce a novel learning approach that automatically models and adapts to non-stationarity, via an Ornstein-Uhlenbeck process with an adaptive drift parameter. The adaptive drift tends to draw the parameters towards the initialisation distribution, so the approach can be understood as a form of soft parameter reset. We show empirically that our approach performs well in non-stationary supervised and off-policy reinforcement learning settings.","sentences":["Neural networks are traditionally trained under the assumption that data come from a stationary distribution.","However, settings which violate this assumption are becoming more popular; examples include supervised learning under distributional shifts, reinforcement learning, continual learning and non-stationary contextual bandits.","In this work we introduce a novel learning approach that automatically models and adapts to non-stationarity, via an Ornstein-Uhlenbeck process with an adaptive drift parameter.","The adaptive drift tends to draw the parameters towards the initialisation distribution, so the approach can be understood as a form of soft parameter reset.","We show empirically that our approach performs well in non-stationary supervised and off-policy reinforcement learning settings."],"url":"http://arxiv.org/abs/2411.04034v1"}
{"created":"2024-11-06 16:31:28","title":"Beemo: Benchmark of Expert-edited Machine-generated Outputs","abstract":"The rapid proliferation of large language models (LLMs) has increased the volume of machine-generated texts (MGTs) and blurred text authorship in various domains. However, most existing MGT benchmarks include single-author texts (human-written and machine-generated). This conventional design fails to capture more practical multi-author scenarios, where the user refines the LLM response for natural flow, coherence, and factual correctness. Our paper introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo), which includes 6.5k texts written by humans, generated by ten instruction-finetuned LLMs, and edited by experts for various use cases, ranging from creative writing to summarization. Beemo additionally comprises 13.1k machine-generated and LLM-edited texts, allowing for diverse MGT detection evaluation across various edit types. We document Beemo's creation protocol and present the results of benchmarking 33 configurations of MGT detectors in different experimental setups. We find that expert-based editing evades MGT detection, while LLM-edited texts are unlikely to be recognized as human-written. Beemo and all materials are publicly available.","sentences":["The rapid proliferation of large language models (LLMs) has increased the volume of machine-generated texts (MGTs) and blurred text authorship in various domains.","However, most existing MGT benchmarks include single-author texts (human-written and machine-generated).","This conventional design fails to capture more practical multi-author scenarios, where the user refines the LLM response for natural flow, coherence, and factual correctness.","Our paper introduces the Benchmark of Expert-edited Machine-generated Outputs (Beemo), which includes 6.5k texts written by humans, generated by ten instruction-finetuned LLMs, and edited by experts for various use cases, ranging from creative writing to summarization.","Beemo additionally comprises 13.1k machine-generated and LLM-edited texts, allowing for diverse MGT detection evaluation across various edit types.","We document Beemo's creation protocol and present the results of benchmarking 33 configurations of MGT detectors in different experimental setups.","We find that expert-based editing evades MGT detection, while LLM-edited texts are unlikely to be recognized as human-written.","Beemo and all materials are publicly available."],"url":"http://arxiv.org/abs/2411.04032v1"}
{"created":"2024-11-06 16:28:17","title":"Quantum-Safe Hybrid Key Exchanges with KEM-Based Authentication","abstract":"Authenticated Key Exchange (AKE) between any two entities is one of the most important security protocols available for securing our digital networks and infrastructures. In PQCrypto 2023, Bruckner, Ramacher and Striecks proposed a novel hybrid AKE (HAKE) protocol, dubbed Muckle+, that is particularly useful in large quantum-safe networks consisting of a large number of nodes. Their protocol is hybrid in the sense that it allows key material from conventional and post-quantum primitives, as well as from quantum key distribution, to be incorporated into a single end-to-end shared key.   To achieve the desired authentication properties, Muckle+ utilizes post-quantum digital signatures. However, available instantiations of such signatures schemes are not yet efficient enough compared to their post-quantum key-encapsulation mechanism (KEM) counterparts, particularly in large networks with potentially several connections in a short period of time.   To mitigate this gap, we propose Muckle# that pushes the efficiency boundaries of currently known HAKE constructions. Muckle# uses post-quantum key-encapsulating mechanisms for implicit authentication inspired by recent works done in the area of Transport Layer Security (TLS) protocols, particularly, in KEMTLS (CCS'20).   We port those ideas to the HAKE framework and develop novel proof techniques on the way. Due to our novel KEM-based approach, the resulting protocol has a slightly different message flow compared to prior work that we carefully align with the HAKE framework and which makes our changes to the Muckle+ non-trivial.","sentences":["Authenticated Key Exchange (AKE) between any two entities is one of the most important security protocols available for securing our digital networks and infrastructures.","In PQCrypto 2023, Bruckner, Ramacher and Striecks proposed a novel hybrid AKE (HAKE) protocol, dubbed Muckle+, that is particularly useful in large quantum-safe networks consisting of a large number of nodes.","Their protocol is hybrid in the sense that it allows key material from conventional and post-quantum primitives, as well as from quantum key distribution, to be incorporated into a single end-to-end shared key.   ","To achieve the desired authentication properties, Muckle+ utilizes post-quantum digital signatures.","However, available instantiations of such signatures schemes are not yet efficient enough compared to their post-quantum key-encapsulation mechanism (KEM) counterparts, particularly in large networks with potentially several connections in a short period of time.   ","To mitigate this gap, we propose Muckle# that pushes the efficiency boundaries of currently known HAKE constructions.","Muckle# uses post-quantum key-encapsulating mechanisms for implicit authentication inspired by recent works done in the area of Transport Layer Security (TLS) protocols, particularly, in KEMTLS (CCS'20).   ","We port those ideas to the HAKE framework and develop novel proof techniques on the way.","Due to our novel KEM-based approach, the resulting protocol has a slightly different message flow compared to prior work that we carefully align with the HAKE framework and which makes our changes to the Muckle+ non-trivial."],"url":"http://arxiv.org/abs/2411.04030v1"}
{"created":"2024-11-06 16:21:19","title":"Prototyping O-RAN Enabled UAV Experimentation for the AERPAW Testbed","abstract":"The Open Radio Access Network (O-RAN) architecture is reshaping the telecommunications landscape by enhancing network flexibility, openness, and intelligence. This paper establishes the requirements, evaluates the design tradeoffs, and introduces a scalable architecture and prototype of an open-source O-RAN experimentation platform within the Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW), an at scale testbed that integrates unmanned aerial vehicles (UAVs) with advanced wireless network technologies, offering experimentation in both outdoor testbed and emulation via a custom digital twin (DT). Through a series of aerial experiments, we evaluate FlexRIC, an open-source RAN Intelligent Controller, within the AERPAW hardware-software platform for network data monitoring, providing valuable insights into the proposed integration and revealing opportunities for leveraging O-RAN to create custom service based optimizations for cellular connected UAVs. We discuss the challenges and potential use cases of this integration and demonstrate the use of a generative artificial intelligence model for generating realistic data based on collected real-world data to support AERPAW's DT.","sentences":["The Open Radio Access Network (O-RAN) architecture is reshaping the telecommunications landscape by enhancing network flexibility, openness, and intelligence.","This paper establishes the requirements, evaluates the design tradeoffs, and introduces a scalable architecture and prototype of an open-source O-RAN experimentation platform within the Aerial Experimentation and Research Platform for Advanced Wireless (AERPAW), an at scale testbed that integrates unmanned aerial vehicles (UAVs) with advanced wireless network technologies, offering experimentation in both outdoor testbed and emulation via a custom digital twin (DT).","Through a series of aerial experiments, we evaluate FlexRIC, an open-source RAN Intelligent Controller, within the AERPAW hardware-software platform for network data monitoring, providing valuable insights into the proposed integration and revealing opportunities for leveraging O-RAN to create custom service based optimizations for cellular connected UAVs.","We discuss the challenges and potential use cases of this integration and demonstrate the use of a generative artificial intelligence model for generating realistic data based on collected real-world data to support AERPAW's DT."],"url":"http://arxiv.org/abs/2411.04027v1"}
{"created":"2024-11-06 16:20:37","title":"Prompt Engineering Using GPT for Word-Level Code-Mixed Language Identification in Low-Resource Dravidian Languages","abstract":"Language Identification (LI) is crucial for various natural language processing tasks, serving as a foundational step in applications such as sentiment analysis, machine translation, and information retrieval. In multilingual societies like India, particularly among the youth engaging on social media, text often exhibits code-mixing, blending local languages with English at different linguistic levels. This phenomenon presents formidable challenges for LI systems, especially when languages intermingle within single words. Dravidian languages, prevalent in southern India, possess rich morphological structures yet suffer from under-representation in digital platforms, leading to the adoption of Roman or hybrid scripts for communication. This paper introduces a prompt based method for a shared task aimed at addressing word-level LI challenges in Dravidian languages. In this work, we leveraged GPT-3.5 Turbo to understand whether the large language models is able to correctly classify words into correct categories. Our findings show that the Kannada model consistently outperformed the Tamil model across most metrics, indicating a higher accuracy and reliability in identifying and categorizing Kannada language instances. In contrast, the Tamil model showed moderate performance, particularly needing improvement in precision and recall.","sentences":["Language Identification (LI) is crucial for various natural language processing tasks, serving as a foundational step in applications such as sentiment analysis, machine translation, and information retrieval.","In multilingual societies like India, particularly among the youth engaging on social media, text often exhibits code-mixing, blending local languages with English at different linguistic levels.","This phenomenon presents formidable challenges for LI systems, especially when languages intermingle within single words.","Dravidian languages, prevalent in southern India, possess rich morphological structures yet suffer from under-representation in digital platforms, leading to the adoption of Roman or hybrid scripts for communication.","This paper introduces a prompt based method for a shared task aimed at addressing word-level LI challenges in Dravidian languages.","In this work, we leveraged GPT-3.5","Turbo to understand whether the large language models is able to correctly classify words into correct categories.","Our findings show that the Kannada model consistently outperformed the Tamil model across most metrics, indicating a higher accuracy and reliability in identifying and categorizing Kannada language instances.","In contrast, the Tamil model showed moderate performance, particularly needing improvement in precision and recall."],"url":"http://arxiv.org/abs/2411.04025v1"}
{"created":"2024-11-06 15:57:20","title":"Multi-Scale and Multimodal Species Distribution Modeling","abstract":"Species distribution models (SDMs) aim to predict the distribution of species by relating occurrence data with environmental variables. Recent applications of deep learning to SDMs have enabled new avenues, specifically the inclusion of spatial data (environmental rasters, satellite images) as model predictors, allowing the model to consider the spatial context around each species' observations. However, the appropriate spatial extent of the images is not straightforward to determine and may affect the performance of the model, as scale is recognized as an important factor in SDMs. We develop a modular structure for SDMs that allows us to test the effect of scale in both single- and multi-scale settings. Furthermore, our model enables different scales to be considered for different modalities, using a late fusion approach. Results on the GeoLifeCLEF 2023 benchmark indicate that considering multimodal data and learning multi-scale representations leads to more accurate models.","sentences":["Species distribution models (SDMs) aim to predict the distribution of species by relating occurrence data with environmental variables.","Recent applications of deep learning to SDMs have enabled new avenues, specifically the inclusion of spatial data (environmental rasters, satellite images) as model predictors, allowing the model to consider the spatial context around each species' observations.","However, the appropriate spatial extent of the images is not straightforward to determine and may affect the performance of the model, as scale is recognized as an important factor in SDMs.","We develop a modular structure for SDMs that allows us to test the effect of scale in both single- and multi-scale settings.","Furthermore, our model enables different scales to be considered for different modalities, using a late fusion approach.","Results on the GeoLifeCLEF 2023 benchmark indicate that considering multimodal data and learning multi-scale representations leads to more accurate models."],"url":"http://arxiv.org/abs/2411.04016v1"}
{"created":"2024-11-06 15:50:19","title":"$k$NN Attention Demystified: A Theoretical Exploration for Scalable Transformers","abstract":"Despite their power, Transformers face challenges with long sequences due to the quadratic complexity of self-attention. To address this limitation, methods like $k$-Nearest-Neighbor ($k$NN) attention have been introduced [Roy, Saffar, Vaswani, Grangier, 2021] enabling each token to attend to only its $k$ closest tokens. While $k$NN attention has shown empirical success in making Transformers more efficient, its exact approximation guarantees have not been theoretically analyzed. In this work, we establish a theoretical framework for $k$NN attention, reformulating self-attention as expectations over softmax distributions and leveraging lazy Gumbel sampling [Mussmann, Levy, Ermon, 2017] with $k$NN indices for efficient approximation. Building on this framework, we also propose novel sub-quadratic algorithms that approximate self-attention gradients by leveraging efficient sampling techniques, such as Markov Chain-based estimation. Finally, we demonstrate the practical effectiveness of these algorithms through empirical experiments, showcasing their benefits in both training and inference.","sentences":["Despite their power, Transformers face challenges with long sequences due to the quadratic complexity of self-attention.","To address this limitation, methods like $k$-Nearest-Neighbor ($k$NN) attention have been introduced [Roy, Saffar, Vaswani, Grangier, 2021] enabling each token to attend to only its $k$ closest tokens.","While $k$NN attention has shown empirical success in making Transformers more efficient, its exact approximation guarantees have not been theoretically analyzed.","In this work, we establish a theoretical framework for $k$NN attention, reformulating self-attention as expectations over softmax distributions and leveraging lazy Gumbel sampling [Mussmann, Levy, Ermon, 2017] with $k$NN indices for efficient approximation.","Building on this framework, we also propose novel sub-quadratic algorithms that approximate self-attention gradients by leveraging efficient sampling techniques, such as Markov Chain-based estimation.","Finally, we demonstrate the practical effectiveness of these algorithms through empirical experiments, showcasing their benefits in both training and inference."],"url":"http://arxiv.org/abs/2411.04013v1"}
{"created":"2024-11-06 15:47:18","title":"Aligning Characteristic Descriptors with Images for Human-Expert-like Explainability","abstract":"In mission-critical domains such as law enforcement and medical diagnosis, the ability to explain and interpret the outputs of deep learning models is crucial for ensuring user trust and supporting informed decision-making. Despite advancements in explainability, existing methods often fall short in providing explanations that mirror the depth and clarity of those given by human experts. Such expert-level explanations are essential for the dependable application of deep learning models in law enforcement and medical contexts. Additionally, we recognize that most explanations in real-world scenarios are communicated primarily through natural language. Addressing these needs, we propose a novel approach that utilizes characteristic descriptors to explain model decisions by identifying their presence in images, thereby generating expert-like explanations. Our method incorporates a concept bottleneck layer within the model architecture, which calculates the similarity between image and descriptor encodings to deliver inherent and faithful explanations. Through experiments in face recognition and chest X-ray diagnosis, we demonstrate that our approach offers a significant contrast over existing techniques, which are often limited to the use of saliency maps. We believe our approach represents a significant step toward making deep learning systems more accountable, transparent, and trustworthy in the critical domains of face recognition and medical diagnosis.","sentences":["In mission-critical domains such as law enforcement and medical diagnosis, the ability to explain and interpret the outputs of deep learning models is crucial for ensuring user trust and supporting informed decision-making.","Despite advancements in explainability, existing methods often fall short in providing explanations that mirror the depth and clarity of those given by human experts.","Such expert-level explanations are essential for the dependable application of deep learning models in law enforcement and medical contexts.","Additionally, we recognize that most explanations in real-world scenarios are communicated primarily through natural language.","Addressing these needs, we propose a novel approach that utilizes characteristic descriptors to explain model decisions by identifying their presence in images, thereby generating expert-like explanations.","Our method incorporates a concept bottleneck layer within the model architecture, which calculates the similarity between image and descriptor encodings to deliver inherent and faithful explanations.","Through experiments in face recognition and chest X-ray diagnosis, we demonstrate that our approach offers a significant contrast over existing techniques, which are often limited to the use of saliency maps.","We believe our approach represents a significant step toward making deep learning systems more accountable, transparent, and trustworthy in the critical domains of face recognition and medical diagnosis."],"url":"http://arxiv.org/abs/2411.04008v1"}
{"created":"2024-11-06 15:44:59","title":"Select2Plan: Training-Free ICL-Based Planning through VQA and Memory Retrieval","abstract":"This study explores the potential of off-the-shelf Vision-Language Models (VLMs) for high-level robot planning in the context of autonomous navigation. Indeed, while most of existing learning-based approaches for path planning require extensive task-specific training/fine-tuning, we demonstrate how such training can be avoided for most practical cases. To do this, we introduce Select2Plan (S2P), a novel training-free framework for high-level robot planning which completely eliminates the need for fine-tuning or specialised training. By leveraging structured Visual Question-Answering (VQA) and In-Context Learning (ICL), our approach drastically reduces the need for data collection, requiring a fraction of the task-specific data typically used by trained models, or even relying only on online data. Our method facilitates the effective use of a generally trained VLM in a flexible and cost-efficient way, and does not require additional sensing except for a simple monocular camera. We demonstrate its adaptability across various scene types, context sources, and sensing setups. We evaluate our approach in two distinct scenarios: traditional First-Person View (FPV) and infrastructure-driven Third-Person View (TPV) navigation, demonstrating the flexibility and simplicity of our method. Our technique significantly enhances the navigational capabilities of a baseline VLM of approximately 50% in TPV scenario, and is comparable to trained models in the FPV one, with as few as 20 demonstrations.","sentences":["This study explores the potential of off-the-shelf Vision-Language Models (VLMs) for high-level robot planning in the context of autonomous navigation.","Indeed, while most of existing learning-based approaches for path planning require extensive task-specific training/fine-tuning, we demonstrate how such training can be avoided for most practical cases.","To do this, we introduce Select2Plan (S2P), a novel training-free framework for high-level robot planning which completely eliminates the need for fine-tuning or specialised training.","By leveraging structured Visual Question-Answering (VQA) and In-Context Learning (ICL), our approach drastically reduces the need for data collection, requiring a fraction of the task-specific data typically used by trained models, or even relying only on online data.","Our method facilitates the effective use of a generally trained VLM in a flexible and cost-efficient way, and does not require additional sensing except for a simple monocular camera.","We demonstrate its adaptability across various scene types, context sources, and sensing setups.","We evaluate our approach in two distinct scenarios: traditional First-Person View (FPV) and infrastructure-driven Third-Person View (TPV) navigation, demonstrating the flexibility and simplicity of our method.","Our technique significantly enhances the navigational capabilities of a baseline VLM of approximately 50% in TPV scenario, and is comparable to trained models in the FPV one, with as few as 20 demonstrations."],"url":"http://arxiv.org/abs/2411.04006v1"}
{"created":"2024-11-06 15:44:10","title":"Object-Centric Dexterous Manipulation from Human Motion Data","abstract":"Manipulating objects to achieve desired goal states is a basic but important skill for dexterous manipulation. Human hand motions demonstrate proficient manipulation capability, providing valuable data for training robots with multi-finger hands. Despite this potential, substantial challenges arise due to the embodiment gap between human and robot hands. In this work, we introduce a hierarchical policy learning framework that uses human hand motion data for training object-centric dexterous robot manipulation. At the core of our method is a high-level trajectory generative model, learned with a large-scale human hand motion capture dataset, to synthesize human-like wrist motions conditioned on the desired object goal states. Guided by the generated wrist motions, deep reinforcement learning is further used to train a low-level finger controller that is grounded in the robot's embodiment to physically interact with the object to achieve the goal. Through extensive evaluation across 10 household objects, our approach not only demonstrates superior performance but also showcases generalization capability to novel object geometries and goal states. Furthermore, we transfer the learned policies from simulation to a real-world bimanual dexterous robot system, further demonstrating its applicability in real-world scenarios. Project website: https://cypypccpy.github.io/obj-dex.github.io/.","sentences":["Manipulating objects to achieve desired goal states is a basic but important skill for dexterous manipulation.","Human hand motions demonstrate proficient manipulation capability, providing valuable data for training robots with multi-finger hands.","Despite this potential, substantial challenges arise due to the embodiment gap between human and robot hands.","In this work, we introduce a hierarchical policy learning framework that uses human hand motion data for training object-centric dexterous robot manipulation.","At the core of our method is a high-level trajectory generative model, learned with a large-scale human hand motion capture dataset, to synthesize human-like wrist motions conditioned on the desired object goal states.","Guided by the generated wrist motions, deep reinforcement learning is further used to train a low-level finger controller that is grounded in the robot's embodiment to physically interact with the object to achieve the goal.","Through extensive evaluation across 10 household objects, our approach not only demonstrates superior performance but also showcases generalization capability to novel object geometries and goal states.","Furthermore, we transfer the learned policies from simulation to a real-world bimanual dexterous robot system, further demonstrating its applicability in real-world scenarios.","Project website: https://cypypccpy.github.io/obj-dex.github.io/."],"url":"http://arxiv.org/abs/2411.04005v1"}
{"created":"2024-11-06 15:43:33","title":"Learning Aggregate Queries Defined by First-Order Logic with Counting","abstract":"In the logical framework introduced by Grohe and Tur\\'an (TOCS 2004) for Boolean classification problems, the instances to classify are tuples from a logical structure, and Boolean classifiers are described by parametric models based on logical formulas. This is a specific scenario for supervised passive learning, where classifiers should be learned based on labelled examples. Existing results in this scenario focus on Boolean classification. This paper presents learnability results beyond Boolean classification. We focus on multiclass classification problems where the task is to assign input tuples to arbitrary integers. To represent such integer-valued classifiers, we use aggregate queries specified by an extension of first-order logic with counting terms called FOC1.   Our main result shows the following: given a database of polylogarithmic degree, within quasi-linear time, we can build an index structure that makes it possible to learn FOC1-definable integer-valued classifiers in time polylogarithmic in the size of the database and polynomial in the number of training examples.","sentences":["In the logical framework introduced by Grohe and Tur\\'an (TOCS 2004) for Boolean classification problems, the instances to classify are tuples from a logical structure, and Boolean classifiers are described by parametric models based on logical formulas.","This is a specific scenario for supervised passive learning, where classifiers should be learned based on labelled examples.","Existing results in this scenario focus on Boolean classification.","This paper presents learnability results beyond Boolean classification.","We focus on multiclass classification problems where the task is to assign input tuples to arbitrary integers.","To represent such integer-valued classifiers, we use aggregate queries specified by an extension of first-order logic with counting terms called FOC1.   ","Our main result shows the following: given a database of polylogarithmic degree, within quasi-linear time, we can build an index structure that makes it possible to learn FOC1-definable integer-valued classifiers in time polylogarithmic in the size of the database and polynomial in the number of training examples."],"url":"http://arxiv.org/abs/2411.04003v1"}
{"created":"2024-11-06 15:40:46","title":"ParaGAN: A Scalable Distributed Training Framework for Generative Adversarial Networks","abstract":"Recent advances in Generative Artificial Intelligence have fueled numerous applications, particularly those involving Generative Adversarial Networks (GANs), which are essential for synthesizing realistic photos and videos. However, efficiently training GANs remains a critical challenge due to their computationally intensive and numerically unstable nature. Existing methods often require days or even weeks for training, posing significant resource and time constraints.   In this work, we introduce ParaGAN, a scalable distributed GAN training framework that leverages asynchronous training and an asymmetric optimization policy to accelerate GAN training. ParaGAN employs a congestion-aware data pipeline and hardware-aware layout transformation to enhance accelerator utilization, resulting in over 30% improvements in throughput. With ParaGAN, we reduce the training time of BigGAN from 15 days to 14 hours while achieving 91% scaling efficiency. Additionally, ParaGAN enables unprecedented high-resolution image generation using BigGAN.","sentences":["Recent advances in Generative Artificial Intelligence have fueled numerous applications, particularly those involving Generative Adversarial Networks (GANs), which are essential for synthesizing realistic photos and videos.","However, efficiently training GANs remains a critical challenge due to their computationally intensive and numerically unstable nature.","Existing methods often require days or even weeks for training, posing significant resource and time constraints.   ","In this work, we introduce ParaGAN, a scalable distributed GAN training framework that leverages asynchronous training and an asymmetric optimization policy to accelerate GAN training.","ParaGAN employs a congestion-aware data pipeline and hardware-aware layout transformation to enhance accelerator utilization, resulting in over 30% improvements in throughput.","With ParaGAN, we reduce the training time of BigGAN from 15 days to 14 hours while achieving 91% scaling efficiency.","Additionally, ParaGAN enables unprecedented high-resolution image generation using BigGAN."],"url":"http://arxiv.org/abs/2411.03999v1"}
{"created":"2024-11-06 15:38:31","title":"Towards Resource-Efficient Federated Learning in Industrial IoT for Multivariate Time Series Analysis","abstract":"Anomaly and missing data constitute a thorny problem in industrial applications. In recent years, deep learning enabled anomaly detection has emerged as a critical direction, however the improved detection accuracy is achieved with the utilization of large neural networks, increasing their storage and computational cost. Moreover, the data collected in edge devices contain user privacy, introducing challenges that can be successfully addressed by the privacy-preserving distributed paradigm, known as federated learning (FL). This framework allows edge devices to train and exchange models increasing also the communication cost. Thus, to deal with the increased communication, processing and storage challenges of the FL based deep anomaly detection NN pruning is expected to have significant benefits towards reducing the processing, storage and communication complexity. With this focus, a novel compression-based optimization problem is proposed at the server-side of a FL paradigm that fusses the received local models broadcast and performs pruning generating a more compressed model. Experiments in the context of anomaly detection and missing value imputation demonstrate that the proposed FL scenario along with the proposed compressed-based method are able to achieve high compression rates (more than $99.7\\%$) with negligible performance losses (less than $1.18\\%$ ) as compared to the centralized solutions.","sentences":["Anomaly and missing data constitute a thorny problem in industrial applications.","In recent years, deep learning enabled anomaly detection has emerged as a critical direction, however the improved detection accuracy is achieved with the utilization of large neural networks, increasing their storage and computational cost.","Moreover, the data collected in edge devices contain user privacy, introducing challenges that can be successfully addressed by the privacy-preserving distributed paradigm, known as federated learning (FL).","This framework allows edge devices to train and exchange models increasing also the communication cost.","Thus, to deal with the increased communication, processing and storage challenges of the FL based deep anomaly detection NN pruning is expected to have significant benefits towards reducing the processing, storage and communication complexity.","With this focus, a novel compression-based optimization problem is proposed at the server-side of a FL paradigm that fusses the received local models broadcast and performs pruning generating a more compressed model.","Experiments in the context of anomaly detection and missing value imputation demonstrate that the proposed FL scenario along with the proposed compressed-based method are able to achieve high compression rates (more than $99.7\\%$) with negligible performance losses (less than $1.18\\%$ ) as compared to the centralized solutions."],"url":"http://arxiv.org/abs/2411.03996v1"}
{"created":"2024-11-06 15:34:57","title":"Local vs distributed representations: What is the right basis for interpretability?","abstract":"Much of the research on the interpretability of deep neural networks has focused on studying the visual features that maximally activate individual neurons. However, recent work has cast doubts on the usefulness of such local representations for understanding the behavior of deep neural networks because individual neurons tend to respond to multiple unrelated visual patterns, a phenomenon referred to as \"superposition\". A promising alternative to disentangle these complex patterns is learning sparsely distributed vector representations from entire network layers, as the resulting basis vectors seemingly encode single identifiable visual patterns consistently. Thus, one would expect the resulting code to align better with human perceivable visual patterns, but supporting evidence remains, at best, anecdotal. To fill this gap, we conducted three large-scale psychophysics experiments collected from a pool of 560 participants. Our findings provide (i) strong evidence that features obtained from sparse distributed representations are easier to interpret by human observers and (ii) that this effect is more pronounced in the deepest layers of a neural network. Complementary analyses also reveal that (iii) features derived from sparse distributed representations contribute more to the model's decision. Overall, our results highlight that distributed representations constitute a superior basis for interpretability, underscoring a need for the field to move beyond the interpretation of local neural codes in favor of sparsely distributed ones.","sentences":["Much of the research on the interpretability of deep neural networks has focused on studying the visual features that maximally activate individual neurons.","However, recent work has cast doubts on the usefulness of such local representations for understanding the behavior of deep neural networks because individual neurons tend to respond to multiple unrelated visual patterns, a phenomenon referred to as \"superposition\".","A promising alternative to disentangle these complex patterns is learning sparsely distributed vector representations from entire network layers, as the resulting basis vectors seemingly encode single identifiable visual patterns consistently.","Thus, one would expect the resulting code to align better with human perceivable visual patterns, but supporting evidence remains, at best, anecdotal.","To fill this gap, we conducted three large-scale psychophysics experiments collected from a pool of 560 participants.","Our findings provide (i) strong evidence that features obtained from sparse distributed representations are easier to interpret by human observers and (ii) that this effect is more pronounced in the deepest layers of a neural network.","Complementary analyses also reveal that (iii) features derived from sparse distributed representations contribute more to the model's decision.","Overall, our results highlight that distributed representations constitute a superior basis for interpretability, underscoring a need for the field to move beyond the interpretation of local neural codes in favor of sparsely distributed ones."],"url":"http://arxiv.org/abs/2411.03993v1"}
{"created":"2024-11-06 15:30:42","title":"ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy","abstract":"Imitation learning, e.g., diffusion policy, has been proven effective in various robotic manipulation tasks. However, extensive demonstrations are required for policy robustness and generalization. To reduce the demonstration reliance, we leverage spatial symmetry and propose ET-SEED, an efficient trajectory-level SE(3) equivariant diffusion model for generating action sequences in complex robot manipulation tasks. Further, previous equivariant diffusion models require the per-step equivariance in the Markov process, making it difficult to learn policy under such strong constraints. We theoretically extend equivariant Markov kernels and simplify the condition of equivariant diffusion process, thereby significantly improving training efficiency for trajectory-level SE(3) equivariant diffusion policy in an end-to-end manner. We evaluate ET-SEED on representative robotic manipulation tasks, involving rigid body, articulated and deformable object. Experiments demonstrate superior data efficiency and manipulation proficiency of our proposed method, as well as its ability to generalize to unseen configurations with only a few demonstrations. Website: https://et-seed.github.io/","sentences":["Imitation learning, e.g., diffusion policy, has been proven effective in various robotic manipulation tasks.","However, extensive demonstrations are required for policy robustness and generalization.","To reduce the demonstration reliance, we leverage spatial symmetry and propose ET-SEED, an efficient trajectory-level SE(3) equivariant diffusion model for generating action sequences in complex robot manipulation tasks.","Further, previous equivariant diffusion models require the per-step equivariance in the Markov process, making it difficult to learn policy under such strong constraints.","We theoretically extend equivariant Markov kernels and simplify the condition of equivariant diffusion process, thereby significantly improving training efficiency for trajectory-level SE(3) equivariant diffusion policy in an end-to-end manner.","We evaluate ET-SEED on representative robotic manipulation tasks, involving rigid body, articulated and deformable object.","Experiments demonstrate superior data efficiency and manipulation proficiency of our proposed method, as well as its ability to generalize to unseen configurations with only a few demonstrations.","Website: https://et-seed.github.io/"],"url":"http://arxiv.org/abs/2411.03990v1"}
{"created":"2024-11-06 15:19:24","title":"ReEdit: Multimodal Exemplar-Based Image Editing with Diffusion Models","abstract":"Modern Text-to-Image (T2I) Diffusion models have revolutionized image editing by enabling the generation of high-quality photorealistic images. While the de facto method for performing edits with T2I models is through text instructions, this approach non-trivial due to the complex many-to-many mapping between natural language and images. In this work, we address exemplar-based image editing -- the task of transferring an edit from an exemplar pair to a content image(s). We propose ReEdit, a modular and efficient end-to-end framework that captures edits in both text and image modalities while ensuring the fidelity of the edited image. We validate the effectiveness of ReEdit through extensive comparisons with state-of-the-art baselines and sensitivity analyses of key design choices. Our results demonstrate that ReEdit consistently outperforms contemporary approaches both qualitatively and quantitatively. Additionally, ReEdit boasts high practical applicability, as it does not require any task-specific optimization and is four times faster than the next best baseline.","sentences":["Modern Text-to-Image (T2I) Diffusion models have revolutionized image editing by enabling the generation of high-quality photorealistic images.","While the de facto method for performing edits with T2I models is through text instructions, this approach non-trivial due to the complex many-to-many mapping between natural language and images.","In this work, we address exemplar-based image editing -- the task of transferring an edit from an exemplar pair to a content image(s).","We propose ReEdit, a modular and efficient end-to-end framework that captures edits in both text and image modalities while ensuring the fidelity of the edited image.","We validate the effectiveness of ReEdit through extensive comparisons with state-of-the-art baselines and sensitivity analyses of key design choices.","Our results demonstrate that ReEdit consistently outperforms contemporary approaches both qualitatively and quantitatively.","Additionally, ReEdit boasts high practical applicability, as it does not require any task-specific optimization and is four times faster than the next best baseline."],"url":"http://arxiv.org/abs/2411.03982v1"}
{"created":"2024-11-06 15:14:27","title":"Customized Multiple Clustering via Multi-Modal Subspace Proxy Learning","abstract":"Multiple clustering aims to discover various latent structures of data from different aspects. Deep multiple clustering methods have achieved remarkable performance by exploiting complex patterns and relationships in data. However, existing works struggle to flexibly adapt to diverse user-specific needs in data grouping, which may require manual understanding of each clustering. To address these limitations, we introduce Multi-Sub, a novel end-to-end multiple clustering approach that incorporates a multi-modal subspace proxy learning framework in this work. Utilizing the synergistic capabilities of CLIP and GPT-4, Multi-Sub aligns textual prompts expressing user preferences with their corresponding visual representations. This is achieved by automatically generating proxy words from large language models that act as subspace bases, thus allowing for the customized representation of data in terms specific to the user's interests. Our method consistently outperforms existing baselines across a broad set of datasets in visual multiple clustering tasks. Our code is available at https://github.com/Alexander-Yao/Multi-Sub.","sentences":["Multiple clustering aims to discover various latent structures of data from different aspects.","Deep multiple clustering methods have achieved remarkable performance by exploiting complex patterns and relationships in data.","However, existing works struggle to flexibly adapt to diverse user-specific needs in data grouping, which may require manual understanding of each clustering.","To address these limitations, we introduce Multi-Sub, a novel end-to-end multiple clustering approach that incorporates a multi-modal subspace proxy learning framework in this work.","Utilizing the synergistic capabilities of CLIP and GPT-4, Multi-Sub aligns textual prompts expressing user preferences with their corresponding visual representations.","This is achieved by automatically generating proxy words from large language models that act as subspace bases, thus allowing for the customized representation of data in terms specific to the user's interests.","Our method consistently outperforms existing baselines across a broad set of datasets in visual multiple clustering tasks.","Our code is available at https://github.com/Alexander-Yao/Multi-Sub."],"url":"http://arxiv.org/abs/2411.03978v1"}
{"created":"2024-11-06 15:13:31","title":"HRDecoder: High-Resolution Decoder Network for Fundus Image Lesion Segmentation","abstract":"High resolution is crucial for precise segmentation in fundus images, yet handling high-resolution inputs incurs considerable GPU memory costs, with diminishing performance gains as overhead increases. To address this issue while tackling the challenge of segmenting tiny objects, recent studies have explored local-global fusion methods. These methods preserve fine details using local regions and capture long-range context information from downscaled global images. However, the necessity of multiple forward passes inevitably incurs significant computational overhead, adversely affecting inference speed. In this paper, we propose HRDecoder, a simple High-Resolution Decoder network for fundus lesion segmentation. It integrates a high-resolution representation learning module to capture fine-grained local features and a high-resolution fusion module to fuse multi-scale predictions. Our method effectively improves the overall segmentation accuracy of fundus lesions while consuming reasonable memory and computational overhead, and maintaining satisfying inference speed. Experimental results on the IDRID and DDR datasets demonstrate the effectiveness of our method. Code is available at https://github.com/CVIU-CSU/HRDecoder.","sentences":["High resolution is crucial for precise segmentation in fundus images, yet handling high-resolution inputs incurs considerable GPU memory costs, with diminishing performance gains as overhead increases.","To address this issue while tackling the challenge of segmenting tiny objects, recent studies have explored local-global fusion methods.","These methods preserve fine details using local regions and capture long-range context information from downscaled global images.","However, the necessity of multiple forward passes inevitably incurs significant computational overhead, adversely affecting inference speed.","In this paper, we propose HRDecoder, a simple High-Resolution Decoder network for fundus lesion segmentation.","It integrates a high-resolution representation learning module to capture fine-grained local features and a high-resolution fusion module to fuse multi-scale predictions.","Our method effectively improves the overall segmentation accuracy of fundus lesions while consuming reasonable memory and computational overhead, and maintaining satisfying inference speed.","Experimental results on the IDRID and DDR datasets demonstrate the effectiveness of our method.","Code is available at https://github.com/CVIU-CSU/HRDecoder."],"url":"http://arxiv.org/abs/2411.03976v1"}
{"created":"2024-11-06 15:10:41","title":"Temporal Network Creation Games: The Impact of Non-Locality and Terminals","abstract":"We live in a world full of networks where our economy, our communication, and even our social life crucially depends on them. These networks typically emerge from the interaction of many entities, which is why researchers study agent-based models of network formation. While traditionally static networks with a fixed set of links were considered, a recent stream of works focuses on networks whose behavior may change over time. In particular, Bil\\`o et al. (IJCAI 2023) recently introduced a game-theoretic network formation model that embeds temporal aspects in networks. More precisely, a network is formed by selfish agents corresponding to nodes in a given host network with edges having labels denoting their availability over time. Each agent strategically selects local, i.e., incident, edges to ensure temporal reachability towards everyone at low cost.   In this work we set out to explore the impact of two novel conceptual features: agents are no longer restricted to creating incident edges, called the global setting, and agents might only want to ensure that they can reach a subset of the other nodes, called the terminal model. For both, we study the existence, structure, and quality of equilibrium networks. For the terminal model, we prove that many core properties crucially depend on the number of terminals. We also develop a novel tool that allows translating equilibrium constructions from the non-terminal model to the terminal model. For the global setting, we show the surprising result that equilibria in the global and the local model are incomparable and we establish a high lower bound on the Price of Anarchy of the global setting that matches the upper bound of the local model. This shows the counter-intuitive fact that allowing agents more flexibility in edge creation does not improve the quality of equilibrium networks.","sentences":["We live in a world full of networks where our economy, our communication, and even our social life crucially depends on them.","These networks typically emerge from the interaction of many entities, which is why researchers study agent-based models of network formation.","While traditionally static networks with a fixed set of links were considered, a recent stream of works focuses on networks whose behavior may change over time.","In particular, Bil\\`o et al. (IJCAI 2023) recently introduced a game-theoretic network formation model that embeds temporal aspects in networks.","More precisely, a network is formed by selfish agents corresponding to nodes in a given host network with edges having labels denoting their availability over time.","Each agent strategically selects local, i.e., incident, edges to ensure temporal reachability towards everyone at low cost.   ","In this work we set out to explore the impact of two novel conceptual features: agents are no longer restricted to creating incident edges, called the global setting, and agents might only want to ensure that they can reach a subset of the other nodes, called the terminal model.","For both, we study the existence, structure, and quality of equilibrium networks.","For the terminal model, we prove that many core properties crucially depend on the number of terminals.","We also develop a novel tool that allows translating equilibrium constructions from the non-terminal model to the terminal model.","For the global setting, we show the surprising result that equilibria in the global and the local model are incomparable and we establish a high lower bound on the Price of Anarchy of the global setting that matches the upper bound of the local model.","This shows the counter-intuitive fact that allowing agents more flexibility in edge creation does not improve the quality of equilibrium networks."],"url":"http://arxiv.org/abs/2411.03973v1"}
{"created":"2024-11-06 15:03:47","title":"WorryWords: Norms of Anxiety Association for over 44k English Words","abstract":"Anxiety, the anticipatory unease about a potential negative outcome, is a common and beneficial human emotion. However, there is still much that is not known, such as how anxiety relates to our body and how it manifests in language. This is especially pertinent given the increasing impact of anxiety-related disorders. In this work, we introduce WorryWords, the first large-scale repository of manually derived word--anxiety associations for over 44,450 English words. We show that the anxiety associations are highly reliable. We use WorryWords to study the relationship between anxiety and other emotion constructs, as well as the rate at which children acquire anxiety words with age. Finally, we show that using WorryWords alone, one can accurately track the change of anxiety in streams of text. The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences. WorryWords (and its translations to over 100 languages) is freely available. http://saifmohammad.com/worrywords.html","sentences":["Anxiety, the anticipatory unease about a potential negative outcome, is a common and beneficial human emotion.","However, there is still much that is not known, such as how anxiety relates to our body and how it manifests in language.","This is especially pertinent given the increasing impact of anxiety-related disorders.","In this work, we introduce WorryWords, the first large-scale repository of manually derived word--anxiety associations for over 44,450 English words.","We show that the anxiety associations are highly reliable.","We use WorryWords to study the relationship between anxiety and other emotion constructs, as well as the rate at which children acquire anxiety words with age.","Finally, we show that using WorryWords alone, one can accurately track the change of anxiety in streams of text.","The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences.","WorryWords (and its translations to over 100 languages) is freely available. http://saifmohammad.com/worrywords.html"],"url":"http://arxiv.org/abs/2411.03966v1"}
{"created":"2024-11-06 14:54:19","title":"What Really is Commonsense Knowledge?","abstract":"Commonsense datasets have been well developed in Natural Language Processing, mainly through crowdsource human annotation. However, there are debates on the genuineness of commonsense reasoning benchmarks. In specific, a significant portion of instances in some commonsense benchmarks do not concern commonsense knowledge. That problem would undermine the measurement of the true commonsense reasoning ability of evaluated models. It is also suggested that the problem originated from a blurry concept of commonsense knowledge, as distinguished from other types of knowledge. To demystify all of the above claims, in this study, we survey existing definitions of commonsense knowledge, ground into the three frameworks for defining concepts, and consolidate them into a multi-framework unified definition of commonsense knowledge (so-called consolidated definition). We then use the consolidated definition for annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets to examine the above claims. Our study shows that there exists a large portion of non-commonsense-knowledge instances in the two datasets, and a large performance gap on these two subsets where Large Language Models (LLMs) perform worse on commonsense-knowledge instances.","sentences":["Commonsense datasets have been well developed in Natural Language Processing, mainly through crowdsource human annotation.","However, there are debates on the genuineness of commonsense reasoning benchmarks.","In specific, a significant portion of instances in some commonsense benchmarks do not concern commonsense knowledge.","That problem would undermine the measurement of the true commonsense reasoning ability of evaluated models.","It is also suggested that the problem originated from a blurry concept of commonsense knowledge, as distinguished from other types of knowledge.","To demystify all of the above claims, in this study, we survey existing definitions of commonsense knowledge, ground into the three frameworks for defining concepts, and consolidate them into a multi-framework unified definition of commonsense knowledge (so-called consolidated definition).","We then use the consolidated definition for annotations and experiments on the CommonsenseQA and CommonsenseQA 2.0 datasets to examine the above claims.","Our study shows that there exists a large portion of non-commonsense-knowledge instances in the two datasets, and a large performance gap on these two subsets where Large Language Models (LLMs) perform worse on commonsense-knowledge instances."],"url":"http://arxiv.org/abs/2411.03964v1"}
{"created":"2024-11-06 14:51:02","title":"How Does A Text Preprocessing Pipeline Affect Ontology Syntactic Matching?","abstract":"The generic text preprocessing pipeline, comprising Tokenisation, Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has been implemented in many ontology matching (OM) systems. However, the lack of standardisation in text preprocessing creates diversity in mapping results. In this paper, we investigate the effect of the text preprocessing pipeline on OM tasks at syntactic levels. Our experiments on 8 Ontology Alignment Evaluation Initiative (OAEI) track repositories with 49 distinct alignments indicate: (1) Tokenisation and Normalisation are currently more effective than Stop Words Removal and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and Stemming is task-specific. We recommend standalone Lemmatisation or Stemming with post-hoc corrections. We find that (3) Porter Stemmer and Snowball Stemmer perform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS) Tagging does not help Lemmatisation. To repair less effective Stop Words Removal and Stemming/Lemmatisation used in OM tasks, we propose a novel context-based pipeline repair approach that significantly improves matching correctness and overall matching performance. We also discuss the use of text preprocessing pipeline in the new era of large language models (LLMs).","sentences":["The generic text preprocessing pipeline, comprising Tokenisation, Normalisation, Stop Words Removal, and Stemming/Lemmatisation, has been implemented in many ontology matching (OM) systems.","However, the lack of standardisation in text preprocessing creates diversity in mapping results.","In this paper, we investigate the effect of the text preprocessing pipeline on OM tasks at syntactic levels.","Our experiments on 8 Ontology Alignment Evaluation Initiative (OAEI) track repositories with 49 distinct alignments indicate: (1) Tokenisation and Normalisation are currently more effective than Stop Words Removal and Stemming/Lemmatisation; and (2) The selection of Lemmatisation and Stemming is task-specific.","We recommend standalone Lemmatisation or Stemming with post-hoc corrections.","We find that (3) Porter Stemmer and Snowball Stemmer perform better than Lancaster Stemmer; and that (4) Part-of-Speech (POS)","Tagging does not help Lemmatisation.","To repair less effective Stop Words Removal and Stemming/Lemmatisation used in OM tasks, we propose a novel context-based pipeline repair approach that significantly improves matching correctness and overall matching performance.","We also discuss the use of text preprocessing pipeline in the new era of large language models (LLMs)."],"url":"http://arxiv.org/abs/2411.03962v1"}
{"created":"2024-11-06 14:45:41","title":"Face Reconstruction from Face Embeddings using Adapter to a Face Foundation Model","abstract":"Face recognition systems extract embedding vectors from face images and use these embeddings to verify or identify individuals. Face reconstruction attack (also known as template inversion) refers to reconstructing face images from face embeddings and using the reconstructed face image to enter a face recognition system. In this paper, we propose to use a face foundation model to reconstruct face images from the embeddings of a blackbox face recognition model. The foundation model is trained with 42M images to generate face images from the facial embeddings of a fixed face recognition model. We propose to use an adapter to translate target embeddings into the embedding space of the foundation model. The generated images are evaluated on different face recognition models and different datasets, demonstrating the effectiveness of our method to translate embeddings of different face recognition models. We also evaluate the transferability of reconstructed face images when attacking different face recognition models. Our experimental results show that our reconstructed face images outperform previous reconstruction attacks against face recognition models.","sentences":["Face recognition systems extract embedding vectors from face images and use these embeddings to verify or identify individuals.","Face reconstruction attack (also known as template inversion) refers to reconstructing face images from face embeddings and using the reconstructed face image to enter a face recognition system.","In this paper, we propose to use a face foundation model to reconstruct face images from the embeddings of a blackbox face recognition model.","The foundation model is trained with 42M images to generate face images from the facial embeddings of a fixed face recognition model.","We propose to use an adapter to translate target embeddings into the embedding space of the foundation model.","The generated images are evaluated on different face recognition models and different datasets, demonstrating the effectiveness of our method to translate embeddings of different face recognition models.","We also evaluate the transferability of reconstructed face images when attacking different face recognition models.","Our experimental results show that our reconstructed face images outperform previous reconstruction attacks against face recognition models."],"url":"http://arxiv.org/abs/2411.03960v1"}
{"created":"2024-11-06 14:45:16","title":"Energy Score-based Pseudo-Label Filtering and Adaptive Loss for Imbalanced Semi-supervised SAR target recognition","abstract":"Automatic target recognition (ATR) is an important use case for synthetic aperture radar (SAR) image interpretation. Recent years have seen significant advancements in SAR ATR technology based on semi-supervised learning. However, existing semi-supervised SAR ATR algorithms show low recognition accuracy in the case of class imbalance. This work offers a non-balanced semi-supervised SAR target recognition approach using dynamic energy scores and adaptive loss. First, an energy score-based method is developed to dynamically select unlabeled samples near to the training distribution as pseudo-labels during training, assuring pseudo-label reliability in long-tailed distribution circumstances. Secondly, loss functions suitable for class imbalances are proposed, including adaptive margin perception loss and adaptive hard triplet loss, the former offsets inter-class confusion of classifiers, alleviating the imbalance issue inherent in pseudo-label generation. The latter effectively tackles the model's preference for the majority class by focusing on complex difficult samples during training. Experimental results on extremely imbalanced SAR datasets demonstrate that the proposed method performs well under the dual constraints of scarce labels and data imbalance, effectively overcoming the model bias caused by data imbalance and achieving high-precision target recognition.","sentences":["Automatic target recognition (ATR) is an important use case for synthetic aperture radar (SAR) image interpretation.","Recent years have seen significant advancements in SAR ATR technology based on semi-supervised learning.","However, existing semi-supervised SAR ATR algorithms show low recognition accuracy in the case of class imbalance.","This work offers a non-balanced semi-supervised SAR target recognition approach using dynamic energy scores and adaptive loss.","First, an energy score-based method is developed to dynamically select unlabeled samples near to the training distribution as pseudo-labels during training, assuring pseudo-label reliability in long-tailed distribution circumstances.","Secondly, loss functions suitable for class imbalances are proposed, including adaptive margin perception loss and adaptive hard triplet loss, the former offsets inter-class confusion of classifiers, alleviating the imbalance issue inherent in pseudo-label generation.","The latter effectively tackles the model's preference for the majority class by focusing on complex difficult samples during training.","Experimental results on extremely imbalanced SAR datasets demonstrate that the proposed method performs well under the dual constraints of scarce labels and data imbalance, effectively overcoming the model bias caused by data imbalance and achieving high-precision target recognition."],"url":"http://arxiv.org/abs/2411.03959v1"}
{"created":"2024-11-06 14:42:39","title":"Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in Retrieval-Augmented Generation","abstract":"Retrieval-Augmented Generation (RAG) has proven to be an effective method for mitigating hallucination issues inherent in large language models (LLMs). Previous approaches typically train retrievers based on semantic similarity, lacking optimization for RAG. More recent works have proposed aligning retrievers with the preference signals of LLMs. However, these preference signals are often difficult for dense retrievers, which typically have weaker language capabilities, to understand and learn effectively. Drawing inspiration from pedagogical theories like Guided Discovery Learning, we propose a novel framework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the language capabilities of LLMs to construct examples from a more granular, information-centric perspective to guide the learning of retrievers. Specifically, our method utilizes LLMs to construct easy-to-understand examples from samples where the retriever performs poorly, focusing on three learning objectives highly relevant to the RAG scenario: relevance, comprehensiveness, and purity. These examples serve as scaffolding to ultimately align the retriever with the LLM's preferences. Furthermore, we employ a dual curriculum learning strategy and leverage the reciprocal feedback between LLM and retriever to further enhance the performance of the RAG system. A series of experiments demonstrate that our proposed framework enhances the performance of RAG systems equipped with different retrievers and is applicable to various LLMs.","sentences":["Retrieval-Augmented Generation (RAG) has proven to be an effective method for mitigating hallucination issues inherent in large language models (LLMs).","Previous approaches typically train retrievers based on semantic similarity, lacking optimization for RAG.","More recent works have proposed aligning retrievers with the preference signals of LLMs.","However, these preference signals are often difficult for dense retrievers, which typically have weaker language capabilities, to understand and learn effectively.","Drawing inspiration from pedagogical theories like Guided Discovery Learning, we propose a novel framework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the language capabilities of LLMs to construct examples from a more granular, information-centric perspective to guide the learning of retrievers.","Specifically, our method utilizes LLMs to construct easy-to-understand examples from samples where the retriever performs poorly, focusing on three learning objectives highly relevant to the RAG scenario: relevance, comprehensiveness, and purity.","These examples serve as scaffolding to ultimately align the retriever with the LLM's preferences.","Furthermore, we employ a dual curriculum learning strategy and leverage the reciprocal feedback between LLM and retriever to further enhance the performance of the RAG system.","A series of experiments demonstrate that our proposed framework enhances the performance of RAG systems equipped with different retrievers and is applicable to various LLMs."],"url":"http://arxiv.org/abs/2411.03957v1"}
{"created":"2024-11-06 14:33:30","title":"Continuous-Time State Estimation Methods in Robotics: A Survey","abstract":"Accurate, efficient, and robust state estimation is more important than ever in robotics as the variety of platforms and complexity of tasks continue to grow. Historically, discrete-time filters and smoothers have been the dominant approach, in which the estimated variables are states at discrete sample times. The paradigm of continuous-time state estimation proposes an alternative strategy by estimating variables that express the state as a continuous function of time, which can be evaluated at any query time. Not only can this benefit downstream tasks such as planning and control, but it also significantly increases estimator performance and flexibility, as well as reduces sensor preprocessing and interfacing complexity. Despite this, continuous-time methods remain underutilized, potentially because they are less well-known within robotics. To remedy this, this work presents a unifying formulation of these methods and the most exhaustive literature review to date, systematically categorizing prior work by methodology, application, state variables, historical context, and theoretical contribution to the field. By surveying splines and Gaussian processes together and contextualizing works from other research domains, this work identifies and analyzes open problems in continuous-time state estimation and suggests new research directions.","sentences":["Accurate, efficient, and robust state estimation is more important than ever in robotics as the variety of platforms and complexity of tasks continue to grow.","Historically, discrete-time filters and smoothers have been the dominant approach, in which the estimated variables are states at discrete sample times.","The paradigm of continuous-time state estimation proposes an alternative strategy by estimating variables that express the state as a continuous function of time, which can be evaluated at any query time.","Not only can this benefit downstream tasks such as planning and control, but it also significantly increases estimator performance and flexibility, as well as reduces sensor preprocessing and interfacing complexity.","Despite this, continuous-time methods remain underutilized, potentially because they are less well-known within robotics.","To remedy this, this work presents a unifying formulation of these methods and the most exhaustive literature review to date, systematically categorizing prior work by methodology, application, state variables, historical context, and theoretical contribution to the field.","By surveying splines and Gaussian processes together and contextualizing works from other research domains, this work identifies and analyzes open problems in continuous-time state estimation and suggests new research directions."],"url":"http://arxiv.org/abs/2411.03951v1"}
{"created":"2024-11-06 14:29:49","title":"Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of Study in Tabletop Role-Playing Games Soundtracks","abstract":"This paper investigates the capabilities of text-to-audio music generation models in producing long-form music with prompts that change over time, focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We introduce Babel Bardo, a system that uses Large Language Models (LLMs) to transform speech transcriptions into music descriptions for controlling a text-to-music model. Four versions of Babel Bardo were compared in two TRPG campaigns: a baseline using direct speech transcriptions, and three LLM-based versions with varying approaches to music description generation. Evaluations considered audio quality, story alignment, and transition smoothness. Results indicate that detailed music descriptions improve audio quality while maintaining consistency across consecutive descriptions enhances story alignment and transition smoothness.","sentences":["This paper investigates the capabilities of text-to-audio music generation models in producing long-form music with prompts that change over time, focusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs).","We introduce Babel Bardo, a system that uses Large Language Models (LLMs) to transform speech transcriptions into music descriptions for controlling a text-to-music model.","Four versions of Babel Bardo were compared in two TRPG campaigns: a baseline using direct speech transcriptions, and three LLM-based versions with varying approaches to music description generation.","Evaluations considered audio quality, story alignment, and transition smoothness.","Results indicate that detailed music descriptions improve audio quality while maintaining consistency across consecutive descriptions enhances story alignment and transition smoothness."],"url":"http://arxiv.org/abs/2411.03948v1"}
{"created":"2024-11-06 14:25:05","title":"Can Custom Models Learn In-Context? An Exploration of Hybrid Architecture Performance on In-Context Learning Tasks","abstract":"In-Context Learning (ICL) is a phenomenon where task learning occurs through a prompt sequence without the necessity of parameter updates. ICL in Multi-Headed Attention (MHA) with absolute positional embedding has been the focus of more study than other sequence model varieties. We examine implications of architectural differences between GPT-2 and LLaMa as well as LlaMa and Mamba. We extend work done by Garg et al. (2022) and Park et al. (2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the interplay between sequence transformation blocks and regressive performance in-context. We note that certain architectural changes cause degraded training efficiency/ICL accuracy by converging to suboptimal predictors or converging slower. We also find certain hybrids showing optimistic performance improvements, informing potential future ICL-focused architecture modifications. Additionally, we propose the \"ICL regression score\", a scalar metric describing a model's whole performance on a specific task. Compute limitations impose restrictions on our architecture-space, training duration, number of training runs, function class complexity, and benchmark complexity. To foster reproducible and extensible research, we provide a typed, modular, and extensible Python package on which we run all experiments.","sentences":["In-Context Learning (ICL) is a phenomenon where task learning occurs through a prompt sequence without the necessity of parameter updates.","ICL in Multi-Headed Attention (MHA) with absolute positional embedding has been the focus of more study than other sequence model varieties.","We examine implications of architectural differences between GPT-2 and LLaMa as well as LlaMa and Mamba.","We extend work done by Garg et al. (2022) and Park et al.","(2024) to GPT-2/LLaMa hybrid and LLaMa/Mamba hybrid models - examining the interplay between sequence transformation blocks and regressive performance in-context.","We note that certain architectural changes cause degraded training efficiency/ICL accuracy by converging to suboptimal predictors or converging slower.","We also find certain hybrids showing optimistic performance improvements, informing potential future ICL-focused architecture modifications.","Additionally, we propose the \"ICL regression score\", a scalar metric describing a model's whole performance on a specific task.","Compute limitations impose restrictions on our architecture-space, training duration, number of training runs, function class complexity, and benchmark complexity.","To foster reproducible and extensible research, we provide a typed, modular, and extensible Python package on which we run all experiments."],"url":"http://arxiv.org/abs/2411.03945v1"}
{"created":"2024-11-06 14:21:28","title":"Towards Achieving Energy Efficiency and Service Availability in O-RAN via Formal Verification","abstract":"As Open Radio Access Networks (O-RAN) continue to expand, AI-driven applications (xApps) are increasingly being deployed enhance network management. However, developing xApps without formal verification risks introducing logical inconsistencies, particularly in balancing energy efficiency and service availability. In this paper, we argue that prior to their development, the formal analysis of xApp models should be a critical early step in the O-RAN design process. Using the PRISM model checker, we demonstrate how our results provide realistic insights into the thresholds between energy efficiency and service availability. While our models are simplified, the findings highlight how AI-informed decisions can enable more effective cell-switching policies. We position formal verification as an essential practice for future xApp development, avoiding fallacies in real-world applications and ensuring networks operate efficiently.","sentences":["As Open Radio Access Networks (O-RAN) continue to expand, AI-driven applications (xApps) are increasingly being deployed enhance network management.","However, developing xApps without formal verification risks introducing logical inconsistencies, particularly in balancing energy efficiency and service availability.","In this paper, we argue that prior to their development, the formal analysis of xApp models should be a critical early step in the O-RAN design process.","Using the PRISM model checker, we demonstrate how our results provide realistic insights into the thresholds between energy efficiency and service availability.","While our models are simplified, the findings highlight how AI-informed decisions can enable more effective cell-switching policies.","We position formal verification as an essential practice for future xApp development, avoiding fallacies in real-world applications and ensuring networks operate efficiently."],"url":"http://arxiv.org/abs/2411.03943v1"}
{"created":"2024-11-06 14:18:23","title":"Fine-tuning -- a Transfer Learning approach","abstract":"Secondary research use of Electronic Health Records (EHRs) is often hampered by the abundance of missing data in this valuable resource. Missingness in EHRs occurs naturally as a result of the data recording practices during routine clinical care, but handling it is crucial to the precision of medical analysis and the decision-making that follows. The literature contains a variety of imputation methodologies based on deep neural networks. Those aim to overcome the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which cannot be handled by classical and statistical imputation methods. However, all existing deep imputation methods rely on end-to-end pipelines that incorporate both imputation and downstream analyses, e.g. classification. This coupling makes it difficult to assess the quality of imputation and takes away the flexibility of re-using the imputer for a different task. Furthermore, most end-to-end deep architectures tend to use complex networks to perform the downstream task, in addition to the already sophisticated deep imputation network. We, therefore ask if the high performance reported in the literature is due to the imputer or the classifier and further ask if an optimised state-of-the-art imputer is used, a simpler classifier can achieve comparable performance. This paper explores the development of a modular, deep learning-based imputation and classification pipeline, specifically built to leverage the capabilities of state-of-the-art imputation models for downstream classification tasks. Such a modular approach enables a) objective assessment of the quality of the imputer and classifier independently, and b) enables the exploration of the performance of simpler classification architectures using an optimised imputer.","sentences":["Secondary research use of Electronic Health Records (EHRs) is often hampered by the abundance of missing data in this valuable resource.","Missingness in EHRs occurs naturally as a result of the data recording practices during routine clinical care, but handling it is crucial to the precision of medical analysis and the decision-making that follows.","The literature contains a variety of imputation methodologies based on deep neural networks.","Those aim to overcome the dynamic, heterogeneous and multivariate missingness patterns of EHRs, which cannot be handled by classical and statistical imputation methods.","However, all existing deep imputation methods rely on end-to-end pipelines that incorporate both imputation and downstream analyses, e.g. classification.","This coupling makes it difficult to assess the quality of imputation and takes away the flexibility of re-using the imputer for a different task.","Furthermore, most end-to-end deep architectures tend to use complex networks to perform the downstream task, in addition to the already sophisticated deep imputation network.","We, therefore ask if the high performance reported in the literature is due to the imputer or the classifier and further ask if an optimised state-of-the-art imputer is used, a simpler classifier can achieve comparable performance.","This paper explores the development of a modular, deep learning-based imputation and classification pipeline, specifically built to leverage the capabilities of state-of-the-art imputation models for downstream classification tasks.","Such a modular approach enables a) objective assessment of the quality of the imputer and classifier independently, and b) enables the exploration of the performance of simpler classification architectures using an optimised imputer."],"url":"http://arxiv.org/abs/2411.03941v1"}
{"created":"2024-11-06 14:16:14","title":"Where postdoctoral journeys lead","abstract":"Postdoctoral training is a career stage often described as a demanding and anxiety-laden time when many promising PhDs see their academic dreams slip away due to circumstances beyond their control. We use a unique data set of academic publishing and careers to chart the more or less successful postdoctoral paths. We build a measure of academic success on the citation patterns two to five years into a faculty career. Then, we monitor how students' postdoc positions -- in terms of relocation, change of topic, and early well-cited papers -- relate to their early-career success. One key finding is that the postdoc period seems more important than the doctoral training to achieve this form of success. This is especially interesting in light of the many studies of academic faculty hiring that link Ph.D. granting institutions and hires, omitting the postdoc stage. Another group of findings can be summarized as a Goldilocks principle: it seems beneficial to change one's direction, but not too much.","sentences":["Postdoctoral training is a career stage often described as a demanding and anxiety-laden time when many promising PhDs see their academic dreams slip away due to circumstances beyond their control.","We use a unique data set of academic publishing and careers to chart the more or less successful postdoctoral paths.","We build a measure of academic success on the citation patterns two to five years into a faculty career.","Then, we monitor how students' postdoc positions -- in terms of relocation, change of topic, and early well-cited papers -- relate to their early-career success.","One key finding is that the postdoc period seems more important than the doctoral training to achieve this form of success.","This is especially interesting in light of the many studies of academic faculty hiring that link Ph.D. granting institutions and hires, omitting the postdoc stage.","Another group of findings can be summarized as a Goldilocks principle: it seems beneficial to change one's direction, but not too much."],"url":"http://arxiv.org/abs/2411.03938v1"}
{"created":"2024-11-06 14:11:46","title":"GUIDE-VAE: Advancing Data Generation with User Information and Pattern Dictionaries","abstract":"Generative modelling of multi-user datasets has become prominent in science and engineering. Generating a data point for a given user requires employing user information, and conventional generative models, including variational autoencoders (VAEs), often ignore that. This paper introduces GUIDE-VAE, a novel conditional generative model that leverages user embeddings to generate user-guided data. By allowing the model to benefit from shared patterns across users, GUIDE-VAE enhances performance in multi-user settings, even under significant data imbalance. In addition to integrating user information, GUIDE-VAE incorporates a pattern dictionary-based covariance composition (PDCC) to improve the realism of generated samples by capturing complex feature dependencies. While user embeddings drive performance gains, PDCC addresses common issues such as noise and over-smoothing typically seen in VAEs.   The proposed GUIDE-VAE was evaluated on a multi-user smart meter dataset characterized by substantial data imbalance across users. Quantitative results show that GUIDE-VAE performs effectively in both synthetic data generation and missing record imputation tasks, while qualitative evaluations reveal that GUIDE-VAE produces more plausible and less noisy data. These results establish GUIDE-VAE as a promising tool for controlled, realistic data generation in multi-user datasets, with potential applications across various domains requiring user-informed modelling.","sentences":["Generative modelling of multi-user datasets has become prominent in science and engineering.","Generating a data point for a given user requires employing user information, and conventional generative models, including variational autoencoders (VAEs), often ignore that.","This paper introduces GUIDE-VAE, a novel conditional generative model that leverages user embeddings to generate user-guided data.","By allowing the model to benefit from shared patterns across users, GUIDE-VAE enhances performance in multi-user settings, even under significant data imbalance.","In addition to integrating user information, GUIDE-VAE incorporates a pattern dictionary-based covariance composition (PDCC) to improve the realism of generated samples by capturing complex feature dependencies.","While user embeddings drive performance gains, PDCC addresses common issues such as noise and over-smoothing typically seen in VAEs.   ","The proposed GUIDE-VAE was evaluated on a multi-user smart meter dataset characterized by substantial data imbalance across users.","Quantitative results show that GUIDE-VAE performs effectively in both synthetic data generation and missing record imputation tasks, while qualitative evaluations reveal that GUIDE-VAE produces more plausible and less noisy data.","These results establish GUIDE-VAE as a promising tool for controlled, realistic data generation in multi-user datasets, with potential applications across various domains requiring user-informed modelling."],"url":"http://arxiv.org/abs/2411.03936v1"}
{"created":"2024-11-06 14:11:39","title":"Interactions Across Blocks in Post-Training Quantization of Large Language Models","abstract":"Post-training quantization is widely employed to reduce the computational demands of neural networks. Typically, individual substructures, such as layers or blocks of layers, are quantized with the objective of minimizing quantization errors in their pre-activations by fine-tuning the corresponding weights. Deriving this local objective from the global objective of minimizing task loss involves two key simplifications: assuming substructures are mutually independent and ignoring the knowledge of subsequent substructures as well as the task loss. In this work, we assess the effects of these simplifications on weight-only quantization of large language models. We introduce two multi-block fine-tuning strategies and compare them against the baseline of fine-tuning single transformer blocks. The first captures correlations of weights across blocks by jointly optimizing multiple quantized blocks. The second incorporates knowledge of subsequent blocks by minimizing the error in downstream pre-activations rather than focusing solely on the quantized block. Our findings indicate that the effectiveness of these methods depends on the specific network model, with no impact on some models but demonstrating significant benefits for others.","sentences":["Post-training quantization is widely employed to reduce the computational demands of neural networks.","Typically, individual substructures, such as layers or blocks of layers, are quantized with the objective of minimizing quantization errors in their pre-activations by fine-tuning the corresponding weights.","Deriving this local objective from the global objective of minimizing task loss involves two key simplifications: assuming substructures are mutually independent and ignoring the knowledge of subsequent substructures as well as the task loss.","In this work, we assess the effects of these simplifications on weight-only quantization of large language models.","We introduce two multi-block fine-tuning strategies and compare them against the baseline of fine-tuning single transformer blocks.","The first captures correlations of weights across blocks by jointly optimizing multiple quantized blocks.","The second incorporates knowledge of subsequent blocks by minimizing the error in downstream pre-activations rather than focusing solely on the quantized block.","Our findings indicate that the effectiveness of these methods depends on the specific network model, with no impact on some models but demonstrating significant benefits for others."],"url":"http://arxiv.org/abs/2411.03934v1"}
{"created":"2024-11-06 14:04:34","title":"Inexact block LU preconditioners for incompressible fluids with flow rate conditions","abstract":"When studying the dynamics of incompressible fluids in bounded domains the only available data often provide average flow rate conditions on portions of the domain's boundary. In engineering applications a common practice to complete these conditions is to prescribe a Dirichlet condition by assuming a-priori a spatial profile for the velocity field. However, this strongly influence the accuracy of the numerical solution. A more mathematically sound approach is to prescribe the flow rate conditions using Lagrange multipliers, resulting in an augmented weak formulation of the Navier-Stokes problem.   In this paper we start from the SIMPLE preconditioner, introduced so far for the standard Navier-Stokes equations, and we derive two preconditioners for the monolithic solution of the augmented problem. This can be useful in complex applications where splitting the computation of the velocity/pressure and Lagrange multipliers numerical solutions can be very expensive. In particular, we investigate the numerical performance of the preconditioners in both idealized and real-life scenarios. Finally, we highlight the advantages of treating flow rate conditions with a Lagrange multipliers approach instead of prescribing a Dirichlet condition.","sentences":["When studying the dynamics of incompressible fluids in bounded domains the only available data often provide average flow rate conditions on portions of the domain's boundary.","In engineering applications a common practice to complete these conditions is to prescribe a Dirichlet condition by assuming a-priori a spatial profile for the velocity field.","However, this strongly influence the accuracy of the numerical solution.","A more mathematically sound approach is to prescribe the flow rate conditions using Lagrange multipliers, resulting in an augmented weak formulation of the Navier-Stokes problem.   ","In this paper we start from the SIMPLE preconditioner, introduced so far for the standard Navier-Stokes equations, and we derive two preconditioners for the monolithic solution of the augmented problem.","This can be useful in complex applications where splitting the computation of the velocity/pressure and Lagrange multipliers numerical solutions can be very expensive.","In particular, we investigate the numerical performance of the preconditioners in both idealized and real-life scenarios.","Finally, we highlight the advantages of treating flow rate conditions with a Lagrange multipliers approach instead of prescribing a Dirichlet condition."],"url":"http://arxiv.org/abs/2411.03929v1"}
{"created":"2024-11-06 14:03:49","title":"DEIO: Deep Event Inertial Odometry","abstract":"Event cameras are bio-inspired, motion-activated sensors that demonstrate impressive potential in handling challenging situations, such as motion blur and high-dynamic range. Despite their promise, existing event-based simultaneous localization and mapping (SLAM) approaches exhibit limited performance in real-world applications. On the other hand, state-of-the-art SLAM approaches that incorporate deep neural networks for better robustness and applicability. However, these is a lack of research in fusing learning-based event SLAM methods with IMU, which could be indispensable to push the event-based SLAM to large-scale, low-texture or complex scenarios. In this paper, we propose DEIO, the first monocular deep event-inertial odometry framework that combines learning-based method with traditional nonlinear graph-based optimization. Specifically, we tightly integrate a trainable event-based differentiable bundle adjustment (e-DBA) with the IMU pre-integration in a factor graph which employs keyframe-based sliding window optimization. Numerical Experiments in nine public challenge datasets show that our method can achieve superior performance compared with the image-based and event-based benchmarks. The source code is available at: https://github.com/arclab-hku/DEIO.","sentences":["Event cameras are bio-inspired, motion-activated sensors that demonstrate impressive potential in handling challenging situations, such as motion blur and high-dynamic range.","Despite their promise, existing event-based simultaneous localization and mapping (SLAM) approaches exhibit limited performance in real-world applications.","On the other hand, state-of-the-art SLAM approaches that incorporate deep neural networks for better robustness and applicability.","However, these is a lack of research in fusing learning-based event SLAM methods with IMU, which could be indispensable to push the event-based SLAM to large-scale, low-texture or complex scenarios.","In this paper, we propose DEIO, the first monocular deep event-inertial odometry framework that combines learning-based method with traditional nonlinear graph-based optimization.","Specifically, we tightly integrate a trainable event-based differentiable bundle adjustment (e-DBA) with the IMU pre-integration in a factor graph which employs keyframe-based sliding window optimization.","Numerical Experiments in nine public challenge datasets show that our method can achieve superior performance compared with the image-based and event-based benchmarks.","The source code is available at: https://github.com/arclab-hku/DEIO."],"url":"http://arxiv.org/abs/2411.03928v1"}
{"created":"2024-11-06 13:57:53","title":"Act in Collusion: A Persistent Distributed Multi-Target Backdoor in Federated Learning","abstract":"Federated learning, a novel paradigm designed to protect data privacy, is vulnerable to backdoor attacks due to its distributed nature. Current research often designs attacks based on a single attacker with a single backdoor, overlooking more realistic and complex threats in federated learning. We propose a more practical threat model for federated learning: the distributed multi-target backdoor. In this model, multiple attackers control different clients, embedding various triggers and targeting different classes, collaboratively implanting backdoors into the global model via central aggregation. Empirical validation shows that existing methods struggle to maintain the effectiveness of multiple backdoors in the global model. Our key insight is that similar backdoor triggers cause parameter conflicts and injecting new backdoors disrupts gradient directions, significantly weakening some backdoors performance. To solve this, we propose a Distributed Multi-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of backdoors from different malicious clients. To avoid parameter conflicts, we design a multi-channel dispersed frequency trigger strategy to maximize trigger differences. To mitigate gradient interference, we introduce backdoor replay in local training to neutralize conflicting gradients. Extensive validation shows that 30 rounds after the attack, Attack Success Rates of three different backdoors from various clients remain above 93%. The code will be made publicly available after the review period.","sentences":["Federated learning, a novel paradigm designed to protect data privacy, is vulnerable to backdoor attacks due to its distributed nature.","Current research often designs attacks based on a single attacker with a single backdoor, overlooking more realistic and complex threats in federated learning.","We propose a more practical threat model for federated learning: the distributed multi-target backdoor.","In this model, multiple attackers control different clients, embedding various triggers and targeting different classes, collaboratively implanting backdoors into the global model via central aggregation.","Empirical validation shows that existing methods struggle to maintain the effectiveness of multiple backdoors in the global model.","Our key insight is that similar backdoor triggers cause parameter conflicts and injecting new backdoors disrupts gradient directions, significantly weakening some backdoors performance.","To solve this, we propose a Distributed Multi-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of backdoors from different malicious clients.","To avoid parameter conflicts, we design a multi-channel dispersed frequency trigger strategy to maximize trigger differences.","To mitigate gradient interference, we introduce backdoor replay in local training to neutralize conflicting gradients.","Extensive validation shows that 30 rounds after the attack, Attack Success Rates of three different backdoors from various clients remain above 93%.","The code will be made publicly available after the review period."],"url":"http://arxiv.org/abs/2411.03926v1"}
{"created":"2024-11-06 13:57:50","title":"Quantum Algorithm for Sparse Online Learning with Truncated Gradient Descent","abstract":"Logistic regression, the Support Vector Machine (SVM), and least squares are well-studied methods in the statistical and computer science community, with various practical applications. High-dimensional data arriving on a real-time basis makes the design of online learning algorithms that produce sparse solutions essential. The seminal work of \\hyperlink{cite.langford2009sparse}{Langford, Li, and Zhang (2009)} developed a method to obtain sparsity via truncated gradient descent, showing a near-optimal online regret bound. Based on this method, we develop a quantum sparse online learning algorithm for logistic regression, the SVM, and least squares. Given efficient quantum access to the inputs, we show that a quadratic speedup in the time complexity with respect to the dimension of the problem is achievable, while maintaining a regret of $O(1/\\sqrt{T})$, where $T$ is the number of iterations.","sentences":["Logistic regression, the Support Vector Machine (SVM), and least squares are well-studied methods in the statistical and computer science community, with various practical applications.","High-dimensional data arriving on a real-time basis makes the design of online learning algorithms that produce sparse solutions essential.","The seminal work of \\hyperlink{cite.langford2009sparse}{Langford, Li, and Zhang (2009)} developed a method to obtain sparsity via truncated gradient descent, showing a near-optimal online regret bound.","Based on this method, we develop a quantum sparse online learning algorithm for logistic regression, the SVM, and least squares.","Given efficient quantum access to the inputs, we show that a quadratic speedup in the time complexity with respect to the dimension of the problem is achievable, while maintaining a regret of $O(1/\\sqrt{T})$, where $T$ is the number of iterations."],"url":"http://arxiv.org/abs/2411.03925v1"}
{"created":"2024-11-06 13:54:26","title":"Self-supervised Representation Learning for Cell Event Recognition through Time Arrow Prediction","abstract":"The spatio-temporal nature of live-cell microscopy data poses challenges in the analysis of cell states which is fundamental in bioimaging. Deep-learning based segmentation or tracking methods rely on large amount of high quality annotations to work effectively. In this work, we explore an alternative solution: using feature maps obtained from self-supervised representation learning (SSRL) on time arrow prediction (TAP) for the downstream supervised task of cell event recognition. We demonstrate through extensive experiments and analysis that this approach can achieve better performance with limited annotation compared to models trained from end to end using fully supervised approach. Our analysis also provides insight into applications of the SSRL using TAP in live-cell microscopy.","sentences":["The spatio-temporal nature of live-cell microscopy data poses challenges in the analysis of cell states which is fundamental in bioimaging.","Deep-learning based segmentation or tracking methods rely on large amount of high quality annotations to work effectively.","In this work, we explore an alternative solution: using feature maps obtained from self-supervised representation learning (SSRL) on time arrow prediction (TAP) for the downstream supervised task of cell event recognition.","We demonstrate through extensive experiments and analysis that this approach can achieve better performance with limited annotation compared to models trained from end to end using fully supervised approach.","Our analysis also provides insight into applications of the SSRL using TAP in live-cell microscopy."],"url":"http://arxiv.org/abs/2411.03924v1"}
{"created":"2024-11-06 13:54:08","title":"Evaluation data contamination in LLMs: how do we measure it and (when) does it matter?","abstract":"Hampering the interpretation of benchmark scores, evaluation data contamination has become a growing concern in the evaluation of LLMs, and an active area of research studies its effects. While evaluation data contamination is easily understood intuitively, it is surprisingly difficult to define precisely which samples should be considered contaminated and, consequently, how it impacts benchmark scores. We propose that these questions should be addressed together and that contamination metrics can be assessed based on whether models benefit from the examples they mark contaminated. We propose a novel analysis method called ConTAM, and show with a large scale survey of existing and novel n-gram based contamination metrics across 13 benchmarks and 7 models from 2 different families that ConTAM can be used to better understand evaluation data contamination and its effects. We find that contamination may have a much larger effect than reported in recent LLM releases and benefits models differently at different scales. We also find that considering only the longest contaminated substring provides a better signal than considering a union of all contaminated substrings, and that doing model and benchmark specific threshold analysis greatly increases the specificity of the results. Lastly, we investigate the impact of hyperparameter choices, finding that, among other things, both using larger values of n and disregarding matches that are infrequent in the pre-training data lead to many false negatives. With ConTAM, we provide a method to empirically ground evaluation data contamination metrics in downstream effects. With our exploration, we shed light on how evaluation data contamination can impact LLMs and provide insight into the considerations important when doing contamination analysis. We end our paper by discussing these in more detail and providing concrete suggestions for future work.","sentences":["Hampering the interpretation of benchmark scores, evaluation data contamination has become a growing concern in the evaluation of LLMs, and an active area of research studies its effects.","While evaluation data contamination is easily understood intuitively, it is surprisingly difficult to define precisely which samples should be considered contaminated and, consequently, how it impacts benchmark scores.","We propose that these questions should be addressed together and that contamination metrics can be assessed based on whether models benefit from the examples they mark contaminated.","We propose a novel analysis method called ConTAM, and show with a large scale survey of existing and novel n-gram based contamination metrics across 13 benchmarks and 7 models from 2 different families that ConTAM can be used to better understand evaluation data contamination and its effects.","We find that contamination may have a much larger effect than reported in recent LLM releases and benefits models differently at different scales.","We also find that considering only the longest contaminated substring provides a better signal than considering a union of all contaminated substrings, and that doing model and benchmark specific threshold analysis greatly increases the specificity of the results.","Lastly, we investigate the impact of hyperparameter choices, finding that, among other things, both using larger values of n and disregarding matches that are infrequent in the pre-training data lead to many false negatives.","With ConTAM, we provide a method to empirically ground evaluation data contamination metrics in downstream effects.","With our exploration, we shed light on how evaluation data contamination can impact LLMs and provide insight into the considerations important when doing contamination analysis.","We end our paper by discussing these in more detail and providing concrete suggestions for future work."],"url":"http://arxiv.org/abs/2411.03923v1"}
