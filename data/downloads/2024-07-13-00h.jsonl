{"created":"2024-07-10 17:59:43","title":"LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models","abstract":"Visual instruction tuning has made considerable strides in enhancing the capabilities of Large Multimodal Models (LMMs). However, existing open LMMs largely focus on single-image tasks, their applications to multi-image scenarios remains less explored. Additionally, prior LMM research separately tackles different scenarios, leaving it impossible to generalize cross scenarios with new emerging capabilities. To this end, we introduce LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame (video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To enable these capabilities, we regard the interleaved data format as a general template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4 primary domains with 14 tasks and 41 datasets. We also curate the LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance of LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading results in multi-image, video, and 3D benchmarks, while maintaining the performance of single-image tasks. Besides, our model also exhibits several emerging capabilities, e.g., transferring tasks across different settings and modalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT","sentences":["Visual instruction tuning has made considerable strides in enhancing the capabilities of Large Multimodal Models (LMMs).","However, existing open LMMs largely focus on single-image tasks, their applications to multi-image scenarios remains less explored.","Additionally, prior LMM research separately tackles different scenarios, leaving it impossible to generalize cross scenarios with new emerging capabilities.","To this end, we introduce LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame (video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs.","To enable these capabilities, we regard the interleaved data format as a general template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4 primary domains with 14 tasks and 41 datasets.","We also curate the LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance of LMMs.","Through extensive experiments, LLaVA-NeXT-Interleave achieves leading results in multi-image, video, and 3D benchmarks, while maintaining the performance of single-image tasks.","Besides, our model also exhibits several emerging capabilities, e.g., transferring tasks across different settings and modalities.","Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT"],"url":"http://arxiv.org/abs/2407.07895v1"}
{"created":"2024-07-10 17:57:58","title":"Training on the Test Task Confounds Evaluation and Emergence","abstract":"We study a fundamental problem in the evaluation of large language models that we call training on the test task. Unlike wrongful practices like training on the test data, leakage, or data contamination, training on the test task is not a malpractice. Rather, the term describes a growing set of techniques to include task-relevant data in the pretraining stage of a language model. We demonstrate that training on the test task confounds both relative model evaluations and claims about emergent capabilities. We argue that the seeming superiority of one model family over another may be explained by a different degree of training on the test task. To this end, we propose an effective method to adjust for training on the test task by fine-tuning each model under comparison on the same task-relevant data before evaluation. We then show that instances of emergent behavior largely vanish once we adjust for training on the test task. This also applies to reported instances of emergent behavior that cannot be explained by the choice of evaluation metric. Our work promotes a new perspective on the evaluation of large language models with broad implications for benchmarking and the study of emergent capabilities.","sentences":["We study a fundamental problem in the evaluation of large language models that we call training on the test task.","Unlike wrongful practices like training on the test data, leakage, or data contamination, training on the test task is not a malpractice.","Rather, the term describes a growing set of techniques to include task-relevant data in the pretraining stage of a language model.","We demonstrate that training on the test task confounds both relative model evaluations and claims about emergent capabilities.","We argue that the seeming superiority of one model family over another may be explained by a different degree of training on the test task.","To this end, we propose an effective method to adjust for training on the test task by fine-tuning each model under comparison on the same task-relevant data before evaluation.","We then show that instances of emergent behavior largely vanish once we adjust for training on the test task.","This also applies to reported instances of emergent behavior that cannot be explained by the choice of evaluation metric.","Our work promotes a new perspective on the evaluation of large language models with broad implications for benchmarking and the study of emergent capabilities."],"url":"http://arxiv.org/abs/2407.07890v1"}
{"created":"2024-07-10 17:57:04","title":"AdaptiGraph: Material-Adaptive Graph-Based Neural Dynamics for Robotic Manipulation","abstract":"Predictive models are a crucial component of many robotic systems. Yet, constructing accurate predictive models for a variety of deformable objects, especially those with unknown physical properties, remains a significant challenge. This paper introduces AdaptiGraph, a learning-based dynamics modeling approach that enables robots to predict, adapt to, and control a wide array of challenging deformable materials with unknown physical properties. AdaptiGraph leverages the highly flexible graph-based neural dynamics (GBND) framework, which represents material bits as particles and employs a graph neural network (GNN) to predict particle motion. Its key innovation is a unified physical property-conditioned GBND model capable of predicting the motions of diverse materials with varying physical properties without retraining. Upon encountering new materials during online deployment, AdaptiGraph utilizes a physical property optimization process for a few-shot adaptation of the model, enhancing its fit to the observed interaction data. The adapted models can precisely simulate the dynamics and predict the motion of various deformable materials, such as ropes, granular media, rigid boxes, and cloth, while adapting to different physical properties, including stiffness, granular size, and center of pressure. On prediction and manipulation tasks involving a diverse set of real-world deformable objects, our method exhibits superior prediction accuracy and task proficiency over non-material-conditioned and non-adaptive models. The project page is available at https://robopil.github.io/adaptigraph/ .","sentences":["Predictive models are a crucial component of many robotic systems.","Yet, constructing accurate predictive models for a variety of deformable objects, especially those with unknown physical properties, remains a significant challenge.","This paper introduces AdaptiGraph, a learning-based dynamics modeling approach that enables robots to predict, adapt to, and control a wide array of challenging deformable materials with unknown physical properties.","AdaptiGraph leverages the highly flexible graph-based neural dynamics (GBND) framework, which represents material bits as particles and employs a graph neural network (GNN) to predict particle motion.","Its key innovation is a unified physical property-conditioned GBND model capable of predicting the motions of diverse materials with varying physical properties without retraining.","Upon encountering new materials during online deployment, AdaptiGraph utilizes a physical property optimization process for a few-shot adaptation of the model, enhancing its fit to the observed interaction data.","The adapted models can precisely simulate the dynamics and predict the motion of various deformable materials, such as ropes, granular media, rigid boxes, and cloth, while adapting to different physical properties, including stiffness, granular size, and center of pressure.","On prediction and manipulation tasks involving a diverse set of real-world deformable objects, our method exhibits superior prediction accuracy and task proficiency over non-material-conditioned and non-adaptive models.","The project page is available at https://robopil.github.io/adaptigraph/ ."],"url":"http://arxiv.org/abs/2407.07889v1"}
{"created":"2024-07-10 17:52:30","title":"Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing","abstract":"Recent progress in reinforcement learning (RL) and tactile sensing has significantly advanced dexterous manipulation. However, these methods often utilize simplified tactile signals due to the gap between tactile simulation and the real world. We introduce a sensor model for tactile skin that enables zero-shot sim-to-real transfer of ternary shear and binary normal forces. Using this model, we develop an RL policy that leverages sliding contact for dexterous in-hand translation. We conduct extensive real-world experiments to assess how tactile sensing facilitates policy adaptation to various unseen object properties and robot hand orientations. We demonstrate that our 3-axis tactile policies consistently outperform baselines that use only shear forces, only normal forces, or only proprioception. Website: https://jessicayin.github.io/tactile-skin-rl/","sentences":["Recent progress in reinforcement learning (RL) and tactile sensing has significantly advanced dexterous manipulation.","However, these methods often utilize simplified tactile signals due to the gap between tactile simulation and the real world.","We introduce a sensor model for tactile skin that enables zero-shot sim-to-real transfer of ternary shear and binary normal forces.","Using this model, we develop an RL policy that leverages sliding contact for dexterous in-hand translation.","We conduct extensive real-world experiments to assess how tactile sensing facilitates policy adaptation to various unseen object properties and robot hand orientations.","We demonstrate that our 3-axis tactile policies consistently outperform baselines that use only shear forces, only normal forces, or only proprioception.","Website: https://jessicayin.github.io/tactile-skin-rl/"],"url":"http://arxiv.org/abs/2407.07885v1"}
{"created":"2024-07-10 17:51:33","title":"Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation","abstract":"Recent studies have made significant progress in addressing dexterous manipulation problems, particularly in in-hand object reorientation. However, there are few existing works that explore the potential utilization of developed dexterous manipulation controllers for downstream tasks. In this study, we focus on constrained dexterous manipulation for food peeling. Food peeling presents various constraints on the reorientation controller, such as the requirement for the hand to securely hold the object after reorientation for peeling. We propose a simple system for learning a reorientation controller that facilitates the subsequent peeling task. Videos are available at: https://taochenshh.github.io/projects/veg-peeling.","sentences":["Recent studies have made significant progress in addressing dexterous manipulation problems, particularly in in-hand object reorientation.","However, there are few existing works that explore the potential utilization of developed dexterous manipulation controllers for downstream tasks.","In this study, we focus on constrained dexterous manipulation for food peeling.","Food peeling presents various constraints on the reorientation controller, such as the requirement for the hand to securely hold the object after reorientation for peeling.","We propose a simple system for learning a reorientation controller that facilitates the subsequent peeling task.","Videos are available at: https://taochenshh.github.io/projects/veg-peeling."],"url":"http://arxiv.org/abs/2407.07884v1"}
{"created":"2024-07-10 17:48:25","title":"Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization","abstract":"This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences. We categorize noise into pointwise noise, which includes low-quality data points, and pairwise noise, which encompasses erroneous data pair associations that affect preference rankings. Utilizing Distributionally Robust Optimization (DRO), we enhance DPO's resilience to these types of noise. Our theoretical insights reveal that DPO inherently embeds DRO principles, conferring robustness to pointwise noise, with the regularization coefficient $\\beta$ playing a critical role in its noise resistance. Extending this framework, we introduce Distributionally Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing against worst-case pairwise scenarios. The novel hyperparameter $\\beta'$ in Dr. DPO allows for fine-tuned control over data pair reliability, providing a strategic balance between exploration and exploitation in noisy training environments. Empirical evaluations demonstrate that Dr. DPO substantially improves the quality of generated text and response accuracy in preference datasets, showcasing enhanced performance in both noisy and noise-free settings. The code is available at https://github.com/junkangwu/Dr_DPO.","sentences":["This study addresses the challenge of noise in training datasets for Direct Preference Optimization (DPO), a method for aligning Large Language Models (LLMs) with human preferences.","We categorize noise into pointwise noise, which includes low-quality data points, and pairwise noise, which encompasses erroneous data pair associations that affect preference rankings.","Utilizing Distributionally Robust Optimization (DRO), we enhance DPO's resilience to these types of noise.","Our theoretical insights reveal that DPO inherently embeds DRO principles, conferring robustness to pointwise noise, with the regularization coefficient $\\beta$ playing a critical role in its noise resistance.","Extending this framework, we introduce Distributionally Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing against worst-case pairwise scenarios.","The novel hyperparameter $\\beta'$ in Dr. DPO allows for fine-tuned control over data pair reliability, providing a strategic balance between exploration and exploitation in noisy training environments.","Empirical evaluations demonstrate that Dr. DPO substantially improves the quality of generated text and response accuracy in preference datasets, showcasing enhanced performance in both noisy and noise-free settings.","The code is available at https://github.com/junkangwu/Dr_DPO."],"url":"http://arxiv.org/abs/2407.07880v1"}
{"created":"2024-07-10 17:41:10","title":"Generative Image as Action Models","abstract":"Image-generation diffusion models have been fine-tuned to unlock new capabilities such as image-editing and novel view synthesis. Can we similarly unlock image-generation models for visuomotor control? We present GENIMA, a behavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions' as targets on RGB images. These images are fed into a controller that maps the visual targets into a sequence of joint-positions. We study GENIMA on 25 RLBench and 9 real-world manipulation tasks. We find that, by lifting actions into image-space, internet pre-trained diffusion models can generate policies that outperform state-of-the-art visuomotor approaches, especially in robustness to scene perturbations and generalizing to novel objects. Our method is also competitive with 3D agents, despite lacking priors such as depth, keypoints, or motion-planners.","sentences":["Image-generation diffusion models have been fine-tuned to unlock new capabilities such as image-editing and novel view synthesis.","Can we similarly unlock image-generation models for visuomotor control?","We present GENIMA, a behavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions' as targets on RGB images.","These images are fed into a controller that maps the visual targets into a sequence of joint-positions.","We study GENIMA on 25 RLBench and 9 real-world manipulation tasks.","We find that, by lifting actions into image-space, internet pre-trained diffusion models can generate policies that outperform state-of-the-art visuomotor approaches, especially in robustness to scene perturbations and generalizing to novel objects.","Our method is also competitive with 3D agents, despite lacking priors such as depth, keypoints, or motion-planners."],"url":"http://arxiv.org/abs/2407.07875v1"}
{"created":"2024-07-10 17:40:30","title":"Toto: Time Series Optimized Transformer for Observability","abstract":"This technical report describes the Time Series Optimized Transformer for Observability (Toto), a new state of the art foundation model for time series forecasting developed by Datadog. In addition to advancing the state of the art on generalized time series benchmarks in domains such as electricity and weather, this model is the first general-purpose time series forecasting foundation model to be specifically tuned for observability metrics.   Toto was trained on a dataset of one trillion time series data points, the largest among all currently published time series foundation models. Alongside publicly available time series datasets, 75% of the data used to train Toto consists of fully anonymous numerical metric data points from the Datadog platform.   In our experiments, Toto outperforms existing time series foundation models on observability data. It does this while also excelling at general-purpose forecasting tasks, achieving state-of-the-art zero-shot performance on multiple open benchmark datasets.","sentences":["This technical report describes the Time Series Optimized Transformer for Observability (Toto), a new state of the art foundation model for time series forecasting developed by Datadog.","In addition to advancing the state of the art on generalized time series benchmarks in domains such as electricity and weather, this model is the first general-purpose time series forecasting foundation model to be specifically tuned for observability metrics.   ","Toto was trained on a dataset of one trillion time series data points, the largest among all currently published time series foundation models.","Alongside publicly available time series datasets, 75% of the data used to train Toto consists of fully anonymous numerical metric data points from the Datadog platform.   ","In our experiments, Toto outperforms existing time series foundation models on observability data.","It does this while also excelling at general-purpose forecasting tasks, achieving state-of-the-art zero-shot performance on multiple open benchmark datasets."],"url":"http://arxiv.org/abs/2407.07874v2"}
{"created":"2024-07-10 17:39:50","title":"Dynamical Measure Transport and Neural PDE Solvers for Sampling","abstract":"The task of sampling from a probability density can be approached as transporting a tractable density function to the target, known as dynamical measure transport. In this work, we tackle it through a principled unified framework using deterministic or stochastic evolutions described by partial differential equations (PDEs). This framework incorporates prior trajectory-based sampling methods, such as diffusion models or Schr\\\"odinger bridges, without relying on the concept of time-reversals. Moreover, it allows us to propose novel numerical methods for solving the transport task and thus sampling from complicated targets without the need for the normalization constant or data samples. We employ physics-informed neural networks (PINNs) to approximate the respective PDE solutions, implying both conceptional and computational advantages. In particular, PINNs allow for simulation- and discretization-free optimization and can be trained very efficiently, leading to significantly better mode coverage in the sampling task compared to alternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton methods to achieve high accuracy in sampling.","sentences":["The task of sampling from a probability density can be approached as transporting a tractable density function to the target, known as dynamical measure transport.","In this work, we tackle it through a principled unified framework using deterministic or stochastic evolutions described by partial differential equations (PDEs).","This framework incorporates prior trajectory-based sampling methods, such as diffusion models or Schr\\\"odinger bridges, without relying on the concept of time-reversals.","Moreover, it allows us to propose novel numerical methods for solving the transport task and thus sampling from complicated targets without the need for the normalization constant or data samples.","We employ physics-informed neural networks (PINNs) to approximate the respective PDE solutions, implying both conceptional and computational advantages.","In particular, PINNs allow for simulation- and discretization-free optimization and can be trained very efficiently, leading to significantly better mode coverage in the sampling task compared to alternative methods.","Moreover, they can readily be fine-tuned with Gauss-Newton methods to achieve high accuracy in sampling."],"url":"http://arxiv.org/abs/2407.07873v1"}
{"created":"2024-07-10 17:37:15","title":"Enhancing HNSW Index for Real-Time Updates: Addressing Unreachable Points and Performance Degradation","abstract":"The approximate nearest neighbor search (ANNS) is a fundamental and essential component in information retrieval, with graph-based methodologies demonstrating superior performance compared to alternative approaches. Extensive research efforts have been dedicated to improving search efficiency by developing various graph-based indices, such as HNSW (Hierarchical Navigable Small World). However, the performance of HNSW and most graph-based indices becomes unacceptable when faced with a large number of real-time deletions, insertions, and updates. Furthermore, during update operations, HNSW can result in some data points becoming unreachable, a situation we refer to as the `unreachable points phenomenon'. This phenomenon could significantly affect the search accuracy of the graph in certain situations.   To address these issues, we present efficient measures to overcome the shortcomings of HNSW, specifically addressing poor performance over long periods of delete and update operations and resolving the issues caused by the unreachable points phenomenon. Our proposed MN-RU algorithm effectively improves update efficiency and suppresses the growth rate of unreachable points, ensuring better overall performance and maintaining the integrity of the graph. Our results demonstrate that our methods outperform existing approaches. Furthermore, since our methods are based on HNSW, they can be easily integrated with existing indices widely used in the industrial field, making them practical for future real-world applications. Code is available at https://github.com/xwt1/ICPADS-MN-RU.git","sentences":["The approximate nearest neighbor search (ANNS) is a fundamental and essential component in information retrieval, with graph-based methodologies demonstrating superior performance compared to alternative approaches.","Extensive research efforts have been dedicated to improving search efficiency by developing various graph-based indices, such as HNSW (Hierarchical Navigable Small World).","However, the performance of HNSW and most graph-based indices becomes unacceptable when faced with a large number of real-time deletions, insertions, and updates.","Furthermore, during update operations, HNSW can result in some data points becoming unreachable, a situation we refer to as the `unreachable points phenomenon'.","This phenomenon could significantly affect the search accuracy of the graph in certain situations.   ","To address these issues, we present efficient measures to overcome the shortcomings of HNSW, specifically addressing poor performance over long periods of delete and update operations and resolving the issues caused by the unreachable points phenomenon.","Our proposed MN-RU algorithm effectively improves update efficiency and suppresses the growth rate of unreachable points, ensuring better overall performance and maintaining the integrity of the graph.","Our results demonstrate that our methods outperform existing approaches.","Furthermore, since our methods are based on HNSW, they can be easily integrated with existing indices widely used in the industrial field, making them practical for future real-world applications.","Code is available at https://github.com/xwt1/ICPADS-MN-RU.git"],"url":"http://arxiv.org/abs/2407.07871v1"}
{"created":"2024-07-10 17:32:05","title":"Green Screen Augmentation Enables Scene Generalisation in Robotic Manipulation","abstract":"Generalising vision-based manipulation policies to novel environments remains a challenging area with limited exploration. Current practices involve collecting data in one location, training imitation learning or reinforcement learning policies with this data, and deploying the policy in the same location. However, this approach lacks scalability as it necessitates data collection in multiple locations for each task. This paper proposes a novel approach where data is collected in a location predominantly featuring green screens. We introduce Green-screen Augmentation (GreenAug), employing a chroma key algorithm to overlay background textures onto a green screen. Through extensive real-world empirical studies with over 850 training demonstrations and 8.2k evaluation episodes, we demonstrate that GreenAug surpasses no augmentation, standard computer vision augmentation, and prior generative augmentation methods in performance. While no algorithmic novelties are claimed, our paper advocates for a fundamental shift in data collection practices. We propose that real-world demonstrations in future research should utilise green screens, followed by the application of GreenAug. We believe GreenAug unlocks policy generalisation to visually distinct novel locations, addressing the current scene generalisation limitations in robot learning.","sentences":["Generalising vision-based manipulation policies to novel environments remains a challenging area with limited exploration.","Current practices involve collecting data in one location, training imitation learning or reinforcement learning policies with this data, and deploying the policy in the same location.","However, this approach lacks scalability as it necessitates data collection in multiple locations for each task.","This paper proposes a novel approach where data is collected in a location predominantly featuring green screens.","We introduce Green-screen Augmentation (GreenAug), employing a chroma key algorithm to overlay background textures onto a green screen.","Through extensive real-world empirical studies with over 850 training demonstrations and 8.2k evaluation episodes, we demonstrate that GreenAug surpasses no augmentation, standard computer vision augmentation, and prior generative augmentation methods in performance.","While no algorithmic novelties are claimed, our paper advocates for a fundamental shift in data collection practices.","We propose that real-world demonstrations in future research should utilise green screens, followed by the application of GreenAug.","We believe GreenAug unlocks policy generalisation to visually distinct novel locations, addressing the current scene generalisation limitations in robot learning."],"url":"http://arxiv.org/abs/2407.07868v1"}
{"created":"2024-07-10 17:23:33","title":"Controlling Space and Time with Diffusion Models","abstract":"We present 4DiM, a cascaded diffusion model for 4D novel view synthesis (NVS), conditioned on one or more images of a general scene, and a set of camera poses and timestamps. To overcome challenges due to limited availability of 4D training data, we advocate joint training on 3D (with camera pose), 4D (pose+time) and video (time but no pose) data and propose a new architecture that enables the same. We further advocate the calibration of SfM posed data using monocular metric depth estimators for metric scale camera control. For model evaluation, we introduce new metrics to enrich and overcome shortcomings of current evaluation schemes, demonstrating state-of-the-art results in both fidelity and pose control compared to existing diffusion models for 3D NVS, while at the same time adding the ability to handle temporal dynamics. 4DiM is also used for improved panorama stitching, pose-conditioned video to video translation, and several other tasks. For an overview see https://4d-diffusion.github.io","sentences":["We present 4DiM, a cascaded diffusion model for 4D novel view synthesis (NVS), conditioned on one or more images of a general scene, and a set of camera poses and timestamps.","To overcome challenges due to limited availability of 4D training data, we advocate joint training on 3D (with camera pose), 4D (pose+time) and video (time but no pose) data and propose a new architecture that enables the same.","We further advocate the calibration of SfM posed data using monocular metric depth estimators for metric scale camera control.","For model evaluation, we introduce new metrics to enrich and overcome shortcomings of current evaluation schemes, demonstrating state-of-the-art results in both fidelity and pose control compared to existing diffusion models for 3D NVS, while at the same time adding the ability to handle temporal dynamics.","4DiM is also used for improved panorama stitching, pose-conditioned video to video translation, and several other tasks.","For an overview see https://4d-diffusion.github.io"],"url":"http://arxiv.org/abs/2407.07860v1"}
{"created":"2024-07-10 17:20:59","title":"FACTS About Building Retrieval Augmented Generation-based Chatbots","abstract":"Enterprise chatbots, powered by generative AI, are emerging as key applications to enhance employee productivity. Retrieval Augmented Generation (RAG), Large Language Models (LLMs), and orchestration frameworks like Langchain and Llamaindex are crucial for building these chatbots. However, creating effective enterprise chatbots is challenging and requires meticulous RAG pipeline engineering. This includes fine-tuning embeddings and LLMs, extracting documents from vector databases, rephrasing queries, reranking results, designing prompts, honoring document access controls, providing concise responses, including references, safeguarding personal information, and building orchestration agents. We present a framework for building RAG-based chatbots based on our experience with three NVIDIA chatbots: for IT/HR benefits, financial earnings, and general content. Our contributions are three-fold: introducing the FACTS framework (Freshness, Architectures, Cost, Testing, Security), presenting fifteen RAG pipeline control points, and providing empirical results on accuracy-latency tradeoffs between large and small LLMs. To the best of our knowledge, this is the first paper of its kind that provides a holistic view of the factors as well as solutions for building secure enterprise-grade chatbots.\"","sentences":["Enterprise chatbots, powered by generative AI, are emerging as key applications to enhance employee productivity.","Retrieval Augmented Generation (RAG), Large Language Models (LLMs), and orchestration frameworks like Langchain and Llamaindex are crucial for building these chatbots.","However, creating effective enterprise chatbots is challenging and requires meticulous RAG pipeline engineering.","This includes fine-tuning embeddings and LLMs, extracting documents from vector databases, rephrasing queries, reranking results, designing prompts, honoring document access controls, providing concise responses, including references, safeguarding personal information, and building orchestration agents.","We present a framework for building RAG-based chatbots based on our experience with three NVIDIA chatbots: for IT/HR benefits, financial earnings, and general content.","Our contributions are three-fold: introducing the FACTS framework (Freshness, Architectures, Cost, Testing, Security), presenting fifteen RAG pipeline control points, and providing empirical results on accuracy-latency tradeoffs between large and small LLMs.","To the best of our knowledge, this is the first paper of its kind that provides a holistic view of the factors as well as solutions for building secure enterprise-grade chatbots.\""],"url":"http://arxiv.org/abs/2407.07858v1"}
{"created":"2024-07-10 17:14:54","title":"Progressive Growing of Patch Size: Resource-Efficient Curriculum Learning for Dense Prediction Tasks","abstract":"In this work, we introduce Progressive Growing of Patch Size, a resource-efficient implicit curriculum learning approach for dense prediction tasks. Our curriculum approach is defined by growing the patch size during model training, which gradually increases the task's difficulty. We integrated our curriculum into the nnU-Net framework and evaluated the methodology on all 10 tasks of the Medical Segmentation Decathlon. With our approach, we are able to substantially reduce runtime, computational costs, and CO2 emissions of network training compared to classical constant patch size training. In our experiments, the curriculum approach resulted in improved convergence. We are able to outperform standard nnU-Net training, which is trained with constant patch size, in terms of Dice Score on 7 out of 10 MSD tasks while only spending roughly 50% of the original training runtime. To the best of our knowledge, our Progressive Growing of Patch Size is the first successful employment of a sample-length curriculum in the form of patch size in the field of computer vision. Our code is publicly available at https://github.com/compai-lab/2024-miccai-fischer.","sentences":["In this work, we introduce Progressive Growing of Patch Size, a resource-efficient implicit curriculum learning approach for dense prediction tasks.","Our curriculum approach is defined by growing the patch size during model training, which gradually increases the task's difficulty.","We integrated our curriculum into the nnU-Net framework and evaluated the methodology on all 10 tasks of the Medical Segmentation Decathlon.","With our approach, we are able to substantially reduce runtime, computational costs, and CO2 emissions of network training compared to classical constant patch size training.","In our experiments, the curriculum approach resulted in improved convergence.","We are able to outperform standard nnU-Net training, which is trained with constant patch size, in terms of Dice Score on 7 out of 10 MSD tasks while only spending roughly 50% of the original training runtime.","To the best of our knowledge, our Progressive Growing of Patch Size is the first successful employment of a sample-length curriculum in the form of patch size in the field of computer vision.","Our code is publicly available at https://github.com/compai-lab/2024-miccai-fischer."],"url":"http://arxiv.org/abs/2407.07853v2"}
{"created":"2024-07-10 17:13:17","title":"OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training","abstract":"OpenDiLoCo is an open-source implementation and replication of the Distributed Low-Communication (DiLoCo) training method for large language models. We provide a reproducible implementation of the DiLoCo experiments, offering it within a scalable, decentralized training framework using the Hivemind library. We demonstrate its effectiveness by training a model across two continents and three countries, while maintaining 90-95% compute utilization. Additionally, we conduct ablations studies focusing on the algorithm's compute efficiency, scalability in the number of workers and show that its gradients can be all-reduced using FP16 without any performance degradation. Furthermore, we scale OpenDiLoCo to 3x the size of the original work, demonstrating its effectiveness for billion parameter models.","sentences":["OpenDiLoCo is an open-source implementation and replication of the Distributed Low-Communication (DiLoCo) training method for large language models.","We provide a reproducible implementation of the DiLoCo experiments, offering it within a scalable, decentralized training framework using the Hivemind library.","We demonstrate its effectiveness by training a model across two continents and three countries, while maintaining 90-95% compute utilization.","Additionally, we conduct ablations studies focusing on the algorithm's compute efficiency, scalability in the number of workers and show that its gradients can be all-reduced using FP16 without any performance degradation.","Furthermore, we scale OpenDiLoCo to 3x the size of the original work, demonstrating its effectiveness for billion parameter models."],"url":"http://arxiv.org/abs/2407.07852v1"}
{"created":"2024-07-10 17:12:57","title":"Harnessing Integrated CPU-GPU System Memory for HPC: a first look into Grace Hopper","abstract":"Memory management across discrete CPU and GPU physical memory is traditionally achieved through explicit GPU allocations and data copy or unified virtual memory. The Grace Hopper Superchip, for the first time, supports an integrated CPU-GPU system page table, hardware-level addressing of system allocated memory, and cache-coherent NVLink-C2C interconnect, bringing an alternative solution for enabling a Unified Memory system. In this work, we provide the first in-depth study of the system memory management on the Grace Hopper Superchip, in both in-memory and memory oversubscription scenarios. We provide a suite of six representative applications, including the Qiskit quantum computing simulator, using system memory and managed memory. Using our memory utilization profiler and hardware counters, we quantify and characterize the impact of the integrated CPU-GPU system page table on GPU applications. Our study focuses on first-touch policy, page table entry initialization, page sizes, and page migration. We identify practical optimization strategies for different access patterns. Our results show that as a new solution for unified memory, the system-allocated memory can benefit most use cases with minimal porting efforts.","sentences":["Memory management across discrete CPU and GPU physical memory is traditionally achieved through explicit GPU allocations and data copy or unified virtual memory.","The Grace Hopper Superchip, for the first time, supports an integrated CPU-GPU system page table, hardware-level addressing of system allocated memory, and cache-coherent NVLink-C2C interconnect, bringing an alternative solution for enabling a Unified Memory system.","In this work, we provide the first in-depth study of the system memory management on the Grace Hopper Superchip, in both in-memory and memory oversubscription scenarios.","We provide a suite of six representative applications, including the Qiskit quantum computing simulator, using system memory and managed memory.","Using our memory utilization profiler and hardware counters, we quantify and characterize the impact of the integrated CPU-GPU system page table on GPU applications.","Our study focuses on first-touch policy, page table entry initialization, page sizes, and page migration.","We identify practical optimization strategies for different access patterns.","Our results show that as a new solution for unified memory, the system-allocated memory can benefit most use cases with minimal porting efforts."],"url":"http://arxiv.org/abs/2407.07850v1"}
{"created":"2024-07-10 17:10:10","title":"Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers","abstract":"Previous work has demonstrated that MLPs within ReLU Transformers exhibit high levels of sparsity, with many of their activations equal to zero for any given token. We build on that work to more deeply explore how token-level sparsity evolves over the course of training, and how it connects to broader sparsity patterns over the course of a sequence or batch, demonstrating that the different layers within small transformers exhibit distinctly layer-specific patterns on both of these fronts. In particular, we demonstrate that the first and last layer of the network have distinctive and in many ways inverted relationships to sparsity, and explore implications for the structure of feature representations being learned at different depths of the model. We additionally explore the phenomenon of ReLU dimensions \"turning off\", and show evidence suggesting that \"neuron death\" is being primarily driven by the dynamics of training, rather than simply occurring randomly or accidentally as a result of outliers.","sentences":["Previous work has demonstrated that MLPs within ReLU Transformers exhibit high levels of sparsity, with many of their activations equal to zero for any given token.","We build on that work to more deeply explore how token-level sparsity evolves over the course of training, and how it connects to broader sparsity patterns over the course of a sequence or batch, demonstrating that the different layers within small transformers exhibit distinctly layer-specific patterns on both of these fronts.","In particular, we demonstrate that the first and last layer of the network have distinctive and in many ways inverted relationships to sparsity, and explore implications for the structure of feature representations being learned at different depths of the model.","We additionally explore the phenomenon of ReLU dimensions \"turning off\", and show evidence suggesting that \"neuron death\" is being primarily driven by the dynamics of training, rather than simply occurring randomly or accidentally as a result of outliers."],"url":"http://arxiv.org/abs/2407.07848v1"}
{"created":"2024-07-10 17:08:08","title":"Natural Language Mechanisms via Self-Resolution with Foundation Models","abstract":"Practical mechanisms often limit agent reports to constrained formats like trades or orderings, potentially limiting the information agents can express. We propose a novel class of mechanisms that elicit agent reports in natural language and leverage the world-modeling capabilities of large language models (LLMs) to select outcomes and assign payoffs. We identify sufficient conditions for these mechanisms to be incentive-compatible and efficient as the LLM being a good enough world model and a strong inter-agent information over-determination condition. We show situations where these LM-based mechanisms can successfully aggregate information in signal structures on which prediction markets fail.","sentences":["Practical mechanisms often limit agent reports to constrained formats like trades or orderings, potentially limiting the information agents can express.","We propose a novel class of mechanisms that elicit agent reports in natural language and leverage the world-modeling capabilities of large language models (LLMs) to select outcomes and assign payoffs.","We identify sufficient conditions for these mechanisms to be incentive-compatible and efficient as the LLM being a good enough world model and a strong inter-agent information over-determination condition.","We show situations where these LM-based mechanisms can successfully aggregate information in signal structures on which prediction markets fail."],"url":"http://arxiv.org/abs/2407.07845v1"}
{"created":"2024-07-10 17:05:49","title":"OV-DINO: Unified Open-Vocabulary Detection with Language-Aware Selective Fusion","abstract":"Open-vocabulary detection is a challenging task due to the requirement of detecting objects based on class names, including those not encountered during training. Existing methods have shown strong zero-shot detection capabilities through pre-training on diverse large-scale datasets. However, these approaches still face two primary challenges: (i) how to universally integrate diverse data sources for end-to-end training, and (ii) how to effectively leverage the language-aware capability for region-level cross-modality understanding. To address these challenges, we propose a novel unified open-vocabulary detection method called OV-DINO, which pre-trains on diverse large-scale datasets with language-aware selective fusion in a unified framework. Specifically, we introduce a Unified Data Integration (UniDI) pipeline to enable end-to-end training and eliminate noise from pseudo-label generation by unifying different data sources into detection-centric data. In addition, we propose a Language-Aware Selective Fusion (LASF) module to enable the language-aware ability of the model through a language-aware query selection and fusion process. We evaluate the performance of the proposed OV-DINO on popular open-vocabulary detection benchmark datasets, achieving state-of-the-art results with an AP of 50.6\\% on the COCO dataset and 40.0\\% on the LVIS dataset in a zero-shot manner, demonstrating its strong generalization ability. Furthermore, the fine-tuned OV-DINO on COCO achieves 58.4\\% AP, outperforming many existing methods with the same backbone. The code for OV-DINO will be available at \\href{https://github.com/wanghao9610/OV-DINO}{https://github.com/wanghao9610/OV-DINO}.","sentences":["Open-vocabulary detection is a challenging task due to the requirement of detecting objects based on class names, including those not encountered during training.","Existing methods have shown strong zero-shot detection capabilities through pre-training on diverse large-scale datasets.","However, these approaches still face two primary challenges: (i) how to universally integrate diverse data sources for end-to-end training, and (ii) how to effectively leverage the language-aware capability for region-level cross-modality understanding.","To address these challenges, we propose a novel unified open-vocabulary detection method called OV-DINO, which pre-trains on diverse large-scale datasets with language-aware selective fusion in a unified framework.","Specifically, we introduce a Unified Data Integration (UniDI) pipeline to enable end-to-end training and eliminate noise from pseudo-label generation by unifying different data sources into detection-centric data.","In addition, we propose a Language-Aware Selective Fusion (LASF) module to enable the language-aware ability of the model through a language-aware query selection and fusion process.","We evaluate the performance of the proposed OV-DINO on popular open-vocabulary detection benchmark datasets, achieving state-of-the-art results with an AP of 50.6\\% on the COCO dataset and 40.0\\% on the LVIS dataset in a zero-shot manner, demonstrating its strong generalization ability.","Furthermore, the fine-tuned OV-DINO on COCO achieves 58.4\\% AP, outperforming many existing methods with the same backbone.","The code for OV-DINO will be available at \\href{https://github.com/wanghao9610/OV-DINO}{https://github.com/wanghao9610/OV-DINO}."],"url":"http://arxiv.org/abs/2407.07844v1"}
{"created":"2024-07-10 17:02:42","title":"Study on Aspect Ratio Variability toward Robustness of Vision Transformer-based Vehicle Re-identification","abstract":"Vision Transformers (ViTs) have excelled in vehicle re-identification (ReID) tasks. However, non-square aspect ratios of image or video input might significantly affect the re-identification performance. To address this issue, we propose a novel ViT-based ReID framework in this paper, which fuses models trained on a variety of aspect ratios. Our main contributions are threefold: (i) We analyze aspect ratio performance on VeRi-776 and VehicleID datasets, guiding input settings based on aspect ratios of original images. (ii) We introduce patch-wise mixup intra-image during ViT patchification (guided by spatial attention scores) and implement uneven stride for better object aspect ratio matching. (iii) We propose a dynamic feature fusing ReID network, enhancing model robustness. Our ReID method achieves a significantly improved mean Average Precision (mAP) of 91.0\\% compared to the the closest state-of-the-art (CAL) result of 80.9\\% on VehicleID dataset.","sentences":["Vision Transformers (ViTs) have excelled in vehicle re-identification (ReID) tasks.","However, non-square aspect ratios of image or video input might significantly affect the re-identification performance.","To address this issue, we propose a novel ViT-based ReID framework in this paper, which fuses models trained on a variety of aspect ratios.","Our main contributions are threefold: (i) We analyze aspect ratio performance on VeRi-776 and VehicleID datasets, guiding input settings based on aspect ratios of original images.","(ii) We introduce patch-wise mixup intra-image during ViT patchification (guided by spatial attention scores) and implement uneven stride for better object aspect ratio matching.","(iii) We propose a dynamic feature fusing ReID network, enhancing model robustness.","Our ReID method achieves a significantly improved mean Average Precision (mAP) of 91.0\\% compared to the the closest state-of-the-art (CAL) result of 80.9\\% on VehicleID dataset."],"url":"http://arxiv.org/abs/2407.07842v1"}
{"created":"2024-07-10 17:00:57","title":"Benchmarking Embedding Aggregation Methods in Computational Pathology: A Clinical Data Perspective","abstract":"Recent advances in artificial intelligence (AI), in particular self-supervised learning of foundation models (FMs), are revolutionizing medical imaging and computational pathology (CPath). A constant challenge in the analysis of digital Whole Slide Images (WSIs) is the problem of aggregating tens of thousands of tile-level image embeddings to a slide-level representation. Due to the prevalent use of datasets created for genomic research, such as TCGA, for method development, the performance of these techniques on diagnostic slides from clinical practice has been inadequately explored. This study conducts a thorough benchmarking analysis of ten slide-level aggregation techniques across nine clinically relevant tasks, including diagnostic assessment, biomarker classification, and outcome prediction. The results yield following key insights: (1) Embeddings derived from domain-specific (histological images) FMs outperform those from generic ImageNet-based models across aggregation methods. (2) Spatial-aware aggregators enhance the performance significantly when using ImageNet pre-trained models but not when using FMs. (3) No single model excels in all tasks and spatially-aware models do not show general superiority as it would be expected. These findings underscore the need for more adaptable and universally applicable aggregation techniques, guiding future research towards tools that better meet the evolving needs of clinical-AI in pathology. The code used in this work is available at \\url{https://github.com/fuchs-lab-public/CPath_SABenchmark}.","sentences":["Recent advances in artificial intelligence (AI), in particular self-supervised learning of foundation models (FMs), are revolutionizing medical imaging and computational pathology (CPath).","A constant challenge in the analysis of digital Whole Slide Images (WSIs) is the problem of aggregating tens of thousands of tile-level image embeddings to a slide-level representation.","Due to the prevalent use of datasets created for genomic research, such as TCGA, for method development, the performance of these techniques on diagnostic slides from clinical practice has been inadequately explored.","This study conducts a thorough benchmarking analysis of ten slide-level aggregation techniques across nine clinically relevant tasks, including diagnostic assessment, biomarker classification, and outcome prediction.","The results yield following key insights: (1) Embeddings derived from domain-specific (histological images)","FMs outperform those from generic ImageNet-based models across aggregation methods.","(2) Spatial-aware aggregators enhance the performance significantly when using ImageNet pre-trained models but not when using FMs.","(3) No single model excels in all tasks and spatially-aware models do not show general superiority as it would be expected.","These findings underscore the need for more adaptable and universally applicable aggregation techniques, guiding future research towards tools that better meet the evolving needs of clinical-AI in pathology.","The code used in this work is available at \\url{https://github.com/fuchs-lab-public/CPath_SABenchmark}."],"url":"http://arxiv.org/abs/2407.07841v1"}
{"created":"2024-07-10 17:00:29","title":"Decompose and Compare Consistency: Measuring VLMs' Answer Reliability via Task-Decomposition Consistency Comparison","abstract":"Despite tremendous advancements, current state-of-the-art Vision-Language Models (VLMs) are still far from perfect. They tend to hallucinate and may generate biased responses. In such circumstances, having a way to assess the reliability of a given response generated by a VLM is quite useful. Existing methods, such as estimating uncertainty using answer likelihoods or prompt-based confidence generation, often suffer from overconfidence. Other methods use self-consistency comparison but are affected by confirmation biases. To alleviate these, we propose \\textbf{De}compose and \\textbf{C}ompare \\textbf{C}onsistency (\\texttt{DeCC}) for reliability measurement. By comparing the consistency between the direct answer generated using the VLM's internal reasoning process, and the indirect answers obtained by decomposing the question into sub-questions and reasoning over the sub-answers produced by the VLM, \\texttt{DeCC} measures the reliability of VLM's direct answer. Experiments across six vision-language tasks with three VLMs show \\texttt{DeCC}'s reliability estimation achieves better correlation with task accuracy compared to the existing methods.","sentences":["Despite tremendous advancements, current state-of-the-art Vision-Language Models (VLMs) are still far from perfect.","They tend to hallucinate and may generate biased responses.","In such circumstances, having a way to assess the reliability of a given response generated by a VLM is quite useful.","Existing methods, such as estimating uncertainty using answer likelihoods or prompt-based confidence generation, often suffer from overconfidence.","Other methods use self-consistency comparison but are affected by confirmation biases.","To alleviate these, we propose \\textbf{De}compose and \\textbf{C}ompare \\textbf{C}onsistency (\\texttt{DeCC}) for reliability measurement.","By comparing the consistency between the direct answer generated using the VLM's internal reasoning process, and the indirect answers obtained by decomposing the question into sub-questions and reasoning over the sub-answers produced by the VLM, \\texttt{DeCC} measures the reliability of VLM's direct answer.","Experiments across six vision-language tasks with three VLMs show \\texttt{DeCC}'s reliability estimation achieves better correlation with task accuracy compared to the existing methods."],"url":"http://arxiv.org/abs/2407.07840v1"}
{"created":"2024-07-10 16:55:01","title":"RoBus: A Multimodal Dataset for Controllable Road Networks and Building Layouts Generation","abstract":"Automated 3D city generation, focusing on road networks and building layouts, is in high demand for applications in urban design, multimedia games and autonomous driving simulations. The surge of generative AI facilitates designing city layouts based on deep learning models. However, the lack of high-quality datasets and benchmarks hinders the progress of these data-driven methods in generating road networks and building layouts. Furthermore, few studies consider urban characteristics, which generally take graphics as analysis objects and are crucial for practical applications, to control the generative process. To alleviate these problems, we introduce a multimodal dataset with accompanying evaluation metrics for controllable generation of Road networks and Building layouts (RoBus), which is the first and largest open-source dataset in city generation so far. RoBus dataset is formatted as images, graphics and texts, with $72,400$ paired samples that cover around $80,000km^2$ globally. We analyze the RoBus dataset statistically and validate the effectiveness against existing road networks and building layouts generation methods. Additionally, we design new baselines that incorporate urban characteristics, such as road orientation and building density, in the process of generating road networks and building layouts using the RoBus dataset, enhancing the practicality of automated urban design. The RoBus dataset and related codes are published at https://github.com/tourlics/RoBus_Dataset.","sentences":["Automated 3D city generation, focusing on road networks and building layouts, is in high demand for applications in urban design, multimedia games and autonomous driving simulations.","The surge of generative AI facilitates designing city layouts based on deep learning models.","However, the lack of high-quality datasets and benchmarks hinders the progress of these data-driven methods in generating road networks and building layouts.","Furthermore, few studies consider urban characteristics, which generally take graphics as analysis objects and are crucial for practical applications, to control the generative process.","To alleviate these problems, we introduce a multimodal dataset with accompanying evaluation metrics for controllable generation of Road networks and Building layouts (RoBus), which is the first and largest open-source dataset in city generation so far.","RoBus dataset is formatted as images, graphics and texts, with $72,400$ paired samples that cover around $80,000km^2$ globally.","We analyze the RoBus dataset statistically and validate the effectiveness against existing road networks and building layouts generation methods.","Additionally, we design new baselines that incorporate urban characteristics, such as road orientation and building density, in the process of generating road networks and building layouts using the RoBus dataset, enhancing the practicality of automated urban design.","The RoBus dataset and related codes are published at https://github.com/tourlics/RoBus_Dataset."],"url":"http://arxiv.org/abs/2407.07835v1"}
{"created":"2024-07-10 16:51:32","title":"Disentangled Representation Learning through Geometry Preservation with the Gromov-Monge Gap","abstract":"Learning disentangled representations in an unsupervised manner is a fundamental challenge in machine learning. Solving it may unlock other problems, such as generalization, interpretability, or fairness. While remarkably difficult to solve in general, recent works have shown that disentanglement is provably achievable under additional assumptions that can leverage geometrical constraints, such as local isometry. To use these insights, we propose a novel perspective on disentangled representation learning built on quadratic optimal transport. Specifically, we formulate the problem in the Gromov-Monge setting, which seeks isometric mappings between distributions supported on different spaces. We propose the Gromov-Monge-Gap (GMG), a regularizer that quantifies the geometry-preservation of an arbitrary push-forward map between two distributions supported on different spaces. We demonstrate the effectiveness of GMG regularization for disentanglement on four standard benchmarks. Moreover, we show that geometry preservation can even encourage unsupervised disentanglement without the standard reconstruction objective - making the underlying model decoder-free, and promising a more practically viable and scalable perspective on unsupervised disentanglement.","sentences":["Learning disentangled representations in an unsupervised manner is a fundamental challenge in machine learning.","Solving it may unlock other problems, such as generalization, interpretability, or fairness.","While remarkably difficult to solve in general, recent works have shown that disentanglement is provably achievable under additional assumptions that can leverage geometrical constraints, such as local isometry.","To use these insights, we propose a novel perspective on disentangled representation learning built on quadratic optimal transport.","Specifically, we formulate the problem in the Gromov-Monge setting, which seeks isometric mappings between distributions supported on different spaces.","We propose the Gromov-Monge-Gap (GMG), a regularizer that quantifies the geometry-preservation of an arbitrary push-forward map between two distributions supported on different spaces.","We demonstrate the effectiveness of GMG regularization for disentanglement on four standard benchmarks.","Moreover, we show that geometry preservation can even encourage unsupervised disentanglement without the standard reconstruction objective - making the underlying model decoder-free, and promising a more practically viable and scalable perspective on unsupervised disentanglement."],"url":"http://arxiv.org/abs/2407.07829v1"}
{"created":"2024-07-10 16:50:59","title":"Estimating the stability number of a random graph using convolutional neural networks","abstract":"Graph combinatorial optimization problems are widely applicable and notoriously difficult to compute; for example, consider the traveling salesman or facility location problems. In this paper, we explore the feasibility of using convolutional neural networks (CNNs) on graph images to predict the cardinality of combinatorial properties of random graphs and networks. Specifically, we use image representations of modified adjacency matrices of random graphs as training samples for a CNN model to predict the stability number of random graphs; where the stability number is the cardinality of a maximum set of vertices containing no pairwise adjacency. Our approach demonstrates the potential for applying deep learning in combinatorial optimization problems.","sentences":["Graph combinatorial optimization problems are widely applicable and notoriously difficult to compute; for example, consider the traveling salesman or facility location problems.","In this paper, we explore the feasibility of using convolutional neural networks (CNNs) on graph images to predict the cardinality of combinatorial properties of random graphs and networks.","Specifically, we use image representations of modified adjacency matrices of random graphs as training samples for a CNN model to predict the stability number of random graphs; where the stability number is the cardinality of a maximum set of vertices containing no pairwise adjacency.","Our approach demonstrates the potential for applying deep learning in combinatorial optimization problems."],"url":"http://arxiv.org/abs/2407.07827v1"}
{"created":"2024-07-10 16:49:23","title":"RT-LA-VocE: Real-Time Low-SNR Audio-Visual Speech Enhancement","abstract":"In this paper, we aim to generate clean speech frame by frame from a live video stream and a noisy audio stream without relying on future inputs. To this end, we propose RT-LA-VocE, which completely re-designs every component of LA-VocE, a state-of-the-art non-causal audio-visual speech enhancement model, to perform causal real-time inference with a 40ms input frame. We do so by devising new visual and audio encoders that rely solely on past frames, replacing the Transformer encoder with the Emformer, and designing a new causal neural vocoder C-HiFi-GAN. On the popular AVSpeech dataset, we show that our algorithm achieves state-of-the-art results in all real-time scenarios. More importantly, each component is carefully tuned to minimize the algorithm latency to the theoretical minimum (40ms) while maintaining a low end-to-end processing latency of 28.15ms per frame, enabling real-time frame-by-frame enhancement with minimal delay.","sentences":["In this paper, we aim to generate clean speech frame by frame from a live video stream and a noisy audio stream without relying on future inputs.","To this end, we propose RT-LA-VocE, which completely re-designs every component of LA-VocE, a state-of-the-art non-causal audio-visual speech enhancement model, to perform causal real-time inference with a 40ms input frame.","We do so by devising new visual and audio encoders that rely solely on past frames, replacing the Transformer encoder with the Emformer, and designing a new causal neural vocoder C-HiFi-GAN.","On the popular AVSpeech dataset, we show that our algorithm achieves state-of-the-art results in all real-time scenarios.","More importantly, each component is carefully tuned to minimize the algorithm latency to the theoretical minimum (40ms) while maintaining a low end-to-end processing latency of 28.15ms per frame, enabling real-time frame-by-frame enhancement with minimal delay."],"url":"http://arxiv.org/abs/2407.07825v1"}
{"created":"2024-07-10 16:45:52","title":"When to Accept Automated Predictions and When to Defer to Human Judgment?","abstract":"Ensuring the reliability and safety of automated decision-making is crucial. It is well-known that data distribution shifts in machine learning can produce unreliable outcomes. This paper proposes a new approach for measuring the reliability of predictions under distribution shifts. We analyze how the outputs of a trained neural network change using clustering to measure distances between outputs and class centroids. We propose this distance as a metric to evaluate the confidence of predictions under distribution shifts. We assign each prediction to a cluster with centroid representing the mean softmax output for all correct predictions of a given class. We then define a safety threshold for a class as the smallest distance from an incorrect prediction to the given class centroid. We evaluate the approach on the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a Vision Transformer, respectively. The results show that our approach is consistent across these data sets and network models, and indicate that the proposed metric can offer an efficient way of determining when automated predictions are acceptable and when they should be deferred to human operators given a distribution shift.","sentences":["Ensuring the reliability and safety of automated decision-making is crucial.","It is well-known that data distribution shifts in machine learning can produce unreliable outcomes.","This paper proposes a new approach for measuring the reliability of predictions under distribution shifts.","We analyze how the outputs of a trained neural network change using clustering to measure distances between outputs and class centroids.","We propose this distance as a metric to evaluate the confidence of predictions under distribution shifts.","We assign each prediction to a cluster with centroid representing the mean softmax output for all correct predictions of a given class.","We then define a safety threshold for a class as the smallest distance from an incorrect prediction to the given class centroid.","We evaluate the approach on the MNIST and CIFAR-10 datasets using a Convolutional Neural Network and a Vision Transformer, respectively.","The results show that our approach is consistent across these data sets and network models, and indicate that the proposed metric can offer an efficient way of determining when automated predictions are acceptable and when they should be deferred to human operators given a distribution shift."],"url":"http://arxiv.org/abs/2407.07821v1"}
{"created":"2024-07-10 16:43:14","title":"The Misclassification Likelihood Matrix: Some Classes Are More Likely To Be Misclassified Than Others","abstract":"This study introduces the Misclassification Likelihood Matrix (MLM) as a novel tool for quantifying the reliability of neural network predictions under distribution shifts. The MLM is obtained by leveraging softmax outputs and clustering techniques to measure the distances between the predictions of a trained neural network and class centroids. By analyzing these distances, the MLM provides a comprehensive view of the model's misclassification tendencies, enabling decision-makers to identify the most common and critical sources of errors. The MLM allows for the prioritization of model improvements and the establishment of decision thresholds based on acceptable risk levels. The approach is evaluated on the MNIST dataset using a Convolutional Neural Network (CNN) and a perturbed version of the dataset to simulate distribution shifts. The results demonstrate the effectiveness of the MLM in assessing the reliability of predictions and highlight its potential in enhancing the interpretability and risk mitigation capabilities of neural networks. The implications of this work extend beyond image classification, with ongoing applications in autonomous systems, such as self-driving cars, to improve the safety and reliability of decision-making in complex, real-world environments.","sentences":["This study introduces the Misclassification Likelihood Matrix (MLM) as a novel tool for quantifying the reliability of neural network predictions under distribution shifts.","The MLM is obtained by leveraging softmax outputs and clustering techniques to measure the distances between the predictions of a trained neural network and class centroids.","By analyzing these distances, the MLM provides a comprehensive view of the model's misclassification tendencies, enabling decision-makers to identify the most common and critical sources of errors.","The MLM allows for the prioritization of model improvements and the establishment of decision thresholds based on acceptable risk levels.","The approach is evaluated on the MNIST dataset using a Convolutional Neural Network (CNN) and a perturbed version of the dataset to simulate distribution shifts.","The results demonstrate the effectiveness of the MLM in assessing the reliability of predictions and highlight its potential in enhancing the interpretability and risk mitigation capabilities of neural networks.","The implications of this work extend beyond image classification, with ongoing applications in autonomous systems, such as self-driving cars, to improve the safety and reliability of decision-making in complex, real-world environments."],"url":"http://arxiv.org/abs/2407.07818v1"}
{"created":"2024-07-10 16:41:19","title":"Daisy: An integrated repeat protein curation service","abstract":"Tandem repeats in proteins identification, classification and curation is a complex process that requires manual processing from experts, processing power and time. There are recent and relevant advances applying machine learning for protein structure prediction and repeat classification that are useful for this process. However, no service contemplates required databases and software to supplement researching on repeat proteins. In this publication we present Daisy, an integrated repeat protein curation web service. This service can process Protein Data Bank (PDB) and the AlphaFold Database entries for tandem repeats identification. In addition, it uses an algorithm to search a sequence against a library of Pfam hidden Markov model (HMM). Repeat classifications are associated with the identified families through RepeatsDB. This prediction is considered for enhancing the ReUPred algorithm execution and hastening the repeat units identification process. The service can also operate every associated PDB and AlphaFold structure with a UniProt proteome registry. Availability: The Daisy web service is freely accessible at daisy.bioinformatica.org.","sentences":["Tandem repeats in proteins identification, classification and curation is a complex process that requires manual processing from experts, processing power and time.","There are recent and relevant advances applying machine learning for protein structure prediction and repeat classification that are useful for this process.","However, no service contemplates required databases and software to supplement researching on repeat proteins.","In this publication we present Daisy, an integrated repeat protein curation web service.","This service can process Protein Data Bank (PDB) and the AlphaFold Database entries for tandem repeats identification.","In addition, it uses an algorithm to search a sequence against a library of Pfam hidden Markov model (HMM).","Repeat classifications are associated with the identified families through RepeatsDB.","This prediction is considered for enhancing the ReUPred algorithm execution and hastening the repeat units identification process.","The service can also operate every associated PDB and AlphaFold structure with a UniProt proteome registry.","Availability: The Daisy web service is freely accessible at daisy.bioinformatica.org."],"url":"http://arxiv.org/abs/2407.07817v1"}
{"created":"2024-07-10 16:40:44","title":"A Survey on Deep Stereo Matching in the Twenties","abstract":"Stereo matching is close to hitting a half-century of history, yet witnessed a rapid evolution in the last decade thanks to deep learning. While previous surveys in the late 2010s covered the first stage of this revolution, the last five years of research brought further ground-breaking advancements to the field. This paper aims to fill this gap in a two-fold manner: first, we offer an in-depth examination of the latest developments in deep stereo matching, focusing on the pioneering architectural designs and groundbreaking paradigms that have redefined the field in the 2020s; second, we present a thorough analysis of the critical challenges that have emerged alongside these advances, providing a comprehensive taxonomy of these issues and exploring the state-of-the-art techniques proposed to address them. By reviewing both the architectural innovations and the key challenges, we offer a holistic view of deep stereo matching and highlight the specific areas that require further investigation. To accompany this survey, we maintain a regularly updated project page that catalogs papers on deep stereo matching in our Awesome-Deep-Stereo-Matching (https://github.com/fabiotosi92/Awesome-Deep-Stereo-Matching) repository.","sentences":["Stereo matching is close to hitting a half-century of history, yet witnessed a rapid evolution in the last decade thanks to deep learning.","While previous surveys in the late 2010s covered the first stage of this revolution, the last five years of research brought further ground-breaking advancements to the field.","This paper aims to fill this gap in a two-fold manner: first, we offer an in-depth examination of the latest developments in deep stereo matching, focusing on the pioneering architectural designs and groundbreaking paradigms that have redefined the field in the 2020s; second, we present a thorough analysis of the critical challenges that have emerged alongside these advances, providing a comprehensive taxonomy of these issues and exploring the state-of-the-art techniques proposed to address them.","By reviewing both the architectural innovations and the key challenges, we offer a holistic view of deep stereo matching and highlight the specific areas that require further investigation.","To accompany this survey, we maintain a regularly updated project page that catalogs papers on deep stereo matching in our Awesome-Deep-Stereo-Matching (https://github.com/fabiotosi92/Awesome-Deep-Stereo-Matching) repository."],"url":"http://arxiv.org/abs/2407.07816v1"}
{"created":"2024-07-10 16:30:27","title":"Transformer Alignment in Large Language Models","abstract":"Large Language Models (LLMs) have made significant strides in natural language processing, and a precise understanding of the internal mechanisms driving their success is essential. We regard LLMs as transforming embeddings via a discrete, coupled, nonlinear, dynamical system in high dimensions. This perspective motivates tracing the trajectories of individual tokens as they pass through transformer blocks, and linearizing the system along these trajectories through their Jacobian matrices. In our analysis of 38 openly available LLMs, we uncover the alignment of top left and right singular vectors of Residual Jacobians, as well as the emergence of linearity and layer-wise exponential growth. Notably, we discover that increased alignment $\\textit{positively correlates}$ with model performance. Metrics evaluated post-training show significant improvement in comparison to measurements made with randomly initialized weights, highlighting the significant effects of training in transformers. These findings reveal a remarkable level of regularity that has previously been overlooked, reinforcing the dynamical interpretation and paving the way for deeper understanding and optimization of LLM architectures.","sentences":["Large Language Models (LLMs) have made significant strides in natural language processing, and a precise understanding of the internal mechanisms driving their success is essential.","We regard LLMs as transforming embeddings via a discrete, coupled, nonlinear, dynamical system in high dimensions.","This perspective motivates tracing the trajectories of individual tokens as they pass through transformer blocks, and linearizing the system along these trajectories through their Jacobian matrices.","In our analysis of 38 openly available LLMs, we uncover the alignment of top left and right singular vectors of Residual Jacobians, as well as the emergence of linearity and layer-wise exponential growth.","Notably, we discover that increased alignment $\\textit{positively correlates}$ with model performance.","Metrics evaluated post-training show significant improvement in comparison to measurements made with randomly initialized weights, highlighting the significant effects of training in transformers.","These findings reveal a remarkable level of regularity that has previously been overlooked, reinforcing the dynamical interpretation and paving the way for deeper understanding and optimization of LLM architectures."],"url":"http://arxiv.org/abs/2407.07810v1"}
{"created":"2024-07-10 16:25:26","title":"SUMix: Mixup with Semantic and Uncertain Information","abstract":"Mixup data augmentation approaches have been applied for various tasks of deep learning to improve the generalization ability of deep neural networks. Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch in one image with patches from another to generate the mixed image. Similarly, the corresponding labels are linearly combined by a fixed ratio $\\lambda$ by l. The objects in two images may be overlapped during the mixing process, so some semantic information is corrupted in the mixed samples. In this case, the mixed image does not match the mixed label information. Besides, such a label may mislead the deep learning model training, which results in poor performance. To solve this problem, we proposed a novel approach named SUMix to learn the mixing ratio as well as the uncertainty for the mixed samples during the training process. First, we design a learnable similarity function to compute an accurate mix ratio. Second, an approach is investigated as a regularized term to model the uncertainty of the mixed samples. We conduct experiments on five image benchmarks, and extensive experimental results imply that our method is capable of improving the performance of classifiers with different cutting-based mixup approaches. The source code is available at https://github.com/JinXins/SUMix.","sentences":["Mixup data augmentation approaches have been applied for various tasks of deep learning to improve the generalization ability of deep neural networks.","Some existing approaches CutMix, SaliencyMix, etc. randomly replace a patch in one image with patches from another to generate the mixed image.","Similarly, the corresponding labels are linearly combined by a fixed ratio $\\lambda$ by l.","The objects in two images may be overlapped during the mixing process, so some semantic information is corrupted in the mixed samples.","In this case, the mixed image does not match the mixed label information.","Besides, such a label may mislead the deep learning model training, which results in poor performance.","To solve this problem, we proposed a novel approach named SUMix to learn the mixing ratio as well as the uncertainty for the mixed samples during the training process.","First, we design a learnable similarity function to compute an accurate mix ratio.","Second, an approach is investigated as a regularized term to model the uncertainty of the mixed samples.","We conduct experiments on five image benchmarks, and extensive experimental results imply that our method is capable of improving the performance of classifiers with different cutting-based mixup approaches.","The source code is available at https://github.com/JinXins/SUMix."],"url":"http://arxiv.org/abs/2407.07805v1"}
{"created":"2024-07-10 16:23:52","title":"Call Graph Soundness in Android Static Analysis","abstract":"Static analysis is sound in theory, but an implementation may unsoundly fail to analyze all of a program's code. Any such omission is a serious threat to the validity of the tool's output. Our work is the first to measure the prevalence of these omissions. Previously, researchers and analysts did not know what is missed by static analysis, what sort of code is missed, or the reasons behind these omissions. To address this gap, we ran 13 static analysis tools and a dynamic analysis on 1000 Android apps. Any method in the dynamic analysis but not in a static analysis is an unsoundness.   Our findings include the following. (1) Apps built around external frameworks challenge static analyzers. On average, the 13 static analysis tools failed to capture 61% of the dynamically-executed methods. (2) A high level of precision in call graph construction is a synonym for a high level of unsoundness; (3) No existing approach significantly improves static analysis soundness. This includes those specifically tailored for a given mechanism, such as DroidRA to address reflection. It also includes systematic approaches, such as EdgeMiner, capturing all callbacks in the Android framework systematically. (4) Modeling entry point methods challenges call graph construction which jeopardizes soundness.","sentences":["Static analysis is sound in theory, but an implementation may unsoundly fail to analyze all of a program's code.","Any such omission is a serious threat to the validity of the tool's output.","Our work is the first to measure the prevalence of these omissions.","Previously, researchers and analysts did not know what is missed by static analysis, what sort of code is missed, or the reasons behind these omissions.","To address this gap, we ran 13 static analysis tools and a dynamic analysis on 1000 Android apps.","Any method in the dynamic analysis but not in a static analysis is an unsoundness.   ","Our findings include the following.","(1) Apps built around external frameworks challenge static analyzers.","On average, the 13 static analysis tools failed to capture 61% of the dynamically-executed methods.","(2) A high level of precision in call graph construction is a synonym for a high level of unsoundness; (3) No existing approach significantly improves static analysis soundness.","This includes those specifically tailored for a given mechanism, such as DroidRA to address reflection.","It also includes systematic approaches, such as EdgeMiner, capturing all callbacks in the Android framework systematically.","(4) Modeling entry point methods challenges call graph construction which jeopardizes soundness."],"url":"http://arxiv.org/abs/2407.07804v1"}
{"created":"2024-07-10 16:20:53","title":"ROSA: Random Subspace Adaptation for Efficient Fine-Tuning","abstract":"Model training requires significantly more memory, compared with inference. Parameter efficient fine-tuning (PEFT) methods provide a means of adapting large models to downstream tasks using less memory. However, existing methods such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce latency overhead at inference time or achieve subpar downstream performance compared with full fine-tuning. In this work we propose Random Subspace Adaptation (ROSA), a method that outperforms previous PEFT methods by a significant margin, while maintaining a zero latency overhead during inference time. In contrast to previous methods, ROSA is able to adapt subspaces of arbitrarily large dimension, better approximating full-finetuning. We demonstrate both theoretically and experimentally that this makes ROSA strictly more expressive than LoRA, without consuming additional memory during runtime. As PEFT methods are especially useful in the natural language processing domain, where models operate on scales that make full fine-tuning very expensive, we evaluate ROSA in two common NLP scenarios: natural language generation (NLG) and natural language understanding (NLU) with GPT-2 and RoBERTa, respectively. We show that on almost every GLUE task ROSA outperforms LoRA by a significant margin, while also outperforming LoRA on NLG tasks. Our code is available at https://github.com/rosa-paper/rosa","sentences":["Model training requires significantly more memory, compared with inference.","Parameter efficient fine-tuning (PEFT) methods provide a means of adapting large models to downstream tasks using less memory.","However, existing methods such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce latency overhead at inference time or achieve subpar downstream performance compared with full fine-tuning.","In this work we propose Random Subspace Adaptation (ROSA), a method that outperforms previous PEFT methods by a significant margin, while maintaining a zero latency overhead during inference time.","In contrast to previous methods, ROSA is able to adapt subspaces of arbitrarily large dimension, better approximating full-finetuning.","We demonstrate both theoretically and experimentally that this makes ROSA strictly more expressive than LoRA, without consuming additional memory during runtime.","As PEFT methods are especially useful in the natural language processing domain, where models operate on scales that make full fine-tuning very expensive, we evaluate ROSA in two common NLP scenarios: natural language generation (NLG) and natural language understanding (NLU) with GPT-2 and RoBERTa, respectively.","We show that on almost every GLUE task ROSA outperforms LoRA by a significant margin, while also outperforming LoRA on NLG tasks.","Our code is available at https://github.com/rosa-paper/rosa"],"url":"http://arxiv.org/abs/2407.07802v1"}
{"created":"2024-07-10 16:16:02","title":"Attribute or Abstain: Large Language Models as Long Document Assistants","abstract":"LLMs can help humans working with long documents, but are known to hallucinate. Attribution can increase trust in LLM responses: The LLM provides evidence that supports its response, which enhances verifiability. Existing approaches to attribution have only been evaluated in RAG settings, where the initial retrieval confounds LLM performance. This is crucially different from the long document setting, where retrieval is not needed, but could help. Thus, a long document specific evaluation of attribution is missing. To fill this gap, we present LAB, a benchmark of 6 diverse long document tasks with attribution, and experiment with different approaches to attribution on 4 LLMs of different sizes, both prompted and fine-tuned. We find that citation, i.e. response generation and evidence extraction in one step, mostly performs best. We investigate whether the ``Lost in the Middle'' phenomenon exists for attribution, but do not find this. We also find that evidence quality can predict response quality on datasets with simple responses, but not so for complex responses, as models struggle with providing evidence for complex claims. We release code and data for further investigation.","sentences":["LLMs can help humans working with long documents, but are known to hallucinate.","Attribution can increase trust in LLM responses: The LLM provides evidence that supports its response, which enhances verifiability.","Existing approaches to attribution have only been evaluated in RAG settings, where the initial retrieval confounds LLM performance.","This is crucially different from the long document setting, where retrieval is not needed, but could help.","Thus, a long document specific evaluation of attribution is missing.","To fill this gap, we present LAB, a benchmark of 6 diverse long document tasks with attribution, and experiment with different approaches to attribution on 4 LLMs of different sizes, both prompted and fine-tuned.","We find that citation, i.e. response generation and evidence extraction in one step, mostly performs best.","We investigate whether the ``Lost in the Middle'' phenomenon exists for attribution, but do not find this.","We also find that evidence quality can predict response quality on datasets with simple responses, but not so for complex responses, as models struggle with providing evidence for complex claims.","We release code and data for further investigation."],"url":"http://arxiv.org/abs/2407.07799v1"}
{"created":"2024-07-10 16:14:34","title":"Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard","abstract":"We introduce a novel and extensible benchmark for large language models (LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku. The open-source game simulation code, available on GitHub, allows LLMs to compete and generates detailed data files in JSON, CSV, TXT, and PNG formats for leaderboard rankings and further analysis. We present the results of games among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and GPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of results from other LLMs. In total, we simulated 2,310 matches (5 sessions for each pair among 7 LLMs and a random player) across three types of games, using three distinct prompt types: list, illustration, and image. The results revealed significant variations in LLM performance across different games and prompt types, with analysis covering win and disqualification rates, missed opportunity analysis, and invalid move analysis. The details of the leaderboard and result matrix data are available as open-access data on GitHub. This study enhances our understanding of LLMs' capabilities in playing games they were not specifically trained for, helping to assess their rule comprehension and strategic thinking. On the path to Artificial General Intelligence (AGI), this study lays the groundwork for future exploration into their utility in complex decision-making scenarios, illuminating their strategic thinking abilities and offering directions for further inquiry into the limits of LLMs within game-based frameworks.","sentences":["We introduce a novel and extensible benchmark for large language models (LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.","The open-source game simulation code, available on GitHub, allows LLMs to compete and generates detailed data files in JSON, CSV, TXT, and PNG formats for leaderboard rankings and further analysis.","We present the results of games among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and GPT-4o by OpenAI, and Llama3-70B by Meta.","We also encourage submissions of results from other LLMs.","In total, we simulated 2,310 matches (5 sessions for each pair among 7 LLMs and a random player) across three types of games, using three distinct prompt types: list, illustration, and image.","The results revealed significant variations in LLM performance across different games and prompt types, with analysis covering win and disqualification rates, missed opportunity analysis, and invalid move analysis.","The details of the leaderboard and result matrix data are available as open-access data on GitHub.","This study enhances our understanding of LLMs' capabilities in playing games they were not specifically trained for, helping to assess their rule comprehension and strategic thinking.","On the path to Artificial General Intelligence (AGI), this study lays the groundwork for future exploration into their utility in complex decision-making scenarios, illuminating their strategic thinking abilities and offering directions for further inquiry into the limits of LLMs within game-based frameworks."],"url":"http://arxiv.org/abs/2407.07796v2"}
{"created":"2024-07-10 16:12:09","title":"Reinforcement Learning of Adaptive Acquisition Policies for Inverse Problems","abstract":"A promising way to mitigate the expensive process of obtaining a high-dimensional signal is to acquire a limited number of low-dimensional measurements and solve an under-determined inverse problem by utilizing the structural prior about the signal. In this paper, we focus on adaptive acquisition schemes to save further the number of measurements. To this end, we propose a reinforcement learning-based approach that sequentially collects measurements to better recover the underlying signal by acquiring fewer measurements. Our approach applies to general inverse problems with continuous action spaces and jointly learns the recovery algorithm. Using insights obtained from theoretical analysis, we also provide a probabilistic design for our methods using variational formulation. We evaluate our approach on multiple datasets and with two measurement spaces (Gaussian, Radon). Our results confirm the benefits of adaptive strategies in low-acquisition horizon settings.","sentences":["A promising way to mitigate the expensive process of obtaining a high-dimensional signal is to acquire a limited number of low-dimensional measurements and solve an under-determined inverse problem by utilizing the structural prior about the signal.","In this paper, we focus on adaptive acquisition schemes to save further the number of measurements.","To this end, we propose a reinforcement learning-based approach that sequentially collects measurements to better recover the underlying signal by acquiring fewer measurements.","Our approach applies to general inverse problems with continuous action spaces and jointly learns the recovery algorithm.","Using insights obtained from theoretical analysis, we also provide a probabilistic design for our methods using variational formulation.","We evaluate our approach on multiple datasets and with two measurement spaces (Gaussian, Radon).","Our results confirm the benefits of adaptive strategies in low-acquisition horizon settings."],"url":"http://arxiv.org/abs/2407.07794v1"}
{"created":"2024-07-10 16:08:46","title":"Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities","abstract":"The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation.   Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.","sentences":["The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation.","However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge.","In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform.","Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation.   ","Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information.","Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication.","Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions.","This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge.","Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools."],"url":"http://arxiv.org/abs/2407.07791v1"}
{"created":"2024-07-10 16:07:51","title":"Systematic Evaluation of Neural Retrieval Models on the Touch\u00e9 2020 Argument Retrieval Subset of BEIR","abstract":"The zero-shot effectiveness of neural retrieval models is often evaluated on the BEIR benchmark -- a combination of different IR evaluation datasets. Interestingly, previous studies found that particularly on the BEIR subset Touch\\'e 2020, an argument retrieval task, neural retrieval models are considerably less effective than BM25. Still, so far, no further investigation has been conducted on what makes argument retrieval so \"special\". To more deeply analyze the respective potential limits of neural retrieval models, we run a reproducibility study on the Touch\\'e 2020 data. In our study, we focus on two experiments: (i) a black-box evaluation (i.e., no model retraining), incorporating a theoretical exploration using retrieval axioms, and (ii) a data denoising evaluation involving post-hoc relevance judgments. Our black-box evaluation reveals an inherent bias of neural models towards retrieving short passages from the Touch\\'e 2020 data, and we also find that quite a few of the neural models' results are unjudged in the Touch\\'e 2020 data. As many of the short Touch\\'e passages are not argumentative and thus non-relevant per se, and as the missing judgments complicate fair comparison, we denoise the Touch\\'e 2020 data by excluding very short passages (less than 20 words) and by augmenting the unjudged data with post-hoc judgments following the Touch\\'e guidelines. On the denoised data, the effectiveness of the neural models improves by up to 0.52 in nDCG@10, but BM25 is still more effective. Our code and the augmented Touch\\'e 2020 dataset are available at \\url{https://github.com/castorini/touche-error-analysis}.","sentences":["The zero-shot effectiveness of neural retrieval models is often evaluated on the BEIR benchmark -- a combination of different IR evaluation datasets.","Interestingly, previous studies found that particularly on the BEIR subset Touch\\'e 2020, an argument retrieval task, neural retrieval models are considerably less effective than BM25.","Still, so far, no further investigation has been conducted on what makes argument retrieval so \"special\".","To more deeply analyze the respective potential limits of neural retrieval models, we run a reproducibility study on the Touch\\'e 2020 data.","In our study, we focus on two experiments: (i) a black-box evaluation (i.e., no model retraining), incorporating a theoretical exploration using retrieval axioms, and (ii) a data denoising evaluation involving post-hoc relevance judgments.","Our black-box evaluation reveals an inherent bias of neural models towards retrieving short passages from the Touch\\'e 2020 data, and we also find that quite a few of the neural models' results are unjudged in the Touch\\'e 2020 data.","As many of the short Touch\\'e passages are not argumentative and thus non-relevant per se, and as the missing judgments complicate fair comparison, we denoise the Touch\\'e 2020 data by excluding very short passages (less than 20 words) and by augmenting the unjudged data with post-hoc judgments following the Touch\\'e guidelines.","On the denoised data, the effectiveness of the neural models improves by up to 0.52 in nDCG@10, but BM25 is still more effective.","Our code and the augmented Touch\\'e 2020 dataset are available at \\url{https://github.com/castorini/touche-error-analysis}."],"url":"http://arxiv.org/abs/2407.07790v1"}
{"created":"2024-07-10 16:06:32","title":"Raising the Ceiling: Conflict-Free Local Feature Matching with Dynamic View Switching","abstract":"Current feature matching methods prioritize improving modeling capabilities to better align outputs with ground-truth matches, which are the theoretical upper bound on matching results, metaphorically depicted as the \"ceiling\". However, these enhancements fail to address the underlying issues that directly hinder ground-truth matches, including the scarcity of matchable points in small scale images, matching conflicts in dense methods, and the keypoint-repeatability reliance in sparse methods. We propose a novel feature matching method named RCM, which Raises the Ceiling of Matching from three aspects. 1) RCM introduces a dynamic view switching mechanism to address the scarcity of matchable points in source images by strategically switching image pairs. 2) RCM proposes a conflict-free coarse matching module, addressing matching conflicts in the target image through a many-to-one matching strategy. 3) By integrating the semi-sparse paradigm and the coarse-to-fine architecture, RCM preserves the benefits of both high efficiency and global search, mitigating the reliance on keypoint repeatability. As a result, RCM enables more matchable points in the source image to be matched in an exhaustive and conflict-free manner in the target image, leading to a substantial 260% increase in ground-truth matches. Comprehensive experiments show that RCM exhibits remarkable performance and efficiency in comparison to state-of-the-art methods.","sentences":["Current feature matching methods prioritize improving modeling capabilities to better align outputs with ground-truth matches, which are the theoretical upper bound on matching results, metaphorically depicted as the \"ceiling\".","However, these enhancements fail to address the underlying issues that directly hinder ground-truth matches, including the scarcity of matchable points in small scale images, matching conflicts in dense methods, and the keypoint-repeatability reliance in sparse methods.","We propose a novel feature matching method named RCM, which Raises the Ceiling of Matching from three aspects.","1) RCM introduces a dynamic view switching mechanism to address the scarcity of matchable points in source images by strategically switching image pairs.","2) RCM proposes a conflict-free coarse matching module, addressing matching conflicts in the target image through a many-to-one matching strategy.","3) By integrating the semi-sparse paradigm and the coarse-to-fine architecture, RCM preserves the benefits of both high efficiency and global search, mitigating the reliance on keypoint repeatability.","As a result, RCM enables more matchable points in the source image to be matched in an exhaustive and conflict-free manner in the target image, leading to a substantial 260% increase in ground-truth matches.","Comprehensive experiments show that RCM exhibits remarkable performance and efficiency in comparison to state-of-the-art methods."],"url":"http://arxiv.org/abs/2407.07789v1"}
{"created":"2024-07-10 16:04:18","title":"BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark","abstract":"We introduce BiGym, a new benchmark and learning environment for mobile bi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks set in home environments, ranging from simple target reaching to complex kitchen cleaning. To capture the real-world performance accurately, we provide human-collected demonstrations for each task, reflecting the diverse modalities found in real-world robot trajectories. BiGym supports a variety of observations, including proprioceptive data and visual inputs such as RGB, and depth from 3 camera views. To validate the usability of BiGym, we thoroughly benchmark the state-of-the-art imitation learning algorithms and demo-driven reinforcement learning algorithms within the environment and discuss the future opportunities.","sentences":["We introduce BiGym, a new benchmark and learning environment for mobile bi-manual demo-driven robotic manipulation.","BiGym features 40 diverse tasks set in home environments, ranging from simple target reaching to complex kitchen cleaning.","To capture the real-world performance accurately, we provide human-collected demonstrations for each task, reflecting the diverse modalities found in real-world robot trajectories.","BiGym supports a variety of observations, including proprioceptive data and visual inputs such as RGB, and depth from 3 camera views.","To validate the usability of BiGym, we thoroughly benchmark the state-of-the-art imitation learning algorithms and demo-driven reinforcement learning algorithms within the environment and discuss the future opportunities."],"url":"http://arxiv.org/abs/2407.07788v2"}
{"created":"2024-07-10 16:04:08","title":"Continuous Control with Coarse-to-fine Reinforcement Learning","abstract":"Despite recent advances in improving the sample-efficiency of reinforcement learning (RL) algorithms, designing an RL algorithm that can be practically deployed in real-world environments remains a challenge. In this paper, we present Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RL agents to zoom-into a continuous action space in a coarse-to-fine manner, enabling the use of stable, sample-efficient value-based RL algorithms for fine-grained continuous control tasks. Our key idea is to train agents that output actions by iterating the procedure of (i) discretizing the continuous action space into multiple intervals and (ii) selecting the interval with the highest Q-value to further discretize at the next level. We then introduce a concrete, value-based algorithm within the CRL framework called Coarse-to-fine Q-Network (CQN). Our experiments demonstrate that CQN significantly outperforms RL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulation tasks with a modest number of environment interactions and expert demonstrations. We also show that CQN robustly learns to solve real-world manipulation tasks within a few minutes of online training.","sentences":["Despite recent advances in improving the sample-efficiency of reinforcement learning (RL) algorithms, designing an RL algorithm that can be practically deployed in real-world environments remains a challenge.","In this paper, we present Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RL agents to zoom-into a continuous action space in a coarse-to-fine manner, enabling the use of stable, sample-efficient value-based RL algorithms for fine-grained continuous control tasks.","Our key idea is to train agents that output actions by iterating the procedure of (i) discretizing the continuous action space into multiple intervals and (ii) selecting the interval with the highest Q-value to further discretize at the next level.","We then introduce a concrete, value-based algorithm within the CRL framework called Coarse-to-fine Q-Network (CQN).","Our experiments demonstrate that CQN significantly outperforms RL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulation tasks with a modest number of environment interactions and expert demonstrations.","We also show that CQN robustly learns to solve real-world manipulation tasks within a few minutes of online training."],"url":"http://arxiv.org/abs/2407.07787v1"}
{"created":"2024-07-10 16:02:13","title":"The Human Factor in AI Red Teaming: Perspectives from Social and Collaborative Computing","abstract":"Rapid progress in general-purpose AI has sparked significant interest in \"red teaming,\" a practice of adversarial testing originating in military and cybersecurity applications. AI red teaming raises many questions about the human factor, such as how red teamers are selected, biases and blindspots in how tests are conducted, and harmful content's psychological effects on red teamers. A growing body of HCI and CSCW literature examines related practices-including data labeling, content moderation, and algorithmic auditing. However, few, if any, have investigated red teaming itself. This workshop seeks to consider the conceptual and empirical challenges associated with this practice, often rendered opaque by non-disclosure agreements. Future studies may explore topics ranging from fairness to mental health and other areas of potential harm. We aim to facilitate a community of researchers and practitioners who can begin to meet these challenges with creativity, innovation, and thoughtful reflection.","sentences":["Rapid progress in general-purpose AI has sparked significant interest in \"red teaming,\" a practice of adversarial testing originating in military and cybersecurity applications.","AI red teaming raises many questions about the human factor, such as how red teamers are selected, biases and blindspots in how tests are conducted, and harmful content's psychological effects on red teamers.","A growing body of HCI and CSCW literature examines related practices-including data labeling, content moderation, and algorithmic auditing.","However, few, if any, have investigated red teaming itself.","This workshop seeks to consider the conceptual and empirical challenges associated with this practice, often rendered opaque by non-disclosure agreements.","Future studies may explore topics ranging from fairness to mental health and other areas of potential harm.","We aim to facilitate a community of researchers and practitioners who can begin to meet these challenges with creativity, innovation, and thoughtful reflection."],"url":"http://arxiv.org/abs/2407.07786v1"}
{"created":"2024-07-10 16:00:21","title":"Edge-dominance games on graphs","abstract":"We consider zero-sum games in which players move between adjacent states, where in each pair of adjacent states one state dominates the other. The states in our game can represent positional advantages in physical conflict such as high ground or camouflage, or product characteristics that lend an advantage over competing sellers in a duopoly. We study the equilibria of the game as a function of the topological and geometric properties of the underlying graph. Our main result characterizes the expected payoff of both players starting from any initial position, under the assumption that the graph does not contain certain types of small cycles. This characterization leverages the block-cut tree of the graph, a construction that describes the topology of the biconnected components of the graph. We identify three natural types of (on-path) pure equilibria, and characterize when these equilibria exist under the above assumptions. On the geometric side, we show that strongly connected outerplanar graphs with undirected girth at least 4 always support some of these types of on-path pure equilibria. Finally, we show that a data structure describing all pure equilibria can be efficiently computed for these games.","sentences":["We consider zero-sum games in which players move between adjacent states, where in each pair of adjacent states one state dominates the other.","The states in our game can represent positional advantages in physical conflict such as high ground or camouflage, or product characteristics that lend an advantage over competing sellers in a duopoly.","We study the equilibria of the game as a function of the topological and geometric properties of the underlying graph.","Our main result characterizes the expected payoff of both players starting from any initial position, under the assumption that the graph does not contain certain types of small cycles.","This characterization leverages the block-cut tree of the graph, a construction that describes the topology of the biconnected components of the graph.","We identify three natural types of (on-path) pure equilibria, and characterize when these equilibria exist under the above assumptions.","On the geometric side, we show that strongly connected outerplanar graphs with undirected girth at least 4 always support some of these types of on-path pure equilibria.","Finally, we show that a data structure describing all pure equilibria can be efficiently computed for these games."],"url":"http://arxiv.org/abs/2407.07785v1"}
{"created":"2024-07-10 15:56:24","title":"Cross Domain Object Detection via Multi-Granularity Confidence Alignment based Mean Teacher","abstract":"Cross domain object detection learns an object detector for an unlabeled target domain by transferring knowledge from an annotated source domain. Promising results have been achieved via Mean Teacher, however, pseudo labeling which is the bottleneck of mutual learning remains to be further explored. In this study, we find that confidence misalignment of the predictions, including category-level overconfidence, instance-level task confidence inconsistency, and image-level confidence misfocusing, leading to the injection of noisy pseudo label in the training process, will bring suboptimal performance on the target domain. To tackle this issue, we present a novel general framework termed Multi-Granularity Confidence Alignment Mean Teacher (MGCAMT) for cross domain object detection, which alleviates confidence misalignment across category-, instance-, and image-levels simultaneously to obtain high quality pseudo supervision for better teacher-student learning. Specifically, to align confidence with accuracy at category level, we propose Classification Confidence Alignment (CCA) to model category uncertainty based on Evidential Deep Learning (EDL) and filter out the category incorrect labels via an uncertainty-aware selection strategy. Furthermore, to mitigate the instance-level misalignment between classification and localization, we design Task Confidence Alignment (TCA) to enhance the interaction between the two task branches and allow each classification feature to adaptively locate the optimal feature for the regression. Finally, we develop imagery Focusing Confidence Alignment (FCA) adopting another way of pseudo label learning, i.e., we use the original outputs from the Mean Teacher network for supervised learning without label assignment to concentrate on holistic information in the target image. These three procedures benefit from each other from a cooperative learning perspective.","sentences":["Cross domain object detection learns an object detector for an unlabeled target domain by transferring knowledge from an annotated source domain.","Promising results have been achieved via Mean Teacher, however, pseudo labeling which is the bottleneck of mutual learning remains to be further explored.","In this study, we find that confidence misalignment of the predictions, including category-level overconfidence, instance-level task confidence inconsistency, and image-level confidence misfocusing, leading to the injection of noisy pseudo label in the training process, will bring suboptimal performance on the target domain.","To tackle this issue, we present a novel general framework termed Multi-Granularity Confidence Alignment Mean Teacher (MGCAMT) for cross domain object detection, which alleviates confidence misalignment across category-, instance-, and image-levels simultaneously to obtain high quality pseudo supervision for better teacher-student learning.","Specifically, to align confidence with accuracy at category level, we propose Classification Confidence Alignment (CCA) to model category uncertainty based on Evidential Deep Learning (EDL) and filter out the category incorrect labels via an uncertainty-aware selection strategy.","Furthermore, to mitigate the instance-level misalignment between classification and localization, we design Task Confidence Alignment (TCA) to enhance the interaction between the two task branches and allow each classification feature to adaptively locate the optimal feature for the regression.","Finally, we develop imagery Focusing Confidence Alignment (FCA) adopting another way of pseudo label learning, i.e., we use the original outputs from the Mean Teacher network for supervised learning without label assignment to concentrate on holistic information in the target image.","These three procedures benefit from each other from a cooperative learning perspective."],"url":"http://arxiv.org/abs/2407.07780v1"}
{"created":"2024-07-10 15:52:44","title":"WorldAPIs: The World Is Worth How Many APIs? A Thought Experiment","abstract":"AI systems make decisions in physical environments through primitive actions or affordances that are accessed via API calls. While deploying AI agents in the real world involves numerous high-level actions, existing embodied simulators offer a limited set of domain-salient APIs. This naturally brings up the questions: how many primitive actions (APIs) are needed for a versatile embodied agent, and what should they look like? We explore this via a thought experiment: assuming that wikiHow tutorials cover a wide variety of human-written tasks, what is the space of APIs needed to cover these instructions? We propose a framework to iteratively induce new APIs by grounding wikiHow instruction to situated agent policies. Inspired by recent successes in large language models (LLMs) for embodied planning, we propose a few-shot prompting to steer GPT-4 to generate Pythonic programs as agent policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and then 2) fabricate new API calls when necessary. The focus of this thought experiment is on defining these APIs rather than their executability. We apply the proposed pipeline on instructions from wikiHow tutorials. On a small fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary for capturing the rich variety of tasks in the physical world. A detailed automatic and human analysis of the induction output reveals that the proposed pipeline enables effective reuse and creation of APIs. Moreover, a manual review revealed that existing simulators support only a small subset of the induced APIs (9 of the top 50 frequent APIs), motivating the development of action-rich embodied environments.","sentences":["AI systems make decisions in physical environments through primitive actions or affordances that are accessed via API calls.","While deploying AI agents in the real world involves numerous high-level actions, existing embodied simulators offer a limited set of domain-salient APIs.","This naturally brings up the questions: how many primitive actions (APIs) are needed for a versatile embodied agent, and what should they look like?","We explore this via a thought experiment: assuming that wikiHow tutorials cover a wide variety of human-written tasks, what is the space of APIs needed to cover these instructions?","We propose a framework to iteratively induce new APIs by grounding wikiHow instruction to situated agent policies.","Inspired by recent successes in large language models (LLMs) for embodied planning, we propose a few-shot prompting to steer GPT-4 to generate Pythonic programs as agent policies and bootstrap a universe of APIs by 1) reusing a seed set of APIs; and then 2) fabricate new API calls when necessary.","The focus of this thought experiment is on defining these APIs rather than their executability.","We apply the proposed pipeline on instructions from wikiHow tutorials.","On a small fraction (0.5%) of tutorials, we induce an action space of 300+ APIs necessary for capturing the rich variety of tasks in the physical world.","A detailed automatic and human analysis of the induction output reveals that the proposed pipeline enables effective reuse and creation of APIs.","Moreover, a manual review revealed that existing simulators support only a small subset of the induced APIs (9 of the top 50 frequent APIs), motivating the development of action-rich embodied environments."],"url":"http://arxiv.org/abs/2407.07778v1"}
{"created":"2024-07-10 15:49:07","title":"Mobility VLA: Multimodal Instruction Navigation with Long-Context VLMs and Topological Graphs","abstract":"An elusive goal in navigation research is to build an intelligent agent that can understand multimodal instructions including natural language and image, and perform useful navigation. To achieve this, we study a widely useful category of navigation tasks we call Multimodal Instruction Navigation with demonstration Tours (MINT), in which the environment prior is provided through a previously recorded demonstration video. Recent advances in Vision Language Models (VLMs) have shown a promising path in achieving this goal as it demonstrates capabilities in perceiving and reasoning about multimodal inputs. However, VLMs are typically trained to predict textual output and it is an open research question about how to best utilize them in navigation. To solve MINT, we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation policy that combines the environment understanding and common sense reasoning power of long-context VLMs and a robust low-level navigation policy based on topological graphs. The high-level policy consists of a long-context VLM that takes the demonstration tour video and the multimodal user instruction as input to find the goal frame in the tour video. Next, a low-level policy uses the goal frame and an offline constructed topological graph to generate robot actions at every timestep. We evaluated Mobility VLA in a 836m^2 real world environment and show that Mobility VLA has a high end-to-end success rates on previously unsolved multimodal instructions such as \"Where should I return this?\" while holding a plastic bin.","sentences":["An elusive goal in navigation research is to build an intelligent agent that can understand multimodal instructions including natural language and image, and perform useful navigation.","To achieve this, we study a widely useful category of navigation tasks we call Multimodal Instruction Navigation with demonstration Tours (MINT), in which the environment prior is provided through a previously recorded demonstration video.","Recent advances in Vision Language Models (VLMs) have shown a promising path in achieving this goal as it demonstrates capabilities in perceiving and reasoning about multimodal inputs.","However, VLMs are typically trained to predict textual output and it is an open research question about how to best utilize them in navigation.","To solve MINT, we present Mobility VLA, a hierarchical Vision-Language-Action (VLA) navigation policy that combines the environment understanding and common sense reasoning power of long-context VLMs and a robust low-level navigation policy based on topological graphs.","The high-level policy consists of a long-context VLM that takes the demonstration tour video and the multimodal user instruction as input to find the goal frame in the tour video.","Next, a low-level policy uses the goal frame and an offline constructed topological graph to generate robot actions at every timestep.","We evaluated Mobility VLA in a 836m^2 real world environment and show that Mobility VLA has a high end-to-end success rates on previously unsolved multimodal instructions such as \"Where should I return this?\" while holding a plastic bin."],"url":"http://arxiv.org/abs/2407.07775v1"}
{"created":"2024-07-10 15:47:33","title":"Finite Blocklength Performance of Capacity-achieving Codes in the Light of Complexity Theory","abstract":"Since the work of Polyanskiy, Poor and Verd\\'u on the finite blocklength performance of capacity-achieving codes for discrete memoryless channels, many papers have attempted to find further results for more practically relevant channels. However, it seems that the complexity of computing capacity-achieving codes has not been investigated until now. We study this question for the simplest non-trivial Gaussian channels, i.e., the additive colored Gaussian noise channel. To assess the computational complexity, we consider the classes $\\mathrm{FP}_1$ and $\\#\\mathrm{P}_1$. $\\mathrm{FP}_1$ includes functions computable by a deterministic Turing machine in polynomial time, whereas $\\#\\mathrm{P}_1$ encompasses functions that count the number of solutions verifiable in polynomial time. It is widely assumed that $\\mathrm{FP}_1\\neq\\#\\mathrm{P}_1$. It is of interest to determine the conditions under which, for a given $M \\in \\mathbb{N}$, where $M$ describes the precision of the deviation of $C(P,N)$, for a certain blocklength $n_M$ and a decoding error $\\epsilon > 0$ with $\\epsilon\\in\\mathbb{Q}$, the following holds: $R_{n_M}(\\epsilon)>C(P,N)-\\frac{1}{2^M}$. It is shown that there is a polynomial-time computable $N_*$ such that for sufficiently large $P_*\\in\\mathbb{Q}$, the sequences $\\{R_{n_M}(\\epsilon)\\}_{{n_M}\\in\\mathbb{N}}$, where each $R_{n_M}(\\epsilon)$ satisfies the previous condition, cannot be computed in polynomial time if $\\mathrm{FP}_1\\neq\\#\\mathrm{P}_1$. Hence, the complexity of computing the sequence $\\{R_{n_M}(\\epsilon)\\}_{n_M\\in\\mathbb{N}}$ grows faster than any polynomial as $M$ increases. Consequently, it is shown that either the sequence of achievable rates $\\{R_{n_M}(\\epsilon)\\}_{n_M\\in\\mathbb{N}}$ as a function of the blocklength, or the sequence of blocklengths $\\{n_M\\}_{M\\in\\mathbb{N}}$ corresponding to the achievable rates, is not a polynomial-time computable sequence.","sentences":["Since the work of Polyanskiy, Poor and Verd\\'u on the finite blocklength performance of capacity-achieving codes for discrete memoryless channels, many papers have attempted to find further results for more practically relevant channels.","However, it seems that the complexity of computing capacity-achieving codes has not been investigated until now.","We study this question for the simplest non-trivial Gaussian channels, i.e., the additive colored Gaussian noise channel.","To assess the computational complexity, we consider the classes $\\mathrm{FP}_1$ and $\\#\\mathrm{P}_1$. $\\mathrm{FP}_1$ includes functions computable by a deterministic Turing machine in polynomial time, whereas $\\#\\mathrm{P}_1$ encompasses functions that count the number of solutions verifiable in polynomial time.","It is widely assumed that $\\mathrm{FP}_1\\neq\\#\\mathrm{P}_1$. It is of interest to determine the conditions under which, for a given $M \\in \\mathbb{N}$, where $M$ describes the precision of the deviation of $C(P,N)$, for a certain blocklength $n_M$ and a decoding error $\\epsilon > 0$ with $\\epsilon\\in\\mathbb{Q}$, the following holds: $R_{n_M}(\\epsilon)>C(P,N)-\\frac{1}{2^M}$.","It is shown that there is a polynomial-time computable $N_*$ such that for sufficiently large $P_*\\in\\mathbb{Q}$, the sequences $\\{R_{n_M}(\\epsilon)\\}_{{n_M}\\in\\mathbb{N}}$, where each $R_{n_M}(\\epsilon)$ satisfies the previous condition, cannot be computed in polynomial time if $\\mathrm{FP}_1\\neq\\#\\mathrm{P}_1$. Hence, the complexity of computing the sequence $\\{R_{n_M}(\\epsilon)\\}_{n_M\\in\\mathbb{N}}$ grows faster than any polynomial as $M$ increases.","Consequently, it is shown that either the sequence of achievable rates $\\{R_{n_M}(\\epsilon)\\}_{n_M\\in\\mathbb{N}}$ as a function of the blocklength, or the sequence of blocklengths $\\{n_M\\}_{M\\in\\mathbb{N}}$ corresponding to the achievable rates, is not a polynomial-time computable sequence."],"url":"http://arxiv.org/abs/2407.07773v1"}
{"created":"2024-07-10 15:46:32","title":"Multi-task Prompt Words Learning for Social Media Content Generation","abstract":"The rapid development of the Internet has profoundly changed human life. Humans are increasingly expressing themselves and interacting with others on social media platforms. However, although artificial intelligence technology has been widely used in many aspects of life, its application in social media content creation is still blank. To solve this problem, we propose a new prompt word generation framework based on multi-modal information fusion, which combines multiple tasks including topic classification, sentiment analysis, scene recognition and keyword extraction to generate more comprehensive prompt words. Subsequently, we use a template containing a set of prompt words to guide ChatGPT to generate high-quality tweets. Furthermore, in the absence of effective and objective evaluation criteria in the field of content generation, we use the ChatGPT tool to evaluate the results generated by the algorithm, making large-scale evaluation of content generation algorithms possible. Evaluation results on extensive content generation demonstrate that our cue word generation framework generates higher quality content compared to manual methods and other cueing techniques, while topic classification, sentiment analysis, and scene recognition significantly enhance content clarity and its consistency with the image.","sentences":["The rapid development of the Internet has profoundly changed human life.","Humans are increasingly expressing themselves and interacting with others on social media platforms.","However, although artificial intelligence technology has been widely used in many aspects of life, its application in social media content creation is still blank.","To solve this problem, we propose a new prompt word generation framework based on multi-modal information fusion, which combines multiple tasks including topic classification, sentiment analysis, scene recognition and keyword extraction to generate more comprehensive prompt words.","Subsequently, we use a template containing a set of prompt words to guide ChatGPT to generate high-quality tweets.","Furthermore, in the absence of effective and objective evaluation criteria in the field of content generation, we use the ChatGPT tool to evaluate the results generated by the algorithm, making large-scale evaluation of content generation algorithms possible.","Evaluation results on extensive content generation demonstrate that our cue word generation framework generates higher quality content compared to manual methods and other cueing techniques, while topic classification, sentiment analysis, and scene recognition significantly enhance content clarity and its consistency with the image."],"url":"http://arxiv.org/abs/2407.07771v1"}
{"created":"2024-07-10 15:43:45","title":"An investigation of the Online Payment and Banking System Apps in Bangladesh","abstract":"Presently, Bangladesh is expending substantial efforts to digitize its national infrastructure, with a significant emphasis on achieving this goal through mobile applications that facilitate online payments and banking system advancements. Despite the lack of knowledge about the security level of these systems, they are currently in frequent use without much consideration. To observe whether they follow the minimum global set standards, we choose to conduct static and dynamic analysis of the applications using available open-source analyzers and open-source tools. This allows us to attempt to extract sensitive information, if possible, and determine whether the applications adhere to the standards of MASVS set by OWASP. We show how we analyzed 17 .apks and a SDK using open source scanner and discover security flaws to the applications, such as weaknesses related to data storage, vulnerable cryptographic elements, insecure network communications, and unsafe utilization of WebViews, detected by the scanner. These outputs demonstrate the need for extensive manual analysis of the application through source code review and dynamic analysis. We further implement reverse engineering and dynamic approach to verify the outputs and expose some applications do not comply with the standard method of network communication. Moreover, we attempt to verify the rest of the potential vulnerabilities in the next phase of our ongoing investigation.","sentences":["Presently, Bangladesh is expending substantial efforts to digitize its national infrastructure, with a significant emphasis on achieving this goal through mobile applications that facilitate online payments and banking system advancements.","Despite the lack of knowledge about the security level of these systems, they are currently in frequent use without much consideration.","To observe whether they follow the minimum global set standards, we choose to conduct static and dynamic analysis of the applications using available open-source analyzers and open-source tools.","This allows us to attempt to extract sensitive information, if possible, and determine whether the applications adhere to the standards of MASVS set by OWASP.","We show how we analyzed 17 .apks and a SDK using open source scanner and discover security flaws to the applications, such as weaknesses related to data storage, vulnerable cryptographic elements, insecure network communications, and unsafe utilization of WebViews, detected by the scanner.","These outputs demonstrate the need for extensive manual analysis of the application through source code review and dynamic analysis.","We further implement reverse engineering and dynamic approach to verify the outputs and expose some applications do not comply with the standard method of network communication.","Moreover, we attempt to verify the rest of the potential vulnerabilities in the next phase of our ongoing investigation."],"url":"http://arxiv.org/abs/2407.07766v1"}
{"created":"2024-07-10 15:43:30","title":"Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem","abstract":"This work continues to investigate the link between differentially private (DP) and online learning. Alon, Livni, Malliaris, and Moran (2019) showed that for binary concept classes, DP learnability of a given class implies that it has a finite Littlestone dimension (equivalently, that it is online learnable). Their proof relies on a model-theoretic result by Hodges (1997), which demonstrates that any binary concept class with a large Littlestone dimension contains a large subclass of thresholds. In a follow-up work, Jung, Kim, and Tewari (2020) extended this proof to multiclass PAC learning with a bounded number of labels. Unfortunately, Hodges's result does not apply in other natural settings such as multiclass PAC learning with an unbounded label space, and PAC learning of partial concept classes.   This naturally raises the question of whether DP learnability continues to imply online learnability in more general scenarios: indeed, Alon, Hanneke, Holzman, and Moran (2021) explicitly leave it as an open question in the context of partial concept classes, and the same question is open in the general multiclass setting. In this work, we give a positive answer to these questions showing that for general classification tasks, DP learnability implies online learnability. Our proof reasons directly about Littlestone trees, without relying on thresholds. We achieve this by establishing several Ramsey-type theorems for trees, which might be of independent interest.","sentences":["This work continues to investigate the link between differentially private (DP) and online learning.","Alon, Livni, Malliaris, and Moran (2019) showed that for binary concept classes, DP learnability of a given class implies that it has a finite Littlestone dimension (equivalently, that it is online learnable).","Their proof relies on a model-theoretic result by Hodges (1997), which demonstrates that any binary concept class with a large Littlestone dimension contains a large subclass of thresholds.","In a follow-up work, Jung, Kim, and Tewari (2020) extended this proof to multiclass PAC learning with a bounded number of labels.","Unfortunately, Hodges's result does not apply in other natural settings such as multiclass PAC learning with an unbounded label space, and PAC learning of partial concept classes.   ","This naturally raises the question of whether DP learnability continues to imply online learnability in more general scenarios: indeed, Alon, Hanneke, Holzman, and Moran (2021) explicitly leave it as an open question in the context of partial concept classes, and the same question is open in the general multiclass setting.","In this work, we give a positive answer to these questions showing that for general classification tasks, DP learnability implies online learnability.","Our proof reasons directly about Littlestone trees, without relying on thresholds.","We achieve this by establishing several Ramsey-type theorems for trees, which might be of independent interest."],"url":"http://arxiv.org/abs/2407.07765v1"}
{"created":"2024-07-10 15:42:58","title":"PosFormer: Recognizing Complex Handwritten Mathematical Expression with Position Forest Transformer","abstract":"Handwritten Mathematical Expression Recognition (HMER) has wide applications in human-machine interaction scenarios, such as digitized education and automated offices. Recently, sequence-based models with encoder-decoder architectures have been commonly adopted to address this task by directly predicting LaTeX sequences of expression images. However, these methods only implicitly learn the syntax rules provided by LaTeX, which may fail to describe the position and hierarchical relationship between symbols due to complex structural relations and diverse handwriting styles. To overcome this challenge, we propose a position forest transformer (PosFormer) for HMER, which jointly optimizes two tasks: expression recognition and position recognition, to explicitly enable position-aware symbol feature representation learning. Specifically, we first design a position forest that models the mathematical expression as a forest structure and parses the relative position relationships between symbols. Without requiring extra annotations, each symbol is assigned a position identifier in the forest to denote its relative spatial position. Second, we propose an implicit attention correction module to accurately capture attention for HMER in the sequence-based decoder architecture. Extensive experiments validate the superiority of PosFormer, which consistently outperforms the state-of-the-art methods 2.03%/1.22%/2.00%, 1.83%, and 4.62% gains on the single-line CROHME 2014/2016/2019, multi-line M2E, and complex MNE datasets, respectively, with no additional latency or computational cost. Code is available at https://github.com/SJTU-DeepVisionLab/PosFormer.","sentences":["Handwritten Mathematical Expression Recognition (HMER) has wide applications in human-machine interaction scenarios, such as digitized education and automated offices.","Recently, sequence-based models with encoder-decoder architectures have been commonly adopted to address this task by directly predicting LaTeX sequences of expression images.","However, these methods only implicitly learn the syntax rules provided by LaTeX, which may fail to describe the position and hierarchical relationship between symbols due to complex structural relations and diverse handwriting styles.","To overcome this challenge, we propose a position forest transformer (PosFormer) for HMER, which jointly optimizes two tasks: expression recognition and position recognition, to explicitly enable position-aware symbol feature representation learning.","Specifically, we first design a position forest that models the mathematical expression as a forest structure and parses the relative position relationships between symbols.","Without requiring extra annotations, each symbol is assigned a position identifier in the forest to denote its relative spatial position.","Second, we propose an implicit attention correction module to accurately capture attention for HMER in the sequence-based decoder architecture.","Extensive experiments validate the superiority of PosFormer, which consistently outperforms the state-of-the-art methods 2.03%/1.22%/2.00%, 1.83%, and 4.62% gains on the single-line CROHME 2014/2016/2019, multi-line M2E, and complex MNE datasets, respectively, with no additional latency or computational cost.","Code is available at https://github.com/SJTU-DeepVisionLab/PosFormer."],"url":"http://arxiv.org/abs/2407.07764v1"}
{"created":"2024-07-10 15:39:47","title":"S&D Messenger: Exchanging Semantic and Domain Knowledge for Generic Semi-Supervised Medical Image Segmentation","abstract":"Semi-supervised medical image segmentation (SSMIS) has emerged as a promising solution to tackle the challenges of time-consuming manual labeling in the medical field. However, in practical scenarios, there are often domain variations within the datasets, leading to derivative scenarios like semi-supervised medical domain generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA). In this paper, we aim to develop a generic framework that masters all three tasks. We notice a critical shared challenge across three scenarios: the explicit semantic knowledge for segmentation performance and rich domain knowledge for generalizability exclusively exist in the labeled set and unlabeled set respectively. Such discrepancy hinders existing methods from effectively comprehending both types of knowledge under semi-supervised settings. To tackle this challenge, we develop a Semantic & Domain Knowledge Messenger (S&D Messenger) which facilitates direct knowledge delivery between the labeled and unlabeled set, and thus allowing the model to comprehend both of them in each individual learning flow. Equipped with our S&D Messenger, a naive pseudo-labeling method can achieve huge improvement on six benchmark datasets for SSMIS (+7.5%), UMDA (+5.6%), and Semi-MDG tasks (+1.14%), compared with state-of-the-art methods designed for specific tasks.","sentences":["Semi-supervised medical image segmentation (SSMIS) has emerged as a promising solution to tackle the challenges of time-consuming manual labeling in the medical field.","However, in practical scenarios, there are often domain variations within the datasets, leading to derivative scenarios like semi-supervised medical domain generalization (Semi-MDG) and unsupervised medical domain adaptation (UMDA).","In this paper, we aim to develop a generic framework that masters all three tasks.","We notice a critical shared challenge across three scenarios: the explicit semantic knowledge for segmentation performance and rich domain knowledge for generalizability exclusively exist in the labeled set and unlabeled set respectively.","Such discrepancy hinders existing methods from effectively comprehending both types of knowledge under semi-supervised settings.","To tackle this challenge, we develop a Semantic & Domain Knowledge Messenger (S&D Messenger) which facilitates direct knowledge delivery between the labeled and unlabeled set, and thus allowing the model to comprehend both of them in each individual learning flow.","Equipped with our S&D Messenger, a naive pseudo-labeling method can achieve huge improvement on six benchmark datasets for SSMIS (+7.5%), UMDA (+5.6%), and Semi-MDG tasks (+1.14%), compared with state-of-the-art methods designed for specific tasks."],"url":"http://arxiv.org/abs/2407.07763v1"}
{"created":"2024-07-10 15:39:45","title":"Learning and Motivational Impact of Game-Based Learning: Comparing Face-to-Face and Online Formats on Computer Science Education","abstract":"Contribution: This article analyzes the learning and motivational impact of teacher-authored educational video games on computer science education and compares its effectiveness in both face-to-face and online (remote) formats. This work presents comparative data and findings obtained from 217 students who played the game in a face-to-face format (control group) and 104 students who played the game in an online format (experimental group). Background: Serious video games have been proven effective at computer science education, however, it is still unknown whether the effectiveness of these games is the same regardless of their format, face-to-face or online. Moreover, the usage of games created through authoring tools has barely been explored. Research Questions: Are teacher-authored educational video games effective in terms of learning and motivation for computer science students? Does the effectiveness of teacher-authored educational video games depend on whether they are used in a face-to-face or online format? Methodology: A quasi-experiment has been conducted by using three instruments (pre-test, post-test, and questionnaire) with the purpose of comparing the effectiveness of game-based learning in face-to-face and online formats. A total of 321 computer science students played a teacher-authored educational video game aimed to learn about software design. Findings: The results reveal that teacher-authored educational video games are highly effective in terms of knowledge acquisition and motivation both in face-to-face and online formats. The results also show that some students' perceptions were more positive when a face-to-face format was used.","sentences":["Contribution:","This article analyzes the learning and motivational impact of teacher-authored educational video games on computer science education and compares its effectiveness in both face-to-face and online (remote) formats.","This work presents comparative data and findings obtained from 217 students who played the game in a face-to-face format (control group) and 104 students who played the game in an online format (experimental group).","Background: Serious video games have been proven effective at computer science education, however, it is still unknown whether the effectiveness of these games is the same regardless of their format, face-to-face or online.","Moreover, the usage of games created through authoring tools has barely been explored.","Research Questions: Are teacher-authored educational video games effective in terms of learning and motivation for computer science students?","Does the effectiveness of teacher-authored educational video games depend on whether they are used in a face-to-face or online format?","Methodology: A quasi-experiment has been conducted by using three instruments (pre-test, post-test, and questionnaire) with the purpose of comparing the effectiveness of game-based learning in face-to-face and online formats.","A total of 321 computer science students played a teacher-authored educational video game aimed to learn about software design.","Findings:","The results reveal that teacher-authored educational video games are highly effective in terms of knowledge acquisition and motivation both in face-to-face and online formats.","The results also show that some students' perceptions were more positive when a face-to-face format was used."],"url":"http://arxiv.org/abs/2407.07762v1"}
{"created":"2024-07-10 15:36:00","title":"Learning Spatial-Semantic Features for Robust Video Object Segmentation","abstract":"Tracking and segmenting multiple similar objects with complex or separate parts in long-term videos is inherently challenging due to the ambiguity of target parts and identity confusion caused by occlusion, background clutter, and long-term variations. In this paper, we propose a robust video object segmentation framework equipped with spatial-semantic features and discriminative object queries to address the above issues. Specifically, we construct a spatial-semantic network comprising a semantic embedding block and spatial dependencies modeling block to associate the pretrained ViT features with global semantic features and local spatial features, providing a comprehensive target representation. In addition, we develop a masked cross-attention module to generate object queries that focus on the most discriminative parts of target objects during query propagation, alleviating noise accumulation and ensuring effective long-term query propagation. The experimental results show that the proposed method set a new state-of-the-art performance on multiple datasets, including the DAVIS2017 test (89.1%), YoutubeVOS 2019 (88.5%), MOSE (75.1%), LVOS test (73.0%), and LVOS val (75.1%), which demonstrate the effectiveness and generalization capacity of the proposed method. We will make all source code and trained models publicly available.","sentences":["Tracking and segmenting multiple similar objects with complex or separate parts in long-term videos is inherently challenging due to the ambiguity of target parts and identity confusion caused by occlusion, background clutter, and long-term variations.","In this paper, we propose a robust video object segmentation framework equipped with spatial-semantic features and discriminative object queries to address the above issues.","Specifically, we construct a spatial-semantic network comprising a semantic embedding block and spatial dependencies modeling block to associate the pretrained ViT features with global semantic features and local spatial features, providing a comprehensive target representation.","In addition, we develop a masked cross-attention module to generate object queries that focus on the most discriminative parts of target objects during query propagation, alleviating noise accumulation and ensuring effective long-term query propagation.","The experimental results show that the proposed method set a new state-of-the-art performance on multiple datasets, including the DAVIS2017 test (89.1%), YoutubeVOS 2019 (88.5%), MOSE (75.1%), LVOS test (73.0%), and LVOS val (75.1%), which demonstrate the effectiveness and generalization capacity of the proposed method.","We will make all source code and trained models publicly available."],"url":"http://arxiv.org/abs/2407.07760v1"}
{"created":"2024-07-10 15:35:56","title":"Validity of contextual formulas (extended version)","abstract":"Many well-known logical identities are naturally written as equivalences between contextual formulas. A simple example is the Boole-Shannon expansion $c[p] \\equiv (p \\wedge c[\\mathrm{true}] ) \\vee (\\neg\\, p \\wedge c[\\mathrm{false}] )$, where $c$ denotes an arbitrary formula with possibly multiple occurrences of a \"hole\", called a context, and $c[\\varphi]$ denotes the result of \"filling\" all holes of $c$ with the formula $\\varphi$. Another example is the unfolding rule $\\mu X. c[X] \\equiv c[\\mu X. c[X]]$ of the modal $\\mu$-calculus.   We consider the modal $\\mu$-calculus as overarching temporal logic and, as usual, reduce the problem whether $\\varphi_1 \\equiv \\varphi_2$ holds for contextual formulas $\\varphi_1, \\varphi_2$ to the problem whether $\\varphi_1 \\leftrightarrow \\varphi_2$ is valid . We show that the problem whether a contextual formula of the $\\mu$-calculus is valid for all contexts can be reduced to validity of ordinary formulas. Our first result constructs a canonical context such that a formula is valid for all contexts if{}f it is valid for this particular one. However, the ordinary formula is exponential in the nesting-depth of the context variables. In a second result we solve this problem, thus proving that validity of contextual formulas is EXP-complete, as for ordinary equivalences. We also prove that both results hold for CTL and LTL as well. We conclude the paper with some experimental results. In particular, we use our implementation to automatically prove the correctness of a set of six contextual equivalences of LTL recently introduced by Esparza et al. for the normalization of LTL formulas. While Esparza et al. need several pages of manual proof, our tool only needs milliseconds to do the job and to compute counterexamples for incorrect variants of the equivalences.","sentences":["Many well-known logical identities are naturally written as equivalences between contextual formulas.","A simple example is the Boole-Shannon expansion $c[p] \\equiv (p \\wedge c[\\mathrm{true}] ) \\vee (\\neg\\, p \\wedge c[\\mathrm{false}] )$, where $c$ denotes an arbitrary formula with possibly multiple occurrences of a \"hole\", called a context, and $c[\\varphi]$ denotes the result of \"filling\" all holes of $c$ with the formula $\\varphi$. Another example is the unfolding rule $\\mu X. c[X] \\equiv c[\\mu X. c[X]]$ of the modal $\\mu$-calculus.   ","We consider the modal $\\mu$-calculus as overarching temporal logic and, as usual, reduce the problem whether $\\varphi_1 \\equiv \\varphi_2$ holds for contextual formulas $\\varphi_1, \\varphi_2$ to the problem whether $\\varphi_1 \\leftrightarrow \\varphi_2$ is valid .","We show that the problem whether a contextual formula of the $\\mu$-calculus is valid for all contexts can be reduced to validity of ordinary formulas.","Our first result constructs a canonical context such that a formula is valid for all contexts if{}f it is valid for this particular one.","However, the ordinary formula is exponential in the nesting-depth of the context variables.","In a second result we solve this problem, thus proving that validity of contextual formulas is EXP-complete, as for ordinary equivalences.","We also prove that both results hold for CTL and LTL as well.","We conclude the paper with some experimental results.","In particular, we use our implementation to automatically prove the correctness of a set of six contextual equivalences of LTL recently introduced by Esparza et al.","for the normalization of LTL formulas.","While Esparza et al. need several pages of manual proof, our tool only needs milliseconds to do the job and to compute counterexamples for incorrect variants of the equivalences."],"url":"http://arxiv.org/abs/2407.07759v1"}
{"created":"2024-07-10 15:34:06","title":"Can ChatGPT Pass a Theory of Computing Course?","abstract":"Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering \"simple\"-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.","sentences":["Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical questions, especially those within theory of computing (ToC) courses.","In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM.","For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams.","For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure.","We scored each of ChatGPT's outputs on these questions.","Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering \"simple\"-style questions, e.g., true/false and multiple choice.","However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs."],"url":"http://arxiv.org/abs/2407.07757v1"}
{"created":"2024-07-10 15:28:02","title":"Neural Geometry Processing via Spherical Neural Surfaces","abstract":"Neural surfaces (e.g., neural map encoding, deep implicits and neural radiance fields) have recently gained popularity because of their generic structure (e.g., multi-layer perceptron) and easy integration with modern learning-based setups. Traditionally, we have a rich toolbox of geometry processing algorithms designed for polygonal meshes to analyze and operate on surface geometry. However, neural representations are typically discretized and converted into a mesh, before applying any geometry processing algorithm. This is unsatisfactory and, as we demonstrate, unnecessary. In this work, we propose a spherical neural surface representation (a spherical parametrization) for genus-0 surfaces and demonstrate how to compute core geometric operators directly on this representation. Namely, we show how to construct the normals and the first and second fundamental forms of the surface, and how to compute the surface gradient, surface divergence and Laplace Beltrami operator on scalar/vector fields defined on the surface. These operators, in turn, enable us to create geometry processing tools that act directly on the neural representations without any unnecessary meshing. We demonstrate illustrative applications in (neural) spectral analysis, heat flow and mean curvature flow, and our method shows robustness to isometric shape variations. We both propose theoretical formulations and validate their numerical estimates. By systematically linking neural surface representations with classical geometry processing algorithms, we believe this work can become a key ingredient in enabling neural geometry processing.","sentences":["Neural surfaces (e.g., neural map encoding, deep implicits and neural radiance fields) have recently gained popularity because of their generic structure (e.g., multi-layer perceptron) and easy integration with modern learning-based setups.","Traditionally, we have a rich toolbox of geometry processing algorithms designed for polygonal meshes to analyze and operate on surface geometry.","However, neural representations are typically discretized and converted into a mesh, before applying any geometry processing algorithm.","This is unsatisfactory and, as we demonstrate, unnecessary.","In this work, we propose a spherical neural surface representation (a spherical parametrization) for genus-0 surfaces and demonstrate how to compute core geometric operators directly on this representation.","Namely, we show how to construct the normals and the first and second fundamental forms of the surface, and how to compute the surface gradient, surface divergence and Laplace Beltrami operator on scalar/vector fields defined on the surface.","These operators, in turn, enable us to create geometry processing tools that act directly on the neural representations without any unnecessary meshing.","We demonstrate illustrative applications in (neural) spectral analysis, heat flow and mean curvature flow, and our method shows robustness to isometric shape variations.","We both propose theoretical formulations and validate their numerical estimates.","By systematically linking neural surface representations with classical geometry processing algorithms, we believe this work can become a key ingredient in enabling neural geometry processing."],"url":"http://arxiv.org/abs/2407.07755v1"}
{"created":"2024-07-10 15:24:06","title":"Quantum CSS Duadic and Triadic Codes: New Insights and Properties","abstract":"In this study, we investigate the construction of quantum CSS duadic codes with dimensions greater than one. We introduce a method for extending smaller splittings of quantum duadic codes to create larger, potentially degenerate quantum duadic codes. Furthermore, we present a technique for computing or bounding the minimum distances of quantum codes constructed through this approach. Additionally, we introduce quantum CSS triadic codes, a family of quantum codes with a rate of at least $\\frac{1}{3}$.","sentences":["In this study, we investigate the construction of quantum CSS duadic codes with dimensions greater than one.","We introduce a method for extending smaller splittings of quantum duadic codes to create larger, potentially degenerate quantum duadic codes.","Furthermore, we present a technique for computing or bounding the minimum distances of quantum codes constructed through this approach.","Additionally, we introduce quantum CSS triadic codes, a family of quantum codes with a rate of at least $\\frac{1}{3}$."],"url":"http://arxiv.org/abs/2407.07753v1"}
{"created":"2024-07-10 15:20:21","title":"Fast Approximation Algorithms for Euclidean Minimum Weight Perfect Matching","abstract":"We study the problem of finding a Euclidean minimum weight perfect matching for $n$ points in the plane. It is known that a deterministic approximation algorithm for this problems must have at least $\\Omega(n \\log n)$ runtime. We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\\log n)$ and show that it has approximation ratio $O(n^{0.2995})$. This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \\log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.599})$ in all fixed dimensions.","sentences":["We study the problem of finding a Euclidean minimum weight perfect matching for $n$ points in the plane.","It is known that a deterministic approximation algorithm for this problems must have at least $\\Omega(n \\log n)$ runtime.","We propose such an algorithm for the Euclidean minimum weight perfect matching problem with runtime $O(n\\log n)$ and show that it has approximation ratio $O(n^{0.2995})$.","This improves the so far best known approximation ratio of $n/2$. We also develop an $O(n \\log n)$ algorithm for the Euclidean minimum weight perfect matching problem in higher dimensions and show it has approximation ratio $O(n^{0.599})$ in all fixed dimensions."],"url":"http://arxiv.org/abs/2407.07749v1"}
{"created":"2024-07-10 15:11:37","title":"LSM: A Comprehensive Metric for Assessing the Safety of Lane Detection Systems in Autonomous Driving","abstract":"Comprehensive perception of the vehicle's environment and correct interpretation of the environment are crucial for the safe operation of autonomous vehicles. The perception of surrounding objects is the main component for further tasks such as trajectory planning. However, safe trajectory planning requires not only object detection, but also the detection of drivable areas and lane corridors. While first approaches consider an advanced safety evaluation of object detection, the evaluation of lane detection still lacks sufficient safety metrics. Similar to the safety metrics for object detection, additional factors such as the semantics of the scene with road type and road width, the detection range as well as the potential causes of missing detections, incorporated by vehicle speed, should be considered for the evaluation of lane detection. Therefore, we propose the Lane Safety Metric (LSM), which takes these factors into account and allows to evaluate the safety of lane detection systems by determining an easily interpretable safety score. We evaluate our offline safety metric on various virtual scenarios using different lane detection approaches and compare it with state-of-the-art performance metrics.","sentences":["Comprehensive perception of the vehicle's environment and correct interpretation of the environment are crucial for the safe operation of autonomous vehicles.","The perception of surrounding objects is the main component for further tasks such as trajectory planning.","However, safe trajectory planning requires not only object detection, but also the detection of drivable areas and lane corridors.","While first approaches consider an advanced safety evaluation of object detection, the evaluation of lane detection still lacks sufficient safety metrics.","Similar to the safety metrics for object detection, additional factors such as the semantics of the scene with road type and road width, the detection range as well as the potential causes of missing detections, incorporated by vehicle speed, should be considered for the evaluation of lane detection.","Therefore, we propose the Lane Safety Metric (LSM), which takes these factors into account and allows to evaluate the safety of lane detection systems by determining an easily interpretable safety score.","We evaluate our offline safety metric on various virtual scenarios using different lane detection approaches and compare it with state-of-the-art performance metrics."],"url":"http://arxiv.org/abs/2407.07740v1"}
{"created":"2024-07-10 15:07:58","title":"Fine-Tuning Large Language Models with User-Level Differential Privacy","abstract":"We investigate practical and scalable algorithms for training large language models (LLMs) with user-level differential privacy (DP) in order to provably safeguard all the examples contributed by each user. We study two variants of DP-SGD with: (1) example-level sampling (ELS) and per-example gradient clipping, and (2) user-level sampling (ULS) and per-user gradient clipping. We derive a novel user-level DP accountant that allows us to compute provably tight privacy guarantees for ELS. Using this, we show that while ELS can outperform ULS in specific settings, ULS generally yields better results when each user has a diverse collection of examples. We validate our findings through experiments in synthetic mean estimation and LLM fine-tuning tasks under fixed compute budgets. We find that ULS is significantly better in settings where either (1) strong privacy guarantees are required, or (2) the compute budget is large. Notably, our focus on LLM-compatible training algorithms allows us to scale to models with hundreds of millions of parameters and datasets with hundreds of thousands of users.","sentences":["We investigate practical and scalable algorithms for training large language models (LLMs) with user-level differential privacy (DP) in order to provably safeguard all the examples contributed by each user.","We study two variants of DP-SGD with: (1) example-level sampling (ELS) and per-example gradient clipping, and (2) user-level sampling (ULS) and per-user gradient clipping.","We derive a novel user-level DP accountant that allows us to compute provably tight privacy guarantees for ELS.","Using this, we show that while ELS can outperform ULS in specific settings, ULS generally yields better results when each user has a diverse collection of examples.","We validate our findings through experiments in synthetic mean estimation and LLM fine-tuning tasks under fixed compute budgets.","We find that ULS is significantly better in settings where either (1) strong privacy guarantees are required, or (2) the compute budget is large.","Notably, our focus on LLM-compatible training algorithms allows us to scale to models with hundreds of millions of parameters and datasets with hundreds of thousands of users."],"url":"http://arxiv.org/abs/2407.07737v1"}
{"created":"2024-07-10 15:06:52","title":"Protecting NeRFs' Copyright via Plug-And-Play Watermarking Base Model","abstract":"Neural Radiance Fields (NeRFs) have become a key method for 3D scene representation. With the rising prominence and influence of NeRF, safeguarding its intellectual property has become increasingly important. In this paper, we propose \\textbf{NeRFProtector}, which adopts a plug-and-play strategy to protect NeRF's copyright during its creation. NeRFProtector utilizes a pre-trained watermarking base model, enabling NeRF creators to embed binary messages directly while creating their NeRF. Our plug-and-play property ensures NeRF creators can flexibly choose NeRF variants without excessive modifications. Leveraging our newly designed progressive distillation, we demonstrate performance on par with several leading-edge neural rendering methods. Our project is available at: \\url{https://qsong2001.github.io/NeRFProtector}.","sentences":["Neural Radiance Fields (NeRFs) have become a key method for 3D scene representation.","With the rising prominence and influence of NeRF, safeguarding its intellectual property has become increasingly important.","In this paper, we propose \\textbf{NeRFProtector}, which adopts a plug-and-play strategy to protect NeRF's copyright during its creation.","NeRFProtector utilizes a pre-trained watermarking base model, enabling NeRF creators to embed binary messages directly while creating their NeRF.","Our plug-and-play property ensures NeRF creators can flexibly choose NeRF variants without excessive modifications.","Leveraging our newly designed progressive distillation, we demonstrate performance on par with several leading-edge neural rendering methods.","Our project is available at: \\url{https://qsong2001.github.io/NeRFProtector}."],"url":"http://arxiv.org/abs/2407.07735v1"}
{"created":"2024-07-10 15:00:08","title":"SaMoye: Zero-shot Singing Voice Conversion Based on Feature Disentanglement and Synthesis","abstract":"Singing voice conversion (SVC) aims to convert a singer's voice in a given music piece to another singer while keeping the original content. We propose an end-to-end feature disentanglement-based model, which we named SaMoye, to enable zero-shot many-to-many singing voice conversion. SaMoye disentangles the features of the singing voice into content features, timbre features, and pitch features respectively. The content features are enhanced using a GPT-based model to perform cross-prediction with the phoneme of the lyrics. SaMoye can generate the music with converted voice by replacing the timbre features with the target singer. We also establish an unparalleled large-scale dataset to guarantee zero-shot performance. The dataset consists of 1500k pure singing vocal clips containing at least 10,000 singers.","sentences":["Singing voice conversion (SVC) aims to convert a singer's voice in a given music piece to another singer while keeping the original content.","We propose an end-to-end feature disentanglement-based model, which we named SaMoye, to enable zero-shot many-to-many singing voice conversion.","SaMoye disentangles the features of the singing voice into content features, timbre features, and pitch features respectively.","The content features are enhanced using a GPT-based model to perform cross-prediction with the phoneme of the lyrics.","SaMoye can generate the music with converted voice by replacing the timbre features with the target singer.","We also establish an unparalleled large-scale dataset to guarantee zero-shot performance.","The dataset consists of 1500k pure singing vocal clips containing at least 10,000 singers."],"url":"http://arxiv.org/abs/2407.07728v2"}
{"created":"2024-07-10 14:57:46","title":"PaliGemma: A versatile 3B VLM for transfer","abstract":"PaliGemma is an open Vision-Language Model (VLM) that is based on the SigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to be a versatile and broadly knowledgeable base model that is effective to transfer. It achieves strong performance on a wide variety of open-world tasks. We evaluate PaliGemma on almost 40 diverse tasks including standard VLM benchmarks, but also more specialized tasks such as remote-sensing and segmentation.","sentences":["PaliGemma is an open Vision-Language Model (VLM) that is based on the SigLIP-So400m vision encoder and the Gemma-2B language model.","It is trained to be a versatile and broadly knowledgeable base model that is effective to transfer.","It achieves strong performance on a wide variety of open-world tasks.","We evaluate PaliGemma on almost 40 diverse tasks including standard VLM benchmarks, but also more specialized tasks such as remote-sensing and segmentation."],"url":"http://arxiv.org/abs/2407.07726v1"}
{"created":"2024-07-10 14:57:35","title":"Topological Offsets","abstract":"We introduce Topological Offsets, a novel approach to generate manifold and self-intersection-free offset surfaces that are topologically equivalent to an offset infinitesimally close to the surface. Our approach, by construction, creates a manifold, watertight, and self-intersection-free offset surface strictly enclosing the input, while doing a best effort to move it to a prescribed distance from the input. Differently from existing approaches, we embed the input in a volumetric mesh, and insert a topological offset around the mesh with purely combinatorial operations. The topological offset is then inflated/deflated to match the user-prescribed distance, while enforcing that no intersections or non-manifold configurations are introduced. We evaluate the effectiveness and robustness of our approach on the non-intersecting subset of Thingi10k, and show that topological offsets are beneficial in multiple graphics applications, including (1) converting non-manifold surfaces to manifold ones, (2) creation of nested cages/layered offsets, and (3) reliably computing finite offsets.","sentences":["We introduce Topological Offsets, a novel approach to generate manifold and self-intersection-free offset surfaces that are topologically equivalent to an offset infinitesimally close to the surface.","Our approach, by construction, creates a manifold, watertight, and self-intersection-free offset surface strictly enclosing the input, while doing a best effort to move it to a prescribed distance from the input.","Differently from existing approaches, we embed the input in a volumetric mesh, and insert a topological offset around the mesh with purely combinatorial operations.","The topological offset is then inflated/deflated to match the user-prescribed distance, while enforcing that no intersections or non-manifold configurations are introduced.","We evaluate the effectiveness and robustness of our approach on the non-intersecting subset of Thingi10k, and show that topological offsets are beneficial in multiple graphics applications, including (1) converting non-manifold surfaces to manifold ones, (2) creation of nested cages/layered offsets, and (3) reliably computing finite offsets."],"url":"http://arxiv.org/abs/2407.07725v1"}
{"created":"2024-07-10 14:50:00","title":"High-Performance Sorting-Based k-mer Counting in Distributed Memory with Flexible Hybrid Parallelism","abstract":"In generating large quantities of DNA data, high-throughput sequencing technologies require advanced bioinformatics infrastructures for efficient data analysis. k-mer counting, the process of quantifying the frequency of fixed-length k DNA subsequences, is a fundamental step in various bioinformatics pipelines, including genome assembly and protein prediction. Due to the growing volume of data, the scaling of the counting process is critical. In the literature, distributed memory software uses hash tables, which exhibit poor cache friendliness and consume excessive memory. They often also lack support for flexible parallelism, which makes integration into existing bioinformatics pipelines difficult. In this work, we propose HySortK, a highly efficient sorting-based distributed memory k-mer counter. HySortK reduces the communication volume through a carefully designed communication scheme and domain-specific optimization strategies. Furthermore, we introduce an abstract task layer for flexible hybrid parallelism to address load imbalances in different scenarios. HySortK achieves a 2-10x speedup compared to the GPU baseline on 4 and 8 nodes. Compared to state-of-the-art CPU software, HySortK achieves up to 2x speedup while reducing peak memory usage by 30% on 16 nodes. Finally, we integrated HySortK into an existing genome assembly pipeline and achieved up to 1.8x speedup, proving its flexibility and practicality in real-world scenarios.","sentences":["In generating large quantities of DNA data, high-throughput sequencing technologies require advanced bioinformatics infrastructures for efficient data analysis.","k-mer counting, the process of quantifying the frequency of fixed-length k DNA subsequences, is a fundamental step in various bioinformatics pipelines, including genome assembly and protein prediction.","Due to the growing volume of data, the scaling of the counting process is critical.","In the literature, distributed memory software uses hash tables, which exhibit poor cache friendliness and consume excessive memory.","They often also lack support for flexible parallelism, which makes integration into existing bioinformatics pipelines difficult.","In this work, we propose HySortK, a highly efficient sorting-based distributed memory k-mer counter.","HySortK reduces the communication volume through a carefully designed communication scheme and domain-specific optimization strategies.","Furthermore, we introduce an abstract task layer for flexible hybrid parallelism to address load imbalances in different scenarios.","HySortK achieves a 2-10x speedup compared to the GPU baseline on 4 and 8 nodes.","Compared to state-of-the-art CPU software, HySortK achieves up to 2x speedup while reducing peak memory usage by 30% on 16 nodes.","Finally, we integrated HySortK into an existing genome assembly pipeline and achieved up to 1.8x speedup, proving its flexibility and practicality in real-world scenarios."],"url":"http://arxiv.org/abs/2407.07718v1"}
{"created":"2024-07-10 14:44:25","title":"Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs","abstract":"Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems. Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning. Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications. This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements. We benchmark DGS against state-of-the-art feature engineering and graph neural network methods using five diverse datasets. The results indicate that DGS achieves competitive performance while improving inference speed up to 12x compared to other deep learning approaches on our tested benchmarks. Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs.","sentences":["Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems.","Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning.","Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications.","This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements.","We benchmark DGS against state-of-the-art feature engineering and graph neural network methods using five diverse datasets.","The results indicate that DGS achieves competitive performance while improving inference speed up to 12x compared to other deep learning approaches on our tested benchmarks.","Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs."],"url":"http://arxiv.org/abs/2407.07712v1"}
{"created":"2024-07-10 14:34:53","title":"Evaluating the Role of Security Assurance Cases in Agile Medical Device Development","abstract":"Cybersecurity issues in medical devices threaten patient safety and can cause harm if exploited. Standards and regulations therefore require vendors of such devices to provide an assessment of the cybersecurity risks as well as a description of their mitigation. Security assurance cases (SACs) capture these elements as a structured argument. Compiling an SAC requires taking domain-specific regulations and requirements as well as the way of working into account. In this case study, we evaluate CASCADE, an approach for building SAC in the context of a large medical device manufacturer with an established agile development workflow. We investigate the regulatory context as well as the adaptations needed in the development process. Our results show the suitability of SACs in the medical device industry. We identified 17 use cases in which an SAC supports internal and external needs. The connection to safety assurance can be achieved by incorporating information from the risk assessment matrix into the SAC. Integration into the development process can be achieved by introducing a new role and rules for the design review and the release to production as well as additional criteria for the definition of done. We also show that SACs built with CASCADE fulfill the requirements of relevant standards in the medical domain such as ISO 14971.","sentences":["Cybersecurity issues in medical devices threaten patient safety and can cause harm if exploited.","Standards and regulations therefore require vendors of such devices to provide an assessment of the cybersecurity risks as well as a description of their mitigation.","Security assurance cases (SACs) capture these elements as a structured argument.","Compiling an SAC requires taking domain-specific regulations and requirements as well as the way of working into account.","In this case study, we evaluate CASCADE, an approach for building SAC in the context of a large medical device manufacturer with an established agile development workflow.","We investigate the regulatory context as well as the adaptations needed in the development process.","Our results show the suitability of SACs in the medical device industry.","We identified 17 use cases in which an SAC supports internal and external needs.","The connection to safety assurance can be achieved by incorporating information from the risk assessment matrix into the SAC.","Integration into the development process can be achieved by introducing a new role and rules for the design review and the release to production as well as additional criteria for the definition of done.","We also show that SACs built with CASCADE fulfill the requirements of relevant standards in the medical domain such as ISO 14971."],"url":"http://arxiv.org/abs/2407.07704v1"}
{"created":"2024-07-10 14:31:36","title":"The V-Lab VR Educational Application Framework","abstract":"This paper presents the V-Lab, a VR application development framework for educational scenarios mainly involving scientific processes executed in laboratory environments such as chemistry and biology laboratories. This work is an extension of the Onlabs simulator which has been developed by the Hellenic Open University as a distance teaching enabler for similar subjects, helping to alleviate the need for access to the physical laboratory infrastructure; thus, shortening training periods of students in the laboratory and making their training during the periods of physical presence more productive and secure. The extensions of the Onlabs to deliver an enhanced and modular framework that can be extended to multiple educational scenarios is the work performed within the context of the European project XR2Learn (Leveraging the European XR industry technologies to empower immersive learning and training).","sentences":["This paper presents the V-Lab, a VR application development framework for educational scenarios mainly involving scientific processes executed in laboratory environments such as chemistry and biology laboratories.","This work is an extension of the Onlabs simulator which has been developed by the Hellenic Open University as a distance teaching enabler for similar subjects, helping to alleviate the need for access to the physical laboratory infrastructure; thus, shortening training periods of students in the laboratory and making their training during the periods of physical presence more productive and secure.","The extensions of the Onlabs to deliver an enhanced and modular framework that can be extended to multiple educational scenarios is the work performed within the context of the European project XR2Learn (Leveraging the European XR industry technologies to empower immersive learning and training)."],"url":"http://arxiv.org/abs/2407.07698v1"}
{"created":"2024-07-10 14:24:53","title":"African Democracy in the Era of Generative Disinformation: Challenges and Countermeasures against AI-Generated Propaganda","abstract":"In light of prominent discourse around the negative implications of generative AI, an emerging area of research is investigating the current and estimated impacts of AI-generated propaganda on African citizens participating in elections. Throughout Africa, there have already been suspected cases of AI-generated propaganda influencing electoral outcomes or precipitating coups in countries like Nigeria, Burkina Faso, and Gabon, underscoring the need for comprehensive research in this domain. This paper aims to highlight the risks associated with the spread of generative AI-driven disinformation within Africa while concurrently examining the roles of government, civil society, academia, and the general public in the responsible development, practical use, and robust governance of AI. To understand how African governments might effectively counteract the impact of AI-generated propaganda, this paper presents case studies illustrating the current usage of generative AI for election-related propaganda in Africa. Subsequently, this paper discusses efforts by fact-checking organisations to mitigate the negative impacts of disinformation, explores the potential for new initiatives to actively engage citizens in literacy efforts to combat disinformation spread, and advocates for increased governmental regulatory measures. Overall, this research seeks to increase comprehension of the potential ramifications of AI-generated propaganda on democratic processes within Africa and propose actionable strategies for stakeholders to address these multifaceted challenges.","sentences":["In light of prominent discourse around the negative implications of generative AI, an emerging area of research is investigating the current and estimated impacts of AI-generated propaganda on African citizens participating in elections.","Throughout Africa, there have already been suspected cases of AI-generated propaganda influencing electoral outcomes or precipitating coups in countries like Nigeria, Burkina Faso, and Gabon, underscoring the need for comprehensive research in this domain.","This paper aims to highlight the risks associated with the spread of generative AI-driven disinformation within Africa while concurrently examining the roles of government, civil society, academia, and the general public in the responsible development, practical use, and robust governance of AI.","To understand how African governments might effectively counteract the impact of AI-generated propaganda, this paper presents case studies illustrating the current usage of generative AI for election-related propaganda in Africa.","Subsequently, this paper discusses efforts by fact-checking organisations to mitigate the negative impacts of disinformation, explores the potential for new initiatives to actively engage citizens in literacy efforts to combat disinformation spread, and advocates for increased governmental regulatory measures.","Overall, this research seeks to increase comprehension of the potential ramifications of AI-generated propaganda on democratic processes within Africa and propose actionable strategies for stakeholders to address these multifaceted challenges."],"url":"http://arxiv.org/abs/2407.07695v1"}
{"created":"2024-07-10 14:09:40","title":"On the impact of VR/AR applications on optical transport networks: First experiments with Meta Quest 3 gaming and conferencing application","abstract":"With the advent of next-generation AR/VR headsets, many of them with affordable prices, telecom operators have forecasted an explosive growth of traffic in their networks. Penetration of AR/VR services and applications is estimated to grow exponentially in the next few years. This work attempts to shed light on the bandwidth capacity requirements and latency of popular AR/VR applications with four different real experimental settings on the Meta Quest 3 headsets, and their potential impact on the network.","sentences":["With the advent of next-generation AR/VR headsets, many of them with affordable prices, telecom operators have forecasted an explosive growth of traffic in their networks.","Penetration of AR/VR services and applications is estimated to grow exponentially in the next few years.","This work attempts to shed light on the bandwidth capacity requirements and latency of popular AR/VR applications with four different real experimental settings on the Meta Quest 3 headsets, and their potential impact on the network."],"url":"http://arxiv.org/abs/2407.07686v1"}
{"created":"2024-07-10 14:08:27","title":"Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control","abstract":"This paper presents a novel approach to Autonomous Vehicle (AV) control through the application of active inference, a theory derived from neuroscience that conceptualizes the brain as a predictive machine. Traditional autonomous driving systems rely heavily on Modular Pipelines, Imitation Learning, or Reinforcement Learning, each with inherent limitations in adaptability, generalization, and computational efficiency. Active inference addresses these challenges by minimizing prediction error (termed \"surprise\") through a dynamic model that balances perception and action. Our method integrates active inference with deep learning to manage lateral control in AVs, enabling them to perform lane following maneuvers within a simulated urban environment. We demonstrate that our model, despite its simplicity, effectively learns and generalizes from limited data without extensive retraining, significantly reducing computational demands. The proposed approach not only enhances the adaptability and performance of AVs in dynamic scenarios but also aligns closely with human-like driving behavior, leveraging a generative model to predict and adapt to environmental changes. Results from extensive experiments in the CARLA simulator show promising outcomes, outperforming traditional methods in terms of adaptability and efficiency, thereby advancing the potential of active inference in real-world autonomous driving applications.","sentences":["This paper presents a novel approach to Autonomous Vehicle (AV) control through the application of active inference, a theory derived from neuroscience that conceptualizes the brain as a predictive machine.","Traditional autonomous driving systems rely heavily on Modular Pipelines, Imitation Learning, or Reinforcement Learning, each with inherent limitations in adaptability, generalization, and computational efficiency.","Active inference addresses these challenges by minimizing prediction error (termed \"surprise\") through a dynamic model that balances perception and action.","Our method integrates active inference with deep learning to manage lateral control in AVs, enabling them to perform lane following maneuvers within a simulated urban environment.","We demonstrate that our model, despite its simplicity, effectively learns and generalizes from limited data without extensive retraining, significantly reducing computational demands.","The proposed approach not only enhances the adaptability and performance of AVs in dynamic scenarios but also aligns closely with human-like driving behavior, leveraging a generative model to predict and adapt to environmental changes.","Results from extensive experiments in the CARLA simulator show promising outcomes, outperforming traditional methods in terms of adaptability and efficiency, thereby advancing the potential of active inference in real-world autonomous driving applications."],"url":"http://arxiv.org/abs/2407.07684v1"}
{"created":"2024-07-10 14:08:24","title":"The Language of Weather: Social Media Reactions to Weather Accounting for Climatic and Linguistic Baselines","abstract":"This study explores how different weather conditions influence public sentiment on social media, focusing on Twitter data from the UK. By considering climate and linguistic baselines, we improve the accuracy of weather-related sentiment analysis. Our findings show that emotional responses to weather are complex, influenced by combinations of weather variables and regional language differences. The results highlight the importance of context-sensitive methods for better understanding public mood in response to weather, which can enhance impact-based forecasting and risk communication in the context of climate change.","sentences":["This study explores how different weather conditions influence public sentiment on social media, focusing on Twitter data from the UK.","By considering climate and linguistic baselines, we improve the accuracy of weather-related sentiment analysis.","Our findings show that emotional responses to weather are complex, influenced by combinations of weather variables and regional language differences.","The results highlight the importance of context-sensitive methods for better understanding public mood in response to weather, which can enhance impact-based forecasting and risk communication in the context of climate change."],"url":"http://arxiv.org/abs/2407.07683v1"}
{"created":"2024-07-10 14:05:09","title":"APTAS for bin packing with general cost structures","abstract":"We consider the following generalization of the bin packing problem. We are given a set of items each of which is associated with a rational size in the interval [0,1], and a monotone non-decreasing non-negative cost function f defined over the cardinalities of the subsets of items. A feasible solution is a partition of the set of items into bins subject to the constraint that the total size of items in every bin is at most 1. Unlike bin packing, the goal function is to minimize the total cost of the bins where the cost of a bin is the value of f applied on the cardinality of the subset of items packed into the bin. We present an APTAS for this strongly NP-hard problem. We also provide a complete complexity classification of the problem with respect to the choice of f.","sentences":["We consider the following generalization of the bin packing problem.","We are given a set of items each of which is associated with a rational size in the interval [0,1], and a monotone non-decreasing non-negative cost function f defined over the cardinalities of the subsets of items.","A feasible solution is a partition of the set of items into bins subject to the constraint that the total size of items in every bin is at most 1.","Unlike bin packing, the goal function is to minimize the total cost of the bins where the cost of a bin is the value of f applied on the cardinality of the subset of items packed into the bin.","We present an APTAS for this strongly NP-hard problem.","We also provide a complete complexity classification of the problem with respect to the choice of f."],"url":"http://arxiv.org/abs/2407.07677v1"}
