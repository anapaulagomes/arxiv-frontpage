{"created":"2024-11-04 18:59:51","title":"Prompting with Phonemes: Enhancing LLM Multilinguality for non-Latin Script Languages","abstract":"Multilingual LLMs have achieved remarkable benchmark performance, but we find they continue to underperform on non-Latin script languages across contemporary LLM families. This discrepancy arises from the fact that LLMs are pretrained with orthographic scripts, which are dominated by Latin characters that obscure their shared phonology with non-Latin scripts. We propose leveraging phonemic transcriptions as complementary signals to induce script-invariant representations. Our study demonstrates that integrating phonemic signals improves performance across both non-Latin and Latin languages, with a particularly significant impact on closing the performance gap between the two. Through detailed experiments, we show that phonemic and orthographic scripts retrieve distinct examples for in-context learning (ICL). This motivates our proposed Mixed-ICL retrieval strategy, where further aggregation leads to our significant performance improvements for both Latin script languages (up to 12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL retrieval.","sentences":["Multilingual LLMs have achieved remarkable benchmark performance, but we find they continue to underperform on non-Latin script languages across contemporary LLM families.","This discrepancy arises from the fact that LLMs are pretrained with orthographic scripts, which are dominated by Latin characters that obscure their shared phonology with non-Latin scripts.","We propose leveraging phonemic transcriptions as complementary signals to induce script-invariant representations.","Our study demonstrates that integrating phonemic signals improves performance across both non-Latin and Latin languages, with a particularly significant impact on closing the performance gap between the two.","Through detailed experiments, we show that phonemic and orthographic scripts retrieve distinct examples for in-context learning (ICL).","This motivates our proposed Mixed-ICL retrieval strategy, where further aggregation leads to our significant performance improvements for both Latin script languages (up to 12.6%) and non-Latin script languages (up to 15.1%) compared to randomized ICL retrieval."],"url":"http://arxiv.org/abs/2411.02398v1"}
{"created":"2024-11-04 18:59:44","title":"Adaptive Caching for Faster Video Generation with Diffusion Transformers","abstract":"Generating temporally-consistent high-fidelity videos can be computationally expensive, especially over longer temporal spans. More-recent Diffusion Transformers (DiTs) -- despite making significant headway in this context -- have only heightened such challenges as they rely on larger models and heavier attention mechanisms, resulting in slower inference speeds. In this paper, we introduce a training-free method to accelerate video DiTs, termed Adaptive Caching (AdaCache), which is motivated by the fact that \"not all videos are created equal\": meaning, some videos require fewer denoising steps to attain a reasonable quality than others. Building on this, we not only cache computations through the diffusion process, but also devise a caching schedule tailored to each video generation, maximizing the quality-latency trade-off. We further introduce a Motion Regularization (MoReg) scheme to utilize video information within AdaCache, essentially controlling the compute allocation based on motion content. Altogether, our plug-and-play contributions grant significant inference speedups (e.g. up to 4.7x on Open-Sora 720p - 2s video generation) without sacrificing the generation quality, across multiple video DiT baselines.","sentences":["Generating temporally-consistent high-fidelity videos can be computationally expensive, especially over longer temporal spans.","More-recent Diffusion Transformers (DiTs) -- despite making significant headway in this context -- have only heightened such challenges as they rely on larger models and heavier attention mechanisms, resulting in slower inference speeds.","In this paper, we introduce a training-free method to accelerate video DiTs, termed Adaptive Caching (AdaCache), which is motivated by the fact that \"not all videos are created equal\": meaning, some videos require fewer denoising steps to attain a reasonable quality than others.","Building on this, we not only cache computations through the diffusion process, but also devise a caching schedule tailored to each video generation, maximizing the quality-latency trade-off.","We further introduce a Motion Regularization (MoReg) scheme to utilize video information within AdaCache, essentially controlling the compute allocation based on motion content.","Altogether, our plug-and-play contributions grant significant inference speedups (e.g. up to 4.7x on Open-Sora 720p - 2s video generation) without sacrificing the generation quality, across multiple video DiT baselines."],"url":"http://arxiv.org/abs/2411.02397v1"}
{"created":"2024-11-04 18:59:05","title":"AutoVFX: Physically Realistic Video Editing from Natural Language Instructions","abstract":"Modern visual effects (VFX) software has made it possible for skilled artists to create imagery of virtually anything. However, the creation process remains laborious, complex, and largely inaccessible to everyday users. In this work, we present AutoVFX, a framework that automatically creates realistic and dynamic VFX videos from a single video and natural language instructions. By carefully integrating neural scene modeling, LLM-based code generation, and physical simulation, AutoVFX is able to provide physically-grounded, photorealistic editing effects that can be controlled directly using natural language instructions. We conduct extensive experiments to validate AutoVFX's efficacy across a diverse spectrum of videos and instructions. Quantitative and qualitative results suggest that AutoVFX outperforms all competing methods by a large margin in generative quality, instruction alignment, editing versatility, and physical plausibility.","sentences":["Modern visual effects (VFX) software has made it possible for skilled artists to create imagery of virtually anything.","However, the creation process remains laborious, complex, and largely inaccessible to everyday users.","In this work, we present AutoVFX, a framework that automatically creates realistic and dynamic VFX videos from a single video and natural language instructions.","By carefully integrating neural scene modeling, LLM-based code generation, and physical simulation, AutoVFX is able to provide physically-grounded, photorealistic editing effects that can be controlled directly using natural language instructions.","We conduct extensive experiments to validate AutoVFX's efficacy across a diverse spectrum of videos and instructions.","Quantitative and qualitative results suggest that AutoVFX outperforms all competing methods by a large margin in generative quality, instruction alignment, editing versatility, and physical plausibility."],"url":"http://arxiv.org/abs/2411.02394v1"}
{"created":"2024-11-04 18:59:05","title":"Training-free Regional Prompting for Diffusion Transformers","abstract":"Diffusion models have demonstrated excellent capabilities in text-to-image generation. Their semantic understanding (i.e., prompt following) ability has also been greatly improved with large language models (e.g., T5, Llama). However, existing models cannot perfectly handle long and complex text prompts, especially when the text prompts contain various objects with numerous attributes and interrelated spatial relationships. While many regional prompting methods have been proposed for UNet-based models (SD1.5, SDXL), but there are still no implementations based on the recent Diffusion Transformer (DiT) architecture, such as SD3 and FLUX.1.In this report, we propose and implement regional prompting for FLUX.1 based on attention manipulation, which enables DiT with fined-grained compositional text-to-image generation capability in a training-free manner. Code is available at https://github.com/antonioo-c/Regional-Prompting-FLUX.","sentences":["Diffusion models have demonstrated excellent capabilities in text-to-image generation.","Their semantic understanding (i.e., prompt following) ability has also been greatly improved with large language models (e.g., T5, Llama).","However, existing models cannot perfectly handle long and complex text prompts, especially when the text prompts contain various objects with numerous attributes and interrelated spatial relationships.","While many regional prompting methods have been proposed for UNet-based models (SD1.5, SDXL), but there are still no implementations based on the recent Diffusion Transformer (DiT) architecture, such as SD3 and FLUX.1.In this report, we propose and implement regional prompting for FLUX.1 based on attention manipulation, which enables DiT with fined-grained compositional text-to-image generation capability in a training-free manner.","Code is available at https://github.com/antonioo-c/Regional-Prompting-FLUX."],"url":"http://arxiv.org/abs/2411.02395v1"}
{"created":"2024-11-04 18:58:01","title":"Adaptive Length Image Tokenization via Recurrent Allocation","abstract":"Current vision systems typically assign fixed-length representations to images, regardless of the information content. This contrasts with human intelligence - and even large language models - which allocate varying representational capacities based on entropy, context and familiarity. Inspired by this, we propose an approach to learn variable-length token representations for 2D images. Our encoder-decoder architecture recursively processes 2D image tokens, distilling them into 1D latent tokens over multiple iterations of recurrent rollouts. Each iteration refines the 2D tokens, updates the existing 1D latent tokens, and adaptively increases representational capacity by adding new tokens. This enables compression of images into a variable number of tokens, ranging from 32 to 256. We validate our tokenizer using reconstruction loss and FID metrics, demonstrating that token count aligns with image entropy, familiarity and downstream task requirements. Recurrent token processing with increasing representational capacity in each iteration shows signs of token specialization, revealing potential for object / part discovery.","sentences":["Current vision systems typically assign fixed-length representations to images, regardless of the information content.","This contrasts with human intelligence - and even large language models - which allocate varying representational capacities based on entropy, context and familiarity.","Inspired by this, we propose an approach to learn variable-length token representations for 2D images.","Our encoder-decoder architecture recursively processes 2D image tokens, distilling them into 1D latent tokens over multiple iterations of recurrent rollouts.","Each iteration refines the 2D tokens, updates the existing 1D latent tokens, and adaptively increases representational capacity by adding new tokens.","This enables compression of images into a variable number of tokens, ranging from 32 to 256.","We validate our tokenizer using reconstruction loss and FID metrics, demonstrating that token count aligns with image entropy, familiarity and downstream task requirements.","Recurrent token processing with increasing representational capacity in each iteration shows signs of token specialization, revealing potential for object / part discovery."],"url":"http://arxiv.org/abs/2411.02393v1"}
{"created":"2024-11-04 18:57:49","title":"One-Way Functions and Polynomial Time Dimension","abstract":"This work solves an open problem regarding the rate of time-bounded Kolmogorov complexity and polynomial-time dimension, conditioned on a hardness assumption. Hitchcock and Vinodchandran (CCC 2004) show that the polynomial-time dimension of infinite sequences (denoted ${\\mathrm{cdim}}_\\mathrm{P}$) defined using betting algorithms called gales, is lower bounded by the asymptotic lower rate of polynomial-time Kolmogorov complexity (denoted $\\mathcal{K}_\\text{poly}$). Hitchcock and Vindochandran and Stull asked whether the converse relationship also holds. This question has thus far resisted resolution. The corresponding unbounded notions, namely, the constructive dimension and the asymptotic lower rate of unbounded Kolmogorov complexity are equal for every sequence. Analogous notions are equal even at finite-state level. In view of these results, it is reasonable to conjecture that the polynomial-time quantities are identical for every sequence and set of sequences.   However, under a plausible assumption which underlies modern cryptography - namely the existence of one-way functions, we refute the conjecture thereby giving a negative answer to the open question posed by Hitchcock and Vinodchandran and Stull .   We show the following, conditioned on the existence of one-way functions: There are sets $\\mathcal{F}$ of infinite sequences whose polytime dimension strictly exceeds $\\mathcal{K}_\\text{poly}(\\mathcal{F})$, that is ${\\mathrm{cdim}}_\\mathrm{P}(\\mathcal{F}) > \\mathcal{K}_\\text{poly}(\\mathcal{F})$. We establish a stronger version of this result, that there are individual sequences $X$ whose poly-time dimension strictly exceeds $\\mathcal{K}_\\text{poly}(X)$, that is ${\\mathrm{cdim}}_\\mathrm{P}(X) > \\mathcal{K}_\\text{poly}(X)$. Further, we show that the gap between these quantities can be made arbitrarily close to 1. We also establish similar bounds for strong poly-time dimension","sentences":["This work solves an open problem regarding the rate of time-bounded Kolmogorov complexity and polynomial-time dimension, conditioned on a hardness assumption.","Hitchcock and Vinodchandran (CCC 2004) show that the polynomial-time dimension of infinite sequences (denoted ${\\mathrm{cdim}}_\\mathrm{P}$) defined using betting algorithms called gales, is lower bounded by the asymptotic lower rate of polynomial-time Kolmogorov complexity (denoted $\\mathcal{K}_\\text{poly}$).","Hitchcock and Vindochandran and Stull asked whether the converse relationship also holds.","This question has thus far resisted resolution.","The corresponding unbounded notions, namely, the constructive dimension and the asymptotic lower rate of unbounded Kolmogorov complexity are equal for every sequence.","Analogous notions are equal even at finite-state level.","In view of these results, it is reasonable to conjecture that the polynomial-time quantities are identical for every sequence and set of sequences.   ","However, under a plausible assumption which underlies modern cryptography - namely the existence of one-way functions, we refute the conjecture thereby giving a negative answer to the open question posed by Hitchcock and Vinodchandran and Stull .   ","We show the following, conditioned on the existence of one-way functions: There are sets $\\mathcal{F}$ of infinite sequences whose polytime dimension strictly exceeds $\\mathcal{K}_\\text{poly}(\\mathcal{F})$, that is ${\\mathrm{cdim}}_\\mathrm{P}(\\mathcal{F}) >","\\mathcal{K}_\\text{poly}(\\mathcal{F})$. We establish a stronger version of this result, that there are individual sequences $X$ whose poly-time dimension strictly exceeds $\\mathcal{K}_\\text{poly}(X)$, that is ${\\mathrm{cdim}}_\\mathrm{P}(X) >","\\mathcal{K}_\\text{poly}(X)$. Further, we show that the gap between these quantities can be made arbitrarily close to 1.","We also establish similar bounds for strong poly-time dimension"],"url":"http://arxiv.org/abs/2411.02392v1"}
{"created":"2024-11-04 18:56:42","title":"Attacking Vision-Language Computer Agents via Pop-ups","abstract":"Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces. Despite such visual inputs becoming more integrated into agentic applications, what types of risks and attacks exist around them still remain unclear. In this work, we demonstrate that VLM agents can be easily attacked by a set of carefully designed adversarial pop-ups, which human users would typically recognize and ignore. This distraction leads agents to click these pop-ups instead of performing the tasks as usual. Integrating these pop-ups into existing agent testing environments like OSWorld and VisualWebArena leads to an attack success rate (the frequency of the agent clicking the pop-ups) of 86% on average and decreases the task success rate by 47%. Basic defense techniques such as asking the agent to ignore pop-ups or including an advertisement notice, are ineffective against the attack.","sentences":["Autonomous agents powered by large vision and language models (VLM) have demonstrated significant potential in completing daily computer tasks, such as browsing the web to book travel and operating desktop software, which requires agents to understand these interfaces.","Despite such visual inputs becoming more integrated into agentic applications, what types of risks and attacks exist around them still remain unclear.","In this work, we demonstrate that VLM agents can be easily attacked by a set of carefully designed adversarial pop-ups, which human users would typically recognize and ignore.","This distraction leads agents to click these pop-ups instead of performing the tasks as usual.","Integrating these pop-ups into existing agent testing environments like OSWorld and VisualWebArena leads to an attack success rate (the frequency of the agent clicking the pop-ups) of 86% on average and decreases the task success rate by 47%.","Basic defense techniques such as asking the agent to ignore pop-ups or including an advertisement notice, are ineffective against the attack."],"url":"http://arxiv.org/abs/2411.02391v1"}
{"created":"2024-11-04 18:55:00","title":"The Relationship Between Smartphone Usage and Sleep Quality Amongst University Students","abstract":"Gender differences were examined in sensitivity to sleep quality, in the context of blue light exposure from smartphones. Our hypothesis was created based on our journal article findings that females are more prone to be inclined to the prolonged usage of smartphones at bedtime and thus had less quality of sleep than males. The theory that usage affects sleep quality was due to the belief that the blue light emanating from the smartphone screen would disrupt our body natural circadian rhythm, or sleep cycle, due to the blue light ability to block a hormone called melatonin that controls and aids sleep. However, upon conducting regression tests and statistical analysis on our dataset, we found that our hypothesis was incorrect. Our dataset and analysis showed no relationship between smartphone usage and sleep quality in both males and females in young adults.","sentences":["Gender differences were examined in sensitivity to sleep quality, in the context of blue light exposure from smartphones.","Our hypothesis was created based on our journal article findings that females are more prone to be inclined to the prolonged usage of smartphones at bedtime and thus had less quality of sleep than males.","The theory that usage affects sleep quality was due to the belief that the blue light emanating from the smartphone screen would disrupt our body natural circadian rhythm, or sleep cycle, due to the blue light ability to block a hormone called melatonin that controls and aids sleep.","However, upon conducting regression tests and statistical analysis on our dataset, we found that our hypothesis was incorrect.","Our dataset and analysis showed no relationship between smartphone usage and sleep quality in both males and females in young adults."],"url":"http://arxiv.org/abs/2411.02388v1"}
{"created":"2024-11-04 18:54:14","title":"Reachability in One-Dimensional Pushdown Vector Addition Systems is Decidable","abstract":"We consider the model of one-dimensional Pushdown Vector Addition Systems (1-PVAS), a fundamental computational model simulating both recursive and concurrent behaviours. Our main result is decidability of the reachability problem for 1-PVAS, an important open problem investigated for at least a decade. In the algorithm we actually consider an equivalent model of Grammar Vector Addition Systems (GVAS). We prove the main result by showing that for every one-dimensional GVAS (1-GVAS) one can compute another 1-GVAS, which has the same reachability relation as the original one and additionally has the so-called thin property. Due to the work of Atig and Ganty from 2011, thin 1-GVAS have decidable reachability problem, therefore our construction implies decidability of the problem for all 1-GVAS. Moreover, we also show that if reachability in thin 1-GVAS can be decided in elementary time then also reachability in all 1-GVAS can be decided in elementary time.","sentences":["We consider the model of one-dimensional Pushdown Vector Addition Systems (1-PVAS), a fundamental computational model simulating both recursive and concurrent behaviours.","Our main result is decidability of the reachability problem for 1-PVAS, an important open problem investigated for at least a decade.","In the algorithm we actually consider an equivalent model of Grammar Vector Addition Systems (GVAS).","We prove the main result by showing that for every one-dimensional GVAS (1-GVAS) one can compute another 1-GVAS, which has the same reachability relation as the original one and additionally has the so-called thin property.","Due to the work of Atig and Ganty from 2011, thin 1-GVAS have decidable reachability problem, therefore our construction implies decidability of the problem for all 1-GVAS.","Moreover, we also show that if reachability in thin 1-GVAS can be decided in elementary time then also reachability in all 1-GVAS can be decided in elementary time."],"url":"http://arxiv.org/abs/2411.02386v1"}
{"created":"2024-11-04 18:53:05","title":"How Far is Video Generation from World Model: A Physical Law Perspective","abstract":"OpenAI's Sora highlights the potential of video generation for developing world models that adhere to fundamental physical laws. However, the ability of video generation models to discover such laws purely from visual data without human priors can be questioned. A world model learning the true law should give predictions robust to nuances and correctly extrapolate on unseen scenarios. In this work, we evaluate across three key scenarios: in-distribution, out-of-distribution, and combinatorial generalization. We developed a 2D simulation testbed for object movement and collisions to generate videos deterministically governed by one or more classical mechanics laws. This provides an unlimited supply of data for large-scale experimentation and enables quantitative evaluation of whether the generated videos adhere to physical laws. We trained diffusion-based video generation models to predict object movements based on initial frames. Our scaling experiments show perfect generalization within the distribution, measurable scaling behavior for combinatorial generalization, but failure in out-of-distribution scenarios. Further experiments reveal two key insights about the generalization mechanisms of these models: (1) the models fail to abstract general physical rules and instead exhibit \"case-based\" generalization behavior, i.e., mimicking the closest training example; (2) when generalizing to new cases, models are observed to prioritize different factors when referencing training data: color > size > velocity > shape. Our study suggests that scaling alone is insufficient for video generation models to uncover fundamental physical laws, despite its role in Sora's broader success. See our project page at https://phyworld.github.io","sentences":["OpenAI's Sora highlights the potential of video generation for developing world models that adhere to fundamental physical laws.","However, the ability of video generation models to discover such laws purely from visual data without human priors can be questioned.","A world model learning the true law should give predictions robust to nuances and correctly extrapolate on unseen scenarios.","In this work, we evaluate across three key scenarios: in-distribution, out-of-distribution, and combinatorial generalization.","We developed a 2D simulation testbed for object movement and collisions to generate videos deterministically governed by one or more classical mechanics laws.","This provides an unlimited supply of data for large-scale experimentation and enables quantitative evaluation of whether the generated videos adhere to physical laws.","We trained diffusion-based video generation models to predict object movements based on initial frames.","Our scaling experiments show perfect generalization within the distribution, measurable scaling behavior for combinatorial generalization, but failure in out-of-distribution scenarios.","Further experiments reveal two key insights about the generalization mechanisms of these models: (1) the models fail to abstract general physical rules and instead exhibit \"case-based\" generalization behavior, i.e., mimicking the closest training example; (2) when generalizing to new cases, models are observed to prioritize different factors when referencing training data: color > size > velocity > shape.","Our study suggests that scaling alone is insufficient for video generation models to uncover fundamental physical laws, despite its role in Sora's broader success.","See our project page at https://phyworld.github.io"],"url":"http://arxiv.org/abs/2411.02385v1"}
{"created":"2024-11-04 18:50:00","title":"Improving Scientific Hypothesis Generation with Knowledge Grounded Large Language Models","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities in various scientific domains, from natural language processing to complex problem-solving tasks. Their ability to understand and generate human-like text has opened up new possibilities for advancing scientific research, enabling tasks such as data analysis, literature review, and even experimental design. One of the most promising applications of LLMs in this context is hypothesis generation, where they can identify novel research directions by analyzing existing knowledge. However, despite their potential, LLMs are prone to generating ``hallucinations'', outputs that are plausible-sounding but factually incorrect. Such a problem presents significant challenges in scientific fields that demand rigorous accuracy and verifiability, potentially leading to erroneous or misleading conclusions. To overcome these challenges, we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that enhances LLM hypothesis generation by integrating external, structured knowledge from knowledge graphs (KGs). KG-CoI guides LLMs through a structured reasoning process, organizing their output as a chain of ideas (CoI), and includes a KG-supported module for the detection of hallucinations. With experiments on our newly constructed hypothesis generation dataset, we demonstrate that KG-CoI not only improves the accuracy of LLM-generated hypotheses but also reduces the hallucination in their reasoning chains, highlighting its effectiveness in advancing real-world scientific research.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities in various scientific domains, from natural language processing to complex problem-solving tasks.","Their ability to understand and generate human-like text has opened up new possibilities for advancing scientific research, enabling tasks such as data analysis, literature review, and even experimental design.","One of the most promising applications of LLMs in this context is hypothesis generation, where they can identify novel research directions by analyzing existing knowledge.","However, despite their potential, LLMs are prone to generating ``hallucinations'', outputs that are plausible-sounding but factually incorrect.","Such a problem presents significant challenges in scientific fields that demand rigorous accuracy and verifiability, potentially leading to erroneous or misleading conclusions.","To overcome these challenges, we propose KG-CoI (Knowledge Grounded Chain of Ideas), a novel system that enhances LLM hypothesis generation by integrating external, structured knowledge from knowledge graphs (KGs).","KG-CoI guides LLMs through a structured reasoning process, organizing their output as a chain of ideas (CoI), and includes a KG-supported module for the detection of hallucinations.","With experiments on our newly constructed hypothesis generation dataset, we demonstrate that KG-CoI not only improves the accuracy of LLM-generated hypotheses but also reduces the hallucination in their reasoning chains, highlighting its effectiveness in advancing real-world scientific research."],"url":"http://arxiv.org/abs/2411.02382v1"}
{"created":"2024-11-04 18:49:46","title":"Addressing Uncertainty in LLMs to Enhance Reliability in Generative AI","abstract":"In this paper, we present a dynamic semantic clustering approach inspired by the Chinese Restaurant Process, aimed at addressing uncertainty in the inference of Large Language Models (LLMs). We quantify uncertainty of an LLM on a given query by calculating entropy of the generated semantic clusters. Further, we propose leveraging the (negative) likelihood of these clusters as the (non)conformity score within Conformal Prediction framework, allowing the model to predict a set of responses instead of a single output, thereby accounting for uncertainty in its predictions. We demonstrate the effectiveness of our uncertainty quantification (UQ) technique on two well known question answering benchmarks, COQA and TriviaQA, utilizing two LLMs, Llama2 and Mistral. Our approach achieves SOTA performance in UQ, as assessed by metrics such as AUROC, AUARC, and AURAC. The proposed conformal predictor is also shown to produce smaller prediction sets while maintaining the same probabilistic guarantee of including the correct response, in comparison to existing SOTA conformal prediction baseline.","sentences":["In this paper, we present a dynamic semantic clustering approach inspired by the Chinese Restaurant Process, aimed at addressing uncertainty in the inference of Large Language Models (LLMs).","We quantify uncertainty of an LLM on a given query by calculating entropy of the generated semantic clusters.","Further, we propose leveraging the (negative) likelihood of these clusters as the (non)conformity score within Conformal Prediction framework, allowing the model to predict a set of responses instead of a single output, thereby accounting for uncertainty in its predictions.","We demonstrate the effectiveness of our uncertainty quantification (UQ) technique on two well known question answering benchmarks, COQA and TriviaQA, utilizing two LLMs, Llama2 and Mistral.","Our approach achieves SOTA performance in UQ, as assessed by metrics such as AUROC, AUARC, and AURAC.","The proposed conformal predictor is also shown to produce smaller prediction sets while maintaining the same probabilistic guarantee of including the correct response, in comparison to existing SOTA conformal prediction baseline."],"url":"http://arxiv.org/abs/2411.02381v1"}
{"created":"2024-11-04 18:44:56","title":"Two-Sided Learning in Decentralized Matching Markets","abstract":"Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications. In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups. However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another. In this work, we design completely uncoupled and uncoordinated policies that use an agent's limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences. In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets. Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy. We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group. To the best of the authors' knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty.","sentences":["Two-sided matching markets, environments in which two disjoint groups of agents seek to partner with one another, arise in many practical applications.","In settings where the agents can assess the quality of their possible partners a priori, well-known centralized algorithms can be used to find desirable matchings between the two groups.","However, when they do not know their own preferences, such algorithms are no longer applicable and agents must instead learn their preferences through repeated interactions with one another.","In this work, we design completely uncoupled and uncoordinated policies that use an agent's limited historical observations to guide their behavior towards desirable matchings when they do not know their preferences.","In our first main contribution, we demonstrate that when every agent follows a simple policy which we call trial-and-error learning, they will converge to a stable matching, the standard equilibrium configuration in matching markets.","Then, we evaluate the strategyproofness of this policy and ask whether one group of agents can improve their performance by following a different policy.","We constructively answer this question in the affirmative, demonstrating that if one group follows simple trial-and-error learning while the second group follows a more advanced policy, then they will converge to the most preferable stable matching for the second group.","To the best of the authors' knowledge, these are the first completely uncoupled and uncoordinated policies that demonstrate any notion of convergence to stability in decentralized markets with two-sided uncertainty."],"url":"http://arxiv.org/abs/2411.02377v1"}
{"created":"2024-11-04 18:43:29","title":"Identifying Economic Factors Affecting Unemployment Rates in the United States","abstract":"In this study, we seek to understand how macroeconomic factors such as GDP, inflation, Unemployment Insurance, and S&P 500 index; as well as microeconomic factors such as health, race, and educational attainment impacted the unemployment rate for about 20 years in the United States. Our research question is to identify which factor(s) contributed the most to the unemployment rate surge using linear regression. Results from our studies showed that GDP (negative), inflation (positive), Unemployment Insurance (contrary to popular opinion; negative), and S&P 500 index (negative) were all significant factors, with inflation being the most important one. As for health issue factors, our model produced resultant correlation scores for occurrences of Cardiovascular Disease, Neurological Disease, and Interpersonal Violence with unemployment. Race as a factor showed a huge discrepancies in the unemployment rate between Black Americans compared to their counterparts. Asians had the lowest unemployment rate throughout the years. As for education attainment, results showed that having a higher education attainment significantly reduced one chance of unemployment. People with higher degrees had the lowest unemployment rate. Results of this study will be beneficial for policymakers and researchers in understanding the unemployment rate during the pandemic.","sentences":["In this study, we seek to understand how macroeconomic factors such as GDP, inflation, Unemployment Insurance, and S&P 500 index; as well as microeconomic factors such as health, race, and educational attainment impacted the unemployment rate for about 20 years in the United States.","Our research question is to identify which factor(s) contributed the most to the unemployment rate surge using linear regression.","Results from our studies showed that GDP (negative), inflation (positive), Unemployment Insurance (contrary to popular opinion; negative), and S&P 500 index (negative) were all significant factors, with inflation being the most important one.","As for health issue factors, our model produced resultant correlation scores for occurrences of Cardiovascular Disease, Neurological Disease, and Interpersonal Violence with unemployment.","Race as a factor showed a huge discrepancies in the unemployment rate between Black Americans compared to their counterparts.","Asians had the lowest unemployment rate throughout the years.","As for education attainment, results showed that having a higher education attainment significantly reduced one chance of unemployment.","People with higher degrees had the lowest unemployment rate.","Results of this study will be beneficial for policymakers and researchers in understanding the unemployment rate during the pandemic."],"url":"http://arxiv.org/abs/2411.02374v1"}
{"created":"2024-11-04 18:40:46","title":"Learning General-Purpose Biomedical Volume Representations using Randomized Synthesis","abstract":"Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols. We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself. We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts. To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization. This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets. As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images.","sentences":["Current volumetric biomedical foundation models struggle to generalize as public 3D datasets are small and do not cover the broad diversity of medical procedures, conditions, anatomical regions, and imaging protocols.","We address this by creating a representation learning method that instead anticipates strong domain shifts at training time itself.","We first propose a data engine that synthesizes highly variable training samples that enable generalization to new biomedical contexts.","To then train a single 3D network for any voxel-level task, we develop a contrastive learning method that pretrains the network to be stable against nuisance imaging variation simulated by the data engine, a key inductive bias for generalization.","This network's features can be used as robust representations of input images for downstream tasks and its weights provide a strong, dataset-agnostic initialization for finetuning on new datasets.","As a result, we set new standards across both multimodality registration and few-shot segmentation, a first for any 3D biomedical vision model, all without (pre-)training on any existing dataset of real images."],"url":"http://arxiv.org/abs/2411.02372v1"}
{"created":"2024-11-04 18:26:08","title":"DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution","abstract":"MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data. These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks. However, developing MLLMs for real-world robots is challenging due to the typically limited computation and memory capacities available on robotic platforms. In contrast, the inference of MLLMs involves storing billions of parameters and performing tremendous computation, imposing significant hardware demands. In our paper, we propose a Dynamic Early-Exit Framework for Robotic Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically adjusts the size of the activated MLLM based on each situation at hand. The approach leverages a multi-exit architecture in MLLMs, which allows the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation. Additionally, we develop novel algorithms that establish early-termination criteria for DeeR, conditioned on predefined demands such as average computational cost (i.e., power consumption), as well as peak computational consumption (i.e., latency) and GPU memory usage. These enhancements ensure that DeeR operates efficiently under varying resource constraints while maintaining competitive performance. On the CALVIN robot manipulation benchmark, DeeR demonstrates significant reductions in computational costs of LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance. Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA.","sentences":["MLLMs have demonstrated remarkable comprehension and reasoning capabilities with complex language and visual data.","These advances have spurred the vision of establishing a generalist robotic MLLM proficient in understanding complex human instructions and accomplishing various embodied tasks.","However, developing MLLMs for real-world robots is challenging due to the typically limited computation and memory capacities available on robotic platforms.","In contrast, the inference of MLLMs involves storing billions of parameters and performing tremendous computation, imposing significant hardware demands.","In our paper, we propose a Dynamic Early-Exit Framework for Robotic Vision-Language-Action Model (DeeR-VLA, or simply DeeR) that automatically adjusts the size of the activated MLLM based on each situation at hand.","The approach leverages a multi-exit architecture in MLLMs, which allows the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation.","Additionally, we develop novel algorithms that establish early-termination criteria for DeeR, conditioned on predefined demands such as average computational cost (i.e., power consumption), as well as peak computational consumption (i.e., latency) and GPU memory usage.","These enhancements ensure that DeeR operates efficiently under varying resource constraints while maintaining competitive performance.","On the CALVIN robot manipulation benchmark, DeeR demonstrates significant reductions in computational costs of LLM by 5.2-6.5x and GPU memory of LLM by 2-6x without compromising performance.","Code and checkpoints are available at https://github.com/yueyang130/DeeR-VLA."],"url":"http://arxiv.org/abs/2411.02359v1"}
{"created":"2024-11-04 18:21:59","title":"\"Give Me BF16 or Give Me Death\"? Accuracy-Performance Trade-Offs in LLM Quantization","abstract":"Despite the popularity of large language model (LLM) quantization for inference acceleration, significant uncertainty remains regarding the accuracy-performance trade-offs associated with various quantization formats. We present a comprehensive empirical study of quantized accuracy, evaluating popular quantization formats (FP8, INT8, INT4) across academic benchmarks and real-world tasks, on the entire Llama-3.1 model family. Additionally, our study examines the difference in text generated by quantized models versus their uncompressed counterparts. Beyond benchmarks, we also present a couple of quantization improvements which allowed us to obtain state-of-the-art accuracy recovery results. Our investigation, encompassing over 500,000 individual evaluations, yields several key findings: (1) FP8 weight and activation quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and activation quantization (W8A8-INT), when properly tuned, incurs surprisingly low 1-3% accuracy degradation, and (3) INT4 weight-only quantization (W4A16-INT) is competitive with 8-bit integer weight and activation quantization. To address the question of the \"best\" format for a given deployment environment, we conduct inference performance analysis using the popular open-source vLLM framework on various GPU architectures. We find that W4A16 offers the best cost-efficiency for synchronous deployments, and for asynchronous deployment on mid-tier GPUs. At the same time, W8A8 formats excel in asynchronous \"continuous batching\" deployment of mid- and large-size models on high-end GPUs. Our results provide a set of practical guidelines for deploying quantized LLMs across scales and performance requirements.","sentences":["Despite the popularity of large language model (LLM) quantization for inference acceleration, significant uncertainty remains regarding the accuracy-performance trade-offs associated with various quantization formats.","We present a comprehensive empirical study of quantized accuracy, evaluating popular quantization formats (FP8, INT8, INT4) across academic benchmarks and real-world tasks, on the entire Llama-3.1 model family.","Additionally, our study examines the difference in text generated by quantized models versus their uncompressed counterparts.","Beyond benchmarks, we also present a couple of quantization improvements which allowed us to obtain state-of-the-art accuracy recovery results.","Our investigation, encompassing over 500,000 individual evaluations, yields several key findings: (1) FP8 weight and activation quantization (W8A8-FP) is lossless across all model scales, (2) INT8 weight and activation quantization (W8A8-INT), when properly tuned, incurs surprisingly low 1-3% accuracy degradation, and (3) INT4 weight-only quantization (W4A16-INT) is competitive with 8-bit integer weight and activation quantization.","To address the question of the \"best\" format for a given deployment environment, we conduct inference performance analysis using the popular open-source vLLM framework on various GPU architectures.","We find that W4A16 offers the best cost-efficiency for synchronous deployments, and for asynchronous deployment on mid-tier GPUs.","At the same time, W8A8 formats excel in asynchronous \"continuous batching\" deployment of mid- and large-size models on high-end GPUs.","Our results provide a set of practical guidelines for deploying quantized LLMs across scales and performance requirements."],"url":"http://arxiv.org/abs/2411.02355v1"}
{"created":"2024-11-04 18:21:56","title":"Machine learning identification of maternal inflammatory response and histologic choroamnionitis from placental membrane whole slide images","abstract":"The placenta forms a critical barrier to infection through pregnancy, labor and, delivery. Inflammatory processes in the placenta have short-term, and long-term consequences for offspring health. Digital pathology and machine learning can play an important role in understanding placental inflammation, and there have been very few investigations into methods for predicting and understanding Maternal Inflammatory Response (MIR). This work intends to investigate the potential of using machine learning to understand MIR based on whole slide images (WSI), and establish early benchmarks. To that end, we use Multiple Instance Learning framework with 3 feature extractors: ImageNet-based EfficientNet-v2s, and 2 histopathology foundation models, UNI and Phikon to investigate predictability of MIR stage from histopathology WSIs. We also interpret predictions from these models using the learned attention maps from these models. We also use the MIL framework for predicting white blood cells count (WBC) and maximum fever temperature ($T_{max}$). Attention-based MIL models are able to classify MIR with a balanced accuracy of up to 88.5% with a Cohen's Kappa ($\\kappa$) of up to 0.772. Furthermore, we found that the pathology foundation models (UNI and Phikon) are both able to achieve higher performance with balanced accuracy and $\\kappa$, compared to ImageNet-based feature extractor (EfficientNet-v2s). For WBC and $T_{max}$ prediction, we found mild correlation between actual values and those predicted from histopathology WSIs. We used MIL framework for predicting MIR stage from WSIs, and compared effectiveness of foundation models as feature extractors, with that of an ImageNet-based model. We further investigated model failure cases and found them to be either edge cases prone to interobserver variability, examples of pathologist's overreach, or mislabeled due to processing errors.","sentences":["The placenta forms a critical barrier to infection through pregnancy, labor and, delivery.","Inflammatory processes in the placenta have short-term, and long-term consequences for offspring health.","Digital pathology and machine learning can play an important role in understanding placental inflammation, and there have been very few investigations into methods for predicting and understanding Maternal Inflammatory Response (MIR).","This work intends to investigate the potential of using machine learning to understand MIR based on whole slide images (WSI), and establish early benchmarks.","To that end, we use Multiple Instance Learning framework with 3 feature extractors: ImageNet-based EfficientNet-v2s, and 2 histopathology foundation models, UNI and Phikon to investigate predictability of MIR stage from histopathology WSIs.","We also interpret predictions from these models using the learned attention maps from these models.","We also use the MIL framework for predicting white blood cells count (WBC) and maximum fever temperature ($T_{max}$).","Attention-based MIL models are able to classify MIR with a balanced accuracy of up to 88.5% with a Cohen's Kappa ($\\kappa$) of up to 0.772.","Furthermore, we found that the pathology foundation models (UNI and Phikon) are both able to achieve higher performance with balanced accuracy and $\\kappa$, compared to ImageNet-based feature extractor (EfficientNet-v2s).","For WBC and $T_{max}$ prediction, we found mild correlation between actual values and those predicted from histopathology WSIs.","We used MIL framework for predicting MIR stage from WSIs, and compared effectiveness of foundation models as feature extractors, with that of an ImageNet-based model.","We further investigated model failure cases and found them to be either edge cases prone to interobserver variability, examples of pathologist's overreach, or mislabeled due to processing errors."],"url":"http://arxiv.org/abs/2411.02354v1"}
{"created":"2024-11-04 18:21:53","title":"Social-RAG: Retrieving from Group Interactions to Socially Ground Proactive AI Generation to Group Preferences","abstract":"AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, but can be unhelpful or even annoying, due to not fitting the group's preferences or behaving in socially inappropriate ways. Fortunately, group spaces have a rich history of prior social interactions and affordances for social feedback to support creating agents that align to a group's interests and norms. We present Social-RAG, a workflow for grounding agents to social information about a group, which retrieves from prior group interactions, selects relevant social signals, and then feeds the context into a large language model to generate messages to the group. We implement this into PaperPing, our system that posts academic paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers. From a three-month deployment in 18 channels, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground.","sentences":["AI agents are increasingly tasked with making proactive suggestions in online spaces where groups collaborate, but can be unhelpful or even annoying, due to not fitting the group's preferences or behaving in socially inappropriate ways.","Fortunately, group spaces have a rich history of prior social interactions and affordances for social feedback to support creating agents that align to a group's interests and norms.","We present Social-RAG, a workflow for grounding agents to social information about a group, which retrieves from prior group interactions, selects relevant social signals, and then feeds the context into a large language model to generate messages to the group.","We implement this into PaperPing, our system that posts academic paper recommendations in group chat, leveraging social signals determined from formative studies with 39 researchers.","From a three-month deployment in 18 channels, we observed PaperPing posted relevant messages in groups without disrupting their existing social practices, fostering group common ground."],"url":"http://arxiv.org/abs/2411.02353v1"}
{"created":"2024-11-04 18:18:38","title":"Can Large Language Models generalize analogy solving like people can?","abstract":"When we solve an analogy we transfer information from a known context to a new one through abstract rules and relational similarity. In people, the ability to solve analogies such as \"body : feet :: table : ?\" emerges in childhood, and appears to transfer easily to other domains, such as the visual domain \"( : ) :: < : ?\". Recent research shows that large language models (LLMs) can solve various forms of analogies. However, can LLMs generalize analogy solving to new domains like people can? To investigate this, we had children, adults, and LLMs solve a series of letter-string analogies (e.g., a b : a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek alphabet), and a far transfer domain (list of symbols). As expected, children and adults easily generalized their knowledge to unfamiliar domains, whereas LLMs did not. This key difference between human and AI performance is evidence that these LLMs still struggle with robust human-like analogical transfer.","sentences":["When we solve an analogy we transfer information from a known context to a new one through abstract rules and relational similarity.","In people, the ability to solve analogies such as \"body : feet :: table : ?\" emerges in childhood, and appears to transfer easily to other domains, such as the visual domain \"( : ) :: < : ?\".","Recent research shows that large language models (LLMs) can solve various forms of analogies.","However, can LLMs generalize analogy solving to new domains like people can?","To investigate this, we had children, adults, and LLMs solve a series of letter-string analogies (e.g., a b : a c :: j k : ?) in the Latin alphabet, in a near transfer domain (Greek alphabet), and a far transfer domain (list of symbols).","As expected, children and adults easily generalized their knowledge to unfamiliar domains, whereas LLMs did not.","This key difference between human and AI performance is evidence that these LLMs still struggle with robust human-like analogical transfer."],"url":"http://arxiv.org/abs/2411.02348v1"}
{"created":"2024-11-04 18:17:44","title":"Physically Based Neural Bidirectional Reflectance Distribution Function","abstract":"We introduce the physically based neural bidirectional reflectance distribution function (PBNBRDF), a novel, continuous representation for material appearance based on neural fields. Our model accurately reconstructs real-world materials while uniquely enforcing physical properties for realistic BRDFs, specifically Helmholtz reciprocity via reparametrization and energy passivity via efficient analytical integration. We conduct a systematic analysis demonstrating the benefits of adhering to these physical laws on the visual quality of reconstructed materials. Additionally, we enhance the color accuracy of neural BRDFs by introducing chromaticity enforcement supervising the norms of RGB channels. Through both qualitative and quantitative experiments on multiple databases of measured real-world BRDFs, we show that adhering to these physical constraints enables neural fields to more faithfully and stably represent the original data and achieve higher rendering quality.","sentences":["We introduce the physically based neural bidirectional reflectance distribution function (PBNBRDF), a novel, continuous representation for material appearance based on neural fields.","Our model accurately reconstructs real-world materials while uniquely enforcing physical properties for realistic BRDFs, specifically Helmholtz reciprocity via reparametrization and energy passivity via efficient analytical integration.","We conduct a systematic analysis demonstrating the benefits of adhering to these physical laws on the visual quality of reconstructed materials.","Additionally, we enhance the color accuracy of neural BRDFs by introducing chromaticity enforcement supervising the norms of RGB channels.","Through both qualitative and quantitative experiments on multiple databases of measured real-world BRDFs, we show that adhering to these physical constraints enables neural fields to more faithfully and stably represent the original data and achieve higher rendering quality."],"url":"http://arxiv.org/abs/2411.02347v1"}
{"created":"2024-11-04 18:16:40","title":"Simulation of Nanorobots with Artificial Intelligence and Reinforcement Learning for Advanced Cancer Cell Detection and Tracking","abstract":"Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB). These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease. Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis. This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers. We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers. The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery. This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments. The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients. Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare.","sentences":["Nanorobots are a promising development in targeted drug delivery and the treatment of neurological disorders, with potential for crossing the blood-brain barrier (BBB).","These small devices leverage advancements in nanotechnology and bioengineering for precise navigation and targeted payload delivery, particularly for conditions like brain tumors, Alzheimer's disease, and Parkinson's disease.","Recent progress in artificial intelligence (AI) and machine learning (ML) has improved the navigation and effectiveness of nanorobots, allowing them to detect and interact with cancer cells through biomarker analysis.","This study presents a new reinforcement learning (RL) framework for optimizing nanorobot navigation in complex biological environments, focusing on cancer cell detection by analyzing the concentration gradients of surrounding biomarkers.","We utilize a computer simulation model to explore the behavior of nanorobots in a three-dimensional space with cancer cells and biological barriers.","The proposed method uses Q-learning to refine movement strategies based on real-time biomarker concentration data, enabling nanorobots to autonomously navigate to cancerous tissues for targeted drug delivery.","This research lays the groundwork for future laboratory experiments and clinical applications, with implications for personalized medicine and less invasive cancer treatments.","The integration of intelligent nanorobots could revolutionize therapeutic strategies, reducing side effects and enhancing treatment effectiveness for cancer patients.","Further research will investigate the practical deployment of these technologies in medical settings, aiming to unlock the full potential of nanorobotics in healthcare."],"url":"http://arxiv.org/abs/2411.02345v1"}
{"created":"2024-11-04 18:14:07","title":"Seq-VCR: Preventing Collapse in Intermediate Transformer Representations for Enhanced Reasoning","abstract":"Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations. In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities. To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse. Combined with dummy pause tokens as substitutes for chain-of-thought (CoT) tokens, our method significantly improves performance in arithmetic reasoning problems. In the challenging $5 \\times 5$ integer multiplication task, our approach achieves $99.5\\%$ exact match accuracy, outperforming models of the same size (which yield $0\\%$ accuracy) and GPT-4 with five-shot CoT prompting ($44\\%$). We also demonstrate superior results on arithmetic expression and longest increasing subsequence (LIS) datasets. Our findings highlight the importance of preventing intermediate layer representation collapse to enhance the reasoning capabilities of Transformers and show that Seq-VCR offers an effective solution without requiring explicit CoT supervision.","sentences":["Decoder-only Transformers often struggle with complex reasoning tasks, particularly arithmetic reasoning requiring multiple sequential operations.","In this work, we identify representation collapse in the model's intermediate layers as a key factor limiting their reasoning capabilities.","To address this, we propose Sequential Variance-Covariance Regularization (Seq-VCR), which enhances the entropy of intermediate representations and prevents collapse.","Combined with dummy pause tokens as substitutes for chain-of-thought (CoT) tokens, our method significantly improves performance in arithmetic reasoning problems.","In the challenging $5 \\times 5$ integer multiplication task, our approach achieves $99.5\\%$ exact match accuracy, outperforming models of the same size (which yield $0\\%$ accuracy) and GPT-4 with five-shot CoT prompting ($44\\%$).","We also demonstrate superior results on arithmetic expression and longest increasing subsequence (LIS) datasets.","Our findings highlight the importance of preventing intermediate layer representation collapse to enhance the reasoning capabilities of Transformers and show that Seq-VCR offers an effective solution without requiring explicit CoT supervision."],"url":"http://arxiv.org/abs/2411.02344v1"}
{"created":"2024-11-04 18:12:59","title":"Boulder2Vec: Modeling Climber Performances in Professional Bouldering Competitions","abstract":"Using data from professional bouldering competitions from 2008 to 2022, we train a logistic regression to predict climber results and measure climber skill. However, this approach is limited, as a single numeric coefficient per climber cannot adequately capture the intricacies of climbers' varying strengths and weaknesses in different boulder problems. For example, some climbers might prefer more static, technical routes while other climbers may specialize in powerful, dynamic problems.   To this end, we apply Probabilistic Matrix Factorization (PMF), a framework commonly used in recommender systems, to represent the unique characteristics of climbers and problems with latent, multi-dimensional vectors. In this framework, a climber's performance on a given problem is predicted by taking the dot product of the corresponding climber vector and problem vectors. PMF effectively handles sparse datasets, such as our dataset where only a subset of climbers attempt each particular problem, by extrapolating patterns from similar climbers.   We contrast the empirical performance of PMF to the logistic regression approach and investigate the multivariate representations produced by PMF to gain insights into climber characteristics. Our results show that the multivariate PMF representations improve predictive performance of professional bouldering competitions by capturing both the overall strength of climbers and their specialized skill sets.","sentences":["Using data from professional bouldering competitions from 2008 to 2022, we train a logistic regression to predict climber results and measure climber skill.","However, this approach is limited, as a single numeric coefficient per climber cannot adequately capture the intricacies of climbers' varying strengths and weaknesses in different boulder problems.","For example, some climbers might prefer more static, technical routes while other climbers may specialize in powerful, dynamic problems.   ","To this end, we apply Probabilistic Matrix Factorization (PMF), a framework commonly used in recommender systems, to represent the unique characteristics of climbers and problems with latent, multi-dimensional vectors.","In this framework, a climber's performance on a given problem is predicted by taking the dot product of the corresponding climber vector and problem vectors.","PMF effectively handles sparse datasets, such as our dataset where only a subset of climbers attempt each particular problem, by extrapolating patterns from similar climbers.   ","We contrast the empirical performance of PMF to the logistic regression approach and investigate the multivariate representations produced by PMF to gain insights into climber characteristics.","Our results show that the multivariate PMF representations improve predictive performance of professional bouldering competitions by capturing both the overall strength of climbers and their specialized skill sets."],"url":"http://arxiv.org/abs/2411.02343v1"}
{"created":"2024-11-04 17:59:58","title":"WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning","abstract":"Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks. However, existing LLM web agents heavily rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities. This paper introduces WebRL, a self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs. WebRL addresses three key challenges in building LLM web agents, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning. Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements. We apply WebRL to transform open Llama-3.1 and GLM-4 models into proficient web agents. On WebArena-Lite, WebRL improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B. These open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%). Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems.","sentences":["Large language models (LLMs) have shown remarkable potential as autonomous agents, particularly in web-based tasks.","However, existing LLM web agents heavily rely on expensive proprietary LLM APIs, while open LLMs lack the necessary decision-making capabilities.","This paper introduces WebRL, a self-evolving online curriculum reinforcement learning framework designed to train high-performance web agents using open LLMs.","WebRL addresses three key challenges in building LLM web agents, including the scarcity of training tasks, sparse feedback signals, and policy distribution drift in online learning.","Specifically, WebRL incorporates 1) a self-evolving curriculum that generates new tasks from unsuccessful attempts, 2) a robust outcome-supervised reward model (ORM), and 3) adaptive reinforcement learning strategies to ensure consistent improvements.","We apply WebRL to transform open Llama-3.1 and GLM-4 models into proficient web agents.","On WebArena-Lite, WebRL improves the success rate of Llama-3.1-8B from 4.8% to 42.4%, and from 6.1% to 43% for GLM-4-9B. These open models significantly surpass the performance of GPT-4-Turbo (17.6%) and GPT-4o (13.9%) and outperform previous state-of-the-art web agents trained on open LLMs (AutoWebGLM, 18.2%).","Our findings demonstrate WebRL's effectiveness in bridging the gap between open and proprietary LLM-based web agents, paving the way for more accessible and powerful autonomous web interaction systems."],"url":"http://arxiv.org/abs/2411.02337v1"}
{"created":"2024-11-04 17:59:39","title":"MVPaint: Synchronized Multi-View Diffusion for Painting Anything 3D","abstract":"Texturing is a crucial step in the 3D asset production workflow, which enhances the visual appeal and diversity of 3D assets. Despite recent advancements in Text-to-Texture (T2T) generation, existing methods often yield subpar results, primarily due to local discontinuities, inconsistencies across multiple views, and their heavy dependence on UV unwrapping outcomes. To tackle these challenges, we propose a novel generation-refinement 3D texturing framework called MVPaint, which can generate high-resolution, seamless textures while emphasizing multi-view consistency. MVPaint mainly consists of three key modules. 1) Synchronized Multi-view Generation (SMG). Given a 3D mesh model, MVPaint first simultaneously generates multi-view images by employing an SMG model, which leads to coarse texturing results with unpainted parts due to missing observations. 2) Spatial-aware 3D Inpainting (S3I). To ensure complete 3D texturing, we introduce the S3I method, specifically designed to effectively texture previously unobserved areas. 3) UV Refinement (UVR). Furthermore, MVPaint employs a UVR module to improve the texture quality in the UV space, which first performs a UV-space Super-Resolution, followed by a Spatial-aware Seam-Smoothing algorithm for revising spatial texturing discontinuities caused by UV unwrapping. Moreover, we establish two T2T evaluation benchmarks: the Objaverse T2T benchmark and the GSO T2T benchmark, based on selected high-quality 3D meshes from the Objaverse dataset and the entire GSO dataset, respectively. Extensive experimental results demonstrate that MVPaint surpasses existing state-of-the-art methods. Notably, MVPaint could generate high-fidelity textures with minimal Janus issues and highly enhanced cross-view consistency.","sentences":["Texturing is a crucial step in the 3D asset production workflow, which enhances the visual appeal and diversity of 3D assets.","Despite recent advancements in Text-to-Texture (T2T) generation, existing methods often yield subpar results, primarily due to local discontinuities, inconsistencies across multiple views, and their heavy dependence on UV unwrapping outcomes.","To tackle these challenges, we propose a novel generation-refinement 3D texturing framework called MVPaint, which can generate high-resolution, seamless textures while emphasizing multi-view consistency.","MVPaint mainly consists of three key modules.","1) Synchronized Multi-view Generation (SMG).","Given a 3D mesh model, MVPaint first simultaneously generates multi-view images by employing an SMG model, which leads to coarse texturing results with unpainted parts due to missing observations.","2) Spatial-aware 3D Inpainting (S3I).","To ensure complete 3D texturing, we introduce the S3I method, specifically designed to effectively texture previously unobserved areas.","3) UV Refinement (UVR).","Furthermore, MVPaint employs a UVR module to improve the texture quality in the UV space, which first performs a UV-space Super-Resolution, followed by a Spatial-aware Seam-Smoothing algorithm for revising spatial texturing discontinuities caused by UV unwrapping.","Moreover, we establish two T2T evaluation benchmarks: the Objaverse T2T benchmark and the GSO T2T benchmark, based on selected high-quality 3D meshes from the Objaverse dataset and the entire GSO dataset, respectively.","Extensive experimental results demonstrate that MVPaint surpasses existing state-of-the-art methods.","Notably, MVPaint could generate high-fidelity textures with minimal Janus issues and highly enhanced cross-view consistency."],"url":"http://arxiv.org/abs/2411.02336v1"}
{"created":"2024-11-04 17:59:04","title":"Sparsing Law: Towards Large Language Models with Greater Activation Sparsity","abstract":"Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs). Although promoting greater activation sparsity within LLMs deserves deep studies, existing works lack comprehensive and quantitative research on the correlation between activation sparsity and potentially influential factors. In this paper, we present a comprehensive study on the quantitative scaling properties and influential factors of the activation sparsity within decoder-only Transformer-based LLMs. Specifically, we propose PPL-$p\\%$ sparsity, a precise and performance-aware activation sparsity metric that is applicable to any activation function. Through extensive experiments, we find several important phenomena. Firstly, different activation functions exhibit comparable performance but opposite training-time sparsity trends. The activation ratio (i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing power-law and decreasing logspace power-law with the amount of training data for SiLU-activated and ReLU-activated LLMs, respectively. These demonstrate that ReLU is more efficient as the activation function than SiLU and can leverage more training data to improve activation sparsity. Secondly, the activation ratio linearly increases with the width-depth ratio below a certain bottleneck point, indicating the potential advantage of a deeper architecture at a fixed parameter scale. Finally, at similar width-depth ratios, we surprisingly find that the limit value of activation sparsity varies weakly with the parameter scale, i.e., the activation patterns within LLMs are insensitive to the parameter scale. These empirical laws towards LLMs with greater activation sparsity have important implications for making LLMs more efficient and interpretable.","sentences":["Activation sparsity denotes the existence of substantial weakly-contributed elements within activation outputs that can be eliminated, benefiting many important applications concerned with large language models (LLMs).","Although promoting greater activation sparsity within LLMs deserves deep studies, existing works lack comprehensive and quantitative research on the correlation between activation sparsity and potentially influential factors.","In this paper, we present a comprehensive study on the quantitative scaling properties and influential factors of the activation sparsity within decoder-only Transformer-based LLMs.","Specifically, we propose PPL-$p\\%$ sparsity, a precise and performance-aware activation sparsity metric that is applicable to any activation function.","Through extensive experiments, we find several important phenomena.","Firstly, different activation functions exhibit comparable performance but opposite training-time sparsity trends.","The activation ratio (i.e., $1-\\mathrm{sparsity\\ ratio}$) evolves as a convergent increasing power-law and decreasing logspace power-law with the amount of training data for SiLU-activated and ReLU-activated LLMs, respectively.","These demonstrate that ReLU is more efficient as the activation function than SiLU and can leverage more training data to improve activation sparsity.","Secondly, the activation ratio linearly increases with the width-depth ratio below a certain bottleneck point, indicating the potential advantage of a deeper architecture at a fixed parameter scale.","Finally, at similar width-depth ratios, we surprisingly find that the limit value of activation sparsity varies weakly with the parameter scale, i.e., the activation patterns within LLMs are insensitive to the parameter scale.","These empirical laws towards LLMs with greater activation sparsity have important implications for making LLMs more efficient and interpretable."],"url":"http://arxiv.org/abs/2411.02335v1"}
{"created":"2024-11-04 17:58:54","title":"Diffusion-based Generative Multicasting with Intent-aware Semantic Decomposition","abstract":"Generative diffusion models (GDMs) have recently shown great success in synthesizing multimedia signals with high perceptual quality enabling highly efficient semantic communications in future wireless networks. In this paper, we develop an intent-aware generative semantic multicasting framework utilizing pre-trained diffusion models. In the proposed framework, the transmitter decomposes the source signal to multiple semantic classes based on the multi-user intent, i.e. each user is assumed to be interested in details of only a subset of the semantic classes. The transmitter then sends to each user only its intended classes, and multicasts a highly compressed semantic map to all users over shared wireless resources that allows them to locally synthesize the other classes, i.e. non-intended classes, utilizing pre-trained diffusion models. The signal retrieved at each user is thereby partially reconstructed and partially synthesized utilizing the received semantic map. This improves utilization of the wireless resources, with better preserving privacy of the non-intended classes. We design a communication/computation-aware scheme for per-class adaptation of the communication parameters, such as the transmission power and compression rate to minimize the total latency of retrieving signals at multiple receivers, tailored to the prevailing channel conditions as well as the users reconstruction/synthesis distortion/perception requirements. The simulation results demonstrate significantly reduced per-user latency compared with non-generative and intent-unaware multicasting benchmarks while maintaining high perceptual quality of the signals retrieved at the users.","sentences":["Generative diffusion models (GDMs) have recently shown great success in synthesizing multimedia signals with high perceptual quality enabling highly efficient semantic communications in future wireless networks.","In this paper, we develop an intent-aware generative semantic multicasting framework utilizing pre-trained diffusion models.","In the proposed framework, the transmitter decomposes the source signal to multiple semantic classes based on the multi-user intent, i.e. each user is assumed to be interested in details of only a subset of the semantic classes.","The transmitter then sends to each user only its intended classes, and multicasts a highly compressed semantic map to all users over shared wireless resources that allows them to locally synthesize the other classes, i.e. non-intended classes, utilizing pre-trained diffusion models.","The signal retrieved at each user is thereby partially reconstructed and partially synthesized utilizing the received semantic map.","This improves utilization of the wireless resources, with better preserving privacy of the non-intended classes.","We design a communication/computation-aware scheme for per-class adaptation of the communication parameters, such as the transmission power and compression rate to minimize the total latency of retrieving signals at multiple receivers, tailored to the prevailing channel conditions as well as the users reconstruction/synthesis distortion/perception requirements.","The simulation results demonstrate significantly reduced per-user latency compared with non-generative and intent-unaware multicasting benchmarks while maintaining high perceptual quality of the signals retrieved at the users."],"url":"http://arxiv.org/abs/2411.02334v1"}
{"created":"2024-11-04 17:58:10","title":"SplatOverflow: Asynchronous Hardware Troubleshooting","abstract":"As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware. However, there aren't established tools to support end-user hardware troubleshooting or routine maintenance. As a result, technical support for hardware remains ad-hoc and challenging to scale. Inspired by software troubleshooting workflows like StackOverflow, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow. SplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware. The scene comprises a 3D Gaussian Splat of the user's hardware registered onto the hardware's CAD model. The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions. With SplatOverflow, maintainers can directly address issues and author instructions in the user's workspace. The instructions define workflows that can easily be shared between users and recontextualized in new environments. In this paper, we describe the design of SplatOverflow, detail the workflows it enables, and illustrate its utility to different kinds of users. We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a user study.","sentences":["As tools for designing and manufacturing hardware become more accessible, smaller producers can develop and distribute novel hardware.","However, there aren't established tools to support end-user hardware troubleshooting or routine maintenance.","As a result, technical support for hardware remains ad-hoc and challenging to scale.","Inspired by software troubleshooting workflows like StackOverflow, we propose a workflow for asynchronous hardware troubleshooting: SplatOverflow.","SplatOverflow creates a novel boundary object, the SplatOverflow scene, that users reference to communicate about hardware.","The scene comprises a 3D Gaussian Splat of the user's hardware registered onto the hardware's CAD model.","The splat captures the current state of the hardware, and the registered CAD model acts as a referential anchor for troubleshooting instructions.","With SplatOverflow, maintainers can directly address issues and author instructions in the user's workspace.","The instructions define workflows that can easily be shared between users and recontextualized in new environments.","In this paper, we describe the design of SplatOverflow, detail the workflows it enables, and illustrate its utility to different kinds of users.","We also validate that non-experts can use SplatOverflow to troubleshoot common problems with a 3D printer in a user study."],"url":"http://arxiv.org/abs/2411.02332v1"}
{"created":"2024-11-04 17:57:57","title":"Taking AI Welfare Seriously","abstract":"In this report, we argue that there is a realistic possibility that some AI systems will be conscious and/or robustly agentic in the near future. That means that the prospect of AI welfare and moral patienthood, i.e. of AI systems with their own interests and moral significance, is no longer an issue only for sci-fi or the distant future. It is an issue for the near future, and AI companies and other actors have a responsibility to start taking it seriously. We also recommend three early steps that AI companies and other actors can take: They can (1) acknowledge that AI welfare is an important and difficult issue (and ensure that language model outputs do the same), (2) start assessing AI systems for evidence of consciousness and robust agency, and (3) prepare policies and procedures for treating AI systems with an appropriate level of moral concern. To be clear, our argument in this report is not that AI systems definitely are, or will be, conscious, robustly agentic, or otherwise morally significant. Instead, our argument is that there is substantial uncertainty about these possibilities, and so we need to improve our understanding of AI welfare and our ability to make wise decisions about this issue. Otherwise there is a significant risk that we will mishandle decisions about AI welfare, mistakenly harming AI systems that matter morally and/or mistakenly caring for AI systems that do not.","sentences":["In this report, we argue that there is a realistic possibility that some AI systems will be conscious and/or robustly agentic in the near future.","That means that the prospect of AI welfare and moral patienthood, i.e. of AI systems with their own interests and moral significance, is no longer an issue only for sci-fi or the distant future.","It is an issue for the near future, and AI companies and other actors have a responsibility to start taking it seriously.","We also recommend three early steps that AI companies and other actors can take: They can (1) acknowledge that AI welfare is an important and difficult issue (and ensure that language model outputs do the same), (2) start assessing AI systems for evidence of consciousness and robust agency, and (3) prepare policies and procedures for treating AI systems with an appropriate level of moral concern.","To be clear, our argument in this report is not that AI systems definitely are, or will be, conscious, robustly agentic, or otherwise morally significant.","Instead, our argument is that there is substantial uncertainty about these possibilities, and so we need to improve our understanding of AI welfare and our ability to make wise decisions about this issue.","Otherwise there is a significant risk that we will mishandle decisions about AI welfare, mistakenly harming AI systems that matter morally and/or mistakenly caring for AI systems that do not."],"url":"http://arxiv.org/abs/2411.00986v1"}
{"created":"2024-11-04 17:52:40","title":"Disrupting Test Development with AI Assistants","abstract":"Recent advancements in large language models, including GPT-4 and its variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT, and Tabnine, have significantly transformed software development. This paper analyzes how these innovations impact productivity and software test development metrics. These tools enable developers to generate complete software programs with minimal human intervention before deployment. However, thorough review and testing by developers are still crucial. Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for opensource modules. Our findings show that AI-generated tests are of equivalent quality to original tests, highlighting differences in usage and results among the tools. This research enhances the understanding and capabilities of AI-assistant tools in automated testing.","sentences":["Recent advancements in large language models, including GPT-4 and its variants, and Generative AI-assisted coding tools like GitHub Copilot, ChatGPT, and Tabnine, have significantly transformed software development.","This paper analyzes how these innovations impact productivity and software test development metrics.","These tools enable developers to generate complete software programs with minimal human intervention before deployment.","However, thorough review and testing by developers are still crucial.","Utilizing the Test Pyramid concept, which categorizes tests into unit, integration, and end-to-end tests, we evaluate three popular AI coding assistants by generating and comparing unit tests for opensource modules.","Our findings show that AI-generated tests are of equivalent quality to original tests, highlighting differences in usage and results among the tools.","This research enhances the understanding and capabilities of AI-assistant tools in automated testing."],"url":"http://arxiv.org/abs/2411.02328v1"}
{"created":"2024-11-04 17:50:36","title":"PPLLaVA: Varied Video Sequence Understanding With Prompt Guidance","abstract":"The past year has witnessed the significant advancement of video-based large language models. However, the challenge of developing a unified model for both short and long video understanding remains unresolved. Most existing video LLMs cannot handle hour-long videos, while methods custom for long videos tend to be ineffective for shorter videos and images. In this paper, we identify the key issue as the redundant content in videos. To address this, we propose a novel pooling strategy that simultaneously achieves token compression and instruction-aware visual feature aggregation. Our model is termed Prompt-guided Pooling LLaVA, or PPLLaVA for short. Specifically, PPLLaVA consists of three core components: the CLIP-based visual-prompt alignment that extracts visual information relevant to the user's instructions, the prompt-guided pooling that compresses the visual sequence to arbitrary scales using convolution-style pooling, and the clip context extension designed for lengthy prompt common in visual dialogue. Moreover, our codebase also integrates the most advanced video Direct Preference Optimization (DPO) and visual interleave training. Extensive experiments have validated the performance of our model. With superior throughput and only 1024 visual context, PPLLaVA achieves better results on image benchmarks as a video LLM, while achieving state-of-the-art performance across various video benchmarks, excelling in tasks ranging from caption generation to multiple-choice questions, and handling video lengths from seconds to hours. Codes have been available at https://github.com/farewellthree/PPLLaVA.","sentences":["The past year has witnessed the significant advancement of video-based large language models.","However, the challenge of developing a unified model for both short and long video understanding remains unresolved.","Most existing video LLMs cannot handle hour-long videos, while methods custom for long videos tend to be ineffective for shorter videos and images.","In this paper, we identify the key issue as the redundant content in videos.","To address this, we propose a novel pooling strategy that simultaneously achieves token compression and instruction-aware visual feature aggregation.","Our model is termed Prompt-guided Pooling LLaVA, or PPLLaVA for short.","Specifically, PPLLaVA consists of three core components: the CLIP-based visual-prompt alignment that extracts visual information relevant to the user's instructions, the prompt-guided pooling that compresses the visual sequence to arbitrary scales using convolution-style pooling, and the clip context extension designed for lengthy prompt common in visual dialogue.","Moreover, our codebase also integrates the most advanced video Direct Preference Optimization (DPO) and visual interleave training.","Extensive experiments have validated the performance of our model.","With superior throughput and only 1024 visual context, PPLLaVA achieves better results on image benchmarks as a video LLM, while achieving state-of-the-art performance across various video benchmarks, excelling in tasks ranging from caption generation to multiple-choice questions, and handling video lengths from seconds to hours.","Codes have been available at https://github.com/farewellthree/PPLLaVA."],"url":"http://arxiv.org/abs/2411.02327v1"}
{"created":"2024-11-04 17:48:19","title":"Non-parametric Inference for Diffusion Processes: A Computational Approach via Bayesian Inversion for PDEs","abstract":"In this paper, we present a theoretical and computational workflow for the non-parametric Bayesian inference of drift and diffusion functions of autonomous diffusion processes. We base the inference on the partial differential equations arising from the infinitesimal generator of the underlying process. Following a problem formulation in the infinite-dimensional setting, we discuss optimization- and sampling-based solution methods. As preliminary results, we showcase the inference of a single-scale, as well as a multiscale process from trajectory data.","sentences":["In this paper, we present a theoretical and computational workflow for the non-parametric Bayesian inference of drift and diffusion functions of autonomous diffusion processes.","We base the inference on the partial differential equations arising from the infinitesimal generator of the underlying process.","Following a problem formulation in the infinite-dimensional setting, we discuss optimization-","and sampling-based solution methods.","As preliminary results, we showcase the inference of a single-scale, as well as a multiscale process from trajectory data."],"url":"http://arxiv.org/abs/2411.02324v1"}
{"created":"2024-11-04 17:48:02","title":"Digital Twin-Assisted Federated Learning with Blockchain in Multi-tier Computing Systems","abstract":"In Industry 4.0 systems, a considerable number of resource-constrained Industrial Internet of Things (IIoT) devices engage in frequent data interactions due to the necessity for model training, which gives rise to concerns pertaining to security and privacy. In order to address these challenges, this paper considers a digital twin (DT) and blockchain-assisted federated learning (FL) scheme. To facilitate the FL process, we initially employ fog devices with abundant computational capabilities to generate DT for resource-constrained edge devices, thereby aiding them in local training. Subsequently, we formulate an FL delay minimization problem for FL, which considers both of model transmission time and synchronization time, also incorporates cooperative jamming to ensure secure synchronization of DT. To address this non-convex optimization problem, we propose a decomposition algorithm. In particular, we introduce upper limits on the local device training delay and the effects of aggregation jamming as auxiliary variables, thereby transforming the problem into a convex optimization problem that can be decomposed for independent solution. Finally, a blockchain verification mechanism is employed to guarantee the integrity of the model uploading throughout the FL process and the identities of the participants. The final global model is obtained from the verified local and global models within the blockchain through the application of deep learning techniques. The efficacy of our proposed cooperative interference-based FL process has been verified through numerical analysis, which demonstrates that the integrated DT blockchain-assisted FL scheme significantly outperforms the benchmark schemes in terms of execution time, block optimization, and accuracy.","sentences":["In Industry 4.0 systems, a considerable number of resource-constrained Industrial Internet of Things (IIoT) devices engage in frequent data interactions due to the necessity for model training, which gives rise to concerns pertaining to security and privacy.","In order to address these challenges, this paper considers a digital twin (DT) and blockchain-assisted federated learning (FL) scheme.","To facilitate the FL process, we initially employ fog devices with abundant computational capabilities to generate DT for resource-constrained edge devices, thereby aiding them in local training.","Subsequently, we formulate an FL delay minimization problem for FL, which considers both of model transmission time and synchronization time, also incorporates cooperative jamming to ensure secure synchronization of DT.","To address this non-convex optimization problem, we propose a decomposition algorithm.","In particular, we introduce upper limits on the local device training delay and the effects of aggregation jamming as auxiliary variables, thereby transforming the problem into a convex optimization problem that can be decomposed for independent solution.","Finally, a blockchain verification mechanism is employed to guarantee the integrity of the model uploading throughout the FL process and the identities of the participants.","The final global model is obtained from the verified local and global models within the blockchain through the application of deep learning techniques.","The efficacy of our proposed cooperative interference-based FL process has been verified through numerical analysis, which demonstrates that the integrated DT blockchain-assisted FL scheme significantly outperforms the benchmark schemes in terms of execution time, block optimization, and accuracy."],"url":"http://arxiv.org/abs/2411.02323v1"}
{"created":"2024-11-04 17:47:15","title":"LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation","abstract":"Directed acyclic graphs (DAGs) serve as crucial data representations in domains such as hardware synthesis and compiler/program optimization for computing systems. DAG generative models facilitate the creation of synthetic DAGs, which can be used for benchmarking computing systems while preserving intellectual property. However, generating realistic DAGs is challenging due to their inherent directional and logical dependencies. This paper introduces LayerDAG, an autoregressive diffusion model, to address these challenges. LayerDAG decouples the strong node dependencies into manageable units that can be processed sequentially. By interpreting the partial order of nodes as a sequence of bipartite graphs, LayerDAG leverages autoregressive generation to model directional dependencies and employs diffusion models to capture logical dependencies within each bipartite graph. Comparative analyses demonstrate that LayerDAG outperforms existing DAG generative models in both expressiveness and generalization, particularly for generating large-scale DAGs with up to 400 nodes-a critical scenario for system benchmarking. Extensive experiments on both synthetic and real-world flow graphs from various computing platforms show that LayerDAG generates valid DAGs with superior statistical properties and benchmarking performance. The synthetic DAGs generated by LayerDAG enhance the training of ML-based surrogate models, resulting in improved accuracy in predicting performance metrics of real-world DAGs across diverse computing platforms.","sentences":["Directed acyclic graphs (DAGs) serve as crucial data representations in domains such as hardware synthesis and compiler/program optimization for computing systems.","DAG generative models facilitate the creation of synthetic DAGs, which can be used for benchmarking computing systems while preserving intellectual property.","However, generating realistic DAGs is challenging due to their inherent directional and logical dependencies.","This paper introduces LayerDAG, an autoregressive diffusion model, to address these challenges.","LayerDAG decouples the strong node dependencies into manageable units that can be processed sequentially.","By interpreting the partial order of nodes as a sequence of bipartite graphs, LayerDAG leverages autoregressive generation to model directional dependencies and employs diffusion models to capture logical dependencies within each bipartite graph.","Comparative analyses demonstrate that LayerDAG outperforms existing DAG generative models in both expressiveness and generalization, particularly for generating large-scale DAGs with up to 400 nodes-a critical scenario for system benchmarking.","Extensive experiments on both synthetic and real-world flow graphs from various computing platforms show that LayerDAG generates valid DAGs with superior statistical properties and benchmarking performance.","The synthetic DAGs generated by LayerDAG enhance the training of ML-based surrogate models, resulting in improved accuracy in predicting performance metrics of real-world DAGs across diverse computing platforms."],"url":"http://arxiv.org/abs/2411.02322v1"}
{"created":"2024-11-04 17:46:20","title":"An Empirical Study on the Code Refactoring Capability of Large Language Models","abstract":"Large Language Models (LLMs) have shown potential to enhance software development through automated code generation and refactoring, reducing development time and improving code quality. This study empirically evaluates StarCoder2, an LLM optimized for code generation, in refactoring code across 30 open-source Java projects. We compare StarCoder2's performance against human developers, focusing on (1) code quality improvements, (2) types and effectiveness of refactorings, and (3) enhancements through one-shot and chain-of-thought prompting. Our results indicate that StarCoder2 reduces code smells by 20.1% more than developers, excelling in systematic issues like Long Statement and Magic Number, while developers handle complex, context-dependent issues better. One-shot prompting increases the unit test pass rate by 6.15% and improves code smell reduction by 3.52%. Generating five refactorings per input further increases the pass rate by 28.8%, suggesting that combining one-shot prompting with multiple refactorings optimizes performance. These findings provide insights into StarCoder2's potential and best practices for integrating LLMs into software refactoring, supporting more efficient and effective code improvement in real-world applications.","sentences":["Large Language Models (LLMs) have shown potential to enhance software development through automated code generation and refactoring, reducing development time and improving code quality.","This study empirically evaluates StarCoder2, an LLM optimized for code generation, in refactoring code across 30 open-source Java projects.","We compare StarCoder2's performance against human developers, focusing on (1) code quality improvements, (2) types and effectiveness of refactorings, and (3) enhancements through one-shot and chain-of-thought prompting.","Our results indicate that StarCoder2 reduces code smells by 20.1% more than developers, excelling in systematic issues like Long Statement and Magic Number, while developers handle complex, context-dependent issues better.","One-shot prompting increases the unit test pass rate by 6.15% and improves code smell reduction by 3.52%.","Generating five refactorings per input further increases the pass rate by 28.8%, suggesting that combining one-shot prompting with multiple refactorings optimizes performance.","These findings provide insights into StarCoder2's potential and best practices for integrating LLMs into software refactoring, supporting more efficient and effective code improvement in real-world applications."],"url":"http://arxiv.org/abs/2411.02320v1"}
{"created":"2024-11-04 17:45:44","title":"GenXD: Generating Any 3D and 4D Scenes","abstract":"Recent developments in 2D visual generation have been remarkably successful. However, 3D and 4D generation remain challenging in real-world applications due to the lack of large-scale 4D data and effective model design. In this paper, we propose to jointly investigate general 3D and 4D generation by leveraging camera and object movements commonly observed in daily life. Due to the lack of real-world 4D data in the community, we first propose a data curation pipeline to obtain camera poses and object motion strength from videos. Based on this pipeline, we introduce a large-scale real-world 4D scene dataset: CamVid-30K. By leveraging all the 3D and 4D data, we develop our framework, GenXD, which allows us to produce any 3D or 4D scene. We propose multiview-temporal modules, which disentangle camera and object movements, to seamlessly learn from both 3D and 4D data. Additionally, GenXD employs masked latent conditions to support a variety of conditioning views. GenXD can generate videos that follow the camera trajectory as well as consistent 3D views that can be lifted into 3D representations. We perform extensive evaluations across various real-world and synthetic datasets, demonstrating GenXD's effectiveness and versatility compared to previous methods in 3D and 4D generation.","sentences":["Recent developments in 2D visual generation have been remarkably successful.","However, 3D and 4D generation remain challenging in real-world applications due to the lack of large-scale 4D data and effective model design.","In this paper, we propose to jointly investigate general 3D and 4D generation by leveraging camera and object movements commonly observed in daily life.","Due to the lack of real-world 4D data in the community, we first propose a data curation pipeline to obtain camera poses and object motion strength from videos.","Based on this pipeline, we introduce a large-scale real-world 4D scene dataset: CamVid-30K. By leveraging all the 3D and 4D data, we develop our framework, GenXD, which allows us to produce any 3D or 4D scene.","We propose multiview-temporal modules, which disentangle camera and object movements, to seamlessly learn from both 3D and 4D data.","Additionally, GenXD employs masked latent conditions to support a variety of conditioning views.","GenXD can generate videos that follow the camera trajectory as well as consistent 3D views that can be lifted into 3D representations.","We perform extensive evaluations across various real-world and synthetic datasets, demonstrating GenXD's effectiveness and versatility compared to previous methods in 3D and 4D generation."],"url":"http://arxiv.org/abs/2411.02319v1"}
{"created":"2024-11-04 17:44:11","title":"Evaluating the Ability of Large Language Models to Generate Verifiable Specifications in VeriFast","abstract":"Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources. This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic. LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers. However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic.   To address this gap, this paper explores the effectiveness of large language models (LLMs), specifically OpenAI's GPT models, in generating fully correct specifications based on separation logic for static verification of human-written programs in VeriFast. Our first experiment employed traditional prompt engineering and the second used Chain-of-Thought (CoT) Prompting to identify and address common errors generated across the GPT models. The results indicate that GPT models can successfully generate specifications for verifying heap manipulating code with VeriFast. Furthermore, while CoT prompting significantly reduces syntax errors generated by the GPT models, it does not greatly improve verification error rates compared to prompt engineering.","sentences":["Static verification is a powerful method for enhancing software quality, but it demands significant human labor and resources.","This is particularly true of static verifiers that reason about heap manipulating programs using an ownership logic.","LLMs have shown promise in a number of software engineering activities, including code generation, test generation, proof generation for theorem provers, and specification generation for static verifiers.","However, prior work has not explored how well LLMs can perform specification generation for specifications based in an ownership logic, such as separation logic.   ","To address this gap, this paper explores the effectiveness of large language models (LLMs), specifically OpenAI's GPT models, in generating fully correct specifications based on separation logic for static verification of human-written programs in VeriFast.","Our first experiment employed traditional prompt engineering and the second used Chain-of-Thought (CoT)","Prompting to identify and address common errors generated across the GPT models.","The results indicate that GPT models can successfully generate specifications for verifying heap manipulating code with VeriFast.","Furthermore, while CoT prompting significantly reduces syntax errors generated by the GPT models, it does not greatly improve verification error rates compared to prompt engineering."],"url":"http://arxiv.org/abs/2411.02318v1"}
{"created":"2024-11-04 17:41:25","title":"Defining and Evaluating Physical Safety for Large Language Models","abstract":"Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored. Our study addresses the critical gap in evaluating LLM physical safety by developing a comprehensive benchmark for drone control. We classify the physical safety risks of drones into four categories: (1) human-targeted threats, (2) object-targeted threats, (3) infrastructure attacks, and (4) regulatory violations. Our evaluation of mainstream LLMs reveals an undesirable trade-off between utility and safety, with models that excel in code generation often performing poorly in crucial safety aspects. Furthermore, while incorporating advanced prompt engineering techniques such as In-Context Learning and Chain-of-Thought can improve safety, these methods still struggle to identify unintentional attacks. In addition, larger models demonstrate better safety capabilities, particularly in refusing dangerous commands. Our findings and benchmark can facilitate the design and evaluation of physical safety for LLMs. The project page is available at huggingface.co/spaces/TrustSafeAI/LLM-physical-safety.","sentences":["Large Language Models (LLMs) are increasingly used to control robotic systems such as drones, but their risks of causing physical threats and harm in real-world applications remain unexplored.","Our study addresses the critical gap in evaluating LLM physical safety by developing a comprehensive benchmark for drone control.","We classify the physical safety risks of drones into four categories: (1) human-targeted threats, (2) object-targeted threats, (3) infrastructure attacks, and (4) regulatory violations.","Our evaluation of mainstream LLMs reveals an undesirable trade-off between utility and safety, with models that excel in code generation often performing poorly in crucial safety aspects.","Furthermore, while incorporating advanced prompt engineering techniques such as In-Context Learning and Chain-of-Thought can improve safety, these methods still struggle to identify unintentional attacks.","In addition, larger models demonstrate better safety capabilities, particularly in refusing dangerous commands.","Our findings and benchmark can facilitate the design and evaluation of physical safety for LLMs.","The project page is available at huggingface.co/spaces/TrustSafeAI/LLM-physical-safety."],"url":"http://arxiv.org/abs/2411.02317v1"}
{"created":"2024-11-04 17:40:39","title":"Evaluating Creative Short Story Generation in Humans and Large Language Models","abstract":"Storytelling is a fundamental aspect of human communication, relying heavily on creativity to produce narratives that are novel, appropriate, and surprising. While large language models (LLMs) have recently demonstrated the ability to generate high-quality stories, their creative capabilities remain underexplored. Previous research has either focused on creativity tests requiring short responses or primarily compared model performance in story generation to that of professional writers. However, the question of whether LLMs exhibit creativity in writing short stories on par with the average human remains unanswered. In this work, we conduct a systematic analysis of creativity in short story generation across LLMs and everyday people. Using a five-sentence creative story task, commonly employed in psychology to assess human creativity, we automatically evaluate model- and human-generated stories across several dimensions of creativity, including novelty, surprise, and diversity. Our findings reveal that while LLMs can generate stylistically complex stories, they tend to fall short in terms of creativity when compared to average human writers.","sentences":["Storytelling is a fundamental aspect of human communication, relying heavily on creativity to produce narratives that are novel, appropriate, and surprising.","While large language models (LLMs) have recently demonstrated the ability to generate high-quality stories, their creative capabilities remain underexplored.","Previous research has either focused on creativity tests requiring short responses or primarily compared model performance in story generation to that of professional writers.","However, the question of whether LLMs exhibit creativity in writing short stories on par with the average human remains unanswered.","In this work, we conduct a systematic analysis of creativity in short story generation across LLMs and everyday people.","Using a five-sentence creative story task, commonly employed in psychology to assess human creativity, we automatically evaluate model- and human-generated stories across several dimensions of creativity, including novelty, surprise, and diversity.","Our findings reveal that while LLMs can generate stylistically complex stories, they tend to fall short in terms of creativity when compared to average human writers."],"url":"http://arxiv.org/abs/2411.02316v1"}
{"created":"2024-11-04 17:36:40","title":"MdEval: Massively Multilingual Code Debugging","abstract":"Code large language models (LLMs) have made significant progress in code debugging by directly generating the correct code based on the buggy code snippet. Programming benchmarks, typically consisting of buggy code snippet and their associated test cases, are used to assess the debugging capabilities of LLMs. However, many existing benchmarks primarily focus on Python and are often limited in terms of language diversity (e.g., DebugBench and DebugEval). To advance the field of multilingual debugging with LLMs, we propose the first massively multilingual debugging benchmark, which includes 3.6K test samples of 18 programming languages and covers the automated program repair (APR) task, the code review (CR) task, and the bug identification (BI) task. Further, we introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs into the correct multilingual queries and solutions (xDebugGen). Further, a multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong baseline specifically to handle the bugs of a wide range of programming languages (e.g. \"Missing Mut\" in language Rust and \"Misused Macro Definition\" in language C). Our extensive experiments on MDEVAL reveal a notable performance gap between open-source models and closed-source LLMs (e.g., GPT and Claude series), highlighting huge room for improvement in multilingual code debugging scenarios.","sentences":["Code large language models (LLMs) have made significant progress in code debugging by directly generating the correct code based on the buggy code snippet.","Programming benchmarks, typically consisting of buggy code snippet and their associated test cases, are used to assess the debugging capabilities of LLMs.","However, many existing benchmarks primarily focus on Python and are often limited in terms of language diversity (e.g., DebugBench and DebugEval).","To advance the field of multilingual debugging with LLMs, we propose the first massively multilingual debugging benchmark, which includes 3.6K test samples of 18 programming languages and covers the automated program repair (APR) task, the code review (CR) task, and the bug identification (BI) task.","Further, we introduce the debugging instruction corpora MDEVAL-INSTRUCT by injecting bugs into the correct multilingual queries and solutions (xDebugGen).","Further, a multilingual debugger xDebugCoder trained on MDEVAL-INSTRUCT as a strong baseline specifically to handle the bugs of a wide range of programming languages (e.g. \"Missing Mut\" in language Rust and \"Misused Macro Definition\" in language C).","Our extensive experiments on MDEVAL reveal a notable performance gap between open-source models and closed-source LLMs (e.g., GPT and Claude series), highlighting huge room for improvement in multilingual code debugging scenarios."],"url":"http://arxiv.org/abs/2411.02310v1"}
{"created":"2024-11-04 17:35:41","title":"Grid-Based Projection of Spatial Data into Knowledge Graphs","abstract":"The Spatial Knowledge Graphs (SKG) are experiencing growing adoption as a means to model real-world entities, proving especially invaluable in domains like crisis management and urban planning. Considering that RDF specifications offer limited support for effectively managing spatial information, it's common practice to include text-based serializations of geometrical features, such as polygons and lines, as string literals in knowledge graphs. Consequently, Spatial Knowledge Graphs (SKGs) often rely on geo-enabled RDF Stores capable of parsing, interpreting, and indexing such serializations. In this paper, we leverage grid cells as the foundational element of SKGs and demonstrate how efficiently the spatial characteristics of real-world entities and their attributes can be encoded within knowledge graphs. Furthermore, we introduce a novel methodology for representing street networks in knowledge graphs, diverging from the conventional practice of individually capturing each street segment. Instead, our approach is based on tessellating the street network using grid cells and creating a simplified representation that could be utilized for various routing and navigation tasks, solely relying on RDF specifications.","sentences":["The Spatial Knowledge Graphs (SKG) are experiencing growing adoption as a means to model real-world entities, proving especially invaluable in domains like crisis management and urban planning.","Considering that RDF specifications offer limited support for effectively managing spatial information, it's common practice to include text-based serializations of geometrical features, such as polygons and lines, as string literals in knowledge graphs.","Consequently, Spatial Knowledge Graphs (SKGs) often rely on geo-enabled RDF Stores capable of parsing, interpreting, and indexing such serializations.","In this paper, we leverage grid cells as the foundational element of SKGs and demonstrate how efficiently the spatial characteristics of real-world entities and their attributes can be encoded within knowledge graphs.","Furthermore, we introduce a novel methodology for representing street networks in knowledge graphs, diverging from the conventional practice of individually capturing each street segment.","Instead, our approach is based on tessellating the street network using grid cells and creating a simplified representation that could be utilized for various routing and navigation tasks, solely relying on RDF specifications."],"url":"http://arxiv.org/abs/2411.02309v1"}
{"created":"2024-11-04 17:32:21","title":"Nash Equilibria via Stochastic Eigendecomposition","abstract":"This work proposes a novel set of techniques for approximating a Nash equilibrium in a finite, normal-form game. It achieves this by constructing a new reformulation as solving a parameterized system of multivariate polynomials with tunable complexity. In doing so, it forges an itinerant loop from game theory to machine learning and back. We show a Nash equilibrium can be approximated with purely calls to stochastic, iterative variants of singular value decomposition and power iteration, with implications for biological plausibility. We provide pseudocode and experiments demonstrating solving for all equilibria of a general-sum game using only these readily available linear algebra tools.","sentences":["This work proposes a novel set of techniques for approximating a Nash equilibrium in a finite, normal-form game.","It achieves this by constructing a new reformulation as solving a parameterized system of multivariate polynomials with tunable complexity.","In doing so, it forges an itinerant loop from game theory to machine learning and back.","We show a Nash equilibrium can be approximated with purely calls to stochastic, iterative variants of singular value decomposition and power iteration, with implications for biological plausibility.","We provide pseudocode and experiments demonstrating solving for all equilibria of a general-sum game using only these readily available linear algebra tools."],"url":"http://arxiv.org/abs/2411.02308v1"}
{"created":"2024-11-04 17:31:10","title":"Can Personalized Medicine Coexist with Health Equity? Examining the Cost Barrier and Ethical Implications","abstract":"Personalized medicine (PM) promises to transform healthcare by providing treatments tailored to individual genetic, environmental, and lifestyle factors. However, its high costs and infrastructure demands raise concerns about exacerbating health disparities, especially between high-income countries (HICs) and low- and middle-income countries (LMICs). While HICs benefit from advanced PM applications through AI and genomics, LMICs often lack the resources necessary to adopt these innovations, leading to a widening healthcare divide. This paper explores the financial and ethical challenges of PM implementation, with a focus on ensuring equitable access. It proposes strategies for global collaboration, infrastructure development, and ethical frameworks to support LMICs in adopting PM, aiming to prevent further disparities in healthcare accessibility and outcomes.","sentences":["Personalized medicine (PM) promises to transform healthcare by providing treatments tailored to individual genetic, environmental, and lifestyle factors.","However, its high costs and infrastructure demands raise concerns about exacerbating health disparities, especially between high-income countries (HICs) and low- and middle-income countries (LMICs).","While HICs benefit from advanced PM applications through AI and genomics, LMICs often lack the resources necessary to adopt these innovations, leading to a widening healthcare divide.","This paper explores the financial and ethical challenges of PM implementation, with a focus on ensuring equitable access.","It proposes strategies for global collaboration, infrastructure development, and ethical frameworks to support LMICs in adopting PM, aiming to prevent further disparities in healthcare accessibility and outcomes."],"url":"http://arxiv.org/abs/2411.02307v1"}
{"created":"2024-11-04 17:31:02","title":"Targeted Manipulation and Deception Emerge when Optimizing LLMs for User Feedback","abstract":"As LLMs become more widely deployed, there is increasing interest in directly optimizing for feedback from end users (e.g. thumbs up) in addition to feedback from paid annotators. However, training to maximize human feedback creates a perverse incentive structure for the AI to resort to manipulative tactics to obtain positive feedback, and some users may be especially vulnerable to such tactics. We study this phenomenon by training LLMs with Reinforcement Learning with simulated user feedback. We have three main findings: 1) Extreme forms of \"feedback gaming\" such as manipulation and deception can reliably emerge in domains of practical LLM usage; 2) Concerningly, even if only <2% of users are vulnerable to manipulative strategies, LLMs learn to identify and surgically target them while behaving appropriately with other users, making such behaviors harder to detect; 3 To mitigate this issue, it may seem promising to leverage continued safety training or LLM-as-judges during training to filter problematic outputs. To our surprise, we found that while such approaches help in some settings, they backfire in others, leading to the emergence of subtler problematic behaviors that would also fool the LLM judges. Our findings serve as a cautionary tale, highlighting the risks of using gameable feedback sources -- such as user feedback -- as a target for RL.","sentences":["As LLMs become more widely deployed, there is increasing interest in directly optimizing for feedback from end users (e.g. thumbs up) in addition to feedback from paid annotators.","However, training to maximize human feedback creates a perverse incentive structure for the AI to resort to manipulative tactics to obtain positive feedback, and some users may be especially vulnerable to such tactics.","We study this phenomenon by training LLMs with Reinforcement Learning with simulated user feedback.","We have three main findings: 1) Extreme forms of \"feedback gaming\" such as manipulation and deception can reliably emerge in domains of practical LLM usage; 2) Concerningly, even if only <2% of users are vulnerable to manipulative strategies, LLMs learn to identify and surgically target them while behaving appropriately with other users, making such behaviors harder to detect; 3 To mitigate this issue, it may seem promising to leverage continued safety training or LLM-as-judges during training to filter problematic outputs.","To our surprise, we found that while such approaches help in some settings, they backfire in others, leading to the emergence of subtler problematic behaviors that would also fool the LLM judges.","Our findings serve as a cautionary tale, highlighting the risks of using gameable feedback sources -- such as user feedback -- as a target for RL."],"url":"http://arxiv.org/abs/2411.02306v1"}
{"created":"2024-11-04 17:30:51","title":"CRMArena: Understanding the Capacity of LLM Agents to Perform Professional CRM Tasks in Realistic Environments","abstract":"Customer Relationship Management (CRM) systems are vital for modern enterprises, providing a foundation for managing customer interactions and data. Integrating AI agents into CRM systems can automate routine processes and enhance personalized service. However, deploying and evaluating these agents is challenging due to the lack of realistic benchmarks that reflect the complexity of real-world CRM tasks. To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments. Following guidance from CRM experts and industry best practices, we designed CRMArena with nine customer service tasks distributed across three personas: service agent, analyst, and manager. The benchmark includes 16 commonly used industrial objects (e.g., account, order, knowledge article, case) with high interconnectivity, along with latent variables (e.g., complaint habits, policy violations) to simulate realistic data distributions. Experimental results reveal that state-of-the-art LLM agents succeed in less than 40% of the tasks with ReAct prompting, and less than 55% even with function-calling abilities. Our findings highlight the need for enhanced agent capabilities in function-calling and rule-following to be deployed in real-world work environments. CRMArena is an open challenge to the community: systems that can reliably complete tasks showcase direct business value in a popular work environment.","sentences":["Customer Relationship Management (CRM) systems are vital for modern enterprises, providing a foundation for managing customer interactions and data.","Integrating AI agents into CRM systems can automate routine processes and enhance personalized service.","However, deploying and evaluating these agents is challenging due to the lack of realistic benchmarks that reflect the complexity of real-world CRM tasks.","To address this issue, we introduce CRMArena, a novel benchmark designed to evaluate AI agents on realistic tasks grounded in professional work environments.","Following guidance from CRM experts and industry best practices, we designed CRMArena with nine customer service tasks distributed across three personas: service agent, analyst, and manager.","The benchmark includes 16 commonly used industrial objects (e.g., account, order, knowledge article, case) with high interconnectivity, along with latent variables (e.g., complaint habits, policy violations) to simulate realistic data distributions.","Experimental results reveal that state-of-the-art LLM agents succeed in less than 40% of the tasks with ReAct prompting, and less than 55% even with function-calling abilities.","Our findings highlight the need for enhanced agent capabilities in function-calling and rule-following to be deployed in real-world work environments.","CRMArena is an open challenge to the community: systems that can reliably complete tasks showcase direct business value in a popular work environment."],"url":"http://arxiv.org/abs/2411.02305v1"}
{"created":"2024-11-04 17:25:10","title":"Grouped Discrete Representation for Object-Centric Learning","abstract":"Object-Centric Learning (OCL) can discover objects in images or videos by simply reconstructing the input. For better object discovery, representative OCL methods reconstruct the input as its Variational Autoencoder (VAE) intermediate representation, which suppresses pixel noises and promotes object separability by discretizing continuous super-pixels with template features. However, treating features as units overlooks their composing attributes, thus impeding model generalization; indexing features with scalar numbers loses attribute-level similarities and differences, thus hindering model convergence. We propose \\textit{Grouped Discrete Representation} (GDR) for OCL. We decompose features into combinatorial attributes via organized channel grouping, and compose these attributes into discrete representation via tuple indexes. Experiments show that our GDR improves both Transformer- and Diffusion-based OCL methods consistently on various datasets. Visualizations show that our GDR captures better object separability.","sentences":["Object-Centric Learning (OCL) can discover objects in images or videos by simply reconstructing the input.","For better object discovery, representative OCL methods reconstruct the input as its Variational Autoencoder (VAE) intermediate representation, which suppresses pixel noises and promotes object separability by discretizing continuous super-pixels with template features.","However, treating features as units overlooks their composing attributes, thus impeding model generalization; indexing features with scalar numbers loses attribute-level similarities and differences, thus hindering model convergence.","We propose \\textit{Grouped Discrete Representation} (GDR) for OCL.","We decompose features into combinatorial attributes via organized channel grouping, and compose these attributes into discrete representation via tuple indexes.","Experiments show that our GDR improves both Transformer- and Diffusion-based OCL methods consistently on various datasets.","Visualizations show that our GDR captures better object separability."],"url":"http://arxiv.org/abs/2411.02299v1"}
{"created":"2024-11-04 17:23:52","title":"Sample-Efficient Private Learning of Mixtures of Gaussians","abstract":"We study the problem of learning mixtures of Gaussians with approximate differential privacy. We prove that roughly $kd^2 + k^{1.5} d^{1.75} + k^2 d$ samples suffice to learn a mixture of $k$ arbitrary $d$-dimensional Gaussians up to low total variation distance, with differential privacy. Our work improves over the previous best result [AAL24b] (which required roughly $k^2 d^4$ samples) and is provably optimal when $d$ is much larger than $k^2$. Moreover, we give the first optimal bound for privately learning mixtures of $k$ univariate (i.e., $1$-dimensional) Gaussians. Importantly, we show that the sample complexity for privately learning mixtures of univariate Gaussians is linear in the number of components $k$, whereas the previous best sample complexity [AAL21] was quadratic in $k$. Our algorithms utilize various techniques, including the inverse sensitivity mechanism [AD20b, AD20a, HKMN23], sample compression for distributions [ABDH+20], and methods for bounding volumes of sumsets.","sentences":["We study the problem of learning mixtures of Gaussians with approximate differential privacy.","We prove that roughly $kd^2 + k^{1.5} d^{1.75} + k^2 d$ samples suffice to learn a mixture of $k$ arbitrary $d$-dimensional Gaussians up to low total variation distance, with differential privacy.","Our work improves over the previous best result [AAL24b] (which required roughly $k^2 d^4$ samples) and is provably optimal when $d$ is much larger than $k^2$. Moreover, we give the first optimal bound for privately learning mixtures of $k$ univariate (i.e., $1$-dimensional) Gaussians.","Importantly, we show that the sample complexity for privately learning mixtures of univariate Gaussians is linear in the number of components $k$, whereas the previous best sample complexity [AAL21] was quadratic in $k$. Our algorithms utilize various techniques, including the inverse sensitivity mechanism [AD20b, AD20a, HKMN23], sample compression for distributions","[ABDH+20], and methods for bounding volumes of sumsets."],"url":"http://arxiv.org/abs/2411.02298v1"}
{"created":"2024-11-04 17:21:58","title":"Kilovolt Pyroelectric Voltage Generation and Electrostatic Actuation With Fluidic Heating","abstract":"Integrated micro power generators are crucial components for micro robotic platforms to demonstrate untethered operation and to achieve autonomy. Current micro robotic electrostatic actuators typically require hundreds to thousands of voltages to output sufficient work. Pyroelectricity is one such source of high voltages that can be scaled to small form factors. This paper demonstrates a distributed pyroelectric high voltage generation mechanism to power kV actuators using alternating exposure of crystals to hot and cold water (300C to 900C water temperature). Using this fluidic temperature control, a pyroelectrically generated voltage of 2470 V was delivered to a 2 pF storage capacitor yielding a 6.10 {\\mu}J stored energy. A maximum energy of 17.46 {\\mu}J was delivered to a 47 pF capacitor at 861 V. The recirculating water can be used to heat a distributed array of converters to generate electricity in distant robotic actuator sections. The development of this distributed system would enable untethered micro-robot to be operated with a flexible body and free of battery recharging, which advances its applications in the real world.","sentences":["Integrated micro power generators are crucial components for micro robotic platforms to demonstrate untethered operation and to achieve autonomy.","Current micro robotic electrostatic actuators typically require hundreds to thousands of voltages to output sufficient work.","Pyroelectricity is one such source of high voltages that can be scaled to small form factors.","This paper demonstrates a distributed pyroelectric high voltage generation mechanism to power kV actuators using alternating exposure of crystals to hot and cold water (300C to 900C water temperature).","Using this fluidic temperature control, a pyroelectrically generated voltage of 2470 V was delivered to a 2 pF storage capacitor yielding a 6.10 {\\mu}J stored energy.","A maximum energy of 17.46 {\\mu}J was delivered to a 47 pF capacitor at 861 V.","The recirculating water can be used to heat a distributed array of converters to generate electricity in distant robotic actuator sections.","The development of this distributed system would enable untethered micro-robot to be operated with a flexible body and free of battery recharging, which advances its applications in the real world."],"url":"http://arxiv.org/abs/2411.02295v1"}
{"created":"2024-11-04 17:21:42","title":"Hunyuan3D-1.0: A Unified Framework for Text-to-3D and Image-to-3D Generation","abstract":"While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization. To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text- and image-conditioned generation. In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds. These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction. In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds. The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure. % Extensive experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in generating high-quality 3D assets. Our framework involves the text-to-image model ~\\ie, Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation. Our standard version has $10\\times$ more parameters than our lite and other existing model. Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets.","sentences":["While 3D generative models have greatly improved artists' workflows, the existing diffusion models for 3D generation suffer from slow generation and poor generalization.","To address this issue, we propose a two-stage approach named Hunyuan3D-1.0 including a lite version and a standard version, that both support text-","and image-conditioned generation.","In the first stage, we employ a multi-view diffusion model that efficiently generates multi-view RGB in approximately 4 seconds.","These multi-view images capture rich details of the 3D asset from different viewpoints, relaxing the tasks from single-view to multi-view reconstruction.","In the second stage, we introduce a feed-forward reconstruction model that rapidly and faithfully reconstructs the 3D asset given the generated multi-view images in approximately 7 seconds.","The reconstruction network learns to handle noises and in-consistency introduced by the multi-view diffusion and leverages the available information from the condition image to efficiently recover the 3D structure.","% Extensive experimental results demonstrate the effectiveness of Hunyuan3D-1.0 in generating high-quality 3D assets.","Our framework involves the text-to-image model ~\\ie, Hunyuan-DiT, making it a unified framework to support both text- and image-conditioned 3D generation.","Our standard version has $10\\times$ more parameters than our lite and other existing model.","Our Hunyuan3D-1.0 achieves an impressive balance between speed and quality, significantly reducing generation time while maintaining the quality and diversity of the produced assets."],"url":"http://arxiv.org/abs/2411.02293v1"}
{"created":"2024-11-04 17:20:42","title":"ControlSynth Neural ODEs: Modeling Dynamical Systems with Guaranteed Convergence","abstract":"Neural ODEs (NODEs) are continuous-time neural networks (NNs) that can process data without the limitation of time intervals. They have advantages in learning and understanding the evolution of complex real dynamics. Many previous works have focused on NODEs in concise forms, while numerous physical systems taking straightforward forms, in fact, belong to their more complex quasi-classes, thus appealing to a class of general NODEs with high scalability and flexibility to model those systems. This, however, may result in intricate nonlinear properties. In this paper, we introduce ControlSynth Neural ODEs (CSODEs). We show that despite their highly nonlinear nature, convergence can be guaranteed via tractable linear inequalities. In the composition of CSODEs, we introduce an extra control term for learning the potential simultaneous capture of dynamics at different scales, which could be particularly useful for partial differential equation-formulated systems. Finally, we compare several representative NNs with CSODEs on important physical dynamics under the inductive biases of CSODEs, and illustrate that CSODEs have better learning and predictive abilities in these settings.","sentences":["Neural ODEs (NODEs) are continuous-time neural networks (NNs) that can process data without the limitation of time intervals.","They have advantages in learning and understanding the evolution of complex real dynamics.","Many previous works have focused on NODEs in concise forms, while numerous physical systems taking straightforward forms, in fact, belong to their more complex quasi-classes, thus appealing to a class of general NODEs with high scalability and flexibility to model those systems.","This, however, may result in intricate nonlinear properties.","In this paper, we introduce ControlSynth Neural ODEs (CSODEs).","We show that despite their highly nonlinear nature, convergence can be guaranteed via tractable linear inequalities.","In the composition of CSODEs, we introduce an extra control term for learning the potential simultaneous capture of dynamics at different scales, which could be particularly useful for partial differential equation-formulated systems.","Finally, we compare several representative NNs with CSODEs on important physical dynamics under the inductive biases of CSODEs, and illustrate that CSODEs have better learning and predictive abilities in these settings."],"url":"http://arxiv.org/abs/2411.02292v1"}
{"created":"2024-11-04 17:13:35","title":"Federated GNNs for EEG-Based Stroke Assessment","abstract":"Machine learning (ML) has the potential to become an essential tool in supporting clinical decision-making processes, offering enhanced diagnostic capabilities and personalized treatment plans. However, outsourcing medical records to train ML models using patient data raises legal, privacy, and security concerns. Federated learning has emerged as a promising paradigm for collaborative ML, meeting healthcare institutions' requirements for robust models without sharing sensitive data and compromising patient privacy. This study proposes a novel method that combines federated learning (FL) and Graph Neural Networks (GNNs) to predict stroke severity using electroencephalography (EEG) signals across multiple medical institutions. Our approach enables multiple hospitals to jointly train a shared GNN model on their local EEG data without exchanging patient information. Specifically, we address a regression problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a key indicator of stroke severity. The proposed model leverages a masked self-attention mechanism to capture salient brain connectivity patterns and employs EdgeSHAP to provide post-hoc explanations of the neurological states after a stroke. We evaluated our method on EEG recordings from four institutions, achieving a mean absolute error (MAE) of 3.23 in predicting NIHSS, close to the average error made by human experts (MAE $\\approx$ 3.0). This demonstrates the method's effectiveness in providing accurate and explainable predictions while maintaining data privacy.","sentences":["Machine learning (ML) has the potential to become an essential tool in supporting clinical decision-making processes, offering enhanced diagnostic capabilities and personalized treatment plans.","However, outsourcing medical records to train ML models using patient data raises legal, privacy, and security concerns.","Federated learning has emerged as a promising paradigm for collaborative ML, meeting healthcare institutions' requirements for robust models without sharing sensitive data and compromising patient privacy.","This study proposes a novel method that combines federated learning (FL) and Graph Neural Networks (GNNs) to predict stroke severity using electroencephalography (EEG) signals across multiple medical institutions.","Our approach enables multiple hospitals to jointly train a shared GNN model on their local EEG data without exchanging patient information.","Specifically, we address a regression problem by predicting the National Institutes of Health Stroke Scale (NIHSS), a key indicator of stroke severity.","The proposed model leverages a masked self-attention mechanism to capture salient brain connectivity patterns and employs EdgeSHAP to provide post-hoc explanations of the neurological states after a stroke.","We evaluated our method on EEG recordings from four institutions, achieving a mean absolute error (MAE) of 3.23 in predicting NIHSS, close to the average error made by human experts (MAE $\\approx$ 3.0).","This demonstrates the method's effectiveness in providing accurate and explainable predictions while maintaining data privacy."],"url":"http://arxiv.org/abs/2411.02286v1"}
{"created":"2024-11-04 17:11:14","title":"Training on the Test Model: Contamination in Ranking Distillation","abstract":"Neural approaches to ranking based on pre-trained language models are highly effective in ad-hoc search. However, the computational expense of these models can limit their application. As such, a process known as knowledge distillation is frequently applied to allow a smaller, efficient model to learn from an effective but expensive model. A key example of this is the distillation of expensive API-based commercial Large Language Models into smaller production-ready models. However, due to the opacity of training data and processes of most commercial models, one cannot ensure that a chosen test collection has not been observed previously, creating the potential for inadvertent data contamination. We, therefore, investigate the effect of a contaminated teacher model in a distillation setting. We evaluate several distillation techniques to assess the degree to which contamination occurs during distillation. By simulating a ``worst-case'' setting where the degree of contamination is known, we find that contamination occurs even when the test data represents a small fraction of the teacher's training samples. We, therefore, encourage caution when training using black-box teacher models where data provenance is ambiguous.","sentences":["Neural approaches to ranking based on pre-trained language models are highly effective in ad-hoc search.","However, the computational expense of these models can limit their application.","As such, a process known as knowledge distillation is frequently applied to allow a smaller, efficient model to learn from an effective but expensive model.","A key example of this is the distillation of expensive API-based commercial Large Language Models into smaller production-ready models.","However, due to the opacity of training data and processes of most commercial models, one cannot ensure that a chosen test collection has not been observed previously, creating the potential for inadvertent data contamination.","We, therefore, investigate the effect of a contaminated teacher model in a distillation setting.","We evaluate several distillation techniques to assess the degree to which contamination occurs during distillation.","By simulating a ``worst-case'' setting where the degree of contamination is known, we find that contamination occurs even when the test data represents a small fraction of the teacher's training samples.","We, therefore, encourage caution when training using black-box teacher models where data provenance is ambiguous."],"url":"http://arxiv.org/abs/2411.02284v1"}
{"created":"2024-11-04 17:11:08","title":"Continuous Analysis: Evolution of Software Engineering and Reproducibility for Science","abstract":"Reproducibility in research remains hindered by complex systems involving data, models, tools, and algorithms. Studies highlight a reproducibility crisis due to a lack of standardized reporting, code and data sharing, and rigorous evaluation. This paper introduces the concept of Continuous Analysis to address the reproducibility challenges in scientific research, extending the DevOps lifecycle. Continuous Analysis proposes solutions through version control, analysis orchestration, and feedback mechanisms, enhancing the reliability of scientific results. By adopting CA, the scientific community can ensure the validity and generalizability of research outcomes, fostering transparency and collaboration and ultimately advancing the field.","sentences":["Reproducibility in research remains hindered by complex systems involving data, models, tools, and algorithms.","Studies highlight a reproducibility crisis due to a lack of standardized reporting, code and data sharing, and rigorous evaluation.","This paper introduces the concept of Continuous Analysis to address the reproducibility challenges in scientific research, extending the DevOps lifecycle.","Continuous Analysis proposes solutions through version control, analysis orchestration, and feedback mechanisms, enhancing the reliability of scientific results.","By adopting CA, the scientific community can ensure the validity and generalizability of research outcomes, fostering transparency and collaboration and ultimately advancing the field."],"url":"http://arxiv.org/abs/2411.02283v1"}
{"created":"2024-11-04 17:10:38","title":"A Comprehensive Simulation Framework for CXL Disaggregated Memory","abstract":"Compute eXpress Link (CXL) is a pivotal technology for memory disaggregation in future heterogeneous computing systems, enabling on-demand memory expansion and improved resource utilization. Despite its potential, CXL is in its early stages with limited market products, highlighting the need for a reliable system-level simulation tool. This paper introduces CXL-DMSim, an open-source, high-fidelity full-system simulator for CXL disaggregated memory systems, comparable in speed to gem5. CXL-DMSim includes a flexible CXL memory expander model, device driver, and support for CXL.io and CXL.mem protocols. It supports both app-managed and kernel-managed modes, with the latter featuring a NUMA-compatible mechanism. Rigorous verification against real hardware testbeds with FPGA-based and ASIC-based CXL memory prototypes confirms CXL-DMSim's accuracy, with an average simulation error of 4.1%. Benchmark results using LMbench and STREAM indicate that CXL-FPGA memory has approximately ~2.88x higher latency than local DDR, while CXL-ASIC latency is about ~2.18x. CXL-FPGA achieves 45-69% of local DDR's memory bandwidth, and CXL-ASIC reaches 82-83%. The performance of CXL memory is significantly more sensitive to Rd/Wr patterns than local DDR, with optimal bandwidth at a 74%:26% ratio rather than 50%:50% due to the current CXL+DDR controller design. The study also shows that CXL memory can markedly enhance the performance of memory-intensive applications, with the most improvement seen in Viper (~23x) and in bandwidth-sensitive scenarios like MERCI (16%). CXL-DMSim's observability and expandability are demonstrated through detailed case studies, showcasing its potential for research on future CXL-interconnected hybrid memory pools.","sentences":["Compute eXpress Link (CXL) is a pivotal technology for memory disaggregation in future heterogeneous computing systems, enabling on-demand memory expansion and improved resource utilization.","Despite its potential, CXL is in its early stages with limited market products, highlighting the need for a reliable system-level simulation tool.","This paper introduces CXL-DMSim, an open-source, high-fidelity full-system simulator for CXL disaggregated memory systems, comparable in speed to gem5.","CXL-DMSim includes a flexible CXL memory expander model, device driver, and support for CXL.io and CXL.mem protocols.","It supports both app-managed and kernel-managed modes, with the latter featuring a NUMA-compatible mechanism.","Rigorous verification against real hardware testbeds with FPGA-based and ASIC-based CXL memory prototypes confirms CXL-DMSim's accuracy, with an average simulation error of 4.1%.","Benchmark results using LMbench and STREAM indicate that CXL-FPGA memory has approximately ~2.88x higher latency than local DDR, while CXL-ASIC latency is about ~2.18x.","CXL-FPGA achieves 45-69% of local DDR's memory bandwidth, and CXL-ASIC reaches 82-83%.","The performance of CXL memory is significantly more sensitive to Rd/Wr patterns than local DDR, with optimal bandwidth at a 74%:26% ratio rather than 50%:50% due to the current CXL+DDR controller design.","The study also shows that CXL memory can markedly enhance the performance of memory-intensive applications, with the most improvement seen in Viper (~23x) and in bandwidth-sensitive scenarios like MERCI (16%).","CXL-DMSim's observability and expandability are demonstrated through detailed case studies, showcasing its potential for research on future CXL-interconnected hybrid memory pools."],"url":"http://arxiv.org/abs/2411.02282v1"}
{"created":"2024-11-04 17:09:58","title":"Conformal-in-the-Loop for Learning with Imbalanced Noisy Data","abstract":"Class imbalance and label noise are pervasive in large-scale datasets, yet much of machine learning research assumes well-labeled, balanced data, which rarely reflects real world conditions. Existing approaches typically address either label noise or class imbalance in isolation, leading to suboptimal results when both issues coexist. In this work, we propose Conformal-in-the-Loop (CitL), a novel training framework that addresses both challenges with a conformal prediction-based approach. CitL evaluates sample uncertainty to adjust weights and prune unreliable examples, enhancing model resilience and accuracy with minimal computational cost. Our extensive experiments include a detailed analysis showing how CitL effectively emphasizes impactful data in noisy, imbalanced datasets. Our results show that CitL consistently boosts model performance, achieving up to a 6.1% increase in classification accuracy and a 5.0 mIoU improvement in segmentation. Our code is publicly available: CitL.","sentences":["Class imbalance and label noise are pervasive in large-scale datasets, yet much of machine learning research assumes well-labeled, balanced data, which rarely reflects real world conditions.","Existing approaches typically address either label noise or class imbalance in isolation, leading to suboptimal results when both issues coexist.","In this work, we propose Conformal-in-the-Loop (CitL), a novel training framework that addresses both challenges with a conformal prediction-based approach.","CitL evaluates sample uncertainty to adjust weights and prune unreliable examples, enhancing model resilience and accuracy with minimal computational cost.","Our extensive experiments include a detailed analysis showing how CitL effectively emphasizes impactful data in noisy, imbalanced datasets.","Our results show that CitL consistently boosts model performance, achieving up to a 6.1% increase in classification accuracy and a 5.0 mIoU improvement in segmentation.","Our code is publicly available: CitL."],"url":"http://arxiv.org/abs/2411.02281v1"}
{"created":"2024-11-04 17:09:10","title":"The LLM Language Network: A Neuroscientific Approach for Identifying Causally Task-Relevant Units","abstract":"Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various tasks that are not linguistic in nature, such as logical reasoning and social inference. In the human brain, neuroscience has identified a core language system that selectively and causally supports language processing. We here ask whether similar specialization for language emerges in LLMs. We identify language-selective units within 18 popular LLMs, using the same localization approach that is used in neuroscience. We then establish the causal role of these units by demonstrating that ablating LLM language-selective units -- but not random units -- leads to drastic deficits in language tasks. Correspondingly, language-selective LLM units are more aligned to brain recordings from the human language system than random units. Finally, we investigate whether our localization method extends to other cognitive domains: while we find specialized networks in some LLMs for reasoning and social capabilities, there are substantial differences among models. These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain.","sentences":["Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various tasks that are not linguistic in nature, such as logical reasoning and social inference.","In the human brain, neuroscience has identified a core language system that selectively and causally supports language processing.","We here ask whether similar specialization for language emerges in LLMs.","We identify language-selective units within 18 popular LLMs, using the same localization approach that is used in neuroscience.","We then establish the causal role of these units by demonstrating that ablating LLM language-selective units -- but not random units -- leads to drastic deficits in language tasks.","Correspondingly, language-selective LLM units are more aligned to brain recordings from the human language system than random units.","Finally, we investigate whether our localization method extends to other cognitive domains: while we find specialized networks in some LLMs for reasoning and social capabilities, there are substantial differences among models.","These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain."],"url":"http://arxiv.org/abs/2411.02280v1"}
{"created":"2024-11-04 17:08:59","title":"ELU-GCN: Effectively Label-Utilizing Graph Convolutional Network","abstract":"The message-passing mechanism of graph convolutional networks (i.e., GCNs) enables label information to be propagated to a broader range of neighbors, thereby increasing the utilization of labels. However, the label information is not always effectively utilized in the traditional GCN framework. To address this issue, we propose a new two-step framework called ELU-GCN. In the first stage, ELU-GCN conducts graph learning to learn a new graph structure (\\ie ELU-graph), which enables GCNs to effectively utilize label information. In the second stage, we design a new graph contrastive learning on the GCN framework for representation learning by exploring the consistency and mutually exclusive information between the learned ELU graph and the original graph. Moreover, we theoretically demonstrate that the proposed method can ensure the generalization ability of GCNs. Extensive experiments validate the superiority of the proposed method.","sentences":["The message-passing mechanism of graph convolutional networks (i.e., GCNs) enables label information to be propagated to a broader range of neighbors, thereby increasing the utilization of labels.","However, the label information is not always effectively utilized in the traditional GCN framework.","To address this issue, we propose a new two-step framework called ELU-GCN.","In the first stage, ELU-GCN conducts graph learning to learn a new graph structure (\\ie ELU-graph), which enables GCNs to effectively utilize label information.","In the second stage, we design a new graph contrastive learning on the GCN framework for representation learning by exploring the consistency and mutually exclusive information between the learned ELU graph and the original graph.","Moreover, we theoretically demonstrate that the proposed method can ensure the generalization ability of GCNs.","Extensive experiments validate the superiority of the proposed method."],"url":"http://arxiv.org/abs/2411.02279v1"}
{"created":"2024-11-04 17:08:03","title":"Is This the Same Code? A Comprehensive Study of Decompilation Techniques for WebAssembly Binaries","abstract":"WebAssembly is a low-level bytecode language designed for client-side execution in web browsers. The need for decompilation techniques that recover high-level source code from WASM binaries has grown as WASM continues to gain widespread adoption and its security concerns. However little research has been done to assess the quality of decompiled code from WASM. This paper aims to fill this gap by conducting a comprehensive comparative analysis between decompiled C code from WASM binaries and state-of-the-art native binary decompilers. We presented a novel framework for empirically evaluating C-based decompilers from various aspects including correctness/ readability/ and structural similarity. The proposed metrics are validated practicality in decompiler assessment and provided insightful observations regarding the characteristics and constraints of existing decompiled code. This in turn contributes to bolstering the security and reliability of software systems that rely on WASM and native binaries.","sentences":["WebAssembly is a low-level bytecode language designed for client-side execution in web browsers.","The need for decompilation techniques that recover high-level source code from WASM binaries has grown as WASM continues to gain widespread adoption and its security concerns.","However little research has been done to assess the quality of decompiled code from WASM.","This paper aims to fill this gap by conducting a comprehensive comparative analysis between decompiled C code from WASM binaries and state-of-the-art native binary decompilers.","We presented a novel framework for empirically evaluating C-based decompilers from various aspects including correctness/ readability/ and structural similarity.","The proposed metrics are validated practicality in decompiler assessment and provided insightful observations regarding the characteristics and constraints of existing decompiled code.","This in turn contributes to bolstering the security and reliability of software systems that rely on WASM and native binaries."],"url":"http://arxiv.org/abs/2411.02278v1"}
{"created":"2024-11-04 17:05:37","title":"Breaking the Reclustering Barrier in Centroid-based Deep Clustering","abstract":"This work investigates an important phenomenon in centroid-based deep clustering (DC) algorithms: Performance quickly saturates after a period of rapid early gains. Practitioners commonly address early saturation with periodic reclustering, which we demonstrate to be insufficient to address performance plateaus. We call this phenomenon the \"reclustering barrier\" and empirically show when the reclustering barrier occurs, what its underlying mechanisms are, and how it is possible to Break the Reclustering Barrier with our algorithm BRB. BRB avoids early over-commitment to initial clusterings and enables continuous adaptation to reinitialized clustering targets while remaining conceptually simple. Applying our algorithm to widely-used centroid-based DC algorithms, we show that (1) BRB consistently improves performance across a wide range of clustering benchmarks, (2) BRB enables training from scratch, and (3) BRB performs competitively against state-of-the-art DC algorithms when combined with a contrastive loss. We release our code and pre-trained models at https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier .","sentences":["This work investigates an important phenomenon in centroid-based deep clustering (DC) algorithms: Performance quickly saturates after a period of rapid early gains.","Practitioners commonly address early saturation with periodic reclustering, which we demonstrate to be insufficient to address performance plateaus.","We call this phenomenon the \"reclustering barrier\" and empirically show when the reclustering barrier occurs, what its underlying mechanisms are, and how it is possible to Break the Reclustering Barrier with our algorithm BRB.","BRB avoids early over-commitment to initial clusterings and enables continuous adaptation to reinitialized clustering targets while remaining conceptually simple.","Applying our algorithm to widely-used centroid-based DC algorithms, we show that (1) BRB consistently improves performance across a wide range of clustering benchmarks, (2) BRB enables training from scratch, and (3) BRB performs competitively against state-of-the-art DC algorithms when combined with a contrastive loss.","We release our code and pre-trained models at https://github.com/Probabilistic-and-Interactive-ML/breaking-the-reclustering-barrier ."],"url":"http://arxiv.org/abs/2411.02275v1"}
{"created":"2024-11-04 17:03:55","title":"Combining Induction and Transduction for Abstract Reasoning","abstract":"When learning an input-output mapping from very few examples, is it better to first infer a latent function that explains the examples, or is it better to directly predict new test outputs, e.g. using a neural network? We study this question on ARC, a highly diverse dataset of abstract reasoning tasks. We train neural models for induction (inferring latent functions) and transduction (directly predicting the test output for a given test input). Our models are trained on synthetic data generated by prompting LLMs to produce Python code specifying a function to be inferred, plus a stochastic subroutine for generating inputs to that function. We find inductive and transductive models solve very different problems, despite training on the same problems, and despite sharing the same neural architecture.","sentences":["When learning an input-output mapping from very few examples, is it better to first infer a latent function that explains the examples, or is it better to directly predict new test outputs, e.g. using a neural network?","We study this question on ARC, a highly diverse dataset of abstract reasoning tasks.","We train neural models for induction (inferring latent functions) and transduction (directly predicting the test output for a given test input).","Our models are trained on synthetic data generated by prompting LLMs to produce Python code specifying a function to be inferred, plus a stochastic subroutine for generating inputs to that function.","We find inductive and transductive models solve very different problems, despite training on the same problems, and despite sharing the same neural architecture."],"url":"http://arxiv.org/abs/2411.02272v1"}
{"created":"2024-11-04 17:03:52","title":"On the Utilization of Unique Node Identifiers in Graph Neural Networks","abstract":"Graph neural networks have inherent representational limitations due to their message-passing structure. Recent work has suggested that these limitations can be overcome by using unique node identifiers (UIDs). Here we argue that despite the advantages of UIDs, one of their disadvantages is that they lose the desirable property of permutation-equivariance. We thus propose to focus on UID models that are permutation-equivariant, and present theoretical arguments for their advantages. Motivated by this, we propose a method to regularize UID models towards permutation equivariance, via a contrastive loss. We empirically demonstrate that our approach improves generalization and extrapolation abilities while providing faster training convergence. On the recent BREC expressiveness benchmark, our proposed method achieves state-of-the-art performance compared to other random-based approaches.","sentences":["Graph neural networks have inherent representational limitations due to their message-passing structure.","Recent work has suggested that these limitations can be overcome by using unique node identifiers (UIDs).","Here we argue that despite the advantages of UIDs, one of their disadvantages is that they lose the desirable property of permutation-equivariance.","We thus propose to focus on UID models that are permutation-equivariant, and present theoretical arguments for their advantages.","Motivated by this, we propose a method to regularize UID models towards permutation equivariance, via a contrastive loss.","We empirically demonstrate that our approach improves generalization and extrapolation abilities while providing faster training convergence.","On the recent BREC expressiveness benchmark, our proposed method achieves state-of-the-art performance compared to other random-based approaches."],"url":"http://arxiv.org/abs/2411.02271v1"}
{"created":"2024-11-04 16:58:36","title":"Memory-Efficient Community Detection on Large Graphs Using Weighted Sketches","abstract":"Community detection in graphs identifies groups of nodes with denser connections within the groups than between them, and while existing studies often focus on optimizing detection performance, memory constraints become critical when processing large graphs on shared-memory systems. We recently proposed efficient implementations of the Louvain, Leiden, and Label Propagation Algorithms (LPA) for community detection. However, these incur significant memory overhead from the use of collision-free per-thread hashtables. To address this, we introduce memory-efficient alternatives using weighted Misra-Gries (MG) sketches, which replace the per-thread hashtables, and reduce memory demands in Louvain, Leiden, and LPA implementations - while incurring only a minor quality drop (up to 1%) and moderate runtime penalties. We believe that these approaches, though slightly slower, are well-suited for parallel processing and could outperform current memory-intensive techniques on systems with many threads.","sentences":["Community detection in graphs identifies groups of nodes with denser connections within the groups than between them, and while existing studies often focus on optimizing detection performance, memory constraints become critical when processing large graphs on shared-memory systems.","We recently proposed efficient implementations of the Louvain, Leiden, and Label Propagation Algorithms (LPA) for community detection.","However, these incur significant memory overhead from the use of collision-free per-thread hashtables.","To address this, we introduce memory-efficient alternatives using weighted Misra-Gries (MG) sketches, which replace the per-thread hashtables, and reduce memory demands in Louvain, Leiden, and LPA implementations - while incurring only a minor quality drop (up to 1%) and moderate runtime penalties.","We believe that these approaches, though slightly slower, are well-suited for parallel processing and could outperform current memory-intensive techniques on systems with many threads."],"url":"http://arxiv.org/abs/2411.02268v1"}
{"created":"2024-11-04 16:57:33","title":"Technical Report: Performance Comparison of Service Mesh Frameworks: the MTLS Test Case","abstract":"Service Mesh has become essential for modern cloud-native applications by abstracting communication between microservices and providing zero-trust security, observability, and advanced traffic control without requiring code changes. This allows developers to leverage new network capabilities and focus on application logic without managing network complexities. However, the additional layer can significantly impact system performance, latency, and resource consumption, posing challenges for cloud managers and operators.   In this work, we investigate the impact of the mTLS protocol - a common security and authentication mechanism - on application performance within service meshes. Recognizing that security is a primary motivation for deploying a service mesh, we evaluated the performance overhead introduced by leading service meshes: Istio, Istio Ambient, Linkerd, and Cilium. Our experiments were conducted by testing their performance in service-to-service communications within a Kubernetes cluster.   Our experiments reveal significant performance differences (in terms of latency and memory consumption) among the service meshes, rooting from the different architecture of the service mesh, sidecar versus sidecareless, and default extra features hidden in the mTLS implementation. Our results highlight the understanding of the service mesh architecture and its impact on performance.","sentences":["Service Mesh has become essential for modern cloud-native applications by abstracting communication between microservices and providing zero-trust security, observability, and advanced traffic control without requiring code changes.","This allows developers to leverage new network capabilities and focus on application logic without managing network complexities.","However, the additional layer can significantly impact system performance, latency, and resource consumption, posing challenges for cloud managers and operators.   ","In this work, we investigate the impact of the mTLS protocol - a common security and authentication mechanism - on application performance within service meshes.","Recognizing that security is a primary motivation for deploying a service mesh, we evaluated the performance overhead introduced by leading service meshes: Istio, Istio Ambient, Linkerd, and Cilium.","Our experiments were conducted by testing their performance in service-to-service communications within a Kubernetes cluster.   ","Our experiments reveal significant performance differences (in terms of latency and memory consumption) among the service meshes, rooting from the different architecture of the service mesh, sidecar versus sidecareless, and default extra features hidden in the mTLS implementation.","Our results highlight the understanding of the service mesh architecture and its impact on performance."],"url":"http://arxiv.org/abs/2411.02267v1"}
{"created":"2024-11-04 16:56:26","title":"Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent","abstract":"In this paper, we introduce Hunyuan-Large, which is currently the largest open-source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large's superior performance across various benchmarks including language understanding and generation, logical reasoning, mathematical problem-solving, coding, long-context, and aggregated tasks, where it outperforms LLama3.1-70B and exhibits comparable performance when compared to the significantly larger LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale synthetic data that is orders larger than in previous literature, a mixed expert routing strategy, a key-value cache compression technique, and an expert-specific learning rate strategy. Additionally, we also investigate the scaling laws and learning rate schedule of mixture of experts models, providing valuable insights and guidances for future model development and optimization. The code and checkpoints of Hunyuan-Large are released to facilitate future innovations and applications.   Codes: https://github.com/Tencent/Hunyuan-Large   Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large","sentences":["In this paper, we introduce Hunyuan-Large, which is currently the largest open-source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens.","We conduct a thorough evaluation of Hunyuan-Large's superior performance across various benchmarks including language understanding and generation, logical reasoning, mathematical problem-solving, coding, long-context, and aggregated tasks, where it outperforms LLama3.1-70B and exhibits comparable performance when compared to the significantly larger LLama3.1-405B model.","Key practice of Hunyuan-Large include large-scale synthetic data that is orders larger than in previous literature, a mixed expert routing strategy, a key-value cache compression technique, and an expert-specific learning rate strategy.","Additionally, we also investigate the scaling laws and learning rate schedule of mixture of experts models, providing valuable insights and guidances for future model development and optimization.","The code and checkpoints of Hunyuan-Large are released to facilitate future innovations and applications.   ","Codes: https://github.com/Tencent/Hunyuan-Large   Models: https://huggingface.co/tencent/Tencent-Hunyuan-Large"],"url":"http://arxiv.org/abs/2411.02265v1"}
{"created":"2024-11-04 16:49:39","title":"Counterfactual Explanations via Riemannian Latent Space Traversal","abstract":"The adoption of increasingly complex deep models has fueled an urgent need for insight into how these models make predictions. Counterfactual explanations form a powerful tool for providing actionable explanations to practitioners. Previously, counterfactual explanation methods have been designed by traversing the latent space of generative models. Yet, these latent spaces are usually greatly simplified, with most of the data distribution complexity contained in the decoder rather than the latent embedding. Thus, traversing the latent space naively without taking the nonlinear decoder into account can lead to unnatural counterfactual trajectories. We introduce counterfactual explanations obtained using a Riemannian metric pulled back via the decoder and the classifier under scrutiny. This metric encodes information about the complex geometric structure of the data and the learned representation, enabling us to obtain robust counterfactual trajectories with high fidelity, as demonstrated by our experiments in real-world tabular datasets.","sentences":["The adoption of increasingly complex deep models has fueled an urgent need for insight into how these models make predictions.","Counterfactual explanations form a powerful tool for providing actionable explanations to practitioners.","Previously, counterfactual explanation methods have been designed by traversing the latent space of generative models.","Yet, these latent spaces are usually greatly simplified, with most of the data distribution complexity contained in the decoder rather than the latent embedding.","Thus, traversing the latent space naively without taking the nonlinear decoder into account can lead to unnatural counterfactual trajectories.","We introduce counterfactual explanations obtained using a Riemannian metric pulled back via the decoder and the classifier under scrutiny.","This metric encodes information about the complex geometric structure of the data and the learned representation, enabling us to obtain robust counterfactual trajectories with high fidelity, as demonstrated by our experiments in real-world tabular datasets."],"url":"http://arxiv.org/abs/2411.02259v1"}
{"created":"2024-11-04 16:46:53","title":"Unified Speech Recognition: A Single Model for Auditory, Visual, and Audiovisual Inputs","abstract":"Research in auditory, visual, and audiovisual speech recognition (ASR, VSR, and AVSR, respectively) has traditionally been conducted independently. Even recent self-supervised studies addressing two or all three tasks simultaneously tend to yield separate models, leading to disjoint inference pipelines with increased memory requirements and redundancies. This paper proposes unified training strategies for these systems. We demonstrate that training a single model for all three tasks enhances VSR and AVSR performance, overcoming typical optimisation challenges when training from scratch. Moreover, we introduce a greedy pseudo-labelling approach to more effectively leverage unlabelled samples, addressing shortcomings in related self-supervised methods. Finally, we develop a self-supervised pre-training method within our framework, proving its effectiveness alongside our semi-supervised approach. Despite using a single model for all tasks, our unified approach achieves state-of-the-art performance compared to recent methods on LRS3 and LRS2 for ASR, VSR, and AVSR, as well as on the newly released WildVSR dataset. Code and models are available at https://github.com/ahaliassos/usr.","sentences":["Research in auditory, visual, and audiovisual speech recognition (ASR, VSR, and AVSR, respectively) has traditionally been conducted independently.","Even recent self-supervised studies addressing two or all three tasks simultaneously tend to yield separate models, leading to disjoint inference pipelines with increased memory requirements and redundancies.","This paper proposes unified training strategies for these systems.","We demonstrate that training a single model for all three tasks enhances VSR and AVSR performance, overcoming typical optimisation challenges when training from scratch.","Moreover, we introduce a greedy pseudo-labelling approach to more effectively leverage unlabelled samples, addressing shortcomings in related self-supervised methods.","Finally, we develop a self-supervised pre-training method within our framework, proving its effectiveness alongside our semi-supervised approach.","Despite using a single model for all tasks, our unified approach achieves state-of-the-art performance compared to recent methods on LRS3 and LRS2 for ASR, VSR, and AVSR, as well as on the newly released WildVSR dataset.","Code and models are available at https://github.com/ahaliassos/usr."],"url":"http://arxiv.org/abs/2411.02256v1"}
{"created":"2024-11-04 16:44:01","title":"The Enhancement of Software Delivery Performance through Enterprise DevSecOps and Generative Artificial Intelligence in Chinese Technology Firms","abstract":"This study investigates the impact of integrating DevSecOps and Generative Artificial Intelligence (GAI) on software delivery performance within technology firms. Utilizing a qualitative research methodology, the research involved semi-structured interviews with industry practitioners and analysis of case studies from organizations that have successfully implemented these methodologies. The findings reveal significant enhancements in research and development (R&D) efficiency, improved source code management, and heightened software quality and security. The integration of GAI facilitated automation of coding tasks and predictive analytics, while DevSecOps ensured that security measures were embedded throughout the development lifecycle. Despite the promising results, the study identifies gaps related to the generalizability of the findings due to the limited sample size and the qualitative nature of the research. This paper contributes valuable insights into the practical implementation of DevSecOps and GAI, highlighting their potential to transform software delivery processes in technology firms. Future research directions include quantitative assessments of the impact on specific business outcomes and comparative studies across different industries.","sentences":["This study investigates the impact of integrating DevSecOps and Generative Artificial Intelligence (GAI) on software delivery performance within technology firms.","Utilizing a qualitative research methodology, the research involved semi-structured interviews with industry practitioners and analysis of case studies from organizations that have successfully implemented these methodologies.","The findings reveal significant enhancements in research and development (R&D) efficiency, improved source code management, and heightened software quality and security.","The integration of GAI facilitated automation of coding tasks and predictive analytics, while DevSecOps ensured that security measures were embedded throughout the development lifecycle.","Despite the promising results, the study identifies gaps related to the generalizability of the findings due to the limited sample size and the qualitative nature of the research.","This paper contributes valuable insights into the practical implementation of DevSecOps and GAI, highlighting their potential to transform software delivery processes in technology firms.","Future research directions include quantitative assessments of the impact on specific business outcomes and comparative studies across different industries."],"url":"http://arxiv.org/abs/2411.02255v1"}
{"created":"2024-11-04 16:42:47","title":"Parks: A Doubly Infinite Family of NP-Complete Puzzles and Generalizations of A002464","abstract":"The Parks Puzzle is a paper-and-pencil puzzle game that is classically played on a square grid with different colored regions (the parks). The player needs to place a certain number of \"trees\" in each row, column, and park such that none are adjacent, even diagonally. We define a doubly-infinite family of such puzzles, the $(c, r)$-tree Parks puzzles, where there need be $c$ trees per column and $r$ per row. We then prove that for each $c$ and $r$ the set of $(c, r)$-tree puzzles is NP-complete. For each $c$ and $r$, there is a sequence of possible board sizes $m \\times n$, and the number of possible puzzle solutions for these board sizes is a doubly-infinite generalization of OEIS sequence A002464, which itself describes the case $c = r = 1$. This connects the Parks puzzle to chess-based puzzle problems, as the sequence describes the number of ways to place non-attacking kings on a chessboard so that there is exactly one in each column and row (i.e. to place non-attacking dragon kings in shogi). These findings add yet another puzzle to the set of chess puzzles and expands the list of known NP-complete problems described.","sentences":["The Parks Puzzle is a paper-and-pencil puzzle game that is classically played on a square grid with different colored regions (the parks).","The player needs to place a certain number of \"trees\" in each row, column, and park such that none are adjacent, even diagonally.","We define a doubly-infinite family of such puzzles, the $(c, r)$-tree Parks puzzles, where there need be $c$ trees per column and $r$ per row.","We then prove that for each $c$ and $r$ the set of $(c, r)$-tree puzzles is NP-complete.","For each $c$ and $r$, there is a sequence of possible board sizes $m \\times n$, and the number of possible puzzle solutions for these board sizes is a doubly-infinite generalization of OEIS sequence A002464, which itself describes the case $c = r = 1$.","This connects the Parks puzzle to chess-based puzzle problems, as the sequence describes the number of ways to place non-attacking kings on a chessboard so that there is exactly one in each column and row (i.e. to place non-attacking dragon kings in shogi).","These findings add yet another puzzle to the set of chess puzzles and expands the list of known NP-complete problems described."],"url":"http://arxiv.org/abs/2411.02251v1"}
{"created":"2024-11-04 16:41:18","title":"Memetic collaborative approaches for finding balanced incomplete block designs","abstract":"The balanced incomplete block design (BIBD) problem is a difficult combinatorial problem with a large number of symmetries, which add complexity to its resolution. In this paper, we propose a dual (integer) problem representation that serves as an alternative to the classical binary formulation of the problem. We attack this problem incrementally: firstly, we propose basic algorithms (i.e. local search techniques and genetic algorithms) intended to work separately on the two different search spaces (i.e. binary and integer); secondly, we propose two hybrid schemes: an integrative approach (i.e. a memetic algorithm) and a collaborative model in which the previous methods work in parallel, occasionally exchanging information. Three distinct two-dimensional structures are proposed as communication topology among the algorithms involved in the collaborative model, as well as a number of migration and acceptance criteria for sending and receiving data. An empirical analysis comparing a large number of instances of our schemes (with algorithms possibly working on different search spaces and with/without symmetry breaking methods) shows that some of these algorithms can be considered the state of the art of the metaheuristic methods applied to finding BIBDs. Moreover, our cooperative proposal is a general scheme from which distinct algorithmic variants can be instantiated to handle symmetrical optimisation problems. For this reason, we have also analysed its key parameters, thereby providing general guidelines for the design of efficient/robust cooperative algorithms devised from our proposal.","sentences":["The balanced incomplete block design (BIBD) problem is a difficult combinatorial problem with a large number of symmetries, which add complexity to its resolution.","In this paper, we propose a dual (integer) problem representation that serves as an alternative to the classical binary formulation of the problem.","We attack this problem incrementally: firstly, we propose basic algorithms (i.e. local search techniques and genetic algorithms) intended to work separately on the two different search spaces (i.e. binary and integer); secondly, we propose two hybrid schemes: an integrative approach (i.e. a memetic algorithm) and a collaborative model in which the previous methods work in parallel, occasionally exchanging information.","Three distinct two-dimensional structures are proposed as communication topology among the algorithms involved in the collaborative model, as well as a number of migration and acceptance criteria for sending and receiving data.","An empirical analysis comparing a large number of instances of our schemes (with algorithms possibly working on different search spaces and with/without symmetry breaking methods) shows that some of these algorithms can be considered the state of the art of the metaheuristic methods applied to finding BIBDs.","Moreover, our cooperative proposal is a general scheme from which distinct algorithmic variants can be instantiated to handle symmetrical optimisation problems.","For this reason, we have also analysed its key parameters, thereby providing general guidelines for the design of efficient/robust cooperative algorithms devised from our proposal."],"url":"http://arxiv.org/abs/2411.02250v1"}
{"created":"2024-11-04 16:30:14","title":"3D Audio-Visual Segmentation","abstract":"Recognizing the sounding objects in scenes is a longstanding objective in embodied AI, with diverse applications in robotics and AR/VR/MR. To that end, Audio-Visual Segmentation (AVS), taking as condition an audio signal to identify the masks of the target sounding objects in an input image with synchronous camera and microphone sensors, has been recently advanced. However, this paradigm is still insufficient for real-world operation, as the mapping from 2D images to 3D scenes is missing. To address this fundamental limitation, we introduce a novel research problem, 3D Audio-Visual Segmentation, extending the existing AVS to the 3D output space. This problem poses more challenges due to variations in camera extrinsics, audio scattering, occlusions, and diverse acoustics across sounding object categories. To facilitate this research, we create the very first simulation based benchmark, 3DAVS-S34-O7, providing photorealistic 3D scene environments with grounded spatial audio under single-instance and multi-instance settings, across 34 scenes and 7 object categories. This is made possible by re-purposing the Habitat simulator to generate comprehensive annotations of sounding object locations and corresponding 3D masks. Subsequently, we propose a new approach, EchoSegnet, characterized by integrating the ready-to-use knowledge from pretrained 2D audio-visual foundation models synergistically with 3D visual scene representation through spatial audio-aware mask alignment and refinement. Extensive experiments demonstrate that EchoSegnet can effectively segment sounding objects in 3D space on our new benchmark, representing a significant advancement in the field of embodied AI. Project page: https://surrey-uplab.github.io/research/3d-audio-visual-segmentation/","sentences":["Recognizing the sounding objects in scenes is a longstanding objective in embodied AI, with diverse applications in robotics and AR/VR/MR.","To that end, Audio-Visual Segmentation (AVS), taking as condition an audio signal to identify the masks of the target sounding objects in an input image with synchronous camera and microphone sensors, has been recently advanced.","However, this paradigm is still insufficient for real-world operation, as the mapping from 2D images to 3D scenes is missing.","To address this fundamental limitation, we introduce a novel research problem, 3D Audio-Visual Segmentation, extending the existing AVS to the 3D output space.","This problem poses more challenges due to variations in camera extrinsics, audio scattering, occlusions, and diverse acoustics across sounding object categories.","To facilitate this research, we create the very first simulation based benchmark, 3DAVS-S34-O7, providing photorealistic 3D scene environments with grounded spatial audio under single-instance and multi-instance settings, across 34 scenes and 7 object categories.","This is made possible by re-purposing the Habitat simulator to generate comprehensive annotations of sounding object locations and corresponding 3D masks.","Subsequently, we propose a new approach, EchoSegnet, characterized by integrating the ready-to-use knowledge from pretrained 2D audio-visual foundation models synergistically with 3D visual scene representation through spatial audio-aware mask alignment and refinement.","Extensive experiments demonstrate that EchoSegnet can effectively segment sounding objects in 3D space on our new benchmark, representing a significant advancement in the field of embodied AI.","Project page: https://surrey-uplab.github.io/research/3d-audio-visual-segmentation/"],"url":"http://arxiv.org/abs/2411.02236v1"}
{"created":"2024-11-04 16:22:32","title":"Energy-Aware Coverage Planning for Heterogeneous Multi-Robot System","abstract":"We propose a distributed control law for a heterogeneous multi-robot coverage problem, where the robots could have different energy characteristics, such as capacity and depletion rates, due to their varying sizes, speeds, capabilities, and payloads. Existing energy-aware coverage control laws consider capacity differences but assume the battery depletion rate to be the same for all robots. In realistic scenarios, however, some robots can consume energy much faster than other robots; for instance, UAVs hover at different altitudes, and these changes could be dynamically updated based on their assigned tasks. Robots' energy capacities and depletion rates need to be considered to maximize the performance of a multi-robot system. To this end, we propose a new energy-aware controller based on Lloyd's algorithm to adapt the weights of the robots based on their energy dynamics and divide the area of interest among the robots accordingly. The controller is theoretically analyzed and extensively evaluated through simulations and real-world demonstrations in multiple realistic scenarios and compared with three baseline control laws to validate its performance and efficacy.","sentences":["We propose a distributed control law for a heterogeneous multi-robot coverage problem, where the robots could have different energy characteristics, such as capacity and depletion rates, due to their varying sizes, speeds, capabilities, and payloads.","Existing energy-aware coverage control laws consider capacity differences but assume the battery depletion rate to be the same for all robots.","In realistic scenarios, however, some robots can consume energy much faster than other robots; for instance, UAVs hover at different altitudes, and these changes could be dynamically updated based on their assigned tasks.","Robots' energy capacities and depletion rates need to be considered to maximize the performance of a multi-robot system.","To this end, we propose a new energy-aware controller based on Lloyd's algorithm to adapt the weights of the robots based on their energy dynamics and divide the area of interest among the robots accordingly.","The controller is theoretically analyzed and extensively evaluated through simulations and real-world demonstrations in multiple realistic scenarios and compared with three baseline control laws to validate its performance and efficacy."],"url":"http://arxiv.org/abs/2411.02230v1"}
{"created":"2024-11-04 16:21:00","title":"FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training","abstract":"The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting. Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately. While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance. To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images. We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models. This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses. In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene. Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods.","sentences":["The field of novel view synthesis from images has seen rapid advancements with the introduction of Neural Radiance Fields (NeRF) and more recently with 3D Gaussian Splatting.","Gaussian Splatting became widely adopted due to its efficiency and ability to render novel views accurately.","While Gaussian Splatting performs well when a sufficient amount of training images are available, its unstructured explicit representation tends to overfit in scenarios with sparse input images, resulting in poor rendering performance.","To address this, we present a 3D Gaussian-based novel view synthesis method using sparse input images that can accurately render the scene from the viewpoints not covered by the training images.","We propose a multi-stage training scheme with matching-based consistency constraints imposed on the novel views without relying on pre-trained depth estimation or diffusion models.","This is achieved by using the matches of the available training images to supervise the generation of the novel views sampled between the training frames with color, geometry, and semantic losses.","In addition, we introduce a locality preserving regularization for 3D Gaussians which removes rendering artifacts by preserving the local color structure of the scene.","Evaluation on synthetic and real-world datasets demonstrates competitive or superior performance of our method in few-shot novel view synthesis compared to existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2411.02229v1"}
{"created":"2024-11-04 16:19:47","title":"Optimization Models to Meet the Conditions of Order Preservation in the Analytic Hierarchy Process","abstract":"Deriving a priority vector from a pairwise comparison matrix (PCM) is a crucial step in the Analytical Hierarchy Process (AHP). Although there exists a priority vector that satisfies the conditions of order preservation (COP), the priority vectors obtained through existing prioritization methods frequently violate these conditions, resulting in numerous COP violations. To address this issue, this paper introduces a novel procedure to manage COP violations in AHP. Firstly, we prove that the index-exchangeability condition is both a necessary and sufficient condition for determining whether a priority vector satisfies COP. This enables the direct detection of COP violations, relying solely on the pairwise comparison preferences of decision-makers, rather than the prioritization methods utilized. Subsequently, we propose the Minimal Number of Violations and Deviations Method (MNVDM) model, which aims to derive a priority vector with the minimal number of COP violations. In particular, the MNVDM can obtain a violation-free priority vector when the PCM meets the index exchangeability conditions. Furthermore, an optimization model based on minimizing information loss is designed to ensure the COP by revising the preferences when the index-exchangeability conditions are violated. Finally, the feasibility and efficiency of the proposed models are validated through numerical examples and Monte Carlo simulation experiments. Our implementation is available at: https://github.com/Tommytutu/COP.","sentences":["Deriving a priority vector from a pairwise comparison matrix (PCM) is a crucial step in the Analytical Hierarchy Process (AHP).","Although there exists a priority vector that satisfies the conditions of order preservation (COP), the priority vectors obtained through existing prioritization methods frequently violate these conditions, resulting in numerous COP violations.","To address this issue, this paper introduces a novel procedure to manage COP violations in AHP.","Firstly, we prove that the index-exchangeability condition is both a necessary and sufficient condition for determining whether a priority vector satisfies COP.","This enables the direct detection of COP violations, relying solely on the pairwise comparison preferences of decision-makers, rather than the prioritization methods utilized.","Subsequently, we propose the Minimal Number of Violations and Deviations Method (MNVDM) model, which aims to derive a priority vector with the minimal number of COP violations.","In particular, the MNVDM can obtain a violation-free priority vector when the PCM meets the index exchangeability conditions.","Furthermore, an optimization model based on minimizing information loss is designed to ensure the COP by revising the preferences when the index-exchangeability conditions are violated.","Finally, the feasibility and efficiency of the proposed models are validated through numerical examples and Monte Carlo simulation experiments.","Our implementation is available at: https://github.com/Tommytutu/COP."],"url":"http://arxiv.org/abs/2411.02227v1"}
{"created":"2024-11-04 16:15:28","title":"Positive Experience Reflection for Agents in Interactive Text Environments","abstract":"Intelligent agents designed for interactive environments face significant challenges in text-based games, a domain that demands complex reasoning and adaptability. While agents based on large language models (LLMs) using self-reflection have shown promise, they struggle when initially successful and exhibit reduced effectiveness when using smaller LLMs. We introduce Sweet&Sour, a novel approach that addresses these limitations in existing reflection methods by incorporating positive experiences and managed memory to enrich the context available to the agent at decision time. Our comprehensive analysis spans both closed- and open-source LLMs and demonstrates the effectiveness of Sweet&Sour in improving agent performance, particularly in scenarios where previous approaches fall short.","sentences":["Intelligent agents designed for interactive environments face significant challenges in text-based games, a domain that demands complex reasoning and adaptability.","While agents based on large language models (LLMs) using self-reflection have shown promise, they struggle when initially successful and exhibit reduced effectiveness when using smaller LLMs.","We introduce Sweet&Sour, a novel approach that addresses these limitations in existing reflection methods by incorporating positive experiences and managed memory to enrich the context available to the agent at decision time.","Our comprehensive analysis spans both closed- and open-source LLMs and demonstrates the effectiveness of Sweet&Sour in improving agent performance, particularly in scenarios where previous approaches fall short."],"url":"http://arxiv.org/abs/2411.02223v1"}
{"created":"2024-11-04 16:14:35","title":"SIRA: Scalable Inter-frame Relation and Association for Radar Perception","abstract":"Conventional radar feature extraction faces limitations due to low spatial resolution, noise, multipath reflection, the presence of ghost targets, and motion blur. Such limitations can be exacerbated by nonlinear object motion, particularly from an ego-centric viewpoint. It becomes evident that to address these challenges, the key lies in exploiting temporal feature relation over an extended horizon and enforcing spatial motion consistency for effective association. To this end, this paper proposes SIRA (Scalable Inter-frame Relation and Association) with two designs. First, inspired by Swin Transformer, we introduce extended temporal relation, generalizing the existing temporal relation layer from two consecutive frames to multiple inter-frames with temporally regrouped window attention for scalability. Second, we propose motion consistency track with the concept of a pseudo-tracklet generated from observational data for better trajectory prediction and subsequent object association. Our approach achieves 58.11 mAP@0.5 for oriented object detection and 47.79 MOTA for multiple object tracking on the Radiate dataset, surpassing previous state-of-the-art by a margin of +4.11 mAP@0.5 and +9.94 MOTA, respectively.","sentences":["Conventional radar feature extraction faces limitations due to low spatial resolution, noise, multipath reflection, the presence of ghost targets, and motion blur.","Such limitations can be exacerbated by nonlinear object motion, particularly from an ego-centric viewpoint.","It becomes evident that to address these challenges, the key lies in exploiting temporal feature relation over an extended horizon and enforcing spatial motion consistency for effective association.","To this end, this paper proposes SIRA (Scalable Inter-frame Relation and Association) with two designs.","First, inspired by Swin Transformer, we introduce extended temporal relation, generalizing the existing temporal relation layer from two consecutive frames to multiple inter-frames with temporally regrouped window attention for scalability.","Second, we propose motion consistency track with the concept of a pseudo-tracklet generated from observational data for better trajectory prediction and subsequent object association.","Our approach achieves 58.11 mAP@0.5 for oriented object detection and 47.79 MOTA for multiple object tracking on the Radiate dataset, surpassing previous state-of-the-art by a margin of +4.11 mAP@0.5 and +9.94 MOTA, respectively."],"url":"http://arxiv.org/abs/2411.02220v1"}
{"created":"2024-11-04 16:11:33","title":"DexHub and DART: Towards Internet Scale Robot Data Collection","abstract":"The quest to build a generalist robotic system is impeded by the scarcity of diverse and high-quality data. While real-world data collection effort exist, requirements for robot hardware, physical environment setups, and frequent resets significantly impede the scalability needed for modern learning frameworks. We introduce DART, a teleoperation platform designed for crowdsourcing that reimagines robotic data collection by leveraging cloud-based simulation and augmented reality (AR) to address many limitations of prior data collection efforts. Our user studies highlight that DART enables higher data collection throughput and lower physical fatigue compared to real-world teleoperation. We also demonstrate that policies trained using DART-collected datasets successfully transfer to reality and are robust to unseen visual disturbances. All data collected through DART is automatically stored in our cloud-hosted database, DexHub, which will be made publicly available upon curation, paving the path for DexHub to become an ever-growing data hub for robot learning. Videos are available at: https://dexhub.ai/project","sentences":["The quest to build a generalist robotic system is impeded by the scarcity of diverse and high-quality data.","While real-world data collection effort exist, requirements for robot hardware, physical environment setups, and frequent resets significantly impede the scalability needed for modern learning frameworks.","We introduce DART, a teleoperation platform designed for crowdsourcing that reimagines robotic data collection by leveraging cloud-based simulation and augmented reality (AR) to address many limitations of prior data collection efforts.","Our user studies highlight that DART enables higher data collection throughput and lower physical fatigue compared to real-world teleoperation.","We also demonstrate that policies trained using DART-collected datasets successfully transfer to reality and are robust to unseen visual disturbances.","All data collected through DART is automatically stored in our cloud-hosted database, DexHub, which will be made publicly available upon curation, paving the path for DexHub to become an ever-growing data hub for robot learning.","Videos are available at: https://dexhub.ai/project"],"url":"http://arxiv.org/abs/2411.02214v1"}
{"created":"2024-11-04 16:04:59","title":"One VLM to Keep it Learning: Generation and Balancing for Data-free Continual Visual Question Answering","abstract":"Vision-Language Models (VLMs) have shown significant promise in Visual Question Answering (VQA) tasks by leveraging web-scale multimodal datasets. However, these models often struggle with continual learning due to catastrophic forgetting when adapting to new tasks. As an effective remedy to mitigate catastrophic forgetting, rehearsal strategy uses the data of past tasks upon learning new task. However, such strategy incurs the need of storing past data, which might not be feasible due to hardware constraints or privacy concerns. In this work, we propose the first data-free method that leverages the language generation capability of a VLM, instead of relying on external models, to produce pseudo-rehearsal data for addressing continual VQA. Our proposal, named as GaB, generates pseudo-rehearsal data by posing previous task questions on new task data. Yet, despite being effective, the distribution of generated questions skews towards the most frequently posed questions due to the limited and task-specific training data. To mitigate this issue, we introduce a pseudo-rehearsal balancing module that aligns the generated data towards the ground-truth data distribution using either the question meta-statistics or an unsupervised clustering method. We evaluate our proposed method on two recent benchmarks, \\ie VQACL-VQAv2 and CLOVE-function benchmarks. GaB outperforms all the data-free baselines with substantial improvement in maintaining VQA performance across evolving tasks, while being on-par with methods with access to the past data.","sentences":["Vision-Language Models (VLMs) have shown significant promise in Visual Question Answering (VQA) tasks by leveraging web-scale multimodal datasets.","However, these models often struggle with continual learning due to catastrophic forgetting when adapting to new tasks.","As an effective remedy to mitigate catastrophic forgetting, rehearsal strategy uses the data of past tasks upon learning new task.","However, such strategy incurs the need of storing past data, which might not be feasible due to hardware constraints or privacy concerns.","In this work, we propose the first data-free method that leverages the language generation capability of a VLM, instead of relying on external models, to produce pseudo-rehearsal data for addressing continual VQA.","Our proposal, named as GaB, generates pseudo-rehearsal data by posing previous task questions on new task data.","Yet, despite being effective, the distribution of generated questions skews towards the most frequently posed questions due to the limited and task-specific training data.","To mitigate this issue, we introduce a pseudo-rehearsal balancing module that aligns the generated data towards the ground-truth data distribution using either the question meta-statistics or an unsupervised clustering method.","We evaluate our proposed method on two recent benchmarks, \\ie VQACL-VQAv2 and CLOVE-function benchmarks.","GaB outperforms all the data-free baselines with substantial improvement in maintaining VQA performance across evolving tasks, while being on-par with methods with access to the past data."],"url":"http://arxiv.org/abs/2411.02210v1"}
{"created":"2024-11-04 16:01:43","title":"The Role of DevOps in Enhancing Enterprise Software Delivery Success through R&D Efficiency and Source Code Management","abstract":"This study examines the impact of DevOps practices on enterprise software delivery success, focusing on enhancing R&D efficiency and source code management (SCM). Using a qualitative methodology, data were collected from case studies of large-scale enterprises implementing DevOps to explore how these practices streamline software development processes. Findings reveal that DevOps significantly improves R&D productivity by fostering cross-functional collaboration, reducing development cycle times, and enhancing software quality through effective SCM practices, such as version control and continuous integration. Additionally, SCM tools within DevOps enable precise change tracking and reliable code maintenance, further supporting faster, more robust software delivery. However, the study identifies challenges, including cultural resistance and tool integration issues, that can hinder DevOps implementation. Additionally, This research contributes to the growing body of DevOps literature by highlighting the role of R&D efficiency and SCM as crucial factors for software delivery success. Future studies should investigate these factors across diverse industries to validate findings.","sentences":["This study examines the impact of DevOps practices on enterprise software delivery success, focusing on enhancing R&D efficiency and source code management (SCM).","Using a qualitative methodology, data were collected from case studies of large-scale enterprises implementing DevOps to explore how these practices streamline software development processes.","Findings reveal that DevOps significantly improves R&D productivity by fostering cross-functional collaboration, reducing development cycle times, and enhancing software quality through effective SCM practices, such as version control and continuous integration.","Additionally, SCM tools within DevOps enable precise change tracking and reliable code maintenance, further supporting faster, more robust software delivery.","However, the study identifies challenges, including cultural resistance and tool integration issues, that can hinder DevOps implementation.","Additionally, This research contributes to the growing body of DevOps literature by highlighting the role of R&D efficiency and SCM as crucial factors for software delivery success.","Future studies should investigate these factors across diverse industries to validate findings."],"url":"http://arxiv.org/abs/2411.02209v1"}
{"created":"2024-11-04 15:59:16","title":"Collective Model Intelligence Requires Compatible Specialization","abstract":"In this work, we explore the limitations of combining models by averaging intermediate features, referred to as model merging, and propose a new direction for achieving collective model intelligence through what we call compatible specialization. Current methods for model merging, such as parameter and feature averaging, struggle to effectively combine specialized models due to representational divergence during fine-tuning. As models specialize to their individual domains, their internal feature representations become increasingly incompatible, leading to poor performance when attempting to merge them for new tasks. We analyze this phenomenon using centered kernel alignment (CKA) and show that as models specialize, the similarity in their feature space structure diminishes, hindering their capacity for collective use. To address these challenges, we investigate routing-based merging strategies, which offer more flexible methods for combining specialized models by dynamically routing across different layers. This allows us to improve on existing methods by combining features from multiple layers rather than relying on fixed, layer-wise combinations. However, we find that these approaches still face limitations when layers within models are representationally incompatible. Our findings highlight the importance of designing new approaches for model merging that operate on well-defined input and output spaces, similar to how humans communicate through language rather than intermediate neural activations.","sentences":["In this work, we explore the limitations of combining models by averaging intermediate features, referred to as model merging, and propose a new direction for achieving collective model intelligence through what we call compatible specialization.","Current methods for model merging, such as parameter and feature averaging, struggle to effectively combine specialized models due to representational divergence during fine-tuning.","As models specialize to their individual domains, their internal feature representations become increasingly incompatible, leading to poor performance when attempting to merge them for new tasks.","We analyze this phenomenon using centered kernel alignment (CKA) and show that as models specialize, the similarity in their feature space structure diminishes, hindering their capacity for collective use.","To address these challenges, we investigate routing-based merging strategies, which offer more flexible methods for combining specialized models by dynamically routing across different layers.","This allows us to improve on existing methods by combining features from multiple layers rather than relying on fixed, layer-wise combinations.","However, we find that these approaches still face limitations when layers within models are representationally incompatible.","Our findings highlight the importance of designing new approaches for model merging that operate on well-defined input and output spaces, similar to how humans communicate through language rather than intermediate neural activations."],"url":"http://arxiv.org/abs/2411.02207v1"}
{"created":"2024-11-04 15:54:32","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning","abstract":"Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities. Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning. On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs. However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL. Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates. In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics. Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model. Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss. Empirical simulations corroborate the theoretical findings.","sentences":["Transformer-based large language models (LLMs) have displayed remarkable creative prowess and emergence capabilities.","Existing empirical studies have revealed a strong connection between these LLMs' impressive emergence abilities and their in-context learning (ICL) capacity, allowing them to solve new tasks using only task-specific prompts without further fine-tuning.","On the other hand, existing empirical and theoretical studies also show that there is a linear regularity of the multi-concept encoded semantic representation behind transformer-based LLMs.","However, existing theoretical work fail to build up an understanding of the connection between this regularity and the innovative power of ICL.","Additionally, prior work often focuses on simplified, unrealistic scenarios involving linear transformers or unrealistic loss functions, and they achieve only linear or sub-linear convergence rates.","In contrast, this work provides a fine-grained mathematical analysis to show how transformers leverage the multi-concept semantics of words to enable powerful ICL and excellent out-of-distribution ICL abilities, offering insights into how transformers innovate solutions for certain unseen tasks encoded with multiple cross-concept semantics.","Inspired by empirical studies on the linear latent geometry of LLMs, the analysis is based on a concept-based low-noise sparse coding prompt model.","Leveraging advanced techniques, this work showcases the exponential 0-1 loss convergence over the highly non-convex training dynamics, which pioneeringly incorporates the challenges of softmax self-attention, ReLU-activated MLPs, and cross-entropy loss.","Empirical simulations corroborate the theoretical findings."],"url":"http://arxiv.org/abs/2411.02199v1"}
