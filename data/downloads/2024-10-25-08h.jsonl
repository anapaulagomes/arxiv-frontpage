{"created":"2024-10-24 17:59:58","title":"PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views","abstract":"We propose PixelGaussian, an efficient feed-forward framework for learning generalizable 3D Gaussian reconstruction from arbitrary views. Most existing methods rely on uniform pixel-wise Gaussian representations, which learn a fixed number of 3D Gaussians for each view and cannot generalize well to more input views. Differently, our PixelGaussian dynamically adapts both the Gaussian distribution and quantity based on geometric complexity, leading to more efficient representations and significant improvements in reconstruction quality. Specifically, we introduce a Cascade Gaussian Adapter to adjust Gaussian distribution according to local geometry complexity identified by a keypoint scorer. CGA leverages deformable attention in context-aware hypernetworks to guide Gaussian pruning and splitting, ensuring accurate representation in complex regions while reducing redundancy. Furthermore, we design a transformer-based Iterative Gaussian Refiner module that refines Gaussian representations through direct image-Gaussian interactions. Our PixelGaussian can effectively reduce Gaussian redundancy as input views increase. We conduct extensive experiments on the large-scale ACID and RealEstate10K datasets, where our method achieves state-of-the-art performance with good generalization to various numbers of views. Code: https://github.com/Barrybarry-Smith/PixelGaussian.","sentences":["We propose PixelGaussian, an efficient feed-forward framework for learning generalizable 3D Gaussian reconstruction from arbitrary views.","Most existing methods rely on uniform pixel-wise Gaussian representations, which learn a fixed number of 3D Gaussians for each view and cannot generalize well to more input views.","Differently, our PixelGaussian dynamically adapts both the Gaussian distribution and quantity based on geometric complexity, leading to more efficient representations and significant improvements in reconstruction quality.","Specifically, we introduce a Cascade Gaussian Adapter to adjust Gaussian distribution according to local geometry complexity identified by a keypoint scorer.","CGA leverages deformable attention in context-aware hypernetworks to guide Gaussian pruning and splitting, ensuring accurate representation in complex regions while reducing redundancy.","Furthermore, we design a transformer-based Iterative Gaussian Refiner module that refines Gaussian representations through direct image-Gaussian interactions.","Our PixelGaussian can effectively reduce Gaussian redundancy as input views increase.","We conduct extensive experiments on the large-scale ACID and RealEstate10K datasets, where our method achieves state-of-the-art performance with good generalization to various numbers of views.","Code: https://github.com/Barrybarry-Smith/PixelGaussian."],"url":"http://arxiv.org/abs/2410.18979v1"}
{"created":"2024-10-24 17:59:51","title":"Framer: Interactive Frame Interpolation","abstract":"We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity. Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints. Such a design enjoys two clear benefits. First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions. Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles). It is noteworthy that our system also offers an \"autopilot\" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice. Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc. The code, the model, and the interface will be released to facilitate further research.","sentences":["We propose Framer for interactive frame interpolation, which targets producing smoothly transitioning frames between two images as per user creativity.","Concretely, besides taking the start and end frames as inputs, our approach supports customizing the transition process by tailoring the trajectory of some selected keypoints.","Such a design enjoys two clear benefits.","First, incorporating human interaction mitigates the issue arising from numerous possibilities of transforming one image to another, and in turn enables finer control of local motions.","Second, as the most basic form of interaction, keypoints help establish the correspondence across frames, enhancing the model to handle challenging cases (e.g., objects on the start and end frames are of different shapes and styles).","It is noteworthy that our system also offers an \"autopilot\" mode, where we introduce a module to estimate the keypoints and refine the trajectory automatically, to simplify the usage in practice.","Extensive experimental results demonstrate the appealing performance of Framer on various applications, such as image morphing, time-lapse video generation, cartoon interpolation, etc.","The code, the model, and the interface will be released to facilitate further research."],"url":"http://arxiv.org/abs/2410.18978v1"}
{"created":"2024-10-24 17:59:45","title":"MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms","abstract":"This research delves into the problem of interactive editing of human motion generation. Previous motion diffusion models lack explicit modeling of the word-level text-motion correspondence and good explainability, hence restricting their fine-grained editing ability. To address this issue, we propose an attention-based motion diffusion model, namely MotionCLR, with CLeaR modeling of attention mechanisms. Technically, MotionCLR models the in-modality and cross-modality interactions with self-attention and cross-attention, respectively. More specifically, the self-attention mechanism aims to measure the sequential similarity between frames and impacts the order of motion features. By contrast, the cross-attention mechanism works to find the fine-grained word-sequence correspondence and activate the corresponding timesteps in the motion sequence. Based on these key properties, we develop a versatile set of simple yet effective motion editing methods via manipulating attention maps, such as motion (de-)emphasizing, in-place motion replacement, and example-based motion generation, etc. For further verification of the explainability of the attention mechanism, we additionally explore the potential of action-counting and grounded motion generation ability via attention maps. Our experimental results show that our method enjoys good generation and editing ability with good explainability.","sentences":["This research delves into the problem of interactive editing of human motion generation.","Previous motion diffusion models lack explicit modeling of the word-level text-motion correspondence and good explainability, hence restricting their fine-grained editing ability.","To address this issue, we propose an attention-based motion diffusion model, namely MotionCLR, with CLeaR modeling of attention mechanisms.","Technically, MotionCLR models the in-modality and cross-modality interactions with self-attention and cross-attention, respectively.","More specifically, the self-attention mechanism aims to measure the sequential similarity between frames and impacts the order of motion features.","By contrast, the cross-attention mechanism works to find the fine-grained word-sequence correspondence and activate the corresponding timesteps in the motion sequence.","Based on these key properties, we develop a versatile set of simple yet effective motion editing methods via manipulating attention maps, such as motion (de-)emphasizing, in-place motion replacement, and example-based motion generation, etc.","For further verification of the explainability of the attention mechanism, we additionally explore the potential of action-counting and grounded motion generation ability via attention maps.","Our experimental results show that our method enjoys good generation and editing ability with good explainability."],"url":"http://arxiv.org/abs/2410.18977v1"}
{"created":"2024-10-24 17:59:38","title":"CAMEL-Bench: A Comprehensive Arabic LMM Benchmark","abstract":"Recent years have witnessed a significant interest in developing large multimodal models (LMMs) capable of performing various visual reasoning and understanding tasks. This has led to the introduction of multiple LMM benchmarks to evaluate LMMs on different tasks. However, most existing LMM evaluation benchmarks are predominantly English-centric. In this work, we develop a comprehensive LMM evaluation benchmark for the Arabic language to represent a large population of over 400 million speakers. The proposed benchmark, named CAMEL-Bench, comprises eight diverse domains and 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding to evaluate broad scenario generalizability. Our CAMEL-Bench comprises around 29,036 questions that are filtered from a larger pool of samples, where the quality is manually verified by native speakers to ensure reliable model assessment. We conduct evaluations of both closed-source, including GPT-4 series, and open-source LMMs. Our analysis reveals the need for substantial improvement, especially among the best open-source models, with even the closed-source GPT-4o achieving an overall score of 62%. Our benchmark and evaluation scripts are open-sourced.","sentences":["Recent years have witnessed a significant interest in developing large multimodal models (LMMs) capable of performing various visual reasoning and understanding tasks.","This has led to the introduction of multiple LMM benchmarks to evaluate LMMs on different tasks.","However, most existing LMM evaluation benchmarks are predominantly English-centric.","In this work, we develop a comprehensive LMM evaluation benchmark for the Arabic language to represent a large population of over 400 million speakers.","The proposed benchmark, named CAMEL-Bench, comprises eight diverse domains and 38 sub-domains including, multi-image understanding, complex visual perception, handwritten document understanding, video understanding, medical imaging, plant diseases, and remote sensing-based land use understanding to evaluate broad scenario generalizability.","Our CAMEL-Bench comprises around 29,036 questions that are filtered from a larger pool of samples, where the quality is manually verified by native speakers to ensure reliable model assessment.","We conduct evaluations of both closed-source, including GPT-4 series, and open-source LMMs.","Our analysis reveals the need for substantial improvement, especially among the best open-source models, with even the closed-source GPT-4o achieving an overall score of 62%.","Our benchmark and evaluation scripts are open-sourced."],"url":"http://arxiv.org/abs/2410.18976v1"}
{"created":"2024-10-24 17:59:31","title":"Unbounded: A Generative Infinite Game of Character Life Simulation","abstract":"We introduce the concept of a generative infinite game, a video game that transcends the traditional boundaries of finite, hard-coded systems by using generative models. Inspired by James P. Carse's distinction between finite and infinite games, we leverage recent advances in generative AI to create Unbounded: a game of character life simulation that is fully encapsulated in generative models. Specifically, Unbounded draws inspiration from sandbox life simulations and allows you to interact with your autonomous virtual character in a virtual world by feeding, playing with and guiding it - with open-ended mechanics generated by an LLM, some of which can be emergent. In order to develop Unbounded, we propose technical innovations in both the LLM and visual generation domains. Specifically, we present: (1) a specialized, distilled large language model (LLM) that dynamically generates game mechanics, narratives, and character interactions in real-time, and (2) a new dynamic regional image prompt Adapter (IP-Adapter) for vision models that ensures consistent yet flexible visual generation of a character across multiple environments. We evaluate our system through both qualitative and quantitative analysis, showing significant improvements in character life simulation, user instruction following, narrative coherence, and visual consistency for both characters and the environments compared to traditional related approaches.","sentences":["We introduce the concept of a generative infinite game, a video game that transcends the traditional boundaries of finite, hard-coded systems by using generative models.","Inspired by James P. Carse's distinction between finite and infinite games, we leverage recent advances in generative AI to create Unbounded: a game of character life simulation that is fully encapsulated in generative models.","Specifically, Unbounded draws inspiration from sandbox life simulations and allows you to interact with your autonomous virtual character in a virtual world by feeding, playing with and guiding it - with open-ended mechanics generated by an LLM, some of which can be emergent.","In order to develop Unbounded, we propose technical innovations in both the LLM and visual generation domains.","Specifically, we present: (1) a specialized, distilled large language model (LLM) that dynamically generates game mechanics, narratives, and character interactions in real-time, and (2) a new dynamic regional image prompt Adapter (IP-Adapter) for vision models that ensures consistent yet flexible visual generation of a character across multiple environments.","We evaluate our system through both qualitative and quantitative analysis, showing significant improvements in character life simulation, user instruction following, narrative coherence, and visual consistency for both characters and the environments compared to traditional related approaches."],"url":"http://arxiv.org/abs/2410.18975v1"}
{"created":"2024-10-24 17:59:30","title":"3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation","abstract":"Multi-view image diffusion models have significantly advanced open-domain 3D object generation. However, most existing models rely on 2D network architectures that lack inherent 3D biases, resulting in compromised geometric consistency. To address this challenge, we introduce 3D-Adapter, a plug-in module designed to infuse 3D geometry awareness into pretrained image diffusion models. Central to our approach is the idea of 3D feedback augmentation: for each denoising step in the sampling loop, 3D-Adapter decodes intermediate multi-view features into a coherent 3D representation, then re-encodes the rendered RGBD views to augment the pretrained base model through feature addition. We study two variants of 3D-Adapter: a fast feed-forward version based on Gaussian splatting and a versatile training-free version utilizing neural fields and meshes. Our extensive experiments demonstrate that 3D-Adapter not only greatly enhances the geometry quality of text-to-multi-view models such as Instant3D and Zero123++, but also enables high-quality 3D generation using the plain text-to-image Stable Diffusion. Furthermore, we showcase the broad application potential of 3D-Adapter by presenting high quality results in text-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.","sentences":["Multi-view image diffusion models have significantly advanced open-domain 3D object generation.","However, most existing models rely on 2D network architectures that lack inherent 3D biases, resulting in compromised geometric consistency.","To address this challenge, we introduce 3D-Adapter, a plug-in module designed to infuse 3D geometry awareness into pretrained image diffusion models.","Central to our approach is the idea of 3D feedback augmentation: for each denoising step in the sampling loop, 3D-Adapter decodes intermediate multi-view features into a coherent 3D representation, then re-encodes the rendered RGBD views to augment the pretrained base model through feature addition.","We study two variants of 3D-Adapter: a fast feed-forward version based on Gaussian splatting and a versatile training-free version utilizing neural fields and meshes.","Our extensive experiments demonstrate that 3D-Adapter not only greatly enhances the geometry quality of text-to-multi-view models such as Instant3D and Zero123++, but also enables high-quality 3D generation using the plain text-to-image Stable Diffusion.","Furthermore, we showcase the broad application potential of 3D-Adapter by presenting high quality results in text-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks."],"url":"http://arxiv.org/abs/2410.18974v1"}
{"created":"2024-10-24 17:59:21","title":"Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques","abstract":"Cognitive decline is a natural part of aging, often resulting in reduced cognitive abilities. In some cases, however, this decline is more pronounced, typically due to disorders such as Alzheimer's disease. Early detection of anomalous cognitive decline is crucial, as it can facilitate timely professional intervention. While medical data can help in this detection, it often involves invasive procedures. An alternative approach is to employ non-intrusive techniques such as speech or handwriting analysis, which do not necessarily affect daily activities. This survey reviews the most relevant methodologies that use deep learning techniques to automate the cognitive decline estimation task, including audio, text, and visual processing. We discuss the key features and advantages of each modality and methodology, including state-of-the-art approaches like Transformer architecture and foundation models. In addition, we present works that integrate different modalities to develop multimodal models. We also highlight the most significant datasets and the quantitative results from studies using these resources. From this review, several conclusions emerge. In most cases, the textual modality achieves the best results and is the most relevant for detecting cognitive decline. Moreover, combining various approaches from individual modalities into a multimodal model consistently enhances performance across nearly all scenarios.","sentences":["Cognitive decline is a natural part of aging, often resulting in reduced cognitive abilities.","In some cases, however, this decline is more pronounced, typically due to disorders such as Alzheimer's disease.","Early detection of anomalous cognitive decline is crucial, as it can facilitate timely professional intervention.","While medical data can help in this detection, it often involves invasive procedures.","An alternative approach is to employ non-intrusive techniques such as speech or handwriting analysis, which do not necessarily affect daily activities.","This survey reviews the most relevant methodologies that use deep learning techniques to automate the cognitive decline estimation task, including audio, text, and visual processing.","We discuss the key features and advantages of each modality and methodology, including state-of-the-art approaches like Transformer architecture and foundation models.","In addition, we present works that integrate different modalities to develop multimodal models.","We also highlight the most significant datasets and the quantitative results from studies using these resources.","From this review, several conclusions emerge.","In most cases, the textual modality achieves the best results and is the most relevant for detecting cognitive decline.","Moreover, combining various approaches from individual modalities into a multimodal model consistently enhances performance across nearly all scenarios."],"url":"http://arxiv.org/abs/2410.18972v1"}
{"created":"2024-10-24 17:59:16","title":"ConceptDrift: Uncovering Biases through the Lens of Foundational Models","abstract":"Datasets and pre-trained models come with intrinsic biases. Most methods rely on spotting them by analysing misclassified samples, in a semi-automated human-computer validation. In contrast, we propose ConceptDrift, a method which analyzes the weights of a linear probe, learned on top a foundational model. We capitalize on the weight update trajectory, which starts from the embedding of the textual representation of the class, and proceeds to drift towards embeddings that disclose hidden biases. Different from prior work, with this approach we can pin-point unwanted correlations from a dataset, providing more than just possible explanations for the wrong predictions. We empirically prove the efficacy of our method, by significantly improving zero-shot performance with biased-augmented prompting. Our method is not bounded to a single modality, and we experiment in this work with both image (Waterbirds, CelebA, Nico++) and text datasets (CivilComments).","sentences":["Datasets and pre-trained models come with intrinsic biases.","Most methods rely on spotting them by analysing misclassified samples, in a semi-automated human-computer validation.","In contrast, we propose ConceptDrift, a method which analyzes the weights of a linear probe, learned on top a foundational model.","We capitalize on the weight update trajectory, which starts from the embedding of the textual representation of the class, and proceeds to drift towards embeddings that disclose hidden biases.","Different from prior work, with this approach we can pin-point unwanted correlations from a dataset, providing more than just possible explanations for the wrong predictions.","We empirically prove the efficacy of our method, by significantly improving zero-shot performance with biased-augmented prompting.","Our method is not bounded to a single modality, and we experiment in this work with both image (Waterbirds, CelebA, Nico++) and text datasets (CivilComments)."],"url":"http://arxiv.org/abs/2410.18970v1"}
{"created":"2024-10-24 17:59:14","title":"Self-Improving Autonomous Underwater Manipulation","abstract":"Underwater robotic manipulation faces significant challenges due to complex fluid dynamics and unstructured environments, causing most manipulation systems to rely heavily on human teleoperation. In this paper, we introduce AquaBot, a fully autonomous manipulation system that combines behavior cloning from human demonstrations with self-learning optimization to improve beyond human teleoperation performance. With extensive real-world experiments, we demonstrate AquaBot's versatility across diverse manipulation tasks, including object grasping, trash sorting, and rescue retrieval. Our real-world experiments show that AquaBot's self-optimized policy outperforms a human operator by 41% in speed. AquaBot represents a promising step towards autonomous and self-improving underwater manipulation systems. We open-source both hardware and software implementation details.","sentences":["Underwater robotic manipulation faces significant challenges due to complex fluid dynamics and unstructured environments, causing most manipulation systems to rely heavily on human teleoperation.","In this paper, we introduce AquaBot, a fully autonomous manipulation system that combines behavior cloning from human demonstrations with self-learning optimization to improve beyond human teleoperation performance.","With extensive real-world experiments, we demonstrate AquaBot's versatility across diverse manipulation tasks, including object grasping, trash sorting, and rescue retrieval.","Our real-world experiments show that AquaBot's self-optimized policy outperforms a human operator by 41% in speed.","AquaBot represents a promising step towards autonomous and self-improving underwater manipulation systems.","We open-source both hardware and software implementation details."],"url":"http://arxiv.org/abs/2410.18969v1"}
{"created":"2024-10-24 17:58:31","title":"Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms","abstract":"Building a generalist model for user interface (UI) understanding is challenging due to various foundational issues, such as platform diversity, resolution variation, and data limitation. In this paper, we introduce Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI understanding across a wide range of platforms, including iPhone, Android, iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI 2 introduces three key innovations: support for multiple platform types, high-resolution perception through adaptive scaling, and advanced task training data generation powered by GPT-4o with set-of-mark visual prompting. These advancements enable Ferret-UI 2 to perform complex, user-centered interactions, making it highly versatile and adaptable for the expanding diversity of platform ecosystems. Extensive empirical experiments on referring, grounding, user-centric advanced tasks (comprising 9 subtasks $\\times$ 5 platforms), GUIDE next-action prediction dataset, and GUI-World multi-platform benchmark demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also shows strong cross-platform transfer capabilities.","sentences":["Building a generalist model for user interface (UI) understanding is challenging due to various foundational issues, such as platform diversity, resolution variation, and data limitation.","In this paper, we introduce Ferret-UI 2, a multimodal large language model (MLLM) designed for universal UI understanding across a wide range of platforms, including iPhone, Android, iPad, Webpage, and AppleTV.","Building on the foundation of Ferret-UI, Ferret-UI 2 introduces three key innovations: support for multiple platform types, high-resolution perception through adaptive scaling, and advanced task training data generation powered by GPT-4o with set-of-mark visual prompting.","These advancements enable Ferret-UI 2 to perform complex, user-centered interactions, making it highly versatile and adaptable for the expanding diversity of platform ecosystems.","Extensive empirical experiments on referring, grounding, user-centric advanced tasks (comprising 9 subtasks $\\times$ 5 platforms), GUIDE next-action prediction dataset, and GUI-World multi-platform benchmark demonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and also shows strong cross-platform transfer capabilities."],"url":"http://arxiv.org/abs/2410.18967v1"}
{"created":"2024-10-24 17:58:22","title":"Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions","abstract":"Large language models (LLMs) have demonstrated great performance across various benchmarks, showing potential as general-purpose task solvers. However, as LLMs are typically trained on vast amounts of data, a significant concern in their evaluation is data contamination, where overlap between training data and evaluation datasets inflates performance assessments. While multiple approaches have been developed to identify data contamination, these approaches rely on specific assumptions that may not hold universally across different settings. To bridge this gap, we systematically review 47 papers on data contamination detection, categorize the underlying assumptions, and assess whether they have been rigorously validated. We identify and analyze eight categories of assumptions and test three of them as case studies. Our analysis reveals that when classifying instances used for pretraining LLMs, detection approaches based on these three assumptions perform close to random guessing, suggesting that current LLMs learn data distributions rather than memorizing individual instances. Overall, this work underscores the importance of approaches clearly stating their underlying assumptions and testing their validity across various scenarios.","sentences":["Large language models (LLMs) have demonstrated great performance across various benchmarks, showing potential as general-purpose task solvers.","However, as LLMs are typically trained on vast amounts of data, a significant concern in their evaluation is data contamination, where overlap between training data and evaluation datasets inflates performance assessments.","While multiple approaches have been developed to identify data contamination, these approaches rely on specific assumptions that may not hold universally across different settings.","To bridge this gap, we systematically review 47 papers on data contamination detection, categorize the underlying assumptions, and assess whether they have been rigorously validated.","We identify and analyze eight categories of assumptions and test three of them as case studies.","Our analysis reveals that when classifying instances used for pretraining LLMs, detection approaches based on these three assumptions perform close to random guessing, suggesting that current LLMs learn data distributions rather than memorizing individual instances.","Overall, this work underscores the importance of approaches clearly stating their underlying assumptions and testing their validity across various scenarios."],"url":"http://arxiv.org/abs/2410.18966v1"}
{"created":"2024-10-24 17:58:21","title":"On the Crucial Role of Initialization for Matrix Factorization","abstract":"This work revisits the classical low-rank matrix factorization problem and unveils the critical role of initialization in shaping convergence rates for such nonconvex and nonsmooth optimization. We introduce Nystrom initialization, which significantly improves the global convergence of Scaled Gradient Descent (ScaledGD) in both symmetric and asymmetric matrix factorization tasks. Specifically, we prove that ScaledGD with Nystrom initialization achieves quadratic convergence in cases where only linear rates were previously known. Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly used for finetuning foundation models. Our approach, NoRA, i.e., LoRA with Nystrom initialization, demonstrates superior performance across various downstream tasks and model scales, from 1B to 7B parameters, in large language and diffusion models.","sentences":["This work revisits the classical low-rank matrix factorization problem and unveils the critical role of initialization in shaping convergence rates for such nonconvex and nonsmooth optimization.","We introduce Nystrom initialization, which significantly improves the global convergence of Scaled Gradient Descent (ScaledGD) in both symmetric and asymmetric matrix factorization tasks.","Specifically, we prove that ScaledGD with Nystrom initialization achieves quadratic convergence in cases where only linear rates were previously known.","Furthermore, we extend this initialization to low-rank adapters (LoRA) commonly used for finetuning foundation models.","Our approach, NoRA, i.e., LoRA with Nystrom initialization, demonstrates superior performance across various downstream tasks and model scales, from 1B to 7B parameters, in large language and diffusion models."],"url":"http://arxiv.org/abs/2410.18965v1"}
{"created":"2024-10-24 17:58:11","title":"Learning to Look: Seeking Information for Decision Making via Policy Factorization","abstract":"Many robot manipulation tasks require active or interactive exploration behavior in order to be performed successfully. Such tasks are ubiquitous in embodied domains, where agents must actively search for the information necessary for each stage of a task, e.g., moving the head of the robot to find information relevant to manipulation, or in multi-robot domains, where one scout robot may search for the information that another robot needs to make informed decisions. We identify these tasks with a new type of problem, factorized Contextual Markov Decision Processes, and propose DISaM, a dual-policy solution composed of an information-seeking policy that explores the environment to find the relevant contextual information and an information-receiving policy that exploits the context to achieve the manipulation goal. This factorization allows us to train both policies separately, using the information-receiving one to provide reward to train the information-seeking policy. At test time, the dual agent balances exploration and exploitation based on the uncertainty the manipulation policy has on what the next best action is. We demonstrate the capabilities of our dual policy solution in five manipulation tasks that require information-seeking behaviors, both in simulation and in the real-world, where DISaM significantly outperforms existing methods. More information at https://robin-lab.cs.utexas.edu/learning2look/.","sentences":["Many robot manipulation tasks require active or interactive exploration behavior in order to be performed successfully.","Such tasks are ubiquitous in embodied domains, where agents must actively search for the information necessary for each stage of a task, e.g., moving the head of the robot to find information relevant to manipulation, or in multi-robot domains, where one scout robot may search for the information that another robot needs to make informed decisions.","We identify these tasks with a new type of problem, factorized Contextual Markov Decision Processes, and propose DISaM, a dual-policy solution composed of an information-seeking policy that explores the environment to find the relevant contextual information and an information-receiving policy that exploits the context to achieve the manipulation goal.","This factorization allows us to train both policies separately, using the information-receiving one to provide reward to train the information-seeking policy.","At test time, the dual agent balances exploration and exploitation based on the uncertainty the manipulation policy has on what the next best action is.","We demonstrate the capabilities of our dual policy solution in five manipulation tasks that require information-seeking behaviors, both in simulation and in the real-world, where DISaM significantly outperforms existing methods.","More information at https://robin-lab.cs.utexas.edu/learning2look/."],"url":"http://arxiv.org/abs/2410.18964v1"}
{"created":"2024-10-24 17:58:08","title":"OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning","abstract":"Large language models (LLMs) and large multimodal models (LMMs) have shown great potential in automating complex tasks like web browsing and gaming. However, their ability to generalize across diverse applications remains limited, hindering broader utility. To address this challenge, we present OSCAR: Operating System Control via state-Aware reasoning and Re-planning. OSCAR is a generalist agent designed to autonomously navigate and interact with various desktop and mobile applications through standardized controls, such as mouse and keyboard inputs, while processing screen images to fulfill user commands. OSCAR translates human instructions into executable Python code, enabling precise control over graphical user interfaces (GUIs). To enhance stability and adaptability, OSCAR operates as a state machine, equipped with error-handling mechanisms and dynamic task re-planning, allowing it to efficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR's effectiveness through extensive experiments on diverse benchmarks across desktop and mobile platforms, where it transforms complex workflows into simple natural language commands, significantly boosting user productivity. Our code will be open-source upon publication.","sentences":["Large language models (LLMs) and large multimodal models (LMMs) have shown great potential in automating complex tasks like web browsing and gaming.","However, their ability to generalize across diverse applications remains limited, hindering broader utility.","To address this challenge, we present OSCAR: Operating System Control via state-Aware reasoning and Re-planning.","OSCAR is a generalist agent designed to autonomously navigate and interact with various desktop and mobile applications through standardized controls, such as mouse and keyboard inputs, while processing screen images to fulfill user commands.","OSCAR translates human instructions into executable Python code, enabling precise control over graphical user interfaces (GUIs).","To enhance stability and adaptability, OSCAR operates as a state machine, equipped with error-handling mechanisms and dynamic task re-planning, allowing it to efficiently adjust to real-time feedback and exceptions.","We demonstrate OSCAR's effectiveness through extensive experiments on diverse benchmarks across desktop and mobile platforms, where it transforms complex workflows into simple natural language commands, significantly boosting user productivity.","Our code will be open-source upon publication."],"url":"http://arxiv.org/abs/2410.18963v1"}
{"created":"2024-10-24 17:58:05","title":"Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction","abstract":"Spatial intelligence is the ability of a machine to perceive, reason, and act in three dimensions within space and time. Recent advancements in large-scale auto-regressive models have demonstrated remarkable capabilities across various reasoning tasks. However, these models often struggle with fundamental aspects of spatial reasoning, particularly in answering questions like \"Where am I?\" and \"What will I see?\". While some attempts have been done, existing approaches typically treat them as separate tasks, failing to capture their interconnected nature. In this paper, we present Generative Spatial Transformer (GST), a novel auto-regressive framework that jointly addresses spatial localization and view prediction. Our model simultaneously estimates the camera pose from a single image and predicts the view from a new camera pose, effectively bridging the gap between spatial awareness and visual prediction. The proposed innovative camera tokenization method enables the model to learn the joint distribution of 2D projections and their corresponding spatial perspectives in an auto-regressive manner. This unified training paradigm demonstrates that joint optimization of pose estimation and novel view synthesis leads to improved performance in both tasks, for the first time, highlighting the inherent relationship between spatial awareness and visual prediction.","sentences":["Spatial intelligence is the ability of a machine to perceive, reason, and act in three dimensions within space and time.","Recent advancements in large-scale auto-regressive models have demonstrated remarkable capabilities across various reasoning tasks.","However, these models often struggle with fundamental aspects of spatial reasoning, particularly in answering questions like \"Where am I?\" and \"What will I see?\".","While some attempts have been done, existing approaches typically treat them as separate tasks, failing to capture their interconnected nature.","In this paper, we present Generative Spatial Transformer (GST), a novel auto-regressive framework that jointly addresses spatial localization and view prediction.","Our model simultaneously estimates the camera pose from a single image and predicts the view from a new camera pose, effectively bridging the gap between spatial awareness and visual prediction.","The proposed innovative camera tokenization method enables the model to learn the joint distribution of 2D projections and their corresponding spatial perspectives in an auto-regressive manner.","This unified training paradigm demonstrates that joint optimization of pose estimation and novel view synthesis leads to improved performance in both tasks, for the first time, highlighting the inherent relationship between spatial awareness and visual prediction."],"url":"http://arxiv.org/abs/2410.18962v1"}
{"created":"2024-10-24 17:56:08","title":"Context is Key: A Benchmark for Forecasting with Essential Textual Information","abstract":"Forecasting is a critical task in decision making across various domains. While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions. Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language. However, the ability of existing forecasting models to effectively integrate this textual information remains an open question. To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities. We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark. Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings. By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise. The benchmark can be visualized at https://servicenow.github.io/context-is-key-forecasting/v0/ .","sentences":["Forecasting is a critical task in decision making across various domains.","While numerical data provides a foundation, it often lacks crucial context necessary for accurate predictions.","Human forecasters frequently rely on additional information, such as background knowledge or constraints, which can be efficiently communicated through natural language.","However, the ability of existing forecasting models to effectively integrate this textual information remains an open question.","To address this, we introduce \"Context is Key\" (CiK), a time series forecasting benchmark that pairs numerical data with diverse types of carefully crafted textual context, requiring models to integrate both modalities.","We evaluate a range of approaches, including statistical models, time series foundation models, and LLM-based forecasters, and propose a simple yet effective LLM prompting method that outperforms all other tested methods on our benchmark.","Our experiments highlight the importance of incorporating contextual information, demonstrate surprising performance when using LLM-based forecasting models, and also reveal some of their critical shortcomings.","By presenting this benchmark, we aim to advance multimodal forecasting, promoting models that are both accurate and accessible to decision-makers with varied technical expertise.","The benchmark can be visualized at https://servicenow.github.io/context-is-key-forecasting/v0/ ."],"url":"http://arxiv.org/abs/2410.18959v1"}
{"created":"2024-10-24 17:55:52","title":"Stable Consistency Tuning: Understanding and Improving Consistency Models","abstract":"Diffusion models achieve superior generation quality but suffer from slow generation speed due to the iterative nature of denoising. In contrast, consistency models, a new generative family, achieve competitive performance with significantly faster sampling. These models are trained either through consistency distillation, which leverages pretrained diffusion models, or consistency training/tuning directly from raw data. In this work, we propose a novel framework for understanding consistency models by modeling the denoising process of the diffusion model as a Markov Decision Process (MDP) and framing consistency model training as the value estimation through Temporal Difference~(TD) Learning. More importantly, this framework allows us to analyze the limitations of current consistency training/tuning strategies. Built upon Easy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT), which incorporates variance-reduced learning using the score identity. SCT leads to significant performance improvements on benchmarks such as CIFAR-10 and ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID 1.55, a new SoTA for consistency models.","sentences":["Diffusion models achieve superior generation quality but suffer from slow generation speed due to the iterative nature of denoising.","In contrast, consistency models, a new generative family, achieve competitive performance with significantly faster sampling.","These models are trained either through consistency distillation, which leverages pretrained diffusion models, or consistency training/tuning directly from raw data.","In this work, we propose a novel framework for understanding consistency models by modeling the denoising process of the diffusion model as a Markov Decision Process (MDP) and framing consistency model training as the value estimation through Temporal Difference~(TD) Learning.","More importantly, this framework allows us to analyze the limitations of current consistency training/tuning strategies.","Built upon Easy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT), which incorporates variance-reduced learning using the score identity.","SCT leads to significant performance improvements on benchmarks such as CIFAR-10 and ImageNet-64.","On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID 1.55, a new SoTA for consistency models."],"url":"http://arxiv.org/abs/2410.18958v1"}
{"created":"2024-10-24 17:55:03","title":"Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code","abstract":"Large Language Models (LLMs) demonstrate strong proficiency in generating code for high-resource programming languages (HRPLs) like Python but struggle significantly with low-resource programming languages (LRPLs) such as Racket or D. This performance gap deepens the digital divide, preventing developers using LRPLs from benefiting equally from LLM advancements and reinforcing disparities in innovation within underrepresented programming communities. While generating additional training data for LRPLs is promising, it faces two key challenges: manual annotation is labor-intensive and costly, and LLM-generated LRPL code is often of subpar quality. The underlying cause of this issue is the gap between natural language to programming language gap (NL-PL Gap), which is especially pronounced in LRPLs due to limited aligned data. In this work, we introduce a novel approach called Bridge-Coder, which leverages LLMs' intrinsic capabilities to enhance the performance on LRPLs. Our method consists of two key stages. Bridge Generation, where we create high-quality dataset by utilizing LLMs' general knowledge understanding, proficiency in HRPLs, and in-context learning abilities. Then, we apply the Bridged Alignment, which progressively improves the alignment between NL instructions and LRPLs. Experimental results across multiple LRPLs show that Bridge-Coder significantly enhances model performance, demonstrating the effectiveness and generalization of our approach. Furthermore, we offer a detailed analysis of the key components of our method, providing valuable insights for future work aimed at addressing the challenges associated with LRPLs.","sentences":["Large Language Models (LLMs) demonstrate strong proficiency in generating code for high-resource programming languages (HRPLs) like Python but struggle significantly with low-resource programming languages (LRPLs) such as Racket or D. This performance gap deepens the digital divide, preventing developers using LRPLs from benefiting equally from LLM advancements and reinforcing disparities in innovation within underrepresented programming communities.","While generating additional training data for LRPLs is promising, it faces two key challenges: manual annotation is labor-intensive and costly, and LLM-generated LRPL code is often of subpar quality.","The underlying cause of this issue is the gap between natural language to programming language gap (NL-PL Gap), which is especially pronounced in LRPLs due to limited aligned data.","In this work, we introduce a novel approach called Bridge-Coder, which leverages LLMs' intrinsic capabilities to enhance the performance on LRPLs.","Our method consists of two key stages.","Bridge Generation, where we create high-quality dataset by utilizing LLMs' general knowledge understanding, proficiency in HRPLs, and in-context learning abilities.","Then, we apply the Bridged Alignment, which progressively improves the alignment between NL instructions and LRPLs.","Experimental results across multiple LRPLs show that Bridge-Coder significantly enhances model performance, demonstrating the effectiveness and generalization of our approach.","Furthermore, we offer a detailed analysis of the key components of our method, providing valuable insights for future work aimed at addressing the challenges associated with LRPLs."],"url":"http://arxiv.org/abs/2410.18957v1"}
{"created":"2024-10-24 17:54:42","title":"Large Spatial Model: End-to-end Unposed Images to Semantic 3D","abstract":"Reconstructing and understanding 3D structures from a limited number of images is a well-established problem in computer vision. Traditional methods usually break this task into multiple subtasks, each requiring complex transformations between different data representations. For instance, dense reconstruction through Structure-from-Motion (SfM) involves converting images into key points, optimizing camera parameters, and estimating structures. Afterward, accurate sparse reconstructions are required for further dense modeling, which is subsequently fed into task-specific neural networks. This multi-step process results in considerable processing time and increased engineering complexity.   In this work, we present the Large Spatial Model (LSM), which processes unposed RGB images directly into semantic radiance fields. LSM simultaneously estimates geometry, appearance, and semantics in a single feed-forward operation, and it can generate versatile label maps by interacting with language at novel viewpoints. Leveraging a Transformer-based architecture, LSM integrates global geometry through pixel-aligned point maps. To enhance spatial attribute regression, we incorporate local context aggregation with multi-scale fusion, improving the accuracy of fine local details. To tackle the scarcity of labeled 3D semantic data and enable natural language-driven scene manipulation, we incorporate a pre-trained 2D language-based segmentation model into a 3D-consistent semantic feature field. An efficient decoder then parameterizes a set of semantic anisotropic Gaussians, facilitating supervised end-to-end learning. Extensive experiments across various tasks show that LSM unifies multiple 3D vision tasks directly from unposed images, achieving real-time semantic 3D reconstruction for the first time.","sentences":["Reconstructing and understanding 3D structures from a limited number of images is a well-established problem in computer vision.","Traditional methods usually break this task into multiple subtasks, each requiring complex transformations between different data representations.","For instance, dense reconstruction through Structure-from-Motion (SfM) involves converting images into key points, optimizing camera parameters, and estimating structures.","Afterward, accurate sparse reconstructions are required for further dense modeling, which is subsequently fed into task-specific neural networks.","This multi-step process results in considerable processing time and increased engineering complexity.   ","In this work, we present the Large Spatial Model (LSM), which processes unposed RGB images directly into semantic radiance fields.","LSM simultaneously estimates geometry, appearance, and semantics in a single feed-forward operation, and it can generate versatile label maps by interacting with language at novel viewpoints.","Leveraging a Transformer-based architecture, LSM integrates global geometry through pixel-aligned point maps.","To enhance spatial attribute regression, we incorporate local context aggregation with multi-scale fusion, improving the accuracy of fine local details.","To tackle the scarcity of labeled 3D semantic data and enable natural language-driven scene manipulation, we incorporate a pre-trained 2D language-based segmentation model into a 3D-consistent semantic feature field.","An efficient decoder then parameterizes a set of semantic anisotropic Gaussians, facilitating supervised end-to-end learning.","Extensive experiments across various tasks show that LSM unifies multiple 3D vision tasks directly from unposed images, achieving real-time semantic 3D reconstruction for the first time."],"url":"http://arxiv.org/abs/2410.18956v1"}
{"created":"2024-10-24 17:53:53","title":"BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning","abstract":"Large language models (LLMs) such as ChatGPT are fine-tuned on large and diverse instruction-following corpora, and can generalize to new tasks. However, those instruction-tuned LLMs often perform poorly in specialized medical natural language understanding (NLU) tasks that require domain knowledge, granular text comprehension, and structured data extraction. To bridge the gap, we: (1) propose a unified prompting format for 7 important NLU tasks, % through span extraction and multi-choice question-answering (QA), (2) curate an instruction-tuning dataset, MNLU-Instruct, utilizing diverse existing open-source medical NLU corpora, and (3) develop BioMistral-NLU, a generalizable medical NLU model, through fine-tuning BioMistral on MNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting, across 6 important NLU tasks, from two widely adopted medical NLU benchmarks: Biomedical Language Understanding Evaluation (BLUE) and Biomedical Language Understanding and Reasoning Benchmark (BLURB). Our experiments show that our BioMistral-NLU outperforms the original BioMistral, as well as the proprietary LLMs - ChatGPT and GPT-4. Our dataset-agnostic prompting strategy and instruction tuning step over diverse NLU tasks enhance LLMs' generalizability across diverse medical NLU tasks. Our ablation experiments show that instruction-tuning on a wider variety of tasks, even when the total number of training instances remains constant, enhances downstream zero-shot generalization.","sentences":["Large language models (LLMs) such as ChatGPT are fine-tuned on large and diverse instruction-following corpora, and can generalize to new tasks.","However, those instruction-tuned LLMs often perform poorly in specialized medical natural language understanding (NLU) tasks that require domain knowledge, granular text comprehension, and structured data extraction.","To bridge the gap, we: (1) propose a unified prompting format for 7 important NLU tasks, % through span extraction and multi-choice question-answering (QA), (2) curate an instruction-tuning dataset, MNLU-Instruct, utilizing diverse existing open-source medical NLU corpora, and (3) develop BioMistral-NLU, a generalizable medical NLU model, through fine-tuning BioMistral on MNLU-Instruct.","We evaluate BioMistral-NLU in a zero-shot setting, across 6 important NLU tasks, from two widely adopted medical NLU benchmarks: Biomedical Language Understanding Evaluation (BLUE) and Biomedical Language Understanding and Reasoning Benchmark (BLURB).","Our experiments show that our BioMistral-NLU outperforms the original BioMistral, as well as the proprietary LLMs - ChatGPT and GPT-4.","Our dataset-agnostic prompting strategy and instruction tuning step over diverse NLU tasks enhance LLMs' generalizability across diverse medical NLU tasks.","Our ablation experiments show that instruction-tuning on a wider variety of tasks, even when the total number of training instances remains constant, enhances downstream zero-shot generalization."],"url":"http://arxiv.org/abs/2410.18955v1"}
{"created":"2024-10-24 17:53:33","title":"Learning Structured Compressed Sensing with Automatic Resource Allocation","abstract":"Multidimensional data acquisition often requires extensive time and poses significant challenges for hardware and software regarding data storage and processing. Rather than designing a single compression matrix as in conventional compressed sensing, structured compressed sensing yields dimension-specific compression matrices, reducing the number of optimizable parameters. Recent advances in machine learning (ML) have enabled task-based supervised learning of subsampling matrices, albeit at the expense of complex downstream models. Additionally, the sampling resource allocation across dimensions is often determined in advance through heuristics. To address these challenges, we introduce Structured COmpressed Sensing with Automatic Resource Allocation (SCOSARA) with an information theory-based unsupervised learning strategy. SCOSARA adaptively distributes samples across sampling dimensions while maximizing Fisher information content. Using ultrasound localization as a case study, we compare SCOSARA to state-of-the-art ML-based and greedy search algorithms. Simulation results demonstrate that SCOSARA can produce high-quality subsampling matrices that achieve lower Cram\\'er-Rao Bound values than the baselines. In addition, SCOSARA outperforms other ML-based algorithms in terms of the number of trainable parameters, computational complexity, and memory requirements while automatically choosing the number of samples per axis.","sentences":["Multidimensional data acquisition often requires extensive time and poses significant challenges for hardware and software regarding data storage and processing.","Rather than designing a single compression matrix as in conventional compressed sensing, structured compressed sensing yields dimension-specific compression matrices, reducing the number of optimizable parameters.","Recent advances in machine learning (ML) have enabled task-based supervised learning of subsampling matrices, albeit at the expense of complex downstream models.","Additionally, the sampling resource allocation across dimensions is often determined in advance through heuristics.","To address these challenges, we introduce Structured COmpressed Sensing with Automatic Resource Allocation (SCOSARA) with an information theory-based unsupervised learning strategy.","SCOSARA adaptively distributes samples across sampling dimensions while maximizing Fisher information content.","Using ultrasound localization as a case study, we compare SCOSARA to state-of-the-art ML-based and greedy search algorithms.","Simulation results demonstrate that SCOSARA can produce high-quality subsampling matrices that achieve lower Cram\\'er-Rao Bound values than the baselines.","In addition, SCOSARA outperforms other ML-based algorithms in terms of the number of trainable parameters, computational complexity, and memory requirements while automatically choosing the number of samples per axis."],"url":"http://arxiv.org/abs/2410.18954v1"}
{"created":"2024-10-24 17:52:31","title":"Dynamic Vocabulary Pruning in Early-Exit LLMs","abstract":"Increasing the size of large language models (LLMs) has been shown to lead to better performance. However, this comes at the cost of slower and more expensive inference. Early-exiting is a promising approach for improving the efficiency of LLM inference by enabling next token prediction at intermediate layers. Yet, the large vocabulary size in modern LLMs makes the confidence estimation required for exit decisions computationally expensive, diminishing the efficiency gains. To address this, we propose dynamically pruning the vocabulary at test time for each token. Specifically, the vocabulary is pruned at one of the initial layers, and the smaller vocabulary is then used throughout the rest of the forward pass. Our experiments demonstrate that such post-hoc dynamic vocabulary pruning improves the efficiency of confidence estimation in early-exit LLMs while maintaining competitive performance.","sentences":["Increasing the size of large language models (LLMs) has been shown to lead to better performance.","However, this comes at the cost of slower and more expensive inference.","Early-exiting is a promising approach for improving the efficiency of LLM inference by enabling next token prediction at intermediate layers.","Yet, the large vocabulary size in modern LLMs makes the confidence estimation required for exit decisions computationally expensive, diminishing the efficiency gains.","To address this, we propose dynamically pruning the vocabulary at test time for each token.","Specifically, the vocabulary is pruned at one of the initial layers, and the smaller vocabulary is then used throughout the rest of the forward pass.","Our experiments demonstrate that such post-hoc dynamic vocabulary pruning improves the efficiency of confidence estimation in early-exit LLMs while maintaining competitive performance."],"url":"http://arxiv.org/abs/2410.18952v1"}
{"created":"2024-10-24 17:50:08","title":"Adjusted Overfitting Regression","abstract":"In this paper, I will introduce a new form of regression, that can adjust overfitting and underfitting through, \"distance-based regression.\" Overfitting often results in finding false patterns causing inaccurate results, so by having a new approach that minimizes overfitting, more accurate predictions can be derived. Then I will proceed with a test of my regression form and show additional ways to optimize the regression. Finally, I will apply my new technique to a specific data set to demonstrate its practical value.","sentences":["In this paper, I will introduce a new form of regression, that can adjust overfitting and underfitting through, \"distance-based regression.\"","Overfitting often results in finding false patterns causing inaccurate results, so by having a new approach that minimizes overfitting, more accurate predictions can be derived.","Then I will proceed with a test of my regression form and show additional ways to optimize the regression.","Finally, I will apply my new technique to a specific data set to demonstrate its practical value."],"url":"http://arxiv.org/abs/2410.18950v1"}
{"created":"2024-10-24 17:35:12","title":"Path Guiding for Monte Carlo PDE Solvers","abstract":"In recent years, Monte Carlo PDE solvers have garnered increasing attention in computer graphics, demonstrating value across a wide range of applications. Despite offering clear advantages over traditional methods-such as avoiding discretization and enabling local evaluations-Monte Carlo PDE solvers face challenges due to their stochastic nature, including high variance and slow convergence rates. To mitigate the variance issue, we draw inspiration from Monte Carlo path tracing and apply the path guiding technique to the Walk on Stars estimator. Specifically, we examine the target sampling distribution at each step of the Walk on Stars estimator, parameterize it, and introduce neural implicit representations to model the spatially-varying guiding distribution. This path guiding approach is implemented in a wavefront-style PDE solver, and experimental results demonstrate that it effectively reduces variance in Monte Carlo PDE solvers.","sentences":["In recent years, Monte Carlo PDE solvers have garnered increasing attention in computer graphics, demonstrating value across a wide range of applications.","Despite offering clear advantages over traditional methods-such as avoiding discretization and enabling local evaluations-Monte Carlo PDE solvers face challenges due to their stochastic nature, including high variance and slow convergence rates.","To mitigate the variance issue, we draw inspiration from Monte Carlo path tracing and apply the path guiding technique to the Walk on Stars estimator.","Specifically, we examine the target sampling distribution at each step of the Walk on Stars estimator, parameterize it, and introduce neural implicit representations to model the spatially-varying guiding distribution.","This path guiding approach is implemented in a wavefront-style PDE solver, and experimental results demonstrate that it effectively reduces variance in Monte Carlo PDE solvers."],"url":"http://arxiv.org/abs/2410.18944v1"}
{"created":"2024-10-24 17:22:24","title":"Matching Composition and Efficient Weight Reduction in Dynamic Matching","abstract":"We consider the foundational problem of maintaining a $(1-\\varepsilon)$-approximate maximum weight matching (MWM) in an $n$-node dynamic graph undergoing edge insertions and deletions. We provide a general reduction that reduces the problem on graphs with a weight range of $\\mathrm{poly}(n)$ to $\\mathrm{poly}(1/\\varepsilon)$ at the cost of just an additive $\\mathrm{poly}(1/\\varepsilon)$ in update time. This improves upon the prior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight range of $\\varepsilon^{-O(1/\\varepsilon)}$ with a multiplicative cost of $O(\\log n)$.   When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this yields a reduction from dynamic $(1-\\varepsilon)$-approximate MWM in bipartite graphs with a weight range of $\\mathrm{poly}(n)$ to dynamic $(1-\\varepsilon)$-approximate maximum cardinality matching in bipartite graphs at the cost of a multiplicative $\\mathrm{poly}(1/\\varepsilon)$ in update time, thereby resolving an open problem in [GP'13; BDL'21]. Additionally, we show that our approach is amenable to MWM problems in streaming, shared-memory work-depth, and massively parallel computation models. We also apply our techniques to obtain an efficient dynamic algorithm for rounding weighted fractional matchings in general graphs. Underlying our framework is a new structural result about MWM that we call the \"matching composition lemma\" and new dynamic matching subroutines that may be of independent interest.","sentences":["We consider the foundational problem of maintaining a $(1-\\varepsilon)$-approximate maximum weight matching (MWM) in an $n$-node dynamic graph undergoing edge insertions and deletions.","We provide a general reduction that reduces the problem on graphs with a weight range of $\\mathrm{poly}(n)$ to $\\mathrm{poly}(1/\\varepsilon)$ at the cost of just an additive $\\mathrm{poly}(1/\\varepsilon)$ in update time.","This improves upon the prior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weight range of $\\varepsilon^{-O(1/\\varepsilon)}$ with a multiplicative cost of $O(\\log n)$.   When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) this yields a reduction from dynamic $(1-\\varepsilon)$-approximate MWM in bipartite graphs with a weight range of $\\mathrm{poly}(n)$ to dynamic $(1-\\varepsilon)$-approximate maximum cardinality matching in bipartite graphs at the cost of a multiplicative $\\mathrm{poly}(1/\\varepsilon)$ in update time, thereby resolving an open problem in [GP'13; BDL'21].","Additionally, we show that our approach is amenable to MWM problems in streaming, shared-memory work-depth, and massively parallel computation models.","We also apply our techniques to obtain an efficient dynamic algorithm for rounding weighted fractional matchings in general graphs.","Underlying our framework is a new structural result about MWM that we call the \"matching composition lemma\" and new dynamic matching subroutines that may be of independent interest."],"url":"http://arxiv.org/abs/2410.18936v1"}
{"created":"2024-10-24 17:21:43","title":"Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play","abstract":"Complex news events, such as natural disasters and socio-political conflicts, require swift responses from the government and society. Relying on historical events to project the future is insufficient as such events are sparse and do not cover all possible conditions and nuanced situations. Simulation of these complex events can help better prepare and reduce the negative impact. We develop a controllable complex news event simulator guided by both the event schema representing domain knowledge about the scenario and user-provided assumptions representing case-specific conditions. As event dynamics depend on the fine-grained social and cultural context, we further introduce a geo-diverse commonsense and cultural norm-aware knowledge enhancement component. To enhance the coherence of the simulation, apart from the global timeline of events, we take an agent-based approach to simulate the individual character states, plans, and actions. By incorporating the schema and cultural norms, our generated simulations achieve much higher coherence and appropriateness and are received favorably by participants from a humanitarian assistance organization.","sentences":["Complex news events, such as natural disasters and socio-political conflicts, require swift responses from the government and society.","Relying on historical events to project the future is insufficient as such events are sparse and do not cover all possible conditions and nuanced situations.","Simulation of these complex events can help better prepare and reduce the negative impact.","We develop a controllable complex news event simulator guided by both the event schema representing domain knowledge about the scenario and user-provided assumptions representing case-specific conditions.","As event dynamics depend on the fine-grained social and cultural context, we further introduce a geo-diverse commonsense and cultural norm-aware knowledge enhancement component.","To enhance the coherence of the simulation, apart from the global timeline of events, we take an agent-based approach to simulate the individual character states, plans, and actions.","By incorporating the schema and cultural norms, our generated simulations achieve much higher coherence and appropriateness and are received favorably by participants from a humanitarian assistance organization."],"url":"http://arxiv.org/abs/2410.18935v1"}
{"created":"2024-10-24 17:19:53","title":"ANAVI: Audio Noise Awareness using Visuals of Indoor environments for NAVIgation","abstract":"We propose Audio Noise Awareness using Visuals of Indoors for NAVIgation for quieter robot path planning. While humans are naturally aware of the noise they make and its impact on those around them, robots currently lack this awareness. A key challenge in achieving audio awareness for robots is estimating how loud will the robot's actions be at a listener's location? Since sound depends upon the geometry and material composition of rooms, we train the robot to passively perceive loudness using visual observations of indoor environments. To this end, we generate data on how loud an 'impulse' sounds at different listener locations in simulated homes, and train our Acoustic Noise Predictor (ANP). Next, we collect acoustic profiles corresponding to different actions for navigation. Unifying ANP with action acoustics, we demonstrate experiments with wheeled (Hello Robot Stretch) and legged (Unitree Go2) robots so that these robots adhere to the noise constraints of the environment. See code and data at https://anavi-corl24.github.io/","sentences":["We propose Audio Noise Awareness using Visuals of Indoors for NAVIgation for quieter robot path planning.","While humans are naturally aware of the noise they make and its impact on those around them, robots currently lack this awareness.","A key challenge in achieving audio awareness for robots is estimating how loud will the robot's actions be at a listener's location?","Since sound depends upon the geometry and material composition of rooms, we train the robot to passively perceive loudness using visual observations of indoor environments.","To this end, we generate data on how loud an 'impulse' sounds at different listener locations in simulated homes, and train our Acoustic Noise Predictor (ANP).","Next, we collect acoustic profiles corresponding to different actions for navigation.","Unifying ANP with action acoustics, we demonstrate experiments with wheeled (Hello Robot Stretch) and legged (Unitree Go2) robots so that these robots adhere to the noise constraints of the environment.","See code and data at https://anavi-corl24.github.io/"],"url":"http://arxiv.org/abs/2410.18932v1"}
{"created":"2024-10-24 17:18:01","title":"Sort-free Gaussian Splatting via Weighted Sum Rendering","abstract":"Recently, 3D Gaussian Splatting (3DGS) has emerged as a significant advancement in 3D scene reconstruction, attracting considerable attention due to its ability to recover high-fidelity details while maintaining low complexity. Despite the promising results achieved by 3DGS, its rendering performance is constrained by its dependence on costly non-commutative alpha-blending operations. These operations mandate complex view dependent sorting operations that introduce computational overhead, especially on the resource-constrained platforms such as mobile phones. In this paper, we propose Weighted Sum Rendering, which approximates alpha blending with weighted sums, thereby removing the need for sorting. This simplifies implementation, delivers superior performance, and eliminates the \"popping\" artifacts caused by sorting. Experimental results show that optimizing a generalized Gaussian splatting formulation to the new differentiable rendering yields competitive image quality. The method was implemented and tested in a mobile device GPU, achieving on average $1.23\\times$ faster rendering.","sentences":["Recently, 3D Gaussian Splatting (3DGS) has emerged as a significant advancement in 3D scene reconstruction, attracting considerable attention due to its ability to recover high-fidelity details while maintaining low complexity.","Despite the promising results achieved by 3DGS, its rendering performance is constrained by its dependence on costly non-commutative alpha-blending operations.","These operations mandate complex view dependent sorting operations that introduce computational overhead, especially on the resource-constrained platforms such as mobile phones.","In this paper, we propose Weighted Sum Rendering, which approximates alpha blending with weighted sums, thereby removing the need for sorting.","This simplifies implementation, delivers superior performance, and eliminates the \"popping\" artifacts caused by sorting.","Experimental results show that optimizing a generalized Gaussian splatting formulation to the new differentiable rendering yields competitive image quality.","The method was implemented and tested in a mobile device GPU, achieving on average $1.23\\times$ faster rendering."],"url":"http://arxiv.org/abs/2410.18931v1"}
{"created":"2024-10-24 17:14:40","title":"SafeBench: A Safety Evaluation Framework for Multimodal Large Language Models","abstract":"Multimodal Large Language Models (MLLMs) are showing strong safety concerns (e.g., generating harmful outputs for users), which motivates the development of safety evaluation benchmarks. However, we observe that existing safety benchmarks for MLLMs show limitations in query quality and evaluation reliability limiting the detection of model safety implications as MLLMs continue to evolve. In this paper, we propose \\toolns, a comprehensive framework designed for conducting safety evaluations of MLLMs. Our framework consists of a comprehensive harmful query dataset and an automated evaluation protocol that aims to address the above limitations, respectively. We first design an automatic safety dataset generation pipeline, where we employ a set of LLM judges to recognize and categorize the risk scenarios that are most harmful and diverse for MLLMs; based on the taxonomy, we further ask these judges to generate high-quality harmful queries accordingly resulting in 23 risk scenarios with 2,300 multi-modal harmful query pairs. During safety evaluation, we draw inspiration from the jury system in judicial proceedings and pioneer the jury deliberation evaluation protocol that adopts collaborative LLMs to evaluate whether target models exhibit specific harmful behaviors, providing a reliable and unbiased assessment of content security risks. In addition, our benchmark can also be extended to the audio modality showing high scalability and potential. Based on our framework, we conducted large-scale experiments on 15 widely-used open-source MLLMs and 6 commercial MLLMs (e.g., GPT-4o, Gemini), where we revealed widespread safety issues in existing MLLMs and instantiated several insights on MLLM safety performance such as image quality and parameter size.","sentences":["Multimodal Large Language Models (MLLMs) are showing strong safety concerns (e.g., generating harmful outputs for users), which motivates the development of safety evaluation benchmarks.","However, we observe that existing safety benchmarks for MLLMs show limitations in query quality and evaluation reliability limiting the detection of model safety implications as MLLMs continue to evolve.","In this paper, we propose \\toolns, a comprehensive framework designed for conducting safety evaluations of MLLMs.","Our framework consists of a comprehensive harmful query dataset and an automated evaluation protocol that aims to address the above limitations, respectively.","We first design an automatic safety dataset generation pipeline, where we employ a set of LLM judges to recognize and categorize the risk scenarios that are most harmful and diverse for MLLMs; based on the taxonomy, we further ask these judges to generate high-quality harmful queries accordingly resulting in 23 risk scenarios with 2,300 multi-modal harmful query pairs.","During safety evaluation, we draw inspiration from the jury system in judicial proceedings and pioneer the jury deliberation evaluation protocol that adopts collaborative LLMs to evaluate whether target models exhibit specific harmful behaviors, providing a reliable and unbiased assessment of content security risks.","In addition, our benchmark can also be extended to the audio modality showing high scalability and potential.","Based on our framework, we conducted large-scale experiments on 15 widely-used open-source MLLMs and 6 commercial MLLMs (e.g., GPT-4o, Gemini), where we revealed widespread safety issues in existing MLLMs and instantiated several insights on MLLM safety performance such as image quality and parameter size."],"url":"http://arxiv.org/abs/2410.18927v1"}
{"created":"2024-10-24 17:13:39","title":"LoRANN: Low-Rank Matrix Factorization for Approximate Nearest Neighbor Search","abstract":"Approximate nearest neighbor (ANN) search is a key component in many modern machine learning pipelines; recent use cases include retrieval-augmented generation (RAG) and vector databases. Clustering-based ANN algorithms, that use score computation methods based on product quantization (PQ), are often used in industrial-scale applications due to their scalability and suitability for distributed and disk-based implementations. However, they have slower query times than the leading graph-based ANN algorithms. In this work, we propose a new supervised score computation method based on the observation that inner product approximation is a multivariate (multi-output) regression problem that can be solved efficiently by reduced-rank regression. Our experiments show that on modern high-dimensional data sets, the proposed reduced-rank regression (RRR) method is superior to PQ in both query latency and memory usage. We also introduce LoRANN, a clustering-based ANN library that leverages the proposed score computation method. LoRANN is competitive with the leading graph-based algorithms and outperforms the state-of-the-art GPU ANN methods on high-dimensional data sets.","sentences":["Approximate nearest neighbor (ANN) search is a key component in many modern machine learning pipelines; recent use cases include retrieval-augmented generation (RAG) and vector databases.","Clustering-based ANN algorithms, that use score computation methods based on product quantization (PQ), are often used in industrial-scale applications due to their scalability and suitability for distributed and disk-based implementations.","However, they have slower query times than the leading graph-based ANN algorithms.","In this work, we propose a new supervised score computation method based on the observation that inner product approximation is a multivariate (multi-output) regression problem that can be solved efficiently by reduced-rank regression.","Our experiments show that on modern high-dimensional data sets, the proposed reduced-rank regression (RRR) method is superior to PQ in both query latency and memory usage.","We also introduce LoRANN, a clustering-based ANN library that leverages the proposed score computation method.","LoRANN is competitive with the leading graph-based algorithms and outperforms the state-of-the-art GPU ANN methods on high-dimensional data sets."],"url":"http://arxiv.org/abs/2410.18926v1"}
{"created":"2024-10-24 17:12:51","title":"Swarm manipulation: An efficient and accurate technique for multi-object manipulation in virtual reality","abstract":"The theory of swarm control shows promise for controlling multiple objects, however, scalability is hindered by cost constraints, such as hardware and infrastructure. Virtual Reality (VR) can overcome these limitations, but research on swarm interaction in VR is limited. This paper introduces a novel Swarm Manipulation interaction technique and compares it with two baseline techniques: Virtual Hand and Controller (ray-casting). We evaluated these techniques in a user study ($N$ = 12) in three tasks (selection, rotation, and resizing) across five conditions. Our results indicate that Swarm Manipulation yielded superior performance, with significantly faster speeds in most conditions across the three tasks. It notably reduced resizing size deviations but introduced a trade-off between speed and accuracy in the rotation task. Additionally, we conducted a follow-up user study ($N$ = 6) using Swarm Manipulation in two complex VR scenarios and obtained insights through semi-structured interviews, shedding light on optimized swarm control mechanisms and perceptual changes induced by this interaction paradigm. These results demonstrate the potential of the Swarm Manipulation technique to enhance the usability and user experience in VR compared to conventional manipulation techniques. In future studies, we aim to understand and improve swarm interaction via internal swarm particle cooperation.","sentences":["The theory of swarm control shows promise for controlling multiple objects, however, scalability is hindered by cost constraints, such as hardware and infrastructure.","Virtual Reality (VR) can overcome these limitations, but research on swarm interaction in VR is limited.","This paper introduces a novel Swarm Manipulation interaction technique and compares it with two baseline techniques: Virtual Hand and Controller (ray-casting).","We evaluated these techniques in a user study ($N$ = 12) in three tasks (selection, rotation, and resizing) across five conditions.","Our results indicate that Swarm Manipulation yielded superior performance, with significantly faster speeds in most conditions across the three tasks.","It notably reduced resizing size deviations but introduced a trade-off between speed and accuracy in the rotation task.","Additionally, we conducted a follow-up user study ($N$ = 6) using Swarm Manipulation in two complex VR scenarios and obtained insights through semi-structured interviews, shedding light on optimized swarm control mechanisms and perceptual changes induced by this interaction paradigm.","These results demonstrate the potential of the Swarm Manipulation technique to enhance the usability and user experience in VR compared to conventional manipulation techniques.","In future studies, we aim to understand and improve swarm interaction via internal swarm particle cooperation."],"url":"http://arxiv.org/abs/2410.18924v1"}
{"created":"2024-10-24 17:11:52","title":"SegLLM: Multi-round Reasoning Segmentation","abstract":"We present SegLLM, a novel multi-round interactive reasoning segmentation model that enhances LLM-based segmentation by exploiting conversational memory of both visual and textual outputs. By leveraging a mask-aware multimodal LLM, SegLLM re-integrates previous segmentation results into its input stream, enabling it to reason about complex user intentions and segment objects in relation to previously identified entities, including positional, interactional, and hierarchical relationships, across multiple interactions. This capability allows SegLLM to respond to visual and text queries in a chat-like manner. Evaluated on the newly curated MRSeg benchmark, SegLLM outperforms existing methods in multi-round interactive reasoning segmentation by over 20%. Additionally, we observed that training on multi-round reasoning segmentation data enhances performance on standard single-round referring segmentation and localization tasks, resulting in a 5.5% increase in cIoU for referring expression segmentation and a 4.5% improvement in Acc@0.5 for referring expression localization.","sentences":["We present SegLLM, a novel multi-round interactive reasoning segmentation model that enhances LLM-based segmentation by exploiting conversational memory of both visual and textual outputs.","By leveraging a mask-aware multimodal LLM, SegLLM re-integrates previous segmentation results into its input stream, enabling it to reason about complex user intentions and segment objects in relation to previously identified entities, including positional, interactional, and hierarchical relationships, across multiple interactions.","This capability allows SegLLM to respond to visual and text queries in a chat-like manner.","Evaluated on the newly curated MRSeg benchmark, SegLLM outperforms existing methods in multi-round interactive reasoning segmentation by over 20%.","Additionally, we observed that training on multi-round reasoning segmentation data enhances performance on standard single-round referring segmentation and localization tasks, resulting in a 5.5% increase in cIoU for referring expression segmentation and a 4.5% improvement in Acc@0.5 for referring expression localization."],"url":"http://arxiv.org/abs/2410.18923v1"}
{"created":"2024-10-24 17:10:39","title":"From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems","abstract":"Consider the math problem: \"Lily received 3 cookies from her best friend yesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies. How many cookies does Lily have now?\" Many large language models (LLMs) in previous research approach this problem by calculating the answer \"1\" using the equation \"3 - 5 + 3.\" However, from a human perspective, we recognize the inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only had 3. This discrepancy prompts a key question: Are current LLMs merely Blind Solver that apply mathematical operations without deeper reasoning, or can they function as Logical Thinker capable of identifying logical inconsistencies?   To explore this question, we propose a benchmark dataset, FaultyMath, which includes faulty math problems of rich diversity: i) multiple mathematical categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of difficulty, and iii) different origins of faultiness -- ranging from violations of common sense and ambiguous statements to mathematical contradictions and more. We evaluate a broad spectrum of LLMs, including open-source, closed-source, and math-specialized models, using FaultyMath across three dimensions: (i) How accurately can the models detect faulty math problems without being explicitly prompted to do so? (ii) When provided with hints -- either correct or misleading -- about the validity of the problems, to what extent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthy are the explanations generated by LLMs when they recognize a math problem as flawed? Through extensive experimentation and detailed analysis, our results demonstrate that existing LLMs largely function as Blind Solver and fall short of the reasoning capabilities required to perform as Logical Thinker.","sentences":["Consider the math problem: \"Lily received 3 cookies from her best friend yesterday and ate 5 for breakfast.","Today, her friend gave her 3 more cookies.","How many cookies does Lily have now?\"","Many large language models (LLMs) in previous research approach this problem by calculating the answer \"1\" using the equation \"3 - 5 + 3.\"","However, from a human perspective, we recognize the inherent flaw in this problem: Lily cannot eat 5 cookies if she initially only had 3.","This discrepancy prompts a key question: Are current LLMs merely Blind Solver that apply mathematical operations without deeper reasoning, or can they function as Logical Thinker capable of identifying logical inconsistencies?   ","To explore this question, we propose a benchmark dataset, FaultyMath, which includes faulty math problems of rich diversity: i) multiple mathematical categories, e.g., algebra, geometry, number theory, etc., ii) varying levels of difficulty, and iii) different origins of faultiness -- ranging from violations of common sense and ambiguous statements to mathematical contradictions and more.","We evaluate a broad spectrum of LLMs, including open-source, closed-source, and math-specialized models, using FaultyMath across three dimensions: (i) How accurately can the models detect faulty math problems without being explicitly prompted to do so?","(ii) When provided with hints -- either correct or misleading -- about the validity of the problems, to what extent do LLMs adapt to become reliable Logical Thinker?","(iii) How trustworthy are the explanations generated by LLMs when they recognize a math problem as flawed?","Through extensive experimentation and detailed analysis, our results demonstrate that existing LLMs largely function as Blind Solver and fall short of the reasoning capabilities required to perform as Logical Thinker."],"url":"http://arxiv.org/abs/2410.18921v1"}
{"created":"2024-10-24 17:09:37","title":"Optimizing Edge Offloading Decisions for Object Detection","abstract":"Recent advances in machine learning and hardware have produced embedded devices capable of performing real-time object detection with commendable accuracy. We consider a scenario in which embedded devices rely on an onboard object detector, but have the option to offload detection to a more powerful edge server when local accuracy is deemed too low. Resource constraints, however, limit the number of images that can be offloaded to the edge. Our goal is to identify which images to offload to maximize overall detection accuracy under those constraints. To that end, the paper introduces a reward metric designed to quantify potential accuracy improvements from offloading individual images, and proposes an efficient approach to make offloading decisions by estimating this reward based only on local detection results. The approach is computationally frugal enough to run on embedded devices, and empirical findings indicate that it outperforms existing alternatives in improving detection accuracy even when the fraction of offloaded images is small.","sentences":["Recent advances in machine learning and hardware have produced embedded devices capable of performing real-time object detection with commendable accuracy.","We consider a scenario in which embedded devices rely on an onboard object detector, but have the option to offload detection to a more powerful edge server when local accuracy is deemed too low.","Resource constraints, however, limit the number of images that can be offloaded to the edge.","Our goal is to identify which images to offload to maximize overall detection accuracy under those constraints.","To that end, the paper introduces a reward metric designed to quantify potential accuracy improvements from offloading individual images, and proposes an efficient approach to make offloading decisions by estimating this reward based only on local detection results.","The approach is computationally frugal enough to run on embedded devices, and empirical findings indicate that it outperforms existing alternatives in improving detection accuracy even when the fraction of offloaded images is small."],"url":"http://arxiv.org/abs/2410.18919v1"}
{"created":"2024-10-24 17:08:20","title":"Using Parametric PINNs for Predicting Internal and External Turbulent Flows","abstract":"Computational fluid dynamics (CFD) solvers employing two-equation eddy viscosity models are the industry standard for simulating turbulent flows using the Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods are computationally less expensive than direct numerical simulations, they can still incur significant computational costs to achieve the desired accuracy. In this context, physics-informed neural networks (PINNs) offer a promising approach for developing parametric surrogate models that leverage both existing, but limited CFD solutions and the governing differential equations to predict simulation outcomes in a computationally efficient, differentiable, and near real-time manner. In this work, we build upon the previously proposed RANS-PINN framework, which only focused on predicting flow over a cylinder. To investigate the efficacy of RANS-PINN as a viable approach to building parametric surrogate models, we investigate its accuracy in predicting relevant turbulent flow variables for both internal and external flows. To ensure training convergence with a more complex loss function, we adopt a novel sampling approach that exploits the domain geometry to ensure a proper balance among the contributions from various regions within the solution domain. The effectiveness of this framework is then demonstrated for two scenarios that represent a broad class of internal and external flow problems.","sentences":["Computational fluid dynamics (CFD) solvers employing two-equation eddy viscosity models are the industry standard for simulating turbulent flows using the Reynolds-averaged Navier-Stokes (RANS) formulation.","While these methods are computationally less expensive than direct numerical simulations, they can still incur significant computational costs to achieve the desired accuracy.","In this context, physics-informed neural networks (PINNs) offer a promising approach for developing parametric surrogate models that leverage both existing, but limited CFD solutions and the governing differential equations to predict simulation outcomes in a computationally efficient, differentiable, and near real-time manner.","In this work, we build upon the previously proposed RANS-PINN framework, which only focused on predicting flow over a cylinder.","To investigate the efficacy of RANS-PINN as a viable approach to building parametric surrogate models, we investigate its accuracy in predicting relevant turbulent flow variables for both internal and external flows.","To ensure training convergence with a more complex loss function, we adopt a novel sampling approach that exploits the domain geometry to ensure a proper balance among the contributions from various regions within the solution domain.","The effectiveness of this framework is then demonstrated for two scenarios that represent a broad class of internal and external flow problems."],"url":"http://arxiv.org/abs/2410.18917v1"}
{"created":"2024-10-24 17:05:34","title":"Testing Support Size More Efficiently Than Learning Histograms","abstract":"Consider two problems about an unknown probability distribution $p$:   1. How many samples from $p$ are required to test if $p$ is supported on $n$ elements or not? Specifically, given samples from $p$, determine whether it is supported on at most $n$ elements, or it is \"$\\epsilon$-far\" (in total variation distance) from being supported on $n$ elements.   2. Given $m$ samples from $p$, what is the largest lower bound on its support size that we can produce?   The best known upper bound for problem (1) uses a general algorithm for learning the histogram of the distribution $p$, which requires $\\Theta(\\tfrac{n}{\\epsilon^2 \\log n})$ samples. We show that testing can be done more efficiently than learning the histogram, using only $O(\\tfrac{n}{\\epsilon \\log n} \\log(1/\\epsilon))$ samples, nearly matching the best known lower bound of $\\Omega(\\tfrac{n}{\\epsilon \\log n})$. This algorithm also provides a better solution to problem (2), producing larger lower bounds on support size than what follows from previous work. The proof relies on an analysis of Chebyshev polynomial approximations outside the range where they are designed to be good approximations, and the paper is intended as an accessible self-contained exposition of the Chebyshev polynomial method.","sentences":["Consider two problems about an unknown probability distribution $p$:   1.","How many samples from $p$ are required to test if $p$ is supported on $n$ elements or not?","Specifically, given samples from $p$, determine whether it is supported on at most $n$ elements, or it is \"$\\epsilon$-far\" (in total variation distance) from being supported on $n$ elements.   ","2.","Given $m$ samples from $p$, what is the largest lower bound on its support size that we can produce?   ","The best known upper bound for problem (1) uses a general algorithm for learning the histogram of the distribution $p$, which requires $\\Theta(\\tfrac{n}{\\epsilon^2 \\log n})$ samples.","We show that testing can be done more efficiently than learning the histogram, using only $O(\\tfrac{n}{\\epsilon \\log n} \\log(1/\\epsilon))$ samples, nearly matching the best known lower bound of $\\Omega(\\tfrac{n}{\\epsilon \\log n})$.","This algorithm also provides a better solution to problem (2), producing larger lower bounds on support size than what follows from previous work.","The proof relies on an analysis of Chebyshev polynomial approximations outside the range where they are designed to be good approximations, and the paper is intended as an accessible self-contained exposition of the Chebyshev polynomial method."],"url":"http://arxiv.org/abs/2410.18915v1"}
{"created":"2024-10-24 17:02:52","title":"Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling","abstract":"Videos of robots interacting with objects encode rich information about the objects' dynamics. However, existing video prediction approaches typically do not explicitly account for the 3D information from videos, such as robot actions and objects' 3D states, limiting their use in real-world robotic applications. In this work, we introduce a framework to learn object dynamics directly from multi-view RGB videos by explicitly considering the robot's action trajectories and their effects on scene dynamics. We utilize the 3D Gaussian representation of 3D Gaussian Splatting (3DGS) to train a particle-based dynamics model using Graph Neural Networks. This model operates on sparse control particles downsampled from the densely tracked 3D Gaussian reconstructions. By learning the neural dynamics model on offline robot interaction data, our method can predict object motions under varying initial configurations and unseen robot actions. The 3D transformations of Gaussians can be interpolated from the motions of control particles, enabling the rendering of predicted future object states and achieving action-conditioned video prediction. The dynamics model can also be applied to model-based planning frameworks for object manipulation tasks. We conduct experiments on various kinds of deformable materials, including ropes, clothes, and stuffed animals, demonstrating our framework's ability to model complex shapes and dynamics. Our project page is available at https://gs-dynamics.github.io.","sentences":["Videos of robots interacting with objects encode rich information about the objects' dynamics.","However, existing video prediction approaches typically do not explicitly account for the 3D information from videos, such as robot actions and objects' 3D states, limiting their use in real-world robotic applications.","In this work, we introduce a framework to learn object dynamics directly from multi-view RGB videos by explicitly considering the robot's action trajectories and their effects on scene dynamics.","We utilize the 3D Gaussian representation of 3D Gaussian Splatting (3DGS) to train a particle-based dynamics model using Graph Neural Networks.","This model operates on sparse control particles downsampled from the densely tracked 3D Gaussian reconstructions.","By learning the neural dynamics model on offline robot interaction data, our method can predict object motions under varying initial configurations and unseen robot actions.","The 3D transformations of Gaussians can be interpolated from the motions of control particles, enabling the rendering of predicted future object states and achieving action-conditioned video prediction.","The dynamics model can also be applied to model-based planning frameworks for object manipulation tasks.","We conduct experiments on various kinds of deformable materials, including ropes, clothes, and stuffed animals, demonstrating our framework's ability to model complex shapes and dynamics.","Our project page is available at https://gs-dynamics.github.io."],"url":"http://arxiv.org/abs/2410.18912v1"}
{"created":"2024-10-24 16:59:26","title":"SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment","abstract":"Imitation learning from human demonstrations is an effective paradigm for robot manipulation, but acquiring large datasets is costly and resource-intensive, especially for long-horizon tasks. To address this issue, we propose SkillMimicGen (SkillGen), an automated system for generating demonstration datasets from a few human demos. SkillGen segments human demos into manipulation skills, adapts these skills to new contexts, and stitches them together through free-space transit and transfer motion. We also propose a Hybrid Skill Policy (HSP) framework for learning skill initiation, control, and termination components from SkillGen datasets, enabling skills to be sequenced using motion planning at test-time. We demonstrate that SkillGen greatly improves data generation and policy learning performance over a state-of-the-art data generation framework, resulting in the capability to produce data for large scene variations, including clutter, and agents that are on average 24% more successful. We demonstrate the efficacy of SkillGen by generating over 24K demonstrations across 18 task variants in simulation from just 60 human demonstrations, and training proficient, often near-perfect, HSP agents. Finally, we apply SkillGen to 3 real-world manipulation tasks and also demonstrate zero-shot sim-to-real transfer on a long-horizon assembly task. Videos, and more at https://skillgen.github.io.","sentences":["Imitation learning from human demonstrations is an effective paradigm for robot manipulation, but acquiring large datasets is costly and resource-intensive, especially for long-horizon tasks.","To address this issue, we propose SkillMimicGen (SkillGen), an automated system for generating demonstration datasets from a few human demos.","SkillGen segments human demos into manipulation skills, adapts these skills to new contexts, and stitches them together through free-space transit and transfer motion.","We also propose a Hybrid Skill Policy (HSP) framework for learning skill initiation, control, and termination components from SkillGen datasets, enabling skills to be sequenced using motion planning at test-time.","We demonstrate that SkillGen greatly improves data generation and policy learning performance over a state-of-the-art data generation framework, resulting in the capability to produce data for large scene variations, including clutter, and agents that are on average 24% more successful.","We demonstrate the efficacy of SkillGen by generating over 24K demonstrations across 18 task variants in simulation from just 60 human demonstrations, and training proficient, often near-perfect, HSP agents.","Finally, we apply SkillGen to 3 real-world manipulation tasks and also demonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.","Videos, and more at https://skillgen.github.io."],"url":"http://arxiv.org/abs/2410.18907v1"}
{"created":"2024-10-24 16:57:20","title":"PRISM: A Methodology for Auditing Biases in Large Language Models","abstract":"Auditing Large Language Models (LLMs) to discover their biases and preferences is an emerging challenge in creating Responsible Artificial Intelligence (AI). While various methods have been proposed to elicit the preferences of such models, countermeasures have been taken by LLM trainers, such that LLMs hide, obfuscate or point blank refuse to disclosure their positions on certain subjects. This paper presents PRISM, a flexible, inquiry-based methodology for auditing LLMs - that seeks to illicit such positions indirectly through task-based inquiry prompting rather than direct inquiry of said preferences. To demonstrate the utility of the methodology, we applied PRISM on the Political Compass Test, where we assessed the political leanings of twenty-one LLMs from seven providers. We show LLMs, by default, espouse positions that are economically left and socially liberal (consistent with prior work). We also show the space of positions that these models are willing to espouse - where some models are more constrained and less compliant than others - while others are more neutral and objective. In sum, PRISM can more reliably probe and audit LLMs to understand their preferences, biases and constraints.","sentences":["Auditing Large Language Models (LLMs) to discover their biases and preferences is an emerging challenge in creating Responsible Artificial Intelligence (AI).","While various methods have been proposed to elicit the preferences of such models, countermeasures have been taken by LLM trainers, such that LLMs hide, obfuscate or point blank refuse to disclosure their positions on certain subjects.","This paper presents PRISM, a flexible, inquiry-based methodology for auditing LLMs - that seeks to illicit such positions indirectly through task-based inquiry prompting rather than direct inquiry of said preferences.","To demonstrate the utility of the methodology, we applied PRISM on the Political Compass Test, where we assessed the political leanings of twenty-one LLMs from seven providers.","We show LLMs, by default, espouse positions that are economically left and socially liberal (consistent with prior work).","We also show the space of positions that these models are willing to espouse - where some models are more constrained and less compliant than others - while others are more neutral and objective.","In sum, PRISM can more reliably probe and audit LLMs to understand their preferences, biases and constraints."],"url":"http://arxiv.org/abs/2410.18906v1"}
{"created":"2024-10-24 16:48:12","title":"LLMs for Extremely Low-Resource Finno-Ugric Languages","abstract":"The advancement of large language models (LLMs) has predominantly focused on high-resource languages, leaving low-resource languages, such as those in the Finno-Ugric family, significantly underrepresented. This paper addresses this gap by focusing on V\\~oro, Livonian, and Komi. We cover almost the entire cycle of LLM creation, from data collection to instruction tuning and evaluation. Our contributions include developing multilingual base and instruction-tuned models; creating evaluation benchmarks, including the smugri-MT-bench multi-turn conversational benchmark; and conducting human evaluation. We intend for this work to promote linguistic diversity, ensuring that lesser-resourced languages can benefit from advancements in NLP.","sentences":["The advancement of large language models (LLMs) has predominantly focused on high-resource languages, leaving low-resource languages, such as those in the Finno-Ugric family, significantly underrepresented.","This paper addresses this gap by focusing on V\\~oro, Livonian, and Komi.","We cover almost the entire cycle of LLM creation, from data collection to instruction tuning and evaluation.","Our contributions include developing multilingual base and instruction-tuned models; creating evaluation benchmarks, including the smugri-MT-bench multi-turn conversational benchmark; and conducting human evaluation.","We intend for this work to promote linguistic diversity, ensuring that lesser-resourced languages can benefit from advancements in NLP."],"url":"http://arxiv.org/abs/2410.18902v1"}
{"created":"2024-10-24 16:40:36","title":"Comparative Analysis of Indicators for Multiobjective Diversity Optimization","abstract":"Indicator-based (multiobjective) diversity optimization aims at finding a set of near (Pareto-)optimal solutions that maximizes a diversity indicator, where diversity is typically interpreted as the number of essentially different solutions. Whereas, in the first diversity-oriented evolutionary multiobjective optimization algorithm, the NOAH algorithm by Ulrich and Thiele, the Solow Polasky Diversity (also related to Magnitude) served as a metric, other diversity indicators might be considered, such as the parameter-free Max-Min Diversity, and the Riesz s-Energy, which features uniformly distributed solution sets. In this paper, focusing on multiobjective diversity optimization, we discuss different diversity indicators from the perspective of indicator-based evolutionary algorithms (IBEA) with multiple objectives. We examine theoretical, computational, and practical properties of these indicators, such as monotonicity in species, twinning, monotonicity in distance, strict monotonicity in distance, uniformity of maximizing point sets, computational effort for a set of size~n, single-point contributions, subset selection, and submodularity. We present new theorems -- including a proof of the NP-hardness of the Riesz s-Energy Subset Selection Problem -- and consolidate existing results from the literature. In the second part, we apply these indicators in the NOAH algorithm and analyze search dynamics through an example. We examine how optimizing with one indicator affects the performance of others and propose NOAH adaptations specific to the Max-Min indicator.","sentences":["Indicator-based (multiobjective) diversity optimization aims at finding a set of near (Pareto-)optimal solutions that maximizes a diversity indicator, where diversity is typically interpreted as the number of essentially different solutions.","Whereas, in the first diversity-oriented evolutionary multiobjective optimization algorithm, the NOAH algorithm by Ulrich and Thiele, the Solow Polasky Diversity (also related to Magnitude) served as a metric, other diversity indicators might be considered, such as the parameter-free Max-Min Diversity, and the Riesz s-Energy, which features uniformly distributed solution sets.","In this paper, focusing on multiobjective diversity optimization, we discuss different diversity indicators from the perspective of indicator-based evolutionary algorithms (IBEA) with multiple objectives.","We examine theoretical, computational, and practical properties of these indicators, such as monotonicity in species, twinning, monotonicity in distance, strict monotonicity in distance, uniformity of maximizing point sets, computational effort for a set of size~n, single-point contributions, subset selection, and submodularity.","We present new theorems -- including a proof of the NP-hardness of the Riesz s-Energy Subset Selection Problem -- and consolidate existing results from the literature.","In the second part, we apply these indicators in the NOAH algorithm and analyze search dynamics through an example.","We examine how optimizing with one indicator affects the performance of others and propose NOAH adaptations specific to the Max-Min indicator."],"url":"http://arxiv.org/abs/2410.18900v1"}
{"created":"2024-10-24 16:35:23","title":"ArterialNet: Reconstructing Arterial Blood Pressure Waveform with Wearable Pulsatile Signals, a Cohort-Aware Approach","abstract":"Continuous arterial blood pressure (ABP) monitoring is invasive but essential for hemodynamic monitoring. Recent techniques have reconstructed ABP non-invasively using pulsatile signals but produced inaccurate systolic and diastolic blood pressure (SBP and DBP) values and were sensitive to individual variability. ArterialNet integrates generalized pulsatile-to-ABP signal translation and personalized feature extraction using hybrid loss functions and regularization. We validated ArterialNet using the MIMIC-III dataset and achieved a root mean square error (RMSE) of 5.41 mmHg, with at least a 58% lower standard deviation. ArterialNet reconstructed ABP with an RMSE of 7.99 mmHg in remote health scenarios. ArterialNet achieved superior performance in ABP reconstruction and SBP and DBP estimations, with significantly reduced subject variance, demonstrating its potential in remote health settings. We also ablated ArterialNet architecture to investigate the contributions of each component and evaluated its translational impact and robustness by conducting a series of ablations on data quality and availability.","sentences":["Continuous arterial blood pressure (ABP) monitoring is invasive but essential for hemodynamic monitoring.","Recent techniques have reconstructed ABP non-invasively using pulsatile signals but produced inaccurate systolic and diastolic blood pressure (SBP and DBP) values and were sensitive to individual variability.","ArterialNet integrates generalized pulsatile-to-ABP signal translation and personalized feature extraction using hybrid loss functions and regularization.","We validated ArterialNet using the MIMIC-III dataset and achieved a root mean square error (RMSE) of 5.41 mmHg, with at least a 58% lower standard deviation.","ArterialNet reconstructed ABP with an RMSE of 7.99 mmHg in remote health scenarios.","ArterialNet achieved superior performance in ABP reconstruction and SBP and DBP estimations, with significantly reduced subject variance, demonstrating its potential in remote health settings.","We also ablated ArterialNet architecture to investigate the contributions of each component and evaluated its translational impact and robustness by conducting a series of ablations on data quality and availability."],"url":"http://arxiv.org/abs/2410.18895v1"}
{"created":"2024-10-24 16:32:23","title":"Meta-Learning with Heterogeneous Tasks","abstract":"Meta-learning is a general approach to equip machine learning models with the ability to handle few-shot scenarios when dealing with many tasks. Most existing meta-learning methods work based on the assumption that all tasks are of equal importance. However, real-world applications often present heterogeneous tasks characterized by varying difficulty levels, noise in training samples, or being distinctively different from most other tasks. In this paper, we introduce a novel meta-learning method designed to effectively manage such heterogeneous tasks by employing rank-based task-level learning objectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM). HeTRoM is proficient in handling heterogeneous tasks, and it prevents easy tasks from overwhelming the meta-learner. The approach allows for an efficient iterative optimization algorithm based on bi-level optimization, which is then improved by integrating statistical guidance. Our experimental results demonstrate that our method provides flexibility, enabling users to adapt to diverse task settings and enhancing the meta-learner's overall performance.","sentences":["Meta-learning is a general approach to equip machine learning models with the ability to handle few-shot scenarios when dealing with many tasks.","Most existing meta-learning methods work based on the assumption that all tasks are of equal importance.","However, real-world applications often present heterogeneous tasks characterized by varying difficulty levels, noise in training samples, or being distinctively different from most other tasks.","In this paper, we introduce a novel meta-learning method designed to effectively manage such heterogeneous tasks by employing rank-based task-level learning objectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM).","HeTRoM is proficient in handling heterogeneous tasks, and it prevents easy tasks from overwhelming the meta-learner.","The approach allows for an efficient iterative optimization algorithm based on bi-level optimization, which is then improved by integrating statistical guidance.","Our experimental results demonstrate that our method provides flexibility, enabling users to adapt to diverse task settings and enhancing the meta-learner's overall performance."],"url":"http://arxiv.org/abs/2410.18894v1"}
{"created":"2024-10-24 16:30:14","title":"Creating and Repairing Robot Programs in Open-World Domains","abstract":"Using Large Language Models (LLMs) to produce robot programs from natural language has allowed for robot systems that can complete a higher diversity of tasks. However, LLM-generated programs may be faulty, either due to ambiguity in instructions, misinterpretation of the desired task, or missing information about the world state. As these programs run, the state of the world changes and they gather new information. When a failure occurs, it is important that they recover from the current world state and avoid repeating steps that they they previously completed successfully. We propose RoboRepair, a system which traces the execution of a program up until error, and then runs an LLM-produced recovery program that minimizes repeated actions.   To evaluate the efficacy of our system, we create a benchmark consisting of eleven tasks with various error conditions that require the generation of a recovery program. We compare the efficiency of the recovery program to a plan built with an oracle that has foreknowledge of future errors.","sentences":["Using Large Language Models (LLMs) to produce robot programs from natural language has allowed for robot systems that can complete a higher diversity of tasks.","However, LLM-generated programs may be faulty, either due to ambiguity in instructions, misinterpretation of the desired task, or missing information about the world state.","As these programs run, the state of the world changes and they gather new information.","When a failure occurs, it is important that they recover from the current world state and avoid repeating steps that they they previously completed successfully.","We propose RoboRepair, a system which traces the execution of a program up until error, and then runs an LLM-produced recovery program that minimizes repeated actions.   ","To evaluate the efficacy of our system, we create a benchmark consisting of eleven tasks with various error conditions that require the generation of a recovery program.","We compare the efficiency of the recovery program to a plan built with an oracle that has foreknowledge of future errors."],"url":"http://arxiv.org/abs/2410.18893v1"}
{"created":"2024-10-24 16:27:35","title":"Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks","abstract":"Recent advancements in Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation. While these models excel in general complex reasoning tasks, they still face challenges in mathematical problem-solving and logical reasoning. To address these limitations, researchers have explored function calling abilities, allowing LLMs to execute provided functions and utilize their outputs for task completion. However, concentrating on specific tasks can be very inefficient for large-scale LLMs to be used, because of the expensive cost of training and inference stages they need in terms of computational resources. This study introduces a novel framework for training smaller language models in function calling, focusing on specific logical and mathematical reasoning tasks. The approach aims to improve performances of small-scale models for these tasks using function calling, ensuring a high level of accuracy. Our framework employs an agent that, given a problem and a set of callable functions, queries the LLM by injecting a description and examples of the usable functions into the prompt and managing their calls in a step-by-step reasoning chain. This process is used to create a dataset of correct and incorrect reasoning chain chat completions from a large-scale LLM. This dataset is used to train a smaller LLM using Reinforcement Learning from Human Feedback (RLHF), specifically employing the Direct Preference Optimization (DPO) technique. Experimental results demonstrate how the proposed approach balances the trade-off between model size and performance, improving the ability of function calling for reasoning tasks, in smaller models.","sentences":["Recent advancements in Large Language Models (LLMs) have demonstrated exceptional capabilities in natural language understanding and generation.","While these models excel in general complex reasoning tasks, they still face challenges in mathematical problem-solving and logical reasoning.","To address these limitations, researchers have explored function calling abilities, allowing LLMs to execute provided functions and utilize their outputs for task completion.","However, concentrating on specific tasks can be very inefficient for large-scale LLMs to be used, because of the expensive cost of training and inference stages they need in terms of computational resources.","This study introduces a novel framework for training smaller language models in function calling, focusing on specific logical and mathematical reasoning tasks.","The approach aims to improve performances of small-scale models for these tasks using function calling, ensuring a high level of accuracy.","Our framework employs an agent that, given a problem and a set of callable functions, queries the LLM by injecting a description and examples of the usable functions into the prompt and managing their calls in a step-by-step reasoning chain.","This process is used to create a dataset of correct and incorrect reasoning chain chat completions from a large-scale LLM.","This dataset is used to train a smaller LLM using Reinforcement Learning from Human Feedback (RLHF), specifically employing the Direct Preference Optimization (DPO) technique.","Experimental results demonstrate how the proposed approach balances the trade-off between model size and performance, improving the ability of function calling for reasoning tasks, in smaller models."],"url":"http://arxiv.org/abs/2410.18890v1"}
{"created":"2024-10-24 16:27:03","title":"Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance","abstract":"NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field. Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models. While crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency. Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets. In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples. Through a case study of four datasets from the TRUE benchmark, covering different tasks and domains, we empirically analyze the labeling quality of existing datasets, and compare expert, crowd-sourced, and our LLM-based annotations in terms of agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method. Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance. This suggests that many of the LLMs so-called mistakes are due to label errors rather than genuine model failures. Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve model performance.","sentences":["NLP benchmarks rely on standardized datasets for training and evaluating models and are crucial for advancing the field.","Traditionally, expert annotations ensure high-quality labels; however, the cost of expert annotation does not scale well with the growing demand for larger datasets required by modern models.","While crowd-sourcing provides a more scalable solution, it often comes at the expense of annotation precision and consistency.","Recent advancements in large language models (LLMs) offer new opportunities to enhance the annotation process, particularly for detecting label errors in existing datasets.","In this work, we consider the recent approach of LLM-as-a-judge, leveraging an ensemble of LLMs to flag potentially mislabeled examples.","Through a case study of four datasets from the TRUE benchmark, covering different tasks and domains, we empirically analyze the labeling quality of existing datasets, and compare expert, crowd-sourced, and our LLM-based annotations in terms of agreement, label quality, and efficiency, demonstrating the strengths and limitations of each annotation method.","Our findings reveal a substantial number of label errors, which, when corrected, induce a significant upward shift in reported model performance.","This suggests that many of the LLMs so-called mistakes are due to label errors rather than genuine model failures.","Additionally, we discuss the implications of mislabeled data and propose methods to mitigate them in training to improve model performance."],"url":"http://arxiv.org/abs/2410.18889v1"}
{"created":"2024-10-24 16:20:57","title":"Connectivity Labeling Schemes for Edge and Vertex Faults via Expander Hierarchies","abstract":"We consider the problem of assigning short labels to the vertices and edges of a graph $G$ so that given any query $\\langle s,t,F\\rangle$ with $|F|\\leq f$, we can determine whether $s$ and $t$ are still connected in $G-F$, given only the labels of $F\\cup\\{s,t\\}$. This problem has been considered when $F\\subset E$ (edge faults), where correctness is guaranteed with high probability (w.h.p.) or deterministically, and when $F\\subset V$ (vertex faults), both w.h.p.~and deterministically. Our main results are as follows.   [Deterministic Edge Faults.] We give a new deterministic labeling scheme for edge faults that uses $\\tilde{O}(\\sqrt{f})$-bit labels, which can be constructed in polynomial time. This improves on Dory and Parter's [PODC 2021] existential bound of $O(f\\log n)$ (requiring exponential time to compute) and the efficient $\\tilde{O}(f^2)$-bit scheme of Izumi, Emek, Wadayama, and Masuzawa [PODC 2023]. Our construction uses an improved edge-expander hierarchy and a distributed coding technique based on Reed-Solomon codes.   [Deterministic Vertex Faults.] We improve Parter, Petruschka, and Pettie's [STOC 2024] deterministic $O(f^7\\log^{13} n)$-bit labeling scheme for vertex faults to $O(f^4\\log^{7.5} n)$ bits, using an improved vertex-expander hierarchy and better sparsification of shortcut graphs.   [Randomized Edge/Verex Faults.] We improve the size of Dory and Parter's [PODC 2021] randomized edge fault labeling scheme from $O(\\min\\{f+\\log n, \\log^3 n\\})$ bits to $O(\\min\\{f+\\log n, \\log^2 n\\log f\\})$ bits, shaving a $\\log n/\\log f$ factor. We also improve the size of Parter, Petruschka, and Pettie's [STOC 2024] randomized vertex fault labeling scheme from $O(f^3\\log^5 n)$ bits to $O(f^2\\log^6 n)$ bits, which comes closer to their $\\Omega(f)$-bit lower bound.","sentences":["We consider the problem of assigning short labels to the vertices and edges of a graph $G$ so that given any query $\\langle s,t,F\\rangle$ with $|F|\\leq f$, we can determine whether $s$ and $t$ are still connected in $G-F$, given only the labels of $F\\cup\\{s,t\\}$. This problem has been considered when $F\\subset E$ (edge faults), where correctness is guaranteed with high probability (w.h.p.) or deterministically, and when $F\\subset V$ (vertex faults), both w.h.p.~and deterministically.","Our main results are as follows.   ","[Deterministic Edge Faults.]","We give a new deterministic labeling scheme for edge faults that uses $\\tilde{O}(\\sqrt{f})$-bit labels, which can be constructed in polynomial time.","This improves on Dory and Parter's [PODC 2021] existential bound of $O(f\\log n)$ (requiring exponential time to compute) and the efficient $\\tilde{O}(f^2)$-bit scheme of Izumi, Emek, Wadayama, and Masuzawa","[PODC 2023].","Our construction uses an improved edge-expander hierarchy and a distributed coding technique based on Reed-Solomon codes.   ","[Deterministic Vertex Faults.]","We improve Parter, Petruschka, and","Pettie's [STOC 2024] deterministic $O(f^7\\log^{13} n)$-bit labeling scheme for vertex faults to $O(f^4\\log^{7.5} n)$ bits, using an improved vertex-expander hierarchy and better sparsification of shortcut graphs.   ","[Randomized Edge/Verex Faults.]","We improve the size of Dory and Parter's [PODC 2021] randomized edge fault labeling scheme from $O(\\min\\{f+\\log n, \\log^3 n\\})$ bits to $O(\\min\\{f+\\log n, \\log^2 n\\log f\\})$ bits, shaving a $\\log n/\\log f$ factor.","We also improve the size of Parter, Petruschka, and Pettie's","[STOC 2024] randomized vertex fault labeling scheme from $O(f^3\\log^5 n)$ bits to $O(f^2\\log^6 n)$ bits, which comes closer to their $\\Omega(f)$-bit lower bound."],"url":"http://arxiv.org/abs/2410.18885v1"}
{"created":"2024-10-24 16:17:47","title":"A Survey of Multimodal Sarcasm Detection","abstract":"Sarcasm is a rhetorical device that is used to convey the opposite of the literal meaning of an utterance. Sarcasm is widely used on social media and other forms of computer-mediated communication motivating the use of computational models to identify it automatically. While the clear majority of approaches to sarcasm detection have been carried out on text only, sarcasm detection often requires additional information present in tonality, facial expression, and contextual images. This has led to the introduction of multimodal models, opening the possibility to detect sarcasm in multiple modalities such as audio, images, text, and video. In this paper, we present the first comprehensive survey on multimodal sarcasm detection - henceforth MSD - to date. We survey papers published between 2018 and 2023 on the topic, and discuss the models and datasets used for this task. We also present future research directions in MSD.","sentences":["Sarcasm is a rhetorical device that is used to convey the opposite of the literal meaning of an utterance.","Sarcasm is widely used on social media and other forms of computer-mediated communication motivating the use of computational models to identify it automatically.","While the clear majority of approaches to sarcasm detection have been carried out on text only, sarcasm detection often requires additional information present in tonality, facial expression, and contextual images.","This has led to the introduction of multimodal models, opening the possibility to detect sarcasm in multiple modalities such as audio, images, text, and video.","In this paper, we present the first comprehensive survey on multimodal sarcasm detection - henceforth MSD - to date.","We survey papers published between 2018 and 2023 on the topic, and discuss the models and datasets used for this task.","We also present future research directions in MSD."],"url":"http://arxiv.org/abs/2410.18882v1"}
{"created":"2024-10-24 16:17:18","title":"Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences","abstract":"One-step text-to-image generator models offer advantages such as swift inference efficiency, flexible architectures, and state-of-the-art generation performance. In this paper, we study the problem of aligning one-step generator models with human preferences for the first time. Inspired by the success of reinforcement learning using human feedback (RLHF), we formulate the alignment problem as maximizing expected human reward functions while adding an Integral Kullback-Leibler divergence term to prevent the generator from diverging. By overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the first, fast-converging and image data-free human preference alignment method for one-step text-to-image generators. We also introduce novel theoretical insights, showing that using CFG for diffusion distillation is secretly doing RLHF with DI++. Such an interesting finding brings understanding and potential contributions to future research involving CFG. In the experiment sections, we align both UNet-based and DiT-based one-step generators using DI++, which use the Stable Diffusion 1.5 and the PixelArt-$\\alpha$ as the reference diffusion processes. The resulting DiT-based one-step text-to-image model achieves a strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO validation prompt dataset. It also achieves a leading Human preference Score (HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\\alpha$. Both theoretical contributions and empirical evidence indicate that DI++ is a strong human-preference alignment approach for one-step text-to-image models.","sentences":["One-step text-to-image generator models offer advantages such as swift inference efficiency, flexible architectures, and state-of-the-art generation performance.","In this paper, we study the problem of aligning one-step generator models with human preferences for the first time.","Inspired by the success of reinforcement learning using human feedback (RLHF), we formulate the alignment problem as maximizing expected human reward functions while adding an Integral Kullback-Leibler divergence term to prevent the generator from diverging.","By overcoming technical challenges, we introduce Diff-Instruct++ (DI++), the first, fast-converging and image data-free human preference alignment method for one-step text-to-image generators.","We also introduce novel theoretical insights, showing that using CFG for diffusion distillation is secretly doing RLHF with DI++.","Such an interesting finding brings understanding and potential contributions to future research involving CFG.","In the experiment sections, we align both UNet-based and DiT-based one-step generators using DI++, which use the Stable Diffusion 1.5 and the PixelArt-$\\alpha$ as the reference diffusion processes.","The resulting DiT-based one-step text-to-image model achieves a strong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCO validation prompt dataset.","It also achieves a leading Human preference Score (HPSv2.0) of 28.48, outperforming other open-sourced models such as Stable Diffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\\alpha$. Both theoretical contributions and empirical evidence indicate that DI++ is a strong human-preference alignment approach for one-step text-to-image models."],"url":"http://arxiv.org/abs/2410.18881v1"}
{"created":"2024-10-24 16:13:06","title":"Multi-Class Abnormality Classification in Video Capsule Endoscopy Using Deep Learning","abstract":"This report outlines Team Seq2Cure's deep learning approach for the Capsule Vision 2024 Challenge, leveraging an ensemble of convolutional neural networks (CNNs) and transformer-based architectures for multi-class abnormality classification in video capsule endoscopy frames. The dataset comprised over 50,000 frames from three public sources and one private dataset, labeled across 10 abnormality classes. To overcome the limitations of traditional CNNs in capturing global context, we integrated CNN and transformer models within a multi-model ensemble. Our approach achieved a balanced accuracy of 86.34 percent and a mean AUC-ROC score of 0.9908 on the validation set, with significant improvements in classifying complex abnormalities. Code is available at http://github.com/arnavs04/capsule-vision-2024 .","sentences":["This report outlines Team Seq2Cure's deep learning approach for the Capsule Vision 2024 Challenge, leveraging an ensemble of convolutional neural networks (CNNs) and transformer-based architectures for multi-class abnormality classification in video capsule endoscopy frames.","The dataset comprised over 50,000 frames from three public sources and one private dataset, labeled across 10 abnormality classes.","To overcome the limitations of traditional CNNs in capturing global context, we integrated CNN and transformer models within a multi-model ensemble.","Our approach achieved a balanced accuracy of 86.34 percent and a mean AUC-ROC score of 0.9908 on the validation set, with significant improvements in classifying complex abnormalities.","Code is available at http://github.com/arnavs04/capsule-vision-2024 ."],"url":"http://arxiv.org/abs/2410.18879v1"}
{"created":"2024-10-24 16:08:41","title":"Packing Short Cycles","abstract":"Cycle packing is a fundamental problem in optimization, graph theory, and algorithms. Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Bj\\\"orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing.   In Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, $k$ vertex-disjoint cycles of minimum total weight. Our first main result is an algorithm that, for any fixed $k$, solves the problem in polynomial time. We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by $k$. The same results hold for the version of the problem where the task is to find $k$ edge-disjoint cycles.   Our second main result concerns Shortest Cycle Packing, which is a special case of Min-Sum Cycle Packing that asks to find a packing of $k$ shortest cycles in a graph. We prove this problem to be fixed-parameter tractable (FPT) when parameterized by $k$ on weighted planar graphs. We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs. Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing is FPT on general graphs remain challenging open questions.","sentences":["Cycle packing is a fundamental problem in optimization, graph theory, and algorithms.","Motivated by recent advancements in finding vertex-disjoint paths between a specified set of vertices that either minimize the total length of the paths [Bj\\\"orklund, Husfeldt, ICALP 2014; Mari, Mukherjee, Pilipczuk, and Sankowski, SODA 2024] or request the paths to be shortest [Lochet, SODA 2021], we consider the following cycle packing problems: Min-Sum Cycle Packing and Shortest Cycle Packing.   ","In Min-Sum Cycle Packing, we try to find, in a weighted undirected graph, $k$ vertex-disjoint cycles of minimum total weight.","Our first main result is an algorithm that, for any fixed $k$, solves the problem in polynomial time.","We complement this result by establishing the W[1]-hardness of Min-Sum Cycle Packing parameterized by $k$. The same results hold for the version of the problem where the task is to find $k$ edge-disjoint cycles.   ","Our second main result concerns Shortest Cycle Packing, which is a special case of Min-Sum Cycle Packing that asks to find a packing of $k$ shortest cycles in a graph.","We prove this problem to be fixed-parameter tractable (FPT) when parameterized by $k$ on weighted planar graphs.","We also obtain a polynomial kernel for the edge-disjoint variant of the problem on planar graphs.","Deciding whether Min-Sum Cycle Packing is FPT on planar graphs and whether Shortest Cycle Packing is FPT on general graphs remain challenging open questions."],"url":"http://arxiv.org/abs/2410.18878v1"}
{"created":"2024-10-24 16:05:38","title":"Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education","abstract":"In this innovative practice full paper, we address the equity gap for neurodivergent and situationally limited learners by identifying the spectrum of dynamic factors that impact learning and function. Educators have shown a growing interest in identifying learners' cognitive abilities and learning preferences to measure their impact on academic achievement. Often institutions employ one-size-fits-all approaches leaving the burden on disabled students to self-advocate or tolerate inadequate support. Emerging frameworks guide neurodivergent learners through instructional approaches, such as online education. However, these frameworks fail to address holistic environmental needs or recommend technology interventions, particularly for those with undisclosed learning or developmental disabilities and situational limitations. In this article, we integrate a neurodivergent perspective through secondary research of around 100 articles to introduce a Guiding Empowerment Model involving key cognitive and situational factors that contextualize day-to-day experiences affecting learner ability. We synthesize three sample student profiles that highlight user problems in functioning. We use this model to evaluate sample learning platform features and other supportive technology solutions. The proposed approach augments frameworks such as Universal Design for Learning to consider factors including various sensory processing differences, social connection challenges, and environmental limitations. We suggest that by applying the mode through technology-enabled features such as customizable task management, guided varied content access, and guided multi-modal collaboration, major learning barriers of neurodivergent and situationally limited learners will be removed to activate the successful pursuit of their academic goals.","sentences":["In this innovative practice full paper, we address the equity gap for neurodivergent and situationally limited learners by identifying the spectrum of dynamic factors that impact learning and function.","Educators have shown a growing interest in identifying learners' cognitive abilities and learning preferences to measure their impact on academic achievement.","Often institutions employ one-size-fits-all approaches leaving the burden on disabled students to self-advocate or tolerate inadequate support.","Emerging frameworks guide neurodivergent learners through instructional approaches, such as online education.","However, these frameworks fail to address holistic environmental needs or recommend technology interventions, particularly for those with undisclosed learning or developmental disabilities and situational limitations.","In this article, we integrate a neurodivergent perspective through secondary research of around 100 articles to introduce a Guiding Empowerment Model involving key cognitive and situational factors that contextualize day-to-day experiences affecting learner ability.","We synthesize three sample student profiles that highlight user problems in functioning.","We use this model to evaluate sample learning platform features and other supportive technology solutions.","The proposed approach augments frameworks such as Universal Design for Learning to consider factors including various sensory processing differences, social connection challenges, and environmental limitations.","We suggest that by applying the mode through technology-enabled features such as customizable task management, guided varied content access, and guided multi-modal collaboration, major learning barriers of neurodivergent and situationally limited learners will be removed to activate the successful pursuit of their academic goals."],"url":"http://arxiv.org/abs/2410.18876v1"}
{"created":"2024-10-24 15:58:14","title":"Learning Collusion in Episodic, Inventory-Constrained Markets","abstract":"Pricing algorithms have demonstrated the capability to learn tacit collusion that is largely unaddressed by current regulations. Their increasing use in markets, including oligopolistic industries with a history of collusion, calls for closer examination by competition authorities. In this paper, we extend the study of tacit collusion in learning algorithms from basic pricing games to more complex markets characterized by perishable goods with fixed supply and sell-by dates, such as airline tickets, perishables, and hotel rooms. We formalize collusion within this framework and introduce a metric based on price levels under both the competitive (Nash) equilibrium and collusive (monopolistic) optimum. Since no analytical expressions for these price levels exist, we propose an efficient computational approach to derive them. Through experiments, we demonstrate that deep reinforcement learning agents can learn to collude in this more complex domain. Additionally, we analyze the underlying mechanisms and structures of the collusive strategies these agents adopt.","sentences":["Pricing algorithms have demonstrated the capability to learn tacit collusion that is largely unaddressed by current regulations.","Their increasing use in markets, including oligopolistic industries with a history of collusion, calls for closer examination by competition authorities.","In this paper, we extend the study of tacit collusion in learning algorithms from basic pricing games to more complex markets characterized by perishable goods with fixed supply and sell-by dates, such as airline tickets, perishables, and hotel rooms.","We formalize collusion within this framework and introduce a metric based on price levels under both the competitive (Nash) equilibrium and collusive (monopolistic) optimum.","Since no analytical expressions for these price levels exist, we propose an efficient computational approach to derive them.","Through experiments, we demonstrate that deep reinforcement learning agents can learn to collude in this more complex domain.","Additionally, we analyze the underlying mechanisms and structures of the collusive strategies these agents adopt."],"url":"http://arxiv.org/abs/2410.18871v1"}
{"created":"2024-10-24 15:57:17","title":"End-to-end Training for Recommendation with Language-based User Profiles","abstract":"Many online platforms maintain user profiles for personalization. Unfortunately, these profiles are typically not interpretable or easily modifiable by the user. To remedy this shortcoming, we explore natural language-based user profiles, as they promise enhanced transparency and scrutability of recommender systems. While existing work has shown that language-based profiles from standard LLMs can be effective, such generalist LLMs are unlikely to be optimal for this task. In this paper, we introduce LangPTune, the first end-to-end learning method for training LLMs to produce language-based user profiles that optimize recommendation effectiveness. Through comprehensive evaluations of LangPTune across various training configurations and benchmarks, we demonstrate that our approach significantly outperforms existing profile-based methods. In addition, it approaches performance levels comparable to state-of-the-art, less transparent recommender systems, providing a robust and interpretable alternative to conventional systems. Finally, we validate the relative interpretability of these language-based user profiles through user studies involving crowdworkers and GPT-4-based evaluations. Implementation of LangPTune can be found at https://github.com/ZhaolinGao/LangPTune.","sentences":["Many online platforms maintain user profiles for personalization.","Unfortunately, these profiles are typically not interpretable or easily modifiable by the user.","To remedy this shortcoming, we explore natural language-based user profiles, as they promise enhanced transparency and scrutability of recommender systems.","While existing work has shown that language-based profiles from standard LLMs can be effective, such generalist LLMs are unlikely to be optimal for this task.","In this paper, we introduce LangPTune, the first end-to-end learning method for training LLMs to produce language-based user profiles that optimize recommendation effectiveness.","Through comprehensive evaluations of LangPTune across various training configurations and benchmarks, we demonstrate that our approach significantly outperforms existing profile-based methods.","In addition, it approaches performance levels comparable to state-of-the-art, less transparent recommender systems, providing a robust and interpretable alternative to conventional systems.","Finally, we validate the relative interpretability of these language-based user profiles through user studies involving crowdworkers and GPT-4-based evaluations.","Implementation of LangPTune can be found at https://github.com/ZhaolinGao/LangPTune."],"url":"http://arxiv.org/abs/2410.18870v1"}
{"created":"2024-10-24 15:53:21","title":"A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics","abstract":"By incorporating physical consistency as inductive bias, deep neural networks display increased generalization capabilities and data efficiency in learning nonlinear dynamic models. However, the complexity of these models generally increases with the system dimensionality, requiring larger datasets, more complex deep networks, and significant computational effort. We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior. This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a structure-preserving latent space and the associated low-dimensional dynamics. Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically plausible reduced Lagrangian models.","sentences":["By incorporating physical consistency as inductive bias, deep neural networks display increased generalization capabilities and data efficiency in learning nonlinear dynamic models.","However, the complexity of these models generally increases with the system dimensionality, requiring larger datasets, more complex deep networks, and significant computational effort.","We propose a novel geometric network architecture to learn physically-consistent reduced-order dynamic parameters that accurately describe the original high-dimensional system behavior.","This is achieved by building on recent advances in model-order reduction and by adopting a Riemannian perspective to jointly learn a structure-preserving latent space and the associated low-dimensional dynamics.","Our approach enables accurate long-term predictions of the high-dimensional dynamics of rigid and deformable systems with increased data efficiency by inferring interpretable and physically plausible reduced Lagrangian models."],"url":"http://arxiv.org/abs/2410.18868v1"}
{"created":"2024-10-24 15:51:04","title":"The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models and Detection Methods","abstract":"The emergence of diffusion models has transformed synthetic media generation, offering unmatched realism and control over content creation. These advancements have driven innovation across fields such as art, design, and scientific visualization. However, they also introduce significant ethical and societal challenges, particularly through the creation of hyper-realistic images that can facilitate deepfakes, misinformation, and unauthorized reproduction of copyrighted material. In response, the need for effective detection mechanisms has become increasingly urgent. This review examines the evolving adversarial relationship between diffusion model development and the advancement of detection methods. We present a thorough analysis of contemporary detection strategies, including frequency and spatial domain techniques, deep learning-based approaches, and hybrid models that combine multiple methodologies. We also highlight the importance of diverse datasets and standardized evaluation metrics in improving detection accuracy and generalizability. Our discussion explores the practical applications of these detection systems in copyright protection, misinformation prevention, and forensic analysis, while also addressing the ethical implications of synthetic media. Finally, we identify key research gaps and propose future directions to enhance the robustness and adaptability of detection methods in line with the rapid advancements of diffusion models. This review emphasizes the necessity of a comprehensive approach to mitigating the risks associated with AI-generated content in an increasingly digital world.","sentences":["The emergence of diffusion models has transformed synthetic media generation, offering unmatched realism and control over content creation.","These advancements have driven innovation across fields such as art, design, and scientific visualization.","However, they also introduce significant ethical and societal challenges, particularly through the creation of hyper-realistic images that can facilitate deepfakes, misinformation, and unauthorized reproduction of copyrighted material.","In response, the need for effective detection mechanisms has become increasingly urgent.","This review examines the evolving adversarial relationship between diffusion model development and the advancement of detection methods.","We present a thorough analysis of contemporary detection strategies, including frequency and spatial domain techniques, deep learning-based approaches, and hybrid models that combine multiple methodologies.","We also highlight the importance of diverse datasets and standardized evaluation metrics in improving detection accuracy and generalizability.","Our discussion explores the practical applications of these detection systems in copyright protection, misinformation prevention, and forensic analysis, while also addressing the ethical implications of synthetic media.","Finally, we identify key research gaps and propose future directions to enhance the robustness and adaptability of detection methods in line with the rapid advancements of diffusion models.","This review emphasizes the necessity of a comprehensive approach to mitigating the risks associated with AI-generated content in an increasingly digital world."],"url":"http://arxiv.org/abs/2410.18866v1"}
{"created":"2024-10-24 15:48:34","title":"FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning","abstract":"Federated learning has recently gained popularity as a framework for distributed clients to collaboratively train a machine learning model using local data. While traditional federated learning relies on a central server for model aggregation, recent advancements adopt a decentralized framework, enabling direct model exchange between clients and eliminating the single point of failure. However, existing decentralized frameworks often assume all clients train a shared model. Personalizing each client's model can enhance performance, especially with heterogeneous client data distributions. We propose FedSPD, an efficient personalized federated learning algorithm for the decentralized setting, and show that it learns accurate models even in low-connectivity networks. To provide theoretical guarantees on convergence, we introduce a clustering-based framework that enables consensus on models for distinct data clusters while personalizing to unique mixtures of these clusters at different clients. This flexibility, allowing selective model updates based on data distribution, substantially reduces communication costs compared to prior work on personalized federated learning in decentralized settings. Experimental results on real-world datasets show that FedSPD outperforms multiple decentralized variants of personalized federated learning algorithms, especially in scenarios with low-connectivity networks.","sentences":["Federated learning has recently gained popularity as a framework for distributed clients to collaboratively train a machine learning model using local data.","While traditional federated learning relies on a central server for model aggregation, recent advancements adopt a decentralized framework, enabling direct model exchange between clients and eliminating the single point of failure.","However, existing decentralized frameworks often assume all clients train a shared model.","Personalizing each client's model can enhance performance, especially with heterogeneous client data distributions.","We propose FedSPD, an efficient personalized federated learning algorithm for the decentralized setting, and show that it learns accurate models even in low-connectivity networks.","To provide theoretical guarantees on convergence, we introduce a clustering-based framework that enables consensus on models for distinct data clusters while personalizing to unique mixtures of these clusters at different clients.","This flexibility, allowing selective model updates based on data distribution, substantially reduces communication costs compared to prior work on personalized federated learning in decentralized settings.","Experimental results on real-world datasets show that FedSPD outperforms multiple decentralized variants of personalized federated learning algorithms, especially in scenarios with low-connectivity networks."],"url":"http://arxiv.org/abs/2410.18862v1"}
{"created":"2024-10-24 15:44:34","title":"Provably Robust Watermarks for Open-Source Language Models","abstract":"The recent explosion of high-quality language models has necessitated new methods for identifying AI-generated text. Watermarking is a leading solution and could prove to be an essential tool in the age of generative AI. Existing approaches embed watermarks at inference and crucially rely on the large language model (LLM) specification and parameters being secret, which makes them inapplicable to the open-source setting. In this work, we introduce the first watermarking scheme for open-source LLMs. Our scheme works by modifying the parameters of the model, but the watermark can be detected from just the outputs of the model. Perhaps surprisingly, we prove that our watermarks are unremovable under certain assumptions about the adversary's knowledge. To demonstrate the behavior of our construction under concrete parameter instantiations, we present experimental results with OPT-6.7B and OPT-1.3B. We demonstrate robustness to both token substitution and perturbation of the model parameters. We find that the stronger of these attacks, the model-perturbation attack, requires deteriorating the quality score to 0 out of 100 in order to bring the detection rate down to 50%.","sentences":["The recent explosion of high-quality language models has necessitated new methods for identifying AI-generated text.","Watermarking is a leading solution and could prove to be an essential tool in the age of generative AI.","Existing approaches embed watermarks at inference and crucially rely on the large language model (LLM) specification and parameters being secret, which makes them inapplicable to the open-source setting.","In this work, we introduce the first watermarking scheme for open-source LLMs.","Our scheme works by modifying the parameters of the model, but the watermark can be detected from just the outputs of the model.","Perhaps surprisingly, we prove that our watermarks are unremovable under certain assumptions about the adversary's knowledge.","To demonstrate the behavior of our construction under concrete parameter instantiations, we present experimental results with OPT-6.7B and OPT-1.3B.","We demonstrate robustness to both token substitution and perturbation of the model parameters.","We find that the stronger of these attacks, the model-perturbation attack, requires deteriorating the quality score to 0 out of 100 in order to bring the detection rate down to 50%."],"url":"http://arxiv.org/abs/2410.18861v1"}
{"created":"2024-10-24 15:44:33","title":"DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations","abstract":"Large Language Models (LLMs) often hallucinate, producing unfaithful or factually incorrect outputs by misrepresenting the provided context or incorrectly recalling internal knowledge. Recent studies have identified specific attention heads within the Transformer architecture, known as retrieval heads, responsible for extracting relevant contextual information. We hypothesise that masking these retrieval heads can induce hallucinations and that contrasting the outputs of the base LLM and the masked LLM can reduce hallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads (DeCoRe), a novel training-free decoding strategy that amplifies information found in the context and model parameters. DeCoRe mitigates potentially hallucinated responses by dynamically contrasting the outputs of the base LLM and the masked LLM, using conditional entropy as a guide. Our extensive experiments confirm that DeCoRe significantly improves performance on tasks requiring high contextual faithfulness, such as summarisation (XSum by 18.6%), instruction following (MemoTrap by 10.9%), and open-book question answering (NQ-Open by 2.4% and NQ-Swap by 5.5%).","sentences":["Large Language Models (LLMs) often hallucinate, producing unfaithful or factually incorrect outputs by misrepresenting the provided context or incorrectly recalling internal knowledge.","Recent studies have identified specific attention heads within the Transformer architecture, known as retrieval heads, responsible for extracting relevant contextual information.","We hypothesise that masking these retrieval heads can induce hallucinations and that contrasting the outputs of the base LLM and the masked LLM can reduce hallucinations.","To this end, we propose Decoding by Contrasting Retrieval Heads (DeCoRe), a novel training-free decoding strategy that amplifies information found in the context and model parameters.","DeCoRe mitigates potentially hallucinated responses by dynamically contrasting the outputs of the base LLM and the masked LLM, using conditional entropy as a guide.","Our extensive experiments confirm that DeCoRe","significantly improves performance on tasks requiring high contextual faithfulness, such as summarisation (XSum by 18.6%), instruction following (MemoTrap by 10.9%), and open-book question answering (NQ-Open by 2.4% and NQ-Swap by 5.5%)."],"url":"http://arxiv.org/abs/2410.18860v1"}
{"created":"2024-10-24 15:42:25","title":"Probabilistic Language-Image Pre-Training","abstract":"Vision-language models (VLMs) embed aligned image-text pairs into a joint space but often rely on deterministic embeddings, assuming a one-to-one correspondence between images and texts. This oversimplifies real-world relationships, which are inherently many-to-many, with multiple captions describing a single image and vice versa. We introduce Probabilistic Language-Image Pre-training (ProLIP), the first probabilistic VLM pre-trained on a billion-scale image-text dataset using only probabilistic objectives, achieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shot accuracy with ViT-B/16). ProLIP efficiently estimates uncertainty by an \"uncertainty token\" without extra parameters. We also introduce a novel inclusion loss that enforces distributional inclusion relationships between image-text pairs and between original and masked inputs. Experiments demonstrate that, by leveraging uncertainty estimates, ProLIP benefits downstream tasks and aligns with intuitive notions of uncertainty, e.g., shorter texts being more uncertain and more general inputs including specific ones. Utilizing text uncertainties, we further improve ImageNet accuracy from 74.6% to 75.8% (under a few-shot setting), supporting the practical advantages of our probabilistic approach. The code is available at https://github.com/naver-ai/prolip","sentences":["Vision-language models (VLMs) embed aligned image-text pairs into a joint space but often rely on deterministic embeddings, assuming a one-to-one correspondence between images and texts.","This oversimplifies real-world relationships, which are inherently many-to-many, with multiple captions describing a single image and vice versa.","We introduce Probabilistic Language-Image Pre-training (ProLIP), the first probabilistic VLM pre-trained on a billion-scale image-text dataset using only probabilistic objectives, achieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shot accuracy with ViT-B/16).","ProLIP efficiently estimates uncertainty by an \"uncertainty token\" without extra parameters.","We also introduce a novel inclusion loss that enforces distributional inclusion relationships between image-text pairs and between original and masked inputs.","Experiments demonstrate that, by leveraging uncertainty estimates, ProLIP benefits downstream tasks and aligns with intuitive notions of uncertainty, e.g., shorter texts being more uncertain and more general inputs including specific ones.","Utilizing text uncertainties, we further improve ImageNet accuracy from 74.6% to 75.8% (under a few-shot setting), supporting the practical advantages of our probabilistic approach.","The code is available at https://github.com/naver-ai/prolip"],"url":"http://arxiv.org/abs/2410.18857v1"}
{"created":"2024-10-24 15:41:56","title":"Demystifying Large Language Models for Medicine: A Primer","abstract":"Large language models (LLMs) represent a transformative class of AI tools capable of revolutionizing various aspects of healthcare by generating human-like responses across diverse contexts and adapting to novel tasks following human instructions. Their potential application spans a broad range of medical tasks, such as clinical documentation, matching patients to clinical trials, and answering medical questions. In this primer paper, we propose an actionable guideline to help healthcare professionals more efficiently utilize LLMs in their work, along with a set of best practices. This approach consists of several main phases, including formulating the task, choosing LLMs, prompt engineering, fine-tuning, and deployment. We start with the discussion of critical considerations in identifying healthcare tasks that align with the core capabilities of LLMs and selecting models based on the selected task and data, performance requirements, and model interface. We then review the strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs to specialized medical tasks. Deployment considerations, including regulatory compliance, ethical guidelines, and continuous monitoring for fairness and bias, are also discussed. By providing a structured step-by-step methodology, this tutorial aims to equip healthcare professionals with the tools necessary to effectively integrate LLMs into clinical practice, ensuring that these powerful technologies are applied in a safe, reliable, and impactful manner.","sentences":["Large language models (LLMs) represent a transformative class of AI tools capable of revolutionizing various aspects of healthcare by generating human-like responses across diverse contexts and adapting to novel tasks following human instructions.","Their potential application spans a broad range of medical tasks, such as clinical documentation, matching patients to clinical trials, and answering medical questions.","In this primer paper, we propose an actionable guideline to help healthcare professionals more efficiently utilize LLMs in their work, along with a set of best practices.","This approach consists of several main phases, including formulating the task, choosing LLMs, prompt engineering, fine-tuning, and deployment.","We start with the discussion of critical considerations in identifying healthcare tasks that align with the core capabilities of LLMs and selecting models based on the selected task and data, performance requirements, and model interface.","We then review the strategies, such as prompt engineering and fine-tuning, to adapt standard LLMs to specialized medical tasks.","Deployment considerations, including regulatory compliance, ethical guidelines, and continuous monitoring for fairness and bias, are also discussed.","By providing a structured step-by-step methodology, this tutorial aims to equip healthcare professionals with the tools necessary to effectively integrate LLMs into clinical practice, ensuring that these powerful technologies are applied in a safe, reliable, and impactful manner."],"url":"http://arxiv.org/abs/2410.18856v1"}
{"created":"2024-10-24 15:35:08","title":"DL-Polycube: Deep learning enhanced polycube method for high-quality hexahedral mesh generation and volumetric spline construction","abstract":"In this paper, we present a novel algorithm that integrates deep learning with the polycube method (DL-Polycube) to generate high-quality hexahedral (hex) meshes, which are then used to construct volumetric splines for isogeometric analysis. Our DL-Polycube algorithm begins by establishing a connection between surface triangular meshes and polycube structures. We employ deep neural network to classify surface triangular meshes into their corresponding polycube structures. Following this, we combine the acquired polycube structural information with unsupervised learning to perform surface segmentation of triangular meshes. This step addresses the issue of segmentation not corresponding to a polycube while reducing manual intervention. Quality hex meshes are then generated from the polycube structures, with employing octree subdivision, parametric mapping and quality improvement techniques. The incorporation of deep learning for creating polycube structures, combined with unsupervised learning for segmentation of surface triangular meshes, substantially accelerates hex mesh generation. Finally, truncated hierarchical B-splines are constructed on the generated hex meshes. We extract trivariate B\\'ezier elements from these splines and apply them directly in isogeometric analysis. We offer several examples to demonstrate the robustness of our DL-Polycube algorithm.","sentences":["In this paper, we present a novel algorithm that integrates deep learning with the polycube method (DL-Polycube) to generate high-quality hexahedral (hex) meshes, which are then used to construct volumetric splines for isogeometric analysis.","Our DL-Polycube algorithm begins by establishing a connection between surface triangular meshes and polycube structures.","We employ deep neural network to classify surface triangular meshes into their corresponding polycube structures.","Following this, we combine the acquired polycube structural information with unsupervised learning to perform surface segmentation of triangular meshes.","This step addresses the issue of segmentation not corresponding to a polycube while reducing manual intervention.","Quality hex meshes are then generated from the polycube structures, with employing octree subdivision, parametric mapping and quality improvement techniques.","The incorporation of deep learning for creating polycube structures, combined with unsupervised learning for segmentation of surface triangular meshes, substantially accelerates hex mesh generation.","Finally, truncated hierarchical B-splines are constructed on the generated hex meshes.","We extract trivariate B\\'ezier elements from these splines and apply them directly in isogeometric analysis.","We offer several examples to demonstrate the robustness of our DL-Polycube algorithm."],"url":"http://arxiv.org/abs/2410.18852v1"}
{"created":"2024-10-24 15:33:34","title":"Intention Is All You Need","abstract":"Among the many narratives of the transformative power of Generative AI is one that sees in the world a latent nation of programmers who need to wield nothing but intentions and natural language to render their ideas in software. In this paper, this outlook is problematised in two ways. First, it is observed that generative AI is not a neutral vehicle of intention. Multiple recent studies paint a picture of the \"mechanised convergence\" phenomenon, namely, that generative AI has a homogenising effect on intention. Second, it is observed that the formation of intention itself is immensely challenging. Constraints, materiality, and resistance can offer paths to design metaphors for intentional tools. Finally, existentialist approaches to intention are discussed and possible implications for programming are proposed in the form of a speculative, illustrative set of intentional programming practices.","sentences":["Among the many narratives of the transformative power of Generative AI is one that sees in the world a latent nation of programmers who need to wield nothing but intentions and natural language to render their ideas in software.","In this paper, this outlook is problematised in two ways.","First, it is observed that generative AI is not a neutral vehicle of intention.","Multiple recent studies paint a picture of the \"mechanised convergence\" phenomenon, namely, that generative AI has a homogenising effect on intention.","Second, it is observed that the formation of intention itself is immensely challenging.","Constraints, materiality, and resistance can offer paths to design metaphors for intentional tools.","Finally, existentialist approaches to intention are discussed and possible implications for programming are proposed in the form of a speculative, illustrative set of intentional programming practices."],"url":"http://arxiv.org/abs/2410.18851v1"}
{"created":"2024-10-24 15:32:52","title":"We Augmented Whisper With kNN and You Won't Believe What Came Next","abstract":"Speech recognition performance varies by language, domain, and speaker characteristics such as accent, and fine-tuning a model on any of these categories may lead to catastrophic forgetting. $k$ nearest neighbor search ($k$NN), first proposed for neural sequence decoders for natural language generation (NLG) and machine translation (MT), is a non-parametric method that can instead adapt by building an external datastore that can then be searched during inference time, without training the underlying model. We show that Whisper, a transformer end-to-end speech model, benefits from $k$NN. We investigate the differences between the speech and text setups. We discuss implications for speaker adaptation, and analyze improvements by gender, accent, and age.","sentences":["Speech recognition performance varies by language, domain, and speaker characteristics such as accent, and fine-tuning a model on any of these categories may lead to catastrophic forgetting.","$k$ nearest neighbor search ($k$NN), first proposed for neural sequence decoders for natural language generation (NLG) and machine translation (MT), is a non-parametric method that can instead adapt by building an external datastore that can then be searched during inference time, without training the underlying model.","We show that Whisper, a transformer end-to-end speech model, benefits from $k$NN.","We investigate the differences between the speech and text setups.","We discuss implications for speaker adaptation, and analyze improvements by gender, accent, and age."],"url":"http://arxiv.org/abs/2410.18850v1"}
{"created":"2024-10-24 15:26:34","title":"Expanding AI Awareness Through Everyday Interactions with AI: A Reflective Journal Study","abstract":"As the application of AI continues to expand, students in technology programs are poised to be both producers and users of the technologies. They are also positioned to engage with AI applications within and outside the classroom. While focusing on the curriculum when examining students' AI knowledge is common, extending this connection to students' everyday interactions with AI provides a more complete picture of their learning. In this paper, we explore student's awareness and engagement with AI in the context of school and their daily lives. Over six weeks, 22 undergraduate students participated in a reflective journal study and submitted a weekly journal entry about their interactions with AI. The participants were recruited from a technology and society course that focuses on the implications of technology on people, communities, and processes. In their weekly journal entries, participants reflected on interactions with AI on campus (coursework, advertises campus events, or seminars) and beyond (social media, news, or conversations with friends and family). The journal prompts were designed to help them think through what they had read, watched, or been told and reflect on the development of their own perspectives, knowledge, and literacy on the topic. Overall, students described nine categories of interactions: coursework, news and current events, using software and applications, university events, social media related to their work, personal discussions with friends and family, interacting with content, and gaming. Students reported that completing the diaries allowed them time for reflection and made them more aware of the presence of AI in their daily lives and of its potential benefits and drawbacks. This research contributes to the ongoing work on AI awareness and literacy by bringing in perspectives from beyond a formal educational context.","sentences":["As the application of AI continues to expand, students in technology programs are poised to be both producers and users of the technologies.","They are also positioned to engage with AI applications within and outside the classroom.","While focusing on the curriculum when examining students' AI knowledge is common, extending this connection to students' everyday interactions with AI provides a more complete picture of their learning.","In this paper, we explore student's awareness and engagement with AI in the context of school and their daily lives.","Over six weeks, 22 undergraduate students participated in a reflective journal study and submitted a weekly journal entry about their interactions with AI.","The participants were recruited from a technology and society course that focuses on the implications of technology on people, communities, and processes.","In their weekly journal entries, participants reflected on interactions with AI on campus (coursework, advertises campus events, or seminars) and beyond (social media, news, or conversations with friends and family).","The journal prompts were designed to help them think through what they had read, watched, or been told and reflect on the development of their own perspectives, knowledge, and literacy on the topic.","Overall, students described nine categories of interactions: coursework, news and current events, using software and applications, university events, social media related to their work, personal discussions with friends and family, interacting with content, and gaming.","Students reported that completing the diaries allowed them time for reflection and made them more aware of the presence of AI in their daily lives and of its potential benefits and drawbacks.","This research contributes to the ongoing work on AI awareness and literacy by bringing in perspectives from beyond a formal educational context."],"url":"http://arxiv.org/abs/2410.18845v1"}
{"created":"2024-10-24 15:26:14","title":"Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints","abstract":"Pure exploration in bandits models multiple real-world problems, such as tuning hyper-parameters or conducting user studies, where different safety, resource, and fairness constraints on the decision space naturally appear. We study these problems as pure exploration in multi-armed bandits with unknown linear constraints, where the aim is to identify an $r$$\\textit{-good feasible policy}$. First, we propose a Lagrangian relaxation of the sample complexity lower bound for pure exploration under constraints. We show how this lower bound evolves with the sequential estimation of constraints. Second, we leverage the Lagrangian lower bound and the properties of convex optimisation to propose two computationally efficient extensions of Track-and-Stop and Gamified Explorer, namely LATS and LAGEX. To this end, we propose a constraint-adaptive stopping rule, and while tracking the lower bound, use pessimistic estimate of the feasible set at each step. We show that these algorithms achieve asymptotically optimal sample complexity upper bounds up to constraint-dependent constants. Finally, we conduct numerical experiments with different reward distributions and constraints that validate efficient performance of LAGEX and LATS with respect to baselines.","sentences":["Pure exploration in bandits models multiple real-world problems, such as tuning hyper-parameters or conducting user studies, where different safety, resource, and fairness constraints on the decision space naturally appear.","We study these problems as pure exploration in multi-armed bandits with unknown linear constraints, where the aim is to identify an $r$$\\textit{-good feasible policy}$.","First, we propose a Lagrangian relaxation of the sample complexity lower bound for pure exploration under constraints.","We show how this lower bound evolves with the sequential estimation of constraints.","Second, we leverage the Lagrangian lower bound and the properties of convex optimisation to propose two computationally efficient extensions of Track-and-Stop and Gamified Explorer, namely LATS and LAGEX.","To this end, we propose a constraint-adaptive stopping rule, and while tracking the lower bound, use pessimistic estimate of the feasible set at each step.","We show that these algorithms achieve asymptotically optimal sample complexity upper bounds up to constraint-dependent constants.","Finally, we conduct numerical experiments with different reward distributions and constraints that validate efficient performance of LAGEX and LATS with respect to baselines."],"url":"http://arxiv.org/abs/2410.18844v1"}
{"created":"2024-10-24 15:25:56","title":"From Efficiency to Equity: Measuring Fairness in Preference Learning","abstract":"As AI systems, particularly generative models, increasingly influence decision-making, ensuring that they are able to fairly represent diverse human preferences becomes crucial. This paper introduces a novel framework for evaluating epistemic fairness in preference learning models inspired by economic theories of inequality and Rawlsian justice. We propose metrics adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to quantify fairness in these models. We validate our approach using two datasets: a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset. Our analysis reveals variations in model performance across users, highlighting potential epistemic injustices. We explore pre-processing and in-processing techniques to mitigate these inequalities, demonstrating a complex relationship between model efficiency and fairness. This work contributes to AI ethics by providing a framework for evaluating and improving epistemic fairness in preference learning models, offering insights for developing more inclusive AI systems in contexts where diverse human preferences are crucial.","sentences":["As AI systems, particularly generative models, increasingly influence decision-making, ensuring that they are able to fairly represent diverse human preferences becomes crucial.","This paper introduces a novel framework for evaluating epistemic fairness in preference learning models inspired by economic theories of inequality and Rawlsian justice.","We propose metrics adapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio to quantify fairness in these models.","We validate our approach using two datasets: a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.","Our analysis reveals variations in model performance across users, highlighting potential epistemic injustices.","We explore pre-processing and in-processing techniques to mitigate these inequalities, demonstrating a complex relationship between model efficiency and fairness.","This work contributes to AI ethics by providing a framework for evaluating and improving epistemic fairness in preference learning models, offering insights for developing more inclusive AI systems in contexts where diverse human preferences are crucial."],"url":"http://arxiv.org/abs/2410.18841v1"}
{"created":"2024-10-24 15:20:54","title":"From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages","abstract":"In this paper, we propose a model-agnostic cost-effective approach to developing bilingual base large language models (LLMs) to support English and any target language. The method includes vocabulary expansion, initialization of new embeddings, model training and evaluation. We performed our experiments with three languages, each using a non-Latin script - Ukrainian, Arabic, and Georgian.   Our approach demonstrates improved language performance while reducing computational costs. It mitigates the disproportionate penalization of underrepresented languages, promoting fairness and minimizing adverse phenomena such as code-switching and broken grammar. Additionally, we introduce new metrics to evaluate language quality, revealing that vocabulary size significantly impacts the quality of generated text.","sentences":["In this paper, we propose a model-agnostic cost-effective approach to developing bilingual base large language models (LLMs) to support English and any target language.","The method includes vocabulary expansion, initialization of new embeddings, model training and evaluation.","We performed our experiments with three languages, each using a non-Latin script - Ukrainian, Arabic, and Georgian.   ","Our approach demonstrates improved language performance while reducing computational costs.","It mitigates the disproportionate penalization of underrepresented languages, promoting fairness and minimizing adverse phenomena such as code-switching and broken grammar.","Additionally, we introduce new metrics to evaluate language quality, revealing that vocabulary size significantly impacts the quality of generated text."],"url":"http://arxiv.org/abs/2410.18836v1"}
{"created":"2024-10-24 15:20:16","title":"Diffusion for Multi-Embodiment Grasping","abstract":"Grasping is a fundamental skill in robotics with diverse applications across medical, industrial, and domestic domains. However, current approaches for predicting valid grasps are often tailored to specific grippers, limiting their applicability when gripper designs change. To address this limitation, we explore the transfer of grasping strategies between various gripper designs, enabling the use of data from diverse sources. In this work, we present an approach based on equivariant diffusion that facilitates gripper-agnostic encoding of scenes containing graspable objects and gripper-aware decoding of grasp poses by integrating gripper geometry into the model. We also develop a dataset generation framework that produces cluttered scenes with variable-sized object heaps, improving the training of grasp synthesis methods. Experimental evaluation on diverse object datasets demonstrates the generalizability of our approach across gripper architectures, ranging from simple parallel-jaw grippers to humanoid hands, outperforming both single-gripper and multi-gripper state-of-the-art methods.","sentences":["Grasping is a fundamental skill in robotics with diverse applications across medical, industrial, and domestic domains.","However, current approaches for predicting valid grasps are often tailored to specific grippers, limiting their applicability when gripper designs change.","To address this limitation, we explore the transfer of grasping strategies between various gripper designs, enabling the use of data from diverse sources.","In this work, we present an approach based on equivariant diffusion that facilitates gripper-agnostic encoding of scenes containing graspable objects and gripper-aware decoding of grasp poses by integrating gripper geometry into the model.","We also develop a dataset generation framework that produces cluttered scenes with variable-sized object heaps, improving the training of grasp synthesis methods.","Experimental evaluation on diverse object datasets demonstrates the generalizability of our approach across gripper architectures, ranging from simple parallel-jaw grippers to humanoid hands, outperforming both single-gripper and multi-gripper state-of-the-art methods."],"url":"http://arxiv.org/abs/2410.18835v1"}
{"created":"2024-10-24 15:19:48","title":"MazeNet: An Accurate, Fast, and Scalable Deep Learning Solution for Steiner Minimum Trees","abstract":"The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem, which seeks the shortest interconnection of a given number of terminals in a rectilinear plane while avoiding obstacles, is a critical task in integrated circuit design, network optimization, and robot path planning. Since OARSMT is NP-hard, exact algorithms scale poorly with the number of terminals, leading practical solvers to sacrifice accuracy for large problems. We propose MazeNet, a deep learning-based method that learns to solve the OARSMT from data. MazeNet reframes OARSMT as a maze-solving task that can be addressed with a recurrent convolutional neural network (RCNN). A key hallmark of MazeNet is its scalability: we only need to train the RCNN blocks on mazes with a small number of terminals; larger mazes can be solved by replicating the same pre-trained blocks to create a larger network. Across a wide range of experiments, MazeNet achieves perfect OARSMT-solving accuracy, significantly reduces runtime compared to classical exact algorithms, and can handle more terminals than state-of-the-art approximate algorithms.","sentences":["The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem, which seeks the shortest interconnection of a given number of terminals in a rectilinear plane while avoiding obstacles, is a critical task in integrated circuit design, network optimization, and robot path planning.","Since OARSMT is NP-hard, exact algorithms scale poorly with the number of terminals, leading practical solvers to sacrifice accuracy for large problems.","We propose MazeNet, a deep learning-based method that learns to solve the OARSMT from data.","MazeNet reframes OARSMT as a maze-solving task that can be addressed with a recurrent convolutional neural network (RCNN).","A key hallmark of MazeNet is its scalability: we only need to train the RCNN blocks on mazes with a small number of terminals; larger mazes can be solved by replicating the same pre-trained blocks to create a larger network.","Across a wide range of experiments, MazeNet achieves perfect OARSMT-solving accuracy, significantly reduces runtime compared to classical exact algorithms, and can handle more terminals than state-of-the-art approximate algorithms."],"url":"http://arxiv.org/abs/2410.18832v1"}
{"created":"2024-10-24 15:18:51","title":"Multi-Scale Diffusion: Enhancing Spatial Layout in High-Resolution Panoramic Image Generation","abstract":"Diffusion models have recently gained recognition for generating diverse and high-quality content, especially in the domain of image synthesis. These models excel not only in creating fixed-size images but also in producing panoramic images. However, existing methods often struggle with spatial layout consistency when producing high-resolution panoramas, due to the lack of guidance of the global image layout. In this paper, we introduce the Multi-Scale Diffusion (MSD) framework, a plug-and-play module that extends the existing panoramic image generation framework to multiple resolution levels. By utilizing gradient descent techniques, our method effectively incorporates structural information from low-resolution images into high-resolution outputs. A comprehensive evaluation of the proposed method was conducted, comparing it with the prior works in qualitative and quantitative dimensions. The evaluation results demonstrate that our method significantly outperforms others in generating coherent high-resolution panoramas.","sentences":["Diffusion models have recently gained recognition for generating diverse and high-quality content, especially in the domain of image synthesis.","These models excel not only in creating fixed-size images but also in producing panoramic images.","However, existing methods often struggle with spatial layout consistency when producing high-resolution panoramas, due to the lack of guidance of the global image layout.","In this paper, we introduce the Multi-Scale Diffusion (MSD) framework, a plug-and-play module that extends the existing panoramic image generation framework to multiple resolution levels.","By utilizing gradient descent techniques, our method effectively incorporates structural information from low-resolution images into high-resolution outputs.","A comprehensive evaluation of the proposed method was conducted, comparing it with the prior works in qualitative and quantitative dimensions.","The evaluation results demonstrate that our method significantly outperforms others in generating coherent high-resolution panoramas."],"url":"http://arxiv.org/abs/2410.18830v1"}
{"created":"2024-10-24 15:17:09","title":"A generic approach for reactive stateful mitigation of application failures in distributed robotics systems deployed with Kubernetes","abstract":"Offloading computationally expensive algorithms to the edge or even cloud offers an attractive option to tackle limitations regarding on-board computational and energy resources of robotic systems. In cloud-native applications deployed with the container management system Kubernetes (K8s), one key problem is ensuring resilience against various types of failures. However, complex robotic systems interacting with the physical world pose a very specific set of challenges and requirements that are not yet covered by failure mitigation approaches from the cloud-native domain. In this paper, we therefore propose a novel approach for robotic system monitoring and stateful, reactive failure mitigation for distributed robotic systems deployed using Kubernetes (K8s) and the Robot Operating System (ROS2). By employing the generic substrate of Behaviour Trees, our approach can be applied to any robotic workload and supports arbitrarily complex monitoring and failure mitigation strategies. We demonstrate the effectiveness and application-agnosticism of our approach on two example applications, namely Autonomous Mobile Robot (AMR) navigation and robotic manipulation in a simulated environment.","sentences":["Offloading computationally expensive algorithms to the edge or even cloud offers an attractive option to tackle limitations regarding on-board computational and energy resources of robotic systems.","In cloud-native applications deployed with the container management system Kubernetes (K8s), one key problem is ensuring resilience against various types of failures.","However, complex robotic systems interacting with the physical world pose a very specific set of challenges and requirements that are not yet covered by failure mitigation approaches from the cloud-native domain.","In this paper, we therefore propose a novel approach for robotic system monitoring and stateful, reactive failure mitigation for distributed robotic systems deployed using Kubernetes (K8s) and the Robot Operating System (ROS2).","By employing the generic substrate of Behaviour Trees, our approach can be applied to any robotic workload and supports arbitrarily complex monitoring and failure mitigation strategies.","We demonstrate the effectiveness and application-agnosticism of our approach on two example applications, namely Autonomous Mobile Robot (AMR) navigation and robotic manipulation in a simulated environment."],"url":"http://arxiv.org/abs/2410.18825v1"}
{"created":"2024-10-24 15:15:42","title":"PSY: Posterior Sampling Based Privacy Enhancer in Large Language Models","abstract":"Privacy vulnerabilities in LLMs, such as leakage from memorization, have been constantly identified, and various mitigation proposals have been proposed. LoRA is usually used in fine-tuning LLMs and a good entry point to insert privacy-enhancing modules. In this ongoing research, we introduce PSY, a Posterior Sampling based PrivacY enhancer that can be used in LoRA. We propose a simple yet effective realization of PSY using posterior sampling, which effectively prevents privacy leakage from intermediate information and, in turn, preserves the privacy of data owners. We evaluate LoRA extended with PSY against state-of-the-art membership inference and data extraction attacks. The experiments are executed on three different LLM architectures fine-tuned on three datasets with LoRA. In contrast to the commonly used differential privacy method, we find that our proposed modification consistently reduces the attack success rate. Meanwhile, our method has almost no negative impact on model fine-tuning or final performance. Most importantly, PSY reveals a promising path toward privacy enhancement with latent space extensions.","sentences":["Privacy vulnerabilities in LLMs, such as leakage from memorization, have been constantly identified, and various mitigation proposals have been proposed.","LoRA is usually used in fine-tuning LLMs and a good entry point to insert privacy-enhancing modules.","In this ongoing research, we introduce PSY, a Posterior Sampling based PrivacY enhancer that can be used in LoRA.","We propose a simple yet effective realization of PSY using posterior sampling, which effectively prevents privacy leakage from intermediate information and, in turn, preserves the privacy of data owners.","We evaluate LoRA extended with PSY against state-of-the-art membership inference and data extraction attacks.","The experiments are executed on three different LLM architectures fine-tuned on three datasets with LoRA.","In contrast to the commonly used differential privacy method, we find that our proposed modification consistently reduces the attack success rate.","Meanwhile, our method has almost no negative impact on model fine-tuning or final performance.","Most importantly, PSY reveals a promising path toward privacy enhancement with latent space extensions."],"url":"http://arxiv.org/abs/2410.18824v1"}
{"created":"2024-10-24 15:15:01","title":"Towards Visual Text Design Transfer Across Languages","abstract":"Visual text design plays a critical role in conveying themes, emotions, and atmospheres in multimodal formats such as film posters and album covers. Translating these visual and textual elements across languages extends the concept of translation beyond mere text, requiring the adaptation of aesthetic and stylistic features. To address this, we introduce a novel task of Multimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the ability of visual text generation models to perform translation across different writing systems while preserving design intent. Our initial experiments on MuST-Bench reveal that existing visual text generation models struggle with the proposed task due to the inadequacy of textual descriptions in conveying visual design. In response, we introduce SIGIL, a framework for multimodal style translation that eliminates the need for style descriptions. SIGIL enhances image generation models through three innovations: glyph latent for multilingual settings, pretrained VAEs for stable style guidance, and an OCR model with reinforcement learning feedback for optimizing readable character generation. SIGIL outperforms existing baselines by achieving superior style consistency and legibility while maintaining visual fidelity, setting itself apart from traditional description-based approaches. We release MuST-Bench publicly for broader use and exploration https://huggingface.co/datasets/yejinc/MuST-Bench.","sentences":["Visual text design plays a critical role in conveying themes, emotions, and atmospheres in multimodal formats such as film posters and album covers.","Translating these visual and textual elements across languages extends the concept of translation beyond mere text, requiring the adaptation of aesthetic and stylistic features.","To address this, we introduce a novel task of Multimodal Style Translation (MuST-Bench), a benchmark designed to evaluate the ability of visual text generation models to perform translation across different writing systems while preserving design intent.","Our initial experiments on MuST-Bench reveal that existing visual text generation models struggle with the proposed task due to the inadequacy of textual descriptions in conveying visual design.","In response, we introduce SIGIL, a framework for multimodal style translation that eliminates the need for style descriptions.","SIGIL enhances image generation models through three innovations: glyph latent for multilingual settings, pretrained VAEs for stable style guidance, and an OCR model with reinforcement learning feedback for optimizing readable character generation.","SIGIL outperforms existing baselines by achieving superior style consistency and legibility while maintaining visual fidelity, setting itself apart from traditional description-based approaches.","We release MuST-Bench publicly for broader use and exploration https://huggingface.co/datasets/yejinc/MuST-Bench."],"url":"http://arxiv.org/abs/2410.18823v1"}
{"created":"2024-10-24 15:10:27","title":"Binocular-Guided 3D Gaussian Splatting with View Consistency for Sparse View Synthesis","abstract":"Novel view synthesis from sparse inputs is a vital yet challenging task in 3D computer vision. Previous methods explore 3D Gaussian Splatting with neural priors (e.g. depth priors) as an additional supervision, demonstrating promising quality and efficiency compared to the NeRF based methods. However, the neural priors from 2D pretrained models are often noisy and blurry, which struggle to precisely guide the learning of radiance fields. In this paper, We propose a novel method for synthesizing novel views from sparse views with Gaussian Splatting that does not require external prior as supervision. Our key idea lies in exploring the self-supervisions inherent in the binocular stereo consistency between each pair of binocular images constructed with disparity-guided image warping. To this end, we additionally introduce a Gaussian opacity constraint which regularizes the Gaussian locations and avoids Gaussian redundancy for improving the robustness and efficiency of inferring 3D Gaussians from sparse views. Extensive experiments on the LLFF, DTU, and Blender datasets demonstrate that our method significantly outperforms the state-of-the-art methods.","sentences":["Novel view synthesis from sparse inputs is a vital yet challenging task in 3D computer vision.","Previous methods explore 3D Gaussian Splatting with neural priors (e.g. depth priors) as an additional supervision, demonstrating promising quality and efficiency compared to the NeRF based methods.","However, the neural priors from 2D pretrained models are often noisy and blurry, which struggle to precisely guide the learning of radiance fields.","In this paper, We propose a novel method for synthesizing novel views from sparse views with Gaussian Splatting that does not require external prior as supervision.","Our key idea lies in exploring the self-supervisions inherent in the binocular stereo consistency between each pair of binocular images constructed with disparity-guided image warping.","To this end, we additionally introduce a Gaussian opacity constraint which regularizes the Gaussian locations and avoids Gaussian redundancy for improving the robustness and efficiency of inferring 3D Gaussians from sparse views.","Extensive experiments on the LLFF, DTU, and Blender datasets demonstrate that our method significantly outperforms the state-of-the-art methods."],"url":"http://arxiv.org/abs/2410.18822v1"}
{"created":"2024-10-24 15:08:38","title":"Deterministic $(2/3-\\varepsilon)$-Approximation of Matroid Intersection using Nearly-Linear Independence-Oracle Queries","abstract":"In the matroid intersection problem, we are given two matroids $\\mathcal{M}_1 = (V, \\mathcal{I}_1)$ and $\\mathcal{M}_2 = (V, \\mathcal{I}_2)$ defined on the same ground set $V$ of $n$ elements, and the objective is to find a common independent set $S \\in \\mathcal{I}_1 \\cap \\mathcal{I}_2$ of largest possible cardinality, denoted by $r$. In this paper, we consider a deterministic matroid intersection algorithm with only a nearly linear number of independence oracle queries. Our contribution is to present a deterministic $O(\\frac{n}{\\varepsilon} + r \\log r)$-independence-query $(2/3-\\varepsilon)$-approximation algorithm for any $\\varepsilon > 0$. Our idea is very simple: we apply a recent $\\tilde{O}(n \\sqrt{r}/\\varepsilon)$-independence-query $(1 - \\varepsilon)$-approximation algorithm of Blikstad [ICALP 2021], but terminate it before completion. Moreover, we also present a semi-streaming algorithm for $(2/3 -\\varepsilon)$-approximation of matroid intersection in $O(1/\\varepsilon)$ passes.","sentences":["In the matroid intersection problem, we are given two matroids $\\mathcal{M}_1 = (V, \\mathcal{I}_1)$ and $\\mathcal{M}_2 = (V, \\mathcal{I}_2)$ defined on the same ground set $V$ of $n$ elements, and the objective is to find a common independent set $S \\in \\mathcal{I}_1 \\cap \\mathcal{I}_2$ of largest possible cardinality, denoted by $r$. In this paper, we consider a deterministic matroid intersection algorithm with only a nearly linear number of independence oracle queries.","Our contribution is to present a deterministic $O(\\frac{n}{\\varepsilon} + r \\log r)$-independence-query $(2/3-\\varepsilon)$-approximation algorithm for any $\\varepsilon > 0$.","Our idea is very simple: we apply a recent $\\tilde{O}(n \\sqrt{r}/\\varepsilon)$-independence-query $(1 - \\varepsilon)$-approximation algorithm of Blikstad [ICALP 2021], but terminate it before completion.","Moreover, we also present a semi-streaming algorithm for $(2/3 -\\varepsilon)$-approximation of matroid intersection in $O(1/\\varepsilon)$ passes."],"url":"http://arxiv.org/abs/2410.18820v1"}
{"created":"2024-10-24 15:08:17","title":"From Imitation to Introspection: Probing Self-Consciousness in Language Models","abstract":"Self-consciousness, the introspection of one's existence and thoughts, represents a high-level cognitive process. As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious? Drawing upon insights from psychological and neural science, this work presents a practical definition of self-consciousness for language models and refines ten core concepts. Our work pioneers an investigation into self-consciousness in language models by, for the first time, leveraging causal structural games to establish the functional definitions of the ten core concepts. Based on our definitions, we conduct a comprehensive four-stage experiment: quantification (evaluation of ten leading models), representation (visualization of self-consciousness within the models), manipulation (modification of the models' representation), and acquisition (fine-tuning the models on core concepts). Our findings indicate that although models are in the early stages of developing self-consciousness, there is a discernible representation of certain concepts within their internal mechanisms. However, these representations of self-consciousness are hard to manipulate positively at the current stage, yet they can be acquired through targeted fine-tuning. Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness.","sentences":["Self-consciousness, the introspection of one's existence and thoughts, represents a high-level cognitive process.","As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious?","Drawing upon insights from psychological and neural science, this work presents a practical definition of self-consciousness for language models and refines ten core concepts.","Our work pioneers an investigation into self-consciousness in language models by, for the first time, leveraging causal structural games to establish the functional definitions of the ten core concepts.","Based on our definitions, we conduct a comprehensive four-stage experiment: quantification (evaluation of ten leading models), representation (visualization of self-consciousness within the models), manipulation (modification of the models' representation), and acquisition (fine-tuning the models on core concepts).","Our findings indicate that although models are in the early stages of developing self-consciousness, there is a discernible representation of certain concepts within their internal mechanisms.","However, these representations of self-consciousness are hard to manipulate positively at the current stage, yet they can be acquired through targeted fine-tuning.","Our datasets and code are at https://github.com/OpenCausaLab/SelfConsciousness."],"url":"http://arxiv.org/abs/2410.18819v1"}
{"created":"2024-10-24 14:57:46","title":"TangibleChannel: An Innovative Data Physicalization System for Visual Channel Education","abstract":"In this paper, we provide an overview of our attempts to harness data physicalizations as pedagogical tools for enhancing the understanding of visual channels. We first elaborate the research goals that we have crafted for the physicalization prototype, shedding light on the key principles that guided our design choices. Then we detail the materials and datasets we employed for nine channels on our physicalization prototype. A preliminary pilot study is followed to validate its effectiveness. In the end, we present our upcoming research initiatives, including a comparative study for assessing the usability of the physicalization system. In general, the main purpose of our work is to stimulate a wider engagement among visualization educators and researchers, encouraging them to delve into the potentialities of data physicalization as an innovative addition to contemporary teaching methodologies.","sentences":["In this paper, we provide an overview of our attempts to harness data physicalizations as pedagogical tools for enhancing the understanding of visual channels.","We first elaborate the research goals that we have crafted for the physicalization prototype, shedding light on the key principles that guided our design choices.","Then we detail the materials and datasets we employed for nine channels on our physicalization prototype.","A preliminary pilot study is followed to validate its effectiveness.","In the end, we present our upcoming research initiatives, including a comparative study for assessing the usability of the physicalization system.","In general, the main purpose of our work is to stimulate a wider engagement among visualization educators and researchers, encouraging them to delve into the potentialities of data physicalization as an innovative addition to contemporary teaching methodologies."],"url":"http://arxiv.org/abs/2410.18810v1"}
{"created":"2024-10-24 14:57:00","title":"Learning Global Object-Centric Representations via Disentangled Slot Attention","abstract":"Humans can discern scene-independent features of objects across various environments, allowing them to swiftly identify objects amidst changing factors such as lighting, perspective, size, and position and imagine the complete images of the same object in diverse settings. Existing object-centric learning methods only extract scene-dependent object-centric representations, lacking the ability to identify the same object across scenes as humans. Moreover, some existing methods discard the individual object generation capabilities to handle complex scenes. This paper introduces a novel object-centric learning method to empower AI systems with human-like capabilities to identify objects across scenes and generate diverse scenes containing specific objects by learning a set of global object-centric representations. To learn the global object-centric representations that encapsulate globally invariant attributes of objects (i.e., the complete appearance and shape), this paper designs a Disentangled Slot Attention module to convert the scene features into scene-dependent attributes (such as scale, position and orientation) and scene-independent representations (i.e., appearance and shape). Experimental results substantiate the efficacy of the proposed method, demonstrating remarkable proficiency in global object-centric representation learning, object identification, scene generation with specific objects and scene decomposition.","sentences":["Humans can discern scene-independent features of objects across various environments, allowing them to swiftly identify objects amidst changing factors such as lighting, perspective, size, and position and imagine the complete images of the same object in diverse settings.","Existing object-centric learning methods only extract scene-dependent object-centric representations, lacking the ability to identify the same object across scenes as humans.","Moreover, some existing methods discard the individual object generation capabilities to handle complex scenes.","This paper introduces a novel object-centric learning method to empower AI systems with human-like capabilities to identify objects across scenes and generate diverse scenes containing specific objects by learning a set of global object-centric representations.","To learn the global object-centric representations that encapsulate globally invariant attributes of objects (i.e., the complete appearance and shape), this paper designs a Disentangled Slot Attention module to convert the scene features into scene-dependent attributes (such as scale, position and orientation) and scene-independent representations (i.e., appearance and shape).","Experimental results substantiate the efficacy of the proposed method, demonstrating remarkable proficiency in global object-centric representation learning, object identification, scene generation with specific objects and scene decomposition."],"url":"http://arxiv.org/abs/2410.18809v1"}
{"created":"2024-10-24 14:55:09","title":"Delving into the Reversal Curse: How Far Can Large Language Models Generalize?","abstract":"While large language models (LLMs) showcase unprecedented capabilities, they also exhibit certain inherent limitations when facing seemingly trivial tasks. A prime example is the recently debated \"reversal curse\", which surfaces when models, having been trained on the fact \"A is B\", struggle to generalize this knowledge to infer that \"B is A\". In this paper, we examine the manifestation of the reversal curse across various tasks and delve into both the generalization abilities and the problem-solving mechanisms of LLMs. This investigation leads to a series of significant insights: (1) LLMs are able to generalize to \"B is A\" when both A and B are presented in the context as in the case of a multiple-choice question. (2) This generalization ability is highly correlated to the structure of the fact \"A is B\" in the training documents. For example, this generalization only applies to biographies structured in \"[Name] is [Description]\" but not to \"[Description] is [Name]\". (3) We propose and verify the hypothesis that LLMs possess an inherent bias in fact recalling during knowledge application, which explains and underscores the importance of the document structure to successful learning. (4) The negative impact of this bias on the downstream performance of LLMs can hardly be mitigated through training alone. Based on these intriguing findings, our work not only presents a novel perspective for interpreting LLMs' generalization abilities from their intrinsic working mechanism but also provides new insights for the development of more effective learning methods for LLMs.","sentences":["While large language models (LLMs) showcase unprecedented capabilities, they also exhibit certain inherent limitations when facing seemingly trivial tasks.","A prime example is the recently debated \"reversal curse\", which surfaces when models, having been trained on the fact \"A is B\", struggle to generalize this knowledge to infer that \"B is A\".","In this paper, we examine the manifestation of the reversal curse across various tasks and delve into both the generalization abilities and the problem-solving mechanisms of LLMs.","This investigation leads to a series of significant insights: (1) LLMs are able to generalize to \"B is A\" when both A and B are presented in the context as in the case of a multiple-choice question.","(2) This generalization ability is highly correlated to the structure of the fact \"A is B\" in the training documents.","For example, this generalization only applies to biographies structured in \"[Name] is [Description]\" but not to \"[Description] is [Name]\".","(3) We propose and verify the hypothesis that LLMs possess an inherent bias in fact recalling during knowledge application, which explains and underscores the importance of the document structure to successful learning.","(4) The negative impact of this bias on the downstream performance of LLMs can hardly be mitigated through training alone.","Based on these intriguing findings, our work not only presents a novel perspective for interpreting LLMs' generalization abilities from their intrinsic working mechanism but also provides new insights for the development of more effective learning methods for LLMs."],"url":"http://arxiv.org/abs/2410.18808v1"}
{"created":"2024-10-24 14:54:09","title":"A Combinatorial Approach to Neural Emergent Communication","abstract":"Substantial research on deep learning-based emergent communication uses the referential game framework, specifically the Lewis signaling game, however we argue that successful communication in this game typically only need one or two effective symbols (i.e. message length) because of a sampling pitfall in the training data. To address this issue, we provide a theoretical analysis and introduce a combinatorial algorithm SolveMinSym (SMS) to determine the minimum number of symbols for successful communication min(|M|) in the Lewis signaling game. We use SMS algorithm to create datasets with different min(|M|) to empirically show that higher min(|M|) for the training data increases the number of effective symbols in the emergent language.","sentences":["Substantial research on deep learning-based emergent communication uses the referential game framework, specifically the Lewis signaling game, however we argue that successful communication in this game typically only need one or two effective symbols (i.e. message length) because of a sampling pitfall in the training data.","To address this issue, we provide a theoretical analysis and introduce a combinatorial algorithm SolveMinSym (SMS) to determine the minimum number of symbols for successful communication min(|M|) in the Lewis signaling game.","We use SMS algorithm to create datasets with different min(|M|) to empirically show that higher min(|M|) for the training data increases the number of effective symbols in the emergent language."],"url":"http://arxiv.org/abs/2410.18806v1"}
{"created":"2024-10-24 14:52:38","title":"Fast constrained sampling in pre-trained diffusion models","abstract":"Diffusion models have dominated the field of large, generative image models, with the prime examples of Stable Diffusion and DALL-E 3 being widely adopted. These models have been trained to perform text-conditioned generation on vast numbers of image-caption pairs and as a byproduct, have acquired general knowledge about natural image statistics. However, when confronted with the task of constrained sampling, e.g. generating the right half of an image conditioned on the known left half, applying these models is a delicate and slow process, with previously proposed algorithms relying on expensive iterative operations that are usually orders of magnitude slower than text-based inference. This is counter-intuitive, as image-conditioned generation should rely less on the difficult-to-learn semantic knowledge that links captions and imagery, and should instead be achievable by lower-level correlations among image pixels. In practice, inverse models are trained or tuned separately for each inverse problem, e.g. by providing parts of images during training as an additional condition, to allow their application in realistic settings. However, we argue that this is not necessary and propose an algorithm for fast-constrained sampling in large pre-trained diffusion models (Stable Diffusion) that requires no expensive backpropagation operations through the model and produces results comparable even to the state-of-the-art \\emph{tuned} models. Our method is based on a novel optimization perspective to sampling under constraints and employs a numerical approximation to the expensive gradients, previously computed using backpropagation, incurring significant speed-ups.","sentences":["Diffusion models have dominated the field of large, generative image models, with the prime examples of Stable Diffusion and DALL-E 3 being widely adopted.","These models have been trained to perform text-conditioned generation on vast numbers of image-caption pairs and as a byproduct, have acquired general knowledge about natural image statistics.","However, when confronted with the task of constrained sampling, e.g. generating the right half of an image conditioned on the known left half, applying these models is a delicate and slow process, with previously proposed algorithms relying on expensive iterative operations that are usually orders of magnitude slower than text-based inference.","This is counter-intuitive, as image-conditioned generation should rely less on the difficult-to-learn semantic knowledge that links captions and imagery, and should instead be achievable by lower-level correlations among image pixels.","In practice, inverse models are trained or tuned separately for each inverse problem, e.g. by providing parts of images during training as an additional condition, to allow their application in realistic settings.","However, we argue that this is not necessary and propose an algorithm for fast-constrained sampling in large pre-trained diffusion models (Stable Diffusion) that requires no expensive backpropagation operations through the model and produces results comparable even to the state-of-the-art \\emph{tuned} models.","Our method is based on a novel optimization perspective to sampling under constraints and employs a numerical approximation to the expensive gradients, previously computed using backpropagation, incurring significant speed-ups."],"url":"http://arxiv.org/abs/2410.18804v1"}
{"created":"2024-10-24 14:52:21","title":"Language-Agnostic Modeling of Source Reliability on Wikipedia","abstract":"Over the last few years, content verification through reliable sources has become a fundamental need to combat disinformation. Here, we present a language-agnostic model designed to assess the reliability of sources across multiple language editions of Wikipedia. Utilizing editorial activity data, the model evaluates source reliability within different articles of varying controversiality such as Climate Change, COVID-19, History, Media, and Biology topics. Crafting features that express domain usage across articles, the model effectively predicts source reliability, achieving an F1 Macro score of approximately 0.80 for English and other high-resource languages. For mid-resource languages, we achieve 0.65 while the performance of low-resource languages varies; in all cases, the time the domain remains present in the articles (which we dub as permanence) is one of the most predictive features. We highlight the challenge of maintaining consistent model performance across languages of varying resource levels and demonstrate that adapting models from higher-resource languages can improve performance. This work contributes not only to Wikipedia's efforts in ensuring content verifiability but in ensuring reliability across diverse user-generated content in various language communities.","sentences":["Over the last few years, content verification through reliable sources has become a fundamental need to combat disinformation.","Here, we present a language-agnostic model designed to assess the reliability of sources across multiple language editions of Wikipedia.","Utilizing editorial activity data, the model evaluates source reliability within different articles of varying controversiality such as Climate Change, COVID-19, History, Media, and Biology topics.","Crafting features that express domain usage across articles, the model effectively predicts source reliability, achieving an F1 Macro score of approximately 0.80 for English and other high-resource languages.","For mid-resource languages, we achieve 0.65 while the performance of low-resource languages varies; in all cases, the time the domain remains present in the articles (which we dub as permanence) is one of the most predictive features.","We highlight the challenge of maintaining consistent model performance across languages of varying resource levels and demonstrate that adapting models from higher-resource languages can improve performance.","This work contributes not only to Wikipedia's efforts in ensuring content verifiability but in ensuring reliability across diverse user-generated content in various language communities."],"url":"http://arxiv.org/abs/2410.18803v1"}
{"created":"2024-10-24 14:51:09","title":"PointPatchRL -- Masked Reconstruction Improves Reinforcement Learning on Point Clouds","abstract":"Perceiving the environment via cameras is crucial for Reinforcement Learning (RL) in robotics. While images are a convenient form of representation, they often complicate extracting important geometric details, especially with varying geometries or deformable objects. In contrast, point clouds naturally represent this geometry and easily integrate color and positional data from multiple camera views. However, while deep learning on point clouds has seen many recent successes, RL on point clouds is under-researched, with only the simplest encoder architecture considered in the literature. We introduce PointPatchRL (PPRL), a method for RL on point clouds that builds on the common paradigm of dividing point clouds into overlapping patches, tokenizing them, and processing the tokens with transformers. PPRL provides significant improvements compared with other point-cloud processing architectures previously used for RL. We then complement PPRL with masked reconstruction for representation learning and show that our method outperforms strong model-free and model-based baselines on image observations in complex manipulation tasks containing deformable objects and variations in target object geometry. Videos and code are available at https://alrhub.github.io/pprl-website","sentences":["Perceiving the environment via cameras is crucial for Reinforcement Learning (RL) in robotics.","While images are a convenient form of representation, they often complicate extracting important geometric details, especially with varying geometries or deformable objects.","In contrast, point clouds naturally represent this geometry and easily integrate color and positional data from multiple camera views.","However, while deep learning on point clouds has seen many recent successes, RL on point clouds is under-researched, with only the simplest encoder architecture considered in the literature.","We introduce PointPatchRL (PPRL), a method for RL on point clouds that builds on the common paradigm of dividing point clouds into overlapping patches, tokenizing them, and processing the tokens with transformers.","PPRL provides significant improvements compared with other point-cloud processing architectures previously used for RL.","We then complement PPRL with masked reconstruction for representation learning and show that our method outperforms strong model-free and model-based baselines on image observations in complex manipulation tasks containing deformable objects and variations in target object geometry.","Videos and code are available at https://alrhub.github.io/pprl-website"],"url":"http://arxiv.org/abs/2410.18800v1"}
{"created":"2024-10-24 14:51:00","title":"Arbitrary-arity Tree Automata and QCTL","abstract":"We introduce a new class of automata (which we coin EU-automata) running on infininte trees of arbitrary (finite) arity. We develop and study several algorithms to perform classical operations (union, intersection, complement, projection, alternation removal) for those automata, and precisely characterise their complexities. We also develop algorithms for solving membership and emptiness for the languages of trees accepted by EU-automata.   We then use EU-automata to obtain several algorithmic and expressiveness results for the temporal logic QCTL (which extends CTL with quantification over atomic propositions) and for MSO. On the one hand, we obtain decision procedures with optimal complexity for QCTL satisfiability and model checking; on the other hand, we obtain an algorithm for translating any QCTL formula with k quantifier alternations to formulas with at most one quantifier alternation, at the expense of a $(k + 1)$-exponential blow-up in the size of the formulas. Using the same techniques, we prove that any MSO formula can be translated into a formula with at most four quantifier alternations (and only two second-order-quantifier alternations), again with a $(k + 1)$-exponential blow-up in the size of the formula.","sentences":["We introduce a new class of automata (which we coin EU-automata) running on infininte trees of arbitrary (finite) arity.","We develop and study several algorithms to perform classical operations (union, intersection, complement, projection, alternation removal) for those automata, and precisely characterise their complexities.","We also develop algorithms for solving membership and emptiness for the languages of trees accepted by EU-automata.   ","We then use EU-automata to obtain several algorithmic and expressiveness results for the temporal logic QCTL (which extends CTL with quantification over atomic propositions) and for MSO.","On the one hand, we obtain decision procedures with optimal complexity for QCTL satisfiability and model checking; on the other hand, we obtain an algorithm for translating any QCTL formula with k quantifier alternations to formulas with at most one quantifier alternation, at the expense of a $(k + 1)$-exponential blow-up in the size of the formulas.","Using the same techniques, we prove that any MSO formula can be translated into a formula with at most four quantifier alternations (and only two second-order-quantifier alternations), again with a $(k + 1)$-exponential blow-up in the size of the formula."],"url":"http://arxiv.org/abs/2410.18799v1"}
{"created":"2024-10-24 14:50:42","title":"Distill Visual Chart Reasoning Ability from LLMs to MLLMs","abstract":"Solving complex chart Q&A tasks requires advanced visual reasoning abilities in multimodal large language models (MLLMs). Recent studies highlight that these abilities consist of two main parts: recognizing key information from visual inputs and conducting reasoning over it. Thus, a promising approach to enhance MLLMs is to construct relevant training data focusing on the two aspects. However, collecting and annotating complex charts and questions is costly and time-consuming, and ensuring the quality of annotated answers remains a challenge. In this paper, we propose Code-as-Intermediary Translation (CIT), a cost-effective, efficient and easily scalable data synthesis method for distilling visual reasoning abilities from LLMs to MLLMs. The code serves as an intermediary that translates visual chart representations into textual representations, enabling LLMs to understand cross-modal information. Specifically, we employ text-based synthesizing techniques to construct chart-plotting code and produce ReachQA, a dataset containing 3k reasoning-intensive charts and 20k Q&A pairs to enhance both recognition and reasoning abilities. Experiments show that when fine-tuned with our data, models not only perform well on chart-related benchmarks, but also demonstrate improved multimodal reasoning abilities on general mathematical benchmarks like MathVista. The code and dataset are publicly available at https://github.com/hewei2001/ReachQA.","sentences":["Solving complex chart Q&A tasks requires advanced visual reasoning abilities in multimodal large language models (MLLMs).","Recent studies highlight that these abilities consist of two main parts: recognizing key information from visual inputs and conducting reasoning over it.","Thus, a promising approach to enhance MLLMs is to construct relevant training data focusing on the two aspects.","However, collecting and annotating complex charts and questions is costly and time-consuming, and ensuring the quality of annotated answers remains a challenge.","In this paper, we propose Code-as-Intermediary Translation (CIT), a cost-effective, efficient and easily scalable data synthesis method for distilling visual reasoning abilities from LLMs to MLLMs.","The code serves as an intermediary that translates visual chart representations into textual representations, enabling LLMs to understand cross-modal information.","Specifically, we employ text-based synthesizing techniques to construct chart-plotting code and produce ReachQA, a dataset containing 3k reasoning-intensive charts and 20k Q&A pairs to enhance both recognition and reasoning abilities.","Experiments show that when fine-tuned with our data, models not only perform well on chart-related benchmarks, but also demonstrate improved multimodal reasoning abilities on general mathematical benchmarks like MathVista.","The code and dataset are publicly available at https://github.com/hewei2001/ReachQA."],"url":"http://arxiv.org/abs/2410.18798v1"}
{"created":"2024-10-24 14:49:59","title":"Learning Geodesics of Geometric Shape Deformations From Images","abstract":"This paper presents a novel method, named geodesic deformable networks (GDN), that for the first time enables the learning of geodesic flows of deformation fields derived from images. In particular, the capability of our proposed GDN being able to predict geodesics is important for quantifying and comparing deformable shape presented in images. The geodesic deformations, also known as optimal transformations that align pairwise images, are often parameterized by a time sequence of smooth vector fields governed by nonlinear differential equations. A bountiful literature has been focusing on learning the initial conditions (e.g., initial velocity fields) based on registration networks. However, the definition of geodesics central to deformation-based shape analysis is blind to the networks. To address this problem, we carefully develop an efficient neural operator to treat the geodesics as unknown mapping functions learned from the latent deformation spaces. A composition of integral operators and smooth activation functions is then formulated to effectively approximate such mappings. In contrast to previous works, our GDN jointly optimizes a newly defined geodesic loss, which adds additional benefits to promote the network regularizability and generalizability. We demonstrate the effectiveness of GDN on both 2D synthetic data and 3D real brain magnetic resonance imaging (MRI).","sentences":["This paper presents a novel method, named geodesic deformable networks (GDN), that for the first time enables the learning of geodesic flows of deformation fields derived from images.","In particular, the capability of our proposed GDN being able to predict geodesics is important for quantifying and comparing deformable shape presented in images.","The geodesic deformations, also known as optimal transformations that align pairwise images, are often parameterized by a time sequence of smooth vector fields governed by nonlinear differential equations.","A bountiful literature has been focusing on learning the initial conditions (e.g., initial velocity fields) based on registration networks.","However, the definition of geodesics central to deformation-based shape analysis is blind to the networks.","To address this problem, we carefully develop an efficient neural operator to treat the geodesics as unknown mapping functions learned from the latent deformation spaces.","A composition of integral operators and smooth activation functions is then formulated to effectively approximate such mappings.","In contrast to previous works, our GDN jointly optimizes a newly defined geodesic loss, which adds additional benefits to promote the network regularizability and generalizability.","We demonstrate the effectiveness of GDN on both 2D synthetic data and 3D real brain magnetic resonance imaging (MRI)."],"url":"http://arxiv.org/abs/2410.18797v1"}
{"created":"2024-10-24 14:47:36","title":"WARP-LCA: Efficient Convolutional Sparse Coding with Locally Competitive Algorithm","abstract":"The locally competitive algorithm (LCA) can solve sparse coding problems across a wide range of use cases. Recently, convolution-based LCA approaches have been shown to be highly effective for enhancing robustness for image recognition tasks in vision pipelines. To additionally maximize representational sparsity, LCA with hard-thresholding can be applied. While this combination often yields very good solutions satisfying an $\\ell_0$ sparsity criterion, it comes with significant drawbacks for practical application: (i) LCA is very inefficient, typically requiring hundreds of optimization cycles for convergence; (ii) the use of hard-thresholding results in a non-convex loss function, which might lead to suboptimal minima. To address these issues, we propose the Locally Competitive Algorithm with State Warm-up via Predictive Priming (WARP-LCA), which leverages a predictor network to provide a suitable initial guess of the LCA state based on the current input. Our approach significantly improves both convergence speed and the quality of solutions, while maintaining and even enhancing the overall strengths of LCA. We demonstrate that WARP-LCA converges faster by orders of magnitude and reaches better minima compared to conventional LCA. Moreover, the learned representations are more sparse and exhibit superior properties in terms of reconstruction and denoising quality as well as robustness when applied in deep recognition pipelines. Furthermore, we apply WARP-LCA to image denoising tasks, showcasing its robustness and practical effectiveness. Our findings confirm that the naive use of LCA with hard-thresholding results in suboptimal minima, whereas initializing LCA with a predictive guess results in better outcomes. This research advances the field of biologically inspired deep learning by providing a novel approach to convolutional sparse coding.","sentences":["The locally competitive algorithm (LCA) can solve sparse coding problems across a wide range of use cases.","Recently, convolution-based LCA approaches have been shown to be highly effective for enhancing robustness for image recognition tasks in vision pipelines.","To additionally maximize representational sparsity, LCA with hard-thresholding can be applied.","While this combination often yields very good solutions satisfying an $\\ell_0$ sparsity criterion, it comes with significant drawbacks for practical application: (i) LCA is very inefficient, typically requiring hundreds of optimization cycles for convergence; (ii) the use of hard-thresholding results in a non-convex loss function, which might lead to suboptimal minima.","To address these issues, we propose the Locally Competitive Algorithm with State Warm-up via Predictive Priming (WARP-LCA), which leverages a predictor network to provide a suitable initial guess of the LCA state based on the current input.","Our approach significantly improves both convergence speed and the quality of solutions, while maintaining and even enhancing the overall strengths of LCA.","We demonstrate that WARP-LCA converges faster by orders of magnitude and reaches better minima compared to conventional LCA.","Moreover, the learned representations are more sparse and exhibit superior properties in terms of reconstruction and denoising quality as well as robustness when applied in deep recognition pipelines.","Furthermore, we apply WARP-LCA to image denoising tasks, showcasing its robustness and practical effectiveness.","Our findings confirm that the naive use of LCA with hard-thresholding results in suboptimal minima, whereas initializing LCA with a predictive guess results in better outcomes.","This research advances the field of biologically inspired deep learning by providing a novel approach to convolutional sparse coding."],"url":"http://arxiv.org/abs/2410.18794v1"}
{"created":"2024-10-24 14:47:28","title":"Adapting MLOps for Diverse In-Network Intelligence in 6G Era: Challenges and Solutions","abstract":"Seamless integration of artificial intelligence (AI) and machine learning (ML) techniques with wireless systems is a crucial step for 6G AInization. However, such integration faces challenges in terms of model functionality and lifecycle management. ML operations (MLOps) offer a systematic approach to tackle these challenges. Existing approaches toward implementing MLOps in a centralized platform often overlook the challenges posed by diverse learning paradigms and network heterogeneity. This article provides a new approach to MLOps targeting the intricacies of future wireless networks. Considering unique aspects of the future radio access network (RAN), we formulate three operational pipelines, namely reinforcement learning operations (RLOps), federated learning operations (FedOps), and generative AI operations (GenOps). These pipelines form the foundation for seamlessly integrating various learning/inference capabilities into networks. We outline the specific challenges and proposed solutions for each operation, facilitating large-scale deployment of AI-Native 6G networks.","sentences":["Seamless integration of artificial intelligence (AI) and machine learning (ML) techniques with wireless systems is a crucial step for 6G AInization.","However, such integration faces challenges in terms of model functionality and lifecycle management.","ML operations (MLOps) offer a systematic approach to tackle these challenges.","Existing approaches toward implementing MLOps in a centralized platform often overlook the challenges posed by diverse learning paradigms and network heterogeneity.","This article provides a new approach to MLOps targeting the intricacies of future wireless networks.","Considering unique aspects of the future radio access network (RAN), we formulate three operational pipelines, namely reinforcement learning operations (RLOps), federated learning operations (FedOps), and generative AI operations (GenOps).","These pipelines form the foundation for seamlessly integrating various learning/inference capabilities into networks.","We outline the specific challenges and proposed solutions for each operation, facilitating large-scale deployment of AI-Native 6G networks."],"url":"http://arxiv.org/abs/2410.18793v1"}
{"created":"2024-10-24 14:47:25","title":"An LLM Agent for Automatic Geospatial Data Analysis","abstract":"Large language models (LLMs) are being used in data science code generation tasks, but they often struggle with complex sequential tasks, leading to logical errors. Their application to geospatial data processing is particularly challenging due to difficulties in incorporating complex data structures and spatial constraints, effectively utilizing diverse function calls, and the tendency to hallucinate less-used geospatial libraries. To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively. GeoAgent pioneers the integration of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm, offering a novel approach to geospatial data processing. In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks. This benchmark leverages a variety of Python libraries and includes both single-turn and multi-turn tasks such as data acquisition, data analysis, and visualization. By offering a comprehensive evaluation among diverse geospatial contexts, this benchmark sets a new standard for developing LLM-based approaches in geospatial data analysis tasks. Our findings suggest that relying solely on knowledge of LLM is insufficient for accurate geospatial task programming, which requires coherent multi-step processes and multiple function calls. Compared to the baseline LLMs, the proposed GeoAgent has demonstrated superior performance, yielding notable improvements in function calls and task completion. In addition, these results offer valuable insights for the future development of LLM agents in automatic geospatial data analysis task programming.","sentences":["Large language models (LLMs) are being used in data science code generation tasks, but they often struggle with complex sequential tasks, leading to logical errors.","Their application to geospatial data processing is particularly challenging due to difficulties in incorporating complex data structures and spatial constraints, effectively utilizing diverse function calls, and the tendency to hallucinate less-used geospatial libraries.","To tackle these problems, we introduce GeoAgent, a new interactive framework designed to help LLMs handle geospatial data processing more effectively.","GeoAgent pioneers the integration of a code interpreter, static analysis, and Retrieval-Augmented Generation (RAG) techniques within a Monte Carlo Tree Search (MCTS) algorithm, offering a novel approach to geospatial data processing.","In addition, we contribute a new benchmark specifically designed to evaluate the LLM-based approach in geospatial tasks.","This benchmark leverages a variety of Python libraries and includes both single-turn and multi-turn tasks such as data acquisition, data analysis, and visualization.","By offering a comprehensive evaluation among diverse geospatial contexts, this benchmark sets a new standard for developing LLM-based approaches in geospatial data analysis tasks.","Our findings suggest that relying solely on knowledge of LLM is insufficient for accurate geospatial task programming, which requires coherent multi-step processes and multiple function calls.","Compared to the baseline LLMs, the proposed GeoAgent has demonstrated superior performance, yielding notable improvements in function calls and task completion.","In addition, these results offer valuable insights for the future development of LLM agents in automatic geospatial data analysis task programming."],"url":"http://arxiv.org/abs/2410.18792v1"}
{"created":"2024-10-24 14:43:35","title":"Large Generative AI Models meet Open Networks for 6G: Integration, Platform, and Monetization","abstract":"Generative artificial intelligence (GAI) has emerged as a pivotal technology for content generation, reasoning, and decision-making, making it a promising solution on the 6G stage characterized by openness, connected intelligence, and service democratization. This article explores strategies for integrating and monetizing GAI within future open 6G networks, mainly from the perspectives of mobile network operators (MNOs). We propose a novel API-centric telecoms GAI marketplace platform, designed to serve as a central hub for deploying, managing, and monetizing diverse GAI services directly within the network. This platform underpins a flexible and interoperable ecosystem, enhances service delivery, and facilitates seamless integration of GAI capabilities across various network segments, thereby enabling new revenue streams through customer-centric generative services. Results from experimental evaluation in an end-to-end Open RAN testbed, show the latency benefits of this platform for local large language model (LLM) deployment, by comparing token timing for various generated lengths with cloud-based general-purpose LLMs. Lastly, the article discusses key considerations for implementing the GAI marketplace within 6G networks, including monetization strategy, regulatory, management, and service platform aspects.","sentences":["Generative artificial intelligence (GAI) has emerged as a pivotal technology for content generation, reasoning, and decision-making, making it a promising solution on the 6G stage characterized by openness, connected intelligence, and service democratization.","This article explores strategies for integrating and monetizing GAI within future open 6G networks, mainly from the perspectives of mobile network operators (MNOs).","We propose a novel API-centric telecoms GAI marketplace platform, designed to serve as a central hub for deploying, managing, and monetizing diverse GAI services directly within the network.","This platform underpins a flexible and interoperable ecosystem, enhances service delivery, and facilitates seamless integration of GAI capabilities across various network segments, thereby enabling new revenue streams through customer-centric generative services.","Results from experimental evaluation in an end-to-end Open RAN testbed, show the latency benefits of this platform for local large language model (LLM) deployment, by comparing token timing for various generated lengths with cloud-based general-purpose LLMs.","Lastly, the article discusses key considerations for implementing the GAI marketplace within 6G networks, including monetization strategy, regulatory, management, and service platform aspects."],"url":"http://arxiv.org/abs/2410.18790v1"}
{"created":"2024-10-24 14:37:55","title":"Applying Neural Monte Carlo Tree Search to Unsignalized Multi-intersection Scheduling for Autonomous Vehicles","abstract":"Dynamic scheduling of access to shared resources by autonomous systems is a challenging problem, characterized as being NP-hard. The complexity of this task leads to a combinatorial explosion of possibilities in highly dynamic systems where arriving requests must be continuously scheduled subject to strong safety and time constraints. An example of such a system is an unsignalized intersection, where automated vehicles' access to potential conflict zones must be dynamically scheduled. In this paper, we apply Neural Monte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons of vehicles crossing unsignalized intersections. Crucially, we introduce a transformation model that maps successive sequences of potentially conflicting road-space reservation requests from platoons of vehicles into a series of board-game-like problems and use NMCTS to search for solutions representing optimal road-space allocation schedules in the context of past allocations. To optimize search, we incorporate a prioritized re-sampling method with parallel NMCTS (PNMCTS) to improve the quality of training data. To optimize training, a curriculum learning strategy is used to train the agent to schedule progressively more complex boards culminating in overlapping boards that represent busy intersections. In a busy single four-way unsignalized intersection simulation, PNMCTS solved 95\\% of unseen scenarios, reducing crossing time by 43\\% in light and 52\\% in heavy traffic versus first-in, first-out control. In a 3x3 multi-intersection network, the proposed method maintained free-flow in light traffic when all intersections are under control of PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers in average travel time by 74.5\\% and total throughput by 16\\% in heavy traffic.","sentences":["Dynamic scheduling of access to shared resources by autonomous systems is a challenging problem, characterized as being NP-hard.","The complexity of this task leads to a combinatorial explosion of possibilities in highly dynamic systems where arriving requests must be continuously scheduled subject to strong safety and time constraints.","An example of such a system is an unsignalized intersection, where automated vehicles' access to potential conflict zones must be dynamically scheduled.","In this paper, we apply Neural Monte Carlo Tree Search (NMCTS) to the challenging task of scheduling platoons of vehicles crossing unsignalized intersections.","Crucially, we introduce a transformation model that maps successive sequences of potentially conflicting road-space reservation requests from platoons of vehicles into a series of board-game-like problems and use NMCTS to search for solutions representing optimal road-space allocation schedules in the context of past allocations.","To optimize search, we incorporate a prioritized re-sampling method with parallel NMCTS (PNMCTS) to improve the quality of training data.","To optimize training, a curriculum learning strategy is used to train the agent to schedule progressively more complex boards culminating in overlapping boards that represent busy intersections.","In a busy single four-way unsignalized intersection simulation, PNMCTS solved 95\\% of unseen scenarios, reducing crossing time by 43\\% in light and 52\\% in heavy traffic versus first-in, first-out control.","In a 3x3 multi-intersection network, the proposed method maintained free-flow in light traffic when all intersections are under control of PNMCTS and outperformed state-of-the-art RL-based traffic-light controllers in average travel time by 74.5\\% and total throughput by 16\\% in heavy traffic."],"url":"http://arxiv.org/abs/2410.18786v1"}
{"created":"2024-10-24 14:36:48","title":"Should We Really Edit Language Models? On the Evaluation of Edited Language Models","abstract":"Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models. Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria. Some recent works disclose the pitfalls of these editing methods such as knowledge distortion or conflict. However, the general abilities of post-edited language models remain unexplored. In this paper, we perform a comprehensive evaluation on various editing methods and different language models, and have following findings. (1) Existing editing methods lead to inevitable performance deterioration on general benchmarks, indicating that existing editing methods maintain the general abilities of the model within only a few dozen edits. When the number of edits is slightly large, the intrinsic knowledge structure of the model is disrupted or even completely damaged. (2) Instruction-tuned models are more robust to editing, showing less performance drop on general knowledge after editing. (3) Language model with large scale is more resistant to editing compared to small model. (4) The safety of the edited model, is significantly weakened, even for those safety-aligned models. Our findings indicate that current editing methods are only suitable for small-scale knowledge updates within language models, which motivates further research on more practical and reliable editing methods. The details of code and reproduction can be found in https://github.com/lqinfdim/EditingEvaluation.","sentences":["Model editing has become an increasingly popular alternative for efficiently updating knowledge within language models.","Current methods mainly focus on reliability, generalization, and locality, with many methods excelling across these criteria.","Some recent works disclose the pitfalls of these editing methods such as knowledge distortion or conflict.","However, the general abilities of post-edited language models remain unexplored.","In this paper, we perform a comprehensive evaluation on various editing methods and different language models, and have following findings.","(1) Existing editing methods lead to inevitable performance deterioration on general benchmarks, indicating that existing editing methods maintain the general abilities of the model within only a few dozen edits.","When the number of edits is slightly large, the intrinsic knowledge structure of the model is disrupted or even completely damaged.","(2) Instruction-tuned models are more robust to editing, showing less performance drop on general knowledge after editing.","(3) Language model with large scale is more resistant to editing compared to small model.","(4) The safety of the edited model, is significantly weakened, even for those safety-aligned models.","Our findings indicate that current editing methods are only suitable for small-scale knowledge updates within language models, which motivates further research on more practical and reliable editing methods.","The details of code and reproduction can be found in https://github.com/lqinfdim/EditingEvaluation."],"url":"http://arxiv.org/abs/2410.18785v1"}
{"created":"2024-10-24 14:36:12","title":"Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality","abstract":"The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this prior work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Our theory is established based on a key observation: the DDPM update rule is equivalent to running a suitably parameterized SDE upon discretization, where the nonlinear component of the drift term is intrinsically low-dimensional.","sentences":["The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI.","While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency.","This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data.","We strengthen this prior work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality.","For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy.","Our theory is established based on a key observation: the DDPM update rule is equivalent to running a suitably parameterized SDE upon discretization, where the nonlinear component of the drift term is intrinsically low-dimensional."],"url":"http://arxiv.org/abs/2410.18784v1"}
{"created":"2024-10-24 14:31:52","title":"A Little Help Goes a Long Way: Efficient LLM Training by Leveraging Small LMs","abstract":"A primary challenge in large language model (LLM) development is their onerous pre-training cost. Typically, such pre-training involves optimizing a self-supervised objective (such as next-token prediction) over a large corpus. This paper explores a promising paradigm to improve LLM pre-training efficiency and quality by suitably leveraging a small language model (SLM). In particular, this paradigm relies on an SLM to both (1) provide soft labels as additional training supervision, and (2) select a small subset of valuable (\"informative\" and \"hard\") training examples. Put together, this enables an effective transfer of the SLM's predictive distribution to the LLM, while prioritizing specific regions of the training data distribution. Empirically, this leads to reduced LLM training time compared to standard training, while improving the overall quality. Theoretically, we develop a statistical framework to systematically study the utility of SLMs in enabling efficient training of high-quality LLMs. In particular, our framework characterizes how the SLM's seemingly low-quality supervision can enhance the training of a much more capable LLM. Furthermore, it also highlights the need for an adaptive utilization of such supervision, by striking a balance between the bias and variance introduced by the SLM-provided soft labels. We corroborate our theoretical framework by improving the pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B parameters on the Pile dataset.","sentences":["A primary challenge in large language model (LLM) development is their onerous pre-training cost.","Typically, such pre-training involves optimizing a self-supervised objective (such as next-token prediction) over a large corpus.","This paper explores a promising paradigm to improve LLM pre-training efficiency and quality by suitably leveraging a small language model (SLM).","In particular, this paradigm relies on an SLM to both (1) provide soft labels as additional training supervision, and (2) select a small subset of valuable (\"informative\" and \"hard\") training examples.","Put together, this enables an effective transfer of the SLM's predictive distribution to the LLM, while prioritizing specific regions of the training data distribution.","Empirically, this leads to reduced LLM training time compared to standard training, while improving the overall quality.","Theoretically, we develop a statistical framework to systematically study the utility of SLMs in enabling efficient training of high-quality LLMs.","In particular, our framework characterizes how the SLM's seemingly low-quality supervision can enhance the training of a much more capable LLM.","Furthermore, it also highlights the need for an adaptive utilization of such supervision, by striking a balance between the bias and variance introduced by the SLM-provided soft labels.","We corroborate our theoretical framework by improving the pre-training of an LLM with 2.8B parameters by utilizing a smaller LM with 1.5B parameters on the Pile dataset."],"url":"http://arxiv.org/abs/2410.18779v1"}
