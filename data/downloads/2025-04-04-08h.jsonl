{"created":"2025-04-03 17:59:58","title":"Concept Lancet: Image Editing with Compositional Representation Transplant","abstract":"Diffusion models are widely used for image editing tasks. Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space. However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task. Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error. To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing. At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts. This allows us to accurately estimate the presence of concepts in each image, which informs the edit. Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction. To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary. Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation.","sentences":["Diffusion models are widely used for image editing tasks.","Existing editing methods often design a representation manipulation procedure by curating an edit direction in the text embedding or score space.","However, such a procedure faces a key challenge: overestimating the edit strength harms visual consistency while underestimating it fails the editing task.","Notably, each source image may require a different editing strength, and it is costly to search for an appropriate strength via trial-and-error.","To address this challenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing.","At inference time, we decompose the source input in the latent (text embedding or diffusion score) space as a sparse linear combination of the representations of the collected visual concepts.","This allows us to accurately estimate the presence of concepts in each image, which informs the edit.","Based on the editing task (replace/add/remove), we perform a customized concept transplant process to impose the corresponding editing direction.","To sufficiently model the concept space, we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary.","Experiments on multiple diffusion-based image editing baselines show that methods equipped with CoLan achieve state-of-the-art performance in editing effectiveness and consistency preservation."],"url":"http://arxiv.org/abs/2504.02828v1"}
{"created":"2025-04-03 17:59:56","title":"Envisioning Beyond the Pixels: Benchmarking Reasoning-Informed Visual Editing","abstract":"Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats. To address this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE). RISEBench focuses on four key reasoning types: Temporal, Causal, Spatial, and Logical Reasoning. We curate high-quality test cases for each category and propose an evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and an LMM-as-a-judge approach. Our experiments reveal that while GPT-4o-Native significantly outperforms other open-source and proprietary models, even this state-of-the-art system struggles with logical reasoning tasks, highlighting an area that remains underexplored. As an initial effort, RISEBench aims to provide foundational insights into reasoning-aware visual editing and to catalyze future research. Though still in its early stages, we are committed to continuously expanding and refining the benchmark to support more comprehensive, reliable, and scalable evaluations of next-generation multimodal systems. Our code and data will be released at https://github.com/PhoenixZ810/RISEBench.","sentences":["Large Multi-modality Models (LMMs) have made significant progress in visual understanding and generation, but they still face challenges in General Visual Editing, particularly in following complex instructions, preserving appearance consistency, and supporting flexible input formats.","To address this gap, we introduce RISEBench, the first benchmark for evaluating Reasoning-Informed viSual Editing (RISE).","RISEBench focuses on four key reasoning types: Temporal, Causal, Spatial, and Logical Reasoning.","We curate high-quality test cases for each category and propose an evaluation framework that assesses Instruction Reasoning, Appearance Consistency, and Visual Plausibility with both human judges and an LMM-as-a-judge approach.","Our experiments reveal that while GPT-4o-Native significantly outperforms other open-source and proprietary models, even this state-of-the-art system struggles with logical reasoning tasks, highlighting an area that remains underexplored.","As an initial effort, RISEBench aims to provide foundational insights into reasoning-aware visual editing and to catalyze future research.","Though still in its early stages, we are committed to continuously expanding and refining the benchmark to support more comprehensive, reliable, and scalable evaluations of next-generation multimodal systems.","Our code and data will be released at https://github.com/PhoenixZ810/RISEBench."],"url":"http://arxiv.org/abs/2504.02826v1"}
{"created":"2025-04-03 17:59:56","title":"On Vanishing Variance in Transformer Length Generalization","abstract":"It is a widely known issue that Transformers, when trained on shorter sequences, fail to generalize robustly to longer ones at test time. This raises the question of whether Transformer models are real reasoning engines, despite their impressive abilities in mathematical problem solving and code synthesis. In this paper, we offer a vanishing variance perspective on this issue. To the best of our knowledge, we are the first to demonstrate that even for today's frontier models, a longer sequence length results in a decrease in variance in the output of the multi-head attention modules. On the argmax retrieval and dictionary lookup tasks, our experiments show that applying layer normalization after the attention outputs leads to significantly better length generalization. Our analyses attribute this improvement to a reduction-though not a complete elimination-of the distribution shift caused by vanishing variance.","sentences":["It is a widely known issue that Transformers, when trained on shorter sequences, fail to generalize robustly to longer ones at test time.","This raises the question of whether Transformer models are real reasoning engines, despite their impressive abilities in mathematical problem solving and code synthesis.","In this paper, we offer a vanishing variance perspective on this issue.","To the best of our knowledge, we are the first to demonstrate that even for today's frontier models, a longer sequence length results in a decrease in variance in the output of the multi-head attention modules.","On the argmax retrieval and dictionary lookup tasks, our experiments show that applying layer normalization after the attention outputs leads to significantly better length generalization.","Our analyses attribute this improvement to a reduction-though not a complete elimination-of the distribution shift caused by vanishing variance."],"url":"http://arxiv.org/abs/2504.02827v1"}
{"created":"2025-04-03 17:59:12","title":"STING-BEE: Towards Vision-Language Model for Real-World X-ray Baggage Security Inspection","abstract":"Advancements in Computer-Aided Screening (CAS) systems are essential for improving the detection of security threats in X-ray baggage scans. However, current datasets are limited in representing real-world, sophisticated threats and concealment tactics, and existing approaches are constrained by a closed-set paradigm with predefined labels. To address these challenges, we introduce STCray, the first multimodal X-ray baggage security dataset, comprising 46,642 image-caption paired scans across 21 threat categories, generated using an X-ray scanner for airport security. STCray is meticulously developed with our specialized protocol that ensures domain-aware, coherent captions, that lead to the multi-modal instruction following data in X-ray baggage security. This allows us to train a domain-aware visual AI assistant named STING-BEE that supports a range of vision-language tasks, including scene comprehension, referring threat localization, visual grounding, and visual question answering (VQA), establishing novel baselines for multi-modal learning in X-ray baggage security. Further, STING-BEE shows state-of-the-art generalization in cross-domain settings. Code, data, and models are available at https://divs1159.github.io/STING-BEE/.","sentences":["Advancements in Computer-Aided Screening (CAS) systems are essential for improving the detection of security threats in X-ray baggage scans.","However, current datasets are limited in representing real-world, sophisticated threats and concealment tactics, and existing approaches are constrained by a closed-set paradigm with predefined labels.","To address these challenges, we introduce STCray, the first multimodal X-ray baggage security dataset, comprising 46,642 image-caption paired scans across 21 threat categories, generated using an X-ray scanner for airport security.","STCray is meticulously developed with our specialized protocol that ensures domain-aware, coherent captions, that lead to the multi-modal instruction following data in X-ray baggage security.","This allows us to train a domain-aware visual AI assistant named STING-BEE that supports a range of vision-language tasks, including scene comprehension, referring threat localization, visual grounding, and visual question answering (VQA), establishing novel baselines for multi-modal learning in X-ray baggage security.","Further, STING-BEE shows state-of-the-art generalization in cross-domain settings.","Code, data, and models are available at https://divs1159.github.io/STING-BEE/."],"url":"http://arxiv.org/abs/2504.02823v1"}
{"created":"2025-04-03 17:58:44","title":"Do Two AI Scientists Agree?","abstract":"When two AI models are trained on the same scientific task, do they learn the same theory or two different theories? Throughout history of science, we have witnessed the rise and fall of theories driven by experimental validation or falsification: many theories may co-exist when experimental data is lacking, but the space of survived theories become more constrained with more experimental data becoming available. We show the same story is true for AI scientists. With increasingly more systems provided in training data, AI scientists tend to converge in the theories they learned, although sometimes they form distinct groups corresponding to different theories. To mechanistically interpret what theories AI scientists learn and quantify their agreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI Scientists, trained on standard problems in physics, aggregating training results across many seeds simulating the different configurations of AI scientists. Our findings suggests for AI scientists switch from learning a Hamiltonian theory in simple setups to a Lagrangian formulation when more complex systems are introduced. We also observe strong seed dependence of the training dynamics and final learned weights, controlling the rise and fall of relevant theories. We finally demonstrate that not only can our neural networks aid interpretability, it can also be applied to higher dimensional problems.","sentences":["When two AI models are trained on the same scientific task, do they learn the same theory or two different theories?","Throughout history of science, we have witnessed the rise and fall of theories driven by experimental validation or falsification: many theories may co-exist when experimental data is lacking, but the space of survived theories become more constrained with more experimental data becoming available.","We show the same story is true for AI scientists.","With increasingly more systems provided in training data, AI scientists tend to converge in the theories they learned, although sometimes they form distinct groups corresponding to different theories.","To mechanistically interpret what theories AI scientists learn and quantify their agreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI Scientists, trained on standard problems in physics, aggregating training results across many seeds simulating the different configurations of AI scientists.","Our findings suggests for AI scientists switch from learning a Hamiltonian theory in simple setups to a Lagrangian formulation when more complex systems are introduced.","We also observe strong seed dependence of the training dynamics and final learned weights, controlling the rise and fall of relevant theories.","We finally demonstrate that not only can our neural networks aid interpretability, it can also be applied to higher dimensional problems."],"url":"http://arxiv.org/abs/2504.02822v1"}
{"created":"2025-04-03 17:58:35","title":"Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models","abstract":"Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs). In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations. Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model. These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs.","sentences":["Sparse Autoencoders (SAEs) have recently been shown to enhance interpretability and steerability in Large Language Models (LLMs).","In this work, we extend the application of SAEs to Vision-Language Models (VLMs), such as CLIP, and introduce a comprehensive framework for evaluating monosemanticity in vision representations.","Our experimental results reveal that SAEs trained on VLMs significantly enhance the monosemanticity of individual neurons while also exhibiting hierarchical representations that align well with expert-defined structures (e.g., iNaturalist taxonomy).","Most notably, we demonstrate that applying SAEs to intervene on a CLIP vision encoder, directly steer output from multimodal LLMs (e.g., LLaVA) without any modifications to the underlying model.","These findings emphasize the practicality and efficacy of SAEs as an unsupervised approach for enhancing both the interpretability and control of VLMs."],"url":"http://arxiv.org/abs/2504.02821v1"}
{"created":"2025-04-03 17:58:18","title":"GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings","abstract":"Symmetry, where certain features remain invariant under geometric transformations, can often serve as a powerful prior in designing convolutional neural networks (CNNs). While conventional CNNs inherently support translational equivariance, extending this property to rotation and reflection has proven challenging, often forcing a compromise between equivariance, efficiency, and information loss. In this work, we introduce Gaussian Mixture Ring Convolution (GMR-Conv), an efficient convolution kernel that smooths radial symmetry using a mixture of Gaussian-weighted rings. This design mitigates discretization errors of circular kernels, thereby preserving robust rotation and reflection equivariance without incurring computational overhead. We further optimize both the space and speed efficiency of GMR-Conv via a novel parameterization and computation strategy, allowing larger kernels at an acceptable cost. Extensive experiments on eight classification and one segmentation datasets demonstrate that GMR-Conv not only matches conventional CNNs' performance but can also surpass it in applications with orientation-less data. GMR-Conv is also proven to be more robust and efficient than the state-of-the-art equivariant learning methods. Our work provides inspiring empirical evidence that carefully applied radial symmetry can alleviate the challenges of information loss, marking a promising advance in equivariant network architectures. The code is available at https://github.com/XYPB/GMR-Conv.","sentences":["Symmetry, where certain features remain invariant under geometric transformations, can often serve as a powerful prior in designing convolutional neural networks (CNNs).","While conventional CNNs inherently support translational equivariance, extending this property to rotation and reflection has proven challenging, often forcing a compromise between equivariance, efficiency, and information loss.","In this work, we introduce Gaussian Mixture Ring Convolution (GMR-Conv), an efficient convolution kernel that smooths radial symmetry using a mixture of Gaussian-weighted rings.","This design mitigates discretization errors of circular kernels, thereby preserving robust rotation and reflection equivariance without incurring computational overhead.","We further optimize both the space and speed efficiency of GMR-Conv via a novel parameterization and computation strategy, allowing larger kernels at an acceptable cost.","Extensive experiments on eight classification and one segmentation datasets demonstrate that GMR-Conv not only matches conventional CNNs' performance but can also surpass it in applications with orientation-less data.","GMR-Conv is also proven to be more robust and efficient than the state-of-the-art equivariant learning methods.","Our work provides inspiring empirical evidence that carefully applied radial symmetry can alleviate the challenges of information loss, marking a promising advance in equivariant network architectures.","The code is available at https://github.com/XYPB/GMR-Conv."],"url":"http://arxiv.org/abs/2504.02819v1"}
{"created":"2025-04-03 17:57:52","title":"Efficient Autoregressive Shape Generation via Octree-Based Adaptive Tokenization","abstract":"Many 3D generative models rely on variational autoencoders (VAEs) to learn compact shape representations. However, existing methods encode all shapes into a fixed-size token, disregarding the inherent variations in scale and complexity across 3D data. This leads to inefficient latent representations that can compromise downstream generation. We address this challenge by introducing Octree-based Adaptive Tokenization, a novel framework that adjusts the dimension of latent representations according to shape complexity. Our approach constructs an adaptive octree structure guided by a quadric-error-based subdivision criterion and allocates a shape latent vector to each octree cell using a query-based transformer. Building upon this tokenization, we develop an octree-based autoregressive generative model that effectively leverages these variable-sized representations in shape generation. Extensive experiments demonstrate that our approach reduces token counts by 50% compared to fixed-size methods while maintaining comparable visual quality. When using a similar token length, our method produces significantly higher-quality shapes. When incorporated with our downstream generative model, our method creates more detailed and diverse 3D content than existing approaches.","sentences":["Many 3D generative models rely on variational autoencoders (VAEs) to learn compact shape representations.","However, existing methods encode all shapes into a fixed-size token, disregarding the inherent variations in scale and complexity across 3D data.","This leads to inefficient latent representations that can compromise downstream generation.","We address this challenge by introducing Octree-based Adaptive Tokenization, a novel framework that adjusts the dimension of latent representations according to shape complexity.","Our approach constructs an adaptive octree structure guided by a quadric-error-based subdivision criterion and allocates a shape latent vector to each octree cell using a query-based transformer.","Building upon this tokenization, we develop an octree-based autoregressive generative model that effectively leverages these variable-sized representations in shape generation.","Extensive experiments demonstrate that our approach reduces token counts by 50% compared to fixed-size methods while maintaining comparable visual quality.","When using a similar token length, our method produces significantly higher-quality shapes.","When incorporated with our downstream generative model, our method creates more detailed and diverse 3D content than existing approaches."],"url":"http://arxiv.org/abs/2504.02817v1"}
{"created":"2025-04-03 17:55:19","title":"BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation","abstract":"We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios. First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos. Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input. Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios. BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks. Participants competed on seven challenge tracks, each defined by a task, object onboarding setup, and dataset group. Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image). A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 25X faster and 13% more accurate than GenFlow. Methods have a similar ranking on 6D detection as on 6D localization but higher run time. On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21% relative improvement compared to the best 2023 method (CNOS). However, the 2D detection accuracy for unseen objects is still noticealy (-53%) behind the accuracy for seen objects (GDet2023). The online evaluation system stays open and is available at http://bop.felk.cvut.cz/","sentences":["We present the evaluation methodology, datasets and results of the BOP Challenge 2024, the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks.","In 2024, our goal was to transition BOP from lab-like setups to real-world scenarios.","First, we introduced new model-free tasks, where no 3D object models are available and methods need to onboard objects just from provided reference videos.","Second, we defined a new, more practical 6D object detection task where identities of objects visible in a test image are not provided as input.","Third, we introduced new BOP-H3 datasets recorded with high-resolution sensors and AR/VR headsets, closely resembling real-world scenarios.","BOP-H3 include 3D models and onboarding videos to support both model-based and model-free tasks.","Participants competed on seven challenge tracks, each defined by a task, object onboarding setup, and dataset group.","Notably, the best 2024 method for model-based 6D localization of unseen objects (FreeZeV2.1) achieves 22% higher accuracy on BOP-Classic-Core than the best 2023 method (GenFlow), and is only 4% behind the best 2023 method for seen objects (GPose2023) although being significantly slower (24.9 vs 2.7s per image).","A more practical 2024 method for this task is Co-op which takes only 0.8s per image and is 25X faster and 13% more accurate than GenFlow.","Methods have a similar ranking on 6D detection as on 6D localization but higher run time.","On model-based 2D detection of unseen objects, the best 2024 method (MUSE) achieves 21% relative improvement compared to the best 2023 method (CNOS).","However, the 2D detection accuracy for unseen objects is still noticealy (-53%) behind the accuracy for seen objects (GDet2023).","The online evaluation system stays open and is available at http://bop.felk.cvut.cz/"],"url":"http://arxiv.org/abs/2504.02812v1"}
{"created":"2025-04-03 17:55:12","title":"An Assessment of the CO2 Emission Reduction Potential of Residential Load Management in Developing and Developed Countries","abstract":"Intermittent renewable energies are increasingly dominating electricity grids and are forecasted to be the main force driving out fossil fuels from the grid in most major economies until 2040. However, grids based on intermittent renewables are challenged by diurnal and seasonal mismatch between supply of sun and wind and demand for electricity, including for heat pumps and electric two and four wheelers. Load management and demand response measures promise to adjust for this mismatch, utilizing information- and price-based approaches to steer demand towards times with high supply of intermittent renewables. Here, we systematically review the literature estimating CO2 savings from residential load management in developing and developed nations. We find that load management holds high potential, locally differentiated with energy mix (including the respective share of renewables and fossils), climate zone, and the regulatory environment and price mechanism. Most identified studies suggest a mitigation potential between 1 and 20%. Load management becomes more relevant with higher shares of intermittent renewables, and when electricity prices are high. Importantly, load management aligns consumers' financial incentives with climate change mitigation, thus rendering accompanying strategies politically feasible. We summarize key regulatory steps to facilitate load management in economies and to realize relevant consumer surplus and mitigation potential.","sentences":["Intermittent renewable energies are increasingly dominating electricity grids and are forecasted to be the main force driving out fossil fuels from the grid in most major economies until 2040.","However, grids based on intermittent renewables are challenged by diurnal and seasonal mismatch between supply of sun and wind and demand for electricity, including for heat pumps and electric two and four wheelers.","Load management and demand response measures promise to adjust for this mismatch, utilizing information- and price-based approaches to steer demand towards times with high supply of intermittent renewables.","Here, we systematically review the literature estimating CO2 savings from residential load management in developing and developed nations.","We find that load management holds high potential, locally differentiated with energy mix (including the respective share of renewables and fossils), climate zone, and the regulatory environment and price mechanism.","Most identified studies suggest a mitigation potential between 1 and 20%.","Load management becomes more relevant with higher shares of intermittent renewables, and when electricity prices are high.","Importantly, load management aligns consumers' financial incentives with climate change mitigation, thus rendering accompanying strategies politically feasible.","We summarize key regulatory steps to facilitate load management in economies and to realize relevant consumer surplus and mitigation potential."],"url":"http://arxiv.org/abs/2504.02811v1"}
{"created":"2025-04-03 17:54:18","title":"Generative Evaluation of Complex Reasoning in Large Language Models","abstract":"With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets? Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments. To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs. KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty. Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization. We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students. Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges. Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities.","sentences":["With powerful large language models (LLMs) demonstrating superhuman reasoning capabilities, a critical question arises: Do LLMs genuinely reason, or do they merely recall answers from their extensive, web-scraped training datasets?","Publicly released benchmarks inevitably become contaminated once incorporated into subsequent LLM training sets, undermining their reliability as faithful assessments.","To address this, we introduce KUMO, a generative evaluation framework designed specifically for assessing reasoning in LLMs.","KUMO synergistically combines LLMs with symbolic engines to dynamically produce diverse, multi-turn reasoning tasks that are partially observable and adjustable in difficulty.","Through an automated pipeline, KUMO continuously generates novel tasks across open-ended domains, compelling models to demonstrate genuine generalization rather than memorization.","We evaluated 23 state-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO, benchmarking their reasoning abilities against university students.","Our findings reveal that many LLMs have outperformed university-level performance on easy reasoning tasks, and reasoning-scaled LLMs reach university-level performance on complex reasoning challenges.","Moreover, LLM performance on KUMO tasks correlates strongly with results on newly released real-world reasoning benchmarks, underscoring KUMO's value as a robust, enduring assessment tool for genuine LLM reasoning capabilities."],"url":"http://arxiv.org/abs/2504.02810v1"}
{"created":"2025-04-03 17:52:07","title":"MegaMath: Pushing the Limits of Open Math Corpora","abstract":"Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs). However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training. We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet. (2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity. (3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data. By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets.","sentences":["Mathematical reasoning is a cornerstone of human intelligence and a key benchmark for advanced capabilities in large language models (LLMs).","However, the research community still lacks an open, large-scale, high-quality corpus tailored to the demands of math-centric LLM pre-training.","We present MegaMath, an open dataset curated from diverse, math-focused sources through following practices: (1) Revisiting web data: We re-extracted mathematical documents from Common Crawl with math-oriented HTML optimizations, fasttext-based filtering and deduplication, all for acquiring higher-quality data on the Internet.","(2) Recalling Math-related code data: We identified high quality math-related code from large code training corpus, Stack-V2, further enhancing data diversity.","(3) Exploring Synthetic data: We synthesized QA-style text, math-related code, and interleaved text-code blocks from web data or code data.","By integrating these strategies and validating their effectiveness through extensive ablations, MegaMath delivers 371B tokens with the largest quantity and top quality among existing open math pre-training datasets."],"url":"http://arxiv.org/abs/2504.02807v1"}
{"created":"2025-04-03 17:47:06","title":"F-ViTA: Foundation Model Guided Visible to Thermal Translation","abstract":"Thermal imaging is crucial for scene understanding, particularly in low-light and nighttime conditions. However, collecting large thermal datasets is costly and labor-intensive due to the specialized equipment required for infrared image capture. To address this challenge, researchers have explored visible-to-thermal image translation. Most existing methods rely on Generative Adversarial Networks (GANs) or Diffusion Models (DMs), treating the task as a style transfer problem. As a result, these approaches attempt to learn both the modality distribution shift and underlying physical principles from limited training data. In this paper, we propose F-ViTA, a novel approach that leverages the general world knowledge embedded in foundation models to guide the diffusion process for improved translation. Specifically, we condition an InstructPix2Pix Diffusion Model with zero-shot masks and labels from foundation models such as SAM and Grounded DINO. This allows the model to learn meaningful correlations between scene objects and their thermal signatures in infrared imagery. Extensive experiments on five public datasets demonstrate that F-ViTA outperforms state-of-the-art (SOTA) methods. Furthermore, our model generalizes well to out-of-distribution (OOD) scenarios and can generate Long-Wave Infrared (LWIR), Mid-Wave Infrared (MWIR), and Near-Infrared (NIR) translations from the same visible image. Code: https://github.com/JayParanjape/F-ViTA/tree/master.","sentences":["Thermal imaging is crucial for scene understanding, particularly in low-light and nighttime conditions.","However, collecting large thermal datasets is costly and labor-intensive due to the specialized equipment required for infrared image capture.","To address this challenge, researchers have explored visible-to-thermal image translation.","Most existing methods rely on Generative Adversarial Networks (GANs) or Diffusion Models (DMs), treating the task as a style transfer problem.","As a result, these approaches attempt to learn both the modality distribution shift and underlying physical principles from limited training data.","In this paper, we propose F-ViTA, a novel approach that leverages the general world knowledge embedded in foundation models to guide the diffusion process for improved translation.","Specifically, we condition an InstructPix2Pix Diffusion Model with zero-shot masks and labels from foundation models such as SAM and Grounded DINO.","This allows the model to learn meaningful correlations between scene objects and their thermal signatures in infrared imagery.","Extensive experiments on five public datasets demonstrate that F-ViTA outperforms state-of-the-art (SOTA) methods.","Furthermore, our model generalizes well to out-of-distribution (OOD) scenarios and can generate Long-Wave Infrared (LWIR), Mid-Wave Infrared (MWIR), and Near-Infrared (NIR) translations from the same visible image.","Code: https://github.com/JayParanjape/F-ViTA/tree/master."],"url":"http://arxiv.org/abs/2504.02801v1"}
{"created":"2025-04-03 17:43:14","title":"A Survey of Large Language Models in Mental Health Disorder Detection on Social Media","abstract":"The detection and intervention of mental health issues represent a critical global research focus, and social media data has been recognized as an important resource for mental health research. However, how to utilize Large Language Models (LLMs) for mental health problem detection on social media poses significant challenges. Hence, this paper aims to explore the potential of LLM applications in social media data analysis, focusing not only on the most common psychological disorders such as depression and anxiety but also incorporating psychotic disorders and externalizing disorders, summarizing the application methods of LLM from different dimensions, such as text data analysis and detection of mental disorders, and revealing the major challenges and shortcomings of current research. In addition, the paper provides an overview of popular datasets, and evaluation metrics. The survey in this paper provides a comprehensive frame of reference for researchers in the field of mental health, while demonstrating the great potential of LLMs in mental health detection to facilitate the further application of LLMs in future mental health interventions.","sentences":["The detection and intervention of mental health issues represent a critical global research focus, and social media data has been recognized as an important resource for mental health research.","However, how to utilize Large Language Models (LLMs) for mental health problem detection on social media poses significant challenges.","Hence, this paper aims to explore the potential of LLM applications in social media data analysis, focusing not only on the most common psychological disorders such as depression and anxiety but also incorporating psychotic disorders and externalizing disorders, summarizing the application methods of LLM from different dimensions, such as text data analysis and detection of mental disorders, and revealing the major challenges and shortcomings of current research.","In addition, the paper provides an overview of popular datasets, and evaluation metrics.","The survey in this paper provides a comprehensive frame of reference for researchers in the field of mental health, while demonstrating the great potential of LLMs in mental health detection to facilitate the further application of LLMs in future mental health interventions."],"url":"http://arxiv.org/abs/2504.02800v1"}
{"created":"2025-04-03 17:42:56","title":"Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence","abstract":"Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training. This flexibility holds particular promise across medicine, where expert-annotated data is scarce. Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain. Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures. In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting. In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength. Still, tasks requiring spatial or temporal reasoning remained difficult. Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications.","sentences":["Large Vision-Language Models offer a new paradigm for AI-driven image understanding, enabling models to perform tasks without task-specific training.","This flexibility holds particular promise across medicine, where expert-annotated data is scarce.","Yet, VLMs' practical utility in intervention-focused domains--especially surgery, where decision-making is subjective and clinical scenarios are variable--remains uncertain.","Here, we present a comprehensive analysis of 11 state-of-the-art VLMs across 17 key visual understanding tasks in surgical AI--from anatomy recognition to skill assessment--using 13 datasets spanning laparoscopic, robotic, and open procedures.","In our experiments, VLMs demonstrate promising generalizability, at times outperforming supervised models when deployed outside their training setting.","In-context learning, incorporating examples during testing, boosted performance up to three-fold, suggesting adaptability as a key strength.","Still, tasks requiring spatial or temporal reasoning remained difficult.","Beyond surgery, our findings offer insights into VLMs' potential for tackling complex and dynamic scenarios in clinical and broader real-world applications."],"url":"http://arxiv.org/abs/2504.02799v1"}
{"created":"2025-04-03 17:42:07","title":"Spline-based Transformers","abstract":"We introduce Spline-based Transformers, a novel class of Transformer models that eliminate the need for positional encoding. Inspired by workflows using splines in computer animation, our Spline-based Transformers embed an input sequence of elements as a smooth trajectory in latent space. Overcoming drawbacks of positional encoding such as sequence length extrapolation, Spline-based Transformers also provide a novel way for users to interact with transformer latent spaces by directly manipulating the latent control points to create new latent trajectories and sequences. We demonstrate the superior performance of our approach in comparison to conventional positional encoding on a variety of datasets, ranging from synthetic 2D to large-scale real-world datasets of images, 3D shapes, and animations.","sentences":["We introduce Spline-based Transformers, a novel class of Transformer models that eliminate the need for positional encoding.","Inspired by workflows using splines in computer animation, our Spline-based Transformers embed an input sequence of elements as a smooth trajectory in latent space.","Overcoming drawbacks of positional encoding such as sequence length extrapolation, Spline-based Transformers also provide a novel way for users to interact with transformer latent spaces by directly manipulating the latent control points to create new latent trajectories and sequences.","We demonstrate the superior performance of our approach in comparison to conventional positional encoding on a variety of datasets, ranging from synthetic 2D to large-scale real-world datasets of images, 3D shapes, and animations."],"url":"http://arxiv.org/abs/2504.02797v1"}
{"created":"2025-04-03 17:40:49","title":"MENA: Multimodal Epistemic Network Analysis for Visualizing Competencies and Emotions","abstract":"The need to improve geriatric care quality presents a challenge that requires insights from stakeholders. While simulated trainings can boost competencies, extracting meaningful insights from these practices to enhance simulation effectiveness remains a challenge. In this study, we introduce Multimodal Epistemic Network Analysis (MENA), a novel framework for analyzing caregiver attitudes and emotions in an Augmented Reality setting and exploring how the awareness of a virtual geriatric patient (VGP) impacts these aspects. MENA enhances the capabilities of Epistemic Network Analysis by detecting positive emotions, enabling visualization and analysis of complex relationships between caregiving competencies and emotions in dynamic caregiving practices. The framework provides visual representations that demonstrate how participants provided more supportive care and engaged more effectively in person-centered caregiving with aware VGP. This method could be applicable in any setting that depends on dynamic interpersonal interactions, as it visualizes connections between key elements using network graphs and enables the direct comparison of multiple networks, thereby broadening its implications across various fields.","sentences":["The need to improve geriatric care quality presents a challenge that requires insights from stakeholders.","While simulated trainings can boost competencies, extracting meaningful insights from these practices to enhance simulation effectiveness remains a challenge.","In this study, we introduce Multimodal Epistemic Network Analysis (MENA), a novel framework for analyzing caregiver attitudes and emotions in an Augmented Reality setting and exploring how the awareness of a virtual geriatric patient (VGP) impacts these aspects.","MENA enhances the capabilities of Epistemic Network Analysis by detecting positive emotions, enabling visualization and analysis of complex relationships between caregiving competencies and emotions in dynamic caregiving practices.","The framework provides visual representations that demonstrate how participants provided more supportive care and engaged more effectively in person-centered caregiving with aware VGP.","This method could be applicable in any setting that depends on dynamic interpersonal interactions, as it visualizes connections between key elements using network graphs and enables the direct comparison of multiple networks, thereby broadening its implications across various fields."],"url":"http://arxiv.org/abs/2504.02794v1"}
{"created":"2025-04-03 17:40:11","title":"A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models","abstract":"Large artificial intelligence (AI) models have garnered significant attention for their remarkable, often \"superhuman\", performance on standardized benchmarks. However, when these models are deployed in high-stakes verticals such as healthcare, education, and law, they often reveal notable limitations. For instance, they exhibit brittleness to minor variations in input data, present contextually uninformed decisions in critical settings, and undermine user trust by confidently producing or reproducing inaccuracies. These challenges in applying large models necessitate cross-disciplinary innovations to align the models' capabilities with the needs of real-world applications. We introduce a framework that addresses this gap through a layer-wise abstraction of innovations aimed at meeting users' requirements with large models. Through multiple case studies, we illustrate how researchers and practitioners across various fields can operationalize this framework. Beyond modularizing the pipeline of transforming large models into useful \"vertical systems\", we also highlight the dynamism that exists within different layers of the framework. Finally, we discuss how our framework can guide researchers and practitioners to (i) optimally situate their innovations (e.g., when vertical-specific insights can empower broadly impactful vertical-agnostic innovations), (ii) uncover overlooked opportunities (e.g., spotting recurring problems across verticals to develop practically useful foundation models instead of chasing benchmarks), and (iii) facilitate cross-disciplinary communication of critical challenges (e.g., enabling a shared vocabulary for AI developers, domain experts, and human-computer interaction scholars).","sentences":["Large artificial intelligence (AI) models have garnered significant attention for their remarkable, often \"superhuman\", performance on standardized benchmarks.","However, when these models are deployed in high-stakes verticals such as healthcare, education, and law, they often reveal notable limitations.","For instance, they exhibit brittleness to minor variations in input data, present contextually uninformed decisions in critical settings, and undermine user trust by confidently producing or reproducing inaccuracies.","These challenges in applying large models necessitate cross-disciplinary innovations to align the models' capabilities with the needs of real-world applications.","We introduce a framework that addresses this gap through a layer-wise abstraction of innovations aimed at meeting users' requirements with large models.","Through multiple case studies, we illustrate how researchers and practitioners across various fields can operationalize this framework.","Beyond modularizing the pipeline of transforming large models into useful \"vertical systems\", we also highlight the dynamism that exists within different layers of the framework.","Finally, we discuss how our framework can guide researchers and practitioners to (i) optimally situate their innovations (e.g., when vertical-specific insights can empower broadly impactful vertical-agnostic innovations), (ii) uncover overlooked opportunities (e.g., spotting recurring problems across verticals to develop practically useful foundation models instead of chasing benchmarks), and (iii) facilitate cross-disciplinary communication of critical challenges (e.g., enabling a shared vocabulary for AI developers, domain experts, and human-computer interaction scholars)."],"url":"http://arxiv.org/abs/2504.02793v1"}
{"created":"2025-04-03 17:38:59","title":"Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets","abstract":"Imitation learning has emerged as a promising approach towards building generalist robots. However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations. Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available. This data provides a rich source of information about real-world dynamics and agent-environment interactions. Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods. In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning. Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality. We show that by simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator. Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies. Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling. Videos and code are available at https://weirdlabuw.github.io/uwm/.","sentences":["Imitation learning has emerged as a promising approach towards building generalist robots.","However, scaling imitation learning for large robot foundation models remains challenging due to its reliance on high-quality expert demonstrations.","Meanwhile, large amounts of video data depicting a wide range of environments and diverse behaviors are readily available.","This data provides a rich source of information about real-world dynamics and agent-environment interactions.","Leveraging this data directly for imitation learning, however, has proven difficult due to the lack of action annotation required for most contemporary methods.","In this work, we present Unified World Models (UWM), a framework that allows for leveraging both video and action data for policy learning.","Specifically, a UWM integrates an action diffusion process and a video diffusion process within a unified transformer architecture, where independent diffusion timesteps govern each modality.","We show that by simply controlling each diffusion timestep, UWM can flexibly represent a policy, a forward dynamics, an inverse dynamics, and a video generator.","Through simulated and real-world experiments, we show that: (1) UWM enables effective pretraining on large-scale multitask robot datasets with both dynamics and action predictions, resulting in more generalizable and robust policies than imitation learning, (2) UWM naturally facilitates learning from action-free video data through independent control of modality-specific diffusion timesteps, further improving the performance of finetuned policies.","Our results suggest that UWM offers a promising step toward harnessing large, heterogeneous datasets for scalable robot learning, and provides a simple unification between the often disparate paradigms of imitation learning and world modeling.","Videos and code are available at https://weirdlabuw.github.io/uwm/."],"url":"http://arxiv.org/abs/2504.02792v1"}
{"created":"2025-04-03 17:37:46","title":"Dynamic Treewidth in Logarithmic Time","abstract":"We present a dynamic data structure that maintains a tree decomposition of width at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is updated by edge insertions and deletions. The amortized update time of our data structure is $2^{O(k)} \\log n$, where $n$ is the number of vertices. The data structure also supports maintaining any ``dynamic programming scheme'' on the tree decomposition, providing, for example, a dynamic version of Courcelle's theorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation hides factors that depend on $k$. This improves upon a result of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\\l}owski [FOCS 2023], who gave a similar data structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$. Furthermore, our data structure is arguably simpler.   Our main novel idea is to maintain a tree decomposition that is ``downwards well-linked'', which allows us to implement local rotations and analysis similar to those for splay trees.","sentences":["We present a dynamic data structure that maintains a tree decomposition of width at most $9k+8$ of a dynamic graph with treewidth at most $k$, which is updated by edge insertions and deletions.","The amortized update time of our data structure is $2^{O(k)} \\log n$, where $n$ is the number of vertices.","The data structure also supports maintaining any ``dynamic programming scheme'' on the tree decomposition, providing, for example, a dynamic version of Courcelle's theorem with $O_{k}(\\log n)$ amortized update time; the $O_{k}(\\cdot)$ notation hides factors that depend on $k$. This improves upon a result of Korhonen, Majewski, Nadara, Pilipczuk, and Soko{\\l}owski","[FOCS 2023], who gave a similar data structure but with amortized update time $2^{k^{O(1)}} n^{o(1)}$.","Furthermore, our data structure is arguably simpler.   ","Our main novel idea is to maintain a tree decomposition that is ``downwards well-linked'', which allows us to implement local rotations and analysis similar to those for splay trees."],"url":"http://arxiv.org/abs/2504.02790v1"}
{"created":"2025-04-03 17:35:54","title":"A Framework for Robust Cognitive Evaluation of LLMs","abstract":"Emergent cognitive abilities in large language models (LLMs) have been widely observed, but their nature and underlying mechanisms remain poorly understood. A growing body of research draws on cognitive science to investigate LLM cognition, but standard methodologies and experimen-tal pipelines have not yet been established. To address this gap we develop CognitivEval, a framework for systematically evaluating the artificial cognitive capabilities of LLMs, with a particular emphasis on robustness in response collection. The key features of CognitivEval include: (i) automatic prompt permutations, and (ii) testing that gathers both generations and model probability estimates. Our experiments demonstrate that these features lead to more robust experimental outcomes. Using CognitivEval, we replicate five classic experiments in cognitive science, illustrating the framework's generalizability across various experimental tasks and obtaining a cognitive profile of several state of the art LLMs. CognitivEval will be released publicly to foster broader collaboration within the cognitive science community.","sentences":["Emergent cognitive abilities in large language models (LLMs) have been widely observed, but their nature and underlying mechanisms remain poorly understood.","A growing body of research draws on cognitive science to investigate LLM cognition, but standard methodologies and experimen-tal pipelines have not yet been established.","To address this gap we develop CognitivEval, a framework for systematically evaluating the artificial cognitive capabilities of LLMs, with a particular emphasis on robustness in response collection.","The key features of CognitivEval include: (i) automatic prompt permutations, and (ii) testing that gathers both generations and model probability estimates.","Our experiments demonstrate that these features lead to more robust experimental outcomes.","Using CognitivEval, we replicate five classic experiments in cognitive science, illustrating the framework's generalizability across various experimental tasks and obtaining a cognitive profile of several state of the art LLMs.","CognitivEval will be released publicly to foster broader collaboration within the cognitive science community."],"url":"http://arxiv.org/abs/2504.02789v1"}
{"created":"2025-04-03 17:23:16","title":"GPT-ImgEval: A Comprehensive Benchmark for Diagnosing GPT4o in Image Generation","abstract":"The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community. This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis. Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities. Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures. We also provide a complete speculation on GPT-4o's overall architecture. In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation. We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models. We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond. The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval.","sentences":["The recent breakthroughs in OpenAI's GPT4o model have demonstrated surprisingly good capabilities in image generation and editing, resulting in significant excitement in the community.","This technical report presents the first-look evaluation benchmark (named GPT-ImgEval), quantitatively and qualitatively diagnosing GPT-4o's performance across three critical dimensions: (1) generation quality, (2) editing proficiency, and (3) world knowledge-informed semantic synthesis.","Across all three tasks, GPT-4o demonstrates strong performance, significantly surpassing existing methods in both image generation control and output quality, while also showcasing exceptional knowledge reasoning capabilities.","Furthermore, based on the GPT-4o's generated data, we propose a classification-model-based approach to investigate the underlying architecture of GPT-4o, where our empirical results suggest the model consists of an auto-regressive (AR) combined with a diffusion-based head for image decoding, rather than the VAR-like architectures.","We also provide a complete speculation on GPT-4o's overall architecture.","In addition, we conduct a series of analyses to identify and visualize GPT-4o's specific limitations and the synthetic artifacts commonly observed in its image generation.","We also present a comparative study of multi-round image editing between GPT-4o and Gemini 2.0 Flash, and discuss the safety implications of GPT-4o's outputs, particularly their detectability by existing image forensic models.","We hope that our work can offer valuable insight and provide a reliable benchmark to guide future research, foster reproducibility, and accelerate innovation in the field of image generation and beyond.","The codes and datasets used for evaluating GPT-4o can be found at https://github.com/PicoTrex/GPT-ImgEval."],"url":"http://arxiv.org/abs/2504.02782v1"}
{"created":"2025-04-03 17:22:39","title":"Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations","abstract":"Optimization of radio hardware and AI-based network management software yield significant energy savings in radio access networks. The execution of underlying Machine Learning (ML) models, which enable energy savings through recommended actions, may require additional compute and energy, highlighting the opportunity to explore and adopt accurate and energy-efficient ML technologies. This work evaluates the novel use of sparsely structured Neural Circuit Policies (NCPs) in a use case to estimate the energy consumption of base stations. Sparsity in ML models yields reduced memory, computation and energy demand, hence facilitating a low-cost and scalable solution. We also evaluate the generalization capability of NCPs in comparison to traditional and widely used ML models such as Long Short Term Memory (LSTM), via quantifying their sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a clear reduction in computational overhead and energy consumption. Moreover, results indicated that the NCPs are robust to varying HPs such as number of epochs and neurons in each layer, making them a suitable option to ease model management and to reduce energy consumption in Machine Learning Operations (MLOps) in telecommunications.","sentences":["Optimization of radio hardware and AI-based network management software yield significant energy savings in radio access networks.","The execution of underlying Machine Learning (ML) models, which enable energy savings through recommended actions, may require additional compute and energy, highlighting the opportunity to explore and adopt accurate and energy-efficient ML technologies.","This work evaluates the novel use of sparsely structured Neural Circuit Policies (NCPs) in a use case to estimate the energy consumption of base stations.","Sparsity in ML models yields reduced memory, computation and energy demand, hence facilitating a low-cost and scalable solution.","We also evaluate the generalization capability of NCPs in comparison to traditional and widely used ML models such as Long Short Term Memory (LSTM), via quantifying their sensitivity to varying model hyper-parameters (HPs).","NCPs demonstrated a clear reduction in computational overhead and energy consumption.","Moreover, results indicated that the NCPs are robust to varying HPs such as number of epochs and neurons in each layer, making them a suitable option to ease model management and to reduce energy consumption in Machine Learning Operations (MLOps) in telecommunications."],"url":"http://arxiv.org/abs/2504.02781v1"}
{"created":"2025-04-03 17:20:36","title":"From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks","abstract":"The rise of Generative AI, and Large Language Models (LLMs) in particular, is fundamentally changing cognitive processes in knowledge work, raising critical questions about their impact on human reasoning and problem-solving capabilities. As these AI systems become increasingly integrated into workflows, they offer unprecedented opportunities for augmenting human thinking while simultaneously risking cognitive erosion through passive consumption of generated answers. This tension is particularly pronounced in open-ended tasks, where effective solutions require deep contextualization and integration of domain knowledge. Unlike structured tasks with established metrics, measuring the quality of human-LLM interaction in such open-ended tasks poses significant challenges due to the absence of ground truth and the iterative nature of solution development. To address this, we present a framework that analyzes interaction patterns along two dimensions: cognitive activity mode (exploration vs. exploitation) and cognitive engagement mode (constructive vs. detrimental). This framework provides systematic measurements to evaluate when LLMs are effective tools for thought rather than substitutes for human cognition, advancing theoretical understanding and practical guidance for developing AI systems that protect and augment human cognitive capabilities.","sentences":["The rise of Generative AI, and Large Language Models (LLMs) in particular, is fundamentally changing cognitive processes in knowledge work, raising critical questions about their impact on human reasoning and problem-solving capabilities.","As these AI systems become increasingly integrated into workflows, they offer unprecedented opportunities for augmenting human thinking while simultaneously risking cognitive erosion through passive consumption of generated answers.","This tension is particularly pronounced in open-ended tasks, where effective solutions require deep contextualization and integration of domain knowledge.","Unlike structured tasks with established metrics, measuring the quality of human-LLM interaction in such open-ended tasks poses significant challenges due to the absence of ground truth and the iterative nature of solution development.","To address this, we present a framework that analyzes interaction patterns along two dimensions: cognitive activity mode (exploration vs. exploitation) and cognitive engagement mode (constructive vs. detrimental).","This framework provides systematic measurements to evaluate when LLMs are effective tools for thought rather than substitutes for human cognition, advancing theoretical understanding and practical guidance for developing AI systems that protect and augment human cognitive capabilities."],"url":"http://arxiv.org/abs/2504.02780v1"}
{"created":"2025-04-03 17:19:52","title":"BT-ACTION: A Test-Driven Approach for Modular Understanding of User Instruction Leveraging Behaviour Trees and LLMs","abstract":"Natural language instructions are often abstract and complex, requiring robots to execute multiple subtasks even for seemingly simple queries. For example, when a user asks a robot to prepare avocado toast, the task involves several sequential steps. Moreover, such instructions can be ambiguous or infeasible for the robot or may exceed the robot's existing knowledge. While Large Language Models (LLMs) offer strong language reasoning capabilities to handle these challenges, effectively integrating them into robotic systems remains a key challenge. To address this, we propose BT-ACTION, a test-driven approach that combines the modular structure of Behavior Trees (BT) with LLMs to generate coherent sequences of robot actions for following complex user instructions, specifically in the context of preparing recipes in a kitchen-assistance setting. We evaluated BT-ACTION in a comprehensive user study with 45 participants, comparing its performance to direct LLM prompting. Results demonstrate that the modular design of BT-ACTION helped the robot make fewer mistakes and increased user trust, and participants showed a significant preference for the robot leveraging BT-ACTION. The code is publicly available at https://github.com/1Eggbert7/BT_LLM.","sentences":["Natural language instructions are often abstract and complex, requiring robots to execute multiple subtasks even for seemingly simple queries.","For example, when a user asks a robot to prepare avocado toast, the task involves several sequential steps.","Moreover, such instructions can be ambiguous or infeasible for the robot or may exceed the robot's existing knowledge.","While Large Language Models (LLMs) offer strong language reasoning capabilities to handle these challenges, effectively integrating them into robotic systems remains a key challenge.","To address this, we propose BT-ACTION, a test-driven approach that combines the modular structure of Behavior Trees (BT) with LLMs to generate coherent sequences of robot actions for following complex user instructions, specifically in the context of preparing recipes in a kitchen-assistance setting.","We evaluated BT-ACTION in a comprehensive user study with 45 participants, comparing its performance to direct LLM prompting.","Results demonstrate that the modular design of BT-ACTION helped the robot make fewer mistakes and increased user trust, and participants showed a significant preference for the robot leveraging BT-ACTION.","The code is publicly available at https://github.com/1Eggbert7/BT_LLM."],"url":"http://arxiv.org/abs/2504.02779v1"}
{"created":"2025-04-03 17:19:20","title":"Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition","abstract":"Human activity recognition is increasingly vital for supporting independent living, particularly for the elderly and those in need of assistance. Domestic service robots with monitoring capabilities can enhance safety and provide essential support. Although image-based methods have advanced considerably in the past decade, their adoption remains limited by concerns over privacy and sensitivity to low-light or dark conditions. As an alternative, millimetre-wave (mmWave) radar can produce point cloud data which is privacy-preserving. However, processing the sparse and noisy point clouds remains a long-standing challenge. While graph-based methods and attention mechanisms show promise, they predominantly rely on \"fixed\" kernels; kernels that are applied uniformly across all neighbourhoods, highlighting the need for adaptive approaches that can dynamically adjust their kernels to the specific geometry of each local neighbourhood in point cloud data. To overcome this limitation, we introduce an adaptive approach within the graph convolutional framework. Instead of a single shared weight function, our Multi-Head Adaptive Kernel (MAK) module generates multiple dynamic kernels, each capturing different aspects of the local feature space. By progressively refining local features while maintaining global spatial context, our method enables convolution kernels to adapt to varying local features. Experimental results on benchmark datasets confirm the effectiveness of our approach, achieving state-of-the-art performance in human activity recognition. Our source code is made publicly available at: https://github.com/Gbouna/MAK-GCN","sentences":["Human activity recognition is increasingly vital for supporting independent living, particularly for the elderly and those in need of assistance.","Domestic service robots with monitoring capabilities can enhance safety and provide essential support.","Although image-based methods have advanced considerably in the past decade, their adoption remains limited by concerns over privacy and sensitivity to low-light or dark conditions.","As an alternative, millimetre-wave (mmWave) radar can produce point cloud data which is privacy-preserving.","However, processing the sparse and noisy point clouds remains a long-standing challenge.","While graph-based methods and attention mechanisms show promise, they predominantly rely on \"fixed\" kernels; kernels that are applied uniformly across all neighbourhoods, highlighting the need for adaptive approaches that can dynamically adjust their kernels to the specific geometry of each local neighbourhood in point cloud data.","To overcome this limitation, we introduce an adaptive approach within the graph convolutional framework.","Instead of a single shared weight function, our Multi-Head Adaptive Kernel (MAK) module generates multiple dynamic kernels, each capturing different aspects of the local feature space.","By progressively refining local features while maintaining global spatial context, our method enables convolution kernels to adapt to varying local features.","Experimental results on benchmark datasets confirm the effectiveness of our approach, achieving state-of-the-art performance in human activity recognition.","Our source code is made publicly available at: https://github.com/Gbouna/MAK-GCN"],"url":"http://arxiv.org/abs/2504.02778v1"}
{"created":"2025-04-03 17:14:57","title":"TailedCore: Few-Shot Sampling for Unsupervised Long-Tail Noisy Anomaly Detection","abstract":"We aim to solve unsupervised anomaly detection in a practical challenging environment where the normal dataset is both contaminated with defective regions and its product class distribution is tailed but unknown. We observe that existing models suffer from tail-versus-noise trade-off where if a model is robust against pixel noise, then its performance deteriorates on tail class samples, and vice versa. To mitigate the issue, we handle the tail class and noise samples independently. To this end, we propose TailSampler, a novel class size predictor that estimates the class cardinality of samples based on a symmetric assumption on the class-wise distribution of embedding similarities. TailSampler can be utilized to sample the tail class samples exclusively, allowing to handle them separately. Based on these facets, we build a memory-based anomaly detection model TailedCore, whose memory both well captures tail class information and is noise-robust. We extensively validate the effectiveness of TailedCore on the unsupervised long-tail noisy anomaly detection setting, and show that TailedCore outperforms the state-of-the-art in most settings.","sentences":["We aim to solve unsupervised anomaly detection in a practical challenging environment where the normal dataset is both contaminated with defective regions and its product class distribution is tailed but unknown.","We observe that existing models suffer from tail-versus-noise trade-off where if a model is robust against pixel noise, then its performance deteriorates on tail class samples, and vice versa.","To mitigate the issue, we handle the tail class and noise samples independently.","To this end, we propose TailSampler, a novel class size predictor that estimates the class cardinality of samples based on a symmetric assumption on the class-wise distribution of embedding similarities.","TailSampler can be utilized to sample the tail class samples exclusively, allowing to handle them separately.","Based on these facets, we build a memory-based anomaly detection model TailedCore, whose memory both well captures tail class information and is noise-robust.","We extensively validate the effectiveness of TailedCore on the unsupervised long-tail noisy anomaly detection setting, and show that TailedCore outperforms the state-of-the-art in most settings."],"url":"http://arxiv.org/abs/2504.02775v1"}
{"created":"2025-04-03 17:06:39","title":"Efficient Algorithms for Cardinality Estimation and Conjunctive Query Evaluation With Simple Degree Constraints","abstract":"Cardinality estimation and conjunctive query evaluation are two of the most fundamental problems in database query processing. Recent work proposed, studied, and implemented a robust and practical information-theoretic cardinality estimation framework. In this framework, the estimator is the cardinality upper bound of a conjunctive query subject to ``degree-constraints'', which model a rich set of input data statistics. For general degree constraints, computing this bound is computationally hard. Researchers have naturally sought efficiently computable relaxed upper bounds that are as tight as possible. The polymatroid bound is the tightest among those relaxed upper bounds. While it is an open question whether the polymatroid bound can be computed in polynomial-time in general, it is known to be computable in polynomial-time for some classes of degree constraints.   Our focus is on a common class of degree constraints called simple degree constraints. Researchers had not previously determined how to compute the polymatroid bound in polynomial time for this class of constraints. Our first main result is a polynomial time algorithm to compute the polymatroid bound given simple degree constraints. Our second main result is a polynomial-time algorithm to compute a ``proof sequence'' establishing this bound. This proof sequence can then be incorporated in the PANDA-framework to give a faster algorithm to evaluate a conjunctive query. In addition, we show computational limitations to extending our results to broader classes of degree constraints. Finally, our technique leads naturally to a new relaxed upper bound called the {\\em flow bound}, which is computationally tractable.","sentences":["Cardinality estimation and conjunctive query evaluation are two of the most fundamental problems in database query processing.","Recent work proposed, studied, and implemented a robust and practical information-theoretic cardinality estimation framework.","In this framework, the estimator is the cardinality upper bound of a conjunctive query subject to ``degree-constraints'', which model a rich set of input data statistics.","For general degree constraints, computing this bound is computationally hard.","Researchers have naturally sought efficiently computable relaxed upper bounds that are as tight as possible.","The polymatroid bound is the tightest among those relaxed upper bounds.","While it is an open question whether the polymatroid bound can be computed in polynomial-time in general, it is known to be computable in polynomial-time for some classes of degree constraints.   ","Our focus is on a common class of degree constraints called simple degree constraints.","Researchers had not previously determined how to compute the polymatroid bound in polynomial time for this class of constraints.","Our first main result is a polynomial time algorithm to compute the polymatroid bound given simple degree constraints.","Our second main result is a polynomial-time algorithm to compute a ``proof sequence'' establishing this bound.","This proof sequence can then be incorporated in the PANDA-framework to give a faster algorithm to evaluate a conjunctive query.","In addition, we show computational limitations to extending our results to broader classes of degree constraints.","Finally, our technique leads naturally to a new relaxed upper bound called the {\\em flow bound}, which is computationally tractable."],"url":"http://arxiv.org/abs/2504.02770v1"}
{"created":"2025-04-03 17:06:25","title":"Curbing the Ramifications of Authorship Abuse in Science","abstract":"Research performance is often measured using bibliometric indicators, such as publication count, total citations, and $h$-index. These metrics influence career advancements, salary adjustments, administrative opportunities, funding prospects, and professional recognition. However, the reliance on these metrics has also made them targets for manipulation, misuse, and abuse. One primary ethical concern is authorship abuse, which includes paid, ornamental, exploitative, and cartel authorships. These practices are prevalent because they artificially enhance multiple bibliometric indicators all at once. Our study confirms a significant rise in the mean and median number of authors per publication across multiple disciplines over the last 34 years. While it is important to identify the cases of authorship abuse, a thorough investigation of every paper proves impractical. In this study, we propose a credit allocation scheme based on the reciprocals of the Fibonacci numbers, designed to adjust credit for individual contributions while systematically reducing credit for potential authorship abuse. The proposed scheme aligns with rigorous authorship guidelines from scientific associations, which mandate significant contributions across most phases of a study, while accommodating more lenient guidelines from scientific publishers, which recognize authorship for minimal contributions. We recalibrate the traditional bibliometric indicators to emphasize author contribution rather than participation in publications. Additionally, we propose a new indicator, $T^{\\prime}$-index, to assess researchers' leading and contributing roles in their publications. Our proposed credit allocation scheme mitigates the effects of authorship abuse and promotes a more ethical scientific ecosystem.","sentences":["Research performance is often measured using bibliometric indicators, such as publication count, total citations, and $h$-index.","These metrics influence career advancements, salary adjustments, administrative opportunities, funding prospects, and professional recognition.","However, the reliance on these metrics has also made them targets for manipulation, misuse, and abuse.","One primary ethical concern is authorship abuse, which includes paid, ornamental, exploitative, and cartel authorships.","These practices are prevalent because they artificially enhance multiple bibliometric indicators all at once.","Our study confirms a significant rise in the mean and median number of authors per publication across multiple disciplines over the last 34 years.","While it is important to identify the cases of authorship abuse, a thorough investigation of every paper proves impractical.","In this study, we propose a credit allocation scheme based on the reciprocals of the Fibonacci numbers, designed to adjust credit for individual contributions while systematically reducing credit for potential authorship abuse.","The proposed scheme aligns with rigorous authorship guidelines from scientific associations, which mandate significant contributions across most phases of a study, while accommodating more lenient guidelines from scientific publishers, which recognize authorship for minimal contributions.","We recalibrate the traditional bibliometric indicators to emphasize author contribution rather than participation in publications.","Additionally, we propose a new indicator, $T^{\\prime}$-index, to assess researchers' leading and contributing roles in their publications.","Our proposed credit allocation scheme mitigates the effects of authorship abuse and promotes a more ethical scientific ecosystem."],"url":"http://arxiv.org/abs/2504.02769v1"}
{"created":"2025-04-03 17:05:50","title":"MultiBLiMP 1.0: A Massively Multilingual Benchmark of Linguistic Minimal Pairs","abstract":"We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic minimal pairs, covering 101 languages, 6 linguistic phenomena and containing more than 125,000 minimal pairs. Our minimal pairs are created using a fully automated pipeline, leveraging the large-scale linguistic resources of Universal Dependencies and UniMorph. MultiBLiMP 1.0 evaluates abilities of LLMs at an unprecedented multilingual scale, and highlights the shortcomings of the current state-of-the-art in modelling low-resource languages.","sentences":["We introduce MultiBLiMP 1.0, a massively multilingual benchmark of linguistic minimal pairs, covering 101 languages, 6 linguistic phenomena and containing more than 125,000 minimal pairs.","Our minimal pairs are created using a fully automated pipeline, leveraging the large-scale linguistic resources of Universal Dependencies and UniMorph.","MultiBLiMP 1.0 evaluates abilities of LLMs at an unprecedented multilingual scale, and highlights the shortcomings of the current state-of-the-art in modelling low-resource languages."],"url":"http://arxiv.org/abs/2504.02768v1"}
{"created":"2025-04-03 17:04:56","title":"How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?","abstract":"The spread of scientific knowledge depends on how researchers discover and cite previous work. The adoption of large language models (LLMs) in the scientific research process introduces a new layer to these citation practices. However, it remains unclear to what extent LLMs align with human citation practices, how they perform across domains, and may influence citation dynamics. Here, we show that LLMs systematically reinforce the Matthew effect in citations by consistently favoring highly cited papers when generating references. This pattern persists across scientific domains despite significant field-specific variations in existence rates, which refer to the proportion of generated references that match existing records in external bibliometric databases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers, we find that LLM recommendations diverge from traditional citation patterns by preferring more recent references with shorter titles and fewer authors. Emphasizing their content-level relevance, the generated references are semantically aligned with the content of each paper at levels comparable to the ground truth references and display similar network effects while reducing author self-citations. These findings illustrate how LLMs may reshape citation practices and influence the trajectory of scientific discovery by reflecting and amplifying established trends. As LLMs become more integrated into the scientific research process, it is important to understand their role in shaping how scientific communities discover and build upon prior work.","sentences":["The spread of scientific knowledge depends on how researchers discover and cite previous work.","The adoption of large language models (LLMs) in the scientific research process introduces a new layer to these citation practices.","However, it remains unclear to what extent LLMs align with human citation practices, how they perform across domains, and may influence citation dynamics.","Here, we show that LLMs systematically reinforce the Matthew effect in citations by consistently favoring highly cited papers when generating references.","This pattern persists across scientific domains despite significant field-specific variations in existence rates, which refer to the proportion of generated references that match existing records in external bibliometric databases.","Analyzing 274,951 references generated by GPT-4o for 10,000 papers, we find that LLM recommendations diverge from traditional citation patterns by preferring more recent references with shorter titles and fewer authors.","Emphasizing their content-level relevance, the generated references are semantically aligned with the content of each paper at levels comparable to the ground truth references and display similar network effects while reducing author self-citations.","These findings illustrate how LLMs may reshape citation practices and influence the trajectory of scientific discovery by reflecting and amplifying established trends.","As LLMs become more integrated into the scientific research process, it is important to understand their role in shaping how scientific communities discover and build upon prior work."],"url":"http://arxiv.org/abs/2504.02767v1"}
{"created":"2025-04-03 17:02:09","title":"Robot-Led Vision Language Model Wellbeing Assessment of Children","abstract":"This study presents a novel robot-led approach to assessing children's mental wellbeing using a Vision Language Model (VLM). Inspired by the Child Apperception Test (CAT), the social robot NAO presented children with pictorial stimuli to elicit their verbal narratives of the images, which were then evaluated by a VLM in accordance with CAT assessment guidelines. The VLM's assessments were systematically compared to those provided by a trained psychologist. The results reveal that while the VLM demonstrates moderate reliability in identifying cases with no wellbeing concerns, its ability to accurately classify assessments with clinical concern remains limited. Moreover, although the model's performance was generally consistent when prompted with varying demographic factors such as age and gender, a significantly higher false positive rate was observed for girls, indicating potential sensitivity to gender attribute. These findings highlight both the promise and the challenges of integrating VLMs into robot-led assessments of children's wellbeing.","sentences":["This study presents a novel robot-led approach to assessing children's mental wellbeing using a Vision Language Model (VLM).","Inspired by the Child Apperception Test (CAT), the social robot NAO presented children with pictorial stimuli to elicit their verbal narratives of the images, which were then evaluated by a VLM in accordance with CAT assessment guidelines.","The VLM's assessments were systematically compared to those provided by a trained psychologist.","The results reveal that while the VLM demonstrates moderate reliability in identifying cases with no wellbeing concerns, its ability to accurately classify assessments with clinical concern remains limited.","Moreover, although the model's performance was generally consistent when prompted with varying demographic factors such as age and gender, a significantly higher false positive rate was observed for girls, indicating potential sensitivity to gender attribute.","These findings highlight both the promise and the challenges of integrating VLMs into robot-led assessments of children's wellbeing."],"url":"http://arxiv.org/abs/2504.02765v1"}
{"created":"2025-04-03 17:00:44","title":"Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model","abstract":"In this paper, we propose Scene Splatter, a momentum-based paradigm for video diffusion to generate generic scenes from single image. Existing methods, which employ video generation models to synthesize novel views, suffer from limited video length and scene inconsistency, leading to artifacts and distortions during further reconstruction. To address this issue, we construct noisy samples from original features as momentum to enhance video details and maintain scene consistency. However, for latent features with the perception field that spans both known and unknown regions, such latent-level momentum restricts the generative ability of video diffusion in unknown regions. Therefore, we further introduce the aforementioned consistent video as a pixel-level momentum to a directly generated video without momentum for better recovery of unseen regions. Our cascaded momentum enables video diffusion models to generate both high-fidelity and consistent novel views. We further finetune the global Gaussian representations with enhanced frames and render new frames for momentum update in the next step. In this manner, we can iteratively recover a 3D scene, avoiding the limitation of video length. Extensive experiments demonstrate the generalization capability and superior performance of our method in high-fidelity and consistent scene generation.","sentences":["In this paper, we propose Scene Splatter, a momentum-based paradigm for video diffusion to generate generic scenes from single image.","Existing methods, which employ video generation models to synthesize novel views, suffer from limited video length and scene inconsistency, leading to artifacts and distortions during further reconstruction.","To address this issue, we construct noisy samples from original features as momentum to enhance video details and maintain scene consistency.","However, for latent features with the perception field that spans both known and unknown regions, such latent-level momentum restricts the generative ability of video diffusion in unknown regions.","Therefore, we further introduce the aforementioned consistent video as a pixel-level momentum to a directly generated video without momentum for better recovery of unseen regions.","Our cascaded momentum enables video diffusion models to generate both high-fidelity and consistent novel views.","We further finetune the global Gaussian representations with enhanced frames and render new frames for momentum update in the next step.","In this manner, we can iteratively recover a 3D scene, avoiding the limitation of video length.","Extensive experiments demonstrate the generalization capability and superior performance of our method in high-fidelity and consistent scene generation."],"url":"http://arxiv.org/abs/2504.02764v1"}
{"created":"2025-04-03 16:58:57","title":"CanonNet: Canonical Ordering and Curvature Learning for Point Cloud Analysis","abstract":"Point cloud processing poses two fundamental challenges: establishing consistent point ordering and effectively learning fine-grained geometric features. Current architectures rely on complex operations that limit expressivity while struggling to capture detailed surface geometry. We present CanonNet, a lightweight neural network composed of two complementary components: (1) a preprocessing pipeline that creates a canonical point ordering and orientation, and (2) a geometric learning framework where networks learn from synthetic surfaces with precise curvature values. This modular approach eliminates the need for complex transformation-invariant architectures while effectively capturing local geometric properties. Our experiments demonstrate state-of-the-art performance in curvature estimation and competitive results in geometric descriptor tasks with significantly fewer parameters (\\textbf{100X}) than comparable methods. CanonNet's efficiency makes it particularly suitable for real-world applications where computational resources are limited, demonstrating that mathematical preprocessing can effectively complement neural architectures for point cloud analysis. The code for the project is publicly available \\hyperlink{https://benjyfri.github.io/CanonNet/}{https://benjyfri.github.io/CanonNet/}.","sentences":["Point cloud processing poses two fundamental challenges: establishing consistent point ordering and effectively learning fine-grained geometric features.","Current architectures rely on complex operations that limit expressivity while struggling to capture detailed surface geometry.","We present CanonNet, a lightweight neural network composed of two complementary components: (1) a preprocessing pipeline that creates a canonical point ordering and orientation, and (2) a geometric learning framework where networks learn from synthetic surfaces with precise curvature values.","This modular approach eliminates the need for complex transformation-invariant architectures while effectively capturing local geometric properties.","Our experiments demonstrate state-of-the-art performance in curvature estimation and competitive results in geometric descriptor tasks with significantly fewer parameters (\\textbf{100X}) than comparable methods.","CanonNet's efficiency makes it particularly suitable for real-world applications where computational resources are limited, demonstrating that mathematical preprocessing can effectively complement neural architectures for point cloud analysis.","The code for the project is publicly available \\hyperlink{https://benjyfri.github.io/CanonNet/}{https://benjyfri.github.io/CanonNet/}."],"url":"http://arxiv.org/abs/2504.02763v1"}
{"created":"2025-04-03 16:58:06","title":"MD-ProjTex: Texturing 3D Shapes with Multi-Diffusion Projection","abstract":"We introduce MD-ProjTex, a method for fast and consistent text-guided texture generation for 3D shapes using pretrained text-to-image diffusion models. At the core of our approach is a multi-view consistency mechanism in UV space, which ensures coherent textures across different viewpoints. Specifically, MD-ProjTex fuses noise predictions from multiple views at each diffusion step and jointly updates the per-view denoising directions to maintain 3D consistency. In contrast to existing state-of-the-art methods that rely on optimization or sequential view synthesis, MD-ProjTex is computationally more efficient and achieves better quantitative and qualitative results.","sentences":["We introduce MD-ProjTex, a method for fast and consistent text-guided texture generation for 3D shapes using pretrained text-to-image diffusion models.","At the core of our approach is a multi-view consistency mechanism in UV space, which ensures coherent textures across different viewpoints.","Specifically, MD-ProjTex fuses noise predictions from multiple views at each diffusion step and jointly updates the per-view denoising directions to maintain 3D consistency.","In contrast to existing state-of-the-art methods that rely on optimization or sequential view synthesis, MD-ProjTex is computationally more efficient and achieves better quantitative and qualitative results."],"url":"http://arxiv.org/abs/2504.02762v1"}
{"created":"2025-04-03 16:49:58","title":"Echoes of the hidden: Uncovering coordination beyond network structure","abstract":"The study of connectivity and coordination has drawn increasing attention in recent decades due to their central role in driving markets, shaping societal dynamics, and influencing biological systems. Traditionally, observable connections, such as phone calls, financial transactions, or social media connections, have been used to infer coordination and connectivity. However, incomplete, encrypted, or fragmented data, alongside the ubiquity of communication platforms and deliberate obfuscation, often leave many real-world connections hidden. In this study, we demonstrate that coordinating individuals exhibit shared bursty activity patterns, enabling their detection even when observable links between them are sparse or entirely absent. We further propose a generative model based on the network of networks formalism to account for the mechanisms driving this collaborative burstiness, attributing it to shock propagation across networks rather than isolated individual behavior. Model simulations demonstrate that when observable connection density is below 70\\%, burstiness significantly improves coordination detection compared to state-of-the-art temporal and structural methods. This work provides a new perspective on community and coordination dynamics, advancing both theoretical understanding and practical detection. By laying the foundation for identifying hidden connections beyond observable network structures, it enables detection across different platforms, alongside enhancing system behavior understanding, informed decision-making, and risk mitigation.","sentences":["The study of connectivity and coordination has drawn increasing attention in recent decades due to their central role in driving markets, shaping societal dynamics, and influencing biological systems.","Traditionally, observable connections, such as phone calls, financial transactions, or social media connections, have been used to infer coordination and connectivity.","However, incomplete, encrypted, or fragmented data, alongside the ubiquity of communication platforms and deliberate obfuscation, often leave many real-world connections hidden.","In this study, we demonstrate that coordinating individuals exhibit shared bursty activity patterns, enabling their detection even when observable links between them are sparse or entirely absent.","We further propose a generative model based on the network of networks formalism to account for the mechanisms driving this collaborative burstiness, attributing it to shock propagation across networks rather than isolated individual behavior.","Model simulations demonstrate that when observable connection density is below 70\\%, burstiness significantly improves coordination detection compared to state-of-the-art temporal and structural methods.","This work provides a new perspective on community and coordination dynamics, advancing both theoretical understanding and practical detection.","By laying the foundation for identifying hidden connections beyond observable network structures, it enables detection across different platforms, alongside enhancing system behavior understanding, informed decision-making, and risk mitigation."],"url":"http://arxiv.org/abs/2504.02757v1"}
{"created":"2025-04-03 16:35:49","title":"Atrial constitutive neural networks","abstract":"This work presents a novel approach for characterizing the mechanical behavior of atrial tissue using constitutive neural networks. Based on experimental biaxial tensile test data of healthy human atria, we automatically discover the most appropriate constitutive material model, thereby overcoming the limitations of traditional, pre-defined models. This approach offers a new perspective on modeling atrial mechanics and is a significant step towards improved simulation and prediction of cardiac health.","sentences":["This work presents a novel approach for characterizing the mechanical behavior of atrial tissue using constitutive neural networks.","Based on experimental biaxial tensile test data of healthy human atria, we automatically discover the most appropriate constitutive material model, thereby overcoming the limitations of traditional, pre-defined models.","This approach offers a new perspective on modeling atrial mechanics and is a significant step towards improved simulation and prediction of cardiac health."],"url":"http://arxiv.org/abs/2504.02748v1"}
{"created":"2025-04-03 16:26:20","title":"Faster Mixing of the Jerrum-Sinclair Chain","abstract":"We show that the Jerrum-Sinclair Markov chain on matchings mixes in time $\\widetilde{O}(\\Delta^2 m)$ on any graph with $n$ vertices, $m$ edges, and maximum degree $\\Delta$, for any constant edge weight $\\lambda>0$. For general graphs with arbitrary, potentially unbounded $\\Delta$, this provides the first improvement over the classic $\\widetilde{O}(n^2 m)$ mixing time bound of Jerrum and Sinclair (1989) and Sinclair (1992).   To achieve this, we develop a general framework for analyzing mixing times, combining ideas from the classic canonical path method with the \"local-to-global\" approaches recently developed in high-dimensional expanders, introducing key innovations to both techniques.","sentences":["We show that the Jerrum-Sinclair Markov chain on matchings mixes in time $\\widetilde{O}(\\Delta^2 m)$ on any graph with $n$ vertices, $m$ edges, and maximum degree $\\Delta$, for any constant edge weight $\\lambda>0$. For general graphs with arbitrary, potentially unbounded $\\Delta$, this provides the first improvement over the classic $\\widetilde{O}(n^2 m)$ mixing time bound of Jerrum and Sinclair (1989) and Sinclair (1992).   ","To achieve this, we develop a general framework for analyzing mixing times, combining ideas from the classic canonical path method with the \"local-to-global\" approaches recently developed in high-dimensional expanders, introducing key innovations to both techniques."],"url":"http://arxiv.org/abs/2504.02740v1"}
{"created":"2025-04-03 16:24:49","title":"RBR4DNN: Requirements-based Testing of Neural Networks","abstract":"Deep neural network (DNN) testing is crucial for the reliability and safety of critical systems, where failures can have severe consequences. Although various techniques have been developed to create robustness test suites, requirements-based testing for DNNs remains largely unexplored -- yet such tests are recognized as an essential component of software validation of critical systems. In this work, we propose a requirements-based test suite generation method that uses structured natural language requirements formulated in a semantic feature space to create test suites by prompting text-conditional latent diffusion models with the requirement precondition and then using the associated postcondition to define a test oracle to judge outputs of the DNN under test. We investigate the approach using fine-tuned variants of pre-trained generative models. Our experiments on the MNIST, CelebA-HQ, ImageNet, and autonomous car driving datasets demonstrate that the generated test suites are realistic, diverse, consistent with preconditions, and capable of revealing faults.","sentences":["Deep neural network (DNN) testing is crucial for the reliability and safety of critical systems, where failures can have severe consequences.","Although various techniques have been developed to create robustness test suites, requirements-based testing for DNNs remains largely unexplored -- yet such tests are recognized as an essential component of software validation of critical systems.","In this work, we propose a requirements-based test suite generation method that uses structured natural language requirements formulated in a semantic feature space to create test suites by prompting text-conditional latent diffusion models with the requirement precondition and then using the associated postcondition to define a test oracle to judge outputs of the DNN under test.","We investigate the approach using fine-tuned variants of pre-trained generative models.","Our experiments on the MNIST, CelebA-HQ, ImageNet, and autonomous car driving datasets demonstrate that the generated test suites are realistic, diverse, consistent with preconditions, and capable of revealing faults."],"url":"http://arxiv.org/abs/2504.02737v1"}
{"created":"2025-04-03 16:22:15","title":"Pushing the Limit of PPG Sensing in Sedentary Conditions by Addressing Poor Skin-sensor Contact","abstract":"Photoplethysmography (PPG) is a widely used non-invasive technique for monitoring cardiovascular health and various physiological parameters on consumer and medical devices. While motion artifacts are well-known challenges in dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a critical issue often overlooked in existing literature - can distort PPG signal morphology, leading to the loss or shift of essential waveform features and therefore degrading sensing performance. In this work, we propose CP-PPG, a novel approach that transforms Contact Pressure-distorted PPG signals into ones with the ideal morphology. CP-PPG incorporates a novel data collection approach, a well-crafted signal processing pipeline, and an advanced deep adversarial model trained with a custom PPG-aware loss function. We validated CP-PPG through comprehensive evaluations, including 1) morphology transformation performance on our self-collected dataset, 2) downstream physiological monitoring performance on public datasets, and 3) in-the-wild performance. Extensive experiments demonstrate substantial and consistent improvements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement over the original signal) as well as downstream performance across all evaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate (RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR; 41-46% in HRV; 6% in RR; and 4-5% in BP). These findings highlight the critical importance of addressing skin-sensor contact issues for accurate and dependable PPG-based physiological monitoring. Furthermore, CP-PPG can serve as a generic, plug-in API to enhance PPG signal quality.","sentences":["Photoplethysmography (PPG) is a widely used non-invasive technique for monitoring cardiovascular health and various physiological parameters on consumer and medical devices.","While motion artifacts are well-known challenges in dynamic settings, suboptimal skin-sensor contact in sedentary conditions - a critical issue often overlooked in existing literature - can distort PPG signal morphology, leading to the loss or shift of essential waveform features and therefore degrading sensing performance.","In this work, we propose CP-PPG, a novel approach that transforms Contact Pressure-distorted PPG signals into ones with the ideal morphology.","CP-PPG incorporates a novel data collection approach, a well-crafted signal processing pipeline, and an advanced deep adversarial model trained with a custom PPG-aware loss function.","We validated CP-PPG through comprehensive evaluations, including 1) morphology transformation performance on our self-collected dataset, 2) downstream physiological monitoring performance on public datasets, and 3) in-the-wild performance.","Extensive experiments demonstrate substantial and consistent improvements in signal fidelity (Mean Absolute Error: 0.09, 40% improvement over the original signal) as well as downstream performance across all evaluations in Heart Rate (HR), Heart Rate Variability (HRV), Respiration Rate (RR), and Blood Pressure (BP) estimation (on average, 21% improvement in HR; 41-46% in HRV; 6% in RR; and 4-5% in BP).","These findings highlight the critical importance of addressing skin-sensor contact issues for accurate and dependable PPG-based physiological monitoring.","Furthermore, CP-PPG can serve as a generic, plug-in API to enhance PPG signal quality."],"url":"http://arxiv.org/abs/2504.02735v1"}
{"created":"2025-04-03 16:17:56","title":"Enhancing LLM Robustness to Perturbed Instructions: An Empirical Study","abstract":"Large Language Models (LLMs) are highly vulnerable to input perturbations, as even a small prompt change may result in a substantially different output. Existing methods to enhance LLM robustness are primarily focused on perturbed data samples, whereas improving resiliency to perturbations of task-level instructions has remained relatively underexplored. In this work, we focus on character- and word-level edits of task-specific instructions, which substantially degrade downstream performance. We experiment with a variety of techniques to enhance the robustness of LLMs, including self-denoising and representation alignment, testing different models (Llama 3 and Flan-T5), datasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and role-oriented). We find that, on average, self-denoising -- whether performed by a frozen LLM or a fine-tuned model -- achieves substantially higher performance gains than alternative strategies, including more complex baselines such as ensembling and supervised methods.","sentences":["Large Language Models (LLMs) are highly vulnerable to input perturbations, as even a small prompt change may result in a substantially different output.","Existing methods to enhance LLM robustness are primarily focused on perturbed data samples, whereas improving resiliency to perturbations of task-level instructions has remained relatively underexplored.","In this work, we focus on character- and word-level edits of task-specific instructions, which substantially degrade downstream performance.","We experiment with a variety of techniques to enhance the robustness of LLMs, including self-denoising and representation alignment, testing different models (Llama 3 and Flan-T5), datasets (CoLA, QNLI, SST-2) and instructions (both task-oriented and role-oriented).","We find that, on average, self-denoising -- whether performed by a frozen LLM or a fine-tuned model -- achieves substantially higher performance gains than alternative strategies, including more complex baselines such as ensembling and supervised methods."],"url":"http://arxiv.org/abs/2504.02733v1"}
{"created":"2025-04-03 16:17:55","title":"Why do LLMs attend to the first token?","abstract":"Large Language Models (LLMs) tend to attend heavily to the first token in the sequence -- creating a so-called attention sink. Many works have studied this phenomenon in detail, proposing various ways to either leverage or alleviate it. Attention sinks have been connected to quantisation difficulties, security issues, and streaming attention. Yet, while many works have provided conditions in which they occur or not, a critical question remains shallowly answered: Why do LLMs learn such patterns and how are they being used? In this work, we argue theoretically and empirically that this mechanism provides a method for LLMs to avoid over-mixing, connecting this to existing lines of work that study mathematically how information propagates in Transformers. We conduct experiments to validate our theoretical intuitions and show how choices such as context length, depth, and data packing influence the sink behaviour. We hope that this study provides a new practical perspective on why attention sinks are useful in LLMs, leading to a better understanding of the attention patterns that form during training.","sentences":["Large Language Models (LLMs) tend to attend heavily to the first token in the sequence -- creating a so-called attention sink.","Many works have studied this phenomenon in detail, proposing various ways to either leverage or alleviate it.","Attention sinks have been connected to quantisation difficulties, security issues, and streaming attention.","Yet, while many works have provided conditions in which they occur or not, a critical question remains shallowly answered: Why do LLMs learn such patterns and how are they being used?","In this work, we argue theoretically and empirically that this mechanism provides a method for LLMs to avoid over-mixing, connecting this to existing lines of work that study mathematically how information propagates in Transformers.","We conduct experiments to validate our theoretical intuitions and show how choices such as context length, depth, and data packing influence the sink behaviour.","We hope that this study provides a new practical perspective on why attention sinks are useful in LLMs, leading to a better understanding of the attention patterns that form during training."],"url":"http://arxiv.org/abs/2504.02732v1"}
{"created":"2025-04-03 16:13:34","title":"HQViT: Hybrid Quantum Vision Transformer for Image Classification","abstract":"Transformer-based architectures have revolutionized the landscape of deep learning. In computer vision domain, Vision Transformer demonstrates remarkable performance on par with or even surpassing that of convolutional neural networks. However, the quadratic computational complexity of its self-attention mechanism poses challenges for classical computing, making model training with high-dimensional input data, e.g., images, particularly expensive. To address such limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that leverages the principles of quantum computing to accelerate model training while enhancing model performance. HQViT introduces whole-image processing with amplitude encoding to better preserve global image information without additional positional encoding. By leveraging quantum computation on the most critical steps and selectively handling other components in a classical way, we lower the cost of quantum resources for HQViT. The qubit requirement is minimized to $O(log_2N)$ and the number of parameterized quantum gates is only $O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum devices. By offloading the computationally intensive attention coefficient matrix calculation to the quantum framework, HQViT reduces the classical computational load by $O(T^2d)$. Extensive experiments across various computer vision datasets demonstrate that HQViT outperforms existing models, achieving a maximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task) over the state of the art. This work highlights the great potential to combine quantum and classical computing to cope with complex image classification tasks.","sentences":["Transformer-based architectures have revolutionized the landscape of deep learning.","In computer vision domain, Vision Transformer demonstrates remarkable performance on par with or even surpassing that of convolutional neural networks.","However, the quadratic computational complexity of its self-attention mechanism poses challenges for classical computing, making model training with high-dimensional input data, e.g., images, particularly expensive.","To address such limitations, we propose a Hybrid Quantum Vision Transformer (HQViT), that leverages the principles of quantum computing to accelerate model training while enhancing model performance.","HQViT introduces whole-image processing with amplitude encoding to better preserve global image information without additional positional encoding.","By leveraging quantum computation on the most critical steps and selectively handling other components in a classical way, we lower the cost of quantum resources for HQViT.","The qubit requirement is minimized to $O(log_2N)$ and the number of parameterized quantum gates is only $O(log_2d)$, making it well-suited for Noisy Intermediate-Scale Quantum devices.","By offloading the computationally intensive attention coefficient matrix calculation to the quantum framework, HQViT reduces the classical computational load by $O(T^2d)$. Extensive experiments across various computer vision datasets demonstrate that HQViT outperforms existing models, achieving a maximum improvement of up to $10.9\\%$ (on the MNIST 10-classification task) over the state of the art.","This work highlights the great potential to combine quantum and classical computing to cope with complex image classification tasks."],"url":"http://arxiv.org/abs/2504.02730v1"}
{"created":"2025-04-03 16:07:38","title":"ERPO: Advancing Safety Alignment via Ex-Ante Reasoning Preference Optimization","abstract":"Recent advancements in large language models (LLMs) have accelerated progress toward artificial general intelligence, yet their potential to generate harmful content poses critical safety challenges. Existing alignment methods often struggle to cover diverse safety scenarios and remain vulnerable to adversarial attacks. In this work, we propose Ex-Ante Reasoning Preference Optimization (ERPO), a novel safety alignment framework that equips LLMs with explicit preemptive reasoning through Chain-of-Thought and provides clear evidence for safety judgments by embedding predefined safety rules. Specifically, our approach consists of three stages: first, equipping the model with Ex-Ante reasoning through supervised fine-tuning (SFT) using a constructed reasoning module; second, enhancing safety, usefulness, and efficiency via Direct Preference Optimization (DPO); and third, mitigating inference latency with a length-controlled iterative preference optimization strategy. Experiments on multiple open-source LLMs demonstrate that ERPO significantly enhances safety performance while maintaining response efficiency.","sentences":["Recent advancements in large language models (LLMs) have accelerated progress toward artificial general intelligence, yet their potential to generate harmful content poses critical safety challenges.","Existing alignment methods often struggle to cover diverse safety scenarios and remain vulnerable to adversarial attacks.","In this work, we propose Ex-Ante Reasoning Preference Optimization (ERPO), a novel safety alignment framework that equips LLMs with explicit preemptive reasoning through Chain-of-Thought and provides clear evidence for safety judgments by embedding predefined safety rules.","Specifically, our approach consists of three stages: first, equipping the model with Ex-Ante reasoning through supervised fine-tuning (SFT) using a constructed reasoning module; second, enhancing safety, usefulness, and efficiency via Direct Preference Optimization (DPO); and third, mitigating inference latency with a length-controlled iterative preference optimization strategy.","Experiments on multiple open-source LLMs demonstrate that ERPO significantly enhances safety performance while maintaining response efficiency."],"url":"http://arxiv.org/abs/2504.02725v1"}
{"created":"2025-04-03 16:06:44","title":"Autonomous Human-Robot Interaction via Operator Imitation","abstract":"Teleoperated robotic characters can perform expressive interactions with humans, relying on the operators' experience and social intuition. In this work, we propose to create autonomous interactive robots, by training a model to imitate operator data. Our model is trained on a dataset of human-robot interactions, where an expert operator is asked to vary the interactions and mood of the robot, while the operator commands as well as the pose of the human and robot are recorded. Our approach learns to predict continuous operator commands through a diffusion process and discrete commands through a classifier, all unified within a single transformer architecture. We evaluate the resulting model in simulation and with a user study on the real system. We show that our method enables simple autonomous human-robot interactions that are comparable to the expert-operator baseline, and that users can recognize the different robot moods as generated by our model. Finally, we demonstrate a zero-shot transfer of our model onto a different robotic platform with the same operator interface.","sentences":["Teleoperated robotic characters can perform expressive interactions with humans, relying on the operators' experience and social intuition.","In this work, we propose to create autonomous interactive robots, by training a model to imitate operator data.","Our model is trained on a dataset of human-robot interactions, where an expert operator is asked to vary the interactions and mood of the robot, while the operator commands as well as the pose of the human and robot are recorded.","Our approach learns to predict continuous operator commands through a diffusion process and discrete commands through a classifier, all unified within a single transformer architecture.","We evaluate the resulting model in simulation and with a user study on the real system.","We show that our method enables simple autonomous human-robot interactions that are comparable to the expert-operator baseline, and that users can recognize the different robot moods as generated by our model.","Finally, we demonstrate a zero-shot transfer of our model onto a different robotic platform with the same operator interface."],"url":"http://arxiv.org/abs/2504.02724v1"}
{"created":"2025-04-03 16:05:10","title":"Computing High-dimensional Confidence Sets for Arbitrary Distributions","abstract":"We study the problem of learning a high-density region of an arbitrary distribution over $\\mathbb{R}^d$. Given a target coverage parameter $\\delta$, and sample access to an arbitrary distribution $D$, we want to output a confidence set $S \\subset \\mathbb{R}^d$ such that $S$ achieves $\\delta$ coverage of $D$, i.e., $\\mathbb{P}_{y \\sim D} \\left[ y \\in S \\right] \\ge \\delta$, and the volume of $S$ is as small as possible. This is a central problem in high-dimensional statistics with applications in finding confidence sets, uncertainty quantification, and support estimation.   In the most general setting, this problem is statistically intractable, so we restrict our attention to competing with sets from a concept class $C$ with bounded VC-dimension. An algorithm is competitive with class $C$ if, given samples from an arbitrary distribution $D$, it outputs in polynomial time a set that achieves $\\delta$ coverage of $D$, and whose volume is competitive with the smallest set in $C$ with the required coverage $\\delta$. This problem is computationally challenging even in the basic setting when $C$ is the set of all Euclidean balls. Existing algorithms based on coresets find in polynomial time a ball whose volume is $\\exp(\\tilde{O}( d/ \\log d))$-factor competitive with the volume of the best ball.   Our main result is an algorithm that finds a confidence set whose volume is $\\exp(\\tilde{O}(d^{2/3}))$ factor competitive with the optimal ball having the desired coverage. The algorithm is improper (it outputs an ellipsoid). Combined with our computational intractability result for proper learning balls within an $\\exp(\\tilde{O}(d^{1-o(1)}))$ approximation factor in volume, our results provide an interesting separation between proper and (improper) learning of confidence sets.","sentences":["We study the problem of learning a high-density region of an arbitrary distribution over $\\mathbb{R}^d$. Given a target coverage parameter $\\delta$, and sample access to an arbitrary distribution $D$, we want to output a confidence set $S \\subset \\mathbb{R}^d$ such that $S$ achieves $\\delta$ coverage of $D$, i.e., $\\mathbb{P}_{y \\sim D} \\left","[ y \\in S \\right] \\ge \\delta$, and the volume of $S$ is as small as possible.","This is a central problem in high-dimensional statistics with applications in finding confidence sets, uncertainty quantification, and support estimation.   ","In the most general setting, this problem is statistically intractable, so we restrict our attention to competing with sets from a concept class $C$ with bounded VC-dimension.","An algorithm is competitive with class $C$ if, given samples from an arbitrary distribution $D$, it outputs in polynomial time a set that achieves $\\delta$ coverage of $D$, and whose volume is competitive with the smallest set in $C$ with the required coverage $\\delta$.","This problem is computationally challenging even in the basic setting when $C$ is the set of all Euclidean balls.","Existing algorithms based on coresets find in polynomial time a ball whose volume is $\\exp(\\tilde{O}( d/ \\log d))$-factor competitive with the volume of the best ball.   ","Our main result is an algorithm that finds a confidence set whose volume is $\\exp(\\tilde{O}(d^{2/3}))$ factor competitive with the optimal ball having the desired coverage.","The algorithm is improper (it outputs an ellipsoid).","Combined with our computational intractability result for proper learning balls within an $\\exp(\\tilde{O}(d^{1-o(1)}))$ approximation factor in volume, our results provide an interesting separation between proper and (improper) learning of confidence sets."],"url":"http://arxiv.org/abs/2504.02723v1"}
{"created":"2025-04-03 16:05:03","title":"Dynamic Directional Routing of Freight in the Physical Internet","abstract":"The Physical Internet (PI) envisions an interconnected, modular, and dynamically managed logistics system inspired by the Digital Internet. It enables open-access networks where shipments traverse a hyperconnected system of hubs, adjusting routes based on real-time conditions. A key challenge in scalable and adaptive freight movement is routing determining how shipments navigate the network to balance service levels, consolidation, and adaptability. This paper introduces directional routing, a dynamic approach that flexibly adjusts shipment paths, optimizing efficiency and consolidation using real-time logistics data. Unlike shortest-path routing, which follows fixed routes, directional routing dynamically selects feasible next-hop hubs based on network conditions, consolidation opportunities, and service level constraints. It consists of two phases: area discovery, which identifies candidate hubs, and node selection, which determines the next hub based on real-time parameters. This paper advances the area discovery phase by introducing a Reduced Search Space Breadth-First Search (RSS-BFS) method to systematically identify feasible routing areas while balancing service levels and consolidation. The proposed approach enhances network fluidity, scalability, and adaptability in PI-based logistics, advancing autonomous and sustainable freight movement.","sentences":["The Physical Internet (PI) envisions an interconnected, modular, and dynamically managed logistics system inspired by the Digital Internet.","It enables open-access networks where shipments traverse a hyperconnected system of hubs, adjusting routes based on real-time conditions.","A key challenge in scalable and adaptive freight movement is routing determining how shipments navigate the network to balance service levels, consolidation, and adaptability.","This paper introduces directional routing, a dynamic approach that flexibly adjusts shipment paths, optimizing efficiency and consolidation using real-time logistics data.","Unlike shortest-path routing, which follows fixed routes, directional routing dynamically selects feasible next-hop hubs based on network conditions, consolidation opportunities, and service level constraints.","It consists of two phases: area discovery, which identifies candidate hubs, and node selection, which determines the next hub based on real-time parameters.","This paper advances the area discovery phase by introducing a Reduced Search Space Breadth-First Search (RSS-BFS) method to systematically identify feasible routing areas while balancing service levels and consolidation.","The proposed approach enhances network fluidity, scalability, and adaptability in PI-based logistics, advancing autonomous and sustainable freight movement."],"url":"http://arxiv.org/abs/2504.02722v1"}
{"created":"2025-04-03 16:02:46","title":"The Myth of Immutability: A Multivocal Review on Smart Contract Upgradeability","abstract":"The immutability of smart contracts on blockchain platforms like Ethereum promotes security and trustworthiness but presents challenges for updates, bug fixes, or adding new features post-deployment. These limitations can lead to vulnerabilities and outdated functionality, impeding the evolution and maintenance of decentralized applications. Despite various upgrade mechanisms proposed in academic research and industry, a comprehensive analysis of their trade-offs and practical implications is lacking. This study aims to systematically identify, classify, and evaluate existing smart contract upgrade mechanisms, bridging the gap between theoretical concepts and practical implementations. It introduces standardized terminology and evaluates the trade-offs of different approaches using software quality attributes. We conducted a Multivocal Literature Review (MLR) to analyze upgrade mechanisms from both academic research and industry practice. We first establish a unified definition of smart contract upgradeability and identify core components essential for understanding the upgrade process. Based on this definition, we classify existing methods into full upgrade and partial upgrade approaches, introducing standardized terminology to harmonize the diverse terms used in the literature. We then characterize each approach and assess its benefits and limitations using software quality attributes such as complexity, flexibility, security, and usability. The analysis highlights significant trade-offs among upgrade mechanisms, providing valuable insights into the benefits and limitations of each approach. These findings guide developers and researchers in selecting mechanisms tailored to specific project requirements.","sentences":["The immutability of smart contracts on blockchain platforms like Ethereum promotes security and trustworthiness but presents challenges for updates, bug fixes, or adding new features post-deployment.","These limitations can lead to vulnerabilities and outdated functionality, impeding the evolution and maintenance of decentralized applications.","Despite various upgrade mechanisms proposed in academic research and industry, a comprehensive analysis of their trade-offs and practical implications is lacking.","This study aims to systematically identify, classify, and evaluate existing smart contract upgrade mechanisms, bridging the gap between theoretical concepts and practical implementations.","It introduces standardized terminology and evaluates the trade-offs of different approaches using software quality attributes.","We conducted a Multivocal Literature Review (MLR) to analyze upgrade mechanisms from both academic research and industry practice.","We first establish a unified definition of smart contract upgradeability and identify core components essential for understanding the upgrade process.","Based on this definition, we classify existing methods into full upgrade and partial upgrade approaches, introducing standardized terminology to harmonize the diverse terms used in the literature.","We then characterize each approach and assess its benefits and limitations using software quality attributes such as complexity, flexibility, security, and usability.","The analysis highlights significant trade-offs among upgrade mechanisms, providing valuable insights into the benefits and limitations of each approach.","These findings guide developers and researchers in selecting mechanisms tailored to specific project requirements."],"url":"http://arxiv.org/abs/2504.02719v1"}
{"created":"2025-04-03 15:52:39","title":"Web3DB: Web 3.0 RDBMS for Individual Data Ownership","abstract":"This paper introduces Web3DB, a decentralized relational database management system (RDBMS) designed to align with the principles of Web 3.0, addressing critical shortcomings of traditional centralized DBMS, such as data privacy, security vulnerabilities, and single points of failure. Several similar systems have been proposed, but they are not compatible with the legacy systems based on RDBMS. Motivated by the necessity for enhanced data sovereignty and the decentralization of data control, Web3DB leverages blockchain technology for fine-grained access control and utilizes decentralized data storage. This system leverages a novel, modular architecture that contributes to enhanced flexibility, scalability, and user-centric functionality. Central to the Web3DB innovation is its decentralized query execution, which uses cryptographic sortition and blockchain verification to ensure secure and fair query processing across network nodes. The motivation for integrating relational databases within decentralized DBMS primarily stems from the need to combine the robustness and ease of use of relational database structures with the benefits of decentralization. This paper outlines the architecture of Web3DB, its practical implementation, and the system's ability to support SQL-like operations on relational data, manage multi-tenancy, and facilitate open data sharing, setting new standards for decentralized databases in the Web 3.0 era.","sentences":["This paper introduces Web3DB, a decentralized relational database management system (RDBMS) designed to align with the principles of Web 3.0, addressing critical shortcomings of traditional centralized DBMS, such as data privacy, security vulnerabilities, and single points of failure.","Several similar systems have been proposed, but they are not compatible with the legacy systems based on RDBMS.","Motivated by the necessity for enhanced data sovereignty and the decentralization of data control, Web3DB leverages blockchain technology for fine-grained access control and utilizes decentralized data storage.","This system leverages a novel, modular architecture that contributes to enhanced flexibility, scalability, and user-centric functionality.","Central to the Web3DB innovation is its decentralized query execution, which uses cryptographic sortition and blockchain verification to ensure secure and fair query processing across network nodes.","The motivation for integrating relational databases within decentralized DBMS primarily stems from the need to combine the robustness and ease of use of relational database structures with the benefits of decentralization.","This paper outlines the architecture of Web3DB, its practical implementation, and the system's ability to support SQL-like operations on relational data, manage multi-tenancy, and facilitate open data sharing, setting new standards for decentralized databases in the Web 3.0 era."],"url":"http://arxiv.org/abs/2504.02713v1"}
{"created":"2025-04-03 15:52:20","title":"TeleMoM: Consensus-Driven Telecom Intelligence via Mixture of Models","abstract":"Large language models (LLMs) face significant challenges in specialized domains like telecommunication (Telecom) due to technical complexity, specialized terminology, and rapidly evolving knowledge. Traditional methods, such as scaling model parameters or retraining on domain-specific corpora, are computationally expensive and yield diminishing returns, while existing approaches like retrieval-augmented generation, mixture of experts, and fine-tuning struggle with accuracy, efficiency, and coordination. To address this issue, we propose Telecom mixture of models (TeleMoM), a consensus-driven ensemble framework that integrates multiple LLMs for enhanced decision-making in Telecom. TeleMoM employs a two-stage process: proponent models generate justified responses, and an adjudicator finalizes decisions, supported by a quality-checking mechanism. This approach leverages strengths of diverse models to improve accuracy, reduce biases, and handle domain-specific complexities effectively. Evaluation results demonstrate that TeleMoM achieves a 9.7\\% increase in answer accuracy, highlighting its effectiveness in Telecom applications.","sentences":["Large language models (LLMs) face significant challenges in specialized domains like telecommunication (Telecom) due to technical complexity, specialized terminology, and rapidly evolving knowledge.","Traditional methods, such as scaling model parameters or retraining on domain-specific corpora, are computationally expensive and yield diminishing returns, while existing approaches like retrieval-augmented generation, mixture of experts, and fine-tuning struggle with accuracy, efficiency, and coordination.","To address this issue, we propose Telecom mixture of models (TeleMoM), a consensus-driven ensemble framework that integrates multiple LLMs for enhanced decision-making in Telecom.","TeleMoM employs a two-stage process: proponent models generate justified responses, and an adjudicator finalizes decisions, supported by a quality-checking mechanism.","This approach leverages strengths of diverse models to improve accuracy, reduce biases, and handle domain-specific complexities effectively.","Evaluation results demonstrate that TeleMoM achieves a 9.7\\% increase in answer accuracy, highlighting its effectiveness in Telecom applications."],"url":"http://arxiv.org/abs/2504.02712v1"}
{"created":"2025-04-03 15:46:46","title":"The Hidden Space of Safety: Understanding Preference-Tuned LLMs in Multilingual context","abstract":"Alignment tuning has enabled large language models to excel in reasoning, instruction-following, and minimizing harmful generations. However, despite their widespread deployment, these models exhibit a monolingual bias, raising concerns about the effectiveness of alignment across languages. Current alignment methods predominantly focus on English, leaving it unclear how alignment mechanism generalize to multilingual settings. To address this, we conduct a systematic analysis of distributional shifts in the embedding space of LLMs before and after alignment, uncovering its impact on model behavior across diverse languages. We leverage the alignment-induced separation in safety space as a quantitative tool to measure how alignment enforces safety constraints. Our study evaluates seven LLMs using balanced toxicity datasets and parallel text-detoxification benchmarks, revealing substantial disparities in the latent representation space between high-resource and low-resource languages. These findings underscore the need for language-specific fine-tuning to ensure fair, reliable and robust multilingual alignment. Our insights provide a foundation for developing truly safe multilingual LLMs, emphasizing the urgency of addressing alignment gaps in underrepresented languages.","sentences":["Alignment tuning has enabled large language models to excel in reasoning, instruction-following, and minimizing harmful generations.","However, despite their widespread deployment, these models exhibit a monolingual bias, raising concerns about the effectiveness of alignment across languages.","Current alignment methods predominantly focus on English, leaving it unclear how alignment mechanism generalize to multilingual settings.","To address this, we conduct a systematic analysis of distributional shifts in the embedding space of LLMs before and after alignment, uncovering its impact on model behavior across diverse languages.","We leverage the alignment-induced separation in safety space as a quantitative tool to measure how alignment enforces safety constraints.","Our study evaluates seven LLMs using balanced toxicity datasets and parallel text-detoxification benchmarks, revealing substantial disparities in the latent representation space between high-resource and low-resource languages.","These findings underscore the need for language-specific fine-tuning to ensure fair, reliable and robust multilingual alignment.","Our insights provide a foundation for developing truly safe multilingual LLMs, emphasizing the urgency of addressing alignment gaps in underrepresented languages."],"url":"http://arxiv.org/abs/2504.02708v1"}
{"created":"2025-04-03 15:41:48","title":"EvoChain: A Framework for Tracking and Visualizing Smart Contract Evolution","abstract":"Tracking the evolution of smart contracts is challenging due to their immutable nature and complex upgrade mechanisms. We introduce EvoChain, a comprehensive framework and dataset designed to track and visualize smart contract evolution. Building upon data from our previous empirical study, EvoChain models contract relationships using a Neo4j graph database and provides an interactive web interface for exploration. The framework consists of a data layer, an API layer, and a user interface layer. EvoChain allows stakeholders to analyze contract histories, upgrade paths, and associated vulnerabilities by leveraging these components. Our dataset encompasses approximately 1.3 million upgradeable proxies and nearly 15,000 historical versions, enhancing transparency and trust in blockchain ecosystems by providing an accessible platform for understanding smart contract evolution.","sentences":["Tracking the evolution of smart contracts is challenging due to their immutable nature and complex upgrade mechanisms.","We introduce EvoChain, a comprehensive framework and dataset designed to track and visualize smart contract evolution.","Building upon data from our previous empirical study, EvoChain models contract relationships using a Neo4j graph database and provides an interactive web interface for exploration.","The framework consists of a data layer, an API layer, and a user interface layer.","EvoChain allows stakeholders to analyze contract histories, upgrade paths, and associated vulnerabilities by leveraging these components.","Our dataset encompasses approximately 1.3 million upgradeable proxies and nearly 15,000 historical versions, enhancing transparency and trust in blockchain ecosystems by providing an accessible platform for understanding smart contract evolution."],"url":"http://arxiv.org/abs/2504.02704v1"}
{"created":"2025-04-03 15:37:38","title":"Responsible Development of Offensive AI","abstract":"As AI advances, broader consensus is needed to determine research priorities. This endeavor discusses offensive AI and provides guidance by leveraging Sustainable Development Goals (SDGs) and interpretability techniques. The objective is to more effectively establish priorities that balance societal benefits against risks. The two forms of offensive AI evaluated in this study are vulnerability detection agents, which solve Capture- The-Flag challenges, and AI-powered malware.","sentences":["As AI advances, broader consensus is needed to determine research priorities.","This endeavor discusses offensive AI and provides guidance by leveraging Sustainable Development Goals (SDGs) and interpretability techniques.","The objective is to more effectively establish priorities that balance societal benefits against risks.","The two forms of offensive AI evaluated in this study are vulnerability detection agents, which solve Capture- The-Flag challenges, and AI-powered malware."],"url":"http://arxiv.org/abs/2504.02701v1"}
{"created":"2025-04-03 15:34:02","title":"SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions","abstract":"Protein-Protein Interaction (PPI) prediction is a key task in uncovering cellular functional networks and disease mechanisms. However, traditional experimental methods are time-consuming and costly, and existing computational models face challenges in cross-modal feature fusion, robustness, and false-negative suppression. In this paper, we propose a novel supervised contrastive multimodal framework, SCMPPI, for PPI prediction. By integrating protein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology information (Node2Vec graph embedding), and combining an improved supervised contrastive learning strategy, SCMPPI significantly enhances PPI prediction performance. For the PPI task, SCMPPI introduces a negative sample filtering mechanism and modifies the contrastive loss function, effectively optimizing multimodal features. Experiments on eight benchmark datasets, including yeast, human, and H.pylori, show that SCMPPI outperforms existing state-of-the-art methods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%) and AUC (99.62%), and demonstrates strong generalization in cross-species prediction (AUC > 99% on multi-species datasets). Furthermore, SCMPPI has been successfully applied to CD9 networks, the Wnt pathway, and cancer-specific networks, providing a reliable tool for disease target discovery. This framework also offers a new paradigm for multimodal biological information fusion and contrastive learning in collaborative optimization for various combined predictions.","sentences":["Protein-Protein Interaction (PPI) prediction is a key task in uncovering cellular functional networks and disease mechanisms.","However, traditional experimental methods are time-consuming and costly, and existing computational models face challenges in cross-modal feature fusion, robustness, and false-negative suppression.","In this paper, we propose a novel supervised contrastive multimodal framework, SCMPPI, for PPI prediction.","By integrating protein sequence features (AAC, DPC, CKSAAP-ESMC) with PPI network topology information (Node2Vec graph embedding), and combining an improved supervised contrastive learning strategy, SCMPPI significantly enhances PPI prediction performance.","For the PPI task, SCMPPI introduces a negative sample filtering mechanism and modifies the contrastive loss function, effectively optimizing multimodal features.","Experiments on eight benchmark datasets, including yeast, human, and H.pylori, show that SCMPPI outperforms existing state-of-the-art methods (such as DF-PPI and TAGPPI) in key metrics such as accuracy ( 98.01%) and AUC (99.62%), and demonstrates strong generalization in cross-species prediction (AUC > 99% on multi-species datasets).","Furthermore, SCMPPI has been successfully applied to CD9 networks, the Wnt pathway, and cancer-specific networks, providing a reliable tool for disease target discovery.","This framework also offers a new paradigm for multimodal biological information fusion and contrastive learning in collaborative optimization for various combined predictions."],"url":"http://arxiv.org/abs/2504.02698v1"}
{"created":"2025-04-03 15:33:18","title":"Learning Phase Distortion with Selective State Space Models for Video Turbulence Mitigation","abstract":"Atmospheric turbulence is a major source of image degradation in long-range imaging systems. Although numerous deep learning-based turbulence mitigation (TM) methods have been proposed, many are slow, memory-hungry, and do not generalize well. In the spatial domain, methods based on convolutional operators have a limited receptive field, so they cannot handle a large spatial dependency required by turbulence. In the temporal domain, methods relying on self-attention can, in theory, leverage the lucky effects of turbulence, but their quadratic complexity makes it difficult to scale to many frames. Traditional recurrent aggregation methods face parallelization challenges.   In this paper, we present a new TM method based on two concepts: (1) A turbulence mitigation network based on the Selective State Space Model (MambaTM). MambaTM provides a global receptive field in each layer across spatial and temporal dimensions while maintaining linear computational complexity. (2) Learned Latent Phase Distortion (LPD). LPD guides the state space model. Unlike classical Zernike-based representations of phase distortion, the new LPD map uniquely captures the actual effects of turbulence, significantly improving the model's capability to estimate degradation by reducing the ill-posedness. Our proposed method exceeds current state-of-the-art networks on various synthetic and real-world TM benchmarks with significantly faster inference speed. The code is available at http://github.com/xg416/MambaTM.","sentences":["Atmospheric turbulence is a major source of image degradation in long-range imaging systems.","Although numerous deep learning-based turbulence mitigation (TM) methods have been proposed, many are slow, memory-hungry, and do not generalize well.","In the spatial domain, methods based on convolutional operators have a limited receptive field, so they cannot handle a large spatial dependency required by turbulence.","In the temporal domain, methods relying on self-attention can, in theory, leverage the lucky effects of turbulence, but their quadratic complexity makes it difficult to scale to many frames.","Traditional recurrent aggregation methods face parallelization challenges.   ","In this paper, we present a new TM method based on two concepts: (1) A turbulence mitigation network based on the Selective State Space Model (MambaTM).","MambaTM provides a global receptive field in each layer across spatial and temporal dimensions while maintaining linear computational complexity.","(2) Learned Latent Phase Distortion (LPD).","LPD guides the state space model.","Unlike classical Zernike-based representations of phase distortion, the new LPD map uniquely captures the actual effects of turbulence, significantly improving the model's capability to estimate degradation by reducing the ill-posedness.","Our proposed method exceeds current state-of-the-art networks on various synthetic and real-world TM benchmarks with significantly faster inference speed.","The code is available at http://github.com/xg416/MambaTM."],"url":"http://arxiv.org/abs/2504.02697v1"}
{"created":"2025-04-03 15:32:32","title":"Mind the Gap? Not for SVP Hardness under ETH!","abstract":"We prove new hardness results for fundamental lattice problems under the Exponential Time Hypothesis (ETH). Building on a recent breakthrough by Bitansky et al. [BHIRW24], who gave a polynomial-time reduction from $\\mathsf{3SAT}$ to the (gap) $\\mathsf{MAXLIN}$ problem-a class of CSPs with linear equations over finite fields-we derive ETH-hardness for several lattice problems.   First, we show that for any $p \\in [1, \\infty)$, there exists an explicit constant $\\gamma > 1$ such that $\\mathsf{CVP}_{p,\\gamma}$ (the $\\ell_p$-norm approximate Closest Vector Problem) does not admit a $2^{o(n)}$-time algorithm unless ETH is false. Our reduction is deterministic and proceeds via a direct reduction from (gap) $\\mathsf{MAXLIN}$ to $\\mathsf{CVP}_{p,\\gamma}$.   Next, we prove a randomized ETH-hardness result for $\\mathsf{SVP}_{p,\\gamma}$ (the $\\ell_p$-norm approximate Shortest Vector Problem) for all $p > 2$. This result relies on a novel property of the integer lattice $\\mathbb{Z}^n$ in the $\\ell_p$ norm and a randomized reduction from $\\mathsf{CVP}_{p,\\gamma}$ to $\\mathsf{SVP}_{p,\\gamma'}$.   Finally, we improve over prior reductions from $\\mathsf{3SAT}$ to $\\mathsf{BDD}_{p, \\alpha}$ (the Bounded Distance Decoding problem), yielding better ETH-hardness results for $\\mathsf{BDD}_{p, \\alpha}$ for any $p \\in [1, \\infty)$ and $\\alpha > \\alpha_p^{\\ddagger}$, where $\\alpha_p^{\\ddagger}$ is an explicit threshold depending on $p$.   We additionally observe that prior work implies ETH hardness for the gap minimum distance problem ($\\gamma$-$\\mathsf{MDP}$) in codes.","sentences":["We prove new hardness results for fundamental lattice problems under the Exponential Time Hypothesis (ETH).","Building on a recent breakthrough by Bitansky et al.","[BHIRW24], who gave a polynomial-time reduction from $\\mathsf{3SAT}$ to the (gap) $\\mathsf{MAXLIN}$ problem-a class of CSPs with linear equations over finite fields-we derive ETH-hardness for several lattice problems.   ","First, we show that for any $p \\in [1, \\infty)$, there exists an explicit constant $\\gamma > 1$ such that $\\mathsf{CVP}_{p,\\gamma}$ (the $\\ell_p$-norm approximate Closest Vector Problem) does not admit a $2^{o(n)}$-time algorithm unless ETH is false.","Our reduction is deterministic and proceeds via a direct reduction from (gap) $\\mathsf{MAXLIN}$ to $\\mathsf{CVP}_{p,\\gamma}$.   Next, we prove a randomized ETH-hardness result for $\\mathsf{SVP}_{p,\\gamma}$ (the $\\ell_p$-norm approximate Shortest Vector Problem) for all $p > 2$.","This result relies on a novel property of the integer lattice $\\mathbb{Z}^n$ in the $\\ell_p$ norm and a randomized reduction from $\\mathsf{CVP}_{p,\\gamma}$ to $\\mathsf{SVP}_{p,\\gamma'}$.   Finally, we improve over prior reductions from $\\mathsf{3SAT}$ to $\\mathsf{BDD}_{p, \\alpha}$ (the Bounded Distance Decoding problem), yielding better ETH-hardness results for $\\mathsf{BDD}_{p, \\alpha}$ for any $p \\in [1, \\infty)$ and $\\alpha > \\alpha_p^{\\ddagger}$, where $\\alpha_p^{\\ddagger}$ is an explicit threshold depending on $p$.   We additionally observe that prior work implies ETH hardness for the gap minimum distance problem ($\\gamma$-$\\mathsf{MDP}$) in codes."],"url":"http://arxiv.org/abs/2504.02695v1"}
{"created":"2025-04-03 15:30:43","title":"GPTQv2: Efficient Finetuning-Free Quantization for Asymmetric Calibration","abstract":"We introduce GPTQv2, a novel finetuning-free quantization method for compressing large-scale transformer architectures. Unlike the previous GPTQ method, which independently calibrates each layer, we always match the quantized layer's output to the exact output in the full-precision model, resulting in a scheme that we call asymmetric calibration. Such a scheme can effectively reduce the quantization error accumulated in previous layers. We analyze this problem using optimal brain compression to derive a close-formed solution. The new solution explicitly minimizes the quantization error as well as the accumulated asymmetry error. Furthermore, we utilize various techniques to parallelize the solution calculation, including channel parallelization, neuron decomposition, and Cholesky reformulation for matrix fusion. As a result, GPTQv2 is easy to implement, simply using 20 more lines of code than GPTQ but improving its performance under low-bit quantization. Remarkably, on a single GPU, we quantize a 405B language transformer as well as EVA-02 the rank first vision transformer that achieves 90% pretraining Imagenet accuracy. Code is available at github.com/Intelligent-Computing-Lab-Yale/GPTQv2.","sentences":["We introduce GPTQv2, a novel finetuning-free quantization method for compressing large-scale transformer architectures.","Unlike the previous GPTQ method, which independently calibrates each layer, we always match the quantized layer's output to the exact output in the full-precision model, resulting in a scheme that we call asymmetric calibration.","Such a scheme can effectively reduce the quantization error accumulated in previous layers.","We analyze this problem using optimal brain compression to derive a close-formed solution.","The new solution explicitly minimizes the quantization error as well as the accumulated asymmetry error.","Furthermore, we utilize various techniques to parallelize the solution calculation, including channel parallelization, neuron decomposition, and Cholesky reformulation for matrix fusion.","As a result, GPTQv2 is easy to implement, simply using 20 more lines of code than GPTQ but improving its performance under low-bit quantization.","Remarkably, on a single GPU, we quantize a 405B language transformer as well as EVA-02 the rank first vision transformer that achieves 90% pretraining Imagenet accuracy.","Code is available at github.com/Intelligent-Computing-Lab-Yale/GPTQv2."],"url":"http://arxiv.org/abs/2504.02692v1"}
{"created":"2025-04-03 15:28:04","title":"Handover and SINR-Aware Path Optimization in 5G-UAV mmWave Communication using DRL","abstract":"Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted next-generation wireless networks is critical for mobility management and ensuring UAV safety and ubiquitous connectivity, especially in dense urban environments with street canyons and tall buildings. Traditional statistical and model-based techniques have been successfully used for path optimization in communication networks. However, when dynamic channel propagation characteristics such as line-of-sight (LOS), interference, handover, and signal-to-interference and noise ratio (SINR) are included in path optimization, statistical and model-based path planning solutions become obsolete since they cannot adapt to the dynamic and time-varying wireless channels, especially in the mmWave bands. In this paper, we propose a novel model-free actor-critic deep reinforcement learning (AC-DRL) framework for path optimization in UAV-assisted 5G mmWave wireless networks, which combines four important aspects of UAV communication: \\textit{flight time, handover, connectivity and SINR}. We train an AC-RL agent that enables a UAV connected to a gNB to determine the optimal path to a desired destination in the shortest possible time with minimal gNB handover, while maintaining connectivity and the highest possible SINR. We train our model with data from a powerful ray tracing tool called Wireless InSite, which uses 3D images of the propagation environment and provides data that closely resembles the real propagation environment. The simulation results show that our system has superior performance in tracking high SINR compared to other selected RL algorithms.","sentences":["Path planning and optimization for unmanned aerial vehicles (UAVs)-assisted next-generation wireless networks is critical for mobility management and ensuring UAV safety and ubiquitous connectivity, especially in dense urban environments with street canyons and tall buildings.","Traditional statistical and model-based techniques have been successfully used for path optimization in communication networks.","However, when dynamic channel propagation characteristics such as line-of-sight (LOS), interference, handover, and signal-to-interference and noise ratio (SINR) are included in path optimization, statistical and model-based path planning solutions become obsolete since they cannot adapt to the dynamic and time-varying wireless channels, especially in the mmWave bands.","In this paper, we propose a novel model-free actor-critic deep reinforcement learning (AC-DRL) framework for path optimization in UAV-assisted 5G mmWave wireless networks, which combines four important aspects of UAV communication: \\textit{flight time, handover, connectivity and SINR}.","We train an AC-RL agent that enables a UAV connected to a gNB to determine the optimal path to a desired destination in the shortest possible time with minimal gNB handover, while maintaining connectivity and the highest possible SINR.","We train our model with data from a powerful ray tracing tool called Wireless InSite, which uses 3D images of the propagation environment and provides data that closely resembles the real propagation environment.","The simulation results show that our system has superior performance in tracking high SINR compared to other selected RL algorithms."],"url":"http://arxiv.org/abs/2504.02688v1"}
{"created":"2025-04-03 15:26:03","title":"STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability","abstract":"Out-of-Distribution (OOD) detection is a critical task in machine learning, particularly in safety-sensitive applications where model failures can have serious consequences. However, current OOD detection methods often suffer from restrictive distributional assumptions, limited scalability, and a lack of interpretability. To address these challenges, we propose STOOD-X, a two-stage methodology that combines a Statistical nonparametric Test for OOD Detection with eXplainability enhancements. In the first stage, STOOD-X uses feature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD samples without assuming a specific feature distribution. In the second stage, it generates user-friendly, concept-based visual explanations that reveal the features driving each decision, aligning with the BLUE XAI paradigm. Through extensive experiments on benchmark datasets and multiple architectures, STOOD-X achieves competitive performance against state-of-the-art post hoc OOD detectors, particularly in high-dimensional and complex settings. In addition, its explainability framework enables human oversight, bias detection, and model debugging, fostering trust and collaboration between humans and AI systems. The STOOD-X methodology therefore offers a robust, explainable, and scalable solution for real-world OOD detection tasks.","sentences":["Out-of-Distribution (OOD) detection is a critical task in machine learning, particularly in safety-sensitive applications where model failures can have serious consequences.","However, current OOD detection methods often suffer from restrictive distributional assumptions, limited scalability, and a lack of interpretability.","To address these challenges, we propose STOOD-X, a two-stage methodology that combines a Statistical nonparametric Test for OOD Detection with eXplainability enhancements.","In the first stage, STOOD-X uses feature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD samples without assuming a specific feature distribution.","In the second stage, it generates user-friendly, concept-based visual explanations that reveal the features driving each decision, aligning with the BLUE XAI paradigm.","Through extensive experiments on benchmark datasets and multiple architectures, STOOD-X achieves competitive performance against state-of-the-art post hoc OOD detectors, particularly in high-dimensional and complex settings.","In addition, its explainability framework enables human oversight, bias detection, and model debugging, fostering trust and collaboration between humans and AI systems.","The STOOD-X methodology therefore offers a robust, explainable, and scalable solution for real-world OOD detection tasks."],"url":"http://arxiv.org/abs/2504.02685v1"}
{"created":"2025-04-03 15:15:16","title":"Snow: Self-organizing Broadcast Protocol for Cloud","abstract":"In large-scale distributed applications, efficient and reliable broadcast protocols are essential for node communication. Tree-based broadcast lacks flexibility and may suffer performance degradation or even broadcast failure when cluster membership changes. Gossip-based broadcast incurs high bandwidth overhead and only provides probabilistic delivery guarantees. In tree-based broadcasting, when an internal node leaves, its child nodes need to reconnect to a new parent. This process may introduce instability, leading to potential message duplication and increased transmission latency. However, in cloud environments, node departures and arrivals are common, causing frequent performance degradation in tree-based broadcasting. This paper introduces Snow, a self-organizing broadcast protocol designed for cloud environments. Instead, it dynamically sends or forwards messages based on each node's membership view, ultimately forming a broadcast structure resembling a multi-way balanced tree(the height difference of leaf nodes is at most 1). Our experimental results showed that Snow maintains message delivery reliability and latency guarantees under node churn while maintaining low overhead without sending unnecessary redundant messages.","sentences":["In large-scale distributed applications, efficient and reliable broadcast protocols are essential for node communication.","Tree-based broadcast lacks flexibility and may suffer performance degradation or even broadcast failure when cluster membership changes.","Gossip-based broadcast incurs high bandwidth overhead and only provides probabilistic delivery guarantees.","In tree-based broadcasting, when an internal node leaves, its child nodes need to reconnect to a new parent.","This process may introduce instability, leading to potential message duplication and increased transmission latency.","However, in cloud environments, node departures and arrivals are common, causing frequent performance degradation in tree-based broadcasting.","This paper introduces Snow, a self-organizing broadcast protocol designed for cloud environments.","Instead, it dynamically sends or forwards messages based on each node's membership view, ultimately forming a broadcast structure resembling a multi-way balanced tree(the height difference of leaf nodes is at most 1).","Our experimental results showed that Snow maintains message delivery reliability and latency guarantees under node churn while maintaining low overhead without sending unnecessary redundant messages."],"url":"http://arxiv.org/abs/2504.02676v1"}
{"created":"2025-04-03 15:15:10","title":"Cybersickness Assessment Framework(TestBed): Towards a Standardization of Experiments","abstract":"Investigating cybersickness (CS) in virtual reality (VR) often requires significant resources to create the VR environment and manage other experiment-related aspects. Additionally, slight differences in VR content across studies can lead to conflicting results. To address these challenges, we propose a standardized assessment framework to facilitate cybersickness research. The main goal is to enable consistent and comparable CS-related experiments. By establishing this common foundation, researchers can better evaluate and compare the impact of various factors on cybersickness. We provide a comprehensive explanation of the conceptual designs, detail the technical implementation, and offer instructions for using the proposed framework. Lastly, we conclude by discussing the limitations and potential avenues for future development.","sentences":["Investigating cybersickness (CS) in virtual reality (VR) often requires significant resources to create the VR environment and manage other experiment-related aspects.","Additionally, slight differences in VR content across studies can lead to conflicting results.","To address these challenges, we propose a standardized assessment framework to facilitate cybersickness research.","The main goal is to enable consistent and comparable CS-related experiments.","By establishing this common foundation, researchers can better evaluate and compare the impact of various factors on cybersickness.","We provide a comprehensive explanation of the conceptual designs, detail the technical implementation, and offer instructions for using the proposed framework.","Lastly, we conclude by discussing the limitations and potential avenues for future development."],"url":"http://arxiv.org/abs/2504.02675v1"}
{"created":"2025-04-03 15:14:19","title":"Limitations of Religious Data and the Importance of the Target Domain: Towards Machine Translation for Guinea-Bissau Creole","abstract":"We introduce a new dataset for machine translation of Guinea-Bissau Creole (Kiriol), comprising around 40 thousand parallel sentences to English and Portuguese. This dataset is made up of predominantly religious data (from the Bible and texts from the Jehovah's Witnesses), but also a small amount of general domain data (from a dictionary). This mirrors the typical resource availability of many low resource languages. We train a number of transformer-based models to investigate how to improve domain transfer from religious data to a more general domain. We find that adding even 300 sentences from the target domain when training substantially improves the translation performance, highlighting the importance and need for data collection for low-resource languages, even on a small-scale. We additionally find that Portuguese-to-Kiriol translation models perform better on average than other source and target language pairs, and investigate how this relates to the morphological complexity of the languages involved and the degree of lexical overlap between creoles and lexifiers. Overall, we hope our work will stimulate research into Kiriol and into how machine translation might better support creole languages in general.","sentences":["We introduce a new dataset for machine translation of Guinea-Bissau Creole (Kiriol), comprising around 40 thousand parallel sentences to English and Portuguese.","This dataset is made up of predominantly religious data (from the Bible and texts from the Jehovah's Witnesses), but also a small amount of general domain data (from a dictionary).","This mirrors the typical resource availability of many low resource languages.","We train a number of transformer-based models to investigate how to improve domain transfer from religious data to a more general domain.","We find that adding even 300 sentences from the target domain when training substantially improves the translation performance, highlighting the importance and need for data collection for low-resource languages, even on a small-scale.","We additionally find that Portuguese-to-Kiriol translation models perform better on average than other source and target language pairs, and investigate how this relates to the morphological complexity of the languages involved and the degree of lexical overlap between creoles and lexifiers.","Overall, we hope our work will stimulate research into Kiriol and into how machine translation might better support creole languages in general."],"url":"http://arxiv.org/abs/2504.02674v1"}
{"created":"2025-04-03 15:13:36","title":"LLM for Complex Reasoning Task: An Exploratory Study in Fermi Problems","abstract":"Fermi Problems (FPs) are mathematical reasoning tasks that require human-like logic and numerical reasoning. Unlike other reasoning questions, FPs often involve real-world impracticalities or ambiguous concepts, making them challenging even for humans to solve. Despite advancements in AI, particularly with large language models (LLMs) in various reasoning tasks, FPs remain relatively under-explored. This work conducted an exploratory study to examine the capabilities and limitations of LLMs in solving FPs. We first evaluated the overall performance of three advanced LLMs using a publicly available FP dataset. We designed prompts according to the recently proposed TELeR taxonomy, including a zero-shot scenario. Results indicated that all three LLMs achieved a fp_score (range between 0 - 1) below 0.5, underscoring the inherent difficulty of these reasoning tasks. To further investigate, we categorized FPs into standard and specific questions, hypothesizing that LLMs would perform better on standard questions, which are characterized by clarity and conciseness, than on specific ones. Comparative experiments confirmed this hypothesis, demonstrating that LLMs performed better on standard FPs in terms of both accuracy and efficiency.","sentences":["Fermi Problems (FPs) are mathematical reasoning tasks that require human-like logic and numerical reasoning.","Unlike other reasoning questions, FPs often involve real-world impracticalities or ambiguous concepts, making them challenging even for humans to solve.","Despite advancements in AI, particularly with large language models (LLMs) in various reasoning tasks, FPs remain relatively under-explored.","This work conducted an exploratory study to examine the capabilities and limitations of LLMs in solving FPs.","We first evaluated the overall performance of three advanced LLMs using a publicly available FP dataset.","We designed prompts according to the recently proposed TELeR taxonomy, including a zero-shot scenario.","Results indicated that all three LLMs achieved a fp_score (range between 0 - 1) below 0.5, underscoring the inherent difficulty of these reasoning tasks.","To further investigate, we categorized FPs into standard and specific questions, hypothesizing that LLMs would perform better on standard questions, which are characterized by clarity and conciseness, than on specific ones.","Comparative experiments confirmed this hypothesis, demonstrating that LLMs performed better on standard FPs in terms of both accuracy and efficiency."],"url":"http://arxiv.org/abs/2504.02671v1"}
{"created":"2025-04-03 15:11:55","title":"Affordable AI Assistants with Knowledge Graph of Thoughts","abstract":"Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose the Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini, while reducing costs by over 36x compared to GPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and 37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a scalable, affordable, and high-performing solution for AI assistants.","sentences":["Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains.","However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA.","To address these issues, we propose the Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs).","KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts.","Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively.","For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini, while reducing costs by over 36x compared to GPT-4o.","Improvements for recent reasoning models are similar, e.g., 36% and 37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively.","KGoT offers a scalable, affordable, and high-performing solution for AI assistants."],"url":"http://arxiv.org/abs/2504.02670v1"}
{"created":"2025-04-03 15:07:54","title":"Compositionality Unlocks Deep Interpretable Models","abstract":"We propose $\\chi$-net, an intrinsically interpretable architecture combining the compositional multilinear structure of tensor networks with the expressivity and efficiency of deep neural networks. $\\chi$-nets retain equal accuracy compared to their baseline counterparts. Our novel, efficient diagonalisation algorithm, ODT, reveals linear low-rank structure in a multilayer SVHN model. We leverage this toward formal weight-based interpretability and model compression.","sentences":["We propose $\\chi$-net, an intrinsically interpretable architecture combining the compositional multilinear structure of tensor networks with the expressivity and efficiency of deep neural networks.","$\\chi$-nets retain equal accuracy compared to their baseline counterparts.","Our novel, efficient diagonalisation algorithm, ODT, reveals linear low-rank structure in a multilayer SVHN model.","We leverage this toward formal weight-based interpretability and model compression."],"url":"http://arxiv.org/abs/2504.02667v1"}
{"created":"2025-04-03 15:07:28","title":"BECAME: BayEsian Continual Learning with Adaptive Model MErging","abstract":"Continual Learning (CL) strives to learn incrementally across tasks while mitigating catastrophic forgetting. A key challenge in CL is balancing stability (retaining prior knowledge) and plasticity (learning new tasks). While representative gradient projection methods ensure stability, they often limit plasticity. Model merging techniques offer promising solutions, but prior methods typically rely on empirical assumptions and carefully selected hyperparameters. In this paper, we explore the potential of model merging to enhance the stability-plasticity trade-off, providing theoretical insights that underscore its benefits. Specifically, we reformulate the merging mechanism using Bayesian continual learning principles and derive a closed-form solution for the optimal merging coefficient that adapts to the diverse characteristics of tasks. To validate our approach, we introduce a two-stage framework named BECAME, which synergizes the expertise of gradient projection and adaptive merging. Extensive experiments show that our approach outperforms state-of-the-art CL methods and existing merging strategies.","sentences":["Continual Learning (CL) strives to learn incrementally across tasks while mitigating catastrophic forgetting.","A key challenge in CL is balancing stability (retaining prior knowledge) and plasticity (learning new tasks).","While representative gradient projection methods ensure stability, they often limit plasticity.","Model merging techniques offer promising solutions, but prior methods typically rely on empirical assumptions and carefully selected hyperparameters.","In this paper, we explore the potential of model merging to enhance the stability-plasticity trade-off, providing theoretical insights that underscore its benefits.","Specifically, we reformulate the merging mechanism using Bayesian continual learning principles and derive a closed-form solution for the optimal merging coefficient that adapts to the diverse characteristics of tasks.","To validate our approach, we introduce a two-stage framework named BECAME, which synergizes the expertise of gradient projection and adaptive merging.","Extensive experiments show that our approach outperforms state-of-the-art CL methods and existing merging strategies."],"url":"http://arxiv.org/abs/2504.02666v1"}
{"created":"2025-04-03 15:05:57","title":"How humans evaluate AI systems for person detection in automatic train operation: Not all misses are alike","abstract":"If artificial intelligence (AI) is to be applied in safety-critical domains, its performance needs to be evaluated reliably. The present study aimed to understand how humans evaluate AI systems for person detection in automatic train operation. In three experiments, participants saw image sequences of people moving in the vicinity of railway tracks. A simulated AI had highlighted all detected people, sometimes correctly and sometimes not. Participants had to provide a numerical rating of the AI's performance and then verbally explain their rating. The experiments varied several factors that might influence human ratings: the types and plausibility of AI mistakes, the number of affected images, the number of people present in an image, the position of people relevant to the tracks, and the methods used to elicit human evaluations. While all these factors influenced human ratings, some effects were unexpected or deviated from normative standards. For instance, the factor with the strongest impact was people's position relative to the tracks, although participants had explicitly been instructed that the AI could not process such information. Taken together, the results suggest that humans may sometimes evaluate more than the AI's performance on the assigned task. Such mismatches between AI capabilities and human expectations should be taken into consideration when conducting safety audits of AI systems.","sentences":["If artificial intelligence (AI) is to be applied in safety-critical domains, its performance needs to be evaluated reliably.","The present study aimed to understand how humans evaluate AI systems for person detection in automatic train operation.","In three experiments, participants saw image sequences of people moving in the vicinity of railway tracks.","A simulated AI had highlighted all detected people, sometimes correctly and sometimes not.","Participants had to provide a numerical rating of the AI's performance and then verbally explain their rating.","The experiments varied several factors that might influence human ratings: the types and plausibility of AI mistakes, the number of affected images, the number of people present in an image, the position of people relevant to the tracks, and the methods used to elicit human evaluations.","While all these factors influenced human ratings, some effects were unexpected or deviated from normative standards.","For instance, the factor with the strongest impact was people's position relative to the tracks, although participants had explicitly been instructed that the AI could not process such information.","Taken together, the results suggest that humans may sometimes evaluate more than the AI's performance on the assigned task.","Such mismatches between AI capabilities and human expectations should be taken into consideration when conducting safety audits of AI systems."],"url":"http://arxiv.org/abs/2504.02664v1"}
{"created":"2025-04-03 15:03:08","title":"Development of Automated Data Quality Assessment and Evaluation Indices by Analytical Experience","abstract":"The societal need to leverage third-party data has driven the data-distribution market and increased the importance of data quality assessment (DQA) in data transactions between organizations. However, DQA requires expert knowledge of raw data and related data attributes, which hinders consensus-building in data purchasing. This study focused on the differences in DQAs between experienced and inexperienced data handlers. We performed two experiments: The first was a questionnaire survey involving 41 participants with varying levels of data-handling experience, who evaluated 12 data samples using 10 predefined indices with and without quality metadata generated by the automated tool. The second was an eye-tracking experiment to reveal the viewing behavior of participants during data evaluation. It was revealed that using quality metadata generated by the automated tool can reduce misrecognition in DQA. While experienced data handlers rated the quality metadata highly, semi-experienced users gave it the lowest ratings. This study contributes to enhancing data understanding within organizations and promoting the distribution of valuable data by proposing an automated tool to support DQAs.","sentences":["The societal need to leverage third-party data has driven the data-distribution market and increased the importance of data quality assessment (DQA) in data transactions between organizations.","However, DQA requires expert knowledge of raw data and related data attributes, which hinders consensus-building in data purchasing.","This study focused on the differences in DQAs between experienced and inexperienced data handlers.","We performed two experiments: The first was a questionnaire survey involving 41 participants with varying levels of data-handling experience, who evaluated 12 data samples using 10 predefined indices with and without quality metadata generated by the automated tool.","The second was an eye-tracking experiment to reveal the viewing behavior of participants during data evaluation.","It was revealed that using quality metadata generated by the automated tool can reduce misrecognition in DQA.","While experienced data handlers rated the quality metadata highly, semi-experienced users gave it the lowest ratings.","This study contributes to enhancing data understanding within organizations and promoting the distribution of valuable data by proposing an automated tool to support DQAs."],"url":"http://arxiv.org/abs/2504.02663v1"}
{"created":"2025-04-03 15:00:04","title":"Integrating Human Knowledge Through Action Masking in Reinforcement Learning for Operations Research","abstract":"Reinforcement learning (RL) provides a powerful method to address problems in operations research. However, its real-world application often fails due to a lack of user acceptance and trust. A possible remedy is to provide managers with the possibility of altering the RL policy by incorporating human expert knowledge. In this study, we analyze the benefits and caveats of including human knowledge via action masking. While action masking has so far been used to exclude invalid actions, its ability to integrate human expertise remains underexplored. Human knowledge is often encapsulated in heuristics, which suggest reasonable, near-optimal actions in certain situations. Enforcing such actions should hence increase trust among the human workforce to rely on the model's decisions. Yet, a strict enforcement of heuristic actions may also restrict the policy from exploring superior actions, thereby leading to overall lower performance. We analyze the effects of action masking based on three problems with different characteristics, namely, paint shop scheduling, peak load management, and inventory management. Our findings demonstrate that incorporating human knowledge through action masking can achieve substantial improvements over policies trained without action masking. In addition, we find that action masking is crucial for learning effective policies in constrained action spaces, where certain actions can only be performed a limited number of times. Finally, we highlight the potential for suboptimal outcomes when action masks are overly restrictive.","sentences":["Reinforcement learning (RL) provides a powerful method to address problems in operations research.","However, its real-world application often fails due to a lack of user acceptance and trust.","A possible remedy is to provide managers with the possibility of altering the RL policy by incorporating human expert knowledge.","In this study, we analyze the benefits and caveats of including human knowledge via action masking.","While action masking has so far been used to exclude invalid actions, its ability to integrate human expertise remains underexplored.","Human knowledge is often encapsulated in heuristics, which suggest reasonable, near-optimal actions in certain situations.","Enforcing such actions should hence increase trust among the human workforce to rely on the model's decisions.","Yet, a strict enforcement of heuristic actions may also restrict the policy from exploring superior actions, thereby leading to overall lower performance.","We analyze the effects of action masking based on three problems with different characteristics, namely, paint shop scheduling, peak load management, and inventory management.","Our findings demonstrate that incorporating human knowledge through action masking can achieve substantial improvements over policies trained without action masking.","In addition, we find that action masking is crucial for learning effective policies in constrained action spaces, where certain actions can only be performed a limited number of times.","Finally, we highlight the potential for suboptimal outcomes when action masks are overly restrictive."],"url":"http://arxiv.org/abs/2504.02662v1"}
{"created":"2025-04-03 14:54:17","title":"MiLo: Efficient Quantized MoE Inference with Mixture of Low-Rank Compensators","abstract":"A critical approach for efficiently deploying Mixture-of-Experts (MoE) models with massive parameters is quantization. However, state-of-the-art MoE models suffer from non-negligible accuracy loss with extreme quantization, such as under 4 bits. To address this, we introduce MiLo, a novel method that augments highly quantized MoEs with a mixture of low-rank compensators. These compensators consume only a small amount of additional memory but significantly recover accuracy loss from extreme quantization. MiLo also identifies that MoEmodels exhibit distinctive characteristics across weights due to their hybrid dense-sparse architectures, and employs adaptive rank selection policies along with iterative optimizations to close the accuracy gap. MiLo does not rely on calibration data, allowing it to generalize to different MoE models and datasets without overfitting to a calibration set. To avoid the hardware inefficiencies of extreme quantization, such as 3-bit, MiLo develops Tensor Core-friendly 3-bit kernels, enabling measured latency speedups on 3-bit quantized MoE models. Our evaluation shows that MiLo outperforms existing methods on SoTA MoE models across various tasks.","sentences":["A critical approach for efficiently deploying Mixture-of-Experts (MoE) models with massive parameters is quantization.","However, state-of-the-art MoE models suffer from non-negligible accuracy loss with extreme quantization, such as under 4 bits.","To address this, we introduce MiLo, a novel method that augments highly quantized MoEs with a mixture of low-rank compensators.","These compensators consume only a small amount of additional memory but significantly recover accuracy loss from extreme quantization.","MiLo also identifies that MoEmodels exhibit distinctive characteristics across weights due to their hybrid dense-sparse architectures, and employs adaptive rank selection policies along with iterative optimizations to close the accuracy gap.","MiLo does not rely on calibration data, allowing it to generalize to different MoE models and datasets without overfitting to a calibration set.","To avoid the hardware inefficiencies of extreme quantization, such as 3-bit, MiLo develops Tensor Core-friendly 3-bit kernels, enabling measured latency speedups on 3-bit quantized MoE models.","Our evaluation shows that MiLo outperforms existing methods on SoTA MoE models across various tasks."],"url":"http://arxiv.org/abs/2504.02658v1"}
{"created":"2025-04-03 14:51:11","title":"SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning","abstract":"We propose a learning architecture that allows symbolic control and guidance in reinforcement learning with deep neural networks. We introduce SymDQN, a novel modular approach that augments the existing Dueling Deep Q-Networks (DuelDQN) architecture with modules based on the neuro-symbolic framework of Logic Tensor Networks (LTNs). The modules guide action policy learning and allow reinforcement learning agents to display behaviour consistent with reasoning about the environment. Our experiment is an ablation study performed on the modules. It is conducted in a reinforcement learning environment of a 5x5 grid navigated by an agent that encounters various shapes, each associated with a given reward. The underlying DuelDQN attempts to learn the optimal behaviour of the agent in this environment, while the modules facilitate shape recognition and reward prediction. We show that our architecture significantly improves learning, both in terms of performance and the precision of the agent. The modularity of SymDQN allows reflecting on the intricacies and complexities of combining neural and symbolic approaches in reinforcement learning.","sentences":["We propose a learning architecture that allows symbolic control and guidance in reinforcement learning with deep neural networks.","We introduce SymDQN, a novel modular approach that augments the existing Dueling Deep Q-Networks (DuelDQN) architecture with modules based on the neuro-symbolic framework of Logic Tensor Networks (LTNs).","The modules guide action policy learning and allow reinforcement learning agents to display behaviour consistent with reasoning about the environment.","Our experiment is an ablation study performed on the modules.","It is conducted in a reinforcement learning environment of a 5x5 grid navigated by an agent that encounters various shapes, each associated with a given reward.","The underlying DuelDQN attempts to learn the optimal behaviour of the agent in this environment, while the modules facilitate shape recognition and reward prediction.","We show that our architecture significantly improves learning, both in terms of performance and the precision of the agent.","The modularity of SymDQN allows reflecting on the intricacies and complexities of combining neural and symbolic approaches in reinforcement learning."],"url":"http://arxiv.org/abs/2504.02654v1"}
{"created":"2025-04-03 14:49:15","title":"Optimizing Resource Allocation to Mitigate the Risk of Disruptive Events in Homeland Security and Emergency Management","abstract":"Homeland security in the United States faces a daunting task due to the multiple threats and hazards that can occur. Natural disasters, human-caused incidents such as terrorist attacks, and technological failures can result in significant damage, fatalities, injuries, and economic losses. The increasing frequency and severity of disruptive events in the United States highlight the urgent need for effectively allocating resources in homeland security and emergency preparedness. This article presents an optimization-based decision support model to help homeland security policymakers identify and select projects that best mitigate the risk of threats and hazards while satisfying a budget constraint. The model incorporates multiple hazards, probabilistic risk assessments, and multidimensional consequences and integrates historical data and publicly available sources to evaluate and select the most effective risk mitigation projects and optimize resource allocation across various disaster scenarios. We apply this model to the state of Iowa, considering 16 hazards, six types of consequences, and 52 mitigation projects. Our results demonstrate how different budget levels influence project selection, emphasizing cost-effective solutions that maximize risk reduction. Sensitivity analysis examines the robustness of project selection under varying effectiveness assumptions and consequence estimations. The findings offer critical insights for policymakers in homeland security and emergency management and provide a basis for more efficient resource allocation and improved disaster resilience.","sentences":["Homeland security in the United States faces a daunting task due to the multiple threats and hazards that can occur.","Natural disasters, human-caused incidents such as terrorist attacks, and technological failures can result in significant damage, fatalities, injuries, and economic losses.","The increasing frequency and severity of disruptive events in the United States highlight the urgent need for effectively allocating resources in homeland security and emergency preparedness.","This article presents an optimization-based decision support model to help homeland security policymakers identify and select projects that best mitigate the risk of threats and hazards while satisfying a budget constraint.","The model incorporates multiple hazards, probabilistic risk assessments, and multidimensional consequences and integrates historical data and publicly available sources to evaluate and select the most effective risk mitigation projects and optimize resource allocation across various disaster scenarios.","We apply this model to the state of Iowa, considering 16 hazards, six types of consequences, and 52 mitigation projects.","Our results demonstrate how different budget levels influence project selection, emphasizing cost-effective solutions that maximize risk reduction.","Sensitivity analysis examines the robustness of project selection under varying effectiveness assumptions and consequence estimations.","The findings offer critical insights for policymakers in homeland security and emergency management and provide a basis for more efficient resource allocation and improved disaster resilience."],"url":"http://arxiv.org/abs/2504.02652v1"}
{"created":"2025-04-03 14:48:47","title":"Investigating Simple Drawings of $K_n$ using SAT","abstract":"We present a SAT framework which allows to investigate properties of simple drawings of the complete graph $K_n$ using the power of AI. In contrast to classic imperative programming, where a program is operated step by step, our framework models mathematical questions as Boolean formulas which are then solved using modern SAT solvers. Our framework for simple drawings is based on a characterization via rotation systems and finite forbidden substructures. We showcase its universality by addressing various open problems, reproving previous computational results and deriving several new computational results. In particular, we test and progress on several unavoidable configurations such as variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's conjecture on empty triangles, and crossing families for general simple drawings as well as for various subclasses. Moreover, based our computational results we propose some new challenging conjectures.","sentences":["We present a SAT framework which allows to investigate properties of simple drawings of the complete graph $K_n$ using the power of AI.","In contrast to classic imperative programming, where a program is operated step by step, our framework models mathematical questions as Boolean formulas which are then solved using modern SAT solvers.","Our framework for simple drawings is based on a characterization via rotation systems and finite forbidden substructures.","We showcase its universality by addressing various open problems, reproving previous computational results and deriving several new computational results.","In particular, we test and progress on several unavoidable configurations such as variants of Rafla's conjecture on plane Hamiltonian cycles, Harborth's conjecture on empty triangles, and crossing families for general simple drawings as well as for various subclasses.","Moreover, based our computational results we propose some new challenging conjectures."],"url":"http://arxiv.org/abs/2504.02650v1"}
{"created":"2025-04-03 14:37:40","title":"Solving the Paint Shop Problem with Flexible Management of Multi-Lane Buffers Using Reinforcement Learning and Action Masking","abstract":"In the paint shop problem, an unordered incoming sequence of cars assigned to different colors has to be reshuffled with the objective of minimizing the number of color changes. To reshuffle the incoming sequence, manufacturers can employ a first-in-first-out multi-lane buffer system allowing store and retrieve operations. So far, prior studies primarily focused on simple decision heuristics like greedy or simplified problem variants that do not allow full flexibility when performing store and retrieve operations. In this study, we propose a reinforcement learning approach to minimize color changes for the flexible problem variant, where store and retrieve operations can be performed in an arbitrary order. After proving that greedy retrieval is optimal, we incorporate this finding into the model using action masking. Our evaluation, based on 170 problem instances with 2-8 buffer lanes and 5-15 colors, shows that our approach reduces color changes compared to existing methods by considerable margins depending on the problem size. Furthermore, we demonstrate the robustness of our approach towards different buffer sizes and imbalanced color distributions.","sentences":["In the paint shop problem, an unordered incoming sequence of cars assigned to different colors has to be reshuffled with the objective of minimizing the number of color changes.","To reshuffle the incoming sequence, manufacturers can employ a first-in-first-out multi-lane buffer system allowing store and retrieve operations.","So far, prior studies primarily focused on simple decision heuristics like greedy or simplified problem variants that do not allow full flexibility when performing store and retrieve operations.","In this study, we propose a reinforcement learning approach to minimize color changes for the flexible problem variant, where store and retrieve operations can be performed in an arbitrary order.","After proving that greedy retrieval is optimal, we incorporate this finding into the model using action masking.","Our evaluation, based on 170 problem instances with 2-8 buffer lanes and 5-15 colors, shows that our approach reduces color changes compared to existing methods by considerable margins depending on the problem size.","Furthermore, we demonstrate the robustness of our approach towards different buffer sizes and imbalanced color distributions."],"url":"http://arxiv.org/abs/2504.02644v1"}
{"created":"2025-04-03 14:36:08","title":"RoSMM: A Robust and Secure Multi-Modal Watermarking Framework for Diffusion Models","abstract":"Current image watermarking technologies are predominantly categorized into text watermarking techniques and image steganography; however, few methods can simultaneously handle text and image-based watermark data, which limits their applicability in complex digital environments. This paper introduces an innovative multi-modal watermarking approach, drawing on the concept of vector discretization in encoder-based vector quantization. By constructing adjacency matrices, the proposed method enables the transformation of text watermarks into robust image-based representations, providing a novel multi-modal watermarking paradigm for image generation applications. Additionally, this study presents a newly designed image restoration module to mitigate image degradation caused by transmission losses and various noise interferences, thereby ensuring the reliability and integrity of the watermark. Experimental results validate the robustness of the method under multiple noise attacks, providing a secure, scalable, and efficient solution for digital image copyright protection.","sentences":["Current image watermarking technologies are predominantly categorized into text watermarking techniques and image steganography; however, few methods can simultaneously handle text and image-based watermark data, which limits their applicability in complex digital environments.","This paper introduces an innovative multi-modal watermarking approach, drawing on the concept of vector discretization in encoder-based vector quantization.","By constructing adjacency matrices, the proposed method enables the transformation of text watermarks into robust image-based representations, providing a novel multi-modal watermarking paradigm for image generation applications.","Additionally, this study presents a newly designed image restoration module to mitigate image degradation caused by transmission losses and various noise interferences, thereby ensuring the reliability and integrity of the watermark.","Experimental results validate the robustness of the method under multiple noise attacks, providing a secure, scalable, and efficient solution for digital image copyright protection."],"url":"http://arxiv.org/abs/2504.02640v1"}
{"created":"2025-04-03 14:34:51","title":"Reservoir Computing: A New Paradigm for Neural Networks","abstract":"A Literature Review of Reservoir Computing.   Even before Artificial Intelligence was its own field of computational science, humanity has tried to mimic the activity of the human brain. In the early 1940s the first artificial neuron models were created as purely mathematical concepts. Over the years, ideas from neuroscience and computer science were used to develop the modern Neural Network. The interest in these models rose quickly but fell when they failed to be successfully applied to practical applications, and rose again in the late 2000s with the drastic increase in computing power, notably in the field of natural language processing, for example with the state-of-the-art speech recognizer making heavy use of deep neural networks.   Recurrent Neural Networks (RNNs), a class of neural networks with cycles in the network, exacerbates the difficulties of traditional neural nets. Slow convergence limiting the use to small networks, and difficulty to train through gradient-descent methods because of the recurrent dynamics have hindered research on RNNs, yet their biological plausibility and their capability to model dynamical systems over simple functions makes then interesting for computational researchers.   Reservoir Computing emerges as a solution to these problems that RNNs traditionally face. Promising to be both theoretically sound and computationally fast, Reservoir Computing has already been applied successfully to numerous fields: natural language processing, computational biology and neuroscience, robotics, even physics. This survey will explore the history and appeal of both traditional feed-forward and recurrent neural networks, before describing the theory and models of this new reservoir computing paradigm. Finally recent papers using reservoir computing in a variety of scientific fields will be reviewed.","sentences":["A Literature Review of Reservoir Computing.   ","Even before Artificial Intelligence was its own field of computational science, humanity has tried to mimic the activity of the human brain.","In the early 1940s the first artificial neuron models were created as purely mathematical concepts.","Over the years, ideas from neuroscience and computer science were used to develop the modern Neural Network.","The interest in these models rose quickly but fell when they failed to be successfully applied to practical applications, and rose again in the late 2000s with the drastic increase in computing power, notably in the field of natural language processing, for example with the state-of-the-art speech recognizer making heavy use of deep neural networks.   ","Recurrent Neural Networks (RNNs), a class of neural networks with cycles in the network, exacerbates the difficulties of traditional neural nets.","Slow convergence limiting the use to small networks, and difficulty to train through gradient-descent methods because of the recurrent dynamics have hindered research on RNNs, yet their biological plausibility and their capability to model dynamical systems over simple functions makes then interesting for computational researchers.   ","Reservoir Computing emerges as a solution to these problems that RNNs traditionally face.","Promising to be both theoretically sound and computationally fast, Reservoir Computing has already been applied successfully to numerous fields: natural language processing, computational biology and neuroscience, robotics, even physics.","This survey will explore the history and appeal of both traditional feed-forward and recurrent neural networks, before describing the theory and models of this new reservoir computing paradigm.","Finally recent papers using reservoir computing in a variety of scientific fields will be reviewed."],"url":"http://arxiv.org/abs/2504.02639v1"}
{"created":"2025-04-03 14:34:38","title":"Medium Access for Push-Pull Data Transmission in 6G Wireless Systems","abstract":"Medium access in 5G systems was tailored to accommodate diverse traffic classes through network resource slicing. 6G wireless systems are expected to be significantly reliant on Artificial Intelligence (AI), leading to data-driven and goal-oriented communication. This leads to augmentation of the design space for Medium Access Control (MAC) protocols, which is the focus of this article. We introduce a taxonomy based on push-based and pull-based communication, which is useful to categorize both the legacy and the AI-driven access schemes. We provide MAC protocol design guidelines for pull- and push-based communication in terms of goal-oriented criteria, such as timing and data relevance. We articulate a framework for co-existence between pull and push-based communications in 6G systems, combining their advantages. We highlight the design principles and main tradeoffs, as well as the architectural considerations for integrating these designs in Open-Radio Access Network (O-RAN) and 6G systems.","sentences":["Medium access in 5G systems was tailored to accommodate diverse traffic classes through network resource slicing.","6G wireless systems are expected to be significantly reliant on Artificial Intelligence (AI), leading to data-driven and goal-oriented communication.","This leads to augmentation of the design space for Medium Access Control (MAC) protocols, which is the focus of this article.","We introduce a taxonomy based on push-based and pull-based communication, which is useful to categorize both the legacy and the AI-driven access schemes.","We provide MAC protocol design guidelines for pull- and push-based communication in terms of goal-oriented criteria, such as timing and data relevance.","We articulate a framework for co-existence between pull and push-based communications in 6G systems, combining their advantages.","We highlight the design principles and main tradeoffs, as well as the architectural considerations for integrating these designs in Open-Radio Access Network (O-RAN) and 6G systems."],"url":"http://arxiv.org/abs/2504.02637v1"}
{"created":"2025-04-03 14:33:35","title":"A Framework for Developing University Policies on Generative AI Governance: A Cross-national Comparative Study","abstract":"As generative artificial intelligence (GAI) becomes more integrated into higher education and research, universities adopt varied approaches to GAI policy development. To explore these variations, this study conducts a comparative analysis of leading universities in the United States, Japan, and China, examining their institution-wide policies on GAI application and governance. Based on these findings, the study proposes a University Policy Development Framework for GAI (UPDF-GAI) to provide both theoretical insights and practical guidance for universities in developing and refining their GAI policies. A qualitative content analysis of 124 policy documents from 110 universities was conducted, employing thematic coding to synthesize 20 key themes and 9 sub-themes. These themes and sub-themes formed the basis for developing the framework. The analysis reveals varying priorities and focus of GAI policy of universities in different countries. U.S. universities emphasize faculty autonomy, practical application, and policy adaptability, shaped by cutting-edge research and peer collaboration. Japanese universities take a government-regulated approach, prioritizing ethics and risk management, but provide limited support for AI implementation and flexibility. Chinese universities follow a centralized, government-led model, focusing on technology application over early policy development, while actively exploring GAI integration in education and research. The UPDF-GAI framework offers a systematic, adaptable framework for assessing and optimizing GAI policies across different educational contexts. By identifying key policy characteristics, enhancing policy effectiveness, and balancing technology, ethics, and education, enabling universities to develop sustainable, contextually relevant policies that strengthen their digital competitiveness and institutional readiness for AI-driven education.","sentences":["As generative artificial intelligence (GAI) becomes more integrated into higher education and research, universities adopt varied approaches to GAI policy development.","To explore these variations, this study conducts a comparative analysis of leading universities in the United States, Japan, and China, examining their institution-wide policies on GAI application and governance.","Based on these findings, the study proposes a University Policy Development Framework for GAI (UPDF-GAI) to provide both theoretical insights and practical guidance for universities in developing and refining their GAI policies.","A qualitative content analysis of 124 policy documents from 110 universities was conducted, employing thematic coding to synthesize 20 key themes and 9 sub-themes.","These themes and sub-themes formed the basis for developing the framework.","The analysis reveals varying priorities and focus of GAI policy of universities in different countries.","U.S. universities emphasize faculty autonomy, practical application, and policy adaptability, shaped by cutting-edge research and peer collaboration.","Japanese universities take a government-regulated approach, prioritizing ethics and risk management, but provide limited support for AI implementation and flexibility.","Chinese universities follow a centralized, government-led model, focusing on technology application over early policy development, while actively exploring GAI integration in education and research.","The UPDF-GAI framework offers a systematic, adaptable framework for assessing and optimizing GAI policies across different educational contexts.","By identifying key policy characteristics, enhancing policy effectiveness, and balancing technology, ethics, and education, enabling universities to develop sustainable, contextually relevant policies that strengthen their digital competitiveness and institutional readiness for AI-driven education."],"url":"http://arxiv.org/abs/2504.02636v1"}
{"created":"2025-04-03 14:31:20","title":"Data-Driven Design of 3GPP Handover Parameters with Bayesian Optimization and Transfer Learning","abstract":"Mobility management in dense cellular networks is challenging due to varying user speeds and deployment conditions. Traditional 3GPP handover (HO) schemes, relying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to balance radio link failures (RLFs) and ping-pongs. We propose a data-driven HO optimization framework based on high-dimensional Bayesian optimization (HD-BO) and enhanced with transfer learning to reduce training time and improve generalization across different user speeds. Evaluations on a real-world deployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while transfer learning enables rapid adaptation without loss in performance. This highlights the potential of data-driven, site-specific mobility management in large-scale networks.","sentences":["Mobility management in dense cellular networks is challenging due to varying user speeds and deployment conditions.","Traditional 3GPP handover (HO) schemes, relying on fixed A3-offset and time-to-trigger (TTT) parameters, struggle to balance radio link failures (RLFs) and ping-pongs.","We propose a data-driven HO optimization framework based on high-dimensional Bayesian optimization (HD-BO) and enhanced with transfer learning to reduce training time and improve generalization across different user speeds.","Evaluations on a real-world deployment show that HD-BO outperforms 3GPP set-1 and set-5 benchmarks, while transfer learning enables rapid adaptation without loss in performance.","This highlights the potential of data-driven, site-specific mobility management in large-scale networks."],"url":"http://arxiv.org/abs/2504.02633v1"}
{"created":"2025-04-03 14:28:13","title":"Grammar-based Ordinary Differential Equation Discovery","abstract":"The understanding and modeling of complex physical phenomena through dynamical systems has historically driven scientific progress, as it provides the tools for predicting the behavior of different systems under diverse conditions through time. The discovery of dynamical systems has been indispensable in engineering, as it allows for the analysis and prediction of complex behaviors for computational modeling, diagnostics, prognostics, and control of engineered systems. Joining recent efforts that harness the power of symbolic regression in this domain, we propose a novel framework for the end-to-end discovery of ordinary differential equations (ODEs), termed Grammar-based ODE Discovery Engine (GODE). The proposed methodology combines formal grammars with dimensionality reduction and stochastic search for efficiently navigating high-dimensional combinatorial spaces. Grammars allow us to seed domain knowledge and structure for both constraining, as well as, exploring the space of candidate expressions. GODE proves to be more sample- and parameter-efficient than state-of-the-art transformer-based models and to discover more accurate and parsimonious ODE expressions than both genetic programming- and other grammar-based methods for more complex inference tasks, such as the discovery of structural dynamics. Thus, we introduce a tool that could play a catalytic role in dynamics discovery tasks, including modeling, system identification, and monitoring tasks.","sentences":["The understanding and modeling of complex physical phenomena through dynamical systems has historically driven scientific progress, as it provides the tools for predicting the behavior of different systems under diverse conditions through time.","The discovery of dynamical systems has been indispensable in engineering, as it allows for the analysis and prediction of complex behaviors for computational modeling, diagnostics, prognostics, and control of engineered systems.","Joining recent efforts that harness the power of symbolic regression in this domain, we propose a novel framework for the end-to-end discovery of ordinary differential equations (ODEs), termed Grammar-based ODE Discovery Engine (GODE).","The proposed methodology combines formal grammars with dimensionality reduction and stochastic search for efficiently navigating high-dimensional combinatorial spaces.","Grammars allow us to seed domain knowledge and structure for both constraining, as well as, exploring the space of candidate expressions.","GODE proves to be more sample-","and parameter-efficient than state-of-the-art transformer-based models and to discover more accurate and parsimonious ODE expressions than both genetic programming- and other grammar-based methods for more complex inference tasks, such as the discovery of structural dynamics.","Thus, we introduce a tool that could play a catalytic role in dynamics discovery tasks, including modeling, system identification, and monitoring tasks."],"url":"http://arxiv.org/abs/2504.02630v1"}
