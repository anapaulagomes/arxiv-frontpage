{"created":"2024-07-16 17:59:55","title":"Does Refusal Training in LLMs Generalize to the Past Tense?","abstract":"Refusal training is widely used to prevent LLMs from generating harmful, undesirable, or illegal outputs. We reveal a curious generalization gap in the current refusal training approaches: simply reformulating a harmful request in the past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make a Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art LLMs. We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For example, the success rate of this simple attack on GPT-4o increases from 1% using direct requests to 88% using 20 past tense reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a jailbreak judge. Interestingly, we also find that reformulations in the future tense are less effective, suggesting that refusal guardrails tend to consider past historical questions more benign than hypothetical future questions. Moreover, our experiments on fine-tuning GPT-3.5 Turbo show that defending against past reformulations is feasible when past tense examples are explicitly included in the fine-tuning data. Overall, our findings highlight that the widely used alignment techniques -- such as SFT, RLHF, and adversarial training -- employed to align the studied models can be brittle and do not always generalize as intended. We provide code and jailbreak artifacts at https://github.com/tml-epfl/llm-past-tense.","sentences":["Refusal training is widely used to prevent LLMs from generating harmful, undesirable, or illegal outputs.","We reveal a curious generalization gap in the current refusal training approaches: simply reformulating a harmful request in the past tense (e.g., \"How to make a Molotov cocktail?\" to \"How did people make a Molotov cocktail?\") is often sufficient to jailbreak many state-of-the-art LLMs.","We systematically evaluate this method on Llama-3 8B, GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o, and R2D2 models using GPT-3.5 Turbo as a reformulation model.","For example, the success rate of this simple attack on GPT-4o increases from 1% using direct requests to 88% using 20 past tense reformulation attempts on harmful requests from JailbreakBench with GPT-4 as a jailbreak judge.","Interestingly, we also find that reformulations in the future tense are less effective, suggesting that refusal guardrails tend to consider past historical questions more benign than hypothetical future questions.","Moreover, our experiments on fine-tuning GPT-3.5","Turbo show that defending against past reformulations is feasible when past tense examples are explicitly included in the fine-tuning data.","Overall, our findings highlight that the widely used alignment techniques -- such as SFT, RLHF, and adversarial training -- employed to align the studied models can be brittle and do not always generalize as intended.","We provide code and jailbreak artifacts at https://github.com/tml-epfl/llm-past-tense."],"url":"http://arxiv.org/abs/2407.11969v1"}
{"created":"2024-07-16 17:59:46","title":"Hydra: Brokering Cloud and HPC Resources to Support the Execution of Heterogeneous Workloads at Scale","abstract":"Scientific discovery increasingly depends on middleware that enables the execution of heterogeneous workflows on heterogeneous platforms One of the main challenges is to design software components that integrate within the existing ecosystem to enable scale and performance across cloud and high-performance computing HPC platforms Researchers are met with a varied computing landscape which includes services available on commercial cloud platforms data and network capabilities specifically designed for scientific discovery on government-sponsored cloud platforms and scale and performance on HPC platforms We present Hydra an intra cross-cloud HPC brokering system capable of concurrently acquiring resources from commercial private cloud and HPC platforms and managing the execution of heterogeneous workflow applications on those resources This paper offers four main contributions (1) the design of brokering capabilities in the presence of task platform resource and middleware heterogeneity; (2) a reference implementation of that design with Hydra; (3) an experimental characterization of Hydra s overheads and strong weak scaling with heterogeneous workloads and platforms and, (4) the implementation of a workflow that models sea rise with Hydra and its scaling on cloud and HPC platforms","sentences":["Scientific discovery increasingly depends on middleware that enables the execution of heterogeneous workflows on heterogeneous platforms One of the main challenges is to design software components that integrate within the existing ecosystem to enable scale and performance across cloud and high-performance computing HPC platforms Researchers are met with a varied computing landscape which includes services available on commercial cloud platforms data and network capabilities specifically designed for scientific discovery on government-sponsored cloud platforms and scale and performance on HPC platforms We present Hydra an intra cross-cloud HPC brokering system capable of concurrently acquiring resources from commercial private cloud and HPC platforms and managing the execution of heterogeneous workflow applications on those resources This paper offers four main contributions (1) the design of brokering capabilities in the presence of task platform resource and middleware heterogeneity; (2) a reference implementation of that design with Hydra; (3) an experimental characterization of Hydra s overheads and strong weak scaling with heterogeneous workloads and platforms and, (4) the implementation of a workflow that models sea rise with Hydra and its scaling on cloud and HPC platforms"],"url":"http://arxiv.org/abs/2407.11967v1"}
{"created":"2024-07-16 17:59:42","title":"Efficient Training with Denoised Neural Weights","abstract":"Good weight initialization serves as an effective measure to reduce the training cost of a deep neural network (DNN) model. The choice of how to initialize parameters is challenging and may require manual tuning, which can be time-consuming and prone to human error. To overcome such limitations, this work takes a novel step towards building a weight generator to synthesize the neural weights for initialization. We use the image-to-image translation task with generative adversarial networks (GANs) as an example due to the ease of collecting model weights spanning a wide range. Specifically, we first collect a dataset with various image editing concepts and their corresponding trained weights, which are later used for the training of the weight generator. To address the different characteristics among layers and the substantial number of weights to be predicted, we divide the weights into equal-sized blocks and assign each block an index. Subsequently, a diffusion model is trained with such a dataset using both text conditions of the concept and the block indexes. By initializing the image translation model with the denoised weights predicted by our diffusion model, the training requires only 43.3 seconds. Compared to training from scratch (i.e., Pix2pix), we achieve a 15x training time acceleration for a new concept while obtaining even better image generation quality.","sentences":["Good weight initialization serves as an effective measure to reduce the training cost of a deep neural network (DNN) model.","The choice of how to initialize parameters is challenging and may require manual tuning, which can be time-consuming and prone to human error.","To overcome such limitations, this work takes a novel step towards building a weight generator to synthesize the neural weights for initialization.","We use the image-to-image translation task with generative adversarial networks (GANs) as an example due to the ease of collecting model weights spanning a wide range.","Specifically, we first collect a dataset with various image editing concepts and their corresponding trained weights, which are later used for the training of the weight generator.","To address the different characteristics among layers and the substantial number of weights to be predicted, we divide the weights into equal-sized blocks and assign each block an index.","Subsequently, a diffusion model is trained with such a dataset using both text conditions of the concept and the block indexes.","By initializing the image translation model with the denoised weights predicted by our diffusion model, the training requires only 43.3 seconds.","Compared to training from scratch (i.e., Pix2pix), we achieve a 15x training time acceleration for a new concept while obtaining even better image generation quality."],"url":"http://arxiv.org/abs/2407.11966v1"}
{"created":"2024-07-16 17:59:29","title":"UrbanWorld: An Urban World Model for 3D City Generation","abstract":"Cities, as the most fundamental environment of human life, encompass diverse physical elements such as buildings, roads and vegetation with complex interconnection. Crafting realistic, interactive 3D urban environments plays a crucial role in constructing AI agents capable of perceiving, decision-making, and acting like humans in real-world environments. However, creating high-fidelity 3D urban environments usually entails extensive manual labor from designers, involving intricate detailing and accurate representation of complex urban features. Therefore, how to accomplish this in an automatical way remains a longstanding challenge. Toward this problem, we propose UrbanWorld, the first generative urban world model that can automatically create a customized, realistic and interactive 3D urban world with flexible control conditions. UrbanWorld incorporates four key stages in the automatical crafting pipeline: 3D layout generation from openly accessible OSM data, urban scene planning and designing with a powerful urban multimodal large language model (Urban MLLM), controllable urban asset rendering with advanced 3D diffusion techniques, and finally the MLLM-assisted scene refinement. The crafted high-fidelity 3D urban environments enable realistic feedback and interactions for general AI and machine perceptual systems in simulations. We are working on contributing UrbanWorld as an open-source and versatile platform for evaluating and improving AI abilities in perception, decision-making, and interaction in realistic urban environments.","sentences":["Cities, as the most fundamental environment of human life, encompass diverse physical elements such as buildings, roads and vegetation with complex interconnection.","Crafting realistic, interactive 3D urban environments plays a crucial role in constructing AI agents capable of perceiving, decision-making, and acting like humans in real-world environments.","However, creating high-fidelity 3D urban environments usually entails extensive manual labor from designers, involving intricate detailing and accurate representation of complex urban features.","Therefore, how to accomplish this in an automatical way remains a longstanding challenge.","Toward this problem, we propose UrbanWorld, the first generative urban world model that can automatically create a customized, realistic and interactive 3D urban world with flexible control conditions.","UrbanWorld incorporates four key stages in the automatical crafting pipeline: 3D layout generation from openly accessible OSM data, urban scene planning and designing with a powerful urban multimodal large language model (Urban MLLM), controllable urban asset rendering with advanced 3D diffusion techniques, and finally the MLLM-assisted scene refinement.","The crafted high-fidelity 3D urban environments enable realistic feedback and interactions for general AI and machine perceptual systems in simulations.","We are working on contributing UrbanWorld as an open-source and versatile platform for evaluating and improving AI abilities in perception, decision-making, and interaction in realistic urban environments."],"url":"http://arxiv.org/abs/2407.11965v1"}
{"created":"2024-07-16 17:59:06","title":"NeedleBench: Can LLMs Do Retrieval and Reasoning in 1 Million Context Window?","abstract":"In evaluating the long-context capabilities of large language models (LLMs), identifying content relevant to a user's query from original long documents is a crucial prerequisite for any LLM to answer questions based on long text. We present NeedleBench, a framework consisting of a series of progressively more challenging tasks for assessing bilingual long-context capabilities, spanning multiple length intervals (4k, 8k, 32k, 128k, 200k, 1000k, and beyond) and different depth ranges, allowing the strategic insertion of critical data points in different text depth zones to rigorously test the retrieval and reasoning capabilities of models in diverse contexts. We use the NeedleBench framework to assess how well the leading open-source models can identify key information relevant to the question and apply that information to reasoning in bilingual long texts. Furthermore, we propose the Ancestral Trace Challenge (ATC) to mimic the complexity of logical reasoning challenges that are likely to be present in real-world long-context tasks, providing a simple method for evaluating LLMs in dealing with complex long-context situations. Our results suggest that current LLMs have significant room for improvement in practical long-context applications, as they struggle with the complexity of logical reasoning challenges that are likely to be present in real-world long-context tasks. All codes and resources are available at OpenCompass: https://github.com/open-compass/opencompass.","sentences":["In evaluating the long-context capabilities of large language models (LLMs), identifying content relevant to a user's query from original long documents is a crucial prerequisite for any LLM to answer questions based on long text.","We present NeedleBench, a framework consisting of a series of progressively more challenging tasks for assessing bilingual long-context capabilities, spanning multiple length intervals (4k, 8k, 32k, 128k, 200k, 1000k, and beyond) and different depth ranges, allowing the strategic insertion of critical data points in different text depth zones to rigorously test the retrieval and reasoning capabilities of models in diverse contexts.","We use the NeedleBench framework to assess how well the leading open-source models can identify key information relevant to the question and apply that information to reasoning in bilingual long texts.","Furthermore, we propose the Ancestral Trace Challenge (ATC) to mimic the complexity of logical reasoning challenges that are likely to be present in real-world long-context tasks, providing a simple method for evaluating LLMs in dealing with complex long-context situations.","Our results suggest that current LLMs have significant room for improvement in practical long-context applications, as they struggle with the complexity of logical reasoning challenges that are likely to be present in real-world long-context tasks.","All codes and resources are available at OpenCompass: https://github.com/open-compass/opencompass."],"url":"http://arxiv.org/abs/2407.11963v1"}
{"created":"2024-07-16 17:59:01","title":"Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling","abstract":"This paper introduces Motion-oriented Compositional Neural Radiance Fields (MoCo-NeRF), a framework designed to perform free-viewpoint rendering of monocular human videos via novel non-rigid motion modeling approach. In the context of dynamic clothed humans, complex cloth dynamics generate non-rigid motions that are intrinsically distinct from skeletal articulations and critically important for the rendering quality. The conventional approach models non-rigid motions as spatial (3D) deviations in addition to skeletal transformations. However, it is either time-consuming or challenging to achieve optimal quality due to its high learning complexity without a direct supervision. To target this problem, we propose a novel approach of modeling non-rigid motions as radiance residual fields to benefit from more direct color supervision in the rendering and utilize the rigid radiance fields as a prior to reduce the complexity of the learning process. Our approach utilizes a single multiresolution hash encoding (MHE) to concurrently learn the canonical T-pose representation from rigid skeletal motions and the radiance residual field for non-rigid motions. Additionally, to further improve both training efficiency and usability, we extend MoCo-NeRF to support simultaneous training of multiple subjects within a single framework, thanks to our effective design for modeling non-rigid motions. This scalability is achieved through the integration of a global MHE and learnable identity codes in addition to multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap, clearly demonstrating state-of-the-art performance in both single- and multi-subject settings. The code and model will be made publicly available at the project page: https://stevejaehyeok.github.io/publications/moco-nerf.","sentences":["This paper introduces Motion-oriented Compositional Neural Radiance Fields (MoCo-NeRF), a framework designed to perform free-viewpoint rendering of monocular human videos via novel non-rigid motion modeling approach.","In the context of dynamic clothed humans, complex cloth dynamics generate non-rigid motions that are intrinsically distinct from skeletal articulations and critically important for the rendering quality.","The conventional approach models non-rigid motions as spatial (3D) deviations in addition to skeletal transformations.","However, it is either time-consuming or challenging to achieve optimal quality due to its high learning complexity without a direct supervision.","To target this problem, we propose a novel approach of modeling non-rigid motions as radiance residual fields to benefit from more direct color supervision in the rendering and utilize the rigid radiance fields as a prior to reduce the complexity of the learning process.","Our approach utilizes a single multiresolution hash encoding (MHE) to concurrently learn the canonical T-pose representation from rigid skeletal motions and the radiance residual field for non-rigid motions.","Additionally, to further improve both training efficiency and usability, we extend MoCo-NeRF to support simultaneous training of multiple subjects within a single framework, thanks to our effective design for modeling non-rigid motions.","This scalability is achieved through the integration of a global MHE and learnable identity codes in addition to multiple local MHEs.","We present extensive results on ZJU-MoCap and MonoCap, clearly demonstrating state-of-the-art performance in both single- and multi-subject settings.","The code and model will be made publicly available at the project page: https://stevejaehyeok.github.io/publications/moco-nerf."],"url":"http://arxiv.org/abs/2407.11962v1"}
{"created":"2024-07-16 17:54:48","title":"Faster Algorithms for Schatten-p Low Rank Approximation","abstract":"We study algorithms for the Schatten-$p$ Low Rank Approximation (LRA) problem. First, we show that by using fast rectangular matrix multiplication algorithms and different block sizes, we can improve the running time of the algorithms in the recent work of Bakshi, Clarkson and Woodruff (STOC 2022). We then show that by carefully combining our new algorithm with the algorithm of Li and Woodruff (ICML 2020), we can obtain even faster algorithms for Schatten-$p$ LRA.   While the block-based algorithms are fast in the real number model, we do not have a stability analysis which shows that the algorithms work when implemented on a machine with polylogarithmic bits of precision. We show that the LazySVD algorithm of Allen-Zhu and Li (NeurIPS 2016) can be implemented on a floating point machine with only logarithmic, in the input parameters, bits of precision. As far as we are aware, this is the first stability analysis of any algorithm using $O((k/\\sqrt{\\varepsilon})\\text{poly}(\\log n))$ matrix-vector products with the matrix $A$ to output a $1+\\varepsilon$ approximate solution for the rank-$k$ Schatten-$p$ LRA problem.","sentences":["We study algorithms for the Schatten-$p$ Low Rank Approximation (LRA) problem.","First, we show that by using fast rectangular matrix multiplication algorithms and different block sizes, we can improve the running time of the algorithms in the recent work of Bakshi, Clarkson and Woodruff (STOC 2022).","We then show that by carefully combining our new algorithm with the algorithm of Li and Woodruff (ICML 2020), we can obtain even faster algorithms for Schatten-$p$ LRA.   ","While the block-based algorithms are fast in the real number model, we do not have a stability analysis which shows that the algorithms work when implemented on a machine with polylogarithmic bits of precision.","We show that the LazySVD algorithm of Allen-Zhu and Li (NeurIPS 2016) can be implemented on a floating point machine with only logarithmic, in the input parameters, bits of precision.","As far as we are aware, this is the first stability analysis of any algorithm using $O((k/\\sqrt{\\varepsilon})\\text{poly}(\\log n))$ matrix-vector products with the matrix $A$ to output a $1+\\varepsilon$ approximate solution for the rank-$k$ Schatten-$p$ LRA problem."],"url":"http://arxiv.org/abs/2407.11959v1"}
{"created":"2024-07-16 17:48:44","title":"A Transformer-based Approach for Augmenting Software Engineering Chatbots Datasets","abstract":"Background: The adoption of chatbots into software development tasks has become increasingly popular among practitioners, driven by the advantages of cost reduction and acceleration of the software development process. Chatbots understand users' queries through the Natural Language Understanding component (NLU). To yield reasonable performance, NLUs have to be trained with extensive, high-quality datasets, that express a multitude of ways users may interact with chatbots. However, previous studies show that creating a high-quality training dataset for software engineering chatbots is expensive in terms of both resources and time. Aims: Therefore, in this paper, we present an automated transformer-based approach to augment software engineering chatbot datasets. Method: Our approach combines traditional natural language processing techniques with the BART transformer to augment a dataset by generating queries through synonym replacement and paraphrasing. We evaluate the impact of using the augmentation approach on the Rasa NLU's performance using three software engineering datasets. Results: Overall, the augmentation approach shows promising results in improving the Rasa's performance, augmenting queries with varying sentence structures while preserving their original semantics. Furthermore, it increases Rasa's confidence in its intent classification for the correctly classified intents. Conclusions: We believe that our study helps practitioners improve the performance of their chatbots and guides future research to propose augmentation techniques for SE chatbots.","sentences":["Background: The adoption of chatbots into software development tasks has become increasingly popular among practitioners, driven by the advantages of cost reduction and acceleration of the software development process.","Chatbots understand users' queries through the Natural Language Understanding component (NLU).","To yield reasonable performance, NLUs have to be trained with extensive, high-quality datasets, that express a multitude of ways users may interact with chatbots.","However, previous studies show that creating a high-quality training dataset for software engineering chatbots is expensive in terms of both resources and time.","Aims:","Therefore, in this paper, we present an automated transformer-based approach to augment software engineering chatbot datasets.","Method: Our approach combines traditional natural language processing techniques with the BART transformer to augment a dataset by generating queries through synonym replacement and paraphrasing.","We evaluate the impact of using the augmentation approach on the Rasa NLU's performance using three software engineering datasets.","Results: Overall, the augmentation approach shows promising results in improving the Rasa's performance, augmenting queries with varying sentence structures while preserving their original semantics.","Furthermore, it increases Rasa's confidence in its intent classification for the correctly classified intents.","Conclusions: We believe that our study helps practitioners improve the performance of their chatbots and guides future research to propose augmentation techniques for SE chatbots."],"url":"http://arxiv.org/abs/2407.11955v1"}
{"created":"2024-07-16 17:48:05","title":"Gated Temporal Diffusion for Stochastic Long-Term Dense Anticipation","abstract":"Long-term action anticipation has become an important task for many applications such as autonomous driving and human-robot interaction. Unlike short-term anticipation, predicting more actions into the future imposes a real challenge with the increasing uncertainty in longer horizons. While there has been a significant progress in predicting more actions into the future, most of the proposed methods address the task in a deterministic setup and ignore the underlying uncertainty. In this paper, we propose a novel Gated Temporal Diffusion (GTD) network that models the uncertainty of both the observation and the future predictions. As generator, we introduce a Gated Anticipation Network (GTAN) to model both observed and unobserved frames of a video in a mutual representation. On the one hand, using a mutual representation for past and future allows us to jointly model ambiguities in the observation and future, while on the other hand GTAN can by design treat the observed and unobserved parts differently and steer the information flow between them. Our model achieves state-of-the-art results on the Breakfast, Assembly101 and 50Salads datasets in both stochastic and deterministic settings. Code: https://github.com/olga-zats/GTDA .","sentences":["Long-term action anticipation has become an important task for many applications such as autonomous driving and human-robot interaction.","Unlike short-term anticipation, predicting more actions into the future imposes a real challenge with the increasing uncertainty in longer horizons.","While there has been a significant progress in predicting more actions into the future, most of the proposed methods address the task in a deterministic setup and ignore the underlying uncertainty.","In this paper, we propose a novel Gated Temporal Diffusion (GTD) network that models the uncertainty of both the observation and the future predictions.","As generator, we introduce a Gated Anticipation Network (GTAN) to model both observed and unobserved frames of a video in a mutual representation.","On the one hand, using a mutual representation for past and future allows us to jointly model ambiguities in the observation and future, while on the other hand GTAN can by design treat the observed and unobserved parts differently and steer the information flow between them.","Our model achieves state-of-the-art results on the Breakfast, Assembly101 and 50Salads datasets in both stochastic and deterministic settings.","Code: https://github.com/olga-zats/GTDA ."],"url":"http://arxiv.org/abs/2407.11954v1"}
{"created":"2024-07-16 17:44:34","title":"Temporally Consistent Stereo Matching","abstract":"Stereo matching provides depth estimation from binocular images for downstream applications. These applications mostly take video streams as input and require temporally consistent depth maps. However, existing methods mainly focus on the estimation at the single-frame level. This commonly leads to temporally inconsistent results, especially in ill-posed regions. In this paper, we aim to leverage temporal information to improve the temporal consistency, accuracy, and efficiency of stereo matching. To achieve this, we formulate video stereo matching as a process of temporal disparity completion followed by continuous iterative refinements. Specifically, we first project the disparity of the previous timestamp to the current viewpoint, obtaining a semi-dense disparity map. Then, we complete this map through a disparity completion module to obtain a well-initialized disparity map. The state features from the current completion module and from the past refinement are fused together, providing a temporally coherent state for subsequent refinement. Based on this coherent state, we introduce a dual-space refinement module to iteratively refine the initialized result in both disparity and disparity gradient spaces, improving estimations in ill-posed regions. Extensive experiments demonstrate that our method effectively alleviates temporal inconsistency while enhancing both accuracy and efficiency.","sentences":["Stereo matching provides depth estimation from binocular images for downstream applications.","These applications mostly take video streams as input and require temporally consistent depth maps.","However, existing methods mainly focus on the estimation at the single-frame level.","This commonly leads to temporally inconsistent results, especially in ill-posed regions.","In this paper, we aim to leverage temporal information to improve the temporal consistency, accuracy, and efficiency of stereo matching.","To achieve this, we formulate video stereo matching as a process of temporal disparity completion followed by continuous iterative refinements.","Specifically, we first project the disparity of the previous timestamp to the current viewpoint, obtaining a semi-dense disparity map.","Then, we complete this map through a disparity completion module to obtain a well-initialized disparity map.","The state features from the current completion module and from the past refinement are fused together, providing a temporally coherent state for subsequent refinement.","Based on this coherent state, we introduce a dual-space refinement module to iteratively refine the initialized result in both disparity and disparity gradient spaces, improving estimations in ill-posed regions.","Extensive experiments demonstrate that our method effectively alleviates temporal inconsistency while enhancing both accuracy and efficiency."],"url":"http://arxiv.org/abs/2407.11950v1"}
{"created":"2024-07-16 17:42:37","title":"Rethinking Transformer-based Multi-document Summarization: An Empirical Investigation","abstract":"The utilization of Transformer-based models prospers the growth of multi-document summarization (MDS). Given the huge impact and widespread adoption of Transformer-based models in various natural language processing tasks, investigating their performance and behaviors in the context of MDS becomes crucial for advancing the field and enhancing the quality of summary. To thoroughly examine the behaviours of Transformer-based MDS models, this paper presents five empirical studies on (1) measuring the impact of document boundary separators quantitatively; (2) exploring the effectiveness of different mainstream Transformer structures; (3) examining the sensitivity of the encoder and decoder; (4) discussing different training strategies; and (5) discovering the repetition in a summary generation. The experimental results on prevalent MDS datasets and eleven evaluation metrics show the influence of document boundary separators, the granularity of different level features and different model training strategies. The results also reveal that the decoder exhibits greater sensitivity to noises compared to the encoder. This underscores the important role played by the decoder, suggesting a potential direction for future research in MDS. Furthermore, the experimental results indicate that the repetition problem in the generated summaries has correlations with the high uncertainty scores.","sentences":["The utilization of Transformer-based models prospers the growth of multi-document summarization (MDS).","Given the huge impact and widespread adoption of Transformer-based models in various natural language processing tasks, investigating their performance and behaviors in the context of MDS becomes crucial for advancing the field and enhancing the quality of summary.","To thoroughly examine the behaviours of Transformer-based MDS models, this paper presents five empirical studies on (1) measuring the impact of document boundary separators quantitatively; (2) exploring the effectiveness of different mainstream Transformer structures; (3) examining the sensitivity of the encoder and decoder; (4) discussing different training strategies; and (5) discovering the repetition in a summary generation.","The experimental results on prevalent MDS datasets and eleven evaluation metrics show the influence of document boundary separators, the granularity of different level features and different model training strategies.","The results also reveal that the decoder exhibits greater sensitivity to noises compared to the encoder.","This underscores the important role played by the decoder, suggesting a potential direction for future research in MDS.","Furthermore, the experimental results indicate that the repetition problem in the generated summaries has correlations with the high uncertainty scores."],"url":"http://arxiv.org/abs/2407.11948v1"}
{"created":"2024-07-16 17:35:59","title":"Hierarchical Separable Video Transformer for Snapshot Compressive Imaging","abstract":"Transformers have achieved the state-of-the-art performance on solving the inverse problem of Snapshot Compressive Imaging (SCI) for video, whose ill-posedness is rooted in the mixed degradation of spatial masking and temporal aliasing. However, previous Transformers lack an insight into the degradation and thus have limited performance and efficiency. In this work, we tailor an efficient reconstruction architecture without temporal aggregation in early layers and Hierarchical Separable Video Transformer (HiSViT) as building block. HiSViT is built by multiple groups of Cross-Scale Separable Multi-head Self-Attention (CSS-MSA) and Gated Self-Modulated Feed-Forward Network (GSM-FFN) with dense connections, each of which is conducted within a separate channel portions at a different scale, for multi-scale interactions and long-range modeling. By separating spatial operations from temporal ones, CSS-MSA introduces an inductive bias of paying more attention within frames instead of between frames while saving computational overheads. GSM-FFN is design to enhance the locality via gated mechanism and factorized spatial-temporal convolutions. Extensive experiments demonstrate that our method outperforms previous methods by $>\\!0.5$ dB with comparable or fewer complexity and parameters. The source codes and pretrained models are released at https://github.com/pwangcs/HiSViT.","sentences":["Transformers have achieved the state-of-the-art performance on solving the inverse problem of Snapshot Compressive Imaging (SCI) for video, whose ill-posedness is rooted in the mixed degradation of spatial masking and temporal aliasing.","However, previous Transformers lack an insight into the degradation and thus have limited performance and efficiency.","In this work, we tailor an efficient reconstruction architecture without temporal aggregation in early layers and Hierarchical Separable Video Transformer (HiSViT) as building block.","HiSViT is built by multiple groups of Cross-Scale Separable Multi-head Self-Attention (CSS-MSA) and Gated Self-Modulated Feed-Forward Network (GSM-FFN) with dense connections, each of which is conducted within a separate channel portions at a different scale, for multi-scale interactions and long-range modeling.","By separating spatial operations from temporal ones, CSS-MSA introduces an inductive bias of paying more attention within frames instead of between frames while saving computational overheads.","GSM-FFN is design to enhance the locality via gated mechanism and factorized spatial-temporal convolutions.","Extensive experiments demonstrate that our method outperforms previous methods by $>\\!0.5$ dB with comparable or fewer complexity and parameters.","The source codes and pretrained models are released at https://github.com/pwangcs/HiSViT."],"url":"http://arxiv.org/abs/2407.11946v1"}
{"created":"2024-07-16 17:29:24","title":"Beyond Spatial Explanations: Explainable Face Recognition in the Frequency Domain","abstract":"The need for more transparent face recognition (FR), along with other visual-based decision-making systems has recently attracted more attention in research, society, and industry. The reasons why two face images are matched or not matched by a deep learning-based face recognition system are not obvious due to the high number of parameters and the complexity of the models. However, it is important for users, operators, and developers to ensure trust and accountability of the system and to analyze drawbacks such as biased behavior. While many previous works use spatial semantic maps to highlight the regions that have a significant influence on the decision of the face recognition system, frequency components which are also considered by CNNs, are neglected. In this work, we take a step forward and investigate explainable face recognition in the unexplored frequency domain. This makes this work the first to propose explainability of verification-based decisions in the frequency domain, thus explaining the relative influence of the frequency components of each input toward the obtained outcome. To achieve this, we manipulate face images in the spatial frequency domain and investigate the impact on verification outcomes. In extensive quantitative experiments, along with investigating two special scenarios cases, cross-resolution FR and morphing attacks (the latter in supplementary material), we observe the applicability of our proposed frequency-based explanations.","sentences":["The need for more transparent face recognition (FR), along with other visual-based decision-making systems has recently attracted more attention in research, society, and industry.","The reasons why two face images are matched or not matched by a deep learning-based face recognition system are not obvious due to the high number of parameters and the complexity of the models.","However, it is important for users, operators, and developers to ensure trust and accountability of the system and to analyze drawbacks such as biased behavior.","While many previous works use spatial semantic maps to highlight the regions that have a significant influence on the decision of the face recognition system, frequency components which are also considered by CNNs, are neglected.","In this work, we take a step forward and investigate explainable face recognition in the unexplored frequency domain.","This makes this work the first to propose explainability of verification-based decisions in the frequency domain, thus explaining the relative influence of the frequency components of each input toward the obtained outcome.","To achieve this, we manipulate face images in the spatial frequency domain and investigate the impact on verification outcomes.","In extensive quantitative experiments, along with investigating two special scenarios cases, cross-resolution FR and morphing attacks (the latter in supplementary material), we observe the applicability of our proposed frequency-based explanations."],"url":"http://arxiv.org/abs/2407.11941v1"}
{"created":"2024-07-16 17:26:50","title":"Thermal Imaging and Radar for Remote Sleep Monitoring of Breathing and Apnea","abstract":"Polysomnography (PSG), the current gold standard method for monitoring and detecting sleep disorders, is cumbersome and costly. At-home testing solutions, known as home sleep apnea testing (HSAT), exist. However, they are contact-based, a feature which limits the ability of some patient populations to tolerate testing and discourages widespread deployment. Previous work on non-contact sleep monitoring for sleep apnea detection either estimates respiratory effort using radar or nasal airflow using a thermal camera, but has not compared the two or used them together. We conducted a study on 10 participants, ages 34 - 78, with suspected sleep disorders using a hardware setup with a synchronized radar and thermal camera. We show the first comparison of radar and thermal imaging for sleep monitoring, and find that our thermal imaging method outperforms radar significantly. Our thermal imaging method detects apneas with an accuracy of 0.99, a precision of 0.68, a recall of 0.74, an F1 score of 0.71, and an intra-class correlation of 0.70; our radar method detects apneas with an accuracy of 0.83, a precision of 0.13, a recall of 0.86, an F1 score of 0.22, and an intra-class correlation of 0.13. We also present a novel proposal for classifying obstructive and central sleep apnea by leveraging a multimodal setup. This method could be used accurately detect and classify apneas during sleep with non-contact sensors, thereby improving diagnostic capacities in patient populations unable to tolerate current technology.","sentences":["Polysomnography (PSG), the current gold standard method for monitoring and detecting sleep disorders, is cumbersome and costly.","At-home testing solutions, known as home sleep apnea testing (HSAT), exist.","However, they are contact-based, a feature which limits the ability of some patient populations to tolerate testing and discourages widespread deployment.","Previous work on non-contact sleep monitoring for sleep apnea detection either estimates respiratory effort using radar or nasal airflow using a thermal camera, but has not compared the two or used them together.","We conducted a study on 10 participants, ages 34 - 78, with suspected sleep disorders using a hardware setup with a synchronized radar and thermal camera.","We show the first comparison of radar and thermal imaging for sleep monitoring, and find that our thermal imaging method outperforms radar significantly.","Our thermal imaging method detects apneas with an accuracy of 0.99, a precision of 0.68, a recall of 0.74, an F1 score of 0.71, and an intra-class correlation of 0.70; our radar method detects apneas with an accuracy of 0.83, a precision of 0.13, a recall of 0.86, an F1 score of 0.22, and an intra-class correlation of 0.13.","We also present a novel proposal for classifying obstructive and central sleep apnea by leveraging a multimodal setup.","This method could be used accurately detect and classify apneas during sleep with non-contact sensors, thereby improving diagnostic capacities in patient populations unable to tolerate current technology."],"url":"http://arxiv.org/abs/2407.11936v1"}
{"created":"2024-07-16 17:26:34","title":"Learning Multi-view Anomaly Detection","abstract":"This study explores the recently proposed challenging multi-view Anomaly Detection (AD) task. Single-view tasks would encounter blind spots from other perspectives, resulting in inaccuracies in sample-level prediction. Therefore, we introduce the \\textbf{M}ulti-\\textbf{V}iew \\textbf{A}nomaly \\textbf{D}etection (\\textbf{MVAD}) framework, which learns and integrates features from multi-views. Specifically, we proposed a \\textbf{M}ulti-\\textbf{V}iew \\textbf{A}daptive \\textbf{S}election (\\textbf{MVAS}) algorithm for feature learning and fusion across multiple views. The feature maps are divided into neighbourhood attention windows to calculate a semantic correlation matrix between single-view windows and all other views, which is a conducted attention mechanism for each single-view window and the top-K most correlated multi-view windows. Adjusting the window sizes and top-K can minimise the computational complexity to linear. Extensive experiments on the Real-IAD dataset for cross-setting (multi/single-class) validate the effectiveness of our approach, achieving state-of-the-art performance among sample \\textbf{4.1\\%}$\\uparrow$/ image \\textbf{5.6\\%}$\\uparrow$/pixel \\textbf{6.7\\%}$\\uparrow$ levels with a total of ten metrics with only \\textbf{18M} parameters and fewer GPU memory and training time.","sentences":["This study explores the recently proposed challenging multi-view Anomaly Detection (AD) task.","Single-view tasks would encounter blind spots from other perspectives, resulting in inaccuracies in sample-level prediction.","Therefore, we introduce the \\textbf{M}ulti-\\textbf{V}iew \\textbf{A}nomaly \\textbf{D}etection (\\textbf{MVAD}) framework, which learns and integrates features from multi-views.","Specifically, we proposed a \\textbf{M}ulti-\\textbf{V}iew \\textbf{A}daptive \\textbf{S}election (\\textbf{MVAS}) algorithm for feature learning and fusion across multiple views.","The feature maps are divided into neighbourhood attention windows to calculate a semantic correlation matrix between single-view windows and all other views, which is a conducted attention mechanism for each single-view window and the top-K most correlated multi-view windows.","Adjusting the window sizes and top-K can minimise the computational complexity to linear.","Extensive experiments on the Real-IAD dataset for cross-setting (multi/single-class) validate the effectiveness of our approach, achieving state-of-the-art performance among sample \\textbf{4.1\\%}$\\uparrow$/ image \\textbf{5.6\\%}$\\uparrow$/pixel \\textbf{6.7\\%}$\\uparrow$ levels with a total of ten metrics with only \\textbf{18M} parameters and fewer GPU memory and training time."],"url":"http://arxiv.org/abs/2407.11935v1"}
{"created":"2024-07-16 17:25:44","title":"Code Documentation and Analysis to Secure Software Development","abstract":"We present the Code Documentation and Analysis Tool (CoDAT). CoDAT is a tool designed to maintain consistency between the various levels of code documentation, e.g. if a line in a code sketch is changed, the comment that documents the corresponding code is also changed. That is, comments are linked and updated so as to remain internally consistent and also consistent with the code. By flagging \"out of date\" comments, CoDAT alerts the developer to maintain up-to-date documentation.   We use a large language model to check the semantic consistency between a fragment of code and the comments that describe it. Thus we also flag semantic inconsistency as well as out of date comments. This helps programers write code that correctly implements a code sketch, and so provides machine support for a step-wise refinement approach, starting with a code sketch and proceeding down to code through one or more refinement iterations.   CoDAT is implemented in the Intellij IDEA IDE where we use the Code Insight daemon package alongside a custom regular expression algorithm to mark tagged comments whose corresponding code blocks have changed. CoDAT's backend is structurally decentralized to allow a distributed ledger framework for code consistency and architectural compilation tracking.","sentences":["We present the Code Documentation and Analysis Tool (CoDAT).","CoDAT is a tool designed to maintain consistency between the various levels of code documentation, e.g. if a line in a code sketch is changed, the comment that documents the corresponding code is also changed.","That is, comments are linked and updated so as to remain internally consistent and also consistent with the code.","By flagging \"out of date\" comments, CoDAT alerts the developer to maintain up-to-date documentation.   ","We use a large language model to check the semantic consistency between a fragment of code and the comments that describe it.","Thus we also flag semantic inconsistency as well as out of date comments.","This helps programers write code that correctly implements a code sketch, and so provides machine support for a step-wise refinement approach, starting with a code sketch and proceeding down to code through one or more refinement iterations.   ","CoDAT is implemented in the Intellij IDEA IDE where we use the Code Insight daemon package alongside a custom regular expression algorithm to mark tagged comments whose corresponding code blocks have changed.","CoDAT's backend is structurally decentralized to allow a distributed ledger framework for code consistency and architectural compilation tracking."],"url":"http://arxiv.org/abs/2407.11934v1"}
{"created":"2024-07-16 17:23:16","title":"Fine-grained Hallucination Detection and Mitigation in Long-form Question Answering","abstract":"Long-form question answering (LFQA) aims to provide thorough and in-depth answers to complex questions, enhancing comprehension. However, such detailed responses are prone to hallucinations and factual inconsistencies, challenging their faithful evaluation. This work introduces HaluQuestQA, the first hallucination dataset with localized error annotations for human-written and model-generated LFQA answers. HaluQuestQA comprises 698 QA pairs with 4.7k span-level error annotations for five different error types by expert annotators, along with preference judgments. Using our collected data, we thoroughly analyze the shortcomings of long-form answers and find that they lack comprehensiveness and provide unhelpful references. We train an automatic feedback model on this dataset that predicts error spans with incomplete information and provides associated explanations. Finally, we propose a prompt-based approach, Error-informed refinement, that uses signals from the learned feedback model to refine generated answers, which we show reduces hallucination and improves answer quality. Furthermore, humans find answers generated by our approach comprehensive and highly prefer them (84%) over the baseline answers.","sentences":["Long-form question answering (LFQA) aims to provide thorough and in-depth answers to complex questions, enhancing comprehension.","However, such detailed responses are prone to hallucinations and factual inconsistencies, challenging their faithful evaluation.","This work introduces HaluQuestQA, the first hallucination dataset with localized error annotations for human-written and model-generated LFQA answers.","HaluQuestQA comprises 698 QA pairs with 4.7k span-level error annotations for five different error types by expert annotators, along with preference judgments.","Using our collected data, we thoroughly analyze the shortcomings of long-form answers and find that they lack comprehensiveness and provide unhelpful references.","We train an automatic feedback model on this dataset that predicts error spans with incomplete information and provides associated explanations.","Finally, we propose a prompt-based approach, Error-informed refinement, that uses signals from the learned feedback model to refine generated answers, which we show reduces hallucination and improves answer quality.","Furthermore, humans find answers generated by our approach comprehensive and highly prefer them (84%) over the baseline answers."],"url":"http://arxiv.org/abs/2407.11930v1"}
{"created":"2024-07-16 17:21:36","title":"Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach","abstract":"Graph Neural Network (GNN) achieves great success for node-level and graph-level tasks via encoding meaningful topological structures of networks in various domains, ranging from social to biological networks. However, repeated aggregation operations lead to excessive mixing of node representations, particularly in dense regions with multiple GNN layers, resulting in nearly indistinguishable embeddings. This phenomenon leads to the oversmoothing problem that hampers downstream graph analytics tasks. To overcome this issue, we propose a novel and flexible truss-based graph sparsification model that prunes edges from dense regions of the graph. Pruning redundant edges in dense regions helps to prevent the aggregation of excessive neighborhood information during hierarchical message passing and pooling in GNN models. We then utilize our sparsification model in the state-of-the-art baseline GNNs and pooling models, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and AdamGNN. Extensive experiments on different real-world datasets show that our model significantly improves the performance of the baseline GNN models in the graph classification task.","sentences":["Graph Neural Network (GNN) achieves great success for node-level and graph-level tasks via encoding meaningful topological structures of networks in various domains, ranging from social to biological networks.","However, repeated aggregation operations lead to excessive mixing of node representations, particularly in dense regions with multiple GNN layers, resulting in nearly indistinguishable embeddings.","This phenomenon leads to the oversmoothing problem that hampers downstream graph analytics tasks.","To overcome this issue, we propose a novel and flexible truss-based graph sparsification model that prunes edges from dense regions of the graph.","Pruning redundant edges in dense regions helps to prevent the aggregation of excessive neighborhood information during hierarchical message passing and pooling in GNN models.","We then utilize our sparsification model in the state-of-the-art baseline GNNs and pooling models, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and AdamGNN.","Extensive experiments on different real-world datasets show that our model significantly improves the performance of the baseline GNN models in the graph classification task."],"url":"http://arxiv.org/abs/2407.11928v1"}
{"created":"2024-07-16 17:14:13","title":"Learning secondary tool affordances of human partners using iCub robot's egocentric data","abstract":"Objects, in particular tools, provide several action possibilities to the agents that can act on them, which are generally associated with the term of affordances. A tool is typically designed for a specific purpose, such as driving a nail in the case of a hammer, which we call as the primary affordance. A tool can also be used beyond its primary purpose, in which case we can associate this auxiliary use with the term secondary affordance. Previous work on affordance perception and learning has been mostly focused on primary affordances. Here, we address the less explored problem of learning the secondary tool affordances of human partners. To do this, we use the iCub robot to observe human partners with three cameras while they perform actions on twenty objects using four different tools. In our experiments, human partners utilize tools to perform actions that do not correspond to their primary affordances. For example, the iCub robot observes a human partner using a ruler for pushing, pulling, and moving objects instead of measuring their lengths. In this setting, we constructed a dataset by taking images of objects before and after each action is executed. We then model learning secondary affordances by training three neural networks (ResNet-18, ResNet-50, and ResNet-101) each on three tasks, using raw images showing the `initial' and `final' position of objects as input: (1) predicting the tool used to move an object, (2) predicting the tool used with an additional categorical input that encoded the action performed, and (3) joint prediction of both tool used and action performed. Our results indicate that deep learning architectures enable the iCub robot to predict secondary tool affordances, thereby paving the road for human-robot collaborative object manipulation involving complex affordances.","sentences":["Objects, in particular tools, provide several action possibilities to the agents that can act on them, which are generally associated with the term of affordances.","A tool is typically designed for a specific purpose, such as driving a nail in the case of a hammer, which we call as the primary affordance.","A tool can also be used beyond its primary purpose, in which case we can associate this auxiliary use with the term secondary affordance.","Previous work on affordance perception and learning has been mostly focused on primary affordances.","Here, we address the less explored problem of learning the secondary tool affordances of human partners.","To do this, we use the iCub robot to observe human partners with three cameras while they perform actions on twenty objects using four different tools.","In our experiments, human partners utilize tools to perform actions that do not correspond to their primary affordances.","For example, the iCub robot observes a human partner using a ruler for pushing, pulling, and moving objects instead of measuring their lengths.","In this setting, we constructed a dataset by taking images of objects before and after each action is executed.","We then model learning secondary affordances by training three neural networks (ResNet-18, ResNet-50, and ResNet-101) each on three tasks, using raw images showing the `initial' and `final' position of objects as input: (1) predicting the tool used to move an object, (2) predicting the tool used with an additional categorical input that encoded the action performed, and (3) joint prediction of both tool used and action performed.","Our results indicate that deep learning architectures enable the iCub robot to predict secondary tool affordances, thereby paving the road for human-robot collaborative object manipulation involving complex affordances."],"url":"http://arxiv.org/abs/2407.11922v1"}
{"created":"2024-07-16 17:11:43","title":"IPA-NeRF: Illusory Poisoning Attack Against Neural Radiance Fields","abstract":"Neural Radiance Field (NeRF) represents a significant advancement in computer vision, offering implicit neural network-based scene representation and novel view synthesis capabilities. Its applications span diverse fields including robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, etc., some of which are considered high-risk AI applications. However, despite its widespread adoption, the robustness and security of NeRF remain largely unexplored. In this study, we contribute to this area by introducing the Illusory Poisoning Attack against Neural Radiance Fields (IPA-NeRF). This attack involves embedding a hidden backdoor view into NeRF, allowing it to produce predetermined outputs, i.e. illusory, when presented with the specified backdoor view while maintaining normal performance with standard inputs. Our attack is specifically designed to deceive users or downstream models at a particular position while ensuring that any abnormalities in NeRF remain undetectable from other viewpoints. Experimental results demonstrate the effectiveness of our Illusory Poisoning Attack, successfully presenting the desired illusory on the specified viewpoint without impacting other views. Notably, we achieve this attack by introducing small perturbations solely to the training set. The code can be found at https://github.com/jiang-wenxiang/IPA-NeRF.","sentences":["Neural Radiance Field (NeRF) represents a significant advancement in computer vision, offering implicit neural network-based scene representation and novel view synthesis capabilities.","Its applications span diverse fields including robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, etc., some of which are considered high-risk AI applications.","However, despite its widespread adoption, the robustness and security of NeRF remain largely unexplored.","In this study, we contribute to this area by introducing the Illusory Poisoning Attack against Neural Radiance Fields (IPA-NeRF).","This attack involves embedding a hidden backdoor view into NeRF, allowing it to produce predetermined outputs, i.e. illusory, when presented with the specified backdoor view while maintaining normal performance with standard inputs.","Our attack is specifically designed to deceive users or downstream models at a particular position while ensuring that any abnormalities in NeRF remain undetectable from other viewpoints.","Experimental results demonstrate the effectiveness of our Illusory Poisoning Attack, successfully presenting the desired illusory on the specified viewpoint without impacting other views.","Notably, we achieve this attack by introducing small perturbations solely to the training set.","The code can be found at https://github.com/jiang-wenxiang/IPA-NeRF."],"url":"http://arxiv.org/abs/2407.11921v1"}
{"created":"2024-07-16 17:10:16","title":"What's Wrong? Refining Meeting Summaries with LLM Feedback","abstract":"Meeting summarization has become a critical task since digital encounters have become a common practice. Large language models (LLMs) show great potential in summarization, offering enhanced coherence and context understanding compared to traditional methods. However, they still struggle to maintain relevance and avoid hallucination. We introduce a multi-LLM correction approach for meeting summarization using a two-phase process that mimics the human review process: mistake identification and summary refinement. We release QMSum Mistake, a dataset of 200 automatically generated meeting summaries annotated by humans on nine error types, including structural, omission, and irrelevance errors. Our experiments show that these errors can be identified with high accuracy by an LLM. We transform identified mistakes into actionable feedback to improve the quality of a given summary measured by relevance, informativeness, conciseness, and coherence. This post-hoc refinement effectively improves summary quality by leveraging multiple LLMs to validate output quality. Our multi-LLM approach for meeting summarization shows potential for similar complex text generation tasks requiring robustness, action planning, and discussion towards a goal.","sentences":["Meeting summarization has become a critical task since digital encounters have become a common practice.","Large language models (LLMs) show great potential in summarization, offering enhanced coherence and context understanding compared to traditional methods.","However, they still struggle to maintain relevance and avoid hallucination.","We introduce a multi-LLM correction approach for meeting summarization using a two-phase process that mimics the human review process: mistake identification and summary refinement.","We release QMSum Mistake, a dataset of 200 automatically generated meeting summaries annotated by humans on nine error types, including structural, omission, and irrelevance errors.","Our experiments show that these errors can be identified with high accuracy by an LLM.","We transform identified mistakes into actionable feedback to improve the quality of a given summary measured by relevance, informativeness, conciseness, and coherence.","This post-hoc refinement effectively improves summary quality by leveraging multiple LLMs to validate output quality.","Our multi-LLM approach for meeting summarization shows potential for similar complex text generation tasks requiring robustness, action planning, and discussion towards a goal."],"url":"http://arxiv.org/abs/2407.11919v1"}
{"created":"2024-07-16 17:09:55","title":"Market or Markets? Investigating Google Search's Market Shares Under Horizontal and Vertical Segmentation","abstract":"Is Google Search a monopoly with gatekeeping power? Regulators from the US, UK, and Europe have argued that it is based on the assumption that Google Search dominates the market for horizontal (a.k.a. \"general\") web search. Google disputes this, claiming that competition extends to all vertical (a.k.a. \"specialized\") search engines, and that under this market definition it does not have monopoly power. In this study we present the first analysis of Google Search's market share under both horizontal and vertical segmentation of online search. We leverage observational trace data collected from a panel of US residents that includes their web browsing history and copies of the Google Search Engine Result Pages they were shown. We observe that Google Search receives 71.8% of participants' queries when compared to other horizontal search engines, and that participants' search sessions begin at Google greater than 50% of the time in 24 out of 30 vertical market segments (which comprise almost all of our participants' searches). Our results inform the consequential and ongoing debates about the market power of Google Search and the conceptualization of online markets in general.","sentences":["Is Google Search a monopoly with gatekeeping power?","Regulators from the US, UK, and Europe have argued that it is based on the assumption that Google Search dominates the market for horizontal (a.k.a. \"general\") web search.","Google disputes this, claiming that competition extends to all vertical (a.k.a. \"specialized\") search engines, and that under this market definition it does not have monopoly power.","In this study we present the first analysis of Google Search's market share under both horizontal and vertical segmentation of online search.","We leverage observational trace data collected from a panel of US residents that includes their web browsing history and copies of the Google Search Engine Result Pages they were shown.","We observe that Google Search receives 71.8% of participants' queries when compared to other horizontal search engines, and that participants' search sessions begin at Google greater than 50% of the time in 24 out of 30 vertical market segments (which comprise almost all of our participants' searches).","Our results inform the consequential and ongoing debates about the market power of Google Search and the conceptualization of online markets in general."],"url":"http://arxiv.org/abs/2407.11918v1"}
{"created":"2024-07-16 17:09:47","title":"Global Optimisation of Black-Box Functions with Generative Models in the Wasserstein Space","abstract":"We propose a new uncertainty estimator for gradient-free optimisation of black-box simulators using deep generative surrogate models. Optimisation of these simulators is especially challenging for stochastic simulators and higher dimensions. To address these issues, we utilise a deep generative surrogate approach to model the black box response for the entire parameter space. We then leverage this knowledge to estimate the proposed uncertainty based on the Wasserstein distance - the Wasserstein uncertainty. This approach is employed in a posterior agnostic gradient-free optimisation algorithm that minimises regret over the entire parameter space. A series of tests were conducted to demonstrate that our method is more robust to the shape of both the black box function and the stochastic response of the black box than state-of-the-art methods, such as efficient global optimisation with a deep Gaussian process surrogate.","sentences":["We propose a new uncertainty estimator for gradient-free optimisation of black-box simulators using deep generative surrogate models.","Optimisation of these simulators is especially challenging for stochastic simulators and higher dimensions.","To address these issues, we utilise a deep generative surrogate approach to model the black box response for the entire parameter space.","We then leverage this knowledge to estimate the proposed uncertainty based on the Wasserstein distance - the Wasserstein uncertainty.","This approach is employed in a posterior agnostic gradient-free optimisation algorithm that minimises regret over the entire parameter space.","A series of tests were conducted to demonstrate that our method is more robust to the shape of both the black box function and the stochastic response of the black box than state-of-the-art methods, such as efficient global optimisation with a deep Gaussian process surrogate."],"url":"http://arxiv.org/abs/2407.11917v1"}
{"created":"2024-07-16 17:08:40","title":"Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task","abstract":"Head movements are crucial for social human-human interaction. They can transmit important cues (e.g., joint attention, speaker detection) that cannot be achieved with verbal interaction alone. This advantage also holds for human-robot interaction. Even though modeling human motions through generative AI models has become an active research area within robotics in recent years, the use of these methods for producing head movements in human-robot interaction remains underexplored. In this work, we employed a generative AI pipeline to produce human-like head movements for a Nao humanoid robot. In addition, we tested the system on a real-time active-speaker tracking task in a group conversation setting. Overall, the results show that the Nao robot successfully imitates human head movements in a natural manner while actively tracking the speakers during the conversation. Code and data from this study are available at https://github.com/dingdingding60/Humanoids2024HRI","sentences":["Head movements are crucial for social human-human interaction.","They can transmit important cues (e.g., joint attention, speaker detection) that cannot be achieved with verbal interaction alone.","This advantage also holds for human-robot interaction.","Even though modeling human motions through generative AI models has become an active research area within robotics in recent years, the use of these methods for producing head movements in human-robot interaction remains underexplored.","In this work, we employed a generative AI pipeline to produce human-like head movements for a Nao humanoid robot.","In addition, we tested the system on a real-time active-speaker tracking task in a group conversation setting.","Overall, the results show that the Nao robot successfully imitates human head movements in a natural manner while actively tracking the speakers during the conversation.","Code and data from this study are available at https://github.com/dingdingding60/Humanoids2024HRI"],"url":"http://arxiv.org/abs/2407.11915v1"}
{"created":"2024-07-16 17:05:20","title":"Quantised Global Autoencoder: A Holistic Approach to Representing Visual Data","abstract":"In quantised autoencoders, images are usually split into local patches, each encoded by one token. This representation is redundant in the sense that the same number of tokens is spend per region, regardless of the visual information content in that region. Adaptive discretisation schemes like quadtrees are applied to allocate tokens for patches with varying sizes, but this just varies the region of influence for a token which nevertheless remains a local descriptor. Modern architectures add an attention mechanism to the autoencoder which infuses some degree of global information into the local tokens. Despite the global context, tokens are still associated with a local image region. In contrast, our method is inspired by spectral decompositions which transform an input signal into a superposition of global frequencies. Taking the data-driven perspective, we learn custom basis functions corresponding to the codebook entries in our VQ-VAE setup. Furthermore, a decoder combines these basis functions in a non-linear fashion, going beyond the simple linear superposition of spectral decompositions. We can achieve this global description with an efficient transpose operation between features and channels and demonstrate our performance on compression.","sentences":["In quantised autoencoders, images are usually split into local patches, each encoded by one token.","This representation is redundant in the sense that the same number of tokens is spend per region, regardless of the visual information content in that region.","Adaptive discretisation schemes like quadtrees are applied to allocate tokens for patches with varying sizes, but this just varies the region of influence for a token which nevertheless remains a local descriptor.","Modern architectures add an attention mechanism to the autoencoder which infuses some degree of global information into the local tokens.","Despite the global context, tokens are still associated with a local image region.","In contrast, our method is inspired by spectral decompositions which transform an input signal into a superposition of global frequencies.","Taking the data-driven perspective, we learn custom basis functions corresponding to the codebook entries in our VQ-VAE setup.","Furthermore, a decoder combines these basis functions in a non-linear fashion, going beyond the simple linear superposition of spectral decompositions.","We can achieve this global description with an efficient transpose operation between features and channels and demonstrate our performance on compression."],"url":"http://arxiv.org/abs/2407.11913v1"}
{"created":"2024-07-16 17:02:20","title":"Benchmarking the Attribution Quality of Vision Models","abstract":"Attribution maps are one of the most established tools to explain the functioning of computer vision models. They assign importance scores to input features, indicating how relevant each feature is for the prediction of a deep neural network. While much research has gone into proposing new attribution methods, their proper evaluation remains a difficult challenge. In this work, we propose a novel evaluation protocol that overcomes two fundamental limitations of the widely used incremental-deletion protocol, i.e., the out-of-domain issue and lacking inter-model comparisons. This allows us to evaluate 23 attribution methods and how eight different design choices of popular vision models affect their attribution quality. We find that intrinsically explainable models outperform standard models and that raw attribution values exhibit a higher attribution quality than what is known from previous work. Further, we show consistent changes in the attribution quality when varying the network design, indicating that some standard design choices promote attribution quality.","sentences":["Attribution maps are one of the most established tools to explain the functioning of computer vision models.","They assign importance scores to input features, indicating how relevant each feature is for the prediction of a deep neural network.","While much research has gone into proposing new attribution methods, their proper evaluation remains a difficult challenge.","In this work, we propose a novel evaluation protocol that overcomes two fundamental limitations of the widely used incremental-deletion protocol, i.e., the out-of-domain issue and lacking inter-model comparisons.","This allows us to evaluate 23 attribution methods and how eight different design choices of popular vision models affect their attribution quality.","We find that intrinsically explainable models outperform standard models and that raw attribution values exhibit a higher attribution quality than what is known from previous work.","Further, we show consistent changes in the attribution quality when varying the network design, indicating that some standard design choices promote attribution quality."],"url":"http://arxiv.org/abs/2407.11910v1"}
{"created":"2024-07-16 16:51:43","title":"GraphFM: A Scalable Framework for Multi-Graph Pretraining","abstract":"Graph neural networks are typically trained on individual datasets, often requiring highly specialized models and extensive hyperparameter tuning. This dataset-specific approach arises because each graph dataset often has unique node features and diverse connectivity structures, making it difficult to build a generalist model. To address these challenges, we introduce a scalable multi-graph multi-task pretraining approach specifically tailored for node classification tasks across diverse graph datasets from different domains. Our method, Graph Foundation Model (GraphFM), leverages a Perceiver-based encoder that employs learned latent tokens to compress domain-specific features into a common latent space. This approach enhances the model's ability to generalize across different graphs and allows for scaling across diverse data. We demonstrate the efficacy of our approach by training a model on 152 different graph datasets comprising over 7.4 million nodes and 189 million edges, establishing the first set of scaling laws for multi-graph pretraining on datasets spanning many domains (e.g., molecules, citation and product graphs). Our results show that pretraining on a diverse array of real and synthetic graphs improves the model's adaptability and stability, while performing competitively with state-of-the-art specialist models. This work illustrates that multi-graph pretraining can significantly reduce the burden imposed by the current graph training paradigm, unlocking new capabilities for the field of graph neural networks by creating a single generalist model that performs competitively across a wide range of datasets and tasks.","sentences":["Graph neural networks are typically trained on individual datasets, often requiring highly specialized models and extensive hyperparameter tuning.","This dataset-specific approach arises because each graph dataset often has unique node features and diverse connectivity structures, making it difficult to build a generalist model.","To address these challenges, we introduce a scalable multi-graph multi-task pretraining approach specifically tailored for node classification tasks across diverse graph datasets from different domains.","Our method, Graph Foundation Model (GraphFM), leverages a Perceiver-based encoder that employs learned latent tokens to compress domain-specific features into a common latent space.","This approach enhances the model's ability to generalize across different graphs and allows for scaling across diverse data.","We demonstrate the efficacy of our approach by training a model on 152 different graph datasets comprising over 7.4 million nodes and 189 million edges, establishing the first set of scaling laws for multi-graph pretraining on datasets spanning many domains (e.g., molecules, citation and product graphs).","Our results show that pretraining on a diverse array of real and synthetic graphs improves the model's adaptability and stability, while performing competitively with state-of-the-art specialist models.","This work illustrates that multi-graph pretraining can significantly reduce the burden imposed by the current graph training paradigm, unlocking new capabilities for the field of graph neural networks by creating a single generalist model that performs competitively across a wide range of datasets and tasks."],"url":"http://arxiv.org/abs/2407.11907v1"}
{"created":"2024-07-16 16:50:43","title":"SegSTRONG-C: Segmenting Surgical Tools Robustly On Non-adversarial Generated Corruptions -- An EndoVis'24 Challenge","abstract":"Accurate segmentation of tools in robot-assisted surgery is critical for machine perception, as it facilitates numerous downstream tasks including augmented reality feedback. While current feed-forward neural network-based methods exhibit excellent segmentation performance under ideal conditions, these models have proven susceptible to even minor corruptions, significantly impairing the model's performance. This vulnerability is especially problematic in surgical settings where predictions might be used to inform high-stakes decisions. To better understand model behavior under non-adversarial corruptions, prior work has explored introducing artificial corruptions, like Gaussian noise or contrast perturbation to test set images, to assess model robustness. However, these corruptions are either not photo-realistic or model/task agnostic. Thus, these investigations provide limited insights into model deterioration under realistic surgical corruptions. To address this limitation, we introduce the SegSTRONG-C challenge that aims to promote the development of algorithms robust to unforeseen but plausible image corruptions of surgery, like smoke, bleeding, and low brightness. We collect and release corruption-free mock endoscopic video sequences for the challenge participants to train their algorithms and benchmark them on video sequences with photo-realistic non-adversarial corruptions for a binary robot tool segmentation task. This new benchmark will allow us to carefully study neural network robustness to non-adversarial corruptions of surgery, thus constituting an important first step towards more robust models for surgical computer vision. In this paper, we describe the data collection and annotation protocol, baseline evaluations of established segmentation models, and data augmentation-based techniques to enhance model robustness.","sentences":["Accurate segmentation of tools in robot-assisted surgery is critical for machine perception, as it facilitates numerous downstream tasks including augmented reality feedback.","While current feed-forward neural network-based methods exhibit excellent segmentation performance under ideal conditions, these models have proven susceptible to even minor corruptions, significantly impairing the model's performance.","This vulnerability is especially problematic in surgical settings where predictions might be used to inform high-stakes decisions.","To better understand model behavior under non-adversarial corruptions, prior work has explored introducing artificial corruptions, like Gaussian noise or contrast perturbation to test set images, to assess model robustness.","However, these corruptions are either not photo-realistic or model/task agnostic.","Thus, these investigations provide limited insights into model deterioration under realistic surgical corruptions.","To address this limitation, we introduce the SegSTRONG-C challenge that aims to promote the development of algorithms robust to unforeseen but plausible image corruptions of surgery, like smoke, bleeding, and low brightness.","We collect and release corruption-free mock endoscopic video sequences for the challenge participants to train their algorithms and benchmark them on video sequences with photo-realistic non-adversarial corruptions for a binary robot tool segmentation task.","This new benchmark will allow us to carefully study neural network robustness to non-adversarial corruptions of surgery, thus constituting an important first step towards more robust models for surgical computer vision.","In this paper, we describe the data collection and annotation protocol, baseline evaluations of established segmentation models, and data augmentation-based techniques to enhance model robustness."],"url":"http://arxiv.org/abs/2407.11906v1"}
{"created":"2024-07-16 16:38:47","title":"An Overview and Solution for Democratizing AI Workflows at the Network Edge","abstract":"With the process of democratization of the network edge, hardware and software for networks are becoming available to the public, overcoming the confines of traditional cloud providers and network operators. This trend, coupled with the increasing importance of AI in 6G and beyond cellular networks, presents opportunities for innovative AI applications and systems at the network edge. While AI models and services are well-managed in cloud systems, achieving similar maturity for serving network needs remains an open challenge. Existing open solutions are emerging and are yet to consider democratization requirements. In this work, we identify key requirements for democratization and propose NAOMI, a solution for democratizing AI/ML workflows at the network edge designed based on those requirements. Guided by the functionality and overlap analysis of the O-RAN AI/ML workflow architecture and MLOps systems, coupled with the survey of open-source AI/ML tools, we develop a modular, scalable, and distributed hardware architecture-independent solution. NAOMI leverages state-of-the-art open-source tools and can be deployed on distributed clusters of heterogeneous devices. The results show that NAOMI performs up to 40% better in deployment time and up to 73% faster in AI/ML workflow execution for larger datasets compared to AI/ML Framework, a representative open network access solution, while performing inference and utilizing resources on par with its counterpart.","sentences":["With the process of democratization of the network edge, hardware and software for networks are becoming available to the public, overcoming the confines of traditional cloud providers and network operators.","This trend, coupled with the increasing importance of AI in 6G and beyond cellular networks, presents opportunities for innovative AI applications and systems at the network edge.","While AI models and services are well-managed in cloud systems, achieving similar maturity for serving network needs remains an open challenge.","Existing open solutions are emerging and are yet to consider democratization requirements.","In this work, we identify key requirements for democratization and propose NAOMI, a solution for democratizing AI/ML workflows at the network edge designed based on those requirements.","Guided by the functionality and overlap analysis of the O-RAN AI/ML workflow architecture and MLOps systems, coupled with the survey of open-source AI/ML tools, we develop a modular, scalable, and distributed hardware architecture-independent solution.","NAOMI leverages state-of-the-art open-source tools and can be deployed on distributed clusters of heterogeneous devices.","The results show that NAOMI performs up to 40% better in deployment time and up to 73% faster in AI/ML workflow execution for larger datasets compared to AI/ML Framework, a representative open network access solution, while performing inference and utilizing resources on par with its counterpart."],"url":"http://arxiv.org/abs/2407.11905v1"}
{"created":"2024-07-16 16:35:23","title":"Encapsulating Knowledge in One Prompt","abstract":"This paradigm encapsulates knowledge from various models into a solitary prompt without altering the original models or requiring access to the training data, which enables us to achieve efficient and convenient knowledge transfer in more realistic scenarios. From a practicality standpoint, this paradigm not only for the first time proves the effectiveness of Visual Prompt in data inaccessible contexts, but also solves the problems of low model reusability and high storage resource consumption faced by traditional Data-Free Knowledge Transfer, which means that we can realize the parallel knowledge transfer of multiple models without modifying any source model. Extensive experiments across various datasets and models demonstrate the efficacy of the proposed KiOP knowledge transfer paradigm. Without access to real training data and with rigorous storage capacity constraints, it is also capable of yielding considerable outcomes when dealing with cross-model backbone setups and handling parallel knowledge transfer processing requests with multiple (more than 2) models.","sentences":["This paradigm encapsulates knowledge from various models into a solitary prompt without altering the original models or requiring access to the training data, which enables us to achieve efficient and convenient knowledge transfer in more realistic scenarios.","From a practicality standpoint, this paradigm not only for the first time proves the effectiveness of Visual Prompt in data inaccessible contexts, but also solves the problems of low model reusability and high storage resource consumption faced by traditional Data-Free Knowledge Transfer, which means that we can realize the parallel knowledge transfer of multiple models without modifying any source model.","Extensive experiments across various datasets and models demonstrate the efficacy of the proposed KiOP knowledge transfer paradigm.","Without access to real training data and with rigorous storage capacity constraints, it is also capable of yielding considerable outcomes when dealing with cross-model backbone setups and handling parallel knowledge transfer processing requests with multiple (more than 2) models."],"url":"http://arxiv.org/abs/2407.11902v1"}
{"created":"2024-07-16 16:24:55","title":"Trajectory and Power Optimization for Multi-UAV Enabled Emergency Wireless Communications Networks","abstract":"Recently, unmanned aerial vehicle (UAV) has attracted much attention due to its flexible deployment and controllable mobility. As the general communication network cannot meet the emergency requirements, in this paper we study the multi-UAV enabled wireless emergency communication system. Our goal is to maximize the capacity with jointly optimizing trajectory and allocating power. To tackle this non-convex optimization problem, we first decompose it into two sub-problems to optimize the trajectory and power allocation, respectively. Then, we propose the successive convex approximation technique and the block coordinate update algorithm to solve the two subproblems. The approximate optimal solution can be obtained after continuous iterations. Simulation results show that the capacity can be greatly increased using our proposed joint trajectory optimization and power allocation.","sentences":["Recently, unmanned aerial vehicle (UAV) has attracted much attention due to its flexible deployment and controllable mobility.","As the general communication network cannot meet the emergency requirements, in this paper we study the multi-UAV enabled wireless emergency communication system.","Our goal is to maximize the capacity with jointly optimizing trajectory and allocating power.","To tackle this non-convex optimization problem, we first decompose it into two sub-problems to optimize the trajectory and power allocation, respectively.","Then, we propose the successive convex approximation technique and the block coordinate update algorithm to solve the two subproblems.","The approximate optimal solution can be obtained after continuous iterations.","Simulation results show that the capacity can be greatly increased using our proposed joint trajectory optimization and power allocation."],"url":"http://arxiv.org/abs/2407.11896v1"}
{"created":"2024-07-16 16:24:31","title":"OmniBind: Large-scale Omni Multimodal Representation via Binding Spaces","abstract":"Recently, human-computer interaction with various modalities has shown promising applications, like GPT-4o and Gemini. Given the foundational role of multimodal joint representation in understanding and generation pipelines, high-quality omni joint representations would be a step toward co-processing more diverse multimodal information. In this work, we present OmniBind, large-scale multimodal joint representation models ranging in scale from 7 billion to 30 billion parameters, which support 3D, audio, image, and language inputs. Due to the scarcity of data pairs across all modalities, instead of training large models from scratch, we propose remapping and binding the spaces of various pre-trained specialist models together. This approach enables \"scaling up\" by indirectly increasing the model parameters and the amount of seen data. To effectively integrate various spaces, we dynamically assign weights to different spaces by learning routers with two objectives: cross-modal overall alignment and language representation decoupling. Notably, since binding and routing spaces both only require lightweight networks, OmniBind is extremely training-efficient. Learning the largest 30B model requires merely unpaired unimodal data and approximately 3 days on a single 8-4090 node. Extensive experiments demonstrate the versatility and superiority of OmniBind as an omni representation model, highlighting its great potential for diverse applications, such as any-query and composable multimodal understanding.","sentences":["Recently, human-computer interaction with various modalities has shown promising applications, like GPT-4o and Gemini.","Given the foundational role of multimodal joint representation in understanding and generation pipelines, high-quality omni joint representations would be a step toward co-processing more diverse multimodal information.","In this work, we present OmniBind, large-scale multimodal joint representation models ranging in scale from 7 billion to 30 billion parameters, which support 3D, audio, image, and language inputs.","Due to the scarcity of data pairs across all modalities, instead of training large models from scratch, we propose remapping and binding the spaces of various pre-trained specialist models together.","This approach enables \"scaling up\" by indirectly increasing the model parameters and the amount of seen data.","To effectively integrate various spaces, we dynamically assign weights to different spaces by learning routers with two objectives: cross-modal overall alignment and language representation decoupling.","Notably, since binding and routing spaces both only require lightweight networks, OmniBind is extremely training-efficient.","Learning the largest 30B model requires merely unpaired unimodal data and approximately 3 days on a single 8-4090 node.","Extensive experiments demonstrate the versatility and superiority of OmniBind as an omni representation model, highlighting its great potential for diverse applications, such as any-query and composable multimodal understanding."],"url":"http://arxiv.org/abs/2407.11895v1"}
{"created":"2024-07-16 16:23:40","title":"Deep Learning without Global Optimization by Random Fourier Neural Networks","abstract":"We introduce a new training algorithm for variety of deep neural networks that utilize random complex exponential activation functions. Our approach employs a Markov Chain Monte Carlo sampling procedure to iteratively train network layers, avoiding global and gradient-based optimization while maintaining error control. It consistently attains the theoretical approximation rate for residual networks with complex exponential activation functions, determined by network complexity. Additionally, it enables efficient learning of multiscale and high-frequency features, producing interpretable parameter distributions. Despite using sinusoidal basis functions, we do not observe Gibbs phenomena in approximating discontinuous target functions.","sentences":["We introduce a new training algorithm for variety of deep neural networks that utilize random complex exponential activation functions.","Our approach employs a Markov Chain Monte Carlo sampling procedure to iteratively train network layers, avoiding global and gradient-based optimization while maintaining error control.","It consistently attains the theoretical approximation rate for residual networks with complex exponential activation functions, determined by network complexity.","Additionally, it enables efficient learning of multiscale and high-frequency features, producing interpretable parameter distributions.","Despite using sinusoidal basis functions, we do not observe Gibbs phenomena in approximating discontinuous target functions."],"url":"http://arxiv.org/abs/2407.11894v1"}
{"created":"2024-07-16 16:18:40","title":"DepGAN: Leveraging Depth Maps for Handling Occlusions and Transparency in Image Composition","abstract":"Image composition is a complex task which requires a lot of information about the scene for an accurate and realistic composition, such as perspective, lighting, shadows, occlusions, and object interactions. Previous methods have predominantly used 2D information for image composition, neglecting the potentials of 3D spatial information. In this work, we propose DepGAN, a Generative Adversarial Network that utilizes depth maps and alpha channels to rectify inaccurate occlusions and enhance transparency effects in image composition. Central to our network is a novel loss function called Depth Aware Loss which quantifies the pixel wise depth difference to accurately delineate occlusion boundaries while compositing objects at different depth levels. Furthermore, we enhance our network's learning process by utilizing opacity data, enabling it to effectively manage compositions involving transparent and semi-transparent objects. We tested our model against state-of-the-art image composition GANs on benchmark (both real and synthetic) datasets. The results reveal that DepGAN significantly outperforms existing methods in terms of accuracy of object placement semantics, transparency and occlusion handling, both visually and quantitatively. Our code is available at https://amrtsg.github.io/DepGAN/.","sentences":["Image composition is a complex task which requires a lot of information about the scene for an accurate and realistic composition, such as perspective, lighting, shadows, occlusions, and object interactions.","Previous methods have predominantly used 2D information for image composition, neglecting the potentials of 3D spatial information.","In this work, we propose DepGAN, a Generative Adversarial Network that utilizes depth maps and alpha channels to rectify inaccurate occlusions and enhance transparency effects in image composition.","Central to our network is a novel loss function called Depth Aware Loss which quantifies the pixel wise depth difference to accurately delineate occlusion boundaries while compositing objects at different depth levels.","Furthermore, we enhance our network's learning process by utilizing opacity data, enabling it to effectively manage compositions involving transparent and semi-transparent objects.","We tested our model against state-of-the-art image composition GANs on benchmark (both real and synthetic) datasets.","The results reveal that DepGAN significantly outperforms existing methods in terms of accuracy of object placement semantics, transparency and occlusion handling, both visually and quantitatively.","Our code is available at https://amrtsg.github.io/DepGAN/."],"url":"http://arxiv.org/abs/2407.11890v1"}
{"created":"2024-07-16 16:18:29","title":"Map of Elections","abstract":"Our main contribution is the introduction of the map of elections framework. A map of elections consists of three main elements: (1) a dataset of elections (i.e., collections of ordinal votes over given sets of candidates), (2) a way of measuring similarities between these elections, and (3) a representation of the elections in the 2D Euclidean space as points, so that the more similar two elections are, the closer are their points. In our maps, we mostly focus on datasets of synthetic elections, but we also show an example of a map over real-life ones. To measure similarities, we would have preferred to use, e.g., the isomorphic swap distance, but this is infeasible due to its high computational complexity. Hence, we propose polynomial-time computable positionwise distance and use it instead. Regarding the representations in 2D Euclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two alternatives.   We develop the necessary theoretical results to form our maps and argue experimentally that they are accurate and credible. Further, we show how coloring the elections in a map according to various criteria helps in analyzing results of a number of experiments. In particular, we show colorings according to the scores of winning candidates or committees, running times of ILP-based winner determination algorithms, and approximation ratios achieved by particular algorithms.","sentences":["Our main contribution is the introduction of the map of elections framework.","A map of elections consists of three main elements: (1) a dataset of elections (i.e., collections of ordinal votes over given sets of candidates), (2) a way of measuring similarities between these elections, and (3) a representation of the elections in the 2D Euclidean space as points, so that the more similar two elections are, the closer are their points.","In our maps, we mostly focus on datasets of synthetic elections, but we also show an example of a map over real-life ones.","To measure similarities, we would have preferred to use, e.g., the isomorphic swap distance, but this is infeasible due to its high computational complexity.","Hence, we propose polynomial-time computable positionwise distance and use it instead.","Regarding the representations in 2D Euclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two alternatives.   ","We develop the necessary theoretical results to form our maps and argue experimentally that they are accurate and credible.","Further, we show how coloring the elections in a map according to various criteria helps in analyzing results of a number of experiments.","In particular, we show colorings according to the scores of winning candidates or committees, running times of ILP-based winner determination algorithms, and approximation ratios achieved by particular algorithms."],"url":"http://arxiv.org/abs/2407.11889v1"}
{"created":"2024-07-16 16:17:28","title":"Ascend-CC: Confidential Computing on Heterogeneous NPU for Emerging Generative AI Workloads","abstract":"Cloud workloads have dominated generative AI based on large language models (LLM). Specialized hardware accelerators, such as GPUs, NPUs, and TPUs, play a key role in AI adoption due to their superior performance over general-purpose CPUs. The AI models and the data are often highly sensitive and come from mutually distrusting parties. Existing CPU-based TEEs such as Intel SGX or AMD SEV do not provide sufficient protection. Device-centric TEEs like Nvidia-CC only address tightly coupled CPU-GPU systems with a proprietary solution requiring TEE on the host CPU side. On the other hand, existing academic proposals are tailored toward specific CPU-TEE platforms.   To address this gap, we propose Ascend-CC, a confidential computing architecture based on discrete NPU devices that requires no trust in the host system. Ascend-CC provides strong security by ensuring data and model encryption that protects not only the data but also the model parameters and operator binaries. Ascend-CC uses delegation-based memory semantics to ensure isolation from the host software stack, and task attestation provides strong model integrity guarantees. Our Ascend-CC implementation and evaluation with state-of-the-art LLMs such as Llama2 and Llama3 shows that Ascend-CC introduces minimal overhead with no changes in the AI software stack.","sentences":["Cloud workloads have dominated generative AI based on large language models (LLM).","Specialized hardware accelerators, such as GPUs, NPUs, and TPUs, play a key role in AI adoption due to their superior performance over general-purpose CPUs.","The AI models and the data are often highly sensitive and come from mutually distrusting parties.","Existing CPU-based TEEs such as Intel SGX or AMD SEV do not provide sufficient protection.","Device-centric TEEs like Nvidia-CC only address tightly coupled CPU-GPU systems with a proprietary solution requiring TEE on the host CPU side.","On the other hand, existing academic proposals are tailored toward specific CPU-TEE platforms.   ","To address this gap, we propose Ascend-CC, a confidential computing architecture based on discrete NPU devices that requires no trust in the host system.","Ascend-CC provides strong security by ensuring data and model encryption that protects not only the data but also the model parameters and operator binaries.","Ascend-CC uses delegation-based memory semantics to ensure isolation from the host software stack, and task attestation provides strong model integrity guarantees.","Our Ascend-CC implementation and evaluation with state-of-the-art LLMs such as Llama2 and Llama3 shows that Ascend-CC introduces minimal overhead with no changes in the AI software stack."],"url":"http://arxiv.org/abs/2407.11888v1"}
{"created":"2024-07-16 16:08:15","title":"Enhancing Covert Communication in Relay Systems Using Multi-Antenna Technique","abstract":"This paper exploits the multi-antenna technique to enhance the covert communication performance in a relay system, where a source S conducts covert communication with a destination D via a relay R, subjecting to the detections of transmissions in the two hops from a single-antenna warden W. To demonstrate the performance gain from adopting the multi-antenna technique, we first consider the scenario when S, R and D all adopt single antenna, and apply hypothesis testing and statistics theories to develop a theoretical framework for the covert performance modeling in terms of detection error probability (DEP) and covert throughput. We then consider the scenario when S, R and D all adopt multiple antennas, and apply the hypothesis testing, statistics and matrix theories to develop corresponding theoretical framework for performance modeling. We further explore the optimal designs of the target rate and transmit power for covert throughput maximization under above both scenarios, subjecting to the constraints of covertness, reliability and transmit power. To solve the optimization problems, we employ Karushi-Kuhn-Tucker (KKT) conditions method in the single antenna scenario and a search algorithm in the multi-antenna scenario. Finally, we provide extensive numerical results to illustrate how the multi-antenna technique can enhance the covert performance in two-hop relay systems.","sentences":["This paper exploits the multi-antenna technique to enhance the covert communication performance in a relay system, where a source S conducts covert communication with a destination D via a relay R, subjecting to the detections of transmissions in the two hops from a single-antenna warden W. To demonstrate the performance gain from adopting the multi-antenna technique, we first consider the scenario when S, R and D all adopt single antenna, and apply hypothesis testing and statistics theories to develop a theoretical framework for the covert performance modeling in terms of detection error probability (DEP) and covert throughput.","We then consider the scenario when S, R and D all adopt multiple antennas, and apply the hypothesis testing, statistics and matrix theories to develop corresponding theoretical framework for performance modeling.","We further explore the optimal designs of the target rate and transmit power for covert throughput maximization under above both scenarios, subjecting to the constraints of covertness, reliability and transmit power.","To solve the optimization problems, we employ Karushi-Kuhn-Tucker (KKT) conditions method in the single antenna scenario and a search algorithm in the multi-antenna scenario.","Finally, we provide extensive numerical results to illustrate how the multi-antenna technique can enhance the covert performance in two-hop relay systems."],"url":"http://arxiv.org/abs/2407.11882v1"}
{"created":"2024-07-16 16:02:27","title":"Learning Confidence Bounds for Classification with Imbalanced Data","abstract":"Class imbalance poses a significant challenge in classification tasks, where traditional approaches often lead to biased models and unreliable predictions. Undersampling and oversampling techniques have been commonly employed to address this issue, yet they suffer from inherent limitations stemming from their simplistic approach such as loss of information and additional biases respectively. In this paper, we propose a novel framework that leverages learning theory and concentration inequalities to overcome the shortcomings of traditional solutions. We focus on understanding the uncertainty in a class-dependent manner, as captured by confidence bounds that we directly embed into the learning process. By incorporating class-dependent estimates, our method can effectively adapt to the varying degrees of imbalance across different classes, resulting in more robust and reliable classification outcomes. We empirically show how our framework provides a promising direction for handling imbalanced data in classification tasks, offering practitioners a valuable tool for building more accurate and trustworthy models.","sentences":["Class imbalance poses a significant challenge in classification tasks, where traditional approaches often lead to biased models and unreliable predictions.","Undersampling and oversampling techniques have been commonly employed to address this issue, yet they suffer from inherent limitations stemming from their simplistic approach such as loss of information and additional biases respectively.","In this paper, we propose a novel framework that leverages learning theory and concentration inequalities to overcome the shortcomings of traditional solutions.","We focus on understanding the uncertainty in a class-dependent manner, as captured by confidence bounds that we directly embed into the learning process.","By incorporating class-dependent estimates, our method can effectively adapt to the varying degrees of imbalance across different classes, resulting in more robust and reliable classification outcomes.","We empirically show how our framework provides a promising direction for handling imbalanced data in classification tasks, offering practitioners a valuable tool for building more accurate and trustworthy models."],"url":"http://arxiv.org/abs/2407.11878v1"}
{"created":"2024-07-16 16:01:25","title":"Bridging Weighted First Order Model Counting and Graph Polynomials","abstract":"The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain. It can be solved in time polynomial in the domain size for sentences from the two-variable fragment with counting quantifiers, known as $C^2$. This polynomial-time complexity is also retained when extending $C^2$ by one of the following axioms: linear order axiom, tree axiom, forest axiom, directed acyclic graph axiom or connectedness axiom. An interesting question remains as to which other axioms can be added to the first-order sentences in this way. We provide a new perspective on this problem by associating WFOMC with graph polynomials. Using WFOMC, we define Weak Connectedness Polynomial and Strong Connectedness Polynomials for first-order logic sentences. It turns out that these polynomials have the following interesting properties. First, they can be computed in polynomial time in the domain size for sentences from $C^2$. Second, we can use them to solve WFOMC with all of the existing axioms known to be tractable as well as with new ones such as bipartiteness, strong connectedness, being a spanning subgraph, having $k$ connected components, etc. Third, the well-known Tutte polynomial can be recovered as a special case of the Weak Connectedness Polynomial, and the Strict and Non-Strict Directed Chromatic Polynomials can be recovered from the Strong Connectedness Polynomials, which allows us to show that these important graph polynomials can be computed in time polynomial in the number of vertices for any graph that can be encoded by a fixed $C^2$ sentence and a conjunction of an arbitrary number of ground unary literals.","sentences":["The Weighted First-Order Model Counting Problem (WFOMC) asks to compute the weighted sum of models of a given first-order logic sentence over a given domain.","It can be solved in time polynomial in the domain size for sentences from the two-variable fragment with counting quantifiers, known as $C^2$. This polynomial-time complexity is also retained when extending $C^2$ by one of the following axioms: linear order axiom, tree axiom, forest axiom, directed acyclic graph axiom or connectedness axiom.","An interesting question remains as to which other axioms can be added to the first-order sentences in this way.","We provide a new perspective on this problem by associating WFOMC with graph polynomials.","Using WFOMC, we define Weak Connectedness Polynomial and Strong Connectedness Polynomials for first-order logic sentences.","It turns out that these polynomials have the following interesting properties.","First, they can be computed in polynomial time in the domain size for sentences from $C^2$. Second, we can use them to solve WFOMC with all of the existing axioms known to be tractable as well as with new ones such as bipartiteness, strong connectedness, being a spanning subgraph, having $k$ connected components, etc.","Third, the well-known Tutte polynomial can be recovered as a special case of the Weak Connectedness Polynomial, and the Strict and Non-Strict Directed Chromatic Polynomials can be recovered from the Strong Connectedness Polynomials, which allows us to show that these important graph polynomials can be computed in time polynomial in the number of vertices for any graph that can be encoded by a fixed $C^2$ sentence and a conjunction of an arbitrary number of ground unary literals."],"url":"http://arxiv.org/abs/2407.11877v1"}
{"created":"2024-07-16 16:00:42","title":"Simplifying the Theory on Over-Smoothing","abstract":"Graph convolutions have gained popularity due to their ability to efficiently operate on data with an irregular geometric structure. However, graph convolutions cause over-smoothing, which refers to representations becoming more similar with increased depth. However, many different definitions and intuitions currently coexist, leading to research efforts focusing on incompatible directions. This paper attempts to align these directions by showing that over-smoothing is merely a special case of power iteration. This greatly simplifies the existing theory on over-smoothing, making it more accessible. Based on the theory, we provide a novel comprehensive definition of rank collapse as a generalized form of over-smoothing and introduce the rank-one distance as a corresponding metric. Our empirical evaluation of 14 commonly used methods shows that more models than were previously known suffer from this issue.","sentences":["Graph convolutions have gained popularity due to their ability to efficiently operate on data with an irregular geometric structure.","However, graph convolutions cause over-smoothing, which refers to representations becoming more similar with increased depth.","However, many different definitions and intuitions currently coexist, leading to research efforts focusing on incompatible directions.","This paper attempts to align these directions by showing that over-smoothing is merely a special case of power iteration.","This greatly simplifies the existing theory on over-smoothing, making it more accessible.","Based on the theory, we provide a novel comprehensive definition of rank collapse as a generalized form of over-smoothing and introduce the rank-one distance as a corresponding metric.","Our empirical evaluation of 14 commonly used methods shows that more models than were previously known suffer from this issue."],"url":"http://arxiv.org/abs/2407.11876v1"}
{"created":"2024-07-16 15:57:48","title":"Proportional Dynamics in Linear Fisher Markets with Auto-bidding: Convergence, Incentives and Fairness","abstract":"Proportional dynamics, originated from peer-to-peer file sharing systems, models a decentralized price-learning process in Fisher markets. Previously, items in the dynamics operate independently of one another, and each is assumed to belong to a different seller. In this paper, we show how it can be generalized to the setting where each seller brings multiple items and buyers allocate budgets at the granularity of sellers rather than individual items. The generalized dynamics consistently converges to the competitive equilibrium, and interestingly relates to the auto-bidding paradigm currently popular in online advertising auction markets. In contrast to peer-to-peer networks, the proportional rule is not imposed as a protocol in auto-bidding markets. Regarding this incentive concern, we show that buyers have a strong tendency to follow the rule, but it is easy for sellers to profitably deviate (given buyers' commitment to the rule). Based on this observation, we further study the seller-side deviation game and show that it admits a unique pure Nash equilibrium. Though it is generally different from the competitive equilibrium, we show that it attains a good fairness guarantee as long as the market is competitive enough and not severely monopolized.","sentences":["Proportional dynamics, originated from peer-to-peer file sharing systems, models a decentralized price-learning process in Fisher markets.","Previously, items in the dynamics operate independently of one another, and each is assumed to belong to a different seller.","In this paper, we show how it can be generalized to the setting where each seller brings multiple items and buyers allocate budgets at the granularity of sellers rather than individual items.","The generalized dynamics consistently converges to the competitive equilibrium, and interestingly relates to the auto-bidding paradigm currently popular in online advertising auction markets.","In contrast to peer-to-peer networks, the proportional rule is not imposed as a protocol in auto-bidding markets.","Regarding this incentive concern, we show that buyers have a strong tendency to follow the rule, but it is easy for sellers to profitably deviate (given buyers' commitment to the rule).","Based on this observation, we further study the seller-side deviation game and show that it admits a unique pure Nash equilibrium.","Though it is generally different from the competitive equilibrium, we show that it attains a good fairness guarantee as long as the market is competitive enough and not severely monopolized."],"url":"http://arxiv.org/abs/2407.11872v1"}
{"created":"2024-07-16 15:54:28","title":"Fusion LiDAR-Inertial-Encoder data for High-Accuracy SLAM","abstract":"In the realm of robotics, achieving simultaneous localization and mapping (SLAM) is paramount for autonomous navigation, especially in challenging environments like texture-less structures. This paper proposed a factor-graph-based model that tightly integrates IMU and encoder sensors to enhance positioning in such environments. The system operates by meticulously evaluating the data from each sensor. Based on these evaluations, weights are dynamically adjusted to prioritize the more reliable source of information at any given moment. The robot's state is initialized using IMU data, while the encoder aids motion estimation in long corridors. Discrepancies between the two states are used to correct IMU drift. The effectiveness of this method is demonstrably validated through experimentation. Compared to Karto SLAM, a widely used SLAM algorithm, this approach achieves an improvement of 26.98% in rotation angle error and 67.68% reduction in position error. These results convincingly demonstrate the method's superior accuracy and robustness in texture-less environments.","sentences":["In the realm of robotics, achieving simultaneous localization and mapping (SLAM) is paramount for autonomous navigation, especially in challenging environments like texture-less structures.","This paper proposed a factor-graph-based model that tightly integrates IMU and encoder sensors to enhance positioning in such environments.","The system operates by meticulously evaluating the data from each sensor.","Based on these evaluations, weights are dynamically adjusted to prioritize the more reliable source of information at any given moment.","The robot's state is initialized using IMU data, while the encoder aids motion estimation in long corridors.","Discrepancies between the two states are used to correct IMU drift.","The effectiveness of this method is demonstrably validated through experimentation.","Compared to Karto SLAM, a widely used SLAM algorithm, this approach achieves an improvement of 26.98% in rotation angle error and 67.68% reduction in position error.","These results convincingly demonstrate the method's superior accuracy and robustness in texture-less environments."],"url":"http://arxiv.org/abs/2407.11870v1"}
{"created":"2024-07-16 15:54:09","title":"Price Competition in Linear Fisher Markets: Stability, Equilibrium and Personalization","abstract":"Linear Fisher market is one of the most fundamental economic models. The market is traditionally examined on the basis of individual's price-taking behavior. However, this assumption breaks in markets such as online advertising and e-commerce, where several oligopolists dominate the market and are able to compete with each other via strategic actions. Motivated by this, we study the price competition among sellers in linear Fisher markets. From an algorithmic game-theoretic perspective, we establish a model to analyze behaviors of buyers and sellers that are driven by utility-maximizing purposes and also constrained by computational tractability. The main economic observation is the role played by personalization: the classic benchmark market outcome, namely competitive equilibrium, remains to be a steady-state if every buyer must be treated \"equally\"; however, sellers have the incentive to personalize, and as a result the market would become more unpredictable and less efficient. In addition, we build a series of algorithmic and complexity results along the road to justify our modeling choices and reveal market structures. We find interesting connections between our model and other computational problems such as stable matching, network flow, etc. We believe these results and techniques are of independent interest.","sentences":["Linear Fisher market is one of the most fundamental economic models.","The market is traditionally examined on the basis of individual's price-taking behavior.","However, this assumption breaks in markets such as online advertising and e-commerce, where several oligopolists dominate the market and are able to compete with each other via strategic actions.","Motivated by this, we study the price competition among sellers in linear Fisher markets.","From an algorithmic game-theoretic perspective, we establish a model to analyze behaviors of buyers and sellers that are driven by utility-maximizing purposes and also constrained by computational tractability.","The main economic observation is the role played by personalization: the classic benchmark market outcome, namely competitive equilibrium, remains to be a steady-state if every buyer must be treated \"equally\"; however, sellers have the incentive to personalize, and as a result the market would become more unpredictable and less efficient.","In addition, we build a series of algorithmic and complexity results along the road to justify our modeling choices and reveal market structures.","We find interesting connections between our model and other computational problems such as stable matching, network flow, etc.","We believe these results and techniques are of independent interest."],"url":"http://arxiv.org/abs/2407.11869v1"}
{"created":"2024-07-16 15:52:36","title":"Single Layer Single Gradient Unlearning","abstract":"Machine unlearning methods seek to revise pretrained models such that effects of certain training samples can be removed. In addition to effective erasure, low computational cost and general utility retention are also highly desirable. Existing unlearning methods usually involve iterative updates over the model parameters, which incurs a high computational cost. In this work, we propose an efficient method that only requires a one-time gradient computation, with which we modify only a single layer of model parameters. Specifically, we first identify a small number of model layers that lie on the Pareto front of high forget importance and low retain influence as critical layers. Then we search for a suitable step size and take a step along the gradient direction of a single critical layer while keeping other layers frozen. This method is highly modular and can be used to unlearn multiple concepts simultaneously in a controllable manner. We demonstrate the effectiveness and efficiency of this method on various models including CLIP, stable diffusion, and VLMs, surpassing other state-of-the-art methods.","sentences":["Machine unlearning methods seek to revise pretrained models such that effects of certain training samples can be removed.","In addition to effective erasure, low computational cost and general utility retention are also highly desirable.","Existing unlearning methods usually involve iterative updates over the model parameters, which incurs a high computational cost.","In this work, we propose an efficient method that only requires a one-time gradient computation, with which we modify only a single layer of model parameters.","Specifically, we first identify a small number of model layers that lie on the Pareto front of high forget importance and low retain influence as critical layers.","Then we search for a suitable step size and take a step along the gradient direction of a single critical layer while keeping other layers frozen.","This method is highly modular and can be used to unlearn multiple concepts simultaneously in a controllable manner.","We demonstrate the effectiveness and efficiency of this method on various models including CLIP, stable diffusion, and VLMs, surpassing other state-of-the-art methods."],"url":"http://arxiv.org/abs/2407.11867v1"}
{"created":"2024-07-16 15:49:05","title":"A Novel Lexicon for the Moral Foundation of Liberty","abstract":"The moral value of liberty is a central concept in our inference system when it comes to taking a stance towards controversial social issues such as vaccine hesitancy, climate change, or the right to abortion. Here, we propose a novel Liberty lexicon evaluated on more than 3,000 manually annotated data both in in- and out-of-domain scenarios. As a result of this evaluation, we produce a combined lexicon that constitutes the main outcome of this work. This final lexicon incorporates information from an ensemble of lexicons that have been generated using word embedding similarity (WE) and compositional semantics (CS). Our key contributions include enriching the liberty annotations, developing a robust liberty lexicon for broader application, and revealing the complexity of expressions related to liberty across different platforms. Through the evaluation, we show that the difficulty of the task calls for designing approaches that combine knowledge, in an effort of improving the representations of learning systems.","sentences":["The moral value of liberty is a central concept in our inference system when it comes to taking a stance towards controversial social issues such as vaccine hesitancy, climate change, or the right to abortion.","Here, we propose a novel Liberty lexicon evaluated on more than 3,000 manually annotated data both in in- and out-of-domain scenarios.","As a result of this evaluation, we produce a combined lexicon that constitutes the main outcome of this work.","This final lexicon incorporates information from an ensemble of lexicons that have been generated using word embedding similarity (WE) and compositional semantics (CS).","Our key contributions include enriching the liberty annotations, developing a robust liberty lexicon for broader application, and revealing the complexity of expressions related to liberty across different platforms.","Through the evaluation, we show that the difficulty of the task calls for designing approaches that combine knowledge, in an effort of improving the representations of learning systems."],"url":"http://arxiv.org/abs/2407.11862v1"}
{"created":"2024-07-16 15:48:36","title":"What Makes a Meme a Meme? Identifying Memes for Memetics-Aware Dataset Creation","abstract":"Warning: This paper contains memes that may be offensive to some readers.   Multimodal Internet Memes are now a ubiquitous fixture in online discourse. One strand of meme-based research is the classification of memes according to various affects, such as sentiment and hate, supported by manually compiled meme datasets. Understanding the unique characteristics of memes is crucial for meme classification. Unlike other user-generated content, memes spread via memetics, i.e. the process by which memes are imitated and transformed into symbols used to create new memes. In effect, there exists an ever-evolving pool of visual and linguistic symbols that underpin meme culture and are crucial to interpreting the meaning of individual memes. The current approach of training supervised learning models on static datasets, without taking memetics into account, limits the depth and accuracy of meme interpretation. We argue that meme datasets must contain genuine memes, as defined via memetics, so that effective meme classifiers can be built. In this work, we develop a meme identification protocol which distinguishes meme from non-memetic content by recognising the memetics within it. We apply our protocol to random samplings of the leading 7 meme classification datasets and observe that more than half (50. 4\\%) of the evaluated samples were found to contain no signs of memetics. Our work also provides a meme typology grounded in memetics, providing the basis for more effective approaches to the interpretation of memes and the creation of meme datasets.","sentences":["Warning:","This paper contains memes that may be offensive to some readers.   ","Multimodal Internet Memes are now a ubiquitous fixture in online discourse.","One strand of meme-based research is the classification of memes according to various affects, such as sentiment and hate, supported by manually compiled meme datasets.","Understanding the unique characteristics of memes is crucial for meme classification.","Unlike other user-generated content, memes spread via memetics, i.e. the process by which memes are imitated and transformed into symbols used to create new memes.","In effect, there exists an ever-evolving pool of visual and linguistic symbols that underpin meme culture and are crucial to interpreting the meaning of individual memes.","The current approach of training supervised learning models on static datasets, without taking memetics into account, limits the depth and accuracy of meme interpretation.","We argue that meme datasets must contain genuine memes, as defined via memetics, so that effective meme classifiers can be built.","In this work, we develop a meme identification protocol which distinguishes meme from non-memetic content by recognising the memetics within it.","We apply our protocol to random samplings of the leading 7 meme classification datasets and observe that more than half (50. 4\\%) of the evaluated samples were found to contain no signs of memetics.","Our work also provides a meme typology grounded in memetics, providing the basis for more effective approaches to the interpretation of memes and the creation of meme datasets."],"url":"http://arxiv.org/abs/2407.11861v1"}
{"created":"2024-07-16 15:44:37","title":"Mitigating Background Shift in Class-Incremental Semantic Segmentation","abstract":"Class-Incremental Semantic Segmentation(CISS) aims to learn new classes without forgetting the old ones, using only the labels of the new classes. To achieve this, two popular strategies are employed: 1) pseudo-labeling and knowledge distillation to preserve prior knowledge; and 2) background weight transfer, which leverages the broad coverage of background in learning new classes by transferring background weight to the new class classifier. However, the first strategy heavily relies on the old model in detecting old classes while undetected pixels are regarded as the background, thereby leading to the background shift towards the old classes(i.e., misclassification of old class as background). Additionally, in the case of the second approach, initializing the new class classifier with background knowledge triggers a similar background shift issue, but towards the new classes. To address these issues, we propose a background-class separation framework for CISS. To begin with, selective pseudo-labeling and adaptive feature distillation are to distill only trustworthy past knowledge. On the other hand, we encourage the separation between the background and new classes with a novel orthogonal objective along with label-guided output distillation. Our state-of-the-art results validate the effectiveness of these proposed methods.","sentences":["Class-Incremental Semantic Segmentation(CISS) aims to learn new classes without forgetting the old ones, using only the labels of the new classes.","To achieve this, two popular strategies are employed: 1) pseudo-labeling and knowledge distillation to preserve prior knowledge; and 2) background weight transfer, which leverages the broad coverage of background in learning new classes by transferring background weight to the new class classifier.","However, the first strategy heavily relies on the old model in detecting old classes while undetected pixels are regarded as the background, thereby leading to the background shift towards the old classes(i.e., misclassification of old class as background).","Additionally, in the case of the second approach, initializing the new class classifier with background knowledge triggers a similar background shift issue, but towards the new classes.","To address these issues, we propose a background-class separation framework for CISS.","To begin with, selective pseudo-labeling and adaptive feature distillation are to distill only trustworthy past knowledge.","On the other hand, we encourage the separation between the background and new classes with a novel orthogonal objective along with label-guided output distillation.","Our state-of-the-art results validate the effectiveness of these proposed methods."],"url":"http://arxiv.org/abs/2407.11859v1"}
{"created":"2024-07-16 15:38:41","title":"Evaluating Task-Oriented Dialogue Consistency through Constraint Satisfaction","abstract":"Task-oriented dialogues must maintain consistency both within the dialogue itself, ensuring logical coherence across turns, and with the conversational domain, accurately reflecting external knowledge. We propose to conceptualize dialogue consistency as a Constraint Satisfaction Problem (CSP), wherein variables represent segments of the dialogue referencing the conversational domain, and constraints among variables reflect dialogue properties, including linguistic, conversational, and domain-based aspects. To demonstrate the feasibility of the approach, we utilize a CSP solver to detect inconsistencies in dialogues re-lexicalized by an LLM. Our findings indicate that: (i) CSP is effective to detect dialogue inconsistencies; and (ii) consistent dialogue re-lexicalization is challenging for state-of-the-art LLMs, achieving only a 0.15 accuracy rate when compared to a CSP solver. Furthermore, through an ablation study, we reveal that constraints derived from domain knowledge pose the greatest difficulty in being respected. We argue that CSP captures core properties of dialogue consistency that have been poorly considered by approaches based on component pipelines.","sentences":["Task-oriented dialogues must maintain consistency both within the dialogue itself, ensuring logical coherence across turns, and with the conversational domain, accurately reflecting external knowledge.","We propose to conceptualize dialogue consistency as a Constraint Satisfaction Problem (CSP), wherein variables represent segments of the dialogue referencing the conversational domain, and constraints among variables reflect dialogue properties, including linguistic, conversational, and domain-based aspects.","To demonstrate the feasibility of the approach, we utilize a CSP solver to detect inconsistencies in dialogues re-lexicalized by an LLM.","Our findings indicate that: (i) CSP is effective to detect dialogue inconsistencies; and (ii) consistent dialogue re-lexicalization is challenging for state-of-the-art LLMs, achieving only a 0.15 accuracy rate when compared to a CSP solver.","Furthermore, through an ablation study, we reveal that constraints derived from domain knowledge pose the greatest difficulty in being respected.","We argue that CSP captures core properties of dialogue consistency that have been poorly considered by approaches based on component pipelines."],"url":"http://arxiv.org/abs/2407.11857v1"}
{"created":"2024-07-16 15:38:09","title":"Faster and Smaller Solutions of Obliging Games","abstract":"Obliging games have been introduced in the context of the game perspective on reactive synthesis in order to enforce a degree of cooperation between the to-be-synthesized system and the environment. Previous approaches to the analysis of obliging games have been small-step in the sense that they have been based on a reduction to standard (non-obliging) games in which single moves correspond to single moves in the original (obliging) game. Here, we propose a novel, large-step view on obliging games, reducing them to standard games in which single moves encode long-term behaviors in the original game. This not only allows us to give a meaningful definition of the environment winning in obliging games, but also leads to significantly improved bounds on both strategy sizes and the solution runtime for obliging games.","sentences":["Obliging games have been introduced in the context of the game perspective on reactive synthesis in order to enforce a degree of cooperation between the to-be-synthesized system and the environment.","Previous approaches to the analysis of obliging games have been small-step in the sense that they have been based on a reduction to standard (non-obliging) games in which single moves correspond to single moves in the original (obliging) game.","Here, we propose a novel, large-step view on obliging games, reducing them to standard games in which single moves encode long-term behaviors in the original game.","This not only allows us to give a meaningful definition of the environment winning in obliging games, but also leads to significantly improved bounds on both strategy sizes and the solution runtime for obliging games."],"url":"http://arxiv.org/abs/2407.11856v1"}
{"created":"2024-07-16 15:36:58","title":"Scaling Sign Language Translation","abstract":"Sign language translation (SLT) addresses the problem of translating information from a sign language in video to a spoken language in text. Existing studies, while showing progress, are often limited to narrow domains and/or few sign languages and struggle with open-domain tasks. In this paper, we push forward the frontier of SLT by scaling pretraining data, model size, and number of translation directions. We perform large-scale SLT pretraining on different data including 1) noisy multilingual YouTube SLT data, 2) parallel text corpora, and 3) SLT data augmented by translating video captions to other languages with off-the-shelf machine translation models. We unify different pretraining tasks with task-specific prompts under the encoder-decoder architecture, and initialize the SLT model with pretrained (m/By)T5 models across model sizes. SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL to 42 spoken languages) demonstrate the significance of data/model scaling and cross-lingual cross-modal transfer, as well as the feasibility of zero-shot SLT. We finetune the pretrained SLT models on 5 downstream open-domain SLT benchmarks covering 5 sign languages. Experiments show substantial quality improvements over the vanilla baselines, surpassing the previous state-of-the-art (SOTA) by wide margins.","sentences":["Sign language translation (SLT) addresses the problem of translating information from a sign language in video to a spoken language in text.","Existing studies, while showing progress, are often limited to narrow domains and/or few sign languages and struggle with open-domain tasks.","In this paper, we push forward the frontier of SLT by scaling pretraining data, model size, and number of translation directions.","We perform large-scale SLT pretraining on different data including 1) noisy multilingual YouTube SLT data, 2) parallel text corpora, and 3) SLT data augmented by translating video captions to other languages with off-the-shelf machine translation models.","We unify different pretraining tasks with task-specific prompts under the encoder-decoder architecture, and initialize the SLT model with pretrained (m/By)T5 models across model sizes.","SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL to 42 spoken languages) demonstrate the significance of data/model scaling and cross-lingual cross-modal transfer, as well as the feasibility of zero-shot SLT.","We finetune the pretrained SLT models on 5 downstream open-domain SLT benchmarks covering 5 sign languages.","Experiments show substantial quality improvements over the vanilla baselines, surpassing the previous state-of-the-art (SOTA) by wide margins."],"url":"http://arxiv.org/abs/2407.11855v1"}
{"created":"2024-07-16 15:35:15","title":"Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection","abstract":"Grammatical Error Detection (GED) methods rely heavily on human annotated error corpora. However, these annotations are unavailable in many low-resource languages. In this paper, we investigate GED in this context. Leveraging the zero-shot cross-lingual transfer capabilities of multilingual pre-trained language models, we train a model using data from a diverse set of languages to generate synthetic errors in other languages. These synthetic error corpora are then used to train a GED model. Specifically we propose a two-stage fine-tuning pipeline where the GED model is first fine-tuned on multilingual synthetic data from target languages followed by fine-tuning on human-annotated GED corpora from source languages. This approach outperforms current state-of-the-art annotation-free GED methods. We also analyse the errors produced by our method and other strong baselines, finding that our approach produces errors that are more diverse and more similar to human errors.","sentences":["Grammatical Error Detection (GED) methods rely heavily on human annotated error corpora.","However, these annotations are unavailable in many low-resource languages.","In this paper, we investigate GED in this context.","Leveraging the zero-shot cross-lingual transfer capabilities of multilingual pre-trained language models, we train a model using data from a diverse set of languages to generate synthetic errors in other languages.","These synthetic error corpora are then used to train a GED model.","Specifically we propose a two-stage fine-tuning pipeline where the GED model is first fine-tuned on multilingual synthetic data from target languages followed by fine-tuning on human-annotated GED corpora from source languages.","This approach outperforms current state-of-the-art annotation-free GED methods.","We also analyse the errors produced by our method and other strong baselines, finding that our approach produces errors that are more diverse and more similar to human errors."],"url":"http://arxiv.org/abs/2407.11854v1"}
{"created":"2024-07-16 15:35:11","title":"A Case for Application-Aware Space Radiation Tolerance in Orbital Computing","abstract":"We are witnessing a surge in the use of commercial off-the-shelf (COTS) hardware for cost-effective in-orbit computing, such as deep neural network (DNN) based on-satellite sensor data processing, Earth object detection, and task decision.However, once exposed to harsh space environments, COTS hardware is vulnerable to cosmic radiation and suffers from exhaustive single-event upsets (SEUs) and multi-unit upsets (MCUs), both threatening the functionality and correctness of in-orbit computing.Existing hardware and system software protections against radiation are expensive for resource-constrained COTS nanosatellites and overwhelming for upper-layer applications due to their requirement for heavy resource redundancy and frequent reboots. Instead, we make a case for cost-effective space radiation tolerance using application domain knowledge. Our solution for the on-satellite DNN tasks, \\name, exploits the uneven SEU/MCU sensitivity across DNN layers and MCUs' spatial correlation for lightweight radiation-tolerant in-orbit AI computing. Our extensive experiments using Chaohu-1 SAR satellite payloads and a hardware-in-the-loop, real data-driven space radiation emulator validate that RedNet can suppress the influence of radiation errors to $\\approx$ 0 and accelerate the on-satellite DNN inference speed by 8.4%-33.0% at negligible extra costs.","sentences":["We are witnessing a surge in the use of commercial off-the-shelf (COTS) hardware for cost-effective in-orbit computing, such as deep neural network (DNN) based on-satellite sensor data processing, Earth object detection, and task decision.","However, once exposed to harsh space environments, COTS hardware is vulnerable to cosmic radiation and suffers from exhaustive single-event upsets (SEUs) and multi-unit upsets (MCUs), both threatening the functionality and correctness of in-orbit computing.","Existing hardware and system software protections against radiation are expensive for resource-constrained COTS nanosatellites and overwhelming for upper-layer applications due to their requirement for heavy resource redundancy and frequent reboots.","Instead, we make a case for cost-effective space radiation tolerance using application domain knowledge.","Our solution for the on-satellite DNN tasks, \\name, exploits the uneven SEU/MCU sensitivity across DNN layers and MCUs' spatial correlation for lightweight radiation-tolerant in-orbit AI computing.","Our extensive experiments using Chaohu-1 SAR satellite payloads and a hardware-in-the-loop, real data-driven space radiation emulator validate that RedNet can suppress the influence of radiation errors to $\\approx$ 0 and accelerate the on-satellite DNN inference speed by 8.4%-33.0% at negligible extra costs."],"url":"http://arxiv.org/abs/2407.11853v1"}
{"created":"2024-07-16 15:33:00","title":"Schema Matching with Large Language Models: an Experimental Study","abstract":"Large Language Models (LLMs) have shown useful applications in a variety of tasks, including data wrangling. In this paper, we investigate the use of an off-the-shelf LLM for schema matching. Our objective is to identify semantic correspondences between elements of two relational schemas using only names and descriptions. Using a newly created benchmark from the health domain, we propose different so-called task scopes. These are methods for prompting the LLM to do schema matching, which vary in the amount of context information contained in the prompt. Using these task scopes we compare LLM-based schema matching against a string similarity baseline, investigating matching quality, verification effort, decisiveness, and complementarity of the approaches. We find that matching quality suffers from a lack of context information, but also from providing too much context information. In general, using newer LLM versions increases decisiveness. We identify task scopes that have acceptable verification effort and succeed in identifying a significant number of true semantic matches. Our study shows that LLMs have potential in bootstrapping the schema matching process and are able to assist data engineers in speeding up this task solely based on schema element names and descriptions without the need for data instances.","sentences":["Large Language Models (LLMs) have shown useful applications in a variety of tasks, including data wrangling.","In this paper, we investigate the use of an off-the-shelf LLM for schema matching.","Our objective is to identify semantic correspondences between elements of two relational schemas using only names and descriptions.","Using a newly created benchmark from the health domain, we propose different so-called task scopes.","These are methods for prompting the LLM to do schema matching, which vary in the amount of context information contained in the prompt.","Using these task scopes we compare LLM-based schema matching against a string similarity baseline, investigating matching quality, verification effort, decisiveness, and complementarity of the approaches.","We find that matching quality suffers from a lack of context information, but also from providing too much context information.","In general, using newer LLM versions increases decisiveness.","We identify task scopes that have acceptable verification effort and succeed in identifying a significant number of true semantic matches.","Our study shows that LLMs have potential in bootstrapping the schema matching process and are able to assist data engineers in speeding up this task solely based on schema element names and descriptions without the need for data instances."],"url":"http://arxiv.org/abs/2407.11852v1"}
{"created":"2024-07-16 15:32:39","title":"SpaceJAM: a Lightweight and Regularization-free Method for Fast Joint Alignment of Images","abstract":"The unsupervised task of Joint Alignment (JA) of images is beset by challenges such as high complexity, geometric distortions, and convergence to poor local or even global optima. Although Vision Transformers (ViT) have recently provided valuable features for JA, they fall short of fully addressing these issues. Consequently, researchers frequently depend on expensive models and numerous regularization terms, resulting in long training times and challenging hyperparameter tuning. We introduce the Spatial Joint Alignment Model (SpaceJAM), a novel approach that addresses the JA task with efficiency and simplicity. SpaceJAM leverages a compact architecture with only 16K trainable parameters and uniquely operates without the need for regularization or atlas maintenance. Evaluations on SPair-71K and CUB datasets demonstrate that SpaceJAM matches the alignment capabilities of existing methods while significantly reducing computational demands and achieving at least a 10x speedup. SpaceJAM sets a new standard for rapid and effective image alignment, making the process more accessible and efficient. Our code is available at: https://bgu-cs-vil.github.io/SpaceJAM/.","sentences":["The unsupervised task of Joint Alignment (JA) of images is beset by challenges such as high complexity, geometric distortions, and convergence to poor local or even global optima.","Although Vision Transformers (ViT) have recently provided valuable features for JA, they fall short of fully addressing these issues.","Consequently, researchers frequently depend on expensive models and numerous regularization terms, resulting in long training times and challenging hyperparameter tuning.","We introduce the Spatial Joint Alignment Model (SpaceJAM), a novel approach that addresses the JA task with efficiency and simplicity.","SpaceJAM leverages a compact architecture with only 16K trainable parameters and uniquely operates without the need for regularization or atlas maintenance.","Evaluations on SPair-71K and CUB datasets demonstrate that SpaceJAM matches the alignment capabilities of existing methods while significantly reducing computational demands and achieving at least a 10x speedup.","SpaceJAM sets a new standard for rapid and effective image alignment, making the process more accessible and efficient.","Our code is available at: https://bgu-cs-vil.github.io/SpaceJAM/."],"url":"http://arxiv.org/abs/2407.11850v1"}
{"created":"2024-07-16 15:25:13","title":"Variational Randomized Smoothing for Sample-Wise Adversarial Robustness","abstract":"Randomized smoothing is a defensive technique to achieve enhanced robustness against adversarial examples which are small input perturbations that degrade the performance of neural network models. Conventional randomized smoothing adds random noise with a fixed noise level for every input sample to smooth out adversarial perturbations. This paper proposes a new variational framework that uses a per-sample noise level suitable for each input by introducing a noise level selector. Our experimental results demonstrate enhancement of empirical robustness against adversarial attacks. We also provide and analyze the certified robustness for our sample-wise smoothing method.","sentences":["Randomized smoothing is a defensive technique to achieve enhanced robustness against adversarial examples which are small input perturbations that degrade the performance of neural network models.","Conventional randomized smoothing adds random noise with a fixed noise level for every input sample to smooth out adversarial perturbations.","This paper proposes a new variational framework that uses a per-sample noise level suitable for each input by introducing a noise level selector.","Our experimental results demonstrate enhancement of empirical robustness against adversarial attacks.","We also provide and analyze the certified robustness for our sample-wise smoothing method."],"url":"http://arxiv.org/abs/2407.11844v1"}
{"created":"2024-07-16 15:24:44","title":"InferAct: Inferring Safe Actions for LLM-Based Agents Through Preemptive Evaluation and Human Feedback","abstract":"A crucial requirement for deploying LLM-based agents in real-life applications is robustness against risky or irreversible mistakes. However, existing research lacks a focus on the preemptive evaluation of reasoning trajectories performed by LLM agents, leading to a gap in ensuring safe and reliable operations. To explore better solutions, this paper introduces InferAct, a novel approach that leverages the Theory-of-Mind capability of LLMs to proactively detect potential errors before critical actions are executed (e.g., \"buy-now\" in automatic online trading or web shopping). InferAct is also capable of integrating human feedback to prevent irreversible risks and enhance the actor agent's decision-making process. Experiments on three widely used tasks demonstrate the effectiveness of InferAct. The proposed solution presents a novel approach and concrete contributions toward developing LLM agents that can be safely deployed in different environments involving critical decision-making.","sentences":["A crucial requirement for deploying LLM-based agents in real-life applications is robustness against risky or irreversible mistakes.","However, existing research lacks a focus on the preemptive evaluation of reasoning trajectories performed by LLM agents, leading to a gap in ensuring safe and reliable operations.","To explore better solutions, this paper introduces InferAct, a novel approach that leverages the Theory-of-Mind capability of LLMs to proactively detect potential errors before critical actions are executed (e.g., \"buy-now\" in automatic online trading or web shopping).","InferAct is also capable of integrating human feedback to prevent irreversible risks and enhance the actor agent's decision-making process.","Experiments on three widely used tasks demonstrate the effectiveness of InferAct.","The proposed solution presents a novel approach and concrete contributions toward developing LLM agents that can be safely deployed in different environments involving critical decision-making."],"url":"http://arxiv.org/abs/2407.11843v1"}
{"created":"2024-07-16 15:24:01","title":"MVG-Splatting: Multi-View Guided Gaussian Splatting with Adaptive Quantile-Based Geometric Consistency Densification","abstract":"In the rapidly evolving field of 3D reconstruction, 3D Gaussian Splatting (3DGS) and 2D Gaussian Splatting (2DGS) represent significant advancements. Although 2DGS compresses 3D Gaussian primitives into 2D Gaussian surfels to effectively enhance mesh extraction quality, this compression can potentially lead to a decrease in rendering quality. Additionally, unreliable densification processes and the calculation of depth through the accumulation of opacity can compromise the detail of mesh extraction. To address this issue, we introduce MVG-Splatting, a solution guided by Multi-View considerations. Specifically, we integrate an optimized method for calculating normals, which, combined with image gradients, helps rectify inconsistencies in the original depth computations. Additionally, utilizing projection strategies akin to those in Multi-View Stereo (MVS), we propose an adaptive quantile-based method that dynamically determines the level of additional densification guided by depth maps, from coarse to fine detail. Experimental evidence demonstrates that our method not only resolves the issues of rendering quality degradation caused by depth discrepancies but also facilitates direct mesh extraction from dense Gaussian point clouds using the Marching Cubes algorithm. This approach significantly enhances the overall fidelity and accuracy of the 3D reconstruction process, ensuring that both the geometric details and visual quality.","sentences":["In the rapidly evolving field of 3D reconstruction, 3D Gaussian Splatting (3DGS) and 2D Gaussian Splatting (2DGS) represent significant advancements.","Although 2DGS compresses 3D Gaussian primitives into 2D Gaussian surfels to effectively enhance mesh extraction quality, this compression can potentially lead to a decrease in rendering quality.","Additionally, unreliable densification processes and the calculation of depth through the accumulation of opacity can compromise the detail of mesh extraction.","To address this issue, we introduce MVG-Splatting, a solution guided by Multi-View considerations.","Specifically, we integrate an optimized method for calculating normals, which, combined with image gradients, helps rectify inconsistencies in the original depth computations.","Additionally, utilizing projection strategies akin to those in Multi-View Stereo (MVS), we propose an adaptive quantile-based method that dynamically determines the level of additional densification guided by depth maps, from coarse to fine detail.","Experimental evidence demonstrates that our method not only resolves the issues of rendering quality degradation caused by depth discrepancies but also facilitates direct mesh extraction from dense Gaussian point clouds using the Marching Cubes algorithm.","This approach significantly enhances the overall fidelity and accuracy of the 3D reconstruction process, ensuring that both the geometric details and visual quality."],"url":"http://arxiv.org/abs/2407.11840v1"}
{"created":"2024-07-16 15:22:10","title":"The Patchkeeper: An Integrated Wearable Electronic Stethoscope with Multiple Sensors","abstract":"Many parts of human body generate internal sound during biological processes, which are rich sources of information for understanding health and wellbeing. Despite a long history of development and usage of stethoscopes, there is still a lack of proper tools for recording internal body sound together with complementary sensors for long term monitoring. In this paper, we show our development of a wearable electronic stethoscope, coined Patchkeeper (PK), that can be used for internal body sound recording over long periods of time. Patchkeeper also integrates several state-of-the-art biological sensors, including electrocardiogram (ECG), photoplethysmography (PPG), and inertial measurement unit (IMU) sensors. As a wearable device, Patchkeeper can be placed on various parts of the body to collect sound from particular organs, including heart, lung, stomach, and joints etc. We show in this paper that several vital signals can be recorded simultaneously with high quality. As Patchkeeper can be operated directly by the user, e.g. without involving health care professionals, we believe it could be a useful tool for telemedicine and remote diagnostics.","sentences":["Many parts of human body generate internal sound during biological processes, which are rich sources of information for understanding health and wellbeing.","Despite a long history of development and usage of stethoscopes, there is still a lack of proper tools for recording internal body sound together with complementary sensors for long term monitoring.","In this paper, we show our development of a wearable electronic stethoscope, coined Patchkeeper (PK), that can be used for internal body sound recording over long periods of time.","Patchkeeper also integrates several state-of-the-art biological sensors, including electrocardiogram (ECG), photoplethysmography (PPG), and inertial measurement unit (IMU) sensors.","As a wearable device, Patchkeeper can be placed on various parts of the body to collect sound from particular organs, including heart, lung, stomach, and joints etc.","We show in this paper that several vital signals can be recorded simultaneously with high quality.","As Patchkeeper can be operated directly by the user, e.g. without involving health care professionals, we believe it could be a useful tool for telemedicine and remote diagnostics."],"url":"http://arxiv.org/abs/2407.11837v1"}
{"created":"2024-07-16 15:21:23","title":"Touch in Human Social Robot Interaction: Systematic Literature Review with PRISMA Method","abstract":"In the past two decades, there has been a continuous rise in the deployment of robots fulfilling social roles that expands across various industries such as guides, service providers, and educators. To establish robots as integral allies in daily life, it is essential for them to deliver positive and trustworthy experiences, achieved through seamless and satisfying interactions across diverse modalities and communication channels. In the realm of human-robot interactions, touch plays a pivotal role in facilitating meaningful connections and communication. To delve into the significance of haptic technologies and their impact on interactions between humans and social robots, an exploration of the existing literature is essential, since the research about touch is the most underrepresented between the other communication channels (facial expressions, movements, vocals etc). A systematic literature review has been carried out, identifying 42 articles with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), related to touch and haptic technologies and interaction between humans and social robots in the twenty years (2001 -2023). The results show the main differences, pros and cons between the materials and technologies that have been primary used so far, the qualitative and quantitative research that links the HRI touch studies with the human emotion and also the types of touch and repeatability of those methods. The study identifies research gaps and outlines future directions, while it serves as a guide for anyone who will be interesting in conducting HRI touch research or build a haptic system for a social robot.","sentences":["In the past two decades, there has been a continuous rise in the deployment of robots fulfilling social roles that expands across various industries such as guides, service providers, and educators.","To establish robots as integral allies in daily life, it is essential for them to deliver positive and trustworthy experiences, achieved through seamless and satisfying interactions across diverse modalities and communication channels.","In the realm of human-robot interactions, touch plays a pivotal role in facilitating meaningful connections and communication.","To delve into the significance of haptic technologies and their impact on interactions between humans and social robots, an exploration of the existing literature is essential, since the research about touch is the most underrepresented between the other communication channels (facial expressions, movements, vocals etc).","A systematic literature review has been carried out, identifying 42 articles with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), related to touch and haptic technologies and interaction between humans and social robots in the twenty years (2001 -2023).","The results show the main differences, pros and cons between the materials and technologies that have been primary used so far, the qualitative and quantitative research that links the HRI touch studies with the human emotion and also the types of touch and repeatability of those methods.","The study identifies research gaps and outlines future directions, while it serves as a guide for anyone who will be interesting in conducting HRI touch research or build a haptic system for a social robot."],"url":"http://arxiv.org/abs/2407.11834v1"}
{"created":"2024-07-16 15:20:43","title":"LoFTI: Localization and Factuality Transfer to Indian Locales","abstract":"Large language models (LLMs) encode vast amounts of world knowledge acquired via training on large web-scale datasets crawled from the internet. However, these datasets typically exhibit a geographical bias towards English-speaking Western countries. This results in LLMs producing biased or hallucinated responses to queries that require answers localized to other geographical regions. In this work, we introduce a new benchmark named LoFTI (Localization and Factuality Transfer to Indian Locales) that can be used to evaluate an LLM's localization and factual text transfer capabilities. LoFTI consists of factual statements about entities in source and target locations; the source locations are spread across the globe and the target locations are all within India with varying degrees of hyperlocality (country, states, cities). The entities span a wide variety of categories. We use LoFTI to evaluate Mixtral, GPT-4 and two other Mixtral-based approaches well-suited to the task of localized factual transfer. We demonstrate that LoFTI is a high-quality evaluation benchmark and all the models, including GPT-4, produce skewed results across varying levels of hyperlocality.","sentences":["Large language models (LLMs) encode vast amounts of world knowledge acquired via training on large web-scale datasets crawled from the internet.","However, these datasets typically exhibit a geographical bias towards English-speaking Western countries.","This results in LLMs producing biased or hallucinated responses to queries that require answers localized to other geographical regions.","In this work, we introduce a new benchmark named LoFTI (Localization and Factuality Transfer to Indian Locales) that can be used to evaluate an LLM's localization and factual text transfer capabilities.","LoFTI consists of factual statements about entities in source and target locations; the source locations are spread across the globe and the target locations are all within India with varying degrees of hyperlocality (country, states, cities).","The entities span a wide variety of categories.","We use LoFTI to evaluate Mixtral, GPT-4 and two other Mixtral-based approaches well-suited to the task of localized factual transfer.","We demonstrate that LoFTI is a high-quality evaluation benchmark and all the models, including GPT-4, produce skewed results across varying levels of hyperlocality."],"url":"http://arxiv.org/abs/2407.11833v1"}
{"created":"2024-07-16 15:20:30","title":"Approximating the Number of Relevant Variables in a Parity Implies Proper Learning","abstract":"Consider the model where we can access a parity function through random uniform labeled examples in the presence of random classification noise. In this paper, we show that approximating the number of relevant variables in the parity function is as hard as properly learning parities.   More specifically, let $\\gamma:{\\mathbb R}^+\\to {\\mathbb R}^+$, where $\\gamma(x) \\ge x$, be any strictly increasing function. In our first result, we show that from any polynomial-time algorithm that returns a $\\gamma$-approximation, $D$ (i.e., $\\gamma^{-1}(d(f)) \\leq D \\leq \\gamma(d(f))$), of the number of relevant variables~$d(f)$ for any parity $f$, we can, in polynomial time, construct a solution to the long-standing open problem of polynomial-time learning $k(n)$-sparse parities (parities with $k(n)\\le n$ relevant variables), where $k(n) = \\omega_n(1)$.   In our second result, we show that from any $T(n)$-time algorithm that, for any parity $f$, returns a $\\gamma$-approximation of the number of relevant variables $d(f)$ of $f$, we can, in polynomial time, construct a $poly(\\Gamma(n))T(\\Gamma(n)^2)$-time algorithm that properly learns parities, where $\\Gamma(x)=\\gamma(\\gamma(x))$.   If $T(\\Gamma(n)^2)=\\exp({o(n/\\log n)})$, this would resolve another long-standing open problem of properly learning parities in the presence of random classification noise in time $\\exp({o(n/\\log n)})$.","sentences":["Consider the model where we can access a parity function through random uniform labeled examples in the presence of random classification noise.","In this paper, we show that approximating the number of relevant variables in the parity function is as hard as properly learning parities.   ","More specifically, let $\\gamma:{\\mathbb R}^+\\to {\\mathbb R}^+$, where $\\gamma(x) \\ge x$, be any strictly increasing function.","In our first result, we show that from any polynomial-time algorithm that returns a $\\gamma$-approximation, $D$ (i.e., $\\gamma^{-1}(d(f))","\\leq D \\leq \\gamma(d(f))$), of the number of relevant variables~$d(f)$ for any parity","$f$, we can, in polynomial time, construct a solution to the long-standing open problem of polynomial-time learning $k(n)$-sparse parities (parities with $k(n)\\le n$ relevant variables), where $k(n) = \\omega_n(1)$.   In our second result, we show that from any $T(n)$-time algorithm that, for any parity $f$, returns a $\\gamma$-approximation of the number of relevant variables $d(f)$ of $f$, we can, in polynomial time, construct a $poly(\\Gamma(n))T(\\Gamma(n)^2)$-time algorithm that properly learns parities, where $\\Gamma(x)=\\gamma(\\gamma(x))$.   If $T(\\Gamma(n)^2)=\\exp({o(n/\\log n)})$, this would resolve another long-standing open problem of properly learning parities in the presence of random classification noise in time $\\exp({o(n/\\log n)})$."],"url":"http://arxiv.org/abs/2407.11832v1"}
{"created":"2024-07-16 15:20:17","title":"Haskelite: A Tracing Interpreter Based on a Pattern-Matching Calculus","abstract":"Many Haskell textbooks explain the evaluation of pure functional programs as a process of stepwise rewriting using equations. However, usual implementation techniques perform program transformations that make producing the corresponding tracing evaluations difficult. This paper presents a tracing interpreter for a subset of Haskell based on the pattern matching calculus of Kahl. We start from a big-step semantics in the style of Launchbury and develop a small-step semantics in the style of Sestoft's machines. This machine is used in the implementation of a step-by-step educational interpreter. We also discuss some implementation decisions and present illustrative examples.","sentences":["Many Haskell textbooks explain the evaluation of pure functional programs as a process of stepwise rewriting using equations.","However, usual implementation techniques perform program transformations that make producing the corresponding tracing evaluations difficult.","This paper presents a tracing interpreter for a subset of Haskell based on the pattern matching calculus of Kahl.","We start from a big-step semantics in the style of Launchbury and develop a small-step semantics in the style of Sestoft's machines.","This machine is used in the implementation of a step-by-step educational interpreter.","We also discuss some implementation decisions and present illustrative examples."],"url":"http://arxiv.org/abs/2407.11831v1"}
{"created":"2024-07-16 15:18:12","title":"Personalized Conversational Travel Assistant powered by Generative AI","abstract":"The Tourism and Destination Management Organization (DMO) industry is rapidly evolving to adapt to new technologies and traveler expectations. Generative Artificial Intelligence (AI) offers an astonishing and innovative opportunity to enhance the tourism experience by providing personalized, interactive and engaging assistance. In this article, we propose a generative AI-based chatbot for tourism assistance. The chatbot leverages AI ability to generate realistic and creative texts, adopting the friendly persona of the well-known Italian all-knowledgeable aunties, to provide tourists with personalized information, tailored and dynamic pre, during and post recommendations and trip plans and personalized itineraries, using both text and voice commands, and supporting different languages to satisfy Italian and foreign tourists expectations. This work is under development in the Molise CTE research project, funded by the Italian Minister of the Economic Growth (MIMIT), with the aim to leverage the best emerging technologies available, such as Cloud and AI to produce state of the art solutions in the Smart City environment.","sentences":["The Tourism and Destination Management Organization (DMO) industry is rapidly evolving to adapt to new technologies and traveler expectations.","Generative Artificial Intelligence (AI) offers an astonishing and innovative opportunity to enhance the tourism experience by providing personalized, interactive and engaging assistance.","In this article, we propose a generative AI-based chatbot for tourism assistance.","The chatbot leverages AI ability to generate realistic and creative texts, adopting the friendly persona of the well-known Italian all-knowledgeable aunties, to provide tourists with personalized information, tailored and dynamic pre, during and post recommendations and trip plans and personalized itineraries, using both text and voice commands, and supporting different languages to satisfy Italian and foreign tourists expectations.","This work is under development in the Molise CTE research project, funded by the Italian Minister of the Economic Growth (MIMIT), with the aim to leverage the best emerging technologies available, such as Cloud and AI to produce state of the art solutions in the Smart City environment."],"url":"http://arxiv.org/abs/2407.11830v1"}
{"created":"2024-07-16 15:15:39","title":"GPT Assisted Annotation of Rhetorical and Linguistic Features for Interpretable Propaganda Technique Detection in News Text","abstract":"While the use of machine learning for the detection of propaganda techniques in text has garnered considerable attention, most approaches focus on \"black-box\" solutions with opaque inner workings. Interpretable approaches provide a solution, however, they depend on careful feature engineering and costly expert annotated data. Additionally, language features specific to propagandistic text are generally the focus of rhetoricians or linguists, and there is no data set labeled with such features suitable for machine learning. This study codifies 22 rhetorical and linguistic features identified in literature related to the language of persuasion for the purpose of annotating an existing data set labeled with propaganda techniques. To help human experts annotate natural language sentences with these features, RhetAnn, a web application, was specifically designed to minimize an otherwise considerable mental effort. Finally, a small set of annotated data was used to fine-tune GPT-3.5, a generative large language model (LLM), to annotate the remaining data while optimizing for financial cost and classification accuracy. This study demonstrates how combining a small number of human annotated examples with GPT can be an effective strategy for scaling the annotation process at a fraction of the cost of traditional annotation relying solely on human experts. The results are on par with the best performing model at the time of writing, namely GPT-4, at 10x less the cost. Our contribution is a set of features, their properties, definitions, and examples in a machine-readable format, along with the code for RhetAnn and the GPT prompts and fine-tuning procedures for advancing state-of-the-art interpretable propaganda technique detection.","sentences":["While the use of machine learning for the detection of propaganda techniques in text has garnered considerable attention, most approaches focus on \"black-box\" solutions with opaque inner workings.","Interpretable approaches provide a solution, however, they depend on careful feature engineering and costly expert annotated data.","Additionally, language features specific to propagandistic text are generally the focus of rhetoricians or linguists, and there is no data set labeled with such features suitable for machine learning.","This study codifies 22 rhetorical and linguistic features identified in literature related to the language of persuasion for the purpose of annotating an existing data set labeled with propaganda techniques.","To help human experts annotate natural language sentences with these features, RhetAnn, a web application, was specifically designed to minimize an otherwise considerable mental effort.","Finally, a small set of annotated data was used to fine-tune GPT-3.5, a generative large language model (LLM), to annotate the remaining data while optimizing for financial cost and classification accuracy.","This study demonstrates how combining a small number of human annotated examples with GPT can be an effective strategy for scaling the annotation process at a fraction of the cost of traditional annotation relying solely on human experts.","The results are on par with the best performing model at the time of writing, namely GPT-4, at 10x less the cost.","Our contribution is a set of features, their properties, definitions, and examples in a machine-readable format, along with the code for RhetAnn and the GPT prompts and fine-tuning procedures for advancing state-of-the-art interpretable propaganda technique detection."],"url":"http://arxiv.org/abs/2407.11827v1"}
{"created":"2024-07-16 15:11:29","title":"Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy","abstract":"The United States Food and Drug Administration's (FDA's) Premarket Notification 510(K) pathway allows manufacturers to gain approval for a medical device by demonstrating its substantial equivalence to another legally marketed device. However, the inherent ambiguity of this regulatory procedure has led to high recall rates for many devices cleared through this pathway. This trend has raised significant concerns regarding the efficacy of the FDA's current approach, prompting a reassessment of the 510(K) regulatory framework. In this paper, we develop a combined human-algorithm approach to assist the FDA in improving its 510(k) medical device clearance process by reducing the risk of potential recalls and the workload imposed on the FDA. We first develop machine learning methods to estimate the risk of recall of 510(k) medical devices based on the information available at the time of submission. We then propose a data-driven clearance policy that recommends acceptance, rejection, or deferral to FDA's committees for in-depth evaluation. We conduct an empirical study using a unique large-scale dataset of over 31,000 medical devices and 12,000 national and international manufacturers from over 65 countries that we assembled based on data sources from the FDA and Centers for Medicare and Medicaid Service (CMS). A conservative evaluation of our proposed policy based on this data shows a 38.9% improvement in the recall rate and a 43.0% reduction in the FDA's workload. Our analyses also indicate that implementing our policy could result in significant annual cost-savings ranging between \\$2.4 billion and \\$2.7 billion, which highlights the value of using a holistic and data-driven approach to improve the FDA's current 510(K) medical device evaluation pathway.","sentences":["The United States Food and Drug Administration's (FDA's) Premarket Notification 510(K) pathway allows manufacturers to gain approval for a medical device by demonstrating its substantial equivalence to another legally marketed device.","However, the inherent ambiguity of this regulatory procedure has led to high recall rates for many devices cleared through this pathway.","This trend has raised significant concerns regarding the efficacy of the FDA's current approach, prompting a reassessment of the 510(K) regulatory framework.","In this paper, we develop a combined human-algorithm approach to assist the FDA in improving its 510(k) medical device clearance process by reducing the risk of potential recalls and the workload imposed on the FDA.","We first develop machine learning methods to estimate the risk of recall of 510(k) medical devices based on the information available at the time of submission.","We then propose a data-driven clearance policy that recommends acceptance, rejection, or deferral to FDA's committees for in-depth evaluation.","We conduct an empirical study using a unique large-scale dataset of over 31,000 medical devices and 12,000 national and international manufacturers from over 65 countries that we assembled based on data sources from the FDA and Centers for Medicare and Medicaid Service (CMS).","A conservative evaluation of our proposed policy based on this data shows a 38.9% improvement in the recall rate and a 43.0% reduction in the FDA's workload.","Our analyses also indicate that implementing our policy could result in significant annual cost-savings ranging between \\$2.4 billion and \\$2.7 billion, which highlights the value of using a holistic and data-driven approach to improve the FDA's current 510(K) medical device evaluation pathway."],"url":"http://arxiv.org/abs/2407.11823v1"}
{"created":"2024-07-16 15:08:33","title":"Approximating Probabilistic Inference in Statistical EL with Knowledge Graph Embeddings","abstract":"Statistical information is ubiquitous but drawing valid conclusions from it is prohibitively hard. We explain how knowledge graph embeddings can be used to approximate probabilistic inference efficiently using the example of Statistical EL (SEL), a statistical extension of the lightweight Description Logic EL. We provide proofs for runtime and soundness guarantees, and empirically evaluate the runtime and approximation quality of our approach.","sentences":["Statistical information is ubiquitous but drawing valid conclusions from it is prohibitively hard.","We explain how knowledge graph embeddings can be used to approximate probabilistic inference efficiently using the example of Statistical EL (SEL), a statistical extension of the lightweight Description Logic EL.","We provide proofs for runtime and soundness guarantees, and empirically evaluate the runtime and approximation quality of our approach."],"url":"http://arxiv.org/abs/2407.11821v1"}
{"created":"2024-07-16 15:08:30","title":"Stepping Stones: A Progressive Training Strategy for Audio-Visual Semantic Segmentation","abstract":"Audio-Visual Segmentation (AVS) aims to achieve pixel-level localization of sound sources in videos, while Audio-Visual Semantic Segmentation (AVSS), as an extension of AVS, further pursues semantic understanding of audio-visual scenes. However, since the AVSS task requires the establishment of audio-visual correspondence and semantic understanding simultaneously, we observe that previous methods have struggled to handle this mashup of objectives in end-to-end training, resulting in insufficient learning and sub-optimization. Therefore, we propose a two-stage training strategy called \\textit{Stepping Stones}, which decomposes the AVSS task into two simple subtasks from localization to semantic understanding, which are fully optimized in each stage to achieve step-by-step global optimization. This training strategy has also proved its generalization and effectiveness on existing methods. To further improve the performance of AVS tasks, we propose a novel framework Adaptive Audio Visual Segmentation, in which we incorporate an adaptive audio query generator and integrate masked attention into the transformer decoder, facilitating the adaptive fusion of visual and audio features. Extensive experiments demonstrate that our methods achieve state-of-the-art results on all three AVS benchmarks. The project homepage can be accessed at https://gewu-lab.github.io/stepping_stones/.","sentences":["Audio-Visual Segmentation (AVS) aims to achieve pixel-level localization of sound sources in videos, while Audio-Visual Semantic Segmentation (AVSS), as an extension of AVS, further pursues semantic understanding of audio-visual scenes.","However, since the AVSS task requires the establishment of audio-visual correspondence and semantic understanding simultaneously, we observe that previous methods have struggled to handle this mashup of objectives in end-to-end training, resulting in insufficient learning and sub-optimization.","Therefore, we propose a two-stage training strategy called \\textit{Stepping Stones}, which decomposes the AVSS task into two simple subtasks from localization to semantic understanding, which are fully optimized in each stage to achieve step-by-step global optimization.","This training strategy has also proved its generalization and effectiveness on existing methods.","To further improve the performance of AVS tasks, we propose a novel framework Adaptive Audio Visual Segmentation, in which we incorporate an adaptive audio query generator and integrate masked attention into the transformer decoder, facilitating the adaptive fusion of visual and audio features.","Extensive experiments demonstrate that our methods achieve state-of-the-art results on all three AVS benchmarks.","The project homepage can be accessed at https://gewu-lab.github.io/stepping_stones/."],"url":"http://arxiv.org/abs/2407.11820v1"}
{"created":"2024-07-16 15:07:30","title":"Text Indexing for Long Patterns using Locally Consistent Anchors","abstract":"In many real-world database systems, a large fraction of the data is represented by strings: sequences of letters over some alphabet. This is because strings can easily encode data arising from different sources. It is often crucial to represent such string datasets in a compact form but also to simultaneously enable fast pattern matching queries. This is the classic text indexing problem. The four absolute measures anyone should pay attention to when designing or implementing a text index are: (i) index space; (ii) query time; (iii) construction space; and (iv) construction time. Unfortunately, however, most (if not all) widely-used indexes (e.g., suffix tree, suffix array, or their compressed counterparts) are not optimized for all four measures simultaneously, as it is difficult to have the best of all four worlds. Here, we take an important step in this direction by showing that text indexing with sampling based on locally consistent anchors (lc-anchors) offers remarkably good performance in all four measures, when we have at hand a lower bound $\\ell$ on the length of the queried patterns -- which is arguably a quite reasonable assumption in practical applications. Our index offers average-case guarantees. In our experiments using real benchmark datasets, we show that it compares favorably based on the four measures to all classic indexes: (compressed) suffix tree; (compressed) suffix array; and the FM-index. Notably, we also present a counterpart of our index with worst-case guarantees based on the lc-anchors notion of partitioning sets. To the best of our knowledge, this is the first index achieving the best of all worlds in the regime where we have at hand a lower bound $\\ell$ on the length of the queried patterns.","sentences":["In many real-world database systems, a large fraction of the data is represented by strings: sequences of letters over some alphabet.","This is because strings can easily encode data arising from different sources.","It is often crucial to represent such string datasets in a compact form but also to simultaneously enable fast pattern matching queries.","This is the classic text indexing problem.","The four absolute measures anyone should pay attention to when designing or implementing a text index are: (i) index space; (ii) query time; (iii) construction space; and (iv) construction time.","Unfortunately, however, most (if not all) widely-used indexes (e.g., suffix tree, suffix array, or their compressed counterparts) are not optimized for all four measures simultaneously, as it is difficult to have the best of all four worlds.","Here, we take an important step in this direction by showing that text indexing with sampling based on locally consistent anchors (lc-anchors) offers remarkably good performance in all four measures, when we have at hand a lower bound $\\ell$ on the length of the queried patterns -- which is arguably a quite reasonable assumption in practical applications.","Our index offers average-case guarantees.","In our experiments using real benchmark datasets, we show that it compares favorably based on the four measures to all classic indexes: (compressed) suffix tree; (compressed) suffix array; and the FM-index.","Notably, we also present a counterpart of our index with worst-case guarantees based on the lc-anchors notion of partitioning sets.","To the best of our knowledge, this is the first index achieving the best of all worlds in the regime where we have at hand a lower bound $\\ell$ on the length of the queried patterns."],"url":"http://arxiv.org/abs/2407.11819v1"}
{"created":"2024-07-16 15:07:01","title":"Modal Effect Types","abstract":"We propose a novel type system for effects and handlers using modal types. Conventional effect systems attach effects to function types, which can lead to verbose effect-polymorphic types, especially for higher-order functions. Our modal effect system provides succinct types for higher-order first-class functions without losing modularity and reusability. The core idea is to decouple effects from function types and instead to track effects through relative and absolute modalities, which represent transformations on the ambient effects provided by the context.   We formalise the idea of modal effect types in a multimodal System F-style core calculus Met with effects and handlers. Met supports modular effectful programming via modalities without relying on effect variables. We encode a practical fragment of a conventional row-based effect system with effect polymorphism, which captures most common use-cases, into Met in order to formally demonstrate the expressive power of modal effect types. To recover the full power of conventional effect systems beyond this fragment, we seamlessly extend Met to Mete with effect variables. We propose a surface language Metel for Mete with a sound and complete type inference algorithm inspired by FreezeML.","sentences":["We propose a novel type system for effects and handlers using modal types.","Conventional effect systems attach effects to function types, which can lead to verbose effect-polymorphic types, especially for higher-order functions.","Our modal effect system provides succinct types for higher-order first-class functions without losing modularity and reusability.","The core idea is to decouple effects from function types and instead to track effects through relative and absolute modalities, which represent transformations on the ambient effects provided by the context.   ","We formalise the idea of modal effect types in a multimodal System F-style core calculus Met with effects and handlers.","Met supports modular effectful programming via modalities without relying on effect variables.","We encode a practical fragment of a conventional row-based effect system with effect polymorphism, which captures most common use-cases, into Met in order to formally demonstrate the expressive power of modal effect types.","To recover the full power of conventional effect systems beyond this fragment, we seamlessly extend Met to Mete with effect variables.","We propose a surface language Metel for Mete with a sound and complete type inference algorithm inspired by FreezeML."],"url":"http://arxiv.org/abs/2407.11816v1"}
{"created":"2024-07-16 15:03:05","title":"Contrastive Sequential-Diffusion Learning: An approach to Multi-Scene Instructional Video Synthesis","abstract":"Action-centric sequence descriptions like recipe instructions and do-it-yourself projects include non-linear patterns in which the next step may require to be visually consistent not on the immediate previous step but on earlier steps. Current video synthesis approaches fail to generate consistent multi-scene videos for such task descriptions. We propose a contrastive sequential video diffusion method that selects the most suitable previously generated scene to guide and condition the denoising process of the next scene. The result is a multi-scene video that is grounded in the scene descriptions and coherent w.r.t the scenes that require consistent visualisation. Our experiments with real-world data demonstrate the practicality and improved consistency of our model compared to prior work.","sentences":["Action-centric sequence descriptions like recipe instructions and do-it-yourself projects include non-linear patterns in which the next step may require to be visually consistent not on the immediate previous step but on earlier steps.","Current video synthesis approaches fail to generate consistent multi-scene videos for such task descriptions.","We propose a contrastive sequential video diffusion method that selects the most suitable previously generated scene to guide and condition the denoising process of the next scene.","The result is a multi-scene video that is grounded in the scene descriptions and coherent w.r.t the scenes that require consistent visualisation.","Our experiments with real-world data demonstrate the practicality and improved consistency of our model compared to prior work."],"url":"http://arxiv.org/abs/2407.11814v1"}
{"created":"2024-07-16 15:02:18","title":"DFDRNN: A dual-feature based neural network for drug repositioning","abstract":"Drug repositioning is an economically efficient strategy used to discover new indications for existing drugs beyond their original approvals, expanding their applicability and usage to address challenges in disease treatment. In recent years, deep-learning techniques for drug repositioning have gained much attention. While most deep learning-based research methods focus on encoding drugs and diseases by extracting feature information from neighbors in the network, they often pay little attention to the potential relationships between the features of drugs and diseases, leading to imprecise encoding of drugs and diseases. To address this, we design a dual-feature drug repositioning neural network (DFDRNN) model to achieve precise encoding of drugs and diseases. DFDRNN uses two features to represent drugs and diseases: the similarity feature and the association feature. The model incorporates a self-attention mechanism to design two dual-feature extraction modules for achieving precisely encoding of drugs and diseases: the intra-domain dual-feature extraction (IntraDDFE) module and the inter-domain dual-feature extraction (InterDDFE) module. The IntraDDFE module extracts features from a single domain (drug or disease domain), while the InterDDFE module extracts features from the mixed domain (drug and disease domain). In particular, the feature is changed by InterDDFE, ensuring a precise encoding of drugs and diseases. Finally, a cross-dual-domain decoder is designed to predict drug-disease associations in both the drug and disease domains. Compared to six state-of-the-art methods, DFDRNN outperforms others on four benchmark datasets, with an average AUROC of 0.946 and an average AUPR of 0.597.","sentences":["Drug repositioning is an economically efficient strategy used to discover new indications for existing drugs beyond their original approvals, expanding their applicability and usage to address challenges in disease treatment.","In recent years, deep-learning techniques for drug repositioning have gained much attention.","While most deep learning-based research methods focus on encoding drugs and diseases by extracting feature information from neighbors in the network, they often pay little attention to the potential relationships between the features of drugs and diseases, leading to imprecise encoding of drugs and diseases.","To address this, we design a dual-feature drug repositioning neural network (DFDRNN) model to achieve precise encoding of drugs and diseases.","DFDRNN uses two features to represent drugs and diseases: the similarity feature and the association feature.","The model incorporates a self-attention mechanism to design two dual-feature extraction modules for achieving precisely encoding of drugs and diseases: the intra-domain dual-feature extraction (IntraDDFE) module and the inter-domain dual-feature extraction (InterDDFE) module.","The IntraDDFE module extracts features from a single domain (drug or disease domain), while the InterDDFE module extracts features from the mixed domain (drug and disease domain).","In particular, the feature is changed by InterDDFE, ensuring a precise encoding of drugs and diseases.","Finally, a cross-dual-domain decoder is designed to predict drug-disease associations in both the drug and disease domains.","Compared to six state-of-the-art methods, DFDRNN outperforms others on four benchmark datasets, with an average AUROC of 0.946 and an average AUPR of 0.597."],"url":"http://arxiv.org/abs/2407.11812v1"}
{"created":"2024-07-16 15:00:55","title":"About the generalized Hamming weights of matrix-product codes","abstract":"We derive a general lower bound for the generalized Hamming weights of nested matrix-product codes, with a particular emphasis on the cases with two and three constituent codes. We also provide an upper bound which is reminiscent of the bounds used for the minimum distance of matrix-product codes. When the constituent codes are two Reed-Solomon codes, we obtain an explicit formula for the generalized Hamming weights of the resulting matrix-product code. We also deal with the non-nested case for the case of two constituent codes.","sentences":["We derive a general lower bound for the generalized Hamming weights of nested matrix-product codes, with a particular emphasis on the cases with two and three constituent codes.","We also provide an upper bound which is reminiscent of the bounds used for the minimum distance of matrix-product codes.","When the constituent codes are two Reed-Solomon codes, we obtain an explicit formula for the generalized Hamming weights of the resulting matrix-product code.","We also deal with the non-nested case for the case of two constituent codes."],"url":"http://arxiv.org/abs/2407.11810v1"}
{"created":"2024-07-16 14:58:55","title":"Scalable and Reliable Over-the-Air Federated Edge Learning","abstract":"Federated edge learning (FEEL) has emerged as a core paradigm for large-scale optimization. However, FEEL still suffers from a communication bottleneck due to the transmission of high-dimensional model updates from the clients to the federator. Over-the-air computation (AirComp) leverages the additive property of multiple-access channels by aggregating the clients' updates over the channel to save communication resources. While analog uncoded transmission can benefit from the increased signal-to-noise ratio (SNR) due to the simultaneous transmission of many clients, potential errors may severely harm the learning process for small SNRs. To alleviate this problem, channel coding approaches were recently proposed for AirComp in FEEL. However, their error-correction capability degrades with an increasing number of clients. We propose a digital lattice-based code construction with constant error-correction capabilities in the number of clients, and compare to nested-lattice codes, well-known for their optimal rate and power efficiency in the point-to-point AWGN channel.","sentences":["Federated edge learning (FEEL) has emerged as a core paradigm for large-scale optimization.","However, FEEL still suffers from a communication bottleneck due to the transmission of high-dimensional model updates from the clients to the federator.","Over-the-air computation (AirComp) leverages the additive property of multiple-access channels by aggregating the clients' updates over the channel to save communication resources.","While analog uncoded transmission can benefit from the increased signal-to-noise ratio (SNR) due to the simultaneous transmission of many clients, potential errors may severely harm the learning process for small SNRs.","To alleviate this problem, channel coding approaches were recently proposed for AirComp in FEEL.","However, their error-correction capability degrades with an increasing number of clients.","We propose a digital lattice-based code construction with constant error-correction capabilities in the number of clients, and compare to nested-lattice codes, well-known for their optimal rate and power efficiency in the point-to-point AWGN channel."],"url":"http://arxiv.org/abs/2407.11807v1"}
{"created":"2024-07-16 14:57:15","title":"MaskedHLS: Domain-Specific High-Level Synthesis of Masked Cryptographic Designs","abstract":"The design and synthesis of masked cryptographic hardware implementations that are secure against power side-channel attacks (PSCAs) in the presence of glitches is a challenging task. High-Level Synthesis (HLS) is a promising technique for generating masked hardware directly from masked software, offering opportunities for design space exploration. However, conventional HLS tools make modifications that alter the guarantee against PSCA security via masking, resulting in an insecure RTL. Moreover, existing HLS tools can't place registers at designated places and balance parallel paths in a cryptographic design which is needed to stop glitch propagation. This paper introduces a domain-specific HLS approach tailored to obtain a PSCA secure masked hardware implementation directly from a masked software implementation. It places the registers at specific locations required by the glitch-robust masking gadgets, resulting in a secure RTL. Moreover, our tool automatically balances parallel paths and facilitates a reduction in latency while preserving the PSCA security guaranteed by masking. Experimental results with the PRESENT Cipher's S-box and AES Canright's S-box masked with four state-of-the-art gadgets, show that MaskedHLS produces RTLs with 73.9% decrease in registers and 45.7% decrease in latency on an average} compared to manual register insertions. The PSCA security of the MaskedHLS generated RTLs is also shown with TVLA test.","sentences":["The design and synthesis of masked cryptographic hardware implementations that are secure against power side-channel attacks (PSCAs) in the presence of glitches is a challenging task.","High-Level Synthesis (HLS) is a promising technique for generating masked hardware directly from masked software, offering opportunities for design space exploration.","However, conventional HLS tools make modifications that alter the guarantee against PSCA security via masking, resulting in an insecure RTL.","Moreover, existing HLS tools can't place registers at designated places and balance parallel paths in a cryptographic design which is needed to stop glitch propagation.","This paper introduces a domain-specific HLS approach tailored to obtain a PSCA secure masked hardware implementation directly from a masked software implementation.","It places the registers at specific locations required by the glitch-robust masking gadgets, resulting in a secure RTL.","Moreover, our tool automatically balances parallel paths and facilitates a reduction in latency while preserving the PSCA security guaranteed by masking.","Experimental results with the PRESENT Cipher's S-box and AES Canright's S-box masked with four state-of-the-art gadgets, show that MaskedHLS produces RTLs with 73.9% decrease in registers and 45.7% decrease in latency on an average} compared to manual register insertions.","The PSCA security of the MaskedHLS generated RTLs is also shown with TVLA test."],"url":"http://arxiv.org/abs/2407.11806v1"}
{"created":"2024-07-16 14:53:35","title":"Invariant Consistency for Knowledge Distillation","abstract":"Knowledge distillation (KD) involves transferring the knowledge from one neural network to another, often from a larger, well-trained model (teacher) to a smaller, more efficient model (student). Traditional KD methods minimize the Kullback-Leibler (KL) divergence between the probabilistic outputs of the teacher and student networks. However, this approach often overlooks crucial structural knowledge embedded within the teacher's network. In this paper, we introduce Invariant Consistency Distillation (ICD), a novel methodology designed to enhance KD by ensuring that the student model's representations are consistent with those of the teacher. Our approach combines contrastive learning with an explicit invariance penalty, capturing significantly more information from the teacher's representation of the data. Our results on CIFAR-100 demonstrate that ICD outperforms traditional KD techniques and surpasses 13 state-of-the-art methods. In some cases, the student model even exceeds the teacher model in terms of accuracy. Furthermore, we successfully transfer our method to other datasets, including Tiny ImageNet and STL-10. The code will be made public soon.","sentences":["Knowledge distillation (KD) involves transferring the knowledge from one neural network to another, often from a larger, well-trained model (teacher) to a smaller, more efficient model (student).","Traditional KD methods minimize the Kullback-Leibler (KL) divergence between the probabilistic outputs of the teacher and student networks.","However, this approach often overlooks crucial structural knowledge embedded within the teacher's network.","In this paper, we introduce Invariant Consistency Distillation (ICD), a novel methodology designed to enhance KD by ensuring that the student model's representations are consistent with those of the teacher.","Our approach combines contrastive learning with an explicit invariance penalty, capturing significantly more information from the teacher's representation of the data.","Our results on CIFAR-100 demonstrate that ICD outperforms traditional KD techniques and surpasses 13 state-of-the-art methods.","In some cases, the student model even exceeds the teacher model in terms of accuracy.","Furthermore, we successfully transfer our method to other datasets, including Tiny ImageNet and STL-10.","The code will be made public soon."],"url":"http://arxiv.org/abs/2407.11802v1"}
{"created":"2024-07-16 14:52:02","title":"PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation","abstract":"Inference of Large Language Models (LLMs) across computer clusters has become a focal point of research in recent times, with many acceleration techniques taking inspiration from CPU speculative execution. These techniques reduce bottlenecks associated with memory bandwidth, but also increase end-to-end latency per inference run, requiring high speculation acceptance rates to improve performance. Combined with a variable rate of acceptance across tasks, speculative inference techniques can result in reduced performance. Additionally, pipeline-parallel designs require many user requests to maintain maximum utilization. As a remedy, we propose PipeInfer, a pipelined speculative acceleration technique to reduce inter-token latency and improve system utilization for single-request scenarios while also improving tolerance to low speculation acceptance rates and low-bandwidth interconnects. PipeInfer exhibits up to a 2.15$\\times$ improvement in generation speed over standard speculative inference. PipeInfer achieves its improvement through Continuous Asynchronous Speculation and Early Inference Cancellation, the former improving latency and generation speed by running single-token inference simultaneously with several speculative runs, while the latter improves speed and latency by skipping the computation of invalidated runs, even in the middle of inference.","sentences":["Inference of Large Language Models (LLMs) across computer clusters has become a focal point of research in recent times, with many acceleration techniques taking inspiration from CPU speculative execution.","These techniques reduce bottlenecks associated with memory bandwidth, but also increase end-to-end latency per inference run, requiring high speculation acceptance rates to improve performance.","Combined with a variable rate of acceptance across tasks, speculative inference techniques can result in reduced performance.","Additionally, pipeline-parallel designs require many user requests to maintain maximum utilization.","As a remedy, we propose PipeInfer, a pipelined speculative acceleration technique to reduce inter-token latency and improve system utilization for single-request scenarios while also improving tolerance to low speculation acceptance rates and low-bandwidth interconnects.","PipeInfer exhibits up to a 2.15$\\times$ improvement in generation speed over standard speculative inference.","PipeInfer achieves its improvement through Continuous Asynchronous Speculation and Early Inference Cancellation, the former improving latency and generation speed by running single-token inference simultaneously with several speculative runs, while the latter improves speed and latency by skipping the computation of invalidated runs, even in the middle of inference."],"url":"http://arxiv.org/abs/2407.11798v1"}
{"created":"2024-07-16 14:49:42","title":"What's in a Niche? Migration Patterns in Online Communities","abstract":"Broad topics in online platforms represent a type of meso-scale between individual user-defined communities and the whole platform; they typically consist of related communities that address different facets of a shared topic. Users often engage with the topic by moving among the communities within a single category. We find that there are strong regularities in the aggregate pattern of user migration, in that the communities comprising a topic can be ordered in a partial order such that there is more migration in the direction defined by the partial order than against it. Ordered along this overall direction, we find that communities in aggregate become smaller, less toxic, and more linguistically distinctive, suggesting a picture consistent with specialization. We study directions defined not just in the movement of users but also by the movement of URLs and by the direction of mentions from one community to another; each of these produces a consistent direction, but the directions all differ from each other.   We show how, collectively, these distinct trends help organize the structure of large online topics and compare our findings across both Reddit and Wikipedia and in simulations.","sentences":["Broad topics in online platforms represent a type of meso-scale between individual user-defined communities and the whole platform; they typically consist of related communities that address different facets of a shared topic.","Users often engage with the topic by moving among the communities within a single category.","We find that there are strong regularities in the aggregate pattern of user migration, in that the communities comprising a topic can be ordered in a partial order such that there is more migration in the direction defined by the partial order than against it.","Ordered along this overall direction, we find that communities in aggregate become smaller, less toxic, and more linguistically distinctive, suggesting a picture consistent with specialization.","We study directions defined not just in the movement of users but also by the movement of URLs and by the direction of mentions from one community to another; each of these produces a consistent direction, but the directions all differ from each other.   ","We show how, collectively, these distinct trends help organize the structure of large online topics and compare our findings across both Reddit and Wikipedia and in simulations."],"url":"http://arxiv.org/abs/2407.11794v1"}
{"created":"2024-07-16 14:49:27","title":"Click-Gaussian: Interactive Segmentation to Any 3D Gaussians","abstract":"Interactive segmentation of 3D Gaussians opens a great opportunity for real-time manipulation of 3D scenes thanks to the real-time rendering capability of 3D Gaussian Splatting. However, the current methods suffer from time-consuming post-processing to deal with noisy segmentation output. Also, they struggle to provide detailed segmentation, which is important for fine-grained manipulation of 3D scenes. In this study, we propose Click-Gaussian, which learns distinguishable feature fields of two-level granularity, facilitating segmentation without time-consuming post-processing. We delve into challenges stemming from inconsistently learned feature fields resulting from 2D segmentation obtained independently from a 3D scene. 3D segmentation accuracy deteriorates when 2D segmentation results across the views, primary cues for 3D segmentation, are in conflict. To overcome these issues, we propose Global Feature-guided Learning (GFL). GFL constructs the clusters of global feature candidates from noisy 2D segments across the views, which smooths out noises when training the features of 3D Gaussians. Our method runs in 10 ms per click, 15 to 130 times as fast as the previous methods, while also significantly improving segmentation accuracy. Our project page is available at https://seokhunchoi.github.io/Click-Gaussian","sentences":["Interactive segmentation of 3D Gaussians opens a great opportunity for real-time manipulation of 3D scenes thanks to the real-time rendering capability of 3D Gaussian Splatting.","However, the current methods suffer from time-consuming post-processing to deal with noisy segmentation output.","Also, they struggle to provide detailed segmentation, which is important for fine-grained manipulation of 3D scenes.","In this study, we propose Click-Gaussian, which learns distinguishable feature fields of two-level granularity, facilitating segmentation without time-consuming post-processing.","We delve into challenges stemming from inconsistently learned feature fields resulting from 2D segmentation obtained independently from a 3D scene.","3D segmentation accuracy deteriorates when 2D segmentation results across the views, primary cues for 3D segmentation, are in conflict.","To overcome these issues, we propose Global Feature-guided Learning (GFL).","GFL constructs the clusters of global feature candidates from noisy 2D segments across the views, which smooths out noises when training the features of 3D Gaussians.","Our method runs in 10 ms per click, 15 to 130 times as fast as the previous methods, while also significantly improving segmentation accuracy.","Our project page is available at https://seokhunchoi.github.io/Click-Gaussian"],"url":"http://arxiv.org/abs/2407.11793v1"}
{"created":"2024-07-16 14:45:46","title":"Characterizing and Understanding HGNN Training on GPUs","abstract":"Owing to their remarkable representation capabilities for heterogeneous graph data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in many critical real-world domains such as recommendation systems and medical analysis. Prior to their practical application, identifying the optimal HGNN model parameters tailored to specific tasks through extensive training is a time-consuming and costly process. To enhance the efficiency of HGNN training, it is essential to characterize and analyze the execution semantics and patterns within the training process to identify performance bottlenecks. In this study, we conduct an in-depth quantification and analysis of two mainstream HGNN training scenarios, including single-GPU and multi-GPU distributed training. Based on the characterization results, we disclose the performance bottlenecks and their underlying causes in different HGNN training scenarios and provide optimization guidelines from both software and hardware perspectives.","sentences":["Owing to their remarkable representation capabilities for heterogeneous graph data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in many critical real-world domains such as recommendation systems and medical analysis.","Prior to their practical application, identifying the optimal HGNN model parameters tailored to specific tasks through extensive training is a time-consuming and costly process.","To enhance the efficiency of HGNN training, it is essential to characterize and analyze the execution semantics and patterns within the training process to identify performance bottlenecks.","In this study, we conduct an in-depth quantification and analysis of two mainstream HGNN training scenarios, including single-GPU and multi-GPU distributed training.","Based on the characterization results, we disclose the performance bottlenecks and their underlying causes in different HGNN training scenarios and provide optimization guidelines from both software and hardware perspectives."],"url":"http://arxiv.org/abs/2407.11790v1"}
{"created":"2024-07-16 14:45:22","title":"Large Language Models as Misleading Assistants in Conversation","abstract":"Large Language Models (LLMs) are able to provide assistance on a wide range of information-seeking tasks. However, model outputs may be misleading, whether unintentionally or in cases of intentional deception. We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users. We compare outcomes of (1) when the model is prompted to provide truthful assistance, (2) when it is prompted to be subtly misleading, and (3) when it is prompted to argue for an incorrect answer. Our experiments show that GPT-4 can effectively mislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up to a 23% drop in accuracy on the task compared to when a truthful assistant is used. We also find that providing the user model with additional context from the passage partially mitigates the influence of the deceptive model. This work highlights the ability of LLMs to produce misleading information and the effects this may have in real-world situations.","sentences":["Large Language Models (LLMs) are able to provide assistance on a wide range of information-seeking tasks.","However, model outputs may be misleading, whether unintentionally or in cases of intentional deception.","We investigate the ability of LLMs to be deceptive in the context of providing assistance on a reading comprehension task, using LLMs as proxies for human users.","We compare outcomes of (1) when the model is prompted to provide truthful assistance, (2) when it is prompted to be subtly misleading, and (3) when it is prompted to argue for an incorrect answer.","Our experiments show that GPT-4 can effectively mislead both GPT-3.5-Turbo and GPT-4, with deceptive assistants resulting in up to a 23% drop in accuracy on the task compared to when a truthful assistant is used.","We also find that providing the user model with additional context from the passage partially mitigates the influence of the deceptive model.","This work highlights the ability of LLMs to produce misleading information and the effects this may have in real-world situations."],"url":"http://arxiv.org/abs/2407.11789v1"}
{"created":"2024-07-16 14:44:48","title":"Learning feasible transitions for efficient contact planning","abstract":"Contact planning for legged robots in extremely constrained environments is challenging. The main difficulty stems from the mixed nature of the problem, discrete search together with continuous trajectory optimization. To speed up the discrete search problem, we propose in this paper to learn the properties of transitions from one contact mode to the next. In particular, we learn a feasibility classifier and an offset network; the former predicts if a potential next contact state is feasible from the current contact state, while the latter learns to compensate for misalignment in achieving a desired contact state due to imperfections of the low-level control. We integrate these learned networks in a Monte Carlo Tree Search (MCTS) contact planner to better prune the tree and improve the heuristic. Our simulation results demonstrate that training these networks with offline data significantly speeds up the online search process and improves its accuracy.","sentences":["Contact planning for legged robots in extremely constrained environments is challenging.","The main difficulty stems from the mixed nature of the problem, discrete search together with continuous trajectory optimization.","To speed up the discrete search problem, we propose in this paper to learn the properties of transitions from one contact mode to the next.","In particular, we learn a feasibility classifier and an offset network; the former predicts if a potential next contact state is feasible from the current contact state, while the latter learns to compensate for misalignment in achieving a desired contact state due to imperfections of the low-level control.","We integrate these learned networks in a Monte Carlo Tree Search (MCTS) contact planner to better prune the tree and improve the heuristic.","Our simulation results demonstrate that training these networks with offline data significantly speeds up the online search process and improves its accuracy."],"url":"http://arxiv.org/abs/2407.11788v1"}
{"created":"2024-07-16 14:41:27","title":"Defining 'Good': Evaluation Framework for Synthetic Smart Meter Data","abstract":"Access to granular demand data is essential for the net zero transition; it allows for accurate profiling and active demand management as our reliance on variable renewable generation increases. However, public release of this data is often impossible due to privacy concerns. Good quality synthetic data can circumnavigate this issue. Despite significant research on generating synthetic smart meter data, there is still insufficient work on creating a consistent evaluation framework. In this paper, we investigate how common frameworks used by other industries leveraging synthetic data, can be applied to synthetic smart meter data, such as fidelity, utility and privacy. We also recommend specific metrics to ensure that defining aspects of smart meter data are preserved and test the extent to which privacy can be protected using differential privacy. We show that standard privacy attack methods like reconstruction or membership inference attacks are inadequate for assessing privacy risks of smart meter datasets. We propose an improved method by injecting training data with implausible outliers, then launching privacy attacks directly on these outliers. The choice of $\\epsilon$ (a metric of privacy loss) significantly impacts privacy risk, highlighting the necessity of performing these explicit privacy tests when making trade-offs between fidelity and privacy.","sentences":["Access to granular demand data is essential for the net zero transition; it allows for accurate profiling and active demand management as our reliance on variable renewable generation increases.","However, public release of this data is often impossible due to privacy concerns.","Good quality synthetic data can circumnavigate this issue.","Despite significant research on generating synthetic smart meter data, there is still insufficient work on creating a consistent evaluation framework.","In this paper, we investigate how common frameworks used by other industries leveraging synthetic data, can be applied to synthetic smart meter data, such as fidelity, utility and privacy.","We also recommend specific metrics to ensure that defining aspects of smart meter data are preserved and test the extent to which privacy can be protected using differential privacy.","We show that standard privacy attack methods like reconstruction or membership inference attacks are inadequate for assessing privacy risks of smart meter datasets.","We propose an improved method by injecting training data with implausible outliers, then launching privacy attacks directly on these outliers.","The choice of $\\epsilon$ (a metric of privacy loss) significantly impacts privacy risk, highlighting the necessity of performing these explicit privacy tests when making trade-offs between fidelity and privacy."],"url":"http://arxiv.org/abs/2407.11785v1"}
{"created":"2024-07-16 14:41:27","title":"Cryptocurrency Price Forecasting Using XGBoost Regressor and Technical Indicators","abstract":"The rapid growth of the stock market has attracted many investors due to its potential for significant profits. However, predicting stock prices accurately is difficult because financial markets are complex and constantly changing. This is especially true for the cryptocurrency market, which is known for its extreme volatility, making it challenging for traders and investors to make wise and profitable decisions. This study introduces a machine learning approach to predict cryptocurrency prices. Specifically, we make use of important technical indicators such as Exponential Moving Average (EMA) and Moving Average Convergence Divergence (MACD) to train and feed the XGBoost regressor model. We demonstrate our approach through an analysis focusing on the closing prices of Bitcoin cryptocurrency. We evaluate the model's performance through various simulations, showing promising results that suggest its usefulness in aiding/guiding cryptocurrency traders and investors in dynamic market conditions.","sentences":["The rapid growth of the stock market has attracted many investors due to its potential for significant profits.","However, predicting stock prices accurately is difficult because financial markets are complex and constantly changing.","This is especially true for the cryptocurrency market, which is known for its extreme volatility, making it challenging for traders and investors to make wise and profitable decisions.","This study introduces a machine learning approach to predict cryptocurrency prices.","Specifically, we make use of important technical indicators such as Exponential Moving Average (EMA) and Moving Average Convergence Divergence (MACD) to train and feed the XGBoost regressor model.","We demonstrate our approach through an analysis focusing on the closing prices of Bitcoin cryptocurrency.","We evaluate the model's performance through various simulations, showing promising results that suggest its usefulness in aiding/guiding cryptocurrency traders and investors in dynamic market conditions."],"url":"http://arxiv.org/abs/2407.11786v1"}
{"created":"2024-07-16 14:40:07","title":"Data-Juicer Sandbox: A Comprehensive Suite for Multimodal Data-Model Co-development","abstract":"The emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality. However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization. In response, we present a novel sandbox suite tailored for integrated data-model co-development. This sandbox provides a comprehensive experimental platform, enabling rapid iteration and insight-driven refinement of both data and models. Our proposed \"Probe-Analyze-Refine\" workflow, validated through applications on state-of-the-art LLaVA-like and DiT based models, yields significant performance boosts, such as topping the VBench leaderboard. We also uncover fruitful insights gleaned from exhaustive benchmarks, shedding light on the critical interplay between data quality, diversity, and model behavior. With the hope of fostering deeper understanding and future progress in multi-modal data and generative modeling, our codes, datasets, and models are maintained and accessible at https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md.","sentences":["The emergence of large-scale multi-modal generative models has drastically advanced artificial intelligence, introducing unprecedented levels of performance and functionality.","However, optimizing these models remains challenging due to historically isolated paths of model-centric and data-centric developments, leading to suboptimal outcomes and inefficient resource utilization.","In response, we present a novel sandbox suite tailored for integrated data-model co-development.","This sandbox provides a comprehensive experimental platform, enabling rapid iteration and insight-driven refinement of both data and models.","Our proposed \"Probe-Analyze-Refine\" workflow, validated through applications on state-of-the-art LLaVA-like and DiT based models, yields significant performance boosts, such as topping the VBench leaderboard.","We also uncover fruitful insights gleaned from exhaustive benchmarks, shedding light on the critical interplay between data quality, diversity, and model behavior.","With the hope of fostering deeper understanding and future progress in multi-modal data and generative modeling, our codes, datasets, and models are maintained and accessible at https://github.com/modelscope/data-juicer/blob/main/docs/Sandbox.md."],"url":"http://arxiv.org/abs/2407.11784v1"}
{"created":"2024-07-16 14:38:13","title":"SlingBAG: Sliding ball adaptive growth algorithm with differentiable radiation enables super-efficient iterative 3D photoacoustic image reconstruction","abstract":"High-quality 3D photoacoustic imaging (PAI) reconstruction under sparse view or limited view has long been challenging. Traditional 3D iterative-based reconstruction methods suffer from both slow speed and high memory consumption. Recently, in computer graphics, the differentiable rendering has made significant progress, particularly with the rise of 3D Gaussian Splatting. Inspired by these, we introduce differentiable radiation into PAI, developing a novel reconstruction algorithm: the Sliding Ball Adaptive Growth algorithm (SlingBAG) for 3D PAI, which shows ability in high-quality 3D PAI reconstruction both under extremely sparse view and limited view.   We established the point cloud dataset in PAI, and used unique differentiable rapid radiator based on the spherical decomposition strategy and the randomly initialized point cloud adaptively optimized according to sparse sensor data. Each point undergoes updates in 3D coordinates, initial pressure, and resolution (denoted by the radius of ball). Points undergo adaptive growth during iterative process, including point destroying, splitting and duplicating along the gradient of their positions, manifesting the sliding ball effect.   Finally, our point cloud to voxel grid shader renders the final reconstruction results. Simulation and in vivo experiments demonstrate that our SlingBAG reconstruction result's SNR can be more than 40 dB under extremely sparse view, while the SNR of traditional back-projection algorithm's result is less than 20 dB. Moreover, the result of SlingBAG's structural similarity to the ground truth is significantly higher, with an SSIM value of 95.6%.   Notably, our differentiable rapid radiator can conduct forward PA simulation in homogeneous, non-viscous media substantially faster than current methods that numerically simulate the wave propagation, such as k-Wave. The dataset and all code will be open source.","sentences":["High-quality 3D photoacoustic imaging (PAI) reconstruction under sparse view or limited view has long been challenging.","Traditional 3D iterative-based reconstruction methods suffer from both slow speed and high memory consumption.","Recently, in computer graphics, the differentiable rendering has made significant progress, particularly with the rise of 3D Gaussian Splatting.","Inspired by these, we introduce differentiable radiation into PAI, developing a novel reconstruction algorithm: the Sliding Ball Adaptive Growth algorithm (SlingBAG) for 3D PAI, which shows ability in high-quality 3D PAI reconstruction both under extremely sparse view and limited view.   ","We established the point cloud dataset in PAI, and used unique differentiable rapid radiator based on the spherical decomposition strategy and the randomly initialized point cloud adaptively optimized according to sparse sensor data.","Each point undergoes updates in 3D coordinates, initial pressure, and resolution (denoted by the radius of ball).","Points undergo adaptive growth during iterative process, including point destroying, splitting and duplicating along the gradient of their positions, manifesting the sliding ball effect.   ","Finally, our point cloud to voxel grid shader renders the final reconstruction results.","Simulation and in vivo experiments demonstrate that our SlingBAG reconstruction result's SNR can be more than 40 dB under extremely sparse view, while the SNR of traditional back-projection algorithm's result is less than 20 dB. Moreover, the result of SlingBAG's structural similarity to the ground truth is significantly higher, with an SSIM value of 95.6%.   ","Notably, our differentiable rapid radiator can conduct forward PA simulation in homogeneous, non-viscous media substantially faster than current methods that numerically simulate the wave propagation, such as k-Wave.","The dataset and all code will be open source."],"url":"http://arxiv.org/abs/2407.11781v1"}
{"created":"2024-07-16 14:37:33","title":"SwitchCIT: Switching for Continual Instruction Tuning of Large Language Models","abstract":"Large language models (LLMs) have exhibited impressive capabilities in various domains, particularly in general language understanding. However these models, trained on massive text data, may not be finely optimized for specific tasks triggered by instructions. Continual instruction tuning is crucial to adapt LLMs to evolving tasks and domains, ensuring their effectiveness and relevance across a wide range of applications. In the context of continual instruction tuning, where models are sequentially trained on different tasks, catastrophic forgetting can occur, leading to performance degradation on previously learned tasks. This work addresses the catastrophic forgetting in continual instruction learning for LLMs through a switching mechanism for routing computations to parameter-efficient tuned models. We demonstrate the effectiveness of our method through experiments on continual instruction tuning of different natural language generation tasks.","sentences":["Large language models (LLMs) have exhibited impressive capabilities in various domains, particularly in general language understanding.","However these models, trained on massive text data, may not be finely optimized for specific tasks triggered by instructions.","Continual instruction tuning is crucial to adapt LLMs to evolving tasks and domains, ensuring their effectiveness and relevance across a wide range of applications.","In the context of continual instruction tuning, where models are sequentially trained on different tasks, catastrophic forgetting can occur, leading to performance degradation on previously learned tasks.","This work addresses the catastrophic forgetting in continual instruction learning for LLMs through a switching mechanism for routing computations to parameter-efficient tuned models.","We demonstrate the effectiveness of our method through experiments on continual instruction tuning of different natural language generation tasks."],"url":"http://arxiv.org/abs/2407.11780v1"}
{"created":"2024-07-16 14:36:30","title":"Local Feature Selection without Label or Feature Leakage for Interpretable Machine Learning Predictions","abstract":"Local feature selection in machine learning provides instance-specific explanations by focusing on the most relevant features for each prediction, enhancing the interpretability of complex models. However, such methods tend to produce misleading explanations by encoding additional information in their selections. In this work, we attribute the problem of misleading selections by formalizing the concepts of label and feature leakage. We rigorously derive the necessary and sufficient conditions under which we can guarantee no leakage, and show existing methods do not meet these conditions. Furthermore, we propose the first local feature selection method that is proven to have no leakage called SUWR. Our experimental results indicate that SUWR is less prone to overfitting and combines state-of-the-art predictive performance with high feature-selection sparsity. Our generic and easily extendable formal approach provides a strong theoretical basis for future work on interpretability with reliable explanations.","sentences":["Local feature selection in machine learning provides instance-specific explanations by focusing on the most relevant features for each prediction, enhancing the interpretability of complex models.","However, such methods tend to produce misleading explanations by encoding additional information in their selections.","In this work, we attribute the problem of misleading selections by formalizing the concepts of label and feature leakage.","We rigorously derive the necessary and sufficient conditions under which we can guarantee no leakage, and show existing methods do not meet these conditions.","Furthermore, we propose the first local feature selection method that is proven to have no leakage called SUWR.","Our experimental results indicate that SUWR is less prone to overfitting and combines state-of-the-art predictive performance with high feature-selection sparsity.","Our generic and easily extendable formal approach provides a strong theoretical basis for future work on interpretability with reliable explanations."],"url":"http://arxiv.org/abs/2407.11778v1"}
{"created":"2024-07-16 14:33:01","title":"Sharif-MGTD at SemEval-2024 Task 8: A Transformer-Based Approach to Detect Machine Generated Text","abstract":"Detecting Machine-Generated Text (MGT) has emerged as a significant area of study within Natural Language Processing. While language models generate text, they often leave discernible traces, which can be scrutinized using either traditional feature-based methods or more advanced neural language models. In this research, we explore the effectiveness of fine-tuning a RoBERTa-base transformer, a powerful neural architecture, to address MGT detection as a binary classification task. Focusing specifically on Subtask A (Monolingual-English) within the SemEval-2024 competition framework, our proposed system achieves an accuracy of 78.9% on the test dataset, positioning us at 57th among participants. Our study addresses this challenge while considering the limited hardware resources, resulting in a system that excels at identifying human-written texts but encounters challenges in accurately discerning MGTs.","sentences":["Detecting Machine-Generated Text (MGT) has emerged as a significant area of study within Natural Language Processing.","While language models generate text, they often leave discernible traces, which can be scrutinized using either traditional feature-based methods or more advanced neural language models.","In this research, we explore the effectiveness of fine-tuning a RoBERTa-base transformer, a powerful neural architecture, to address MGT detection as a binary classification task.","Focusing specifically on Subtask A (Monolingual-English) within the SemEval-2024 competition framework, our proposed system achieves an accuracy of 78.9% on the test dataset, positioning us at 57th among participants.","Our study addresses this challenge while considering the limited hardware resources, resulting in a system that excels at identifying human-written texts but encounters challenges in accurately discerning MGTs."],"url":"http://arxiv.org/abs/2407.11774v1"}
{"created":"2024-07-16 14:32:56","title":"Educational Personalized Learning Path Planning with Large Language Models","abstract":"Educational Personalized Learning Path Planning (PLPP) aims to tailor learning experiences to individual learners' needs, enhancing learning efficiency and engagement. Despite its potential, traditional PLPP systems often lack adaptability, interactivity, and transparency. This paper proposes a novel approach integrating Large Language Models (LLMs) with prompt engineering to address these challenges. By designing prompts that incorporate learner-specific information, our method guides LLMs like LLama-2-70B and GPT-4 to generate personalized, coherent, and pedagogically sound learning paths. We conducted experiments comparing our method with a baseline approach across various metrics, including accuracy, user satisfaction, and the quality of learning paths. The results show significant improvements in all areas, particularly with GPT-4, demonstrating the effectiveness of prompt engineering in enhancing PLPP. Additional long-term impact analysis further validates our method's potential to improve learner performance and retention. This research highlights the promise of LLMs and prompt engineering in advancing personalized education.","sentences":["Educational Personalized Learning Path Planning (PLPP) aims to tailor learning experiences to individual learners' needs, enhancing learning efficiency and engagement.","Despite its potential, traditional PLPP systems often lack adaptability, interactivity, and transparency.","This paper proposes a novel approach integrating Large Language Models (LLMs) with prompt engineering to address these challenges.","By designing prompts that incorporate learner-specific information, our method guides LLMs like LLama-2-70B and GPT-4 to generate personalized, coherent, and pedagogically sound learning paths.","We conducted experiments comparing our method with a baseline approach across various metrics, including accuracy, user satisfaction, and the quality of learning paths.","The results show significant improvements in all areas, particularly with GPT-4, demonstrating the effectiveness of prompt engineering in enhancing PLPP.","Additional long-term impact analysis further validates our method's potential to improve learner performance and retention.","This research highlights the promise of LLMs and prompt engineering in advancing personalized education."],"url":"http://arxiv.org/abs/2407.11773v1"}
{"created":"2024-07-16 14:32:42","title":"User Behavior Analysis and Clustering in Peace Elite: Insights and Recommendations","abstract":"This study presents a comprehensive analysis of user behavior and clustering in Peace Elite, a popular mobile battle royale game, employing temporal and static data mining techniques to uncover distinct player segments. Our methodology encompasses time series K-means clustering, graph-based algorithms (DeepWalk and LINE), and static attribute clustering, visualized through innovative hybrid charts. Key findings reveal significant variations in player engagement, skill levels, and social interactions across five primary user segments, ranging from highly active and skilled players to inactive or new users. We also analyze the impact of external factors on user retention and the network structure within clusters, uncovering correlations between cluster cohesion and player activity levels. This research provides valuable insights for game developers and marketers, offering data-driven recommendations for personalized game experiences, targeted marketing strategies, and improved player retention in online gaming environments.","sentences":["This study presents a comprehensive analysis of user behavior and clustering in Peace Elite, a popular mobile battle royale game, employing temporal and static data mining techniques to uncover distinct player segments.","Our methodology encompasses time series K-means clustering, graph-based algorithms (DeepWalk and LINE), and static attribute clustering, visualized through innovative hybrid charts.","Key findings reveal significant variations in player engagement, skill levels, and social interactions across five primary user segments, ranging from highly active and skilled players to inactive or new users.","We also analyze the impact of external factors on user retention and the network structure within clusters, uncovering correlations between cluster cohesion and player activity levels.","This research provides valuable insights for game developers and marketers, offering data-driven recommendations for personalized game experiences, targeted marketing strategies, and improved player retention in online gaming environments."],"url":"http://arxiv.org/abs/2407.11772v1"}
{"created":"2024-07-16 14:30:24","title":"XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach","abstract":"Recent advancements in deep learning have significantly improved visual quality inspection and predictive maintenance within industrial settings. However, deploying these technologies on low-resource edge devices poses substantial challenges due to their high computational demands and the inherent complexity of Explainable AI (XAI) methods. This paper addresses these challenges by introducing a novel XAI-integrated Visual Quality Inspection framework that optimizes the deployment of semantic segmentation models on low-resource edge devices. Our framework incorporates XAI and the Large Vision Language Model to deliver human-centered interpretability through visual and textual explanations to end-users. This is crucial for end-user trust and model interpretability. We outline a comprehensive methodology consisting of six fundamental modules: base model fine-tuning, XAI-based explanation generation, evaluation of XAI approaches, XAI-guided data augmentation, development of an edge-compatible model, and the generation of understandable visual and textual explanations. Through XAI-guided data augmentation, the enhanced model incorporating domain expert knowledge with visual and textual explanations is successfully deployed on mobile devices to support end-users in real-world scenarios. Experimental results showcase the effectiveness of the proposed framework, with the mobile model achieving competitive accuracy while significantly reducing model size. This approach paves the way for the broader adoption of reliable and interpretable AI tools in critical industrial applications, where decisions must be both rapid and justifiable.","sentences":["Recent advancements in deep learning have significantly improved visual quality inspection and predictive maintenance within industrial settings.","However, deploying these technologies on low-resource edge devices poses substantial challenges due to their high computational demands and the inherent complexity of Explainable AI (XAI) methods.","This paper addresses these challenges by introducing a novel XAI-integrated Visual Quality Inspection framework that optimizes the deployment of semantic segmentation models on low-resource edge devices.","Our framework incorporates XAI and the Large Vision Language Model to deliver human-centered interpretability through visual and textual explanations to end-users.","This is crucial for end-user trust and model interpretability.","We outline a comprehensive methodology consisting of six fundamental modules: base model fine-tuning, XAI-based explanation generation, evaluation of XAI approaches, XAI-guided data augmentation, development of an edge-compatible model, and the generation of understandable visual and textual explanations.","Through XAI-guided data augmentation, the enhanced model incorporating domain expert knowledge with visual and textual explanations is successfully deployed on mobile devices to support end-users in real-world scenarios.","Experimental results showcase the effectiveness of the proposed framework, with the mobile model achieving competitive accuracy while significantly reducing model size.","This approach paves the way for the broader adoption of reliable and interpretable AI tools in critical industrial applications, where decisions must be both rapid and justifiable."],"url":"http://arxiv.org/abs/2407.11771v1"}
{"created":"2024-07-16 14:28:56","title":"Robust Utility-Preserving Text Anonymization Based on Large Language Models","abstract":"Text anonymization is crucial for sharing sensitive data while maintaining privacy. Existing techniques face the emerging challenges of re-identification attack ability of Large Language Models (LLMs), which have shown advanced capability in memorizing detailed information and patterns as well as connecting disparate pieces of information. In defending against LLM-based re-identification attacks, anonymization could jeopardize the utility of the resulting anonymized data in downstream tasks -- the trade-off between privacy and data utility requires deeper understanding within the context of LLMs. This paper proposes a framework composed of three LLM-based components -- a privacy evaluator, a utility evaluator, and an optimization component, which work collaboratively to perform anonymization. To provide a practical model for large-scale and real-time environments, we distill the anonymization capabilities into a lightweight model using Direct Preference Optimization (DPO). Extensive experiments demonstrate that the proposed models outperform baseline models, showing robustness in reducing the risk of re-identification while preserving greater data utility in downstream tasks. Our code and dataset are available at https://github.com/UKPLab/arxiv2024-rupta.","sentences":["Text anonymization is crucial for sharing sensitive data while maintaining privacy.","Existing techniques face the emerging challenges of re-identification attack ability of Large Language Models (LLMs), which have shown advanced capability in memorizing detailed information and patterns as well as connecting disparate pieces of information.","In defending against LLM-based re-identification attacks, anonymization could jeopardize the utility of the resulting anonymized data in downstream tasks -- the trade-off between privacy and data utility requires deeper understanding within the context of LLMs.","This paper proposes a framework composed of three LLM-based components -- a privacy evaluator, a utility evaluator, and an optimization component, which work collaboratively to perform anonymization.","To provide a practical model for large-scale and real-time environments, we distill the anonymization capabilities into a lightweight model using Direct Preference Optimization (DPO).","Extensive experiments demonstrate that the proposed models outperform baseline models, showing robustness in reducing the risk of re-identification while preserving greater data utility in downstream tasks.","Our code and dataset are available at https://github.com/UKPLab/arxiv2024-rupta."],"url":"http://arxiv.org/abs/2407.11770v1"}
{"created":"2024-07-16 14:28:18","title":"Independent Set Reconfiguration Under Bounded-Hop Token","abstract":"The independent set reconfiguration problem (ISReconf) is the problem of determining, for given independent sets I_s and I_t of a graph G, whether I_s can be transformed into I_t by repeatedly applying a prescribed reconfiguration rule that transforms an independent set to another. As reconfiguration rules for the ISReconf, the Token Sliding (TS) model and the Token Jumping (TJ) model are commonly considered. While the TJ model admits the addition of any vertex (as far as the addition yields an independent set), the TS model admits the addition of only a neighbor of the removed vertex. It is known that the complexity status of the ISReconf differs between the TS and TJ models for some graph classes.   In this paper, we analyze how changes in reconfiguration rules affect the computational complexity of reconfiguration problems. To this end, we generalize the TS and TJ models to a unified reconfiguration rule, called the k-Jump model, which admits the addition of a vertex within distance k from the removed vertex. Then, the TS and TJ models are the 1-Jump and D(G)-Jump models, respectively, where D(G) denotes the diameter of a connected graph G. We give the following three results: First, we show that the computational complexity of the ISReconf under the k-Jump model for general graphs is equivalent for all k >= 3. Second, we present a polynomial-time algorithm to solve the ISReconf under the 2-Jump model for split graphs. We note that the ISReconf under the 1-Jump (i.e., TS) model is PSPACE-complete for split graphs, and hence the complexity status of the ISReconf differs between k = 1 and k = 2. Third, we consider the optimization variant of the ISReconf, which computes the minimum number of steps of any transformation between Is and It. We prove that this optimization variant under the k-Jump model is NP-complete for chordal graphs of diameter at most 2k + 1, for any k >=3.","sentences":["The independent set reconfiguration problem (ISReconf) is the problem of determining, for given independent sets I_s and I_t of a graph G, whether I_s can be transformed into I_t by repeatedly applying a prescribed reconfiguration rule that transforms an independent set to another.","As reconfiguration rules for the ISReconf, the Token Sliding (TS) model and the Token Jumping (TJ) model are commonly considered.","While the TJ model admits the addition of any vertex (as far as the addition yields an independent set), the TS model admits the addition of only a neighbor of the removed vertex.","It is known that the complexity status of the ISReconf differs between the TS and TJ models for some graph classes.   ","In this paper, we analyze how changes in reconfiguration rules affect the computational complexity of reconfiguration problems.","To this end, we generalize the TS and TJ models to a unified reconfiguration rule, called the k-Jump model, which admits the addition of a vertex within distance k from the removed vertex.","Then, the TS and TJ models are the 1-Jump and D(G)-Jump models, respectively, where D(G) denotes the diameter of a connected graph G.","We give the following three results:","First, we show that the computational complexity of the ISReconf under the k-Jump model for general graphs is equivalent for all k >= 3.","Second, we present a polynomial-time algorithm to solve the ISReconf under the 2-Jump model for split graphs.","We note that the ISReconf under the 1-Jump (i.e., TS) model is PSPACE-complete for split graphs, and hence the complexity status of the ISReconf differs between k = 1 and k = 2.","Third, we consider the optimization variant of the ISReconf, which computes the minimum number of steps of any transformation between Is and It.","We prove that this optimization variant under the k-Jump model is NP-complete for chordal graphs of diameter at most 2k","+ 1, for any k >=3."],"url":"http://arxiv.org/abs/2407.11768v1"}
