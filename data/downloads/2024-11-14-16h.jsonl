{"created":"2024-11-13 18:56:39","title":"4D Gaussian Splatting in the Wild with Uncertainty-Aware Regularization","abstract":"Novel view synthesis of dynamic scenes is becoming important in various applications, including augmented and virtual reality. We propose a novel 4D Gaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded monocular videos. To overcome the overfitting problem of existing work for these real-world videos, we introduce an uncertainty-aware regularization that identifies uncertain regions with few observations and selectively imposes additional priors based on diffusion models and depth smoothness on such regions. This approach improves both the performance of novel view synthesis and the quality of training image reconstruction. We also identify the initialization problem of 4DGS in fast-moving dynamic regions, where the Structure from Motion (SfM) algorithm fails to provide reliable 3D landmarks. To initialize Gaussian primitives in such regions, we present a dynamic region densification method using the estimated depth maps and scene flow. Our experiments show that the proposed method improves the performance of 4DGS reconstruction from a video captured by a handheld monocular camera and also exhibits promising results in few-shot static scene reconstruction.","sentences":["Novel view synthesis of dynamic scenes is becoming important in various applications, including augmented and virtual reality.","We propose a novel 4D Gaussian Splatting (4DGS) algorithm for dynamic scenes from casually recorded monocular videos.","To overcome the overfitting problem of existing work for these real-world videos, we introduce an uncertainty-aware regularization that identifies uncertain regions with few observations and selectively imposes additional priors based on diffusion models and depth smoothness on such regions.","This approach improves both the performance of novel view synthesis and the quality of training image reconstruction.","We also identify the initialization problem of 4DGS in fast-moving dynamic regions, where the Structure from Motion (SfM) algorithm fails to provide reliable 3D landmarks.","To initialize Gaussian primitives in such regions, we present a dynamic region densification method using the estimated depth maps and scene flow.","Our experiments show that the proposed method improves the performance of 4DGS reconstruction from a video captured by a handheld monocular camera and also exhibits promising results in few-shot static scene reconstruction."],"url":"http://arxiv.org/abs/2411.08879v1"}
{"created":"2024-11-13 18:55:10","title":"A Short Note on Evaluating RepNet for Temporal Repetition Counting in Videos","abstract":"We discuss some consistent issues on how RepNet has been evaluated in various papers. As a way to mitigate these issues, we report RepNet performance results on different datasets, and release evaluation code and the RepNet checkpoint to obtain these results. Code URL: https://github.com/google-research/google-research/blob/master/repnet/","sentences":["We discuss some consistent issues on how RepNet has been evaluated in various papers.","As a way to mitigate these issues, we report RepNet performance results on different datasets, and release evaluation code and the RepNet checkpoint to obtain these results.","Code URL: https://github.com/google-research/google-research/blob/master/repnet/"],"url":"http://arxiv.org/abs/2411.08878v1"}
{"created":"2024-11-13 18:52:42","title":"Causal Explanations for Image Classifiers","abstract":"Existing algorithms for explaining the output of image classifiers use different definitions of explanations and a variety of techniques to extract them. However, none of the existing tools use a principled approach based on formal definitions of causes and explanations for the explanation extraction. In this paper we present a novel black-box approach to computing explanations grounded in the theory of actual causality. We prove relevant theoretical results and present an algorithm for computing approximate explanations based on these definitions. We prove termination of our algorithm and discuss its complexity and the amount of approximation compared to the precise definition. We implemented the framework in a tool rex and we present experimental results and a comparison with state-of-the-art tools. We demonstrate that rex is the most efficient tool and produces the smallest explanations, in addition to outperforming other black-box tools on standard quality measures.","sentences":["Existing algorithms for explaining the output of image classifiers use different definitions of explanations and a variety of techniques to extract them.","However, none of the existing tools use a principled approach based on formal definitions of causes and explanations for the explanation extraction.","In this paper we present a novel black-box approach to computing explanations grounded in the theory of actual causality.","We prove relevant theoretical results and present an algorithm for computing approximate explanations based on these definitions.","We prove termination of our algorithm and discuss its complexity and the amount of approximation compared to the precise definition.","We implemented the framework in a tool rex and we present experimental results and a comparison with state-of-the-art tools.","We demonstrate that rex is the most efficient tool and produces the smallest explanations, in addition to outperforming other black-box tools on standard quality measures."],"url":"http://arxiv.org/abs/2411.08875v1"}
{"created":"2024-11-13 18:52:24","title":"A Decidable Case of Query Determinacy: Project-Select Views","abstract":"Query determinacy is decidable for project-select views and a project-select-join query with no self joins, as long as the selection predicates are in a first-order theory for which satisfiability is decidable.","sentences":["Query determinacy is decidable for project-select views and a project-select-join query with no self joins, as long as the selection predicates are in a first-order theory for which satisfiability is decidable."],"url":"http://arxiv.org/abs/2411.08874v1"}
{"created":"2024-11-13 18:51:10","title":"Large Wireless Model (LWM): A Foundation Model for Wireless Channels","abstract":"This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels. Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems. Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets. Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets. This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems.","sentences":["This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels.","Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems.","Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets.","Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets.","This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems."],"url":"http://arxiv.org/abs/2411.08872v1"}
{"created":"2024-11-13 18:50:13","title":"The Limited Impact of Medical Adaptation of Large Language and Vision-Language Models","abstract":"Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora. These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions. In this paper, we compare ten public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question-answering (QA). For instance, across all tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 22.7% of cases, reach a (statistical) tie in 36.8% of cases, and are significantly worse than their base models in the remaining 40.5% of cases. Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons. While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions. Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs can show performance improvements, but the benefits do not carry over to tasks based on clinical notes. Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies.","sentences":["Several recent works seek to develop foundation models specifically for medical applications, adapting general-purpose large language models (LLMs) and vision-language models (VLMs) via continued pretraining on publicly available biomedical corpora.","These works typically claim that such domain-adaptive pretraining (DAPT) improves performance on downstream medical tasks, such as answering medical licensing exam questions.","In this paper, we compare ten public \"medical\" LLMs and two VLMs against their corresponding base models, arriving at a different conclusion: all medical VLMs and nearly all medical LLMs fail to consistently improve over their base models in the zero-/few-shot prompting and supervised fine-tuning regimes for medical question-answering (QA).","For instance, across all tasks and model pairs we consider in the 3-shot setting, medical LLMs only outperform their base models in 22.7% of cases, reach a (statistical) tie in 36.8% of cases, and are significantly worse than their base models in the remaining 40.5% of cases.","Our conclusions are based on (i) comparing each medical model head-to-head, directly against the corresponding base model; (ii) optimizing the prompts for each model separately in zero-/few-shot prompting; and (iii) accounting for statistical uncertainty in comparisons.","While these basic practices are not consistently adopted in the literature, our ablations show that they substantially impact conclusions.","Meanwhile, we find that after fine-tuning on specific QA tasks, medical LLMs can show performance improvements, but the benefits do not carry over to tasks based on clinical notes.","Our findings suggest that state-of-the-art general-domain models may already exhibit strong medical knowledge and reasoning capabilities, and offer recommendations to strengthen the conclusions of future studies."],"url":"http://arxiv.org/abs/2411.08870v1"}
{"created":"2024-11-13 18:49:35","title":"CamemBERT 2.0: A Smarter French Language Model Aged to Perfection","abstract":"French language models, such as CamemBERT, have been widely adopted across industries for natural language processing (NLP) tasks, with models like CamemBERT seeing over 4 million downloads per month. However, these models face challenges due to temporal concept drift, where outdated training data leads to a decline in performance, especially when encountering new topics and terminology. This issue emphasizes the need for updated models that reflect current linguistic trends. In this paper, we introduce two new versions of the CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these challenges. CamemBERTav2 is based on the DeBERTaV3 architecture and makes use of the Replaced Token Detection (RTD) objective for better contextual understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked Language Modeling (MLM) objective. Both models are trained on a significantly larger and more recent dataset with longer context length and an updated tokenizer that enhances tokenization performance for French. We evaluate the performance of these models on both general-domain NLP tasks and domain-specific applications, such as medical field tasks, demonstrating their versatility and effectiveness across a range of use cases. Our results show that these updated models vastly outperform their predecessors, making them valuable tools for modern NLP systems. All our new models, as well as intermediate checkpoints, are made openly available on Huggingface.","sentences":["French language models, such as CamemBERT, have been widely adopted across industries for natural language processing (NLP) tasks, with models like CamemBERT seeing over 4 million downloads per month.","However, these models face challenges due to temporal concept drift, where outdated training data leads to a decline in performance, especially when encountering new topics and terminology.","This issue emphasizes the need for updated models that reflect current linguistic trends.","In this paper, we introduce two new versions of the CamemBERT base model-CamemBERTav2 and CamemBERTv2-designed to address these challenges.","CamemBERTav2 is based on the DeBERTaV3 architecture and makes use of the Replaced Token Detection (RTD) objective for better contextual understanding, while CamemBERTv2 is built on RoBERTa, which uses the Masked Language Modeling (MLM) objective.","Both models are trained on a significantly larger and more recent dataset with longer context length and an updated tokenizer that enhances tokenization performance for French.","We evaluate the performance of these models on both general-domain NLP tasks and domain-specific applications, such as medical field tasks, demonstrating their versatility and effectiveness across a range of use cases.","Our results show that these updated models vastly outperform their predecessors, making them valuable tools for modern NLP systems.","All our new models, as well as intermediate checkpoints, are made openly available on Huggingface."],"url":"http://arxiv.org/abs/2411.08868v1"}
{"created":"2024-11-13 18:48:51","title":"Unsupervised Parameter-free Outlier Detection using HDBSCAN* Outlier Profiles","abstract":"In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models. Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them. Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method. GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy. GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation. With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others. Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown. In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset. Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value. Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH.","sentences":["In machine learning and data mining, outliers are data points that significantly differ from the dataset and often introduce irrelevant information that can induce bias in its statistics and models.","Therefore, unsupervised methods are crucial to detect outliers if there is limited or no information about them.","Global-Local Outlier Scores based on Hierarchies (GLOSH) is an unsupervised outlier detection method within HDBSCAN*, a state-of-the-art hierarchical clustering method.","GLOSH estimates outlier scores for each data point by comparing its density to the highest density of the region they reside in the HDBSCAN* hierarchy.","GLOSH may be sensitive to HDBSCAN*'s minpts parameter that influences density estimation.","With limited knowledge about the data, choosing an appropriate minpts value beforehand is challenging as one or some minpts values may better represent the underlying cluster structure than others.","Additionally, in the process of searching for ``potential outliers'', one has to define the number of outliers n a dataset has, which may be impractical and is often unknown.","In this paper, we propose an unsupervised strategy to find the ``best'' minpts value, leveraging the range of GLOSH scores across minpts values to identify the value for which GLOSH scores can best identify outliers from the rest of the dataset.","Moreover, we propose an unsupervised strategy to estimate a threshold for classifying points into inliers and (potential) outliers without the need to pre-define any value.","Our experiments show that our strategies can automatically find the minpts value and threshold that yield the best or near best outlier detection results using GLOSH."],"url":"http://arxiv.org/abs/2411.08867v1"}
{"created":"2024-11-13 18:44:30","title":"LLMStinger: Jailbreaking LLMs using RL fine-tuned LLMs","abstract":"We introduce LLMStinger, a novel approach that leverages Large Language Models (LLMs) to automatically generate adversarial suffixes for jailbreak attacks. Unlike traditional methods, which require complex prompt engineering or white-box access, LLMStinger uses a reinforcement learning (RL) loop to fine-tune an attacker LLM, generating new suffixes based on existing attacks for harmful questions from the HarmBench benchmark. Our method significantly outperforms existing red-teaming approaches (we compared against 15 of the latest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for their extensive safety measures. Additionally, we achieved a 94.97% ASR on GPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability of LLMStinger across open and closed-source models.","sentences":["We introduce LLMStinger, a novel approach that leverages Large Language Models (LLMs) to automatically generate adversarial suffixes for jailbreak attacks.","Unlike traditional methods, which require complex prompt engineering or white-box access, LLMStinger uses a reinforcement learning (RL) loop to fine-tune an attacker LLM, generating new suffixes based on existing attacks for harmful questions from the HarmBench benchmark.","Our method significantly outperforms existing red-teaming approaches (we compared against 15 of the latest methods), achieving a +57.2% improvement in Attack Success Rate (ASR) on LLaMA2-7B-chat and a +50.3% ASR increase on Claude 2, both models known for their extensive safety measures.","Additionally, we achieved a 94.97% ASR on GPT-3.5 and 99.4% on Gemma-2B-it, demonstrating the robustness and adaptability of LLMStinger across open and closed-source models."],"url":"http://arxiv.org/abs/2411.08862v1"}
{"created":"2024-11-13 18:41:16","title":"Designing a Virtual Reality Training Apprenticeship for Cold Spray Advanced Manufacturing","abstract":"Apprenticeship and training programs in advanced manufacturing frequently encounter safety and accessibility concerns due to using heavy machinery. Virtual Reality (VR) training addresses such constraints while maintaining the spatial and procedural learning requirements of such training. However, designing effective VR training is challenging because advanced manufacturing processes are complex and require experts to train novices for a long time. This paper presents a VR Training Apprenticeship (VRTA) tailored for cold spray, which we carefully designed to teach novices step-by-step this particular advanced manufacturing process. To assess its effectiveness, we conducted an exploratory study ($n = 22$). We evaluated user experience (UX) measures in the form of quantitative scales, users' qualitative insights, and task performance with real-world machinery after the VR training. We discuss how the VRTA design contributed to the effectiveness and the challenges of considering VR training for advanced manufacturing.","sentences":["Apprenticeship and training programs in advanced manufacturing frequently encounter safety and accessibility concerns due to using heavy machinery.","Virtual Reality (VR) training addresses such constraints while maintaining the spatial and procedural learning requirements of such training.","However, designing effective VR training is challenging because advanced manufacturing processes are complex and require experts to train novices for a long time.","This paper presents a VR Training Apprenticeship (VRTA) tailored for cold spray, which we carefully designed to teach novices step-by-step this particular advanced manufacturing process.","To assess its effectiveness, we conducted an exploratory study ($n = 22$).","We evaluated user experience (UX) measures in the form of quantitative scales, users' qualitative insights, and task performance with real-world machinery after the VR training.","We discuss how the VRTA design contributed to the effectiveness and the challenges of considering VR training for advanced manufacturing."],"url":"http://arxiv.org/abs/2411.08859v1"}
{"created":"2024-11-13 18:30:28","title":"Experience-based Subproblem Planning for Multi-Robot Motion Planning","abstract":"Multi-robot systems enhance efficiency and productivity across various applications, from manufacturing to surveillance. While single-robot motion planning has improved by using databases of prior solutions, extending this approach to multi-robot motion planning (MRMP) presents challenges due to the increased complexity and diversity of tasks and configurations. Recent discrete methods have attempted to address this by focusing on relevant lower-dimensional subproblems, but they are inadequate for complex scenarios like those involving manipulator robots. To overcome this, we propose a novel approach that %leverages experience-based planning by constructs and utilizes databases of solutions for smaller sub-problems. By focusing on interactions between fewer robots, our method reduces the need for exhaustive database growth, allowing for efficient handling of more complex MRMP scenarios. We validate our approach with experiments involving both mobile and manipulator robots, demonstrating significant improvements over existing methods in scalability and planning efficiency. Our contributions include a rapidly constructed database for low-dimensional MRMP problems, a framework for applying these solutions to larger problems, and experimental validation with up to 32 mobile and 16 manipulator robots.","sentences":["Multi-robot systems enhance efficiency and productivity across various applications, from manufacturing to surveillance.","While single-robot motion planning has improved by using databases of prior solutions, extending this approach to multi-robot motion planning (MRMP) presents challenges due to the increased complexity and diversity of tasks and configurations.","Recent discrete methods have attempted to address this by focusing on relevant lower-dimensional subproblems, but they are inadequate for complex scenarios like those involving manipulator robots.","To overcome this, we propose a novel approach that %leverages experience-based planning by constructs and utilizes databases of solutions for smaller sub-problems.","By focusing on interactions between fewer robots, our method reduces the need for exhaustive database growth, allowing for efficient handling of more complex MRMP scenarios.","We validate our approach with experiments involving both mobile and manipulator robots, demonstrating significant improvements over existing methods in scalability and planning efficiency.","Our contributions include a rapidly constructed database for low-dimensional MRMP problems, a framework for applying these solutions to larger problems, and experimental validation with up to 32 mobile and 16 manipulator robots."],"url":"http://arxiv.org/abs/2411.08851v1"}
{"created":"2024-11-13 18:29:11","title":"Proof Nets for the \u03c0-Calculus","abstract":"In this paper, we establish the foundations of a novel logical framework for the {\\pi}-calculus, based on the deduction-as-computation paradigm. Following the standard proof-theoretic interpretation of logic programming, we represent processes as formulas, and we interpret proofs as computations.   For this purpose, we define a cut-free sequent calculus for an extension of first-order multiplicative and additive linear logic. This extension includes a non-commutative and non-associative connective to faithfully model the prefix operator, and nominal quantifiers to represent name restriction. Finally, we design proof nets providing canonical representatives of derivations up to local rule permutations.","sentences":["In this paper, we establish the foundations of a novel logical framework for the {\\pi}-calculus, based on the deduction-as-computation paradigm.","Following the standard proof-theoretic interpretation of logic programming, we represent processes as formulas, and we interpret proofs as computations.   ","For this purpose, we define a cut-free sequent calculus for an extension of first-order multiplicative and additive linear logic.","This extension includes a non-commutative and non-associative connective to faithfully model the prefix operator, and nominal quantifiers to represent name restriction.","Finally, we design proof nets providing canonical representatives of derivations up to local rule permutations."],"url":"http://arxiv.org/abs/2411.08847v1"}
{"created":"2024-11-13 18:19:51","title":"Multimodal Instruction Tuning with Hybrid State Space Models","abstract":"Handling lengthy context is crucial for enhancing the recognition and understanding capabilities of multimodal large language models (MLLMs) in applications such as processing high-resolution images or high frame rate videos. The rise in image resolution and frame rate substantially increases computational demands due to the increased number of input tokens. This challenge is further exacerbated by the quadratic complexity with respect to sequence length of the self-attention mechanism. Most prior works either pre-train models with long contexts, overlooking the efficiency problem, or attempt to reduce the context length via downsampling (e.g., identify the key image patches or frames) to decrease the context length, which may result in information loss. To circumvent this issue while keeping the remarkable effectiveness of MLLMs, we propose a novel approach using a hybrid transformer-MAMBA model to efficiently handle long contexts in multimodal applications. Our multimodal model can effectively process long context input exceeding 100k tokens, outperforming existing models across various benchmarks. Remarkably, our model enhances inference efficiency for high-resolution images and high-frame-rate videos by about 4 times compared to current models, with efficiency gains increasing as image resolution or video frames rise. Furthermore, our model is the first to be trained on low-resolution images or low-frame-rate videos while being capable of inference on high-resolution images and high-frame-rate videos, offering flexibility for inference in diverse scenarios.","sentences":["Handling lengthy context is crucial for enhancing the recognition and understanding capabilities of multimodal large language models (MLLMs) in applications such as processing high-resolution images or high frame rate videos.","The rise in image resolution and frame rate substantially increases computational demands due to the increased number of input tokens.","This challenge is further exacerbated by the quadratic complexity with respect to sequence length of the self-attention mechanism.","Most prior works either pre-train models with long contexts, overlooking the efficiency problem, or attempt to reduce the context length via downsampling (e.g., identify the key image patches or frames) to decrease the context length, which may result in information loss.","To circumvent this issue while keeping the remarkable effectiveness of MLLMs, we propose a novel approach using a hybrid transformer-MAMBA model to efficiently handle long contexts in multimodal applications.","Our multimodal model can effectively process long context input exceeding 100k tokens, outperforming existing models across various benchmarks.","Remarkably, our model enhances inference efficiency for high-resolution images and high-frame-rate videos by about 4 times compared to current models, with efficiency gains increasing as image resolution or video frames rise.","Furthermore, our model is the first to be trained on low-resolution images or low-frame-rate videos while being capable of inference on high-resolution images and high-frame-rate videos, offering flexibility for inference in diverse scenarios."],"url":"http://arxiv.org/abs/2411.08840v1"}
{"created":"2024-11-13 18:14:23","title":"Goal-oriented Semantic Communication for Robot Arm Reconstruction in Digital Twin: Feature and Temporal Selections","abstract":"As one of the most promising technologies in industry, the Digital Twin (DT) facilitates real-time monitoring and predictive analysis for real-world systems by precisely reconstructing virtual replicas of physical entities. However, this reconstruction faces unprecedented challenges due to the everincreasing communication overhead, especially for digital robot arm reconstruction. To this end, we propose a novel goal-oriented semantic communication (GSC) framework to extract the GSC information for the robot arm reconstruction task in the DT, with the aim of minimising the communication load under the strict and relaxed reconstruction error constraints. Unlike the traditional reconstruction framework that periodically transmits a reconstruction message for real-time DT reconstruction, our framework implements a feature selection (FS) algorithm to extract the semantic information from the reconstruction message, and a deep reinforcement learning-based temporal selection algorithm to selectively transmit the semantic information over time. We validate our proposed GSC framework through both Pybullet simulations and lab experiments based on the Franka Research 3 robot arm. For a range of distinct robotic tasks, simulation results show that our framework can reduce the communication load by at least 59.5% under strict reconstruction error constraints and 80% under relaxed reconstruction error constraints, compared with traditional communication framework. Also, experimental results confirm the effectiveness of our framework, where the communication load is reduced by 53% in strict constraint case and 74% in relaxed constraint case. The demo is available at: https://youtu.be/2OdeHKxcgnk.","sentences":["As one of the most promising technologies in industry, the Digital Twin (DT) facilitates real-time monitoring and predictive analysis for real-world systems by precisely reconstructing virtual replicas of physical entities.","However, this reconstruction faces unprecedented challenges due to the everincreasing communication overhead, especially for digital robot arm reconstruction.","To this end, we propose a novel goal-oriented semantic communication (GSC) framework to extract the GSC information for the robot arm reconstruction task in the DT, with the aim of minimising the communication load under the strict and relaxed reconstruction error constraints.","Unlike the traditional reconstruction framework that periodically transmits a reconstruction message for real-time DT reconstruction, our framework implements a feature selection (FS) algorithm to extract the semantic information from the reconstruction message, and a deep reinforcement learning-based temporal selection algorithm to selectively transmit the semantic information over time.","We validate our proposed GSC framework through both Pybullet simulations and lab experiments based on the Franka Research 3 robot arm.","For a range of distinct robotic tasks, simulation results show that our framework can reduce the communication load by at least 59.5% under strict reconstruction error constraints and 80% under relaxed reconstruction error constraints, compared with traditional communication framework.","Also, experimental results confirm the effectiveness of our framework, where the communication load is reduced by 53% in strict constraint case and 74% in relaxed constraint case.","The demo is available at: https://youtu.be/2OdeHKxcgnk."],"url":"http://arxiv.org/abs/2411.08835v1"}
{"created":"2024-11-13 18:12:22","title":"Advanced OOP and new syntax patterns for Javascript","abstract":"We present OBJS, a new transpiler project featuring the implementation of typified variables and functions call management in Javascript, as well as several new operators and syntax patterns that could make coding more agile and versatile. The goal is to empower this language. According to this point of view, this transpiler aims at implementing Object Oriented Programming paradigms into Javascript. The author opines that this would be likely the best evolution of this language in ways that should be proper to the original syntax, that is, by adopting native C++standards, so that there would be no promiscuity between old and new patterns, benefiting those who come from similar languages.","sentences":["We present OBJS, a new transpiler project featuring the implementation of typified variables and functions call management in Javascript, as well as several new operators and syntax patterns that could make coding more agile and versatile.","The goal is to empower this language.","According to this point of view, this transpiler aims at implementing Object Oriented Programming paradigms into Javascript.","The author opines that this would be likely the best evolution of this language in ways that should be proper to the original syntax, that is, by adopting native C++standards, so that there would be no promiscuity between old and new patterns, benefiting those who come from similar languages."],"url":"http://arxiv.org/abs/2411.08833v1"}
{"created":"2024-11-13 18:12:15","title":"Offline Adaptation of Quadruped Locomotion using Diffusion Models","abstract":"We present a diffusion-based approach to quadrupedal locomotion that simultaneously addresses the limitations of learning and interpolating between multiple skills and of (modes) offline adapting to new locomotion behaviours after training. This is the first framework to apply classifier-free guided diffusion to quadruped locomotion and demonstrate its efficacy by extracting goal-conditioned behaviour from an originally unlabelled dataset. We show that these capabilities are compatible with a multi-skill policy and can be applied with little modification and minimal compute overhead, i.e., running entirely on the robots onboard CPU. We verify the validity of our approach with hardware experiments on the ANYmal quadruped platform.","sentences":["We present a diffusion-based approach to quadrupedal locomotion that simultaneously addresses the limitations of learning and interpolating between multiple skills and of (modes) offline adapting to new locomotion behaviours after training.","This is the first framework to apply classifier-free guided diffusion to quadruped locomotion and demonstrate its efficacy by extracting goal-conditioned behaviour from an originally unlabelled dataset.","We show that these capabilities are compatible with a multi-skill policy and can be applied with little modification and minimal compute overhead, i.e., running entirely on the robots onboard CPU.","We verify the validity of our approach with hardware experiments on the ANYmal quadruped platform."],"url":"http://arxiv.org/abs/2411.08832v1"}
{"created":"2024-11-13 18:00:35","title":"A probabilistic reduced-order modeling framework for patient-specific cardio-mechanical analysis","abstract":"Cardio-mechanical models can be used to support clinical decision-making. Unfortunately, the substantial computational effort involved in many cardiac models hinders their application in the clinic, despite the fact that they may provide valuable information. In this work, we present a probabilistic reduced-order modeling (ROM) framework to dramatically reduce the computational effort of such models while providing a credibility interval. In the online stage, a fast-to-evaluate generalized one-fiber model is considered. This generalized one-fiber model incorporates correction factors to emulate patient-specific attributes, such as local geometry variations. In the offline stage, Bayesian inference is used to calibrate these correction factors on training data generated using a full-order isogeometric cardiac model (FOM). A Gaussian process is used in the online stage to predict the correction factors for geometries that are not in the training data. The proposed framework is demonstrated using two examples. The first example considers idealized left-ventricle geometries, for which the behavior of the ROM framework can be studied in detail. In the second example, the ROM framework is applied to scan-based geometries, based on which the application of the ROM framework in the clinical setting is discussed. The results for the two examples convey that the ROM framework can provide accurate online predictions, provided that adequate FOM training data is available. The uncertainty bands provided by the ROM framework give insight into the trustworthiness of its results. Large uncertainty bands can be considered as an indicator for the further population of the training data set.","sentences":["Cardio-mechanical models can be used to support clinical decision-making.","Unfortunately, the substantial computational effort involved in many cardiac models hinders their application in the clinic, despite the fact that they may provide valuable information.","In this work, we present a probabilistic reduced-order modeling (ROM) framework to dramatically reduce the computational effort of such models while providing a credibility interval.","In the online stage, a fast-to-evaluate generalized one-fiber model is considered.","This generalized one-fiber model incorporates correction factors to emulate patient-specific attributes, such as local geometry variations.","In the offline stage, Bayesian inference is used to calibrate these correction factors on training data generated using a full-order isogeometric cardiac model (FOM).","A Gaussian process is used in the online stage to predict the correction factors for geometries that are not in the training data.","The proposed framework is demonstrated using two examples.","The first example considers idealized left-ventricle geometries, for which the behavior of the ROM framework can be studied in detail.","In the second example, the ROM framework is applied to scan-based geometries, based on which the application of the ROM framework in the clinical setting is discussed.","The results for the two examples convey that the ROM framework can provide accurate online predictions, provided that adequate FOM training data is available.","The uncertainty bands provided by the ROM framework give insight into the trustworthiness of its results.","Large uncertainty bands can be considered as an indicator for the further population of the training data set."],"url":"http://arxiv.org/abs/2411.08822v1"}
{"created":"2024-11-13 17:57:13","title":"On integer sequences for rendering limit sets of Kleinian groups","abstract":"We present a technique for rendering limit sets for kleinian groups, based upon the base transformation of integers and which aims at saving memory resources and being faster than the traditional dictionary based approach.","sentences":["We present a technique for rendering limit sets for kleinian groups, based upon the base transformation of integers and which aims at saving memory resources and being faster than the traditional dictionary based approach."],"url":"http://arxiv.org/abs/2411.08818v1"}
{"created":"2024-11-13 17:53:53","title":"Learning real-time one-counter automata using polynomially many queries","abstract":"In this paper, we introduce a novel method for active learning of deterministic real-time one-counter automata (DROCA). The existing techniques for learning DROCA rely on observing the behaviour of the DROCA up to exponentially large counter-values. Our algorithm eliminates this need and requires only a polynomial number of queries. Additionally, our method differs from existing techniques as we learn a minimal counter-synchronous DROCA, resulting in much smaller counter-examples on equivalence queries. Learning a minimal counter-synchronous DROCA cannot be done in polynomial time unless P = NP, even in the case of visibly one-counter automata. We use a SAT solver to overcome this difficulty. The solver is used to compute a minimal separating DFA from a given set of positive and negative samples.   We prove that the equivalence of two counter-synchronous DROCAs can be checked significantly faster than that of general DROCAs. For visibly one-counter automata, we have discovered an even faster algorithm for equivalence checking. We implemented the proposed learning algorithm and tested it on randomly generated DROCAs. Our evaluations show that the proposed method outperforms the existing techniques on the test set.","sentences":["In this paper, we introduce a novel method for active learning of deterministic real-time one-counter automata (DROCA).","The existing techniques for learning DROCA rely on observing the behaviour of the DROCA up to exponentially large counter-values.","Our algorithm eliminates this need and requires only a polynomial number of queries.","Additionally, our method differs from existing techniques as we learn a minimal counter-synchronous DROCA, resulting in much smaller counter-examples on equivalence queries.","Learning a minimal counter-synchronous DROCA cannot be done in polynomial time unless P = NP, even in the case of visibly one-counter automata.","We use a SAT solver to overcome this difficulty.","The solver is used to compute a minimal separating DFA from a given set of positive and negative samples.   ","We prove that the equivalence of two counter-synchronous DROCAs can be checked significantly faster than that of general DROCAs.","For visibly one-counter automata, we have discovered an even faster algorithm for equivalence checking.","We implemented the proposed learning algorithm and tested it on randomly generated DROCAs.","Our evaluations show that the proposed method outperforms the existing techniques on the test set."],"url":"http://arxiv.org/abs/2411.08815v1"}
{"created":"2024-11-13 17:53:23","title":"Process-aware Human Activity Recognition","abstract":"Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines. Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data. However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness. We propose a novel approach that incorporates process information from context to enhance the HAR performance. Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information. This alignment adaptively weighs these two sources of information to optimise HAR accuracy. Our experiments demonstrate that our approach achieves better accuracy and Macro F1-score compared to baseline models.","sentences":["Humans naturally follow distinct patterns when conducting their daily activities, which are driven by established practices and processes, such as production workflows, social norms and daily routines.","Human activity recognition (HAR) algorithms usually use neural networks or machine learning techniques to analyse inherent relationships within the data.","However, these approaches often overlook the contextual information in which the data are generated, potentially limiting their effectiveness.","We propose a novel approach that incorporates process information from context to enhance the HAR performance.","Specifically, we align probabilistic events generated by machine learning models with process models derived from contextual information.","This alignment adaptively weighs these two sources of information to optimise HAR accuracy.","Our experiments demonstrate that our approach achieves better accuracy and Macro F1-score compared to baseline models."],"url":"http://arxiv.org/abs/2411.08814v1"}
{"created":"2024-11-13 17:51:57","title":"Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique","abstract":"A key development in the cybersecurity evaluations space is the work carried out by Meta, through their CyberSecEval approach. While this work is undoubtedly a useful contribution to a nascent field, there are notable features that limit its utility. Key drawbacks focus on the insecure code detection part of Meta's methodology. We explore these limitations, and use our exploration as a test case for LLM-assisted benchmark analysis.","sentences":["A key development in the cybersecurity evaluations space is the work carried out by Meta, through their CyberSecEval approach.","While this work is undoubtedly a useful contribution to a nascent field, there are notable features that limit its utility.","Key drawbacks focus on the insecure code detection part of Meta's methodology.","We explore these limitations, and use our exploration as a test case for LLM-assisted benchmark analysis."],"url":"http://arxiv.org/abs/2411.08813v1"}
{"created":"2024-11-13 17:41:56","title":"Stochastic Matching via In-n-Out Local Computation Algorithms","abstract":"Consider the following stochastic matching problem. Given a graph $G=(V, E)$, an unknown subgraph $G_p = (V, E_p)$ is realized where $E_p$ includes every edge of $E$ independently with some probability $p \\in (0, 1]$. The goal is to query a sparse subgraph $H$ of $G$, such that the realized edges in $H$ include an approximate maximum matching of $G_p$.   This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets. For any fixed $\\epsilon > 0$, [BDH STOC'20] showed that any graph $G$ has a subgraph $H$ with $\\text{quasipoly}(1/p) = (1/p)^{\\text{poly}(\\log(1/p))}$ maximum degree, achieving a $(1-\\epsilon)$-approximation. A major open question is the best approximation achievable with $\\text{poly}(1/p)$-degree subgraphs. A long line of work has progressively improved the approximation in the $\\text{poly}(1/p)$-degree regime from .5 [BDH+ EC'15] to .501 [AKL EC'17], .656 [BHFR SODA'19], .666 [AB SOSA'19], .731 [BBD SODA'22] (bipartite graphs), and most recently to .68 [DS '24]. In this work, we show that a $\\text{poly}(1/p)$-degree subgraph can obtain a $(1-\\epsilon)$-approximation for any desirably small fixed $\\epsilon > 0$, achieving the best of both worlds.   Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time. While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex). We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings.","sentences":["Consider the following stochastic matching problem.","Given a graph $G=(V, E)$, an unknown subgraph $G_p = (V, E_p)$ is realized where $E_p$ includes every edge of $E$ independently with some probability $p \\in (0, 1]$. The goal is to query a sparse subgraph $H$ of $G$, such that the realized edges in $H$ include an approximate maximum matching of $G_p$.   This problem has been studied extensively over the last decade due to its numerous applications in kidney exchange, online dating, and online labor markets.","For any fixed $\\epsilon > 0$, [BDH STOC'20] showed that any graph $G$ has a subgraph $H$ with $\\text{quasipoly}(1/p) = (1/p)^{\\text{poly}(\\log(1/p))}$ maximum degree, achieving a $(1-\\epsilon)$-approximation.","A major open question is the best approximation achievable with $\\text{poly}(1/p)$-degree subgraphs.","A long line of work has progressively improved the approximation in the $\\text{poly}(1/p)$-degree regime from .5","[BDH+ EC'15] to .501","[AKL EC'17], .656","[BHFR SODA'19], .666","[AB SOSA'19], .731","[BBD SODA'22] (bipartite graphs), and most recently to .68","[DS '24].","In this work, we show that a $\\text{poly}(1/p)$-degree subgraph can obtain a $(1-\\epsilon)$-approximation for any desirably small fixed $\\epsilon > 0$, achieving the best of both worlds.   ","Beyond its quantitative improvement, a key conceptual contribution of our work is to connect local computation algorithms (LCAs) to the stochastic matching problem for the first time.","While prior work on LCAs mainly focuses on their out-queries (the number of vertices probed to produce the output of a given vertex), our analysis also bounds the in-queries (the number of vertices that probe a given vertex).","We prove that the outputs of LCAs with bounded in- and out-queries (in-n-out LCAs for short) have limited correlation, a property that our analysis crucially relies on and might find applications beyond stochastic matchings."],"url":"http://arxiv.org/abs/2411.08805v1"}
{"created":"2024-11-13 17:25:25","title":"Learning Gaussian Multi-Index Models with Gradient Flow: Time Complexity and Directional Convergence","abstract":"This work focuses on the gradient flow dynamics of a neural network model that uses correlation loss to approximate a multi-index function on high-dimensional standard Gaussian data. Specifically, the multi-index function we consider is a sum of neurons $f^*(x) \\!=\\! \\sum_{j=1}^k \\! \\sigma^*(v_j^T x)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first and second Hermite polynomials in its Hermite expansion. It is known that, for the single-index case ($k\\!=\\!1$), overcoming the search phase requires polynomial time complexity. We first generalize this result to multi-index functions characterized by vectors in arbitrary directions. After the search phase, it is not clear whether the network neurons converge to the index vectors, or get stuck at a sub-optimal solution. When the index vectors are orthogonal, we give a complete characterization of the fixed points and prove that neurons converge to the nearest index vectors. Therefore, using $n \\! \\asymp \\! k \\log k$ neurons ensures finding the full set of index vectors with gradient flow with high probability over random initialization. When $ v_i^T v_j \\!=\\! \\beta \\! \\geq \\! 0$ for all $i \\neq j$, we prove the existence of a sharp threshold $\\beta_c \\!=\\! c/(c+k)$ at which the fixed point that computes the average of the index vectors transitions from a saddle point to a minimum. Numerical simulations show that using a correlation loss and a mild overparameterization suffices to learn all of the index vectors when they are nearly orthogonal, however, the correlation loss fails when the dot product between the index vectors exceeds a certain threshold.","sentences":["This work focuses on the gradient flow dynamics of a neural network model that uses correlation loss to approximate a multi-index function on high-dimensional standard Gaussian data.","Specifically, the multi-index function we consider is a sum of neurons $f^*(x) \\!=\\!","\\sum_{j=1}^k \\!","\\sigma^*(v_j^T x)$ where $v_1, \\dots, v_k$ are unit vectors, and $\\sigma^*$ lacks the first and second Hermite polynomials in its Hermite expansion.","It is known that, for the single-index case ($k\\!=\\!1$), overcoming the search phase requires polynomial time complexity.","We first generalize this result to multi-index functions characterized by vectors in arbitrary directions.","After the search phase, it is not clear whether the network neurons converge to the index vectors, or get stuck at a sub-optimal solution.","When the index vectors are orthogonal, we give a complete characterization of the fixed points and prove that neurons converge to the nearest index vectors.","Therefore, using $n \\!","\\asymp \\!","k \\log k$ neurons ensures finding the full set of index vectors with gradient flow with high probability over random initialization.","When $ v_i^T v_j \\!=\\!","\\beta \\!","\\geq \\!","0$ for all $i \\neq j$, we prove the existence of a sharp threshold $\\beta_c \\!=\\!","c/(c+k)$ at which the fixed point that computes the average of the index vectors transitions from a saddle point to a minimum.","Numerical simulations show that using a correlation loss and a mild overparameterization suffices to learn all of the index vectors when they are nearly orthogonal, however, the correlation loss fails when the dot product between the index vectors exceeds a certain threshold."],"url":"http://arxiv.org/abs/2411.08798v1"}
{"created":"2024-11-13 17:19:32","title":"Evaluating World Models with LLM for Decision Making","abstract":"World model emerges as a key module in decision making, where MuZero and Dreamer achieve remarkable successes in complex tasks. Recent work leverages Large Language Models (LLMs) as general world simulators to simulate the dynamics of the world due to their generalizability. LLMs also serve as the world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree of Thought (ToT). However, the world models are either evaluated as a general world simulator, or as a functional module of the agent, i.e., predicting the transitions to assist the planning. In this work, we propose a comprehensive evaluation of the world models with LLMs from the decision making perspective. Specifically, we leverage the 31 diverse environments from (Wang et al., 2023;2024) and curate the rule-based policy of each environment for the diverse evaluation. Then, we design three main tasks, i.e., policy verification, action proposal, and policy planning, where the world models can be used for decision making solely. Finally, we conduct the comprehensive evaluation of the advanced LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main tasks under various settings. The key observations include: i) GPT-4o significantly outperforms GPT-4o-mini on the three main tasks, especially for the tasks which require the domain knowledge, ii) the performance of the world model with LLM will be decreased for long-term decision-making tasks, and iii) the combination of different functionalities of the world model will brings additional unstabilities of the performance.","sentences":["World model emerges as a key module in decision making, where MuZero and Dreamer achieve remarkable successes in complex tasks.","Recent work leverages Large Language Models (LLMs) as general world simulators to simulate the dynamics of the world due to their generalizability.","LLMs also serve as the world model for deliberative reasoning in Reasoning via Planning (RAP) and Tree of Thought (ToT).","However, the world models are either evaluated as a general world simulator, or as a functional module of the agent, i.e., predicting the transitions to assist the planning.","In this work, we propose a comprehensive evaluation of the world models with LLMs from the decision making perspective.","Specifically, we leverage the 31 diverse environments from (Wang et al., 2023;2024) and curate the rule-based policy of each environment for the diverse evaluation.","Then, we design three main tasks, i.e., policy verification, action proposal, and policy planning, where the world models can be used for decision making solely.","Finally, we conduct the comprehensive evaluation of the advanced LLMs, i.e., GPT-4o and GPT-4o-mini, on the environments for the three main tasks under various settings.","The key observations include: i) GPT-4o significantly outperforms GPT-4o-mini on the three main tasks, especially for the tasks which require the domain knowledge, ii) the performance of the world model with LLM will be decreased for long-term decision-making tasks, and iii) the combination of different functionalities of the world model will brings additional unstabilities of the performance."],"url":"http://arxiv.org/abs/2411.08794v1"}
{"created":"2024-11-13 17:17:52","title":"An alignment problem","abstract":"This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps. Here, we introduce the problem of optimally aligning $k$ collections of $m$ spatial supports over $n$ spatial units in a $d$-dimensional Euclidean space. We show that the 1-dimensional case is solvable in time polynomial in $k$, $m$ and $n$. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports. Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case.","sentences":["This work concerns an alignment problem that has applications in many geospatial problems such as resource allocation and building reliable disease maps.","Here, we introduce the problem of optimally aligning $k$ collections of $m$ spatial supports over $n$ spatial units in a $d$-dimensional Euclidean space.","We show that the 1-dimensional case is solvable in time polynomial in $k$, $m$ and $n$. We then show that the 2-dimensional case is NP-hard for 2 collections of 2 supports.","Finally, we devise a heuristic for aligning a set of collections in the 2-dimensional case."],"url":"http://arxiv.org/abs/2411.08792v1"}
{"created":"2024-11-13 17:17:16","title":"Locally Private Sampling with Public Data","abstract":"Local differential privacy (LDP) is increasingly employed in privacy-preserving machine learning to protect user data before sharing it with an untrusted aggregator. Most LDP methods assume that users possess only a single data record, which is a significant limitation since users often gather extensive datasets (e.g., images, text, time-series data) and frequently have access to public datasets. To address this limitation, we propose a locally private sampling framework that leverages both the private and public datasets of each user. Specifically, we assume each user has two distributions: $p$ and $q$ that represent their private dataset and the public dataset, respectively. The objective is to design a mechanism that generates a private sample approximating $p$ while simultaneously preserving $q$. We frame this objective as a minimax optimization problem using $f$-divergence as the utility measure. We fully characterize the minimax optimal mechanisms for general $f$-divergences provided that $p$ and $q$ are discrete distributions. Remarkably, we demonstrate that this optimal mechanism is universal across all $f$-divergences. Experiments validate the effectiveness of our minimax optimal sampler compared to the state-of-the-art locally private sampler.","sentences":["Local differential privacy (LDP) is increasingly employed in privacy-preserving machine learning to protect user data before sharing it with an untrusted aggregator.","Most LDP methods assume that users possess only a single data record, which is a significant limitation since users often gather extensive datasets (e.g., images, text, time-series data) and frequently have access to public datasets.","To address this limitation, we propose a locally private sampling framework that leverages both the private and public datasets of each user.","Specifically, we assume each user has two distributions: $p$ and $q$ that represent their private dataset and the public dataset, respectively.","The objective is to design a mechanism that generates a private sample approximating $p$ while simultaneously preserving $q$. We frame this objective as a minimax optimization problem using $f$-divergence as the utility measure.","We fully characterize the minimax optimal mechanisms for general $f$-divergences provided that $p$ and $q$ are discrete distributions.","Remarkably, we demonstrate that this optimal mechanism is universal across all $f$-divergences.","Experiments validate the effectiveness of our minimax optimal sampler compared to the state-of-the-art locally private sampler."],"url":"http://arxiv.org/abs/2411.08791v1"}
{"created":"2024-11-13 17:16:48","title":"Can sparse autoencoders be used to decompose and interpret steering vectors?","abstract":"Steering vectors are a promising approach to control the behaviour of large language models. However, their underlying mechanisms remain poorly understood. While sparse autoencoders (SAEs) may offer a potential method to interpret steering vectors, recent findings show that SAE-reconstructed vectors often lack the steering properties of the original vectors. This paper investigates why directly applying SAEs to steering vectors yields misleading decompositions, identifying two reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate. These limitations hinder the direct use of SAEs for interpreting steering vectors.","sentences":["Steering vectors are a promising approach to control the behaviour of large language models.","However, their underlying mechanisms remain poorly understood.","While sparse autoencoders (SAEs) may offer a potential method to interpret steering vectors, recent findings show that SAE-reconstructed vectors often lack the steering properties of the original vectors.","This paper investigates why directly applying SAEs to steering vectors yields misleading decompositions, identifying two reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate.","These limitations hinder the direct use of SAEs for interpreting steering vectors."],"url":"http://arxiv.org/abs/2411.08790v1"}
{"created":"2024-11-13 17:13:25","title":"Zero-shot Cross-lingual Transfer Learning with Multiple Source and Target Languages for Information Extraction: Language Selection and Adversarial Training","abstract":"The majority of previous researches addressing multi-lingual IE are limited to zero-shot cross-lingual single-transfer (one-to-one) setting, with high-resource languages predominantly as source training data. As a result, these works provide little understanding and benefit for the realistic goal of developing a multi-lingual IE system that can generalize to as many languages as possible. Our study aims to fill this gap by providing a detailed analysis on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for the recent IE corpora that cover a diverse set of languages. Specifically, we first determine the correlation between single-transfer performance and a wide range of linguistic-based distances. From the obtained insights, a combined language distance metric can be developed that is not only highly correlated but also robust across different tasks and model scales. Next, we investigate the more general zero-shot multi-lingual transfer settings where multiple languages are involved in the training and evaluation processes. Language clustering based on the newly defined distance can provide directions for achieving the optimal cost-performance trade-off in data (languages) selection problem. Finally, a relational-transfer setting is proposed to further incorporate multi-lingual unlabeled data based on adversarial training using the relation induced from the above linguistic distance.","sentences":["The majority of previous researches addressing multi-lingual IE are limited to zero-shot cross-lingual single-transfer (one-to-one) setting, with high-resource languages predominantly as source training data.","As a result, these works provide little understanding and benefit for the realistic goal of developing a multi-lingual IE system that can generalize to as many languages as possible.","Our study aims to fill this gap by providing a detailed analysis on Cross-Lingual Multi-Transferability (many-to-many transfer learning), for the recent IE corpora that cover a diverse set of languages.","Specifically, we first determine the correlation between single-transfer performance and a wide range of linguistic-based distances.","From the obtained insights, a combined language distance metric can be developed that is not only highly correlated but also robust across different tasks and model scales.","Next, we investigate the more general zero-shot multi-lingual transfer settings where multiple languages are involved in the training and evaluation processes.","Language clustering based on the newly defined distance can provide directions for achieving the optimal cost-performance trade-off in data (languages) selection problem.","Finally, a relational-transfer setting is proposed to further incorporate multi-lingual unlabeled data based on adversarial training using the relation induced from the above linguistic distance."],"url":"http://arxiv.org/abs/2411.08785v1"}
{"created":"2024-11-13 17:12:47","title":"Towards Fair and Efficient Public Transportation: A Bus Stop Model","abstract":"We consider a stylized formal model of public transportation, where a set of agents need to travel along a given road, and there is a bus that runs the length of this road. Each agent has a left terminal and a right terminal between which they wish to travel; they can walk all the way, or walk to/from the nearest stop and use the bus for the rest of their journey. The bus can make a fixed number of stops, and the planner needs to select locations for these stops. We study notions of efficiency and fairness for this setting. First, we give a polynomial-time algorithm for computing a solution that minimizes the total travel time; our approach can capture further extensions of the base model, such as more general cost functions or existing infrastructure. Second, we develop a polynomial-time algorithm that outputs solutions with provable fairness guarantees (such as a variant of the justified representation axiom or $2$-approximate core) as long as the agents' costs only depend on the distance they need to walk. Our simulations indicate that our algorithm almost always outputs fair solutions, even for parameter regimes that do not admit theoretical guarantees.","sentences":["We consider a stylized formal model of public transportation, where a set of agents need to travel along a given road, and there is a bus that runs the length of this road.","Each agent has a left terminal and a right terminal between which they wish to travel; they can walk all the way, or walk to/from the nearest stop and use the bus for the rest of their journey.","The bus can make a fixed number of stops, and the planner needs to select locations for these stops.","We study notions of efficiency and fairness for this setting.","First, we give a polynomial-time algorithm for computing a solution that minimizes the total travel time; our approach can capture further extensions of the base model, such as more general cost functions or existing infrastructure.","Second, we develop a polynomial-time algorithm that outputs solutions with provable fairness guarantees (such as a variant of the justified representation axiom or $2$-approximate core) as long as the agents' costs only depend on the distance they need to walk.","Our simulations indicate that our algorithm almost always outputs fair solutions, even for parameter regimes that do not admit theoretical guarantees."],"url":"http://arxiv.org/abs/2411.08784v1"}
{"created":"2024-11-13 17:08:21","title":"SoK: Towards a Common Understanding of Cryptographic Agility","abstract":"Cryptographic agility is gaining attention due to its crucial role in maintaining cryptographic security in a rapidly evolving technological landscape. However, despite its increasing importance, the term cryptographic agility remains vaguely defined and there is no clear consensus on its exact meaning. This lack of clarity poses a challenge since the need for agility becomes more urgent as new cryptographic vulnerabilities and advanced computing threats emerge, emphasizing the need for a systematic approach to clarify and refine the notion on cryptographic agility.   In this paper, we systematize the concept of cryptographic agility by providing three research contributions. First, we review current definitions across academic and gray literature, identifying six distinct categories to differentiate every aspect within the definitions. Second, we synthesize these insights to establish a comprehensive, canonical definition of cryptographic agility. Third, we explore the relationship between cryptographic agility and the related concepts cryptographic versatility and interoperability. In our discussion, we examine the relevance of cryptographic agility, highlight its trade-offs with complexity, assess its individual applicability, and illustrate its various contexts by offering an additional application-specific definition. Our work provides a new perspective on cryptographic agility and related concepts, based on systematical research to clarify and enhance its future use.","sentences":["Cryptographic agility is gaining attention due to its crucial role in maintaining cryptographic security in a rapidly evolving technological landscape.","However, despite its increasing importance, the term cryptographic agility remains vaguely defined and there is no clear consensus on its exact meaning.","This lack of clarity poses a challenge since the need for agility becomes more urgent as new cryptographic vulnerabilities and advanced computing threats emerge, emphasizing the need for a systematic approach to clarify and refine the notion on cryptographic agility.   ","In this paper, we systematize the concept of cryptographic agility by providing three research contributions.","First, we review current definitions across academic and gray literature, identifying six distinct categories to differentiate every aspect within the definitions.","Second, we synthesize these insights to establish a comprehensive, canonical definition of cryptographic agility.","Third, we explore the relationship between cryptographic agility and the related concepts cryptographic versatility and interoperability.","In our discussion, we examine the relevance of cryptographic agility, highlight its trade-offs with complexity, assess its individual applicability, and illustrate its various contexts by offering an additional application-specific definition.","Our work provides a new perspective on cryptographic agility and related concepts, based on systematical research to clarify and enhance its future use."],"url":"http://arxiv.org/abs/2411.08781v1"}
{"created":"2024-11-13 17:02:46","title":"LUDO: Low-Latency Understanding of Highly Deformable Objects using Point Cloud Occupancy Functions","abstract":"Accurately determining the shape and location of internal structures within deformable objects is crucial for medical tasks that require precise targeting, such as robotic biopsies. We introduce LUDO, a method for accurate low-latency understanding of deformable objects. LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks. We demonstrate LUDO's abilities for autonomous targeting of internal regions of interest (ROIs) in highly deformable objects. Additionally, LUDO provides uncertainty estimates and explainability for its predictions, both of which are important in safety-critical applications such as surgical interventions. We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various ROIs inside highly deformable objects. LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods.","sentences":["Accurately determining the shape and location of internal structures within deformable objects is crucial for medical tasks that require precise targeting, such as robotic biopsies.","We introduce LUDO, a method for accurate low-latency understanding of deformable objects.","LUDO reconstructs objects in their deformed state, including their internal structures, from a single-view point cloud observation in under 30 ms using occupancy networks.","We demonstrate LUDO's abilities for autonomous targeting of internal regions of interest (ROIs) in highly deformable objects.","Additionally, LUDO provides uncertainty estimates and explainability for its predictions, both of which are important in safety-critical applications such as surgical interventions.","We evaluate LUDO in real-world robotic experiments, achieving a success rate of 98.9% for puncturing various ROIs inside highly deformable objects.","LUDO demonstrates the potential to interact with deformable objects without the need for deformable registration methods."],"url":"http://arxiv.org/abs/2411.08777v1"}
{"created":"2024-11-13 16:58:51","title":"Optimal Oblivious Subspace Embeddings with Near-optimal Sparsity","abstract":"An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such that, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves the norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor. In this work, we give an oblivious subspace embedding with the optimal dimension $m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde O(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result to nearly match the conjecture of Nelson and Nguyen [FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et al., STOC 2024]. We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks.   In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices. To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction.","sentences":["An oblivious subspace embedding is a random $m\\times n$ matrix $\\Pi$ such that, for any $d$-dimensional subspace, with high probability $\\Pi$ preserves the norms of all vectors in that subspace within a $1\\pm\\epsilon$ factor.","In this work, we give an oblivious subspace embedding with the optimal dimension $m=\\Theta(d/\\epsilon^2)$ that has a near-optimal sparsity of $\\tilde O(1/\\epsilon)$ non-zero entries per column of $\\Pi$. This is the first result to nearly match the conjecture of Nelson and Nguyen","[FOCS 2013] in terms of the best sparsity attainable by an optimal oblivious subspace embedding, improving on a prior bound of $\\tilde O(1/\\epsilon^6)$ non-zeros per column [Chenakkod et al., STOC 2024].","We further extend our approach to the non-oblivious setting, proposing a new family of Leverage Score Sparsified embeddings with Independent Columns, which yield faster runtimes for matrix approximation and regression tasks.   ","In our analysis, we develop a new method which uses a decoupling argument together with the cumulant method for bounding the edge universality error of isotropic random matrices.","To achieve near-optimal sparsity, we combine this general-purpose approach with new traces inequalities that leverage the specific structure of our subspace embedding construction."],"url":"http://arxiv.org/abs/2411.08773v1"}
{"created":"2024-11-13 16:55:39","title":"On Kleisli liftings and decorated trace semantics","abstract":"It is well known that Kleisli categories provide a natural language to model side effects. For instance, in the theory of coalgebras, behavioural equivalence coincides with language equivalence (instead of bisimilarity) when nondeterministic automata are modelled as coalgebras living in the Kleisli category of the powerset monad. In this paper, our aim is to establish decorated trace semantics based on language and ready equivalences for conditional transition systems (CTSs) with/without upgrades. To this end, we model CTSs as coalgebras living in the Kleisli category of a relative monad. Our results are twofold. First, we reduce the problem of defining a Kleisli lifting for the machine endofunctor in the context of a relative monad to the classical notion of Kleisli lifting. Second, we provide a recipe based on indexed categories to construct a Kleisli lifting for general endofunctors.","sentences":["It is well known that Kleisli categories provide a natural language to model side effects.","For instance, in the theory of coalgebras, behavioural equivalence coincides with language equivalence (instead of bisimilarity) when nondeterministic automata are modelled as coalgebras living in the Kleisli category of the powerset monad.","In this paper, our aim is to establish decorated trace semantics based on language and ready equivalences for conditional transition systems (CTSs) with/without upgrades.","To this end, we model CTSs as coalgebras living in the Kleisli category of a relative monad.","Our results are twofold.","First, we reduce the problem of defining a Kleisli lifting for the machine endofunctor in the context of a relative monad to the classical notion of Kleisli lifting.","Second, we provide a recipe based on indexed categories to construct a Kleisli lifting for general endofunctors."],"url":"http://arxiv.org/abs/2411.08770v1"}
{"created":"2024-11-13 16:53:29","title":"Sharingan: Extract User Action Sequence from Desktop Recordings","abstract":"Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes. However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop recordings remains an underexplored area. This paper addresses this gap by proposing two novel VLM-based methods for user action extraction: the Direct Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and the Differential Frame-Based Approach (DiffF), which incorporates explicit frame differences detected via computer vision techniques. We evaluate these methods using a basic self-curated dataset and an advanced benchmark adapted from prior work. Our results show that the DF approach achieves an accuracy of 70% to 80% in identifying user actions, with the extracted action sequences being re-playable though Robotic Process Automation. We find that while VLMs show potential, incorporating explicit UI changes can degrade performance, making the DF approach more reliable. This work represents the first application of VLMs for extracting user action sequences from desktop recordings, contributing new methods, benchmarks, and insights for future research.","sentences":["Video recordings of user activities, particularly desktop recordings, offer a rich source of data for understanding user behaviors and automating processes.","However, despite advancements in Vision-Language Models (VLMs) and their increasing use in video analysis, extracting user actions from desktop recordings remains an underexplored area.","This paper addresses this gap by proposing two novel VLM-based methods for user action extraction: the Direct Frame-Based Approach (DF), which inputs sampled frames directly into VLMs, and the Differential Frame-Based Approach (DiffF), which incorporates explicit frame differences detected via computer vision techniques.","We evaluate these methods using a basic self-curated dataset and an advanced benchmark adapted from prior work.","Our results show that the DF approach achieves an accuracy of 70% to 80% in identifying user actions, with the extracted action sequences being re-playable though Robotic Process Automation.","We find that while VLMs show potential, incorporating explicit UI changes can degrade performance, making the DF approach more reliable.","This work represents the first application of VLMs for extracting user action sequences from desktop recordings, contributing new methods, benchmarks, and insights for future research."],"url":"http://arxiv.org/abs/2411.08768v1"}
{"created":"2024-11-13 16:53:14","title":"SANDWICH: Towards an Offline, Differentiable, Fully-Trainable Wireless Neural Ray-Tracing Surrogate","abstract":"Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional (3D) wireless channel modeling, driven by advances in graphical rendering. Current approaches struggle to accurately model beyond 5G (B5G) network signaling, which often operates at higher frequencies and is more susceptible to environmental conditions and changes. Existing online learning solutions require real-time environmental supervision during training, which is both costly and incompatible with GPU-based processing. In response, we propose a novel approach that redefines ray trajectory generation as a sequential decision-making problem, leveraging generative models to jointly learn the optical, physical, and signal properties within each designated environment. Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that can be trained entirely on GPUs. SANDWICH offers superior performance compared to existing online learning methods, outperforms the baseline by 4e^-2 radian in RT accuracy, and only fades 0.5 dB away from toplined channel gain estimation.","sentences":["Wireless ray-tracing (RT) is emerging as a key tool for three-dimensional (3D) wireless channel modeling, driven by advances in graphical rendering.","Current approaches struggle to accurately model beyond 5G (B5G) network signaling, which often operates at higher frequencies and is more susceptible to environmental conditions and changes.","Existing online learning solutions require real-time environmental supervision during training, which is both costly and incompatible with GPU-based processing.","In response, we propose a novel approach that redefines ray trajectory generation as a sequential decision-making problem, leveraging generative models to jointly learn the optical, physical, and signal properties within each designated environment.","Our work introduces the Scene-Aware Neural Decision Wireless Channel Raytracing Hierarchy (SANDWICH), an innovative offline, fully differentiable approach that can be trained entirely on GPUs.","SANDWICH offers superior performance compared to existing online learning methods, outperforms the baseline by 4e^-2 radian in RT accuracy, and only fades 0.5 dB away from toplined channel gain estimation."],"url":"http://arxiv.org/abs/2411.08767v1"}
{"created":"2024-11-13 16:52:30","title":"Mapping Methane -- The Impact of Dairy Farm Practices on Emissions Through Satellite Data and Machine Learning","abstract":"This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada. Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies. Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability. Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions. Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction. The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution. This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector. It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies. Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification. Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices.","sentences":["This study investigates the correlation between dairy farm characteristics and methane concentrations as derived from satellite observations in Eastern Canada.","Utilizing data from 11 dairy farms collected between January 2020 and December 2022, we integrated Sentinel-5P satellite methane data with critical farm-level attributes, including herd genetics, feeding practices, and management strategies.","Initial analyses revealed significant correlations with methane concentrations, leading to the application of Variance Inflation Factor (VIF) and Principal Component Analysis (PCA) to address multicollinearity and enhance model stability.","Subsequently, machine learning models - specifically Random Forest and Neural Networks - were employed to evaluate feature importance and predict methane emissions.","Our findings indicate a strong negative correlation between the Estimated Breeding Value (EBV) for protein percentage and methane concentrations, suggesting that genetic selection for higher milk protein content could be an effective strategy for emissions reduction.","The integration of atmospheric transport models with satellite data further refined our emission estimates, significantly enhancing accuracy and spatial resolution.","This research underscores the potential of advanced satellite monitoring, machine learning techniques, and atmospheric modeling in improving methane emission assessments within the dairy sector.","It emphasizes the critical role of farm-specific characteristics in developing effective mitigation strategies.","Future investigations should focus on expanding the dataset and incorporating inversion modeling for more precise emission quantification.","Balancing ecological impacts with economic viability will be essential for fostering sustainable dairy farming practices."],"url":"http://arxiv.org/abs/2411.08766v1"}
{"created":"2024-11-13 16:49:56","title":"Flow reconstruction in time-varying geometries using graph neural networks","abstract":"The paper presents a Graph Attention Convolutional Network (GACN) for flow reconstruction from very sparse data in time-varying geometries. The model incorporates a feature propagation algorithm as a preprocessing step to handle extremely sparse inputs, leveraging information from neighboring nodes to initialize missing features. In addition, a binary indicator is introduced as a validity mask to distinguish between the original and propagated data points, enabling more effective learning from sparse inputs. Trained on a unique data set of Direct Numerical Simulations (DNS) of a motored engine at a technically relevant operating condition, the GACN shows robust performance across different resolutions and domain sizes and can effectively handle unstructured data and variable input sizes. The model is tested on previously unseen DNS data as well as on an experimental data set from Particle Image Velocimetry (PIV) measurements that were not considered during training. A comparative analysis shows that the GACN consistently outperforms both a conventional Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS and PIV test sets by achieving lower reconstruction errors and better capturing fine-scale turbulent structures. In particular, the GACN effectively reconstructs flow fields from domains up to 14 times larger than those observed during training, with the performance advantage increasing for larger domains.","sentences":["The paper presents a Graph Attention Convolutional Network (GACN) for flow reconstruction from very sparse data in time-varying geometries.","The model incorporates a feature propagation algorithm as a preprocessing step to handle extremely sparse inputs, leveraging information from neighboring nodes to initialize missing features.","In addition, a binary indicator is introduced as a validity mask to distinguish between the original and propagated data points, enabling more effective learning from sparse inputs.","Trained on a unique data set of Direct Numerical Simulations (DNS) of a motored engine at a technically relevant operating condition, the GACN shows robust performance across different resolutions and domain sizes and can effectively handle unstructured data and variable input sizes.","The model is tested on previously unseen DNS data as well as on an experimental data set from Particle Image Velocimetry (PIV) measurements that were not considered during training.","A comparative analysis shows that the GACN consistently outperforms both a conventional Convolutional Neural Network (CNN) and cubic interpolation methods on the DNS and PIV test sets by achieving lower reconstruction errors and better capturing fine-scale turbulent structures.","In particular, the GACN effectively reconstructs flow fields from domains up to 14 times larger than those observed during training, with the performance advantage increasing for larger domains."],"url":"http://arxiv.org/abs/2411.08764v1"}
{"created":"2024-11-13 16:42:59","title":"ScaleNet: Scale Invariance Learning in Directed Graphs","abstract":"Graph Neural Networks (GNNs) have advanced relational data analysis but lack invariance learning techniques common in image classification. In node classification with GNNs, it is actually the ego-graph of the center node that is classified. This research extends the scale invariance concept to node classification by drawing an analogy to image processing: just as scale invariance being used in image classification to capture multi-scale features, we propose the concept of ``scaled ego-graphs''. Scaled ego-graphs generalize traditional ego-graphs by replacing undirected single-edges with ``scaled-edges'', which are ordered sequences of multiple directed edges. We empirically assess the performance of the proposed scale invariance in graphs on seven benchmark datasets, across both homophilic and heterophilic structures. Our scale-invariance-based graph learning outperforms inception models derived from random walks by being simpler, faster, and more accurate. The scale invariance explains inception models' success on homophilic graphs and limitations on heterophilic graphs. To ensure applicability of inception model to heterophilic graphs as well, we further present ScaleNet, an architecture that leverages multi-scaled features. ScaleNet achieves state-of-the-art results on five out of seven datasets (four homophilic and one heterophilic) and matches top performance on the remaining two, demonstrating its excellent applicability. This represents a significant advance in graph learning, offering a unified framework that enhances node classification across various graph types. Our code is available at https://github.com/Qin87/ScaleNet/tree/July25.","sentences":["Graph Neural Networks (GNNs) have advanced relational data analysis but lack invariance learning techniques common in image classification.","In node classification with GNNs, it is actually the ego-graph of the center node that is classified.","This research extends the scale invariance concept to node classification by drawing an analogy to image processing: just as scale invariance being used in image classification to capture multi-scale features, we propose the concept of ``scaled ego-graphs''.","Scaled ego-graphs generalize traditional ego-graphs by replacing undirected single-edges with ``scaled-edges'', which are ordered sequences of multiple directed edges.","We empirically assess the performance of the proposed scale invariance in graphs on seven benchmark datasets, across both homophilic and heterophilic structures.","Our scale-invariance-based graph learning outperforms inception models derived from random walks by being simpler, faster, and more accurate.","The scale invariance explains inception models' success on homophilic graphs and limitations on heterophilic graphs.","To ensure applicability of inception model to heterophilic graphs as well, we further present ScaleNet, an architecture that leverages multi-scaled features.","ScaleNet achieves state-of-the-art results on five out of seven datasets (four homophilic and one heterophilic) and matches top performance on the remaining two, demonstrating its excellent applicability.","This represents a significant advance in graph learning, offering a unified framework that enhances node classification across various graph types.","Our code is available at https://github.com/Qin87/ScaleNet/tree/July25."],"url":"http://arxiv.org/abs/2411.08758v1"}
{"created":"2024-11-13 16:42:07","title":"Masked Image Modeling Boosting Semi-Supervised Semantic Segmentation","abstract":"In view of the fact that semi- and self-supervised learning share a fundamental principle, effectively modeling knowledge from unlabeled data, various semi-supervised semantic segmentation methods have integrated representative self-supervised learning paradigms for further regularization. However, the potential of the state-of-the-art generative self-supervised paradigm, masked image modeling, has been scarcely studied. This paradigm learns the knowledge through establishing connections between the masked and visible parts of masked image, during the pixel reconstruction process. By inheriting and extending this insight, we successfully leverage masked image modeling to boost semi-supervised semantic segmentation. Specifically, we introduce a novel class-wise masked image modeling that independently reconstructs different image regions according to their respective classes. In this way, the mask-induced connections are established within each class, mitigating the semantic confusion that arises from plainly reconstructing images in basic masked image modeling. To strengthen these intra-class connections, we further develop a feature aggregation strategy that minimizes the distances between features corresponding to the masked and visible parts within the same class. Additionally, in semantic space, we explore the application of masked image modeling to enhance regularization. Extensive experiments conducted on well-known benchmarks demonstrate that our approach achieves state-of-the-art performance. The code will be available at https://github.com/haoxt/S4MIM.","sentences":["In view of the fact that semi- and self-supervised learning share a fundamental principle, effectively modeling knowledge from unlabeled data, various semi-supervised semantic segmentation methods have integrated representative self-supervised learning paradigms for further regularization.","However, the potential of the state-of-the-art generative self-supervised paradigm, masked image modeling, has been scarcely studied.","This paradigm learns the knowledge through establishing connections between the masked and visible parts of masked image, during the pixel reconstruction process.","By inheriting and extending this insight, we successfully leverage masked image modeling to boost semi-supervised semantic segmentation.","Specifically, we introduce a novel class-wise masked image modeling that independently reconstructs different image regions according to their respective classes.","In this way, the mask-induced connections are established within each class, mitigating the semantic confusion that arises from plainly reconstructing images in basic masked image modeling.","To strengthen these intra-class connections, we further develop a feature aggregation strategy that minimizes the distances between features corresponding to the masked and visible parts within the same class.","Additionally, in semantic space, we explore the application of masked image modeling to enhance regularization.","Extensive experiments conducted on well-known benchmarks demonstrate that our approach achieves state-of-the-art performance.","The code will be available at https://github.com/haoxt/S4MIM."],"url":"http://arxiv.org/abs/2411.08756v1"}
{"created":"2024-11-13 16:33:27","title":"Weakly-Supervised Anomaly Detection in Surveillance Videos Based on Two-Stream I3D Convolution Network","abstract":"The widespread implementation of urban surveillance systems has necessitated more sophisticated techniques for anomaly detection to ensure enhanced public safety. This paper presents a significant advancement in the field of anomaly detection through the application of Two-Stream Inflated 3D (I3D) Convolutional Networks. These networks substantially outperform traditional 3D Convolutional Networks (C3D) by more effectively extracting spatial and temporal features from surveillance videos, thus improving the precision of anomaly detection. Our research advances the field by implementing a weakly supervised learning framework based on Multiple Instance Learning (MIL), which uniquely conceptualizes surveillance videos as collections of 'bags' that contain instances (video clips). Each instance is innovatively processed through a ranking mechanism that prioritizes clips based on their potential to display anomalies. This novel strategy not only enhances the accuracy and precision of anomaly detection but also significantly diminishes the dependency on extensive manual annotations. Moreover, through meticulous optimization of model settings, including the choice of optimizer, our approach not only establishes new benchmarks in the performance of anomaly detection systems but also offers a scalable and efficient solution for real-world surveillance applications. This paper contributes significantly to the field of computer vision by delivering a more adaptable, efficient, and context-aware anomaly detection system, which is poised to redefine practices in urban surveillance.","sentences":["The widespread implementation of urban surveillance systems has necessitated more sophisticated techniques for anomaly detection to ensure enhanced public safety.","This paper presents a significant advancement in the field of anomaly detection through the application of Two-Stream Inflated 3D (I3D) Convolutional Networks.","These networks substantially outperform traditional 3D Convolutional Networks (C3D) by more effectively extracting spatial and temporal features from surveillance videos, thus improving the precision of anomaly detection.","Our research advances the field by implementing a weakly supervised learning framework based on Multiple Instance Learning (MIL), which uniquely conceptualizes surveillance videos as collections of 'bags' that contain instances (video clips).","Each instance is innovatively processed through a ranking mechanism that prioritizes clips based on their potential to display anomalies.","This novel strategy not only enhances the accuracy and precision of anomaly detection but also significantly diminishes the dependency on extensive manual annotations.","Moreover, through meticulous optimization of model settings, including the choice of optimizer, our approach not only establishes new benchmarks in the performance of anomaly detection systems but also offers a scalable and efficient solution for real-world surveillance applications.","This paper contributes significantly to the field of computer vision by delivering a more adaptable, efficient, and context-aware anomaly detection system, which is poised to redefine practices in urban surveillance."],"url":"http://arxiv.org/abs/2411.08755v1"}
{"created":"2024-11-13 16:31:08","title":"Which Viewpoint Shows it Best? Language for Weakly Supervising View Selection in Multi-view Videos","abstract":"Given a multi-view video, which viewpoint is most informative for a human observer? Existing methods rely on heuristics or expensive ``best-view\" supervision to answer this question, limiting their applicability. We propose a weakly supervised approach that leverages language accompanying an instructional multi-view video as a means to recover its most informative viewpoint(s). Our key hypothesis is that the more accurately an individual view can predict a view-agnostic text summary, the more informative it is. To put this into action, we propose a framework that uses the relative accuracy of view-dependent caption predictions as a proxy for best view pseudo-labels. Then, those pseudo-labels are used to train a view selector, together with an auxiliary camera pose predictor that enhances view-sensitivity. During inference, our model takes as input only a multi-view video -- no language or camera poses -- and returns the best viewpoint to watch at each timestep. On two challenging datasets comprised of diverse multi-camera setups and how-to activities, our model consistently outperforms state-of-the-art baselines, both with quantitative metrics and human evaluation.","sentences":["Given a multi-view video, which viewpoint is most informative for a human observer?","Existing methods rely on heuristics or expensive ``best-view\" supervision to answer this question, limiting their applicability.","We propose a weakly supervised approach that leverages language accompanying an instructional multi-view video as a means to recover its most informative viewpoint(s).","Our key hypothesis is that the more accurately an individual view can predict a view-agnostic text summary, the more informative it is.","To put this into action, we propose a framework that uses the relative accuracy of view-dependent caption predictions as a proxy for best view pseudo-labels.","Then, those pseudo-labels are used to train a view selector, together with an auxiliary camera pose predictor that enhances view-sensitivity.","During inference, our model takes as input only a multi-view video -- no language or camera poses -- and returns the best viewpoint to watch at each timestep.","On two challenging datasets comprised of diverse multi-camera setups and how-to activities, our model consistently outperforms state-of-the-art baselines, both with quantitative metrics and human evaluation."],"url":"http://arxiv.org/abs/2411.08753v1"}
{"created":"2024-11-13 16:30:41","title":"Multi-Perspective Stance Detection","abstract":"Subjective NLP tasks usually rely on human annotations provided by multiple annotators, whose judgments may vary due to their diverse backgrounds and life experiences. Traditional methods often aggregate multiple annotations into a single ground truth, disregarding the diversity in perspectives that arises from annotator disagreement. In this preliminary study, we examine the effect of including multiple annotations on model accuracy in classification. Our methodology investigates the performance of perspective-aware classification models in stance detection task and further inspects if annotator disagreement affects the model confidence. The results show that multi-perspective approach yields better classification performance outperforming the baseline which uses the single label. This entails that designing more inclusive perspective-aware AI models is not only an essential first step in implementing responsible and ethical AI, but it can also achieve superior results than using the traditional approaches.","sentences":["Subjective NLP tasks usually rely on human annotations provided by multiple annotators, whose judgments may vary due to their diverse backgrounds and life experiences.","Traditional methods often aggregate multiple annotations into a single ground truth, disregarding the diversity in perspectives that arises from annotator disagreement.","In this preliminary study, we examine the effect of including multiple annotations on model accuracy in classification.","Our methodology investigates the performance of perspective-aware classification models in stance detection task and further inspects if annotator disagreement affects the model confidence.","The results show that multi-perspective approach yields better classification performance outperforming the baseline which uses the single label.","This entails that designing more inclusive perspective-aware AI models is not only an essential first step in implementing responsible and ethical AI, but it can also achieve superior results than using the traditional approaches."],"url":"http://arxiv.org/abs/2411.08752v1"}
{"created":"2024-11-13 16:26:19","title":"Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers","abstract":"A central question in multilingual language modeling is whether large language models (LLMs) develop a universal concept representation, disentangled from specific languages. In this paper, we address this question by analyzing latent representations (latents) during a word translation task in transformer-based LLMs. We strategically extract latents from a source translation prompt and insert them into the forward pass on a target translation prompt. By doing so, we find that the output language is encoded in the latent at an earlier layer than the concept to be translated. Building on this insight, we conduct two key experiments. First, we demonstrate that we can change the concept without changing the language and vice versa through activation patching alone. Second, we show that patching with the mean over latents across different languages does not impair and instead improves the models' performance in translating the concept. Our results provide evidence for the existence of language-agnostic concept representations within the investigated models.","sentences":["A central question in multilingual language modeling is whether large language models (LLMs) develop a universal concept representation, disentangled from specific languages.","In this paper, we address this question by analyzing latent representations (latents) during a word translation task in transformer-based LLMs.","We strategically extract latents from a source translation prompt and insert them into the forward pass on a target translation prompt.","By doing so, we find that the output language is encoded in the latent at an earlier layer than the concept to be translated.","Building on this insight, we conduct two key experiments.","First, we demonstrate that we can change the concept without changing the language and vice versa through activation patching alone.","Second, we show that patching with the mean over latents across different languages does not impair and instead improves the models' performance in translating the concept.","Our results provide evidence for the existence of language-agnostic concept representations within the investigated models."],"url":"http://arxiv.org/abs/2411.08745v1"}
{"created":"2024-11-13 16:20:20","title":"A Comparative Study of Discrete Speech Tokens for Semantic-Related Tasks with Large Language Models","abstract":"With the rise of Speech Large Language Models (Speech LLMs), there has been growing interest in discrete speech tokens for their ability to integrate with text-based tokens seamlessly. Compared to most studies that focus on continuous speech features, although discrete-token based LLMs have shown promising results on certain tasks, the performance gap between these two paradigms is rarely explored. In this paper, we present a fair and thorough comparison between discrete and continuous features across a variety of semantic-related tasks using a light-weight LLM (Qwen1.5-0.5B). Our findings reveal that continuous features generally outperform discrete tokens, particularly in tasks requiring fine-grained semantic understanding. Moreover, this study goes beyond surface-level comparison by identifying key factors behind the under-performance of discrete tokens, such as limited token granularity and inefficient information retention. To enhance the performance of discrete tokens, we explore potential aspects based on our analysis. We hope our results can offer new insights into the opportunities for advancing discrete speech tokens in Speech LLMs.","sentences":["With the rise of Speech Large Language Models (Speech LLMs), there has been growing interest in discrete speech tokens for their ability to integrate with text-based tokens seamlessly.","Compared to most studies that focus on continuous speech features, although discrete-token based LLMs have shown promising results on certain tasks, the performance gap between these two paradigms is rarely explored.","In this paper, we present a fair and thorough comparison between discrete and continuous features across a variety of semantic-related tasks using a light-weight LLM (Qwen1.5-0.5B).","Our findings reveal that continuous features generally outperform discrete tokens, particularly in tasks requiring fine-grained semantic understanding.","Moreover, this study goes beyond surface-level comparison by identifying key factors behind the under-performance of discrete tokens, such as limited token granularity and inefficient information retention.","To enhance the performance of discrete tokens, we explore potential aspects based on our analysis.","We hope our results can offer new insights into the opportunities for advancing discrete speech tokens in Speech LLMs."],"url":"http://arxiv.org/abs/2411.08742v1"}
{"created":"2024-11-13 16:18:57","title":"Bayesian Comparisons Between Representations","abstract":"Which neural networks are similar is a fundamental question for both machine learning and neuroscience. Our novel method compares representations based on Bayesian statistics about linear readouts from the representations. Concretely, we suggest to use the total variation distance or Jensen-Shannon distance between prior predictive distributions to compare representations. The prior predictive distribution is a full description of the inductive bias and generalization of a model in Bayesian statistics, making it a great basis for comparisons. As Jensen-Shannon distance and total variation distance are metrics our dissimilarity measures are pseudo-metrics for representations. For a linear readout, our metrics just depend on the linear kernel matrix of the representations. Thus, our metrics connects linear read-out based comparisons to kernel based metrics like centered kernel alignment and representational similarity analysis. We apply our new metrics to deep neural networks trained on ImageNet-1k. Our new metrics can be computed efficiently including a stochastic gradient without dimensionality reductions of the representations. It broadly agrees with existing metrics, but is more stringent. It varies less across different random image samples, and it measures how well two representations could be distinguished based on a linear read out. Thus our metric nicely extends our toolkit for comparing representations.","sentences":["Which neural networks are similar is a fundamental question for both machine learning and neuroscience.","Our novel method compares representations based on Bayesian statistics about linear readouts from the representations.","Concretely, we suggest to use the total variation distance or Jensen-Shannon distance between prior predictive distributions to compare representations.","The prior predictive distribution is a full description of the inductive bias and generalization of a model in Bayesian statistics, making it a great basis for comparisons.","As Jensen-Shannon distance and total variation distance are metrics our dissimilarity measures are pseudo-metrics for representations.","For a linear readout, our metrics just depend on the linear kernel matrix of the representations.","Thus, our metrics connects linear read-out based comparisons to kernel based metrics like centered kernel alignment and representational similarity analysis.","We apply our new metrics to deep neural networks trained on ImageNet-1k.","Our new metrics can be computed efficiently including a stochastic gradient without dimensionality reductions of the representations.","It broadly agrees with existing metrics, but is more stringent.","It varies less across different random image samples, and it measures how well two representations could be distinguished based on a linear read out.","Thus our metric nicely extends our toolkit for comparing representations."],"url":"http://arxiv.org/abs/2411.08739v1"}
{"created":"2024-11-13 16:17:16","title":"New advances in universal approximation with neural networks of minimal width","abstract":"Deep neural networks have achieved remarkable success in diverse applications, prompting the need for a solid theoretical foundation. Recent research has identified the minimal width $\\max\\{2,d_x,d_y\\}$ required for neural networks with input dimensions $d_x$ and output dimension $d_y$ that use leaky ReLU activations to universally approximate $L^p(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta. Here, we present an alternative proof for the minimal width of such neural networks, by directly constructing approximating networks using a coding scheme that leverages the properties of leaky ReLUs and standard $L^p$ results. The obtained construction has a minimal interior dimension of $1$, independent of input and output dimensions, which allows us to show that autoencoders with leaky ReLU activations are universal approximators of $L^p$ functions. Furthermore, we demonstrate that the normalizing flow LU-Net serves as a distributional universal approximator. We broaden our results to show that smooth invertible neural networks can approximate $L^p(\\mathbb{R}^{d},\\mathbb{R}^{d})$ on compacta when the dimension $d\\geq 2$, which provides a constructive proof of a classical theorem of Brenier and Gangbo. In addition, we use a topological argument to establish that for FNNs with monotone Lipschitz continuous activations, $d_x+1$ is a lower bound on the minimal width required for the uniform universal approximation of continuous functions $C^0(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta when $d_x\\geq d_y$.","sentences":["Deep neural networks have achieved remarkable success in diverse applications, prompting the need for a solid theoretical foundation.","Recent research has identified the minimal width $\\max\\{2,d_x,d_y\\}$ required for neural networks with input dimensions $d_x$ and output dimension $d_y$ that use leaky ReLU activations to universally approximate $L^p(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta.","Here, we present an alternative proof for the minimal width of such neural networks, by directly constructing approximating networks using a coding scheme that leverages the properties of leaky ReLUs and standard $L^p$ results.","The obtained construction has a minimal interior dimension of $1$, independent of input and output dimensions, which allows us to show that autoencoders with leaky ReLU activations are universal approximators of $L^p$ functions.","Furthermore, we demonstrate that the normalizing flow LU-Net serves as a distributional universal approximator.","We broaden our results to show that smooth invertible neural networks can approximate $L^p(\\mathbb{R}^{d},\\mathbb{R}^{d})$ on compacta when the dimension $d\\geq 2$, which provides a constructive proof of a classical theorem of Brenier and Gangbo.","In addition, we use a topological argument to establish that for FNNs with monotone Lipschitz continuous activations, $d_x+1$ is a lower bound on the minimal width required for the uniform universal approximation of continuous functions $C^0(\\mathbb{R}^{d_x},\\mathbb{R}^{d_y})$ on compacta when $d_x\\geq d_y$."],"url":"http://arxiv.org/abs/2411.08735v1"}
{"created":"2024-11-13 16:15:38","title":"Dynamic Rewarding with Prompt Optimization Enables Tuning-free Self-Alignment of Language Models","abstract":"Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations. Self-alignment seeks to reduce these expenses by enabling models to align themselves. To further lower costs and achieve alignment without any expensive tuning or annotations, we introduce a new tuning-free approach for self-alignment, Dynamic Rewarding with Prompt Optimization (\\ours). Our approach leverages a search-based optimization framework that allows LLMs to iteratively self-improve and craft the optimal alignment instructions, all without additional training or human intervention. The core of \\ours is a dynamic rewarding mechanism, which identifies and rectifies model-specific alignment weaknesses, allowing LLMs to adapt efficiently to diverse alignment challenges. Empirical evaluations on eight recent LLMs, both open- and closed-sourced, demonstrate that \\ours significantly enhances alignment performance, with base models outperforming their SFT/RLHF-tuned counterparts. Moreover, the prompts automatically optimized by \\ours surpass those curated by human experts, further validating the effectiveness of our approach. Our findings highlight the great potential of current LLMs to achieve adaptive self-alignment through inference-time optimization, complementing tuning-based alignment methods.","sentences":["Aligning Large Language Models (LLMs) traditionally relies on costly training and human preference annotations.","Self-alignment seeks to reduce these expenses by enabling models to align themselves.","To further lower costs and achieve alignment without any expensive tuning or annotations, we introduce a new tuning-free approach for self-alignment, Dynamic Rewarding with Prompt Optimization (\\ours).","Our approach leverages a search-based optimization framework that allows LLMs to iteratively self-improve and craft the optimal alignment instructions, all without additional training or human intervention.","The core of \\ours is a dynamic rewarding mechanism, which identifies and rectifies model-specific alignment weaknesses, allowing LLMs to adapt efficiently to diverse alignment challenges.","Empirical evaluations on eight recent LLMs, both open- and closed-sourced, demonstrate that \\ours significantly enhances alignment performance, with base models outperforming their SFT/RLHF-tuned counterparts.","Moreover, the prompts automatically optimized by \\ours surpass those curated by human experts, further validating the effectiveness of our approach.","Our findings highlight the great potential of current LLMs to achieve adaptive self-alignment through inference-time optimization, complementing tuning-based alignment methods."],"url":"http://arxiv.org/abs/2411.08733v1"}
{"created":"2024-11-13 16:14:13","title":"3D Modelling to Address Pandemic Challenges: A Project-Based Learning Methodology","abstract":"The use of 3D modelling in medical education is a revolutionary tool during the learning process. In fact, this type of technology enables a more interactive teaching approach, making information retention more effective and enhancing students' understanding. 3D modelling allows for the creation of precise representations of the human body, as well as interaction with three-dimensional models, giving students a better spatial understanding of the different organs and systems and enabling simulations of surgical and technical procedures. This way, medical education is enriched with a more realistic and safe educational experience. The goal is to understand whether, when students and schools are challenged, they play an important role in addressing health issues in their community. School-led projects are directed towards educational scenarios that emphasize STEM education, tackling relevant public health problems through open-school initiatives. By implementing an educational scenario focused on 3D modelling and leveraging technology, we aim to raise community awareness on public health issues.","sentences":["The use of 3D modelling in medical education is a revolutionary tool during the learning process.","In fact, this type of technology enables a more interactive teaching approach, making information retention more effective and enhancing students' understanding.","3D modelling allows for the creation of precise representations of the human body, as well as interaction with three-dimensional models, giving students a better spatial understanding of the different organs and systems and enabling simulations of surgical and technical procedures.","This way, medical education is enriched with a more realistic and safe educational experience.","The goal is to understand whether, when students and schools are challenged, they play an important role in addressing health issues in their community.","School-led projects are directed towards educational scenarios that emphasize STEM education, tackling relevant public health problems through open-school initiatives.","By implementing an educational scenario focused on 3D modelling and leveraging technology, we aim to raise community awareness on public health issues."],"url":"http://arxiv.org/abs/2411.08730v1"}
{"created":"2024-11-13 16:10:14","title":"Polymetis:Large Language Modeling for Multiple Material Domains","abstract":"As the application of large language models in various fields continues to expand, materials science also ushers in opportunities for AI-driven innovation. The traditional way of relying on manual search for materials science-related information is now using artificial intelligence technology as an auxiliary tool to improve the efficiency of materials science research. To accelerate researchers' knowledge acquisition and intelligent decision-making support in materials science research, this paper proposes a large language model Polymetis model for a variety of materials fields, aiming to provide highly professional knowledge answers in the field of materials, covering energy materials, functional materials, alloy materials, physical chemistry, biology, and other material directions. The model uses a dataset of about 2 million material knowledge instructions, and in the process of building the dataset, we developed the Intelligent Extraction Large Model (IELM), which is specially used to extract and form structured knowledge from scientific texts, avoiding a large number of costs that need to be manually annotated, and improving efficiency. We inject this data into the GLM4-9B model for learning to enhance its inference capabilities in a variety of material domains. In addition, we have introduced enhanced prompt strategies to ensure that the answers to the model are more organized and comprehensive, providing efficient and comprehensive intelligent support for the diverse needs of materials science exploration, and promoting the development of material science.","sentences":["As the application of large language models in various fields continues to expand, materials science also ushers in opportunities for AI-driven innovation.","The traditional way of relying on manual search for materials science-related information is now using artificial intelligence technology as an auxiliary tool to improve the efficiency of materials science research.","To accelerate researchers' knowledge acquisition and intelligent decision-making support in materials science research, this paper proposes a large language model Polymetis model for a variety of materials fields, aiming to provide highly professional knowledge answers in the field of materials, covering energy materials, functional materials, alloy materials, physical chemistry, biology, and other material directions.","The model uses a dataset of about 2 million material knowledge instructions, and in the process of building the dataset, we developed the Intelligent Extraction Large Model (IELM), which is specially used to extract and form structured knowledge from scientific texts, avoiding a large number of costs that need to be manually annotated, and improving efficiency.","We inject this data into the GLM4-9B model for learning to enhance its inference capabilities in a variety of material domains.","In addition, we have introduced enhanced prompt strategies to ensure that the answers to the model are more organized and comprehensive, providing efficient and comprehensive intelligent support for the diverse needs of materials science exploration, and promoting the development of material science."],"url":"http://arxiv.org/abs/2411.08728v1"}
{"created":"2024-11-13 16:09:04","title":"Voxeland: Probabilistic Instance-Aware Semantic Mapping with Evidence-based Uncertainty Quantification","abstract":"Robots in human-centered environments require accurate scene understanding to perform high-level tasks effectively. This understanding can be achieved through instance-aware semantic mapping, which involves reconstructing elements at the level of individual instances. Neural networks, the de facto solution for scene understanding, still face limitations such as overconfident incorrect predictions with out-of-distribution objects or generating inaccurate masks.Placing excessive reliance on these predictions makes the reconstruction susceptible to errors, reducing the robustness of the resulting maps and hampering robot operation. In this work, we propose Voxeland, a probabilistic framework for incrementally building instance-aware semantic maps. Inspired by the Theory of Evidence, Voxeland treats neural network predictions as subjective opinions regarding map instances at both geometric and semantic levels. These opinions are aggregated over time to form evidences, which are formalized through a probabilistic model. This enables us to quantify uncertainty in the reconstruction process, facilitating the identification of map areas requiring improvement (e.g. reobservation or reclassification). As one strategy to exploit this, we incorporate a Large Vision-Language Model (LVLM) to perform semantic level disambiguation for instances with high uncertainty. Results from the standard benchmarking on the publicly available SceneNN dataset demonstrate that Voxeland outperforms state-of-the-art methods, highlighting the benefits of incorporating and leveraging both instance- and semantic-level uncertainties to enhance reconstruction robustness. This is further validated through qualitative experiments conducted on the real-world ScanNet dataset.","sentences":["Robots in human-centered environments require accurate scene understanding to perform high-level tasks effectively.","This understanding can be achieved through instance-aware semantic mapping, which involves reconstructing elements at the level of individual instances.","Neural networks, the de facto solution for scene understanding, still face limitations such as overconfident incorrect predictions with out-of-distribution objects or generating inaccurate masks.","Placing excessive reliance on these predictions makes the reconstruction susceptible to errors, reducing the robustness of the resulting maps and hampering robot operation.","In this work, we propose Voxeland, a probabilistic framework for incrementally building instance-aware semantic maps.","Inspired by the Theory of Evidence, Voxeland treats neural network predictions as subjective opinions regarding map instances at both geometric and semantic levels.","These opinions are aggregated over time to form evidences, which are formalized through a probabilistic model.","This enables us to quantify uncertainty in the reconstruction process, facilitating the identification of map areas requiring improvement (e.g. reobservation or reclassification).","As one strategy to exploit this, we incorporate a Large Vision-Language Model (LVLM) to perform semantic level disambiguation for instances with high uncertainty.","Results from the standard benchmarking on the publicly available SceneNN dataset demonstrate that Voxeland outperforms state-of-the-art methods, highlighting the benefits of incorporating and leveraging both instance- and semantic-level uncertainties to enhance reconstruction robustness.","This is further validated through qualitative experiments conducted on the real-world ScanNet dataset."],"url":"http://arxiv.org/abs/2411.08727v1"}
{"created":"2024-11-13 16:08:40","title":"Analyst Reports and Stock Performance: Evidence from the Chinese Market","abstract":"This article applies natural language processing (NLP) to extract and quantify textual information to predict stock performance. Using an extensive dataset of Chinese analyst reports and employing a customized BERT deep learning model for Chinese text, this study categorizes the sentiment of the reports as positive, neutral, or negative. The findings underscore the predictive capacity of this sentiment indicator for stock volatility, excess returns, and trading volume. Specifically, analyst reports with strong positive sentiment will increase excess return and intraday volatility, and vice versa, reports with strong negative sentiment also increase volatility and trading volume, but decrease future excess return. The magnitude of this effect is greater for positive sentiment reports than for negative sentiment reports. This article contributes to the empirical literature on sentiment analysis and the response of the stock market to news in the Chinese stock market.","sentences":["This article applies natural language processing (NLP) to extract and quantify textual information to predict stock performance.","Using an extensive dataset of Chinese analyst reports and employing a customized BERT deep learning model for Chinese text, this study categorizes the sentiment of the reports as positive, neutral, or negative.","The findings underscore the predictive capacity of this sentiment indicator for stock volatility, excess returns, and trading volume.","Specifically, analyst reports with strong positive sentiment will increase excess return and intraday volatility, and vice versa, reports with strong negative sentiment also increase volatility and trading volume, but decrease future excess return.","The magnitude of this effect is greater for positive sentiment reports than for negative sentiment reports.","This article contributes to the empirical literature on sentiment analysis and the response of the stock market to news in the Chinese stock market."],"url":"http://arxiv.org/abs/2411.08726v1"}
{"created":"2024-11-13 15:59:15","title":"Short note on the mapping of heritage sites impacted by the 2024 floods in Valencia, Spain","abstract":"This short note presents preliminary findings on the impact of the October 2024 floods on cultural heritage sites in Valencia, Spain. Using publicly available data, we assess the extent of potential damage by overlaying flood maps with heritage site coordinates. We identify that 3.3\\% of heritage sites in the region have been potentially impacted, with churches and shrines (81), outdoor religious iconography (78), and historic irrigation features (45) being the most heavily affected. Our analysis utilizes data from OpenStreetMap and listings from the Generalitat Valenciana, suggesting that while OpenStreetMap's crowd-sourced data can provide useful estimates of the proportion of impacted sites, it may not be suitable for a detailed damage assessment. By sharing this data openly, we aim to contribute to international efforts in preserving cultural heritage after the disaster and provide a foundation for future assessments of heritage site vulnerability to climate-related events.","sentences":["This short note presents preliminary findings on the impact of the October 2024 floods on cultural heritage sites in Valencia, Spain.","Using publicly available data, we assess the extent of potential damage by overlaying flood maps with heritage site coordinates.","We identify that 3.3\\% of heritage sites in the region have been potentially impacted, with churches and shrines (81), outdoor religious iconography (78), and historic irrigation features (45) being the most heavily affected.","Our analysis utilizes data from OpenStreetMap and listings from the Generalitat Valenciana, suggesting that while OpenStreetMap's crowd-sourced data can provide useful estimates of the proportion of impacted sites, it may not be suitable for a detailed damage assessment.","By sharing this data openly, we aim to contribute to international efforts in preserving cultural heritage after the disaster and provide a foundation for future assessments of heritage site vulnerability to climate-related events."],"url":"http://arxiv.org/abs/2411.08717v1"}
{"created":"2024-11-13 15:58:50","title":"Retrieval Augmented Recipe Generation","abstract":"Given the potential applications of generating recipes from food images, this area has garnered significant attention from researchers in recent years. Existing works for recipe generation primarily utilize a two-stage training method, first generating ingredients and then obtaining instructions from both the image and ingredients. Large Multi-modal Models (LMMs), which have achieved notable success across a variety of vision and language tasks, shed light to generating both ingredients and instructions directly from images. Nevertheless, LMMs still face the common issue of hallucinations during recipe generation, leading to suboptimal performance. To tackle this, we propose a retrieval augmented large multimodal model for recipe generation. We first introduce Stochastic Diversified Retrieval Augmentation (SDRA) to retrieve recipes semantically related to the image from an existing datastore as a supplement, integrating them into the prompt to add diverse and rich context to the input image. Additionally, Self-Consistency Ensemble Voting mechanism is proposed to determine the most confident prediction recipes as the final output. It calculates the consistency among generated recipe candidates, which use different retrieval recipes as context for generation. Extensive experiments validate the effectiveness of our proposed method, which demonstrates state-of-the-art (SOTA) performance in recipe generation tasks on the Recipe1M dataset.","sentences":["Given the potential applications of generating recipes from food images, this area has garnered significant attention from researchers in recent years.","Existing works for recipe generation primarily utilize a two-stage training method, first generating ingredients and then obtaining instructions from both the image and ingredients.","Large Multi-modal Models (LMMs), which have achieved notable success across a variety of vision and language tasks, shed light to generating both ingredients and instructions directly from images.","Nevertheless, LMMs still face the common issue of hallucinations during recipe generation, leading to suboptimal performance.","To tackle this, we propose a retrieval augmented large multimodal model for recipe generation.","We first introduce Stochastic Diversified Retrieval Augmentation (SDRA) to retrieve recipes semantically related to the image from an existing datastore as a supplement, integrating them into the prompt to add diverse and rich context to the input image.","Additionally, Self-Consistency Ensemble Voting mechanism is proposed to determine the most confident prediction recipes as the final output.","It calculates the consistency among generated recipe candidates, which use different retrieval recipes as context for generation.","Extensive experiments validate the effectiveness of our proposed method, which demonstrates state-of-the-art (SOTA) performance in recipe generation tasks on the Recipe1M dataset."],"url":"http://arxiv.org/abs/2411.08715v1"}
{"created":"2024-11-13 15:55:05","title":"High-resolution optical and acoustic remote sensing datasets of the Puck Lagoon, Southern Baltic","abstract":"The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on the Northern coast of Poland, hosts valuable benthic habitats and cultural heritage sites. These include, among others, protected Zostera marina meadows, one of the Baltic's major medieval harbours, a ship graveyard, and likely other submerged features that are yet to be discovered. Prior to this project, no comprehensive high-resolution remote sensing data were available for this area. This article describes the first Digital Elevation Models (DEMs) derived from a combination of airborne bathymetric LiDAR, multibeam echosounder, airborne photogrammetry and satellite imagery. These datasets also include multibeam echosounder backscatter and LiDAR intensity, allowing determination of the character and properties of the seafloor. Combined, these datasets are a vital resource for assessing and understanding seafloor morphology, benthic habitats, cultural heritage, and submerged landscapes. Given the significance of Puck Lagoon's hydrographical, ecological, geological, and archaeological environs, the high-resolution bathymetry, acquired by our project, can provide the foundation for sustainable management and informed decision-making for this area of interest.","sentences":["The very shallow marine basin of Puck Lagoon in the southern Baltic Sea, on the Northern coast of Poland, hosts valuable benthic habitats and cultural heritage sites.","These include, among others, protected Zostera marina meadows, one of the Baltic's major medieval harbours, a ship graveyard, and likely other submerged features that are yet to be discovered.","Prior to this project, no comprehensive high-resolution remote sensing data were available for this area.","This article describes the first Digital Elevation Models (DEMs) derived from a combination of airborne bathymetric LiDAR, multibeam echosounder, airborne photogrammetry and satellite imagery.","These datasets also include multibeam echosounder backscatter and LiDAR intensity, allowing determination of the character and properties of the seafloor.","Combined, these datasets are a vital resource for assessing and understanding seafloor morphology, benthic habitats, cultural heritage, and submerged landscapes.","Given the significance of Puck Lagoon's hydrographical, ecological, geological, and archaeological environs, the high-resolution bathymetry, acquired by our project, can provide the foundation for sustainable management and informed decision-making for this area of interest."],"url":"http://arxiv.org/abs/2411.08712v1"}
{"created":"2024-11-13 15:50:38","title":"Are Triggers Needed for Document-Level Event Extraction?","abstract":"Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest. Event arguments are then extracted with respect to the trigger. Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction. In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction. We analyze their usefulness in multiple end-to-end and pipelined neural event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random). Our research shows that trigger effectiveness varies based on the extraction task's characteristics and data quality, with basic, automatically-generated triggers serving as a viable alternative to human-annotated ones. Furthermore, providing detailed event descriptions to the extraction model helps maintain robust performance even when trigger quality degrades. Perhaps surprisingly, we also find that the mere existence of trigger input, even random ones, is important for prompt-based LLM approaches to the task.","sentences":["Most existing work on event extraction has focused on sentence-level texts and presumes the identification of a trigger-span -- a word or phrase in the input that evokes the occurrence of an event of interest.","Event arguments are then extracted with respect to the trigger.","Indeed, triggers are treated as integral to, and trigger detection as an essential component of, event extraction.","In this paper, we provide the first investigation of the role of triggers for the more difficult and much less studied task of document-level event extraction.","We analyze their usefulness in multiple end-to-end and pipelined neural event extraction models for three document-level event extraction datasets, measuring performance using triggers of varying quality (human-annotated, LLM-generated, keyword-based, and random).","Our research shows that trigger effectiveness varies based on the extraction task's characteristics and data quality, with basic, automatically-generated triggers serving as a viable alternative to human-annotated ones.","Furthermore, providing detailed event descriptions to the extraction model helps maintain robust performance even when trigger quality degrades.","Perhaps surprisingly, we also find that the mere existence of trigger input, even random ones, is important for prompt-based LLM approaches to the task."],"url":"http://arxiv.org/abs/2411.08708v1"}
{"created":"2024-11-13 15:50:32","title":"Searching Latent Program Spaces","abstract":"Program synthesis methods aim to automatically generate programs restricted to a language that can explain a given specification of input-output pairs. While purely symbolic approaches suffer from a combinatorial search space, recent methods leverage neural networks to learn distributions over program structures to narrow this search space significantly, enabling more efficient search. However, for challenging problems, it remains difficult to train models to perform program synthesis in one shot, making test-time search essential. Most neural methods lack structured search mechanisms during inference, relying instead on stochastic sampling or gradient updates, which can be inefficient. In this work, we propose the Latent Program Network (LPN), a general algorithm for program induction that learns a distribution over latent programs in a continuous space, enabling efficient search and test-time adaptation. We explore how to train these networks to optimize for test-time computation and demonstrate the use of gradient-based search both during training and at test time. We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates performance by generalizing programs to new inputs rather than explaining the underlying specification. We show that LPN can generalize beyond its training distribution and adapt to unseen tasks by utilizing test-time computation, outperforming algorithms without test-time adaptation mechanisms.","sentences":["Program synthesis methods aim to automatically generate programs restricted to a language that can explain a given specification of input-output pairs.","While purely symbolic approaches suffer from a combinatorial search space, recent methods leverage neural networks to learn distributions over program structures to narrow this search space significantly, enabling more efficient search.","However, for challenging problems, it remains difficult to train models to perform program synthesis in one shot, making test-time search essential.","Most neural methods lack structured search mechanisms during inference, relying instead on stochastic sampling or gradient updates, which can be inefficient.","In this work, we propose the Latent Program Network (LPN), a general algorithm for program induction that learns a distribution over latent programs in a continuous space, enabling efficient search and test-time adaptation.","We explore how to train these networks to optimize for test-time computation and demonstrate the use of gradient-based search both during training and at test time.","We evaluate LPN on ARC-AGI, a program synthesis benchmark that evaluates performance by generalizing programs to new inputs rather than explaining the underlying specification.","We show that LPN can generalize beyond its training distribution and adapt to unseen tasks by utilizing test-time computation, outperforming algorithms without test-time adaptation mechanisms."],"url":"http://arxiv.org/abs/2411.08706v1"}
{"created":"2024-11-13 15:45:46","title":"MVKTrans: Multi-View Knowledge Transfer for Robust Multiomics Classification","abstract":"The distinct characteristics of multiomics data, including complex interactions within and across biological layers and disease heterogeneity (e.g., heterogeneity in etiology and clinical symptoms), drive us to develop novel designs to address unique challenges in multiomics prediction. In this paper, we propose the multi-view knowledge transfer learning (MVKTrans) framework, which transfers intra- and inter-omics knowledge in an adaptive manner by reviewing data heterogeneity and suppressing bias transfer, thereby enhancing classification performance. Specifically, we design a graph contrastive module that is trained on unlabeled data to effectively learn and transfer the underlying intra-omics patterns to the supervised task. This unsupervised pretraining promotes learning general and unbiased representations for each modality, regardless of the downstream tasks. In light of the varying discriminative capacities of modalities across different diseases and/or samples, we introduce an adaptive and bi-directional cross-omics distillation module. This module automatically identifies richer modalities and facilitates dynamic knowledge transfer from more informative to less informative omics, thereby enabling a more robust and generalized integration. Extensive experiments on four real biomedical datasets demonstrate the superior performance and robustness of MVKTrans compared to the state-of-the-art. Code and data are available at https://github.com/Yaolab-fantastic/MVKTrans.","sentences":["The distinct characteristics of multiomics data, including complex interactions within and across biological layers and disease heterogeneity (e.g., heterogeneity in etiology and clinical symptoms), drive us to develop novel designs to address unique challenges in multiomics prediction.","In this paper, we propose the multi-view knowledge transfer learning (MVKTrans) framework, which transfers intra- and inter-omics knowledge in an adaptive manner by reviewing data heterogeneity and suppressing bias transfer, thereby enhancing classification performance.","Specifically, we design a graph contrastive module that is trained on unlabeled data to effectively learn and transfer the underlying intra-omics patterns to the supervised task.","This unsupervised pretraining promotes learning general and unbiased representations for each modality, regardless of the downstream tasks.","In light of the varying discriminative capacities of modalities across different diseases and/or samples, we introduce an adaptive and bi-directional cross-omics distillation module.","This module automatically identifies richer modalities and facilitates dynamic knowledge transfer from more informative to less informative omics, thereby enabling a more robust and generalized integration.","Extensive experiments on four real biomedical datasets demonstrate the superior performance and robustness of MVKTrans compared to the state-of-the-art.","Code and data are available at https://github.com/Yaolab-fantastic/MVKTrans."],"url":"http://arxiv.org/abs/2411.08703v1"}
{"created":"2024-11-13 15:42:28","title":"TRACE: Transformer-based Risk Assessment for Clinical Evaluation","abstract":"We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation. Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes. The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers. To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced. The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values. In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process.","sentences":["We present TRACE (Transformer-based Risk Assessment for Clinical Evaluation), a novel method for clinical risk assessment based on clinical data, leveraging the self-attention mechanism for enhanced feature interaction and result interpretation.","Our approach is able to handle different data modalities, including continuous, categorical and multiple-choice (checkbox) attributes.","The proposed architecture features a shared representation of the clinical data obtained by integrating specialized embeddings of each data modality, enabling the detection of high-risk individuals using Transformer encoder layers.","To assess the effectiveness of the proposed method, a strong baseline based on non-negative multi-layer perceptrons (MLPs) is introduced.","The proposed method outperforms various baselines widely used in the domain of clinical risk assessment, while effectively handling missing values.","In terms of explainability, our Transformer-based method offers easily interpretable results via attention weights, further enhancing the clinicians' decision-making process."],"url":"http://arxiv.org/abs/2411.08701v1"}
{"created":"2024-11-13 15:42:13","title":"Rethinking negative sampling in content-based news recommendation","abstract":"News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay. Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem. However, these models often involve complex neural architectures and often lack consideration for negative examples. In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome. We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system. The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models. The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy. Finally, we discuss how decentralized models can help improve privacy and scalability.","sentences":["News recommender systems are hindered by the brief lifespan of articles, as they undergo rapid relevance decay.","Recent studies have demonstrated the potential of content-based neural techniques in tackling this problem.","However, these models often involve complex neural architectures and often lack consideration for negative examples.","In this study, we posit that the careful sampling of negative examples has a big impact on the model's outcome.","We devise a negative sampling technique that not only improves the accuracy of the model but also facilitates the decentralization of the recommendation system.","The experimental results obtained using the MIND dataset demonstrate that the accuracy of the method under consideration can compete with that of State-of-the-Art models.","The utilization of the sampling technique is essential in reducing model complexity and accelerating the training process, while maintaining a high level of accuracy.","Finally, we discuss how decentralized models can help improve privacy and scalability."],"url":"http://arxiv.org/abs/2411.08700v1"}
{"created":"2024-11-13 15:42:09","title":"FedSub: Introducing class-aware Subnetworks Fusion to Enhance Personalized Federated Learning in Ubiquitous Systems","abstract":"Personalized Federated Learning is essential in AI-driven ubiquitous systems, supporting the distributed development of models able to adapt to diverse and evolving user behaviors while safeguarding privacy. Despite addressing heterogeneous user data distributions in collaborative model training, existing methods often face limitations balancing personalization and generalization, oversimplifying user similarities, or relying heavily on global models. In this paper, we propose FedSub, a novel federated approach designed to enhance personalization through the use of class-aware prototypes and model subnetworks. Prototypes serve as compact representations of user data, clustered on the server to identify similarities based on specific label patterns. Concurrently, subnetworks -- model components necessary to process each class -- are extracted locally and fused by the server according to these clusters, producing highly tailored model updates for each user. This fine-grained, class-specific aggregation of clients' models allows FedSub to capture the unique characteristics of individual user data patterns. The effectiveness of FedSub is validated in three real-world scenarios characterized by high data heterogeneity, derived from human activity recognition and mobile health applications. Experimental evaluations demonstrate FedSub's performance improvements with respect to the state-of-the-art and significant advancements in personalization for ubiquitous systems based on personal mobile and wearable devices.","sentences":["Personalized Federated Learning is essential in AI-driven ubiquitous systems, supporting the distributed development of models able to adapt to diverse and evolving user behaviors while safeguarding privacy.","Despite addressing heterogeneous user data distributions in collaborative model training, existing methods often face limitations balancing personalization and generalization, oversimplifying user similarities, or relying heavily on global models.","In this paper, we propose FedSub, a novel federated approach designed to enhance personalization through the use of class-aware prototypes and model subnetworks.","Prototypes serve as compact representations of user data, clustered on the server to identify similarities based on specific label patterns.","Concurrently, subnetworks -- model components necessary to process each class -- are extracted locally and fused by the server according to these clusters, producing highly tailored model updates for each user.","This fine-grained, class-specific aggregation of clients' models allows FedSub to capture the unique characteristics of individual user data patterns.","The effectiveness of FedSub is validated in three real-world scenarios characterized by high data heterogeneity, derived from human activity recognition and mobile health applications.","Experimental evaluations demonstrate FedSub's performance improvements with respect to the state-of-the-art and significant advancements in personalization for ubiquitous systems based on personal mobile and wearable devices."],"url":"http://arxiv.org/abs/2411.08699v1"}
{"created":"2024-11-13 15:34:52","title":"Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata using LLMs","abstract":"Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs. Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata's infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets. While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata. Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction -- requiring (minimal) manual validation -- of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs. Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data. Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata. It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata's utility as a comprehensive scholarly resource.   Source Repository: https://github.com/scholarly-wikidata/   DOI: https://doi.org/10.5281/zenodo.10989709   License: Creative Commons CC0 (Data), MIT (Code)","sentences":["Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs.","Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata's infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets.","While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata.","Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction -- requiring (minimal) manual validation -- of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs.","Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data.","Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata.","It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata's utility as a comprehensive scholarly resource.   ","Source Repository: https://github.com/scholarly-wikidata/   DOI: https://doi.org/10.5281/zenodo.10989709   License: Creative Commons CC0 (Data), MIT (Code)"],"url":"http://arxiv.org/abs/2411.08696v1"}
{"created":"2024-11-13 15:29:24","title":"Human-Centered AI Transformation: Exploring Behavioral Dynamics in Software Engineering","abstract":"As Artificial Intelligence (AI) becomes integral to software development, understanding the social and cooperative dynamics that affect AI-driven organizational change is important. Yet, despite AI's rapid progress and influence, the human and cooperative facets of these shifts in software organizations remain relatively less explored. This study uses Behavioral Software Engineering (BSE) as a lens to examine these often-overlooked dimensions of AI transformation. Through a qualitative approach involving ten semi-structured interviews across four organizations that are undergoing AI transformations, we performed a thematic analysis that revealed numerous sub-themes linked to twelve BSE concepts across individual, group, and organizational levels. Since the organizations are at an early stage of transformation we found more emphasis on the individual level.   Our findings further reveal six key challenges tied to these BSE aspects that the organizations face during their AI transformation. Aligned with change management literature, we emphasize that effective communication, proactive leadership, and resistance management are essential for successful AI integration. However, we also identify ethical considerations as critical in the AI context-an area largely overlooked in previous research. Furthermore, a narrative analysis illustrates how different roles within an organization experience the AI transition in unique ways. These insights underscore that AI transformation extends beyond technical solutions; it requires a thoughtful approach that balances technological and human factors.","sentences":["As Artificial Intelligence (AI) becomes integral to software development, understanding the social and cooperative dynamics that affect AI-driven organizational change is important.","Yet, despite AI's rapid progress and influence, the human and cooperative facets of these shifts in software organizations remain relatively less explored.","This study uses Behavioral Software Engineering (BSE) as a lens to examine these often-overlooked dimensions of AI transformation.","Through a qualitative approach involving ten semi-structured interviews across four organizations that are undergoing AI transformations, we performed a thematic analysis that revealed numerous sub-themes linked to twelve BSE concepts across individual, group, and organizational levels.","Since the organizations are at an early stage of transformation we found more emphasis on the individual level.   ","Our findings further reveal six key challenges tied to these BSE aspects that the organizations face during their AI transformation.","Aligned with change management literature, we emphasize that effective communication, proactive leadership, and resistance management are essential for successful AI integration.","However, we also identify ethical considerations as critical in the AI context-an area largely overlooked in previous research.","Furthermore, a narrative analysis illustrates how different roles within an organization experience the AI transition in unique ways.","These insights underscore that AI transformation extends beyond technical solutions; it requires a thoughtful approach that balances technological and human factors."],"url":"http://arxiv.org/abs/2411.08693v1"}
{"created":"2024-11-13 15:22:33","title":"Measuring similarity between embedding spaces using induced neighborhood graphs","abstract":"Deep Learning techniques have excelled at generating embedding spaces that capture semantic similarities between items. Often these representations are paired, enabling experiments with analogies (pairs within the same domain) and cross-modality (pairs across domains). These experiments are based on specific assumptions about the geometry of embedding spaces, which allow finding paired items by extrapolating the positional relationships between embedding pairs in the training dataset, allowing for tasks such as finding new analogies, and multimodal zero-shot classification. In this work, we propose a metric to evaluate the similarity between paired item representations. Our proposal is built from the structural similarity between the nearest-neighbors induced graphs of each representation, and can be configured to compare spaces based on different distance metrics and on different neighborhood sizes. We demonstrate that our proposal can be used to identify similar structures at different scales, which is hard to achieve with kernel methods such as Centered Kernel Alignment (CKA). We further illustrate our method with two case studies: an analogy task using GloVe embeddings, and zero-shot classification in the CIFAR-100 dataset using CLIP embeddings. Our results show that accuracy in both analogy and zero-shot classification tasks correlates with the embedding similarity. These findings can help explain performance differences in these tasks, and may lead to improved design of paired-embedding models in the future.","sentences":["Deep Learning techniques have excelled at generating embedding spaces that capture semantic similarities between items.","Often these representations are paired, enabling experiments with analogies (pairs within the same domain) and cross-modality (pairs across domains).","These experiments are based on specific assumptions about the geometry of embedding spaces, which allow finding paired items by extrapolating the positional relationships between embedding pairs in the training dataset, allowing for tasks such as finding new analogies, and multimodal zero-shot classification.","In this work, we propose a metric to evaluate the similarity between paired item representations.","Our proposal is built from the structural similarity between the nearest-neighbors induced graphs of each representation, and can be configured to compare spaces based on different distance metrics and on different neighborhood sizes.","We demonstrate that our proposal can be used to identify similar structures at different scales, which is hard to achieve with kernel methods such as Centered Kernel Alignment (CKA).","We further illustrate our method with two case studies: an analogy task using GloVe embeddings, and zero-shot classification in the CIFAR-100 dataset using CLIP embeddings.","Our results show that accuracy in both analogy and zero-shot classification tasks correlates with the embedding similarity.","These findings can help explain performance differences in these tasks, and may lead to improved design of paired-embedding models in the future."],"url":"http://arxiv.org/abs/2411.08687v1"}
{"created":"2024-11-13 15:20:14","title":"Analogical Reasoning Within a Conceptual Hyperspace","abstract":"We propose an approach to analogical inference that marries the neuro-symbolic computational power of complex-sampled hyperdimensional computing (HDC) with Conceptual Spaces Theory (CST), a promising theory of semantic meaning. CST sketches, at an abstract level, approaches to analogical inference that go beyond the standard predicate-based structure mapping theories. But it does not describe how such an approach can be operationalized. We propose a concrete HDC-based architecture that computes several types of analogy classified by CST. We present preliminary proof-of-concept experimental results within a toy domain and describe how it can perform category-based and property-based analogical reasoning.","sentences":["We propose an approach to analogical inference that marries the neuro-symbolic computational power of complex-sampled hyperdimensional computing (HDC) with Conceptual Spaces Theory (CST), a promising theory of semantic meaning.","CST sketches, at an abstract level, approaches to analogical inference that go beyond the standard predicate-based structure mapping theories.","But it does not describe how such an approach can be operationalized.","We propose a concrete HDC-based architecture that computes several types of analogy classified by CST.","We present preliminary proof-of-concept experimental results within a toy domain and describe how it can perform category-based and property-based analogical reasoning."],"url":"http://arxiv.org/abs/2411.08684v1"}
{"created":"2024-11-13 15:13:48","title":"Integrated Precoder and Trajectory Design for MIMO UAV-Assisted Relay System With Finite-Alphabet Inputs","abstract":"Unmanned aerial vehicles (UAVs) are gaining widespread use in wireless relay systems due to their exceptional flexibility and cost-effectiveness. This paper focuses on the integrated design of UAV trajectories and the precoders at both the transmitter and UAV in a UAV-assisted relay communication system, accounting for transmit power constraints and UAV flight limitations. Unlike previous works that primarily address multiple-input single-output (MISO) systems with Gaussian inputs, we investigate a more realistic scenario involving multiple-input multiple-output (MIMO) systems with finite-alphabet inputs. To tackle the challenging and inherently non-convex problem, we propose an efficient solution algorithm that leverages successive convex approximation and alternating optimization techniques. Simulation results validate the effectiveness of the proposed algorithm, demonstrating its capability to optimize system performance.","sentences":["Unmanned aerial vehicles (UAVs) are gaining widespread use in wireless relay systems due to their exceptional flexibility and cost-effectiveness.","This paper focuses on the integrated design of UAV trajectories and the precoders at both the transmitter and UAV in a UAV-assisted relay communication system, accounting for transmit power constraints and UAV flight limitations.","Unlike previous works that primarily address multiple-input single-output (MISO) systems with Gaussian inputs, we investigate a more realistic scenario involving multiple-input multiple-output (MIMO) systems with finite-alphabet inputs.","To tackle the challenging and inherently non-convex problem, we propose an efficient solution algorithm that leverages successive convex approximation and alternating optimization techniques.","Simulation results validate the effectiveness of the proposed algorithm, demonstrating its capability to optimize system performance."],"url":"http://arxiv.org/abs/2411.08680v1"}
{"created":"2024-11-13 15:08:35","title":"Reducing ADC Front-end Costs During Training of On-sensor Printed Multilayer Perceptrons","abstract":"Printed electronics technology offers a cost-effectiveand fully-customizable solution to computational needs beyondthe capabilities of traditional silicon technologies, offering ad-vantages such as on-demand manufacturing and conformal, low-cost hardware. However, the low-resolution fabrication of printedelectronics, which results in large feature sizes, poses a challengefor integrating complex designs like those of machine learn-ing (ML) classification systems. Current literature optimizes onlythe Multilayer Perceptron (MLP) circuit within the classificationsystem, while the cost of analog-to-digital converters (ADCs)is overlooked. Printed applications frequently require on-sensorprocessing, yet while the digital classifier has been extensivelyoptimized, the analog-to-digital interfacing, specifically the ADCs,dominates the total area and energy consumption. In this work,we target digital printed MLP classifiers and we propose thedesign of customized ADCs per MLP's input which involvesminimizing the distinct represented numbers for each input,simplifying thus the ADC's circuitry. Incorporating this ADCoptimization in the MLP training, enables eliminating ADC levelsand the respective comparators, while still maintaining highclassification accuracy. Our approach achieves 11.2x lower ADCarea for less than 5% accuracy drop across varying MLPs.","sentences":["Printed electronics technology offers a cost-effectiveand fully-customizable solution to computational needs beyondthe capabilities of traditional silicon technologies, offering ad-vantages such as on-demand manufacturing and conformal, low-cost hardware.","However, the low-resolution fabrication of printedelectronics, which results in large feature sizes, poses a challengefor integrating complex designs like those of machine learn-ing (ML) classification systems.","Current literature optimizes onlythe Multilayer Perceptron (MLP) circuit within the classificationsystem, while the cost of analog-to-digital converters (ADCs)is overlooked.","Printed applications frequently require on-sensorprocessing, yet while the digital classifier has been extensivelyoptimized, the analog-to-digital interfacing, specifically the ADCs,dominates the total area and energy consumption.","In this work,we target digital printed MLP classifiers and we propose thedesign of customized ADCs per MLP's input which involvesminimizing the distinct represented numbers for each input,simplifying thus the ADC's circuitry.","Incorporating this ADCoptimization in the MLP training, enables eliminating ADC levelsand the respective comparators, while still maintaining highclassification accuracy.","Our approach achieves 11.2x lower ADCarea for less than 5% accuracy drop across varying MLPs."],"url":"http://arxiv.org/abs/2411.08674v1"}
{"created":"2024-11-13 15:08:18","title":"ScribGen: Generating Scribble Art Through Metaheuristics","abstract":"Art has long been a medium for individuals to engage with the world. Scribble art, a form of abstract visual expression, features spontaneous, gestural strokes made with pens or brushes. These dynamic and expressive compositions, created quickly and impulsively, reveal intricate patterns and hidden meanings upon closer inspection. While scribble art is often associated with spontaneous expression and experimentation, it can also be planned and intentional. Some artists use scribble techniques as a starting point for their creative process, exploring the possibilities of line, shape, and texture before refining their work into more polished compositions. From ancient cave paintings to modern abstract sketches and doodles, scribble art has evolved with civilizations, reflecting diverse artistic movements and cultural influences. This evolution highlights its universal appeal, transcending language and cultural barriers and connecting people through the shared experience of creating art.","sentences":["Art has long been a medium for individuals to engage with the world.","Scribble art, a form of abstract visual expression, features spontaneous, gestural strokes made with pens or brushes.","These dynamic and expressive compositions, created quickly and impulsively, reveal intricate patterns and hidden meanings upon closer inspection.","While scribble art is often associated with spontaneous expression and experimentation, it can also be planned and intentional.","Some artists use scribble techniques as a starting point for their creative process, exploring the possibilities of line, shape, and texture before refining their work into more polished compositions.","From ancient cave paintings to modern abstract sketches and doodles, scribble art has evolved with civilizations, reflecting diverse artistic movements and cultural influences.","This evolution highlights its universal appeal, transcending language and cultural barriers and connecting people through the shared experience of creating art."],"url":"http://arxiv.org/abs/2411.08673v1"}
{"created":"2024-11-13 15:07:15","title":"Joint Model Caching and Resource Allocation in Generative AI-Enabled Wireless Edge Networks","abstract":"With the rapid advancement of artificial intelligence (AI), generative AI (GenAI) has emerged as a transformative tool, enabling customized and personalized AI-generated content (AIGC) services. However, GenAI models with billions of parameters require substantial memory capacity and computational power for deployment and execution, presenting significant challenges to resource-limited edge networks. In this paper, we address the joint model caching and resource allocation problem in GenAI-enabled wireless edge networks. Our objective is to balance the trade-off between delivering high-quality AIGC and minimizing the delay in AIGC service provisioning. To tackle this problem, we employ a deep deterministic policy gradient (DDPG)-based reinforcement learning approach, capable of efficiently determining optimal model caching and resource allocation decisions for AIGC services in response to user mobility and time-varying channel conditions. Numerical results demonstrate that DDPG achieves a higher model hit ratio and provides superior-quality, lower-latency AIGC services compared to other benchmark solutions.","sentences":["With the rapid advancement of artificial intelligence (AI), generative AI (GenAI) has emerged as a transformative tool, enabling customized and personalized AI-generated content (AIGC) services.","However, GenAI models with billions of parameters require substantial memory capacity and computational power for deployment and execution, presenting significant challenges to resource-limited edge networks.","In this paper, we address the joint model caching and resource allocation problem in GenAI-enabled wireless edge networks.","Our objective is to balance the trade-off between delivering high-quality AIGC and minimizing the delay in AIGC service provisioning.","To tackle this problem, we employ a deep deterministic policy gradient (DDPG)-based reinforcement learning approach, capable of efficiently determining optimal model caching and resource allocation decisions for AIGC services in response to user mobility and time-varying channel conditions.","Numerical results demonstrate that DDPG achieves a higher model hit ratio and provides superior-quality, lower-latency AIGC services compared to other benchmark solutions."],"url":"http://arxiv.org/abs/2411.08672v1"}
