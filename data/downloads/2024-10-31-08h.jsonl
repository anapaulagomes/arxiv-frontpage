{"created":"2024-10-30 17:59:41","title":"Bridging the Human to Robot Dexterity Gap through Object-Oriented Rewards","abstract":"Training robots directly from human videos is an emerging area in robotics and computer vision. While there has been notable progress with two-fingered grippers, learning autonomous tasks for multi-fingered robot hands in this way remains challenging. A key reason for this difficulty is that a policy trained on human hands may not directly transfer to a robot hand due to morphology differences. In this work, we present HuDOR, a technique that enables online fine-tuning of policies by directly computing rewards from human videos. Importantly, this reward function is built using object-oriented trajectories derived from off-the-shelf point trackers, providing meaningful learning signals despite the morphology gap and visual differences between human and robot hands. Given a single video of a human solving a task, such as gently opening a music box, HuDOR enables our four-fingered Allegro hand to learn the task with just an hour of online interaction. Our experiments across four tasks show that HuDOR achieves a 4x improvement over baselines. Code and videos are available on our website, https://object-rewards.github.io.","sentences":["Training robots directly from human videos is an emerging area in robotics and computer vision.","While there has been notable progress with two-fingered grippers, learning autonomous tasks for multi-fingered robot hands in this way remains challenging.","A key reason for this difficulty is that a policy trained on human hands may not directly transfer to a robot hand due to morphology differences.","In this work, we present HuDOR, a technique that enables online fine-tuning of policies by directly computing rewards from human videos.","Importantly, this reward function is built using object-oriented trajectories derived from off-the-shelf point trackers, providing meaningful learning signals despite the morphology gap and visual differences between human and robot hands.","Given a single video of a human solving a task, such as gently opening a music box, HuDOR enables our four-fingered Allegro hand to learn the task with just an hour of online interaction.","Our experiments across four tasks show that HuDOR achieves a 4x improvement over baselines.","Code and videos are available on our website, https://object-rewards.github.io."],"url":"http://arxiv.org/abs/2410.23289v1"}
{"created":"2024-10-30 17:59:34","title":"Computing the bridge length: the key ingredient in a continuous isometry classification of periodic point sets","abstract":"The fundamental model of any periodic crystal is a periodic set of points at all atomic centres. Since crystal structures are determined in a rigid form, their strongest equivalence is rigid motion (composition of translations and rotations) or isometry (also including reflections). The recent isometry classification of periodic point sets used a complete invariant isoset whose size essentially depends on the bridge length, defined as the minimum `jump' that suffices to connect any points in the given set.   We propose a practical algorithm to compute the bridge length of any periodic point set given by a motif of points in a periodically translated unit cell. The algorithm has been tested on a large crystal dataset and is required for an efficient continuous classification of all periodic crystals. The exact computation of the bridge length is a key step to realising the inverse design of materials from new invariant values.","sentences":["The fundamental model of any periodic crystal is a periodic set of points at all atomic centres.","Since crystal structures are determined in a rigid form, their strongest equivalence is rigid motion (composition of translations and rotations) or isometry (also including reflections).","The recent isometry classification of periodic point sets used a complete invariant isoset whose size essentially depends on the bridge length, defined as the minimum `jump' that suffices to connect any points in the given set.   ","We propose a practical algorithm to compute the bridge length of any periodic point set given by a motif of points in a periodically translated unit cell.","The algorithm has been tested on a large crystal dataset and is required for an efficient continuous classification of all periodic crystals.","The exact computation of the bridge length is a key step to realising the inverse design of materials from new invariant values."],"url":"http://arxiv.org/abs/2410.23288v1"}
{"created":"2024-10-30 17:59:26","title":"ReferEverything: Towards Segmenting Everything We Can Speak of in Videos","abstract":"We present REM, a framework for segmenting a wide range of concepts in video that can be described through natural language. Our method capitalizes on visual-language representations learned by video diffusion models on Internet-scale datasets. A key insight of our approach is preserving as much of the generative model's original representation as possible, while fine-tuning it on narrow-domain Referral Object Segmentation datasets. As a result, our framework can accurately segment and track rare and unseen objects, despite being trained on object masks from a limited set of categories. Additionally, it can generalize to non-object dynamic concepts, such as waves crashing in the ocean, as demonstrated in our newly introduced benchmark for Referral Video Process Segmentation (Ref-VPS). Our experiments show that REM performs on par with state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, while outperforming them by up to twelve points in terms of region similarity on out-of-domain data, leveraging the power of Internet-scale pre-training.","sentences":["We present REM, a framework for segmenting a wide range of concepts in video that can be described through natural language.","Our method capitalizes on visual-language representations learned by video diffusion models on Internet-scale datasets.","A key insight of our approach is preserving as much of the generative model's original representation as possible, while fine-tuning it on narrow-domain Referral Object Segmentation datasets.","As a result, our framework can accurately segment and track rare and unseen objects, despite being trained on object masks from a limited set of categories.","Additionally, it can generalize to non-object dynamic concepts, such as waves crashing in the ocean, as demonstrated in our newly introduced benchmark for Referral Video Process Segmentation (Ref-VPS).","Our experiments show that REM performs on par with state-of-the-art approaches on in-domain datasets, like Ref-DAVIS, while outperforming them by up to twelve points in terms of region similarity on out-of-domain data, leveraging the power of Internet-scale pre-training."],"url":"http://arxiv.org/abs/2410.23287v1"}
{"created":"2024-10-30 17:59:06","title":"Provable acceleration for diffusion models under minimal assumptions","abstract":"While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations. Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited. To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers. Under minimal assumptions -- namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution -- our accelerated sampler provably achieves $\\varepsilon$-accuracy in total variation within $\\widetilde{O}(d^{5/4}/\\sqrt{\\varepsilon})$ iterations, thereby significantly improving upon the $\\widetilde{O}(d/\\varepsilon)$ iteration complexity of standard score-based samplers. Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees.","sentences":["While score-based diffusion models have achieved exceptional sampling quality, their sampling speeds are often limited by the high computational burden of score function evaluations.","Despite the recent remarkable empirical advances in speeding up the score-based samplers, theoretical understanding of acceleration techniques remains largely limited.","To bridge this gap, we propose a novel training-free acceleration scheme for stochastic samplers.","Under minimal assumptions -- namely, $L^2$-accurate score estimates and a finite second-moment condition on the target distribution -- our accelerated sampler provably achieves $\\varepsilon$-accuracy in total variation within $\\widetilde{O}(d^{5/4}/\\sqrt{\\varepsilon})$ iterations, thereby significantly improving upon the $\\widetilde{O}(d/\\varepsilon)$ iteration complexity of standard score-based samplers.","Notably, our convergence theory does not rely on restrictive assumptions on the target distribution or higher-order score estimation guarantees."],"url":"http://arxiv.org/abs/2410.23285v1"}
{"created":"2024-10-30 17:58:26","title":"DisCo: Distributed Contact-Rich Trajectory Optimization for Forceful Multi-Robot Collaboration","abstract":"We present DisCo, a distributed algorithm for contact-rich, multi-robot tasks. DisCo is a distributed contact-implicit trajectory optimization algorithm, which allows a group of robots to optimize a time sequence of forces to objects and to their environment to accomplish tasks such as collaborative manipulation, robot team sports, and modular robot locomotion. We build our algorithm on a variant of the Alternating Direction Method of Multipliers (ADMM), where each robot computes its own contact forces and contact-switching events from a smaller single-robot, contact-implicit trajectory optimization problem, while cooperating with other robots through dual variables, enforcing constraints between robots. Each robot iterates between solving its local problem, and communicating over a wireless mesh network to enforce these consistency constraints with its neighbors, ultimately converging to a coordinated plan for the group. The local problems solved by each robot are significantly less challenging than a centralized problem with all robots' contact forces and switching events, improving the computational efficiency, while also preserving the privacy of some aspects of each robot's operation. We demonstrate the effectiveness of our algorithm in simulations of collaborative manipulation, multi-robot team sports scenarios, and in modular robot locomotion, where DisCo achieves $3$x higher success rates with a 2.5x to 5x faster computation time. Further, we provide results of hardware experiments on a modular truss robot, with three collaborating truss nodes planning individually while working together to produce a punctuated rolling-gate motion of the composite structure. Videos are available on the project page: https://disco-opt.github.io.","sentences":["We present DisCo, a distributed algorithm for contact-rich, multi-robot tasks.","DisCo is a distributed contact-implicit trajectory optimization algorithm, which allows a group of robots to optimize a time sequence of forces to objects and to their environment to accomplish tasks such as collaborative manipulation, robot team sports, and modular robot locomotion.","We build our algorithm on a variant of the Alternating Direction Method of Multipliers (ADMM), where each robot computes its own contact forces and contact-switching events from a smaller single-robot, contact-implicit trajectory optimization problem, while cooperating with other robots through dual variables, enforcing constraints between robots.","Each robot iterates between solving its local problem, and communicating over a wireless mesh network to enforce these consistency constraints with its neighbors, ultimately converging to a coordinated plan for the group.","The local problems solved by each robot are significantly less challenging than a centralized problem with all robots' contact forces and switching events, improving the computational efficiency, while also preserving the privacy of some aspects of each robot's operation.","We demonstrate the effectiveness of our algorithm in simulations of collaborative manipulation, multi-robot team sports scenarios, and in modular robot locomotion, where DisCo achieves $3$x higher success rates with a 2.5x to 5x faster computation time.","Further, we provide results of hardware experiments on a modular truss robot, with three collaborating truss nodes planning individually while working together to produce a punctuated rolling-gate motion of the composite structure.","Videos are available on the project page: https://disco-opt.github.io."],"url":"http://arxiv.org/abs/2410.23283v1"}
{"created":"2024-10-30 17:57:21","title":"RelationBooth: Towards Relation-Aware Customized Object Generation","abstract":"Customized image generation is crucial for delivering personalized content based on user-provided image prompts, aligning large-scale text-to-image diffusion models with individual needs. However, existing models often overlook the relationships between customized objects in generated images. Instead, this work addresses that gap by focusing on relation-aware customized image generation, which aims to preserve the identities from image prompts while maintaining the predicate relations described in text prompts. Specifically, we introduce RelationBooth, a framework that disentangles identity and relation learning through a well-curated dataset. Our training data consists of relation-specific images, independent object images containing identity information, and text prompts to guide relation generation. Then, we propose two key modules to tackle the two main challenges: generating accurate and natural relations, especially when significant pose adjustments are required, and avoiding object confusion in cases of overlap. First, we introduce a keypoint matching loss that effectively guides the model in adjusting object poses closely tied to their relationships. Second, we incorporate local features from the image prompts to better distinguish between objects, preventing confusion in overlapping cases. Extensive results on three benchmarks demonstrate the superiority of RelationBooth in generating precise relations while preserving object identities across a diverse set of objects and relations. The source code and trained models will be made available to the public.","sentences":["Customized image generation is crucial for delivering personalized content based on user-provided image prompts, aligning large-scale text-to-image diffusion models with individual needs.","However, existing models often overlook the relationships between customized objects in generated images.","Instead, this work addresses that gap by focusing on relation-aware customized image generation, which aims to preserve the identities from image prompts while maintaining the predicate relations described in text prompts.","Specifically, we introduce RelationBooth, a framework that disentangles identity and relation learning through a well-curated dataset.","Our training data consists of relation-specific images, independent object images containing identity information, and text prompts to guide relation generation.","Then, we propose two key modules to tackle the two main challenges: generating accurate and natural relations, especially when significant pose adjustments are required, and avoiding object confusion in cases of overlap.","First, we introduce a keypoint matching loss that effectively guides the model in adjusting object poses closely tied to their relationships.","Second, we incorporate local features from the image prompts to better distinguish between objects, preventing confusion in overlapping cases.","Extensive results on three benchmarks demonstrate the superiority of RelationBooth in generating precise relations while preserving object identities across a diverse set of objects and relations.","The source code and trained models will be made available to the public."],"url":"http://arxiv.org/abs/2410.23280v1"}
{"created":"2024-10-30 17:57:13","title":"A Neural Transformer Framework for Simultaneous Tasks of Segmentation, Classification, and Caller Identification of Marmoset Vocalization","abstract":"Marmoset, a highly vocalized primate, has become a popular animal model for studying social-communicative behavior and its underlying mechanism. In the study of vocal communication, it is vital to know the caller identities, call contents, and vocal exchanges. Previous work of a CNN has achieved a joint model for call segmentation, classification, and caller identification for marmoset vocalizations. However, the CNN has limitations in modeling long-range acoustic patterns; the Transformer architecture that has been shown to outperform CNNs, utilizes the self-attention mechanism that efficiently segregates information parallelly over long distances and captures the global structure of marmoset vocalization. We propose using the Transformer to jointly segment and classify the marmoset calls and identify the callers for each vocalization.","sentences":["Marmoset, a highly vocalized primate, has become a popular animal model for studying social-communicative behavior and its underlying mechanism.","In the study of vocal communication, it is vital to know the caller identities, call contents, and vocal exchanges.","Previous work of a CNN has achieved a joint model for call segmentation, classification, and caller identification for marmoset vocalizations.","However, the CNN has limitations in modeling long-range acoustic patterns; the Transformer architecture that has been shown to outperform CNNs, utilizes the self-attention mechanism that efficiently segregates information parallelly over long distances and captures the global structure of marmoset vocalization.","We propose using the Transformer to jointly segment and classify the marmoset calls and identify the callers for each vocalization."],"url":"http://arxiv.org/abs/2410.23279v1"}
{"created":"2024-10-30 17:56:02","title":"OpenSatMap: A Fine-grained High-resolution Satellite Dataset for Large-scale Map Construction","abstract":"In this paper, we propose OpenSatMap, a fine-grained, high-resolution satellite dataset for large-scale map construction. Map construction is one of the foundations of the transportation industry, such as navigation and autonomous driving. Extracting road structures from satellite images is an efficient way to construct large-scale maps. However, existing satellite datasets provide only coarse semantic-level labels with a relatively low resolution (up to level 19), impeding the advancement of this field. In contrast, the proposed OpenSatMap (1) has fine-grained instance-level annotations; (2) consists of high-resolution images (level 20); (3) is currently the largest one of its kind; (4) collects data with high diversity. Moreover, OpenSatMap covers and aligns with the popular nuScenes dataset and Argoverse 2 dataset to potentially advance autonomous driving technologies. By publishing and maintaining the dataset, we provide a high-quality benchmark for satellite-based map construction and downstream tasks like autonomous driving.","sentences":["In this paper, we propose OpenSatMap, a fine-grained, high-resolution satellite dataset for large-scale map construction.","Map construction is one of the foundations of the transportation industry, such as navigation and autonomous driving.","Extracting road structures from satellite images is an efficient way to construct large-scale maps.","However, existing satellite datasets provide only coarse semantic-level labels with a relatively low resolution (up to level 19), impeding the advancement of this field.","In contrast, the proposed OpenSatMap (1) has fine-grained instance-level annotations; (2) consists of high-resolution images (level 20); (3) is currently the largest one of its kind; (4) collects data with high diversity.","Moreover, OpenSatMap covers and aligns with the popular nuScenes dataset and Argoverse 2 dataset to potentially advance autonomous driving technologies.","By publishing and maintaining the dataset, we provide a high-quality benchmark for satellite-based map construction and downstream tasks like autonomous driving."],"url":"http://arxiv.org/abs/2410.23278v1"}
{"created":"2024-10-30 17:55:52","title":"SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation","abstract":"Human beings are endowed with a complementary learning system, which bridges the slow learning of general world dynamics with fast storage of episodic memory from a new experience. Previous video generation models, however, primarily focus on slow learning by pre-training on vast amounts of data, overlooking the fast learning phase crucial for episodic memory storage. This oversight leads to inconsistencies across temporally distant frames when generating longer videos, as these frames fall beyond the model's context window. To this end, we introduce SlowFast-VGen, a novel dual-speed learning system for action-driven long video generation. Our approach incorporates a masked conditional video diffusion model for the slow learning of world dynamics, alongside an inference-time fast learning strategy based on a temporal LoRA module. Specifically, the fast learning process updates its temporal LoRA parameters based on local inputs and outputs, thereby efficiently storing episodic memory in its parameters. We further propose a slow-fast learning loop algorithm that seamlessly integrates the inner fast learning loop into the outer slow learning loop, enabling the recall of prior multi-episode experiences for context-aware skill learning. To facilitate the slow learning of an approximate world model, we collect a large-scale dataset of 200k videos with language action annotations, covering a wide range of scenarios. Extensive experiments show that SlowFast-VGen outperforms baselines across various metrics for action-driven video generation, achieving an FVD score of 514 compared to 782, and maintaining consistency in longer videos, with an average of 0.37 scene cuts versus 0.89. The slow-fast learning loop algorithm significantly enhances performances on long-horizon planning tasks as well. Project Website: https://slowfast-vgen.github.io","sentences":["Human beings are endowed with a complementary learning system, which bridges the slow learning of general world dynamics with fast storage of episodic memory from a new experience.","Previous video generation models, however, primarily focus on slow learning by pre-training on vast amounts of data, overlooking the fast learning phase crucial for episodic memory storage.","This oversight leads to inconsistencies across temporally distant frames when generating longer videos, as these frames fall beyond the model's context window.","To this end, we introduce SlowFast-VGen, a novel dual-speed learning system for action-driven long video generation.","Our approach incorporates a masked conditional video diffusion model for the slow learning of world dynamics, alongside an inference-time fast learning strategy based on a temporal LoRA module.","Specifically, the fast learning process updates its temporal LoRA parameters based on local inputs and outputs, thereby efficiently storing episodic memory in its parameters.","We further propose a slow-fast learning loop algorithm that seamlessly integrates the inner fast learning loop into the outer slow learning loop, enabling the recall of prior multi-episode experiences for context-aware skill learning.","To facilitate the slow learning of an approximate world model, we collect a large-scale dataset of 200k videos with language action annotations, covering a wide range of scenarios.","Extensive experiments show that SlowFast-VGen outperforms baselines across various metrics for action-driven video generation, achieving an FVD score of 514 compared to 782, and maintaining consistency in longer videos, with an average of 0.37 scene cuts versus 0.89.","The slow-fast learning loop algorithm significantly enhances performances on long-horizon planning tasks as well.","Project Website: https://slowfast-vgen.github.io"],"url":"http://arxiv.org/abs/2410.23277v1"}
{"created":"2024-10-30 17:54:56","title":"Multi-student Diffusion Distillation for Better One-step Generators","abstract":"Diffusion models achieve high-quality sample generation at the cost of a lengthy multistep inference procedure. To overcome this, diffusion distillation techniques produce student generators capable of matching or surpassing the teacher in a single step. However, the student model's inference speed is limited by the size of the teacher architecture, preventing real-time generation for computationally heavy applications. In this work, we introduce Multi-Student Distillation (MSD), a framework to distill a conditional teacher diffusion model into multiple single-step generators. Each student generator is responsible for a subset of the conditioning data, thereby obtaining higher generation quality for the same capacity. MSD trains multiple distilled students, allowing smaller sizes and, therefore, faster inference. Also, MSD offers a lightweight quality boost over single-student distillation with the same architecture. We demonstrate MSD is effective by training multiple same-sized or smaller students on single-step distillation using distribution matching and adversarial distillation techniques. With smaller students, MSD gets competitive results with faster inference for single-step generation. Using 4 same-sized students, MSD sets a new state-of-the-art for one-step image generation: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014.","sentences":["Diffusion models achieve high-quality sample generation at the cost of a lengthy multistep inference procedure.","To overcome this, diffusion distillation techniques produce student generators capable of matching or surpassing the teacher in a single step.","However, the student model's inference speed is limited by the size of the teacher architecture, preventing real-time generation for computationally heavy applications.","In this work, we introduce Multi-Student Distillation (MSD), a framework to distill a conditional teacher diffusion model into multiple single-step generators.","Each student generator is responsible for a subset of the conditioning data, thereby obtaining higher generation quality for the same capacity.","MSD trains multiple distilled students, allowing smaller sizes and, therefore, faster inference.","Also, MSD offers a lightweight quality boost over single-student distillation with the same architecture.","We demonstrate MSD is effective by training multiple same-sized or smaller students on single-step distillation using distribution matching and adversarial distillation techniques.","With smaller students, MSD gets competitive results with faster inference for single-step generation.","Using 4 same-sized students, MSD sets a new state-of-the-art for one-step image generation: FID 1.20 on ImageNet-64x64 and 8.20 on zero-shot COCO2014."],"url":"http://arxiv.org/abs/2410.23274v1"}
{"created":"2024-10-30 17:53:49","title":"Proportional Fairness in Non-Centroid Clustering","abstract":"We revisit the recently developed framework of proportionally fair clustering, where the goal is to provide group fairness guarantees that become stronger for groups of data points (agents) that are large and cohesive. Prior work applies this framework to centroid clustering, where the loss of an agent is its distance to the centroid assigned to its cluster. We expand the framework to non-centroid clustering, where the loss of an agent is a function of the other agents in its cluster, by adapting two proportional fairness criteria -- the core and its relaxation, fully justified representation (FJR) -- to this setting.   We show that the core can be approximated only under structured loss functions, and even then, the best approximation we are able to establish, using an adaptation of the GreedyCapture algorithm developed for centroid clustering [Chen et al., 2019; Micha and Shah, 2020], is unappealing for a natural loss function. In contrast, we design a new (inefficient) algorithm, GreedyCohesiveClustering, which achieves the relaxation FJR exactly under arbitrary loss functions, and show that the efficient GreedyCapture algorithm achieves a constant approximation of FJR. We also design an efficient auditing algorithm, which estimates the FJR approximation of any given clustering solution up to a constant factor. Our experiments on real data suggest that traditional clustering algorithms are highly unfair, whereas GreedyCapture is considerably fairer and incurs only a modest loss in common clustering objectives.","sentences":["We revisit the recently developed framework of proportionally fair clustering, where the goal is to provide group fairness guarantees that become stronger for groups of data points (agents) that are large and cohesive.","Prior work applies this framework to centroid clustering, where the loss of an agent is its distance to the centroid assigned to its cluster.","We expand the framework to non-centroid clustering, where the loss of an agent is a function of the other agents in its cluster, by adapting two proportional fairness criteria -- the core and its relaxation, fully justified representation (FJR) -- to this setting.   ","We show that the core can be approximated only under structured loss functions, and even then, the best approximation we are able to establish, using an adaptation of the GreedyCapture algorithm developed for centroid clustering","[Chen et al., 2019; Micha and Shah, 2020], is unappealing for a natural loss function.","In contrast, we design a new (inefficient) algorithm, GreedyCohesiveClustering, which achieves the relaxation FJR exactly under arbitrary loss functions, and show that the efficient GreedyCapture algorithm achieves a constant approximation of FJR.","We also design an efficient auditing algorithm, which estimates the FJR approximation of any given clustering solution up to a constant factor.","Our experiments on real data suggest that traditional clustering algorithms are highly unfair, whereas GreedyCapture is considerably fairer and incurs only a modest loss in common clustering objectives."],"url":"http://arxiv.org/abs/2410.23273v1"}
{"created":"2024-10-30 17:53:37","title":"A Monte Carlo Framework for Calibrated Uncertainty Estimation in Sequence Prediction","abstract":"Probabilistic prediction of sequences from images and other high-dimensional data is a key challenge, particularly in risk-sensitive applications. In these settings, it is often desirable to quantify the uncertainty associated with the prediction (instead of just determining the most likely sequence, as in language modeling). In this paper, we propose a Monte Carlo framework to estimate probabilities and confidence intervals associated with the distribution of a discrete sequence. Our framework uses a Monte Carlo simulator, implemented as an autoregressively trained neural network, to sample sequences conditioned on an image input. We then use these samples to estimate the probabilities and confidence intervals. Experiments on synthetic and real data show that the framework produces accurate discriminative predictions, but can suffer from miscalibration. In order to address this shortcoming, we propose a time-dependent regularization method, which is shown to produce calibrated predictions.","sentences":["Probabilistic prediction of sequences from images and other high-dimensional data is a key challenge, particularly in risk-sensitive applications.","In these settings, it is often desirable to quantify the uncertainty associated with the prediction (instead of just determining the most likely sequence, as in language modeling).","In this paper, we propose a Monte Carlo framework to estimate probabilities and confidence intervals associated with the distribution of a discrete sequence.","Our framework uses a Monte Carlo simulator, implemented as an autoregressively trained neural network, to sample sequences conditioned on an image input.","We then use these samples to estimate the probabilities and confidence intervals.","Experiments on synthetic and real data show that the framework produces accurate discriminative predictions, but can suffer from miscalibration.","In order to address this shortcoming, we propose a time-dependent regularization method, which is shown to produce calibrated predictions."],"url":"http://arxiv.org/abs/2410.23272v1"}
{"created":"2024-10-30 17:51:31","title":"Commit: Online Groups with Participation Commitments","abstract":"In spite of efforts to increase participation, many online groups struggle to survive past the initial days, as members leave and activity atrophies. We argue that a main assumption of online group design -- that groups ask nothing of their members beyond lurking -- may be preventing many of these groups from sustaining a critical mass of participation. In this paper, we explore an alternative commitment design for online groups, which requires that all members commit at regular intervals to participating, as a condition of remaining in the group. We instantiate this approach in a mobile group chat platform called Commit, and perform a field study comparing commitment against a control condition of social psychological nudges with N=57 participants over three weeks. Commitment doubled the number of contributions versus the control condition, and resulted in 87% (vs. 19%) of participants remaining active by the third week. Participants reported that commitment provided safe cover for them to post even when they were nervous. Through this work, we argue that more effortful, not less effortful, membership may support many online groups.","sentences":["In spite of efforts to increase participation, many online groups struggle to survive past the initial days, as members leave and activity atrophies.","We argue that a main assumption of online group design -- that groups ask nothing of their members beyond lurking -- may be preventing many of these groups from sustaining a critical mass of participation.","In this paper, we explore an alternative commitment design for online groups, which requires that all members commit at regular intervals to participating, as a condition of remaining in the group.","We instantiate this approach in a mobile group chat platform called Commit, and perform a field study comparing commitment against a control condition of social psychological nudges with N=57 participants over three weeks.","Commitment doubled the number of contributions versus the control condition, and resulted in 87% (vs. 19%) of participants remaining active by the third week.","Participants reported that commitment provided safe cover for them to post even when they were nervous.","Through this work, we argue that more effortful, not less effortful, membership may support many online groups."],"url":"http://arxiv.org/abs/2410.23267v1"}
{"created":"2024-10-30 17:50:23","title":"TOMATO: Assessing Visual Temporal Reasoning Capabilities in Multimodal Foundation Models","abstract":"Existing benchmarks often highlight the remarkable performance achieved by state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal context for video understanding. However, how well do the models truly perform visual temporal reasoning? Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single, few, or out-of-order frames. To systematically examine current visual temporal reasoning tasks, we propose three principles with corresponding metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame Information Disparity. Following these principles, we introduce TOMATO, Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to rigorously assess MFMs' temporal reasoning capabilities in video understanding. TOMATO comprises 1,484 carefully curated, human-annotated questions spanning six tasks (i.e., action count, direction, rotation, shape & trend, velocity & frequency, and visual cues), applied to 1,417 videos, including 805 self-recorded and -generated videos, that encompass human-centric, real-world, and simulated scenarios. Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model. Moreover, our in-depth analysis uncovers more fundamental limitations beyond this gap in current MFMs. While they can accurately recognize events in isolated frames, they fail to interpret these frames as a continuous sequence. We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending human world dynamics through the video modality.","sentences":["Existing benchmarks often highlight the remarkable performance achieved by state-of-the-art Multimodal Foundation Models (MFMs) in leveraging temporal context for video understanding.","However, how well do the models truly perform visual temporal reasoning?","Our study of existing benchmarks shows that this capability of MFMs is likely overestimated as many questions can be solved by using a single, few, or out-of-order frames.","To systematically examine current visual temporal reasoning tasks, we propose three principles with corresponding metrics: (1) Multi-Frame Gain, (2) Frame Order Sensitivity, and (3) Frame Information Disparity.","Following these principles, we introduce TOMATO, Temporal Reasoning Multimodal Evaluation, a novel benchmark crafted to rigorously assess MFMs' temporal reasoning capabilities in video understanding.","TOMATO comprises 1,484 carefully curated, human-annotated questions spanning six tasks (i.e., action count, direction, rotation, shape & trend, velocity & frequency, and visual cues), applied to 1,417 videos, including 805 self-recorded and -generated videos, that encompass human-centric, real-world, and simulated scenarios.","Our comprehensive evaluation reveals a human-model performance gap of 57.3% with the best-performing model.","Moreover, our in-depth analysis uncovers more fundamental limitations beyond this gap in current MFMs.","While they can accurately recognize events in isolated frames, they fail to interpret these frames as a continuous sequence.","We believe TOMATO will serve as a crucial testbed for evaluating the next-generation MFMs and as a call to the community to develop AI systems capable of comprehending human world dynamics through the video modality."],"url":"http://arxiv.org/abs/2410.23266v1"}
{"created":"2024-10-30 17:46:31","title":"EMMA: End-to-End Multimodal Model for Autonomous Driving","abstract":"We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving. Built on a multi-modal large language model foundation, EMMA directly maps raw camera sensor data into various driving-specific outputs, including planner trajectories, perception objects, and road graph elements. EMMA maximizes the utility of world knowledge from the pre-trained large language models, by representing all non-sensor inputs (e.g. navigation instructions and ego vehicle status) and outputs (e.g. trajectories and 3D locations) as natural language text. This approach allows EMMA to jointly process various driving tasks in a unified language space, and generate the outputs for each task using task-specific prompts. Empirically, we demonstrate EMMA's effectiveness by achieving state-of-the-art performance in motion planning on nuScenes as well as competitive results on the Waymo Open Motion Dataset (WOMD). EMMA also yields competitive results for camera-primary 3D object detection on the Waymo Open Dataset (WOD). We show that co-training EMMA with planner trajectories, object detection, and road graph tasks yields improvements across all three domains, highlighting EMMA's potential as a generalist model for autonomous driving applications. However, EMMA also exhibits certain limitations: it can process only a small amount of image frames, does not incorporate accurate 3D sensing modalities like LiDAR or radar and is computationally expensive. We hope that our results will inspire further research to mitigate these issues and to further evolve the state of the art in autonomous driving model architectures.","sentences":["We introduce EMMA, an End-to-end Multimodal Model for Autonomous driving.","Built on a multi-modal large language model foundation, EMMA directly maps raw camera sensor data into various driving-specific outputs, including planner trajectories, perception objects, and road graph elements.","EMMA maximizes the utility of world knowledge from the pre-trained large language models, by representing all non-sensor inputs (e.g. navigation instructions and ego vehicle status) and outputs (e.g. trajectories and 3D locations) as natural language text.","This approach allows EMMA to jointly process various driving tasks in a unified language space, and generate the outputs for each task using task-specific prompts.","Empirically, we demonstrate EMMA's effectiveness by achieving state-of-the-art performance in motion planning on nuScenes as well as competitive results on the Waymo Open Motion Dataset (WOMD).","EMMA also yields competitive results for camera-primary 3D object detection on the Waymo Open Dataset (WOD).","We show that co-training EMMA with planner trajectories, object detection, and road graph tasks yields improvements across all three domains, highlighting EMMA's potential as a generalist model for autonomous driving applications.","However, EMMA also exhibits certain limitations: it can process only a small amount of image frames, does not incorporate accurate 3D sensing modalities like LiDAR or radar and is computationally expensive.","We hope that our results will inspire further research to mitigate these issues and to further evolve the state of the art in autonomous driving model architectures."],"url":"http://arxiv.org/abs/2410.23262v1"}
{"created":"2024-10-30 17:46:20","title":"$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources","abstract":"Pre-training is notoriously compute-intensive and academic researchers are notoriously under-resourced. It is, therefore, commonly assumed that academics can't pre-train models. In this paper, we seek to clarify this assumption. We first survey academic researchers to learn about their available compute and then empirically measure the time to replicate models on such resources. We introduce a benchmark to measure the time to pre-train models on given GPUs and also identify ideal settings for maximizing training speed. We run our benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on our experiments. Our results reveal a brighter picture for academic pre-training: for example, although Pythia-1B was originally trained on 64 GPUs for 3 days, we find it is also possible to replicate this model (with the same hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days. We conclude with a cost-benefit analysis to help clarify the trade-offs between price and pre-training time. We believe our benchmark will help academic researchers conduct experiments that require training larger models on more data. We fully release our codebase at: https://github.com/apoorvkh/academic-pretraining.","sentences":["Pre-training is notoriously compute-intensive and academic researchers are notoriously under-resourced.","It is, therefore, commonly assumed that academics can't pre-train models.","In this paper, we seek to clarify this assumption.","We first survey academic researchers to learn about their available compute and then empirically measure the time to replicate models on such resources.","We introduce a benchmark to measure the time to pre-train models on given GPUs and also identify ideal settings for maximizing training speed.","We run our benchmark on a range of models and academic GPUs, spending 2,000 GPU-hours on our experiments.","Our results reveal a brighter picture for academic pre-training: for example, although Pythia-1B was originally trained on 64 GPUs for 3 days, we find it is also possible to replicate this model (with the same hyper-parameters) in 3x fewer GPU-days: i.e. on 4 GPUs in 18 days.","We conclude with a cost-benefit analysis to help clarify the trade-offs between price and pre-training time.","We believe our benchmark will help academic researchers conduct experiments that require training larger models on more data.","We fully release our codebase at: https://github.com/apoorvkh/academic-pretraining."],"url":"http://arxiv.org/abs/2410.23261v1"}
{"created":"2024-10-30 17:37:31","title":"Keypoint Abstraction using Large Models for Object-Relative Imitation Learning","abstract":"Generalization to novel object configurations and instances across diverse tasks and environments is a critical challenge in robotics. Keypoint-based representations have been proven effective as a succinct representation for capturing essential object features, and for establishing a reference frame in action prediction, enabling data-efficient learning of robot skills. However, their manual design nature and reliance on additional human labels limit their scalability. In this paper, we propose KALM, a framework that leverages large pre-trained vision-language models (LMs) to automatically generate task-relevant and cross-instance consistent keypoints. KALM distills robust and consistent keypoints across views and objects by generating proposals using LMs and verifies them against a small set of robot demonstration data. Based on the generated keypoints, we can train keypoint-conditioned policy models that predict actions in keypoint-centric frames, enabling robots to generalize effectively across varying object poses, camera views, and object instances with similar functional shapes. Our method demonstrates strong performance in the real world, adapting to different tasks and environments from only a handful of demonstrations while requiring no additional labels. Website: https://kalm-il.github.io/","sentences":["Generalization to novel object configurations and instances across diverse tasks and environments is a critical challenge in robotics.","Keypoint-based representations have been proven effective as a succinct representation for capturing essential object features, and for establishing a reference frame in action prediction, enabling data-efficient learning of robot skills.","However, their manual design nature and reliance on additional human labels limit their scalability.","In this paper, we propose KALM, a framework that leverages large pre-trained vision-language models (LMs) to automatically generate task-relevant and cross-instance consistent keypoints.","KALM distills robust and consistent keypoints across views and objects by generating proposals using LMs and verifies them against a small set of robot demonstration data.","Based on the generated keypoints, we can train keypoint-conditioned policy models that predict actions in keypoint-centric frames, enabling robots to generalize effectively across varying object poses, camera views, and object instances with similar functional shapes.","Our method demonstrates strong performance in the real world, adapting to different tasks and environments from only a handful of demonstrations while requiring no additional labels.","Website: https://kalm-il.github.io/"],"url":"http://arxiv.org/abs/2410.23254v1"}
{"created":"2024-10-30 17:35:44","title":"Evaluating Cultural and Social Awareness of LLM Web Agents","abstract":"As large language models (LLMs) expand into performing as agents for real-world applications beyond traditional NLP tasks, evaluating their robustness becomes increasingly important. However, existing benchmarks often overlook critical dimensions like cultural and social awareness. To address these, we introduce CASA, a benchmark designed to assess LLM agents' sensitivity to cultural and social norms across two web-based tasks: online shopping and social discussion forums. Our approach evaluates LLM agents' ability to detect and appropriately respond to norm-violating user queries and observations. Furthermore, we propose a comprehensive evaluation framework that measures awareness coverage, helpfulness in managing user queries, and the violation rate when facing misleading web content. Experiments show that current LLMs perform significantly better in non-agent than in web-based agent environments, with agents achieving less than 10% awareness coverage and over 40% violation rates. To improve performance, we explore two methods: prompting and fine-tuning, and find that combining both methods can offer complementary advantages -- fine-tuning on culture-specific datasets significantly enhances the agents' ability to generalize across different regions, while prompting boosts the agents' ability to navigate complex tasks. These findings highlight the importance of constantly benchmarking LLM agents' cultural and social awareness during the development cycle.","sentences":["As large language models (LLMs) expand into performing as agents for real-world applications beyond traditional NLP tasks, evaluating their robustness becomes increasingly important.","However, existing benchmarks often overlook critical dimensions like cultural and social awareness.","To address these, we introduce CASA, a benchmark designed to assess LLM agents' sensitivity to cultural and social norms across two web-based tasks: online shopping and social discussion forums.","Our approach evaluates LLM agents' ability to detect and appropriately respond to norm-violating user queries and observations.","Furthermore, we propose a comprehensive evaluation framework that measures awareness coverage, helpfulness in managing user queries, and the violation rate when facing misleading web content.","Experiments show that current LLMs perform significantly better in non-agent than in web-based agent environments, with agents achieving less than 10% awareness coverage and over 40% violation rates.","To improve performance, we explore two methods: prompting and fine-tuning, and find that combining both methods can offer complementary advantages -- fine-tuning on culture-specific datasets significantly enhances the agents' ability to generalize across different regions, while prompting boosts the agents' ability to navigate complex tasks.","These findings highlight the importance of constantly benchmarking LLM agents' cultural and social awareness during the development cycle."],"url":"http://arxiv.org/abs/2410.23252v1"}
{"created":"2024-10-30 17:29:25","title":"PointRecon: Online Point-based 3D Reconstruction via Ray-based 2D-3D Matching","abstract":"We propose a novel online, point-based 3D reconstruction method from posed monocular RGB videos. Our model maintains a global point cloud representation of the scene, continuously updating the features and 3D locations of points as new images are observed. It expands the point cloud with newly detected points while carefully removing redundancies. The point cloud updates and depth predictions for new points are achieved through a novel ray-based 2D-3D feature matching technique, which is robust against errors in previous point position predictions. In contrast to offline methods, our approach processes infinite-length sequences and provides real-time updates. Additionally, the point cloud imposes no pre-defined resolution or scene size constraints, and its unified global representation ensures view consistency across perspectives. Experiments on the ScanNet dataset show that our method achieves state-of-the-art quality among online MVS approaches. Project page: https://arthurhero.github.io/projects/pointrecon","sentences":["We propose a novel online, point-based 3D reconstruction method from posed monocular RGB videos.","Our model maintains a global point cloud representation of the scene, continuously updating the features and 3D locations of points as new images are observed.","It expands the point cloud with newly detected points while carefully removing redundancies.","The point cloud updates and depth predictions for new points are achieved through a novel ray-based 2D-3D feature matching technique, which is robust against errors in previous point position predictions.","In contrast to offline methods, our approach processes infinite-length sequences and provides real-time updates.","Additionally, the point cloud imposes no pre-defined resolution or scene size constraints, and its unified global representation ensures view consistency across perspectives.","Experiments on the ScanNet dataset show that our method achieves state-of-the-art quality among online MVS approaches.","Project page: https://arthurhero.github.io/projects/pointrecon"],"url":"http://arxiv.org/abs/2410.23245v1"}
{"created":"2024-10-30 17:28:59","title":"Carrot and Stick: Eliciting Comparison Data and Beyond","abstract":"Comparison data elicited from people are fundamental to many machine learning tasks, including reinforcement learning from human feedback for large language models and estimating ranking models. They are typically subjective and not directly verifiable. How to truthfully elicit such comparison data from rational individuals? We design peer prediction mechanisms for eliciting comparison data using a bonus-penalty payment. Our design leverages on the strong stochastic transitivity for comparison data to create symmetrically strongly truthful mechanisms such that truth-telling 1) forms a strict Bayesian Nash equilibrium, and 2) yields the highest payment among all symmetric equilibria. Each individual only needs to evaluate one pair of items and report her comparison in our mechanism.   We further extend the bonus-penalty payment concept to eliciting networked data, designing a symmetrically strongly truthful mechanism when agents' private signals are sampled according to the Ising models. We provide the necessary and sufficient conditions for our bonus-penalty payment to have truth-telling as a strict Bayesian Nash equilibrium. Experiments on two real-world datasets further support our theoretical discoveries.","sentences":["Comparison data elicited from people are fundamental to many machine learning tasks, including reinforcement learning from human feedback for large language models and estimating ranking models.","They are typically subjective and not directly verifiable.","How to truthfully elicit such comparison data from rational individuals?","We design peer prediction mechanisms for eliciting comparison data using a bonus-penalty payment.","Our design leverages on the strong stochastic transitivity for comparison data to create symmetrically strongly truthful mechanisms such that truth-telling 1) forms a strict Bayesian Nash equilibrium, and 2) yields the highest payment among all symmetric equilibria.","Each individual only needs to evaluate one pair of items and report her comparison in our mechanism.   ","We further extend the bonus-penalty payment concept to eliciting networked data, designing a symmetrically strongly truthful mechanism when agents' private signals are sampled according to the Ising models.","We provide the necessary and sufficient conditions for our bonus-penalty payment to have truth-telling as a strict Bayesian Nash equilibrium.","Experiments on two real-world datasets further support our theoretical discoveries."],"url":"http://arxiv.org/abs/2410.23243v1"}
{"created":"2024-10-30 17:28:28","title":"A little less conversation, a little more action, please: Investigating the physical common-sense of LLMs in a 3D embodied environment","abstract":"As general-purpose tools, Large Language Models (LLMs) must often reason about everyday physical environments. In a question-and-answer capacity, understanding the interactions of physical objects may be necessary to give appropriate responses. Moreover, LLMs are increasingly used as reasoning engines in agentic systems, designing and controlling their action sequences. The vast majority of research has tackled this issue using static benchmarks, comprised of text or image-based questions about the physical world. However, these benchmarks do not capture the complexity and nuance of real-life physical processes. Here we advocate for a second, relatively unexplored, approach: 'embodying' the LLMs by granting them control of an agent within a 3D environment. We present the first embodied and cognitively meaningful evaluation of physical common-sense reasoning in LLMs. Our framework allows direct comparison of LLMs with other embodied agents, such as those based on Deep Reinforcement Learning, and human and non-human animals. We employ the Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study physical common-sense reasoning in LLMs. For this, we use the AAI Testbed, a suite of experiments that replicate laboratory studies with non-human animals, to study physical reasoning capabilities including distance estimation, tracking out-of-sight objects, and tool use. We demonstrate that state-of-the-art multi-modal models with no finetuning can complete this style of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI Olympics competition and to human children. Our results show that LLMs are currently outperformed by human children on these tasks. We argue that this approach allows the study of physical reasoning using ecologically valid experiments drawn directly from cognitive science, improving the predictability and reliability of LLMs.","sentences":["As general-purpose tools, Large Language Models (LLMs) must often reason about everyday physical environments.","In a question-and-answer capacity, understanding the interactions of physical objects may be necessary to give appropriate responses.","Moreover, LLMs are increasingly used as reasoning engines in agentic systems, designing and controlling their action sequences.","The vast majority of research has tackled this issue using static benchmarks, comprised of text or image-based questions about the physical world.","However, these benchmarks do not capture the complexity and nuance of real-life physical processes.","Here we advocate for a second, relatively unexplored, approach: 'embodying' the LLMs by granting them control of an agent within a 3D environment.","We present the first embodied and cognitively meaningful evaluation of physical common-sense reasoning in LLMs.","Our framework allows direct comparison of LLMs with other embodied agents, such as those based on Deep Reinforcement Learning, and human and non-human animals.","We employ the Animal-AI (AAI) environment, a simulated 3D virtual laboratory, to study physical common-sense reasoning in LLMs.","For this, we use the AAI Testbed, a suite of experiments that replicate laboratory studies with non-human animals, to study physical reasoning capabilities including distance estimation, tracking out-of-sight objects, and tool use.","We demonstrate that state-of-the-art multi-modal models with no finetuning can complete this style of task, allowing meaningful comparison to the entrants of the 2019 Animal-AI Olympics competition and to human children.","Our results show that LLMs are currently outperformed by human children on these tasks.","We argue that this approach allows the study of physical reasoning using ecologically valid experiments drawn directly from cognitive science, improving the predictability and reliability of LLMs."],"url":"http://arxiv.org/abs/2410.23242v1"}
{"created":"2024-10-30 17:26:32","title":"CRAFT@Large: Building Community Through Co-Making","abstract":"CRAFT@Large (C@L) is an initiative launched by the MakerLAB at Cornell Tech to create an inclusive environment for the intercultural and intergenerational exchange of ideas through making. With our approach, we challenge the traditional definition of community outreach performed by academic makerspaces. Existing academic makerspaces often perform community engagement by only offering hourly, one-time workshops or by having community members provide a problem that is then used by students as a project assignment. These approaches position community members as occasional visitors and non-equal contributors, which not only conflict with the core values of co-creation but also limit the makerspaces' impact on connecting the universities and the communities. C@L explored an alternative approach in which we invited community members as long-term and equal co-makers into the academic makerspaces. In this article, we showcase two sets of collaborations that illustrate the continuity of people through co-making. We present how academic makerspaces can function as a hub that connects community members and partner organizations with the campus community in a long-term relationship.","sentences":["CRAFT@Large (C@L) is an initiative launched by the MakerLAB at Cornell Tech to create an inclusive environment for the intercultural and intergenerational exchange of ideas through making.","With our approach, we challenge the traditional definition of community outreach performed by academic makerspaces.","Existing academic makerspaces often perform community engagement by only offering hourly, one-time workshops or by having community members provide a problem that is then used by students as a project assignment.","These approaches position community members as occasional visitors and non-equal contributors, which not only conflict with the core values of co-creation but also limit the makerspaces' impact on connecting the universities and the communities.","C@L explored an alternative approach in which we invited community members as long-term and equal co-makers into the academic makerspaces.","In this article, we showcase two sets of collaborations that illustrate the continuity of people through co-making.","We present how academic makerspaces can function as a hub that connects community members and partner organizations with the campus community in a long-term relationship."],"url":"http://arxiv.org/abs/2410.23239v1"}
{"created":"2024-10-30 17:22:45","title":"EMOTION: Expressive Motion Sequence Generation for Humanoid Robots with In-Context Learning","abstract":"This paper introduces a framework, called EMOTION, for generating expressive motion sequences in humanoid robots, enhancing their ability to engage in humanlike non-verbal communication. Non-verbal cues such as facial expressions, gestures, and body movements play a crucial role in effective interpersonal interactions. Despite the advancements in robotic behaviors, existing methods often fall short in mimicking the diversity and subtlety of human non-verbal communication. To address this gap, our approach leverages the in-context learning capability of large language models (LLMs) to dynamically generate socially appropriate gesture motion sequences for human-robot interaction. We use this framework to generate 10 different expressive gestures and conduct online user studies comparing the naturalness and understandability of the motions generated by EMOTION and its human-feedback version, EMOTION++, against those by human operators. The results demonstrate that our approach either matches or surpasses human performance in generating understandable and natural robot motions under certain scenarios. We also provide design implications for future research to consider a set of variables when generating expressive robotic gestures.","sentences":["This paper introduces a framework, called EMOTION, for generating expressive motion sequences in humanoid robots, enhancing their ability to engage in humanlike non-verbal communication.","Non-verbal cues such as facial expressions, gestures, and body movements play a crucial role in effective interpersonal interactions.","Despite the advancements in robotic behaviors, existing methods often fall short in mimicking the diversity and subtlety of human non-verbal communication.","To address this gap, our approach leverages the in-context learning capability of large language models (LLMs) to dynamically generate socially appropriate gesture motion sequences for human-robot interaction.","We use this framework to generate 10 different expressive gestures and conduct online user studies comparing the naturalness and understandability of the motions generated by EMOTION and its human-feedback version, EMOTION++, against those by human operators.","The results demonstrate that our approach either matches or surpasses human performance in generating understandable and natural robot motions under certain scenarios.","We also provide design implications for future research to consider a set of variables when generating expressive robotic gestures."],"url":"http://arxiv.org/abs/2410.23234v1"}
{"created":"2024-10-30 17:20:10","title":"Attribute-to-Delete: Machine Unlearning via Datamodel Matching","abstract":"Machine unlearning -- efficiently removing the effect of a small \"forget set\" of training data on a pre-trained machine learning model -- has recently attracted significant research interest. Despite this interest, however, recent work shows that existing machine unlearning techniques do not hold up to thorough evaluation in non-convex settings. In this work, we introduce a new machine unlearning technique that exhibits strong empirical performance even in such challenging settings. Our starting point is the perspective that the goal of unlearning is to produce a model whose outputs are statistically indistinguishable from those of a model re-trained on all but the forget set. This perspective naturally suggests a reduction from the unlearning problem to that of data attribution, where the goal is to predict the effect of changing the training set on a model's outputs. Thus motivated, we propose the following meta-algorithm, which we call Datamodel Matching (DMM): given a trained model, we (a) use data attribution to predict the output of the model if it were re-trained on all but the forget set points; then (b) fine-tune the pre-trained model to match these predicted outputs. In a simple convex setting, we show how this approach provably outperforms a variety of iterative unlearning algorithms. Empirically, we use a combination of existing evaluations and a new metric based on the KL-divergence to show that even in non-convex settings, DMM achieves strong unlearning performance relative to existing algorithms. An added benefit of DMM is that it is a meta-algorithm, in the sense that future advances in data attribution translate directly into better unlearning algorithms, pointing to a clear direction for future progress in unlearning.","sentences":["Machine unlearning -- efficiently removing the effect of a small \"forget set\" of training data on a pre-trained machine learning model -- has recently attracted significant research interest.","Despite this interest, however, recent work shows that existing machine unlearning techniques do not hold up to thorough evaluation in non-convex settings.","In this work, we introduce a new machine unlearning technique that exhibits strong empirical performance even in such challenging settings.","Our starting point is the perspective that the goal of unlearning is to produce a model whose outputs are statistically indistinguishable from those of a model re-trained on all but the forget set.","This perspective naturally suggests a reduction from the unlearning problem to that of data attribution, where the goal is to predict the effect of changing the training set on a model's outputs.","Thus motivated, we propose the following meta-algorithm, which we call Datamodel Matching (DMM): given a trained model, we (a) use data attribution to predict the output of the model if it were re-trained on all but the forget set points; then (b) fine-tune the pre-trained model to match these predicted outputs.","In a simple convex setting, we show how this approach provably outperforms a variety of iterative unlearning algorithms.","Empirically, we use a combination of existing evaluations and a new metric based on the KL-divergence to show that even in non-convex settings, DMM achieves strong unlearning performance relative to existing algorithms.","An added benefit of DMM is that it is a meta-algorithm, in the sense that future advances in data attribution translate directly into better unlearning algorithms, pointing to a clear direction for future progress in unlearning."],"url":"http://arxiv.org/abs/2410.23232v1"}
{"created":"2024-10-30 17:20:08","title":"LGU-SLAM: Learnable Gaussian Uncertainty Matching with Deformable Correlation Sampling for Deep Visual SLAM","abstract":"Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g., DROID, have made significant advancements by leveraging deep visual odometry on dense flow fields. In general, they heavily rely on global visual similarity matching. However, the ambiguous similarity interference in uncertain regions could often lead to excessive noise in correspondences, ultimately misleading SLAM in geometric modeling. To address this issue, we propose a Learnable Gaussian Uncertainty (LGU) matching. It mainly focuses on precise correspondence construction. In our scheme, a learnable 2D Gaussian uncertainty model is designed to associate matching-frame pairs. It could generate input-dependent Gaussian distributions for each correspondence map. Additionally, a multi-scale deformable correlation sampling strategy is devised to adaptively fine-tune the sampling of each direction by a priori look-up ranges, enabling reliable correlation construction. Furthermore, a KAN-bias GRU component is adopted to improve a temporal iterative enhancement for accomplishing sophisticated spatio-temporal modeling with limited parameters. The extensive experiments on real-world and synthetic datasets are conducted to validate the effectiveness and superiority of our method.","sentences":["Deep visual Simultaneous Localization and Mapping (SLAM) techniques, e.g., DROID, have made significant advancements by leveraging deep visual odometry on dense flow fields.","In general, they heavily rely on global visual similarity matching.","However, the ambiguous similarity interference in uncertain regions could often lead to excessive noise in correspondences, ultimately misleading SLAM in geometric modeling.","To address this issue, we propose a Learnable Gaussian Uncertainty (LGU) matching.","It mainly focuses on precise correspondence construction.","In our scheme, a learnable 2D Gaussian uncertainty model is designed to associate matching-frame pairs.","It could generate input-dependent Gaussian distributions for each correspondence map.","Additionally, a multi-scale deformable correlation sampling strategy is devised to adaptively fine-tune the sampling of each direction by a priori look-up ranges, enabling reliable correlation construction.","Furthermore, a KAN-bias GRU component is adopted to improve a temporal iterative enhancement for accomplishing sophisticated spatio-temporal modeling with limited parameters.","The extensive experiments on real-world and synthetic datasets are conducted to validate the effectiveness and superiority of our method."],"url":"http://arxiv.org/abs/2410.23231v1"}
{"created":"2024-10-30 17:18:53","title":"Aligning Audio-Visual Joint Representations with an Agentic Workflow","abstract":"Visual content and accompanied audio signals naturally formulate a joint representation to improve audio-visual (AV) related applications. While studies develop various AV representation learning frameworks, the importance of AV data alignment is usually undermined for achieving high-quality representation. We observe that an audio signal may contain background noise interference. Also, non-synchronization may appear between audio and video streams. These non-strict data alignment limits representation quality and downgrade application performance. In this paper, we propose to improve AV joint representations from a data-centric perspective by aligning audio signals to visual data. Our alignment is conducted in an agentic workflow controlled by an LLM-based assistant named AVAgent. For each input AV data pair, our AVAgent uses a multi-modal LLM to convert audio and visual data into language descriptions separately (i.e., tool use). Then, AVAgent reasons whether this paired data is aligned well and plans to edit the audio signal if needed (i.e., planning). The audio editing is executed by predefined actions that filter noise or augment data. Moreover, we use a VLM to evaluate how modified audio signals match the visual content and provide feedback to AVAgent (i.e., reflection). The tool use, planning, and reflection steps operate cyclically to become an agentic workflow where audio signals are gradually aligned to visual content. To this end, existing methods can directly leverage the aligned AV data via our agentic workflow to improve AV joint representations. The experimental results comprehensively demonstrate the state-of-the-art performance of the proposed approach against previous baselines in diverse downstream tasks.","sentences":["Visual content and accompanied audio signals naturally formulate a joint representation to improve audio-visual (AV) related applications.","While studies develop various AV representation learning frameworks, the importance of AV data alignment is usually undermined for achieving high-quality representation.","We observe that an audio signal may contain background noise interference.","Also, non-synchronization may appear between audio and video streams.","These non-strict data alignment limits representation quality and downgrade application performance.","In this paper, we propose to improve AV joint representations from a data-centric perspective by aligning audio signals to visual data.","Our alignment is conducted in an agentic workflow controlled by an LLM-based assistant named AVAgent.","For each input AV data pair, our AVAgent uses a multi-modal LLM to convert audio and visual data into language descriptions separately (i.e., tool use).","Then, AVAgent reasons whether this paired data is aligned well and plans to edit the audio signal if needed (i.e., planning).","The audio editing is executed by predefined actions that filter noise or augment data.","Moreover, we use a VLM to evaluate how modified audio signals match the visual content and provide feedback to AVAgent (i.e., reflection).","The tool use, planning, and reflection steps operate cyclically to become an agentic workflow where audio signals are gradually aligned to visual content.","To this end, existing methods can directly leverage the aligned AV data via our agentic workflow to improve AV joint representations.","The experimental results comprehensively demonstrate the state-of-the-art performance of the proposed approach against previous baselines in diverse downstream tasks."],"url":"http://arxiv.org/abs/2410.23230v1"}
{"created":"2024-10-30 17:16:38","title":"Emergence of meta-stable clustering in mean-field transformer models","abstract":"We model the evolution of tokens within a deep stack of Transformer layers as a continuous-time flow on the unit sphere, governed by a mean-field interacting particle system, building on the framework introduced in (Geshkovski et al., 2023). Studying the corresponding mean-field Partial Differential Equation (PDE), which can be interpreted as a Wasserstein gradient flow, in this paper we provide a mathematical investigation of the long-term behavior of this system, with a particular focus on the emergence and persistence of meta-stable phases and clustering phenomena, key elements in applications like next-token prediction. More specifically, we perform a perturbative analysis of the mean-field PDE around the iid uniform initialization and prove that, in the limit of large number of tokens, the model remains close to a meta-stable manifold of solutions with a given structure (e.g., periodicity). Further, the structure characterizing the meta-stable manifold is explicitly identified, as a function of the inverse temperature parameter of the model, by the index maximizing a certain rescaling of Gegenbauer polynomials.","sentences":["We model the evolution of tokens within a deep stack of Transformer layers as a continuous-time flow on the unit sphere, governed by a mean-field interacting particle system, building on the framework introduced in (Geshkovski et al., 2023).","Studying the corresponding mean-field Partial Differential Equation (PDE), which can be interpreted as a Wasserstein gradient flow, in this paper we provide a mathematical investigation of the long-term behavior of this system, with a particular focus on the emergence and persistence of meta-stable phases and clustering phenomena, key elements in applications like next-token prediction.","More specifically, we perform a perturbative analysis of the mean-field PDE around the iid uniform initialization and prove that, in the limit of large number of tokens, the model remains close to a meta-stable manifold of solutions with a given structure (e.g., periodicity).","Further, the structure characterizing the meta-stable manifold is explicitly identified, as a function of the inverse temperature parameter of the model, by the index maximizing a certain rescaling of Gegenbauer polynomials."],"url":"http://arxiv.org/abs/2410.23228v1"}
{"created":"2024-10-30 17:15:02","title":"(FL)$^2$: Overcoming Few Labels in Federated Semi-Supervised Learning","abstract":"Federated Learning (FL) is a distributed machine learning framework that trains accurate global models while preserving clients' privacy-sensitive data. However, most FL approaches assume that clients possess labeled data, which is often not the case in practice. Federated Semi-Supervised Learning (FSSL) addresses this label deficiency problem, targeting situations where only the server has a small amount of labeled data while clients do not. However, a significant performance gap exists between Centralized Semi-Supervised Learning (SSL) and FSSL. This gap arises from confirmation bias, which is more pronounced in FSSL due to multiple local training epochs and the separation of labeled and unlabeled data. We propose $(FL)^2$, a robust training method for unlabeled clients using sharpness-aware consistency regularization. We show that regularizing the original pseudo-labeling loss is suboptimal, and hence we carefully select unlabeled samples for regularization. We further introduce client-specific adaptive thresholding and learning status-aware aggregation to adjust the training process based on the learning progress of each client. Our experiments on three benchmark datasets demonstrate that our approach significantly improves performance and bridges the gap with SSL, particularly in scenarios with scarce labeled data.","sentences":["Federated Learning (FL) is a distributed machine learning framework that trains accurate global models while preserving clients' privacy-sensitive data.","However, most FL approaches assume that clients possess labeled data, which is often not the case in practice.","Federated Semi-Supervised Learning (FSSL) addresses this label deficiency problem, targeting situations where only the server has a small amount of labeled data while clients do not.","However, a significant performance gap exists between Centralized Semi-Supervised Learning (SSL) and FSSL.","This gap arises from confirmation bias, which is more pronounced in FSSL due to multiple local training epochs and the separation of labeled and unlabeled data.","We propose $(FL)^2$, a robust training method for unlabeled clients using sharpness-aware consistency regularization.","We show that regularizing the original pseudo-labeling loss is suboptimal, and hence we carefully select unlabeled samples for regularization.","We further introduce client-specific adaptive thresholding and learning status-aware aggregation to adjust the training process based on the learning progress of each client.","Our experiments on three benchmark datasets demonstrate that our approach significantly improves performance and bridges the gap with SSL, particularly in scenarios with scarce labeled data."],"url":"http://arxiv.org/abs/2410.23227v1"}
{"created":"2024-10-30 17:14:54","title":"Deterministic counting from coupling independence","abstract":"We show that spin systems with bounded degrees and coupling independence admit fully polynomial time approximation schemes (FPTAS). We design a new recursive deterministic counting algorithm to achieve this. As applications, we give the first FPTASes for $q$-colourings on graphs of bounded maximum degree $\\Delta\\ge 3$, when $q\\ge (11/6-\\varepsilon_0)\\Delta$ for some small $\\varepsilon_0\\approx 10^{-5}$, or when $\\Delta\\ge 125$ and $q\\ge 1.809\\Delta$, and on graphs with sufficiently large (but constant) girth, when $q\\geq\\Delta+3$. These bounds match the current best randomised approximate counting algorithms by Chen, Delcourt, Moitra, Perarnau, and Postle (2019), Carlson and Vigoda (2024), and Chen, Liu, Mani, and Moitra (2023), respectively.","sentences":["We show that spin systems with bounded degrees and coupling independence admit fully polynomial time approximation schemes (FPTAS).","We design a new recursive deterministic counting algorithm to achieve this.","As applications, we give the first FPTASes for $q$-colourings on graphs of bounded maximum degree $\\Delta\\ge 3$, when $q\\ge (11/6-\\varepsilon_0)\\Delta$ for some small $\\varepsilon_0\\approx 10^{-5}$, or when $\\Delta\\ge 125$ and $q\\ge 1.809\\Delta$, and on graphs with sufficiently large (but constant) girth, when $q\\geq\\Delta+3$. These bounds match the current best randomised approximate counting algorithms by Chen, Delcourt, Moitra, Perarnau, and Postle (2019), Carlson and Vigoda (2024), and Chen, Liu, Mani, and Moitra (2023), respectively."],"url":"http://arxiv.org/abs/2410.23225v1"}
{"created":"2024-10-30 17:13:02","title":"COMAL: A Convergent Meta-Algorithm for Aligning LLMs with General Preferences","abstract":"Many alignment methods, including reinforcement learning from human feedback (RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to capture the full range of general human preferences. To achieve robust alignment with general preferences, we model the alignment problem as a two-player zero-sum game, where the Nash equilibrium policy guarantees a 50% win rate against any competing policy. However, previous algorithms for finding the Nash policy either diverge or converge to a Nash policy in a modified game, even in a simple synthetic setting, thereby failing to maintain the 50% win rate guarantee against all other policies. We propose a meta-algorithm, Convergent Meta Alignment Algorithm (COMAL), for language model alignment with general preferences, inspired by convergent algorithms in game theory. Theoretically, we prove that our meta-algorithm converges to an exact Nash policy in the last iterate. Additionally, our meta-algorithm is simple and can be integrated with many existing methods designed for RLHF and preference optimization with minimal changes. Experimental results demonstrate the effectiveness of the proposed framework when combined with existing preference policy optimization methods.","sentences":["Many alignment methods, including reinforcement learning from human feedback (RLHF), rely on the Bradley-Terry reward assumption, which is insufficient to capture the full range of general human preferences.","To achieve robust alignment with general preferences, we model the alignment problem as a two-player zero-sum game, where the Nash equilibrium policy guarantees a 50% win rate against any competing policy.","However, previous algorithms for finding the Nash policy either diverge or converge to a Nash policy in a modified game, even in a simple synthetic setting, thereby failing to maintain the 50% win rate guarantee against all other policies.","We propose a meta-algorithm, Convergent Meta Alignment Algorithm (COMAL), for language model alignment with general preferences, inspired by convergent algorithms in game theory.","Theoretically, we prove that our meta-algorithm converges to an exact Nash policy in the last iterate.","Additionally, our meta-algorithm is simple and can be integrated with many existing methods designed for RLHF and preference optimization with minimal changes.","Experimental results demonstrate the effectiveness of the proposed framework when combined with existing preference policy optimization methods."],"url":"http://arxiv.org/abs/2410.23223v1"}
{"created":"2024-10-30 17:12:03","title":"Partial Channel Dependence with Channel Masks for Time Series Foundation Models","abstract":"Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets. However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels. In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information. To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix. We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models. Code is available at https://github.com/seunghan96/CM.","sentences":["Recent advancements in foundation models have been successfully extended to the time series (TS) domain, facilitated by the emergence of large-scale TS datasets.","However, previous efforts have primarily focused on designing model architectures to address explicit heterogeneity among datasets such as various numbers of channels, while often overlooking implicit heterogeneity such as varying dependencies between channels.","In this work, we introduce the concept of partial channel dependence (PCD), which enables a more sophisticated adjustment of channel dependencies based on dataset-specific information.","To achieve PCD, we propose a channel mask that captures the relationships between channels within a dataset using two key components: 1) a correlation matrix that encodes relative dependencies between channels, and 2) domain parameters that learn the absolute dependencies specific to each dataset, refining the correlation matrix.","We validate the effectiveness of PCD across four tasks in TS including forecasting, classification, imputation, and anomaly detection, under diverse settings, including few-shot and zero-shot scenarios with both TS foundation models and single-task models.","Code is available at https://github.com/seunghan96/CM."],"url":"http://arxiv.org/abs/2410.23222v1"}
{"created":"2024-10-30 17:11:00","title":"DiaMond: Dementia Diagnosis with Multi-Modal Vision Transformers Using MRI and PET","abstract":"Diagnosing dementia, particularly for Alzheimer's Disease (AD) and frontotemporal dementia (FTD), is complex due to overlapping symptoms. While magnetic resonance imaging (MRI) and positron emission tomography (PET) data are critical for the diagnosis, integrating these modalities in deep learning faces challenges, often resulting in suboptimal performance compared to using single modalities. Moreover, the potential of multi-modal approaches in differential diagnosis, which holds significant clinical importance, remains largely unexplored. We propose a novel framework, DiaMond, to address these issues with vision Transformers to effectively integrate MRI and PET. DiaMond is equipped with self-attention and a novel bi-attention mechanism that synergistically combine MRI and PET, alongside a multi-modal normalization to reduce redundant dependency, thereby boosting the performance. DiaMond significantly outperforms existing multi-modal methods across various datasets, achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN classification, and 76.5% in differential diagnosis of AD and FTD. We also validated the robustness of DiaMond in a comprehensive ablation study. The code is available at https://github.com/ai-med/DiaMond.","sentences":["Diagnosing dementia, particularly for Alzheimer's Disease (AD) and frontotemporal dementia (FTD), is complex due to overlapping symptoms.","While magnetic resonance imaging (MRI) and positron emission tomography (PET) data are critical for the diagnosis, integrating these modalities in deep learning faces challenges, often resulting in suboptimal performance compared to using single modalities.","Moreover, the potential of multi-modal approaches in differential diagnosis, which holds significant clinical importance, remains largely unexplored.","We propose a novel framework, DiaMond, to address these issues with vision Transformers to effectively integrate MRI and PET.","DiaMond is equipped with self-attention and a novel bi-attention mechanism that synergistically combine MRI and PET, alongside a multi-modal normalization to reduce redundant dependency, thereby boosting the performance.","DiaMond significantly outperforms existing multi-modal methods across various datasets, achieving a balanced accuracy of 92.4% in AD diagnosis, 65.2% for AD-MCI-CN classification, and 76.5% in differential diagnosis of AD and FTD.","We also validated the robustness of DiaMond in a comprehensive ablation study.","The code is available at https://github.com/ai-med/DiaMond."],"url":"http://arxiv.org/abs/2410.23219v1"}
{"created":"2024-10-30 17:10:19","title":"OS-ATLAS: A Foundation Action Model for Generalist GUI Agents","abstract":"Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision. Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios. To facilitate future research in this area, we developed OS-Atlas - a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling. We have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web. Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements. This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces. Through extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models. Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs.","sentences":["Existing efforts in building GUI agents heavily rely on the availability of robust commercial Vision-Language Models (VLMs) such as GPT-4o and GeminiProVision.","Practitioners are often reluctant to use open-source VLMs due to their significant performance lag compared to their closed-source counterparts, particularly in GUI grounding and Out-Of-Distribution (OOD) scenarios.","To facilitate future research in this area, we developed OS-Atlas - a foundational GUI action model that excels at GUI grounding and OOD agentic tasks through innovations in both data and modeling.","We have invested significant engineering effort in developing an open-source toolkit for synthesizing GUI grounding data across multiple platforms, including Windows, Linux, MacOS, Android, and the web.","Leveraging this toolkit, we are releasing the largest open-source cross-platform GUI grounding corpus to date, which contains over 13 million GUI elements.","This dataset, combined with innovations in model training, provides a solid foundation for OS-Atlas to understand GUI screenshots and generalize to unseen interfaces.","Through extensive evaluation across six benchmarks spanning three different platforms (mobile, desktop, and web), OS-Atlas demonstrates significant performance improvements over previous state-of-the-art models.","Our evaluation also uncovers valuable insights into continuously improving and scaling the agentic capabilities of open-source VLMs."],"url":"http://arxiv.org/abs/2410.23218v1"}
{"created":"2024-10-30 17:03:27","title":"Levels of explanation -- implementation and evaluation of what and when for different time-sensitive tasks","abstract":"In this work, we focused on constructing and evaluating levels of explanation(LOE) that address two basic aspect of HRI: 1. What information should be communicated to the user by the robot? 2. When should the robot communicate this information? For constructing the LOE, we defined two terms, verbosity and explanation patterns, each with two levels (verbosity -- high and low, explanation patterns -- dynamic and static). Based on these parameters, three different LOE (high, medium, and low) were constructed and evaluated in a user study with a telepresence robot. The user study was conducted for a simulated telerobotic healthcare task with two different conditions related to time sensitivity, as evaluated by two different user groups -- one that performed the task within a time limit and the other with no time limit. We found that the high LOE was preferred in terms of adequacy of explanation, number of collisions, number of incorrect movements, and number of clarifications when users performed the experiment in the without time limit condition. We also found that both high and medium LOE did not have significant differences in completion time, the fluency of HRI, and trust in the robot. When users performed the experiment in the with time limit condition, high and medium LOE had better task performances and were preferred to the low LOE in terms of completion time, fluency, adequacy of explanation, trust, number of collisions, number of incorrect movements and number of clarifications. Future directions for advancing LOE are discussed.","sentences":["In this work, we focused on constructing and evaluating levels of explanation(LOE) that address two basic aspect of HRI:","1.","What information should be communicated to the user by the robot?","2.","When should the robot communicate this information?","For constructing the LOE, we defined two terms, verbosity and explanation patterns, each with two levels (verbosity -- high and low, explanation patterns -- dynamic and static).","Based on these parameters, three different LOE (high, medium, and low) were constructed and evaluated in a user study with a telepresence robot.","The user study was conducted for a simulated telerobotic healthcare task with two different conditions related to time sensitivity, as evaluated by two different user groups -- one that performed the task within a time limit and the other with no time limit.","We found that the high LOE was preferred in terms of adequacy of explanation, number of collisions, number of incorrect movements, and number of clarifications when users performed the experiment in the without time limit condition.","We also found that both high and medium LOE did not have significant differences in completion time, the fluency of HRI, and trust in the robot.","When users performed the experiment in the with time limit condition, high and medium LOE had better task performances and were preferred to the low LOE in terms of completion time, fluency, adequacy of explanation, trust, number of collisions, number of incorrect movements and number of clarifications.","Future directions for advancing LOE are discussed."],"url":"http://arxiv.org/abs/2410.23215v1"}
{"created":"2024-10-30 17:02:54","title":"Grounding by Trying: LLMs with Reinforcement Learning-Enhanced Retrieval","abstract":"The hallucinations of large language models (LLMs) are increasingly mitigated by allowing LLMs to search for information and to ground their answers in real sources. Unfortunately, LLMs often struggle with posing the right search queries, especially when dealing with complex or otherwise indirect topics. Observing that LLMs can learn to search for relevant facts by $\\textit{trying}$ different queries and learning to up-weight queries that successfully produce relevant results, we introduce $\\underline{Le}$arning to $\\underline{Re}$trieve by $\\underline{T}$rying (LeReT), a reinforcement learning framework that explores search queries and uses preference-based optimization to improve their quality. \\methodclass can improve the absolute retrieval accuracy by up to 29\\% and the downstream generator evaluations by 17\\%. The simplicity and flexibility of LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes it a promising technique for improving general LLM pipelines. Project website: http://sherylhsu.com/LeReT/.","sentences":["The hallucinations of large language models (LLMs) are increasingly mitigated by allowing LLMs to search for information and to ground their answers in real sources.","Unfortunately, LLMs often struggle with posing the right search queries, especially when dealing with complex or otherwise indirect topics.","Observing that LLMs can learn to search for relevant facts by $\\textit{trying}$ different queries and learning to up-weight queries that successfully produce relevant results, we introduce $\\underline{Le}$arning to $\\underline{Re}$trieve by $\\underline{T}$rying (LeReT), a reinforcement learning framework that explores search queries and uses preference-based optimization to improve their quality.","\\methodclass can improve the absolute retrieval accuracy by up to 29\\% and the downstream generator evaluations by 17\\%.","The simplicity and flexibility of LeReT allows it to be applied to arbitrary off-the-shelf retrievers and makes it a promising technique for improving general LLM pipelines.","Project website: http://sherylhsu.com/LeReT/."],"url":"http://arxiv.org/abs/2410.23214v1"}
{"created":"2024-10-30 17:01:28","title":"ELMGS: Enhancing memory and computation scaLability through coMpression for 3D Gaussian Splatting","abstract":"3D models have recently been popularized by the potentiality of end-to-end training offered first by Neural Radiance Fields and most recently by 3D Gaussian Splatting models. The latter has the big advantage of naturally providing fast training convergence and high editability. However, as the research around these is still in its infancy, there is still a gap in the literature regarding the model's scalability. In this work, we propose an approach enabling both memory and computation scalability of such models. More specifically, we propose an iterative pruning strategy that removes redundant information encoded in the model. We also enhance compressibility for the model by including in the optimization strategy a differentiable quantization and entropy coding estimator. Our results on popular benchmarks showcase the effectiveness of the proposed approach and open the road to the broad deployability of such a solution even on resource-constrained devices.","sentences":["3D models have recently been popularized by the potentiality of end-to-end training offered first by Neural Radiance Fields and most recently by 3D Gaussian Splatting models.","The latter has the big advantage of naturally providing fast training convergence and high editability.","However, as the research around these is still in its infancy, there is still a gap in the literature regarding the model's scalability.","In this work, we propose an approach enabling both memory and computation scalability of such models.","More specifically, we propose an iterative pruning strategy that removes redundant information encoded in the model.","We also enhance compressibility for the model by including in the optimization strategy a differentiable quantization and entropy coding estimator.","Our results on popular benchmarks showcase the effectiveness of the proposed approach and open the road to the broad deployability of such a solution even on resource-constrained devices."],"url":"http://arxiv.org/abs/2410.23213v1"}
{"created":"2024-10-30 16:59:41","title":"Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks","abstract":"While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge. In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control. To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework. Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training. Our trained agent exhibits strong physical reasoning capabilities, being able to zero-shot solve unseen human-designed environments. Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*. This includes solving some environments that standard RL training completely fails at. We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.","sentences":["While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge.","In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control.","To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework.","Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.","Our trained agent exhibits strong physical reasoning capabilities, being able to zero-shot solve unseen human-designed environments.","Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*.","This includes solving some environments that standard RL training completely fails at.","We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further."],"url":"http://arxiv.org/abs/2410.23208v1"}
{"created":"2024-10-30 16:56:06","title":"Resilient-By-Design: A Resiliency Framework for Future Wireless Networks","abstract":"Our future society will be increasingly digitalised, hyper-connected and globally data driven. The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, including industries, smart cities, eHealth and autonomous transportation. Such far reaching integration will render the society increasingly reliant on wireless networks. While this has the potential to greatly enhance our quality and ease of life, any disruption to these networks would also have significant impact with overreaching consequences. Disruptions can happen due to a variety of reasons, including planned outages, failures due to the nature of wireless propagation, natural disasters, and deliberate cybersecurity attacks. Hence, 6G and beyond 6G networks should not only provide near instant and virtually unlimited connectivity, but also be resilient against internal and external disruptions. This paper proposes a resilient-by-design framework towards this end. First, we provide an overview of the disruption landscape. Thereafter, we comprehensively outline the main features of the proposed concept. Finally, we detail the four key steps of the framework, namely predict, preempt, protect and progress. A simple but illustrative preliminary simulation result is also presented to highlight the potential advantages and efficiency of the proposed approach in addressing outages.","sentences":["Our future society will be increasingly digitalised, hyper-connected and globally data driven.","The sixth generation (6G) and beyond 6G wireless networks are expected to bridge the digital and physical worlds by providing wireless connectivity as a service to different vertical sectors, including industries, smart cities, eHealth and autonomous transportation.","Such far reaching integration will render the society increasingly reliant on wireless networks.","While this has the potential to greatly enhance our quality and ease of life, any disruption to these networks would also have significant impact with overreaching consequences.","Disruptions can happen due to a variety of reasons, including planned outages, failures due to the nature of wireless propagation, natural disasters, and deliberate cybersecurity attacks.","Hence, 6G and beyond 6G networks should not only provide near instant and virtually unlimited connectivity, but also be resilient against internal and external disruptions.","This paper proposes a resilient-by-design framework towards this end.","First, we provide an overview of the disruption landscape.","Thereafter, we comprehensively outline the main features of the proposed concept.","Finally, we detail the four key steps of the framework, namely predict, preempt, protect and progress.","A simple but illustrative preliminary simulation result is also presented to highlight the potential advantages and efficiency of the proposed approach in addressing outages."],"url":"http://arxiv.org/abs/2410.23203v1"}
{"created":"2024-10-30 16:49:59","title":"HEX: Hierarchical Emergence Exploitation in Self-Supervised Algorithms","abstract":"In this paper, we propose an algorithm that can be used on top of a wide variety of self-supervised (SSL) approaches to take advantage of hierarchical structures that emerge during training. SSL approaches typically work through some invariance term to ensure consistency between similar samples and a regularization term to prevent global dimensional collapse. Dimensional collapse refers to data representations spanning a lower-dimensional subspace. Recent work has demonstrated that the representation space of these algorithms gradually reflects a semantic hierarchical structure as training progresses. Data samples of the same hierarchical grouping tend to exhibit greater dimensional collapse locally compared to the dataset as a whole due to sharing features in common with each other. Ideally, SSL algorithms would take advantage of this hierarchical emergence to have an additional regularization term to account for this local dimensional collapse effect. However, the construction of existing SSL algorithms does not account for this property. To address this, we propose an adaptive algorithm that performs a weighted decomposition of the denominator of the InfoNCE loss into two terms: local hierarchical and global collapse regularization respectively. This decomposition is based on an adaptive threshold that gradually lowers to reflect the emerging hierarchical structure of the representation space throughout training. It is based on an analysis of the cosine similarity distribution of samples in a batch. We demonstrate that this hierarchical emergence exploitation (HEX) approach can be integrated across a wide variety of SSL algorithms. Empirically, we show performance improvements of up to 5.6% relative improvement over baseline SSL approaches on classification accuracy on Imagenet with 100 epochs of training.","sentences":["In this paper, we propose an algorithm that can be used on top of a wide variety of self-supervised (SSL) approaches to take advantage of hierarchical structures that emerge during training.","SSL approaches typically work through some invariance term to ensure consistency between similar samples and a regularization term to prevent global dimensional collapse.","Dimensional collapse refers to data representations spanning a lower-dimensional subspace.","Recent work has demonstrated that the representation space of these algorithms gradually reflects a semantic hierarchical structure as training progresses.","Data samples of the same hierarchical grouping tend to exhibit greater dimensional collapse locally compared to the dataset as a whole due to sharing features in common with each other.","Ideally, SSL algorithms would take advantage of this hierarchical emergence to have an additional regularization term to account for this local dimensional collapse effect.","However, the construction of existing SSL algorithms does not account for this property.","To address this, we propose an adaptive algorithm that performs a weighted decomposition of the denominator of the InfoNCE loss into two terms: local hierarchical and global collapse regularization respectively.","This decomposition is based on an adaptive threshold that gradually lowers to reflect the emerging hierarchical structure of the representation space throughout training.","It is based on an analysis of the cosine similarity distribution of samples in a batch.","We demonstrate that this hierarchical emergence exploitation (HEX) approach can be integrated across a wide variety of SSL algorithms.","Empirically, we show performance improvements of up to 5.6% relative improvement over baseline SSL approaches on classification accuracy on Imagenet with 100 epochs of training."],"url":"http://arxiv.org/abs/2410.23200v1"}
{"created":"2024-10-30 16:47:01","title":"ReaWristic: Remote Touch Sensation to Fingers from a Wristband via Visually Augmented Electro-Tactile Feedback","abstract":"We present a technique for providing remote tactile feedback to the thumb and index finger via a wristband device. This enables haptics for touch and pinch interactions in mixed reality (MR) while keeping the hand entirely free. We achieve this through a novel cross-modal stimulation, which we term visually augmented electro-tactile feedback. This consists of (1) electrically stimulating the nerves that innervate the targeted fingers using our wristband device and (2) concurrently, visually augmenting the targeted finger in MR to steer the perceived sensation to the desired location. In our psychophysics study, we found that our approach provides tactile perception akin to tapping and, even from the wrist, it is capable of delivering the sensation to the targeted fingers with about 50% of sensation occurring in the thumb and about 40% of sensation occurring in the index finger. These results on localizability are unprecedented compared to electro-tactile feedback alone or any prior work for creating sensations in the hand with devices worn on the wrist/arm. Moreover, unlike conventional electro-tactile techniques, our wristband dispenses with gel electrodes. Instead, it incorporates custom-made elastomer-based dry electrodes and a stimulation waveform designed for the electrodes, ensuring the practicality of the device beyond laboratory settings. Lastly, we evaluated the haptic realism of our approach in mixed reality and elicited qualitative feedback from users. Participants preferred our approach to a baseline vibrotactile wrist-worn device.","sentences":["We present a technique for providing remote tactile feedback to the thumb and index finger via a wristband device.","This enables haptics for touch and pinch interactions in mixed reality (MR) while keeping the hand entirely free.","We achieve this through a novel cross-modal stimulation, which we term visually augmented electro-tactile feedback.","This consists of (1) electrically stimulating the nerves that innervate the targeted fingers using our wristband device and (2) concurrently, visually augmenting the targeted finger in MR to steer the perceived sensation to the desired location.","In our psychophysics study, we found that our approach provides tactile perception akin to tapping and, even from the wrist, it is capable of delivering the sensation to the targeted fingers with about 50% of sensation occurring in the thumb and about 40% of sensation occurring in the index finger.","These results on localizability are unprecedented compared to electro-tactile feedback alone or any prior work for creating sensations in the hand with devices worn on the wrist/arm.","Moreover, unlike conventional electro-tactile techniques, our wristband dispenses with gel electrodes.","Instead, it incorporates custom-made elastomer-based dry electrodes and a stimulation waveform designed for the electrodes, ensuring the practicality of the device beyond laboratory settings.","Lastly, we evaluated the haptic realism of our approach in mixed reality and elicited qualitative feedback from users.","Participants preferred our approach to a baseline vibrotactile wrist-worn device."],"url":"http://arxiv.org/abs/2410.23193v1"}
{"created":"2024-10-30 16:45:59","title":"Continuous Spatio-Temporal Memory Networks for 4D Cardiac Cine MRI Segmentation","abstract":"Current cardiac cine magnetic resonance image (cMR) studies focus on the end diastole (ED) and end systole (ES) phases, while ignoring the abundant temporal information in the whole image sequence. This is because whole sequence segmentation is currently a tedious process and inaccurate. Conventional whole sequence segmentation approaches first estimate the motion field between frames, which is then used to propagate the mask along the temporal axis. However, the mask propagation results could be prone to error, especially for the basal and apex slices, where through-plane motion leads to significant morphology and structural change during the cardiac cycle. Inspired by recent advances in video object segmentation (VOS), based on spatio-temporal memory (STM) networks, we propose a continuous STM (CSTM) network for semi-supervised whole heart and whole sequence cMR segmentation. Our CSTM network takes full advantage of the spatial, scale, temporal and through-plane continuity prior of the underlying heart anatomy structures, to achieve accurate and fast 4D segmentation. Results of extensive experiments across multiple cMR datasets show that our method can improve the 4D cMR segmentation performance, especially for the hard-to-segment regions.","sentences":["Current cardiac cine magnetic resonance image (cMR) studies focus on the end diastole (ED) and end systole (ES) phases, while ignoring the abundant temporal information in the whole image sequence.","This is because whole sequence segmentation is currently a tedious process and inaccurate.","Conventional whole sequence segmentation approaches first estimate the motion field between frames, which is then used to propagate the mask along the temporal axis.","However, the mask propagation results could be prone to error, especially for the basal and apex slices, where through-plane motion leads to significant morphology and structural change during the cardiac cycle.","Inspired by recent advances in video object segmentation (VOS), based on spatio-temporal memory (STM) networks, we propose a continuous STM (CSTM) network for semi-supervised whole heart and whole sequence cMR segmentation.","Our CSTM network takes full advantage of the spatial, scale, temporal and through-plane continuity prior of the underlying heart anatomy structures, to achieve accurate and fast 4D segmentation.","Results of extensive experiments across multiple cMR datasets show that our method can improve the 4D cMR segmentation performance, especially for the hard-to-segment regions."],"url":"http://arxiv.org/abs/2410.23191v1"}
{"created":"2024-10-30 16:42:22","title":"Explorable Parity Automata","abstract":"We define the class of explorable automata on finite or infinite words. This is a generalization of History-Deterministic (HD) automata, where this time non-deterministic choices can be resolved by building finitely many simultaneous runs instead of just one. We show that recognizing HD parity automata of fixed index among explorable ones is in PTime, thereby giving a strong link between the two notions. We then show that recognizing explorable automata is ExpTime-complete, in the case of finite words or parity automata up to index [0, 2]. Additionally, we define the notion of {\\omega}-explorable automata on infinite words, where countably many runs can be used to resolve the non-deterministic choices. We show ExpTime-completeness for {\\omega}-explorability of automata on infinite words for the safety and coB\\\"uchi acceptance conditions. We finally characterize the expressivity of ({\\omega}-)explorable automata with respect to the parity index hierarchy.","sentences":["We define the class of explorable automata on finite or infinite words.","This is a generalization of History-Deterministic (HD) automata, where this time non-deterministic choices can be resolved by building finitely many simultaneous runs instead of just one.","We show that recognizing HD parity automata of fixed index among explorable ones is in PTime, thereby giving a strong link between the two notions.","We then show that recognizing explorable automata is ExpTime-complete, in the case of finite words or parity automata up to index","[0, 2].","Additionally, we define the notion of {\\omega}-explorable automata on infinite words, where countably many runs can be used to resolve the non-deterministic choices.","We show ExpTime-completeness for {\\omega}-explorability of automata on infinite words for the safety and coB\\\"uchi acceptance conditions.","We finally characterize the expressivity of ({\\omega}-)explorable automata with respect to the parity index hierarchy."],"url":"http://arxiv.org/abs/2410.23187v1"}
{"created":"2024-10-30 16:42:04","title":"Reliability of Topic Modeling","abstract":"Topic models allow researchers to extract latent factors from text data and use those variables in downstream statistical analyses. However, these methodologies can vary significantly due to initialization differences, randomness in sampling procedures, or noisy data. Reliability of these methods is of particular concern as many researchers treat learned topic models as ground truth for subsequent analyses. In this work, we show that the standard practice for quantifying topic model reliability fails to capture essential aspects of the variation in two widely-used topic models. Drawing from a extensive literature on measurement theory, we provide empirical and theoretical analyses of three other metrics for evaluating the reliability of topic models. On synthetic and real-world data, we show that McDonald's $\\omega$ provides the best encapsulation of reliability. This metric provides an essential tool for validation of topic model methodologies that should be a standard component of any topic model-based research.","sentences":["Topic models allow researchers to extract latent factors from text data and use those variables in downstream statistical analyses.","However, these methodologies can vary significantly due to initialization differences, randomness in sampling procedures, or noisy data.","Reliability of these methods is of particular concern as many researchers treat learned topic models as ground truth for subsequent analyses.","In this work, we show that the standard practice for quantifying topic model reliability fails to capture essential aspects of the variation in two widely-used topic models.","Drawing from a extensive literature on measurement theory, we provide empirical and theoretical analyses of three other metrics for evaluating the reliability of topic models.","On synthetic and real-world data, we show that McDonald's $\\omega$ provides the best encapsulation of reliability.","This metric provides an essential tool for validation of topic model methodologies that should be a standard component of any topic model-based research."],"url":"http://arxiv.org/abs/2410.23186v1"}
{"created":"2024-10-30 16:38:09","title":"ProTransformer: Robustify Transformers via Plug-and-Play Paradigm","abstract":"Transformer-based architectures have dominated various areas of machine learning in recent years. In this paper, we introduce a novel robust attention mechanism designed to enhance the resilience of transformer-based architectures. Crucially, this technique can be integrated into existing transformers as a plug-and-play layer, improving their robustness without the need for additional training or fine-tuning. Through comprehensive experiments and ablation studies, we demonstrate that our ProTransformer significantly enhances the robustness of transformer models across a variety of prediction tasks, attack mechanisms, backbone architectures, and data domains. Notably, without further fine-tuning, the ProTransformer consistently improves the performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT, ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler attack. Furthermore, ProTransformer shows promising resilience in large language models (LLMs) against prompting-based attacks, improving the performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing Vicuna by an average of 10.4% against the Jailbreaking attack. Beyond the language domain, ProTransformer also demonstrates outstanding robustness in both vision and graph domains.","sentences":["Transformer-based architectures have dominated various areas of machine learning in recent years.","In this paper, we introduce a novel robust attention mechanism designed to enhance the resilience of transformer-based architectures.","Crucially, this technique can be integrated into existing transformers as a plug-and-play layer, improving their robustness without the need for additional training or fine-tuning.","Through comprehensive experiments and ablation studies, we demonstrate that our ProTransformer significantly enhances the robustness of transformer models across a variety of prediction tasks, attack mechanisms, backbone architectures, and data domains.","Notably, without further fine-tuning, the ProTransformer consistently improves the performance of vanilla transformers by 19.5%, 28.3%, 16.1%, and 11.4% for BERT, ALBERT, DistilBERT, and RoBERTa, respectively, under the classical TextFooler attack.","Furthermore, ProTransformer shows promising resilience in large language models (LLMs) against prompting-based attacks, improving the performance of T5 and LLaMA by 24.8% and 17.8%, respectively, and enhancing Vicuna by an average of 10.4% against the Jailbreaking attack.","Beyond the language domain, ProTransformer also demonstrates outstanding robustness in both vision and graph domains."],"url":"http://arxiv.org/abs/2410.23182v1"}
{"created":"2024-10-30 16:37:04","title":"ReasoningRec: Bridging Personalized Recommendations and Human-Interpretable Explanations through LLM Reasoning","abstract":"This paper presents ReasoningRec, a reasoning-based recommendation framework that leverages Large Language Models (LLMs) to bridge the gap between recommendations and human-interpretable explanations. In contrast to conventional recommendation systems that rely on implicit user-item interactions, ReasoningRec employs LLMs to model users and items, focusing on preferences, aversions, and explanatory reasoning. The framework utilizes a larger LLM to generate synthetic explanations for user preferences, subsequently used to fine-tune a smaller LLM for enhanced recommendation accuracy and human-interpretable explanation. Our experimental study investigates the impact of reasoning and contextual information on personalized recommendations, revealing that the quality of contextual and personalized data significantly influences the LLM's capacity to generate plausible explanations. Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art methods by up to 12.5\\% in recommendation prediction while concurrently providing human-intelligible explanations. The code is available here: https://github.com/millenniumbismay/reasoningrec.","sentences":["This paper presents ReasoningRec, a reasoning-based recommendation framework that leverages Large Language Models (LLMs) to bridge the gap between recommendations and human-interpretable explanations.","In contrast to conventional recommendation systems that rely on implicit user-item interactions, ReasoningRec employs LLMs to model users and items, focusing on preferences, aversions, and explanatory reasoning.","The framework utilizes a larger LLM to generate synthetic explanations for user preferences, subsequently used to fine-tune a smaller LLM for enhanced recommendation accuracy and human-interpretable explanation.","Our experimental study investigates the impact of reasoning and contextual information on personalized recommendations, revealing that the quality of contextual and personalized data significantly influences the LLM's capacity to generate plausible explanations.","Empirical evaluations demonstrate that ReasoningRec surpasses state-of-the-art methods by up to 12.5\\% in recommendation prediction while concurrently providing human-intelligible explanations.","The code is available here: https://github.com/millenniumbismay/reasoningrec."],"url":"http://arxiv.org/abs/2410.23180v1"}
{"created":"2024-10-30 16:36:59","title":"Does equivariance matter at scale?","abstract":"Given large data sets and sufficient compute, is it beneficial to design neural architectures for the structure and symmetries of each problem? Or is it more efficient to learn them from data? We study empirically how equivariant and non-equivariant networks scale with compute and training samples. Focusing on a benchmark problem of rigid-body interactions and on general-purpose transformer architectures, we perform a series of experiments, varying the model size, training steps, and dataset size. We find evidence for three conclusions. First, equivariance improves data efficiency, but training non-equivariant models with data augmentation can close this gap given sufficient epochs. Second, scaling with compute follows a power law, with equivariant models outperforming non-equivariant ones at each tested compute budget. Finally, the optimal allocation of a compute budget onto model size and training duration differs between equivariant and non-equivariant models.","sentences":["Given large data sets and sufficient compute, is it beneficial to design neural architectures for the structure and symmetries of each problem?","Or is it more efficient to learn them from data?","We study empirically how equivariant and non-equivariant networks scale with compute and training samples.","Focusing on a benchmark problem of rigid-body interactions and on general-purpose transformer architectures, we perform a series of experiments, varying the model size, training steps, and dataset size.","We find evidence for three conclusions.","First, equivariance improves data efficiency, but training non-equivariant models with data augmentation can close this gap given sufficient epochs.","Second, scaling with compute follows a power law, with equivariant models outperforming non-equivariant ones at each tested compute budget.","Finally, the optimal allocation of a compute budget onto model size and training duration differs between equivariant and non-equivariant models."],"url":"http://arxiv.org/abs/2410.23179v1"}
{"created":"2024-10-30 16:20:39","title":"The Persistence of Neural Collapse Despite Low-Rank Bias: An Analytic Perspective Through Unconstrained Features","abstract":"Modern deep neural networks have been observed to exhibit a simple structure in their final layer features and weights, commonly referred to as neural collapse. This phenomenon has also been noted in layers beyond the final one, an extension known as deep neural collapse. Recent findings indicate that such a structure is generally not optimal in the deep unconstrained feature model, an approximation of an expressive network. This is attributed to a low-rank bias induced by regularization, which favors solutions with lower-rank than those typically associated with deep neural collapse. In this work, we extend these observations to the cross-entropy loss and analyze how the low-rank bias influences various solutions. Additionally, we explore how this bias induces specific structures in the singular values of the weights at global optima. Furthermore, we examine the loss surface of these models and provide evidence that the frequent observation of deep neural collapse in practice, despite its suboptimality, may result from its higher degeneracy on the loss surface.","sentences":["Modern deep neural networks have been observed to exhibit a simple structure in their final layer features and weights, commonly referred to as neural collapse.","This phenomenon has also been noted in layers beyond the final one, an extension known as deep neural collapse.","Recent findings indicate that such a structure is generally not optimal in the deep unconstrained feature model, an approximation of an expressive network.","This is attributed to a low-rank bias induced by regularization, which favors solutions with lower-rank than those typically associated with deep neural collapse.","In this work, we extend these observations to the cross-entropy loss and analyze how the low-rank bias influences various solutions.","Additionally, we explore how this bias induces specific structures in the singular values of the weights at global optima.","Furthermore, we examine the loss surface of these models and provide evidence that the frequent observation of deep neural collapse in practice, despite its suboptimality, may result from its higher degeneracy on the loss surface."],"url":"http://arxiv.org/abs/2410.23169v1"}
{"created":"2024-10-30 16:19:00","title":"TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters","abstract":"Transformers have become the predominant architecture in foundation models due to their excellent performance across various domains. However, the substantial cost of scaling these models remains a significant concern. This problem arises primarily from their dependence on a fixed number of parameters within linear projections. When architectural modifications (e.g., channel dimensions) are introduced, the entire model typically requires retraining from scratch. As model sizes continue growing, this strategy results in increasingly high computational costs and becomes unsustainable. To overcome this problem, we introduce TokenFormer, a natively scalable architecture that leverages the attention mechanism not only for computations among input tokens but also for interactions between tokens and model parameters, thereby enhancing architectural flexibility. By treating model parameters as tokens, we replace all the linear projections in Transformers with our token-parameter attention layer, where input tokens act as queries and model parameters as keys and values. This reformulation allows for progressive and efficient scaling without necessitating retraining from scratch. Our model scales from 124M to 1.4B parameters by incrementally adding new key-value parameter pairs, achieving performance comparable to Transformers trained from scratch while greatly reducing training costs. Code and models are available at \\url{https://github.com/Haiyang-W/TokenFormer}.","sentences":["Transformers have become the predominant architecture in foundation models due to their excellent performance across various domains.","However, the substantial cost of scaling these models remains a significant concern.","This problem arises primarily from their dependence on a fixed number of parameters within linear projections.","When architectural modifications (e.g., channel dimensions) are introduced, the entire model typically requires retraining from scratch.","As model sizes continue growing, this strategy results in increasingly high computational costs and becomes unsustainable.","To overcome this problem, we introduce TokenFormer, a natively scalable architecture that leverages the attention mechanism not only for computations among input tokens but also for interactions between tokens and model parameters, thereby enhancing architectural flexibility.","By treating model parameters as tokens, we replace all the linear projections in Transformers with our token-parameter attention layer, where input tokens act as queries and model parameters as keys and values.","This reformulation allows for progressive and efficient scaling without necessitating retraining from scratch.","Our model scales from 124M to 1.4B parameters by incrementally adding new key-value parameter pairs, achieving performance comparable to Transformers trained from scratch while greatly reducing training costs.","Code and models are available at \\url{https://github.com/Haiyang-W/TokenFormer}."],"url":"http://arxiv.org/abs/2410.23168v1"}
{"created":"2024-10-30 16:18:22","title":"SciPIP: An LLM-based Scientific Paper Idea Proposer","abstract":"The exponential growth of knowledge and the increasing complexity of interdisciplinary research pose significant challenges for researchers, including information overload and difficulties in exploring novel ideas. The advancements in large language models (LLMs), such as GPT-4, have shown great potential in enhancing idea proposals, but how to effectively utilize large models for reasonable idea proposal has not been thoroughly explored. This paper proposes a scientific paper idea proposer (SciPIP). Based on a user-provided research background, SciPIP retrieves helpful papers from a literature database while leveraging the capabilities of LLMs to generate more novel and feasible ideas. To this end, 1) we construct a literature retrieval database, extracting lots of papers' multi-dimension information for fast access. Then, a literature retrieval method based on semantics, entity, and citation co-occurrences is proposed to search relevant literature from multiple aspects based on the user-provided background. 2) After literature retrieval, we introduce dual-path idea proposal strategies, where one path infers solutions from the retrieved literature and the other path generates original ideas through model brainstorming. We then combine the two to achieve a good balance between feasibility and originality. Through extensive experiments on the natural language processing (NLP) field, we demonstrate that SciPIP can retrieve citations similar to those of existing top conference papers and generate many ideas consistent with them. Additionally, we evaluate the originality of other ideas generated by SciPIP using large language models, further validating the effectiveness of our proposed method. The code and the database are released at https://github.com/cheerss/SciPIP.","sentences":["The exponential growth of knowledge and the increasing complexity of interdisciplinary research pose significant challenges for researchers, including information overload and difficulties in exploring novel ideas.","The advancements in large language models (LLMs), such as GPT-4, have shown great potential in enhancing idea proposals, but how to effectively utilize large models for reasonable idea proposal has not been thoroughly explored.","This paper proposes a scientific paper idea proposer (SciPIP).","Based on a user-provided research background, SciPIP retrieves helpful papers from a literature database while leveraging the capabilities of LLMs to generate more novel and feasible ideas.","To this end, 1) we construct a literature retrieval database, extracting lots of papers' multi-dimension information for fast access.","Then, a literature retrieval method based on semantics, entity, and citation co-occurrences is proposed to search relevant literature from multiple aspects based on the user-provided background.","2) After literature retrieval, we introduce dual-path idea proposal strategies, where one path infers solutions from the retrieved literature and the other path generates original ideas through model brainstorming.","We then combine the two to achieve a good balance between feasibility and originality.","Through extensive experiments on the natural language processing (NLP) field, we demonstrate that SciPIP can retrieve citations similar to those of existing top conference papers and generate many ideas consistent with them.","Additionally, we evaluate the originality of other ideas generated by SciPIP using large language models, further validating the effectiveness of our proposed method.","The code and the database are released at https://github.com/cheerss/SciPIP."],"url":"http://arxiv.org/abs/2410.23166v1"}
{"created":"2024-10-30 16:14:27","title":"Energy-Efficient Intra-Domain Network Slicing for Multi-Layer Orchestration in Intelligent-Driven Distributed 6G Networks: Learning Generic Assignment Skills with Unsupervised Reinforcement Learning","abstract":"Since the 6th Generation (6G) of wireless networks is expected to provide a new level of network services and meet the emerging expectations of the future, it will be a complex and intricate networking system. 6Gs sophistication and robustness will be accompanied by complexities, which will require novel strategies to tackle them. This research work focuses on decentralized and multi-level system models for 6G networks and proposes an energy efficient automation strategy for edge domain management and Network Slicing (NS) with the main objective of reducing the networks complexity by leveraging scalability, efficiency, and generalization. Accordingly, we propose a pre-train phase to discover useful assignment skills in network edge domains by utilizing unsupervised Reinforcement Learning (unsupervised RL). The suggested technique does not depend on the domain specifications and thus is applicable to all the edge domains. Our proposed approach not only enables scalability and decentralization, but it also delivers efficiency by assisting domain controllers to provide various service types. We implemented the pre-training phase, and monitored that the discovered assignment skills span the entire interval of possible resource assignment portions for every service type.","sentences":["Since the 6th Generation (6G) of wireless networks is expected to provide a new level of network services and meet the emerging expectations of the future, it will be a complex and intricate networking system.","6Gs sophistication and robustness will be accompanied by complexities, which will require novel strategies to tackle them.","This research work focuses on decentralized and multi-level system models for 6G networks and proposes an energy efficient automation strategy for edge domain management and Network Slicing (NS) with the main objective of reducing the networks complexity by leveraging scalability, efficiency, and generalization.","Accordingly, we propose a pre-train phase to discover useful assignment skills in network edge domains by utilizing unsupervised Reinforcement Learning (unsupervised RL).","The suggested technique does not depend on the domain specifications and thus is applicable to all the edge domains.","Our proposed approach not only enables scalability and decentralization, but it also delivers efficiency by assisting domain controllers to provide various service types.","We implemented the pre-training phase, and monitored that the discovered assignment skills span the entire interval of possible resource assignment portions for every service type."],"url":"http://arxiv.org/abs/2410.23161v1"}
{"created":"2024-10-30 16:14:09","title":"FlexTSF: A Universal Forecasting Model for Time Series with Variable Regularities","abstract":"Developing a foundation model for time series forecasting across diverse domains has attracted significant attention in recent years. Existing works typically assume regularly sampled, well-structured data, limiting their applicability to more generalized scenarios where time series often contain missing values, unequal sequence lengths, and irregular time intervals between measurements. To cover diverse domains and handle variable regularities, we propose FlexTSF, a universal time series forecasting model that possesses better generalization and natively support both regular and irregular time series. FlexTSF produces forecasts in an autoregressive manner and incorporates three novel designs: VT-Norm, a normalization strategy to ablate data domain barriers, IVP Patcher, a patching module to learn representations from flexibly structured time series, and LED attention, an attention mechanism to seamlessly integrate these two and propagate forecasts with awareness of domain and time information. Experiments on 12 datasets show that FlexTSF outperforms state-of-the-art forecasting models respectively designed for regular and irregular time series. Furthermore, after self-supervised pre-training, FlexTSF shows exceptional performance in both zero-shot and few-show settings for time series forecasting.","sentences":["Developing a foundation model for time series forecasting across diverse domains has attracted significant attention in recent years.","Existing works typically assume regularly sampled, well-structured data, limiting their applicability to more generalized scenarios where time series often contain missing values, unequal sequence lengths, and irregular time intervals between measurements.","To cover diverse domains and handle variable regularities, we propose FlexTSF, a universal time series forecasting model that possesses better generalization and natively support both regular and irregular time series.","FlexTSF produces forecasts in an autoregressive manner and incorporates three novel designs: VT-Norm, a normalization strategy to ablate data domain barriers, IVP Patcher, a patching module to learn representations from flexibly structured time series, and LED attention, an attention mechanism to seamlessly integrate these two and propagate forecasts with awareness of domain and time information.","Experiments on 12 datasets show that FlexTSF outperforms state-of-the-art forecasting models respectively designed for regular and irregular time series.","Furthermore, after self-supervised pre-training, FlexTSF shows exceptional performance in both zero-shot and few-show settings for time series forecasting."],"url":"http://arxiv.org/abs/2410.23160v1"}
{"created":"2024-10-30 16:12:56","title":"Fourier Amplitude and Correlation Loss: Beyond Using L2 Loss for Skillful Precipitation Nowcasting","abstract":"Deep learning approaches have been widely adopted for precipitation nowcasting in recent years. Previous studies mainly focus on proposing new model architectures to improve pixel-wise metrics. However, they frequently result in blurry predictions which provide limited utility to forecasting operations. In this work, we propose a new Fourier Amplitude and Correlation Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss (FAL) and Fourier Correlation Loss (FCL). FAL regularizes the Fourier amplitude of the model prediction and FCL complements the missing phase information. The two loss terms work together to replace the traditional $L_2$ losses such as MSE and weighted MSE for the spatiotemporal prediction problem on signal-based data. Our method is generic, parameter-free and efficient. Extensive experiments using one synthetic dataset and three radar echo datasets demonstrate that our method improves perceptual metrics and meteorology skill scores, with a small trade-off to pixel-wise accuracy and structural similarity. Moreover, to improve the error margin in meteorological skill scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we propose and adopt the Regional Histogram Divergence (RHD), a distance metric that considers the patch-wise similarity between signal-based imagery patterns with tolerance to local transforms. Code is available at https://github.com/argenycw/FACL","sentences":["Deep learning approaches have been widely adopted for precipitation nowcasting in recent years.","Previous studies mainly focus on proposing new model architectures to improve pixel-wise metrics.","However, they frequently result in blurry predictions which provide limited utility to forecasting operations.","In this work, we propose a new Fourier Amplitude and Correlation Loss (FACL) which consists of two novel loss terms: Fourier Amplitude Loss (FAL) and Fourier Correlation Loss (FCL).","FAL regularizes the Fourier amplitude of the model prediction and FCL complements the missing phase information.","The two loss terms work together to replace the traditional $L_2$ losses such as MSE and weighted MSE for the spatiotemporal prediction problem on signal-based data.","Our method is generic, parameter-free and efficient.","Extensive experiments using one synthetic dataset and three radar echo datasets demonstrate that our method improves perceptual metrics and meteorology skill scores, with a small trade-off to pixel-wise accuracy and structural similarity.","Moreover, to improve the error margin in meteorological skill scores such as Critical Success Index (CSI) and Fractions Skill Score (FSS), we propose and adopt the Regional Histogram Divergence (RHD), a distance metric that considers the patch-wise similarity between signal-based imagery patterns with tolerance to local transforms.","Code is available at https://github.com/argenycw/FACL"],"url":"http://arxiv.org/abs/2410.23159v1"}
{"created":"2024-10-30 16:11:40","title":"Directional anomaly detection","abstract":"Semi-supervised anomaly detection is based on the principle that potential anomalies are those records that look different from normal training data. However, in some cases we are specifically interested in anomalies that correspond to high attribute values (or low, but not both). We present two asymmetrical distance measures that take this directionality into account: ramp distance and signed distance. Through experiments on synthetic and real-life datasets we show that ramp distance performs as well or better than the absolute distance traditionally used in anomaly detection. While signed distance also performs well on synthetic data, it performs substantially poorer on real-life datasets. We argue that this reflects the fact that in practice, good scores on some attributes should not be allowed to compensate for bad scores on others.","sentences":["Semi-supervised anomaly detection is based on the principle that potential anomalies are those records that look different from normal training data.","However, in some cases we are specifically interested in anomalies that correspond to high attribute values (or low, but not both).","We present two asymmetrical distance measures that take this directionality into account: ramp distance and signed distance.","Through experiments on synthetic and real-life datasets we show that ramp distance performs as well or better than the absolute distance traditionally used in anomaly detection.","While signed distance also performs well on synthetic data, it performs substantially poorer on real-life datasets.","We argue that this reflects the fact that in practice, good scores on some attributes should not be allowed to compensate for bad scores on others."],"url":"http://arxiv.org/abs/2410.23158v1"}
{"created":"2024-10-30 16:11:05","title":"VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning","abstract":"Broadly intelligent agents should form task-specific abstractions that selectively expose the essential elements of a task, while abstracting away the complexity of the raw sensorimotor space. In this work, we present Neuro-Symbolic Predicates, a first-order abstraction language that combines the strengths of symbolic and neural knowledge representations. We outline an online algorithm for inventing such predicates and learning abstract world models. We compare our approach to hierarchical reinforcement learning, vision-language model planning, and symbolic predicate invention approaches, on both in- and out-of-distribution tasks across five simulated robotic domains. Results show that our approach offers better sample complexity, stronger out-of-distribution generalization, and improved interpretability.","sentences":["Broadly intelligent agents should form task-specific abstractions that selectively expose the essential elements of a task, while abstracting away the complexity of the raw sensorimotor space.","In this work, we present Neuro-Symbolic Predicates, a first-order abstraction language that combines the strengths of symbolic and neural knowledge representations.","We outline an online algorithm for inventing such predicates and learning abstract world models.","We compare our approach to hierarchical reinforcement learning, vision-language model planning, and symbolic predicate invention approaches, on both in- and out-of-distribution tasks across five simulated robotic domains.","Results show that our approach offers better sample complexity, stronger out-of-distribution generalization, and improved interpretability."],"url":"http://arxiv.org/abs/2410.23156v1"}
{"created":"2024-10-30 16:10:46","title":"QWO: Speeding Up Permutation-Based Causal Discovery in LiGAMs","abstract":"Causal discovery is essential for understanding relationships among variables of interest in many scientific domains. In this paper, we focus on permutation-based methods for learning causal graphs in Linear Gaussian Acyclic Models (LiGAMs), where the permutation encodes a causal ordering of the variables. Existing methods in this setting are not scalable due to their high computational complexity. These methods are comprised of two main components: (i) constructing a specific DAG, $\\mathcal{G}^\\pi$, for a given permutation $\\pi$, which represents the best structure that can be learned from the available data while adhering to $\\pi$, and (ii) searching over the space of permutations (i.e., causal orders) to minimize the number of edges in $\\mathcal{G}^\\pi$. We introduce QWO, a novel approach that significantly enhances the efficiency of computing $\\mathcal{G}^\\pi$ for a given permutation $\\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared to the state-of-the-art BIC-based method, making it highly scalable. We show that our method is theoretically sound and can be integrated into existing search strategies such as GRASP and hill-climbing-based methods to improve their performance.","sentences":["Causal discovery is essential for understanding relationships among variables of interest in many scientific domains.","In this paper, we focus on permutation-based methods for learning causal graphs in Linear Gaussian Acyclic Models (LiGAMs), where the permutation encodes a causal ordering of the variables.","Existing methods in this setting are not scalable due to their high computational complexity.","These methods are comprised of two main components: (i) constructing a specific DAG, $\\mathcal{G}^\\pi$, for a given permutation $\\pi$, which represents the best structure that can be learned from the available data while adhering to $\\pi$, and (ii) searching over the space of permutations (i.e., causal orders) to minimize the number of edges in $\\mathcal{G}^\\pi$. We introduce QWO, a novel approach that significantly enhances the efficiency of computing $\\mathcal{G}^\\pi$ for a given permutation $\\pi$. QWO has a speed-up of $O(n^2)$ ($n$ is the number of variables) compared to the state-of-the-art BIC-based method, making it highly scalable.","We show that our method is theoretically sound and can be integrated into existing search strategies such as GRASP and hill-climbing-based methods to improve their performance."],"url":"http://arxiv.org/abs/2410.23155v1"}
{"created":"2024-10-30 16:04:16","title":"HiBO: Hierarchical Bayesian Optimization via Adaptive Search Space Partitioning","abstract":"Optimizing black-box functions in high-dimensional search spaces has been known to be challenging for traditional Bayesian Optimization (BO). In this paper, we introduce HiBO, a novel hierarchical algorithm integrating global-level search space partitioning information into the acquisition strategy of a local BO-based optimizer. HiBO employs a search-tree-based global-level navigator to adaptively split the search space into partitions with different sampling potential. The local optimizer then utilizes this global-level information to guide its acquisition strategy towards most promising regions within the search space. A comprehensive set of evaluations demonstrates that HiBO outperforms state-of-the-art methods in high-dimensional synthetic benchmarks and presents significant practical effectiveness in the real-world task of tuning configurations of database management systems (DBMSs).","sentences":["Optimizing black-box functions in high-dimensional search spaces has been known to be challenging for traditional Bayesian Optimization (BO).","In this paper, we introduce HiBO, a novel hierarchical algorithm integrating global-level search space partitioning information into the acquisition strategy of a local BO-based optimizer.","HiBO employs a search-tree-based global-level navigator to adaptively split the search space into partitions with different sampling potential.","The local optimizer then utilizes this global-level information to guide its acquisition strategy towards most promising regions within the search space.","A comprehensive set of evaluations demonstrates that HiBO outperforms state-of-the-art methods in high-dimensional synthetic benchmarks and presents significant practical effectiveness in the real-world task of tuning configurations of database management systems (DBMSs)."],"url":"http://arxiv.org/abs/2410.23148v1"}
{"created":"2024-10-30 16:03:51","title":"FoLDTree: A ULDA-Based Decision Tree Framework for Efficient Oblique Splits and Feature Selection","abstract":"Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique. While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection. In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure. These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs. Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest. The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods.","sentences":["Traditional decision trees are limited by axis-orthogonal splits, which can perform poorly when true decision boundaries are oblique.","While oblique decision tree methods address this limitation, they often face high computational costs, difficulties with multi-class classification, and a lack of effective feature selection.","In this paper, we introduce LDATree and FoLDTree, two novel frameworks that integrate Uncorrelated Linear Discriminant Analysis (ULDA) and Forward ULDA into a decision tree structure.","These methods enable efficient oblique splits, handle missing values, support feature selection, and provide both class labels and probabilities as model outputs.","Through evaluations on simulated and real-world datasets, LDATree and FoLDTree consistently outperform axis-orthogonal and other oblique decision tree methods, achieving accuracy levels comparable to the random forest.","The results highlight the potential of these frameworks as robust alternatives to traditional single-tree methods."],"url":"http://arxiv.org/abs/2410.23147v1"}
{"created":"2024-10-30 15:59:05","title":"Public Domain 12M: A Highly Aesthetic Image-Text Dataset with Novel Governance Mechanisms","abstract":"We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality public domain and CC0-licensed images with synthetic captions, designed for training text-to-image models. PD12M is the largest public domain image-text dataset to date, with sufficient size to train foundation models while minimizing copyright concerns. Through the Source.Plus platform, we also introduce novel, community-driven dataset governance mechanisms that reduce harm and support reproducibility over time.","sentences":["We present Public Domain 12M (PD12M), a dataset of 12.4 million high-quality public domain and CC0-licensed images with synthetic captions, designed for training text-to-image models.","PD12M is the largest public domain image-text dataset to date, with sufficient size to train foundation models while minimizing copyright concerns.","Through the Source.","Plus platform, we also introduce novel, community-driven dataset governance mechanisms that reduce harm and support reproducibility over time."],"url":"http://arxiv.org/abs/2410.23144v1"}
{"created":"2024-10-30 15:58:05","title":"The Good, the Bad, and the Ugly: The Role of AI Quality Disclosure in Lie Detection","abstract":"We investigate how low-quality AI advisors, lacking quality disclosures, can help spread text-based lies while seeming to help people detect lies. Participants in our experiment discern truth from lies by evaluating transcripts from a game show that mimicked deceptive social media exchanges on topics with objective truths. We find that when relying on low-quality advisors without disclosures, participants' truth-detection rates fall below their own abilities, which recovered once the AI's true effectiveness was revealed. Conversely, high-quality advisor enhances truth detection, regardless of disclosure. We discover that participants' expectations about AI capabilities contribute to their undue reliance on opaque, low-quality advisors.","sentences":["We investigate how low-quality AI advisors, lacking quality disclosures, can help spread text-based lies while seeming to help people detect lies.","Participants in our experiment discern truth from lies by evaluating transcripts from a game show that mimicked deceptive social media exchanges on topics with objective truths.","We find that when relying on low-quality advisors without disclosures, participants' truth-detection rates fall below their own abilities, which recovered once the AI's true effectiveness was revealed.","Conversely, high-quality advisor enhances truth detection, regardless of disclosure.","We discover that participants' expectations about AI capabilities contribute to their undue reliance on opaque, low-quality advisors."],"url":"http://arxiv.org/abs/2410.23143v1"}
{"created":"2024-10-30 15:58:03","title":"FAIR-TAT: Improving Model Fairness Using Targeted Adversarial Training","abstract":"Deep neural networks are susceptible to adversarial attacks and common corruptions, which undermine their robustness. In order to enhance model resilience against such challenges, Adversarial Training (AT) has emerged as a prominent solution. Nevertheless, adversarial robustness is often attained at the expense of model fairness during AT, i.e., disparity in class-wise robustness of the model. While distinctive classes become more robust towards such adversaries, hard to detect classes suffer. Recently, research has focused on improving model fairness specifically for perturbed images, overlooking the accuracy of the most likely non-perturbed data. Additionally, despite their robustness against the adversaries encountered during model training, state-of-the-art adversarial trained models have difficulty maintaining robustness and fairness when confronted with diverse adversarial threats or common corruptions. In this work, we address the above concerns by introducing a novel approach called Fair Targeted Adversarial Training (FAIR-TAT). We show that using targeted adversarial attacks for adversarial training (instead of untargeted attacks) can allow for more favorable trade-offs with respect to adversarial fairness. Empirical results validate the efficacy of our approach.","sentences":["Deep neural networks are susceptible to adversarial attacks and common corruptions, which undermine their robustness.","In order to enhance model resilience against such challenges, Adversarial Training (AT) has emerged as a prominent solution.","Nevertheless, adversarial robustness is often attained at the expense of model fairness during AT, i.e., disparity in class-wise robustness of the model.","While distinctive classes become more robust towards such adversaries, hard to detect classes suffer.","Recently, research has focused on improving model fairness specifically for perturbed images, overlooking the accuracy of the most likely non-perturbed data.","Additionally, despite their robustness against the adversaries encountered during model training, state-of-the-art adversarial trained models have difficulty maintaining robustness and fairness when confronted with diverse adversarial threats or common corruptions.","In this work, we address the above concerns by introducing a novel approach called Fair Targeted Adversarial Training (FAIR-TAT).","We show that using targeted adversarial attacks for adversarial training (instead of untargeted attacks) can allow for more favorable trade-offs with respect to adversarial fairness.","Empirical results validate the efficacy of our approach."],"url":"http://arxiv.org/abs/2410.23142v1"}
{"created":"2024-10-30 15:52:15","title":"Fair Division with Market Values","abstract":"We introduce a model of fair division with market values, where indivisible goods must be partitioned among agents with (additive) subjective valuations, and each good additionally has a market value. The market valuation can be viewed as a separate additive valuation that holds identically across all the agents. We seek allocations that are simultaneously fair with respect to the subjective valuations and with respect to the market valuation.   We show that an allocation that satisfies stochastically-dominant envy-freeness up to one good (SD-EF1) with respect to both the subjective valuations and the market valuation does not always exist, but the weaker guarantee of EF1 with respect to the subjective valuations along with SD-EF1 with respect to the market valuation can be guaranteed. We also study a number of other guarantees such as Pareto optimality, EFX, and MMS. In addition, we explore non-additive valuations and extend our model to cake-cutting. Along the way, we identify several tantalizing open questions.","sentences":["We introduce a model of fair division with market values, where indivisible goods must be partitioned among agents with (additive) subjective valuations, and each good additionally has a market value.","The market valuation can be viewed as a separate additive valuation that holds identically across all the agents.","We seek allocations that are simultaneously fair with respect to the subjective valuations and with respect to the market valuation.   ","We show that an allocation that satisfies stochastically-dominant envy-freeness up to one good (SD-EF1) with respect to both the subjective valuations and the market valuation does not always exist, but the weaker guarantee of EF1 with respect to the subjective valuations along with SD-EF1 with respect to the market valuation can be guaranteed.","We also study a number of other guarantees such as Pareto optimality, EFX, and MMS.","In addition, we explore non-additive valuations and extend our model to cake-cutting.","Along the way, we identify several tantalizing open questions."],"url":"http://arxiv.org/abs/2410.23137v1"}
{"created":"2024-10-30 15:48:36","title":"Real-Time Personalization for LLM-based Recommendation with Customized In-Context Learning","abstract":"Frequently updating Large Language Model (LLM)-based recommender systems to adapt to new user interests -- as done for traditional ones -- is impractical due to high training costs, even with acceleration methods. This work explores adapting to dynamic user interests without any model updates by leveraging In-Context Learning (ICL), which allows LLMs to learn new tasks from few-shot examples provided in the input. Using new-interest examples as the ICL few-shot examples, LLMs may learn real-time interest directly, avoiding the need for model updates. However, existing LLM-based recommenders often lose the in-context learning ability during recommendation tuning, while the original LLM's in-context learning lacks recommendation-specific focus. To address this, we propose RecICL, which customizes recommendation-specific in-context learning for real-time recommendations. RecICL organizes training examples in an in-context learning format, ensuring that in-context learning ability is preserved and aligned with the recommendation task during tuning.   Extensive experiments demonstrate RecICL's effectiveness in delivering real-time recommendations without requiring model updates. Our code is available at https://github.com/ym689/rec_icl.","sentences":["Frequently updating Large Language Model (LLM)-based recommender systems to adapt to new user interests -- as done for traditional ones -- is impractical due to high training costs, even with acceleration methods.","This work explores adapting to dynamic user interests without any model updates by leveraging In-Context Learning (ICL), which allows LLMs to learn new tasks from few-shot examples provided in the input.","Using new-interest examples as the ICL few-shot examples, LLMs may learn real-time interest directly, avoiding the need for model updates.","However, existing LLM-based recommenders often lose the in-context learning ability during recommendation tuning, while the original LLM's in-context learning lacks recommendation-specific focus.","To address this, we propose RecICL, which customizes recommendation-specific in-context learning for real-time recommendations.","RecICL organizes training examples in an in-context learning format, ensuring that in-context learning ability is preserved and aligned with the recommendation task during tuning.   ","Extensive experiments demonstrate RecICL's effectiveness in delivering real-time recommendations without requiring model updates.","Our code is available at https://github.com/ym689/rec_icl."],"url":"http://arxiv.org/abs/2410.23136v1"}
{"created":"2024-10-30 15:45:09","title":"Crowdsourcing Lexical Diversity","abstract":"Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are fundamental for natural language processing applications. In many languages, however, such resources suffer from quality issues: incorrect entries, incompleteness, but also, the rarely addressed issue of bias towards the English language and Anglo-Saxon culture. Such bias manifests itself in the absence of concepts specific to the language or culture at hand, the presence of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit indication of untranslatability, also known as cross-lingual \\emph{lexical gaps}, when a term has no equivalent in another language. This paper proposes a novel crowdsourcing methodology for reducing bias in LSRs. Crowd workers compare lexemes from two languages, focusing on domains rich in lexical diversity, such as kinship or food. Our LingoGap crowdsourcing tool facilitates comparisons through microtasks identifying equivalent terms, language-specific terms, and lexical gaps across languages. We validated our method by applying it to two case studies focused on food-related terminology: (1) English and Arabic, and (2) Standard Indonesian and Banjarese. These experiments identified 2,140 lexical gaps in the first case study and 951 in the second. The success of these experiments confirmed the usability of our method and tool for future large-scale lexicon enrichment tasks.","sentences":["Lexical-semantic resources (LSRs), such as online lexicons or wordnets, are fundamental for natural language processing applications.","In many languages, however, such resources suffer from quality issues: incorrect entries, incompleteness, but also, the rarely addressed issue of bias towards the English language and Anglo-Saxon culture.","Such bias manifests itself in the absence of concepts specific to the language or culture at hand, the presence of foreign (Anglo-Saxon) concepts, as well as in the lack of an explicit indication of untranslatability, also known as cross-lingual \\emph{lexical gaps}, when a term has no equivalent in another language.","This paper proposes a novel crowdsourcing methodology for reducing bias in LSRs.","Crowd workers compare lexemes from two languages, focusing on domains rich in lexical diversity, such as kinship or food.","Our LingoGap crowdsourcing tool facilitates comparisons through microtasks identifying equivalent terms, language-specific terms, and lexical gaps across languages.","We validated our method by applying it to two case studies focused on food-related terminology: (1) English and Arabic, and (2) Standard Indonesian and Banjarese.","These experiments identified 2,140 lexical gaps in the first case study and 951 in the second.","The success of these experiments confirmed the usability of our method and tool for future large-scale lexicon enrichment tasks."],"url":"http://arxiv.org/abs/2410.23133v1"}
{"created":"2024-10-30 15:42:59","title":"Revisiting MAE pre-training for 3D medical image segmentation","abstract":"Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the potential of vast, untapped clinical datasets, for various downstream applications that suffer from the scarcity of labeled data. While SSL has revolutionized fields like natural language processing and computer vision, their adoption in 3D medical image computing has been limited by three key pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D medical image analysis, and insufficient evaluation practices. We address these issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and ii) using a Residual Encoder U-Net architecture within the state-of-the-art nnU-Net framework. iii) A robust development framework, incorporating 5 development and 8 testing brain MRI segmentation datasets, allowed performance-driven design decisions to optimize the simple concept of Masked Auto Encoders (MAEs) for 3D CNNs. The resulting model not only surpasses previous SSL methods but also outperforms the strong nnU-Net baseline by an average of approximately 3 Dice points. Furthermore, our model demonstrates exceptional stability, achieving the highest average rank of 2 out of 7 methods, compared to the second-best method's mean rank of 3.","sentences":["Self-Supervised Learning (SSL) presents an exciting opportunity to unlock the potential of vast, untapped clinical datasets, for various downstream applications that suffer from the scarcity of labeled data.","While SSL has revolutionized fields like natural language processing and computer vision, their adoption in 3D medical image computing has been limited by three key pitfalls: Small pre-training dataset sizes, architectures inadequate for 3D medical image analysis, and insufficient evaluation practices.","We address these issues by i) leveraging a large-scale dataset of 44k 3D brain MRI volumes and ii) using a Residual Encoder U-Net architecture within the state-of-the-art nnU-Net framework.","iii)","A robust development framework, incorporating 5 development and 8 testing brain MRI segmentation datasets, allowed performance-driven design decisions to optimize the simple concept of Masked Auto Encoders (MAEs) for 3D CNNs.","The resulting model not only surpasses previous SSL methods but also outperforms the strong nnU-Net baseline by an average of approximately 3 Dice points.","Furthermore, our model demonstrates exceptional stability, achieving the highest average rank of 2 out of 7 methods, compared to the second-best method's mean rank of 3."],"url":"http://arxiv.org/abs/2410.23132v1"}
{"created":"2024-10-30 15:41:35","title":"Federated Learning under Periodic Client Participation and Heterogeneous Data: A New Communication-Efficient Algorithm and Analysis","abstract":"In federated learning, it is common to assume that clients are always available to participate in training, which may not be feasible with user devices in practice. Recent works analyze federated learning under more realistic participation patterns, such as cyclic client availability or arbitrary participation. However, all such works either require strong assumptions (e.g., all clients participate almost surely within a bounded window), do not achieve linear speedup and reduced communication rounds, or are not applicable in the general non-convex setting. In this work, we focus on nonconvex optimization and consider participation patterns in which the chance of participation over a fixed window of rounds is equal among all clients, which includes cyclic client availability as a special case. Under this setting, we propose a new algorithm, named Amplified SCAFFOLD, and prove that it achieves linear speedup, reduced communication, and resilience to data heterogeneity simultaneously. In particular, for cyclic participation, our algorithm is proved to enjoy $\\mathcal{O}(\\epsilon^{-2})$ communication rounds to find an $\\epsilon$-stationary point in the non-convex stochastic setting. In contrast, the prior work under the same setting requires $\\mathcal{O}(\\kappa^2 \\epsilon^{-4})$ communication rounds, where $\\kappa$ denotes the data heterogeneity. Therefore, our algorithm significantly reduces communication rounds due to better dependency in terms of $\\epsilon$ and $\\kappa$. Our analysis relies on a fine-grained treatment of the nested dependence between client participation and errors in the control variates, which results in tighter guarantees than previous work. We also provide experimental results with (1) synthetic data and (2) real-world data with a large number of clients $(N = 250)$, demonstrating the effectiveness of our algorithm under periodic client participation.","sentences":["In federated learning, it is common to assume that clients are always available to participate in training, which may not be feasible with user devices in practice.","Recent works analyze federated learning under more realistic participation patterns, such as cyclic client availability or arbitrary participation.","However, all such works either require strong assumptions (e.g., all clients participate almost surely within a bounded window), do not achieve linear speedup and reduced communication rounds, or are not applicable in the general non-convex setting.","In this work, we focus on nonconvex optimization and consider participation patterns in which the chance of participation over a fixed window of rounds is equal among all clients, which includes cyclic client availability as a special case.","Under this setting, we propose a new algorithm, named Amplified SCAFFOLD, and prove that it achieves linear speedup, reduced communication, and resilience to data heterogeneity simultaneously.","In particular, for cyclic participation, our algorithm is proved to enjoy $\\mathcal{O}(\\epsilon^{-2})$ communication rounds to find an $\\epsilon$-stationary point in the non-convex stochastic setting.","In contrast, the prior work under the same setting requires $\\mathcal{O}(\\kappa^2 \\epsilon^{-4})$ communication rounds, where $\\kappa$ denotes the data heterogeneity.","Therefore, our algorithm significantly reduces communication rounds due to better dependency in terms of $\\epsilon$ and $\\kappa$. Our analysis relies on a fine-grained treatment of the nested dependence between client participation and errors in the control variates, which results in tighter guarantees than previous work.","We also provide experimental results with (1) synthetic data and (2) real-world data with a large number of clients $(N = 250)$, demonstrating the effectiveness of our algorithm under periodic client participation."],"url":"http://arxiv.org/abs/2410.23131v1"}
{"created":"2024-10-30 15:41:30","title":"Why Fine-grained Labels in Pretraining Benefit Generalization?","abstract":"Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data. While there is ample empirical evidence supporting this, the theoretical justification remains an open problem. This paper addresses this gap by introducing a \"hierarchical multi-view\" structure to confine the input data distribution. Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples.","sentences":["Recent studies show that pretraining a deep neural network with fine-grained labeled data, followed by fine-tuning on coarse-labeled data for downstream tasks, often yields better generalization than pretraining with coarse-labeled data.","While there is ample empirical evidence supporting this, the theoretical justification remains an open problem.","This paper addresses this gap by introducing a \"hierarchical multi-view\" structure to confine the input data distribution.","Under this framework, we prove that: 1) coarse-grained pretraining only allows a neural network to learn the common features well, while 2) fine-grained pretraining helps the network learn the rare features in addition to the common ones, leading to improved accuracy on hard downstream test samples."],"url":"http://arxiv.org/abs/2410.23129v1"}
{"created":"2024-10-30 15:40:06","title":"Leader-Follower 3D Formation for Underwater Robots","abstract":"The schooling behavior of fish is hypothesized to confer many survival benefits, including foraging success, safety from predators, and energy savings through hydrodynamic interactions when swimming in formation. Underwater robot collectives may be able to achieve similar benefits in future applications, e.g. using formation control to achieve efficient spatial sampling for environmental monitoring. Although many theoretical algorithms exist for multi-robot formation control, they have not been tested in the underwater domain due to the fundamental challenges in underwater communication. Here we introduce a leader-follower strategy for underwater formation control that allows us to realize complex 3D formations, using purely vision-based perception and a reactive control algorithm that is low computation. We use a physical platform, BlueSwarm, to demonstrate for the first time an experimental realization of inline, side-by-side, and staggered swimming 3D formations. More complex formations are studied in a physics-based simulator, providing new insights into the convergence and stability of formations given underwater inertial/drag conditions. Our findings lay the groundwork for future applications of underwater robot swarms in aquatic environments with minimal communication.","sentences":["The schooling behavior of fish is hypothesized to confer many survival benefits, including foraging success, safety from predators, and energy savings through hydrodynamic interactions when swimming in formation.","Underwater robot collectives may be able to achieve similar benefits in future applications, e.g. using formation control to achieve efficient spatial sampling for environmental monitoring.","Although many theoretical algorithms exist for multi-robot formation control, they have not been tested in the underwater domain due to the fundamental challenges in underwater communication.","Here we introduce a leader-follower strategy for underwater formation control that allows us to realize complex 3D formations, using purely vision-based perception and a reactive control algorithm that is low computation.","We use a physical platform, BlueSwarm, to demonstrate for the first time an experimental realization of inline, side-by-side, and staggered swimming 3D formations.","More complex formations are studied in a physics-based simulator, providing new insights into the convergence and stability of formations given underwater inertial/drag conditions.","Our findings lay the groundwork for future applications of underwater robot swarms in aquatic environments with minimal communication."],"url":"http://arxiv.org/abs/2410.23128v1"}
{"created":"2024-10-30 15:39:03","title":"Educating for Hardware Specialization in the Chiplet Era: A Path for the HPC Community","abstract":"The advent of chiplet technology introduces cutting-edge opportunities for constructing highly heterogeneous platforms with specialized accelerators. However, the HPC community currently lacks expertise in hardware development, a gap that must be bridged to leverage these advancements. Additionally, technologies like chiplet is cutting-edge with limited educational resource available. This paper addresses potential hardware specialization direction in HPC and how to cultivate these skills among students and staff, emphasizing the importance of understanding and developing custom hardware (e.g., rapid prototyping and resource estimation). We have been mentoring graduate-level students and new staff in hardware designs in a hands-on manner, encouraging them to utilize modern open-source hardware tools for their designs, which facilitates the sharing of research ideas. Additionally, we provide a summary of theses tools as part of our approach to prototyping and mentoring.","sentences":["The advent of chiplet technology introduces cutting-edge opportunities for constructing highly heterogeneous platforms with specialized accelerators.","However, the HPC community currently lacks expertise in hardware development, a gap that must be bridged to leverage these advancements.","Additionally, technologies like chiplet is cutting-edge with limited educational resource available.","This paper addresses potential hardware specialization direction in HPC and how to cultivate these skills among students and staff, emphasizing the importance of understanding and developing custom hardware (e.g., rapid prototyping and resource estimation).","We have been mentoring graduate-level students and new staff in hardware designs in a hands-on manner, encouraging them to utilize modern open-source hardware tools for their designs, which facilitates the sharing of research ideas.","Additionally, we provide a summary of theses tools as part of our approach to prototyping and mentoring."],"url":"http://arxiv.org/abs/2410.23127v1"}
{"created":"2024-10-30 15:31:54","title":"On Memorization of Large Language Models in Logical Reasoning","abstract":"Large language models (LLMs) achieve good performance on challenging reasoning benchmarks, yet could also make basic reasoning mistakes. This contrasting behavior is puzzling when it comes to understanding the mechanisms behind LLMs' reasoning capabilities. One hypothesis is that the increasingly high and nearly saturated performance on common reasoning benchmarks could be due to the memorization of similar problems. In this paper, we systematically investigate this hypothesis with a quantitative measurement of memorization in reasoning tasks, using a dynamically generated logical reasoning benchmark based on Knights and Knaves (K&K) puzzles. We found that LLMs could interpolate the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet fail when those puzzles are slightly perturbed, suggesting that the models heavily rely on memorization to solve those training puzzles. On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance. In-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers suggest that the LLMs learn to reason on K&K puzzles despite training data memorization. This phenomenon indicates that LLMs exhibit a complex interplay between memorization and genuine reasoning abilities. Finally, our analysis with per-sample memorization score sheds light on how LLMs switch between reasoning and memorization in solving logical puzzles. Our code and data are available at https://memkklogic.github.io.","sentences":["Large language models (LLMs) achieve good performance on challenging reasoning benchmarks, yet could also make basic reasoning mistakes.","This contrasting behavior is puzzling when it comes to understanding the mechanisms behind LLMs' reasoning capabilities.","One hypothesis is that the increasingly high and nearly saturated performance on common reasoning benchmarks could be due to the memorization of similar problems.","In this paper, we systematically investigate this hypothesis with a quantitative measurement of memorization in reasoning tasks, using a dynamically generated logical reasoning benchmark based on Knights and Knaves (K&K) puzzles.","We found that LLMs could interpolate the training puzzles (achieving near-perfect accuracy) after fine-tuning, yet fail when those puzzles are slightly perturbed, suggesting that the models heavily rely on memorization to solve those training puzzles.","On the other hand, we show that while fine-tuning leads to heavy memorization, it also consistently improves generalization performance.","In-depth analyses with perturbation tests, cross difficulty-level transferability, probing model internals, and fine-tuning with wrong answers suggest that the LLMs learn to reason on K&K puzzles despite training data memorization.","This phenomenon indicates that LLMs exhibit a complex interplay between memorization and genuine reasoning abilities.","Finally, our analysis with per-sample memorization score sheds light on how LLMs switch between reasoning and memorization in solving logical puzzles.","Our code and data are available at https://memkklogic.github.io."],"url":"http://arxiv.org/abs/2410.23123v1"}
{"created":"2024-10-30 15:27:55","title":"Teaching a Language Model to Distinguish Between Similar Details using a Small Adversarial Training Set","abstract":"Language models can achieve high accuracy on natural language tasks such as NLI, but performance suffers on manually created adversarial examples. We investigate the performance of a language model trained on the Stanford Natural Language Inference (SNLI) corpus on a manually created adversarial test set. We then improve the model's performance by fine tuning the model on a small, manually created adversarial training set, designed to help the language model to learn to differentiate between similar words and phrases in the data. We show an increase in accuracy on the adversarial test set (+ 13%) while still maintaining good performance on the original NLI task. We also show an increase in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI test set (as judged by cosine similarity).","sentences":["Language models can achieve high accuracy on natural language tasks such as NLI, but performance suffers on manually created adversarial examples.","We investigate the performance of a language model trained on the Stanford Natural Language Inference (SNLI) corpus on a manually created adversarial test set.","We then improve the model's performance by fine tuning the model on a small, manually created adversarial training set, designed to help the language model to learn to differentiate between similar words and phrases in the data.","We show an increase in accuracy on the adversarial test set (+ 13%) while still maintaining good performance on the original NLI task.","We also show an increase in accuracy from 91.2% to 92.9% on the most similar contradictions in the SNLI test set (as judged by cosine similarity)."],"url":"http://arxiv.org/abs/2410.23118v1"}
{"created":"2024-10-30 15:25:06","title":"Unified Triplet-Level Hallucination Evaluation for Large Vision-Language Models","abstract":"Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image. Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations. However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation. To remedy that, in this paper we design a unified framework to measure object and relation hallucination in LVLMs simultaneously. The core idea of our framework is to conduct hallucination evaluation on (object, relation, object) triplets extracted from LVLMs' responses, and thus, could be easily generalized to different vision-language tasks. Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time. We conduct comprehensive evaluations on Tri-HE and observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs. Moreover, based on our findings, we design a simple yet effective training-free approach to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced counterparts on Tri-HE, achieving comparable performance with the powerful GPT-4V. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE.","sentences":["Despite the outstanding performance in vision-language reasoning, Large Vision-Language Models (LVLMs) might generate hallucinated contents that do not exist in the given image.","Most existing LVLM hallucination benchmarks are constrained to evaluate the object-related hallucinations.","However, the potential hallucination on the relations between two objects, i.e., relation hallucination, still lacks investigation.","To remedy that, in this paper we design a unified framework to measure object and relation hallucination in LVLMs simultaneously.","The core idea of our framework is to conduct hallucination evaluation on (object, relation, object) triplets extracted from LVLMs' responses, and thus, could be easily generalized to different vision-language tasks.","Based on our framework, we further introduce Tri-HE, a novel Triplet-level Hallucination Evaluation benchmark which can be used to study both object and relation hallucination at the same time.","We conduct comprehensive evaluations on Tri-HE and observe that the relation hallucination issue is even more serious than object hallucination among existing LVLMs, highlighting a previously neglected problem towards reliable LVLMs.","Moreover, based on our findings, we design a simple yet effective training-free approach to mitigate hallucinations for LVLMs, with which, we exceed all open-sourced counterparts on Tri-HE, achieving comparable performance with the powerful GPT-4V. Our dataset and code for the reproduction of our experiments are available publicly at https://github.com/wujunjie1998/Tri-HE."],"url":"http://arxiv.org/abs/2410.23114v1"}
{"created":"2024-10-30 15:23:44","title":"Why Gradient Subspace? Identifying and Mitigating LoRA's Bottlenecks in Federated Fine-Tuning of Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, particularly in task generalization for both text and vision data. While fine-tuning these models can significantly enhance their performance on specific downstream tasks, it often requires high-quality data that cannot be shared due to privacy concerns. Federated Learning (FL) offers a promising solution for collaborative training without direct data sharing. However, many parameter-efficient fine-tuning strategies for LLMs in FL, particularly those based on Low-Rank Adaptation (LoRA), face limitations. In this paper, we critically analyze the convergence and performance guarantees of popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to constrained subspace learning of low-rank matrices. This limitation hinders effective fine-tuning of LLMs in federated settings. Through rigorous analytical and empirical evaluations, we demonstrate that direct weight averaging outperforms LoRA-based strategies, leading to superior performance for fine-tuned models. Our comprehensive comparison exposes inefficiencies in LoRA approaches and underscores the advantages of full-rank weight aggregation. We extend our analysis to low-rank gradient-based optimizers, such as GaLore, used during local training steps. Our findings show that GaLore is a more effective alternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRA across both text and image modalities. While privacy remains paramount in FL discourse, our focus is on assessing performance outcomes of federated fine-tuned models and evaluating various FL frameworks from both theoretical and empirical perspectives. Our findings advocate reassessing the reliance on LoRA within FL contexts, paving the way for more efficient training methodologies.","sentences":["Large Language Models (LLMs) have demonstrated remarkable capabilities across various domains, particularly in task generalization for both text and vision data.","While fine-tuning these models can significantly enhance their performance on specific downstream tasks, it often requires high-quality data that cannot be shared due to privacy concerns.","Federated Learning (FL) offers a promising solution for collaborative training without direct data sharing.","However, many parameter-efficient fine-tuning strategies for LLMs in FL, particularly those based on Low-Rank Adaptation (LoRA), face limitations.","In this paper, we critically analyze the convergence and performance guarantees of popular FL frameworks utilizing LoRA, highlighting its suboptimal nature due to constrained subspace learning of low-rank matrices.","This limitation hinders effective fine-tuning of LLMs in federated settings.","Through rigorous analytical and empirical evaluations, we demonstrate that direct weight averaging outperforms LoRA-based strategies, leading to superior performance for fine-tuned models.","Our comprehensive comparison exposes inefficiencies in LoRA approaches and underscores the advantages of full-rank weight aggregation.","We extend our analysis to low-rank gradient-based optimizers, such as GaLore, used during local training steps.","Our findings show that GaLore is a more effective alternative, outperforming federated LoRA methods like FlexLoRA and FFA-LoRA across both text and image modalities.","While privacy remains paramount in FL discourse, our focus is on assessing performance outcomes of federated fine-tuned models and evaluating various FL frameworks from both theoretical and empirical perspectives.","Our findings advocate reassessing the reliance on LoRA within FL contexts, paving the way for more efficient training methodologies."],"url":"http://arxiv.org/abs/2410.23111v1"}
{"created":"2024-10-30 15:20:10","title":"NASM: Neural Anisotropic Surface Meshing","abstract":"This paper introduces a new learning-based method, NASM, for anisotropic surface meshing. Our key idea is to propose a graph neural network to embed an input mesh into a high-dimensional (high-d) Euclidean embedding space to preserve curvature-based anisotropic metric by using a dot product loss between high-d edge vectors. This can dramatically reduce the computational time and increase the scalability. Then, we propose a novel feature-sensitive remeshing on the generated high-d embedding to automatically capture sharp geometric features. We define a high-d normal metric, and then derive an automatic differentiation on a high-d centroidal Voronoi tessellation (CVT) optimization with the normal metric to simultaneously preserve geometric features and curvature anisotropy that exhibit in the original 3D shapes. To our knowledge, this is the first time that a deep learning framework and a large dataset are proposed to construct a high-d Euclidean embedding space for 3D anisotropic surface meshing. Experimental results are evaluated and compared with the state-of-the-art in anisotropic surface meshing on a large number of surface models from Thingi10K dataset as well as tested on extensive unseen 3D shapes from Multi-Garment Network dataset and FAUST human dataset.","sentences":["This paper introduces a new learning-based method, NASM, for anisotropic surface meshing.","Our key idea is to propose a graph neural network to embed an input mesh into a high-dimensional (high-d)","Euclidean embedding space to preserve curvature-based anisotropic metric by using a dot product loss between high-d edge vectors.","This can dramatically reduce the computational time and increase the scalability.","Then, we propose a novel feature-sensitive remeshing on the generated high-d embedding to automatically capture sharp geometric features.","We define a high-d normal metric, and then derive an automatic differentiation on a high-d centroidal Voronoi tessellation (CVT) optimization with the normal metric to simultaneously preserve geometric features and curvature anisotropy that exhibit in the original 3D shapes.","To our knowledge, this is the first time that a deep learning framework and a large dataset are proposed to construct a high-d Euclidean embedding space for 3D anisotropic surface meshing.","Experimental results are evaluated and compared with the state-of-the-art in anisotropic surface meshing on a large number of surface models from Thingi10K dataset as well as tested on extensive unseen 3D shapes from Multi-Garment Network dataset and FAUST human dataset."],"url":"http://arxiv.org/abs/2410.23109v1"}
{"created":"2024-10-30 15:18:26","title":"Controllable Game Level Generation: Assessing the Effect of Negative Examples in GAN Models","abstract":"Generative Adversarial Networks (GANs) are unsupervised models designed to learn and replicate a target distribution. The vanilla versions of these models can be extended to more controllable models. Conditional Generative Adversarial Networks (CGANs) extend vanilla GANs by conditioning both the generator and discriminator on some additional information (labels). Controllable models based on complementary learning, such as Rumi-GAN, have been introduced. Rumi-GANs leverage negative examples to enhance the generator's ability to learn positive examples. We evaluate the performance of two controllable GAN variants, CGAN and Rumi-GAN, in generating game levels targeting specific constraints of interest: playability and controllability. This evaluation is conducted under two scenarios: with and without the inclusion of negative examples. The goal is to determine whether incorporating negative examples helps the GAN models avoid generating undesirable outputs. Our findings highlight the strengths and weaknesses of each method in enforcing the generation of specific conditions when generating outputs based on given positive and negative examples.","sentences":["Generative Adversarial Networks (GANs) are unsupervised models designed to learn and replicate a target distribution.","The vanilla versions of these models can be extended to more controllable models.","Conditional Generative Adversarial Networks (CGANs) extend vanilla GANs by conditioning both the generator and discriminator on some additional information (labels).","Controllable models based on complementary learning, such as Rumi-GAN, have been introduced.","Rumi-GANs leverage negative examples to enhance the generator's ability to learn positive examples.","We evaluate the performance of two controllable GAN variants, CGAN and Rumi-GAN, in generating game levels targeting specific constraints of interest: playability and controllability.","This evaluation is conducted under two scenarios: with and without the inclusion of negative examples.","The goal is to determine whether incorporating negative examples helps the GAN models avoid generating undesirable outputs.","Our findings highlight the strengths and weaknesses of each method in enforcing the generation of specific conditions when generating outputs based on given positive and negative examples."],"url":"http://arxiv.org/abs/2410.23108v1"}
{"created":"2024-10-30 15:17:58","title":"Decoupling Semantic Similarity from Spatial Alignment for Neural Networks","abstract":"What representation do deep neural networks learn? How similar are images to each other for neural networks? Despite the overwhelming success of deep learning methods key questions about their internal workings still remain largely unanswered, due to their internal high dimensionality and complexity. To address this, one approach is to measure the similarity of activation responses to various inputs. Representational Similarity Matrices (RSMs) distill this similarity into scalar values for each input pair. These matrices encapsulate the entire similarity structure of a system, indicating which input leads to similar responses. While the similarity between images is ambiguous, we argue that the spatial location of semantic objects does neither influence human perception nor deep learning classifiers. Thus this should be reflected in the definition of similarity between image responses for computer vision systems. Revisiting the established similarity calculations for RSMs we expose their sensitivity to spatial alignment. In this paper, we propose to solve this through semantic RSMs, which are invariant to spatial permutation. We measure semantic similarity between input responses by formulating it as a set-matching problem. Further, we quantify the superiority of semantic RSMs over spatio-semantic RSMs through image retrieval and by comparing the similarity between representations to the similarity between predicted class probabilities.","sentences":["What representation do deep neural networks learn?","How similar are images to each other for neural networks?","Despite the overwhelming success of deep learning methods key questions about their internal workings still remain largely unanswered, due to their internal high dimensionality and complexity.","To address this, one approach is to measure the similarity of activation responses to various inputs.","Representational Similarity Matrices (RSMs) distill this similarity into scalar values for each input pair.","These matrices encapsulate the entire similarity structure of a system, indicating which input leads to similar responses.","While the similarity between images is ambiguous, we argue that the spatial location of semantic objects does neither influence human perception nor deep learning classifiers.","Thus this should be reflected in the definition of similarity between image responses for computer vision systems.","Revisiting the established similarity calculations for RSMs we expose their sensitivity to spatial alignment.","In this paper, we propose to solve this through semantic RSMs, which are invariant to spatial permutation.","We measure semantic similarity between input responses by formulating it as a set-matching problem.","Further, we quantify the superiority of semantic RSMs over spatio-semantic RSMs through image retrieval and by comparing the similarity between representations to the similarity between predicted class probabilities."],"url":"http://arxiv.org/abs/2410.23107v1"}
{"created":"2024-10-30 15:15:41","title":"Automated Image-Based Identification and Consistent Classification of Fire Patterns with Quantitative Shape Analysis and Spatial Location Identification","abstract":"Fire patterns, consisting of fire effects that offer insights into fire behavior and origin, are traditionally classified based on investigators' visual observations, leading to subjective interpretations. This study proposes a framework for quantitative fire pattern classification to support fire investigators, aiming for consistency and accuracy. The framework integrates four components. First, it leverages human-computer interaction to extract fire patterns from surfaces, combining investigator expertise with computational analysis. Second, it employs an aspect ratio-based random forest model to classify fire pattern shapes. Third, fire scene point cloud segmentation enables precise identification of fire-affected areas and the mapping of 2D fire patterns to 3D scenes. Lastly, spatial relationships between fire patterns and indoor elements support an interpretation of the fire scene. These components provide a method for fire pattern analysis that synthesizes qualitative and quantitative data. The framework's classification results achieve 93% precision on synthetic data and 83% on real fire patterns.","sentences":["Fire patterns, consisting of fire effects that offer insights into fire behavior and origin, are traditionally classified based on investigators' visual observations, leading to subjective interpretations.","This study proposes a framework for quantitative fire pattern classification to support fire investigators, aiming for consistency and accuracy.","The framework integrates four components.","First, it leverages human-computer interaction to extract fire patterns from surfaces, combining investigator expertise with computational analysis.","Second, it employs an aspect ratio-based random forest model to classify fire pattern shapes.","Third, fire scene point cloud segmentation enables precise identification of fire-affected areas and the mapping of 2D fire patterns to 3D scenes.","Lastly, spatial relationships between fire patterns and indoor elements support an interpretation of the fire scene.","These components provide a method for fire pattern analysis that synthesizes qualitative and quantitative data.","The framework's classification results achieve 93% precision on synthetic data and 83% on real fire patterns."],"url":"http://arxiv.org/abs/2410.23105v1"}
{"created":"2024-10-30 15:12:36","title":"Guided Game Level Repair via Explainable AI","abstract":"Procedurally generated levels created by machine learning models can be unsolvable without further editing. Various methods have been developed to automatically repair these levels by enforcing hard constraints during the post-processing step. However, as levels increase in size, these constraint-based repairs become increasingly slow. This paper proposes using explainability methods to identify specific regions of a level that contribute to its unsolvability. By assigning higher weights to these regions, constraint-based solvers can prioritize these problematic areas, enabling more efficient repairs. Our results, tested across three games, demonstrate that this approach can help to repair procedurally generated levels faster.","sentences":["Procedurally generated levels created by machine learning models can be unsolvable without further editing.","Various methods have been developed to automatically repair these levels by enforcing hard constraints during the post-processing step.","However, as levels increase in size, these constraint-based repairs become increasingly slow.","This paper proposes using explainability methods to identify specific regions of a level that contribute to its unsolvability.","By assigning higher weights to these regions, constraint-based solvers can prioritize these problematic areas, enabling more efficient repairs.","Our results, tested across three games, demonstrate that this approach can help to repair procedurally generated levels faster."],"url":"http://arxiv.org/abs/2410.23101v1"}
{"created":"2024-10-30 15:11:58","title":"Comparative Analysis of Demonstration Selection Algorithms for LLM In-Context Learning","abstract":"In-context learning can help Large Language Models (LLMs) to adapt new tasks without additional training. However, this performance heavily depends on the quality of the demonstrations, driving research into effective demonstration selection algorithms to optimize this process. These algorithms assist users in selecting the best $k$ input-label pairs (demonstration examples) based on a given test input, enabling LLMs to in-context learn the relationship between the provided examples and the test inputs. Despite all the proposed demonstration selection algorithms, their efficiency and effectiveness remain unclear. This lack of clarity make it difficult to apply these algorithms in real-world scenarios and poses challenges for future research aimed at developing improved methods. This paper revisits six proposed algorithms, evaluating them on five datasets from both efficiency and effectiveness perspectives. Our experiments reveal significant variations in algorithm performance across different tasks, with some methods struggling to outperform random selection in certain scenarios. We also find that increasing the number of demonstrations does not always lead to better performance, and that there are often trade-offs between accuracy and computational efficiency. Our code is available at https://github.com/Tizzzzy/Demonstration_Selection_Overview.","sentences":["In-context learning can help Large Language Models (LLMs) to adapt new tasks without additional training.","However, this performance heavily depends on the quality of the demonstrations, driving research into effective demonstration selection algorithms to optimize this process.","These algorithms assist users in selecting the best $k$ input-label pairs (demonstration examples) based on a given test input, enabling LLMs to in-context learn the relationship between the provided examples and the test inputs.","Despite all the proposed demonstration selection algorithms, their efficiency and effectiveness remain unclear.","This lack of clarity make it difficult to apply these algorithms in real-world scenarios and poses challenges for future research aimed at developing improved methods.","This paper revisits six proposed algorithms, evaluating them on five datasets from both efficiency and effectiveness perspectives.","Our experiments reveal significant variations in algorithm performance across different tasks, with some methods struggling to outperform random selection in certain scenarios.","We also find that increasing the number of demonstrations does not always lead to better performance, and that there are often trade-offs between accuracy and computational efficiency.","Our code is available at https://github.com/Tizzzzy/Demonstration_Selection_Overview."],"url":"http://arxiv.org/abs/2410.23099v1"}
{"created":"2024-10-30 15:06:58","title":"First Place Solution to the ECCV 2024 ROAD++ Challenge @ ROAD++ Atomic Activity Recognition 2024","abstract":"This report presents our team's technical solution for participating in Track 3 of the 2024 ECCV ROAD++ Challenge. The task of Track 3 is atomic activity recognition, which aims to identify 64 types of atomic activities in road scenes based on video content. Our approach primarily addresses the challenges of small objects, discriminating between single object and a group of objects, as well as model overfitting in this task. Firstly, we construct a multi-branch activity recognition framework that not only separates different object categories but also the tasks of single object and object group recognition, thereby enhancing recognition accuracy. Subsequently, we develop various model ensembling strategies, including integrations of multiple frame sampling sequences, different frame sampling sequence lengths, multiple training epochs, and different backbone networks. Furthermore, we propose an atomic activity recognition data augmentation method, which greatly expands the sample space by flipping video frames and road topology, effectively mitigating model overfitting. Our methods rank first in the test set of Track 3 for the ROAD++ Challenge 2024, and achieve 69% mAP.","sentences":["This report presents our team's technical solution for participating in Track 3 of the 2024 ECCV ROAD++ Challenge.","The task of Track 3 is atomic activity recognition, which aims to identify 64 types of atomic activities in road scenes based on video content.","Our approach primarily addresses the challenges of small objects, discriminating between single object and a group of objects, as well as model overfitting in this task.","Firstly, we construct a multi-branch activity recognition framework that not only separates different object categories but also the tasks of single object and object group recognition, thereby enhancing recognition accuracy.","Subsequently, we develop various model ensembling strategies, including integrations of multiple frame sampling sequences, different frame sampling sequence lengths, multiple training epochs, and different backbone networks.","Furthermore, we propose an atomic activity recognition data augmentation method, which greatly expands the sample space by flipping video frames and road topology, effectively mitigating model overfitting.","Our methods rank first in the test set of Track 3 for the ROAD++ Challenge 2024, and achieve 69% mAP."],"url":"http://arxiv.org/abs/2410.23092v1"}
{"created":"2024-10-30 15:06:44","title":"CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for Adversarial Defense","abstract":"Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks. In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on essential factors. Inspired by this observation, we attempt to model label generation with essential label-causative factors and incorporate label-non-causative factors to assist data generation. For an adversarial example, we aim to discriminate the perturbations as non-causative factors and make predictions only based on the label-causative factors. Concretely, we propose a casual diffusion model (CausalDiff) that adapts diffusion models for conditional data generation and disentangles the two types of casual factors by learning towards a novel casual information bottleneck objective. Empirically, CausalDiff has significantly outperformed state-of-the-art defense methods on various unseen attacks, achieving an average robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on CIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition Benchmark).","sentences":["Despite ongoing efforts to defend neural classifiers from adversarial attacks, they remain vulnerable, especially to unseen attacks.","In contrast, humans are difficult to be cheated by subtle manipulations, since we make judgments only based on essential factors.","Inspired by this observation, we attempt to model label generation with essential label-causative factors and incorporate label-non-causative factors to assist data generation.","For an adversarial example, we aim to discriminate the perturbations as non-causative factors and make predictions only based on the label-causative factors.","Concretely, we propose a casual diffusion model (CausalDiff) that adapts diffusion models for conditional data generation and disentangles the two types of casual factors by learning towards a novel casual information bottleneck objective.","Empirically, CausalDiff has significantly outperformed state-of-the-art defense methods on various unseen attacks, achieving an average robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on CIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition Benchmark)."],"url":"http://arxiv.org/abs/2410.23091v1"}
{"created":"2024-10-30 15:06:32","title":"CORAL: Benchmarking Multi-turn Conversational Retrieval-Augmentation Generation","abstract":"Retrieval-Augmented Generation (RAG) has become a powerful paradigm for enhancing large language models (LLMs) through external knowledge retrieval. Despite its widespread attention, existing academic research predominantly focuses on single-turn RAG, leaving a significant gap in addressing the complexities of multi-turn conversations found in real-world applications. To bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess RAG systems in realistic multi-turn conversational settings. CORAL includes diverse information-seeking conversations automatically derived from Wikipedia and tackles key challenges such as open-domain coverage, knowledge intensity, free-form responses, and topic shifts. It supports three core tasks of conversational RAG: passage retrieval, response generation, and citation labeling. We propose a unified framework to standardize various conversational RAG methods and conduct a comprehensive evaluation of these methods on CORAL, demonstrating substantial opportunities for improving existing approaches.","sentences":["Retrieval-Augmented Generation (RAG) has become a powerful paradigm for enhancing large language models (LLMs) through external knowledge retrieval.","Despite its widespread attention, existing academic research predominantly focuses on single-turn RAG, leaving a significant gap in addressing the complexities of multi-turn conversations found in real-world applications.","To bridge this gap, we introduce CORAL, a large-scale benchmark designed to assess RAG systems in realistic multi-turn conversational settings.","CORAL includes diverse information-seeking conversations automatically derived from Wikipedia and tackles key challenges such as open-domain coverage, knowledge intensity, free-form responses, and topic shifts.","It supports three core tasks of conversational RAG: passage retrieval, response generation, and citation labeling.","We propose a unified framework to standardize various conversational RAG methods and conduct a comprehensive evaluation of these methods on CORAL, demonstrating substantial opportunities for improving existing approaches."],"url":"http://arxiv.org/abs/2410.23090v1"}
{"created":"2024-10-30 15:05:17","title":"PIP-MM: Pre-Integrating Prompt Information into Visual Encoding via Existing MLLM Structures","abstract":"The Multimodal Large Language Models (MLLMs) have activated the capabilitiesof Large Language Models (LLMs) in solving visual-language tasks by integratingvisual information. The prevailing approach in existing MLLMs involvesemploying an image encoder to extract visual features, converting thesefeatures into visual tokens via an adapter, and then integrating them with theprompt into the LLM. However, because the process of image encoding isprompt-agnostic, the extracted visual features only provide a coarsedescription of the image, impossible to focus on the requirements of theprompt. On one hand, it is easy for image features to lack information aboutthe prompt-specified objects, resulting in unsatisfactory responses. On theother hand, the visual features contain a large amount of irrelevantinformation, which not only increases the burden on memory but also worsens thegeneration effectiveness. To address the aforementioned issues, we propose\\textbf{PIP-MM}, a framework that \\textbf{P}re-\\textbf{I}ntegrates\\textbf{P}rompt information into the visual encoding process using existingmodules of MLLMs. Specifically, We utilize the frozen LLM in the MLLM tovectorize the input prompt, which summarizes the requirements of the prompt.Then, we input the prompt vector into our trained Multi-Layer Perceptron (MLP)to align with the visual input requirements, and subsequently replace the classembedding in the image encoder. Since our model only requires adding atrainable MLP, it can be applied to any MLLM. To validate the effectiveness ofPIP-MM, we conducted experiments on multiple benchmarks. Automated evaluationmetrics and manual assessments demonstrate the strong performance of PIP-MM.Particularly noteworthy is that our model maintains excellent generationresults even when half of the visual tokens are reduced.","sentences":["The Multimodal Large Language Models (MLLMs) have activated the capabilitiesof Large Language Models (LLMs) in solving visual-language tasks by integratingvisual information.","The prevailing approach in existing MLLMs involvesemploying an image encoder to extract visual features, converting thesefeatures into visual tokens via an adapter, and then integrating them with theprompt into the LLM.","However, because the process of image encoding isprompt-agnostic, the extracted visual features only provide a coarsedescription of the image, impossible to focus on the requirements of theprompt.","On one hand, it is easy for image features to lack information aboutthe prompt-specified objects, resulting in unsatisfactory responses.","On theother hand, the visual features contain a large amount of irrelevantinformation, which not only increases the burden on memory but also worsens thegeneration effectiveness.","To address the aforementioned issues, we propose\\textbf{PIP-MM}, a framework that \\textbf{P}re-\\textbf{I}ntegrates\\textbf{P}rompt information into the visual encoding process using existingmodules of MLLMs.","Specifically, We utilize the frozen LLM in the MLLM tovectorize the input prompt, which summarizes the requirements of the prompt.","Then, we input the prompt vector into our trained Multi-Layer Perceptron (MLP)to align with the visual input requirements, and subsequently replace the classembedding in the image encoder.","Since our model only requires adding atrainable MLP, it can be applied to any MLLM.","To validate the effectiveness ofPIP-MM, we conducted experiments on multiple benchmarks.","Automated evaluationmetrics and manual assessments demonstrate the strong performance of PIP-MM.Particularly noteworthy is that our model maintains excellent generationresults even when half of the visual tokens are reduced."],"url":"http://arxiv.org/abs/2410.23089v1"}
{"created":"2024-10-30 15:03:33","title":"Statistical-Computational Trade-offs for Density Estimation","abstract":"We study the density estimation problem defined as follows: given $k$ distributions $p_1, \\ldots, p_k$ over a discrete domain $[n]$, as well as a collection of samples chosen from a ``query'' distribution $q$ over $[n]$, output $p_i$ that is ``close'' to $q$. Recently~\\cite{aamand2023data} gave the first and only known result that achieves sublinear bounds in {\\em both} the sampling complexity and the query time while preserving polynomial data structure space. However, their improvement over linear samples and time is only by subpolynomial factors.   Our main result is a lower bound showing that, for a broad class of data structures, their bounds cannot be significantly improved. In particular, if an algorithm uses $O(n/\\log^c k)$ samples for some constant $c>0$ and polynomial space, then the query time of the data structure must be at least $k^{1-O(1)/\\log \\log k}$, i.e., close to linear in the number of distributions $k$. This is a novel \\emph{statistical-computational} trade-off for density estimation, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time. The lower bound holds even in the realizable case where $q=p_i$ for some $i$, and when the distributions are flat (specifically, all distributions are uniform over half of the domain $[n]$). We also give a simple data structure for our lower bound instance with asymptotically matching upper bounds. Experiments show that the data structure is quite efficient in practice.","sentences":["We study the density estimation problem defined as follows: given $k$ distributions $p_1, \\ldots, p_k$ over a discrete domain $[n]$, as well as a collection of samples chosen from a ``query'' distribution $q$ over $[n]$, output $p_i$ that is ``close'' to $q$. Recently~\\cite{aamand2023data} gave the first and only known result that achieves sublinear bounds in {\\em both} the sampling complexity and the query time while preserving polynomial data structure space.","However, their improvement over linear samples and time is only by subpolynomial factors.   ","Our main result is a lower bound showing that, for a broad class of data structures, their bounds cannot be significantly improved.","In particular, if an algorithm uses $O(n/\\log^c k)$ samples for some constant $c>0$ and polynomial space, then the query time of the data structure must be at least $k^{1-O(1)/\\log \\log k}$, i.e., close to linear in the number of distributions $k$.","This is a novel \\emph{statistical-computational} trade-off for density estimation, demonstrating that any data structure must use close to a linear number of samples or take close to linear query time.","The lower bound holds even in the realizable case where $q=p_i$ for some $i$, and when the distributions are flat (specifically, all distributions are uniform over half of the domain $[n]$).","We also give a simple data structure for our lower bound instance with asymptotically matching upper bounds.","Experiments show that the data structure is quite efficient in practice."],"url":"http://arxiv.org/abs/2410.23087v1"}
{"created":"2024-10-30 15:02:54","title":"From Hype to Reality: The Road Ahead of Deploying DRL in 6G Networks","abstract":"The industrial landscape is rapidly evolving with the advent of 6G applications, which demand massive connectivity, high computational capacity, and ultra-low latency. These requirements present new challenges, which can no longer be efficiently addressed by conventional strategies. In response, this article underscores the transformative potential of Deep Reinforcement Learning (DRL) for 6G, highlighting its advantages over classic machine learning solutions in meeting the demands of 6G. The necessity of DRL is further validated through three DRL applications in an end-to-end communication procedure, including wireless access control, baseband function placement, and network slicing coordination. However, DRL-based network management initiatives are far from mature. We extend the discussion to identify the challenges of applying DRL in practical networks and explore potential solutions along with their respective limitations. In the end, these insights are validated through a practical DRL deployment in managing network slices on the testbed.","sentences":["The industrial landscape is rapidly evolving with the advent of 6G applications, which demand massive connectivity, high computational capacity, and ultra-low latency.","These requirements present new challenges, which can no longer be efficiently addressed by conventional strategies.","In response, this article underscores the transformative potential of Deep Reinforcement Learning (DRL) for 6G, highlighting its advantages over classic machine learning solutions in meeting the demands of 6G.","The necessity of DRL is further validated through three DRL applications in an end-to-end communication procedure, including wireless access control, baseband function placement, and network slicing coordination.","However, DRL-based network management initiatives are far from mature.","We extend the discussion to identify the challenges of applying DRL in practical networks and explore potential solutions along with their respective limitations.","In the end, these insights are validated through a practical DRL deployment in managing network slices on the testbed."],"url":"http://arxiv.org/abs/2410.23086v1"}
