{"created":"2025-03-05 18:59:50","title":"GEN3C: 3D-Informed World-Consistent Video Generation with Precise Camera Control","abstract":"We present GEN3C, a generative video model with precise Camera Control and temporal 3D Consistency. Prior video models already generate realistic videos, but they tend to leverage little 3D information, leading to inconsistencies, such as objects popping in and out of existence. Camera control, if implemented at all, is imprecise, because camera parameters are mere inputs to the neural network which must then infer how the video depends on the camera. In contrast, GEN3C is guided by a 3D cache: point clouds obtained by predicting the pixel-wise depth of seed images or previously generated frames. When generating the next frames, GEN3C is conditioned on the 2D renderings of the 3D cache with the new camera trajectory provided by the user. Crucially, this means that GEN3C neither has to remember what it previously generated nor does it have to infer the image structure from the camera pose. The model, instead, can focus all its generative power on previously unobserved regions, as well as advancing the scene state to the next frame. Our results demonstrate more precise camera control than prior work, as well as state-of-the-art results in sparse-view novel view synthesis, even in challenging settings such as driving scenes and monocular dynamic video. Results are best viewed in videos. Check out our webpage! https://research.nvidia.com/labs/toronto-ai/GEN3C/","sentences":["We present GEN3C, a generative video model with precise Camera Control and temporal 3D Consistency.","Prior video models already generate realistic videos, but they tend to leverage little 3D information, leading to inconsistencies, such as objects popping in and out of existence.","Camera control, if implemented at all, is imprecise, because camera parameters are mere inputs to the neural network which must then infer how the video depends on the camera.","In contrast, GEN3C is guided by a 3D cache: point clouds obtained by predicting the pixel-wise depth of seed images or previously generated frames.","When generating the next frames, GEN3C is conditioned on the 2D renderings of the 3D cache with the new camera trajectory provided by the user.","Crucially, this means that GEN3C","neither has to remember what it previously generated nor does it have to infer the image structure from the camera pose.","The model, instead, can focus all its generative power on previously unobserved regions, as well as advancing the scene state to the next frame.","Our results demonstrate more precise camera control than prior work, as well as state-of-the-art results in sparse-view novel view synthesis, even in challenging settings such as driving scenes and monocular dynamic video.","Results are best viewed in videos.","Check out our webpage! https://research.nvidia.com/labs/toronto-ai/GEN3C/"],"url":"http://arxiv.org/abs/2503.03751v1"}
{"created":"2025-03-05 18:59:23","title":"The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems","abstract":"As large language models (LLMs) become more capable and agentic, the requirement for trust in their outputs grows significantly, yet at the same time concerns have been mounting that models may learn to lie in pursuit of their goals. To address these concerns, a body of work has emerged around the notion of \"honesty\" in LLMs, along with interventions aimed at mitigating deceptive behaviors. However, evaluations of honesty are currently highly limited, with no benchmark combining large scale and applicability to all models. Moreover, many benchmarks claiming to measure honesty in fact simply measure accuracy--the correctness of a model's beliefs--in disguise. In this work, we introduce a large-scale human-collected dataset for measuring honesty directly, allowing us to disentangle accuracy from honesty for the first time. Across a diverse set of LLMs, we find that while larger models obtain higher accuracy on our benchmark, they do not become more honest. Surprisingly, while most frontier LLMs obtain high scores on truthfulness benchmarks, we find a substantial propensity in frontier LLMs to lie when pressured to do so, resulting in low honesty scores on our benchmark. We find that simple methods, such as representation engineering interventions, can improve honesty. These results underscore the growing need for robust evaluations and effective interventions to ensure LLMs remain trustworthy.","sentences":["As large language models (LLMs) become more capable and agentic, the requirement for trust in their outputs grows significantly, yet at the same time concerns have been mounting that models may learn to lie in pursuit of their goals.","To address these concerns, a body of work has emerged around the notion of \"honesty\" in LLMs, along with interventions aimed at mitigating deceptive behaviors.","However, evaluations of honesty are currently highly limited, with no benchmark combining large scale and applicability to all models.","Moreover, many benchmarks claiming to measure honesty in fact simply measure accuracy--the correctness of a model's beliefs--in disguise.","In this work, we introduce a large-scale human-collected dataset for measuring honesty directly, allowing us to disentangle accuracy from honesty for the first time.","Across a diverse set of LLMs, we find that while larger models obtain higher accuracy on our benchmark, they do not become more honest.","Surprisingly, while most frontier LLMs obtain high scores on truthfulness benchmarks, we find a substantial propensity in frontier LLMs to lie when pressured to do so, resulting in low honesty scores on our benchmark.","We find that simple methods, such as representation engineering interventions, can improve honesty.","These results underscore the growing need for robust evaluations and effective interventions to ensure LLMs remain trustworthy."],"url":"http://arxiv.org/abs/2503.03750v1"}
{"created":"2025-03-05 18:58:58","title":"PacketCLIP: Multi-Modal Embedding of Network Traffic and Language for Cybersecurity Reasoning","abstract":"Traffic classification is vital for cybersecurity, yet encrypted traffic poses significant challenges. We present PacketCLIP, a multi-modal framework combining packet data with natural language semantics through contrastive pretraining and hierarchical Graph Neural Network (GNN) reasoning. PacketCLIP integrates semantic reasoning with efficient classification, enabling robust detection of anomalies in encrypted network flows. By aligning textual descriptions with packet behaviors, it offers enhanced interpretability, scalability, and practical applicability across diverse security scenarios. PacketCLIP achieves a 95% mean AUC, outperforms baselines by 11.6%, and reduces model size by 92%, making it ideal for real-time anomaly detection. By bridging advanced machine learning techniques and practical cybersecurity needs, PacketCLIP provides a foundation for scalable, efficient, and interpretable solutions to tackle encrypted traffic classification and network intrusion detection challenges in resource-constrained environments.","sentences":["Traffic classification is vital for cybersecurity, yet encrypted traffic poses significant challenges.","We present PacketCLIP, a multi-modal framework combining packet data with natural language semantics through contrastive pretraining and hierarchical Graph Neural Network (GNN) reasoning.","PacketCLIP integrates semantic reasoning with efficient classification, enabling robust detection of anomalies in encrypted network flows.","By aligning textual descriptions with packet behaviors, it offers enhanced interpretability, scalability, and practical applicability across diverse security scenarios.","PacketCLIP achieves a 95% mean AUC, outperforms baselines by 11.6%, and reduces model size by 92%, making it ideal for real-time anomaly detection.","By bridging advanced machine learning techniques and practical cybersecurity needs, PacketCLIP provides a foundation for scalable, efficient, and interpretable solutions to tackle encrypted traffic classification and network intrusion detection challenges in resource-constrained environments."],"url":"http://arxiv.org/abs/2503.03747v1"}
{"created":"2025-03-05 18:58:44","title":"Process-based Self-Rewarding Language Models","abstract":"Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios. Human-annotated preference data is used for training to further improve LLMs' performance, which is constrained by the upper limit of human performance. Therefore, Self-Rewarding method has been proposed, where LLMs generate training data by rewarding their own outputs. However, the existing self-rewarding paradigm is not effective in mathematical reasoning scenarios and may even lead to a decline in performance. In this work, we propose the Process-based Self-Rewarding pipeline for language models, which introduces long-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference optimization within the self-rewarding paradigm. Our new paradigm successfully enhances the performance of LLMs on multiple mathematical reasoning benchmarks through iterative Process-based Self-Rewarding, demonstrating the immense potential of self-rewarding to achieve LLM reasoning that may surpass human capabilities.","sentences":["Large Language Models have demonstrated outstanding performance across various downstream tasks and have been widely applied in multiple scenarios.","Human-annotated preference data is used for training to further improve LLMs' performance, which is constrained by the upper limit of human performance.","Therefore, Self-Rewarding method has been proposed, where LLMs generate training data by rewarding their own outputs.","However, the existing self-rewarding paradigm is not effective in mathematical reasoning scenarios and may even lead to a decline in performance.","In this work, we propose the Process-based Self-Rewarding pipeline for language models, which introduces long-thought reasoning, step-wise LLM-as-a-Judge, and step-wise preference optimization within the self-rewarding paradigm.","Our new paradigm successfully enhances the performance of LLMs on multiple mathematical reasoning benchmarks through iterative Process-based Self-Rewarding, demonstrating the immense potential of self-rewarding to achieve LLM reasoning that may surpass human capabilities."],"url":"http://arxiv.org/abs/2503.03746v1"}
{"created":"2025-03-05 18:56:48","title":"Constrained Gaussian Wasserstein Optimal Transport with Commutative Covariance Matrices","abstract":"Optimal transport has found widespread applications in signal processing and machine learning. Among its many equivalent formulations, optimal transport seeks to reconstruct a random variable/vector with a prescribed distribution at the destination while minimizing the expected distortion relative to a given random variable/vector at the source. However, in practice, certain constraints may render the optimal transport plan infeasible. In this work, we consider three types of constraints: rate constraints, dimension constraints, and channel constraints, motivated by perception-aware lossy compression, generative principal component analysis, and deep joint source-channel coding, respectively. Special attenion is given to the setting termed Gaussian Wasserstein optimal transport, where both the source and reconstruction variables are multivariate Gaussian, and the end-to-end distortion is measured by the mean squared error. We derive explicit results for the minimum achievable mean squared error under the three aforementioned constraints when the covariance matrices of the source and reconstruction variables commute.","sentences":["Optimal transport has found widespread applications in signal processing and machine learning.","Among its many equivalent formulations, optimal transport seeks to reconstruct a random variable/vector with a prescribed distribution at the destination while minimizing the expected distortion relative to a given random variable/vector at the source.","However, in practice, certain constraints may render the optimal transport plan infeasible.","In this work, we consider three types of constraints: rate constraints, dimension constraints, and channel constraints, motivated by perception-aware lossy compression, generative principal component analysis, and deep joint source-channel coding, respectively.","Special attenion is given to the setting termed Gaussian Wasserstein optimal transport, where both the source and reconstruction variables are multivariate Gaussian, and the end-to-end distortion is measured by the mean squared error.","We derive explicit results for the minimum achievable mean squared error under the three aforementioned constraints when the covariance matrices of the source and reconstruction variables commute."],"url":"http://arxiv.org/abs/2503.03744v1"}
{"created":"2025-03-05 18:56:16","title":"CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning","abstract":"The advancement of visual language models (VLMs) has enhanced mobile device operations, allowing simulated human-like actions to address user requirements. Current VLM-based mobile operating assistants can be structured into three levels: task, subtask, and action. The subtask level, linking high-level goals with low-level executable actions, is crucial for task completion but faces two challenges: ineffective subtasks that lower-level agent cannot execute and inefficient subtasks that fail to contribute to the completion of the higher-level task. These challenges stem from VLM's lack of experience in decomposing subtasks within GUI scenarios in multi-agent architecture. To address these, we propose a new mobile assistant architecture with constrained high-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's deficiency in GUI scenarios planning by using human-planned subtasks as the basis vector. We evaluate our architecture in both English and Chinese contexts across 20 Apps, demonstrating significant improvements in both effectiveness and efficiency. Our dataset and code is available at https://github.com/Yuqi-Zhou/CHOP","sentences":["The advancement of visual language models (VLMs) has enhanced mobile device operations, allowing simulated human-like actions to address user requirements.","Current VLM-based mobile operating assistants can be structured into three levels: task, subtask, and action.","The subtask level, linking high-level goals with low-level executable actions, is crucial for task completion but faces two challenges: ineffective subtasks that lower-level agent cannot execute and inefficient subtasks that fail to contribute to the completion of the higher-level task.","These challenges stem from VLM's lack of experience in decomposing subtasks within GUI scenarios in multi-agent architecture.","To address these, we propose a new mobile assistant architecture with constrained high-frequency o}ptimized planning (CHOP).","Our approach overcomes the VLM's deficiency in GUI scenarios planning by using human-planned subtasks as the basis vector.","We evaluate our architecture in both English and Chinese contexts across 20 Apps, demonstrating significant improvements in both effectiveness and efficiency.","Our dataset and code is available at https://github.com/Yuqi-Zhou/CHOP"],"url":"http://arxiv.org/abs/2503.03743v1"}
{"created":"2025-03-05 18:44:48","title":"OTTER: A Vision-Language-Action Model with Text-Aware Visual Feature Extraction","abstract":"Vision-Language-Action (VLA) models aim to predict robotic actions based on visual observations and language instructions. Existing approaches require fine-tuning pre-trained visionlanguage models (VLMs) as visual and language features are independently fed into downstream policies, degrading the pre-trained semantic alignments. We propose OTTER, a novel VLA architecture that leverages these existing alignments through explicit, text-aware visual feature extraction. Instead of processing all visual features, OTTER selectively extracts and passes only task-relevant visual features that are semantically aligned with the language instruction to the policy transformer. This allows OTTER to keep the pre-trained vision-language encoders frozen. Thereby, OTTER preserves and utilizes the rich semantic understanding learned from large-scale pre-training, enabling strong zero-shot generalization capabilities. In simulation and real-world experiments, OTTER significantly outperforms existing VLA models, demonstrating strong zeroshot generalization to novel objects and environments. Video, code, checkpoints, and dataset: https://ottervla.github.io/.","sentences":["Vision-Language-Action (VLA) models aim to predict robotic actions based on visual observations and language instructions.","Existing approaches require fine-tuning pre-trained visionlanguage models (VLMs) as visual and language features are independently fed into downstream policies, degrading the pre-trained semantic alignments.","We propose OTTER, a novel VLA architecture that leverages these existing alignments through explicit, text-aware visual feature extraction.","Instead of processing all visual features, OTTER selectively extracts and passes only task-relevant visual features that are semantically aligned with the language instruction to the policy transformer.","This allows OTTER to keep the pre-trained vision-language encoders frozen.","Thereby, OTTER preserves and utilizes the rich semantic understanding learned from large-scale pre-training, enabling strong zero-shot generalization capabilities.","In simulation and real-world experiments, OTTER significantly outperforms existing VLA models, demonstrating strong zeroshot generalization to novel objects and environments.","Video, code, checkpoints, and dataset: https://ottervla.github.io/."],"url":"http://arxiv.org/abs/2503.03734v1"}
{"created":"2025-03-05 18:44:35","title":"Rethinking Deep Clustering Paradigms: Self-Supervision Is All You Need","abstract":"The recent advances in deep clustering have been made possible by significant progress in self-supervised and pseudo-supervised learning. However, the trade-off between self-supervision and pseudo-supervision can give rise to three primary issues. The joint training causes Feature Randomness and Feature Drift, whereas the independent training causes Feature Randomness and Feature Twist. In essence, using pseudo-labels generates random and unreliable features. The combination of pseudo-supervision and self-supervision drifts the reliable clustering-oriented features. Moreover, moving from self-supervision to pseudo-supervision can twist the curved latent manifolds. This paper addresses the limitations of existing deep clustering paradigms concerning Feature Randomness, Feature Drift, and Feature Twist. We propose a new paradigm with a new strategy that replaces pseudo-supervision with a second round of self-supervision training. The new strategy makes the transition between instance-level self-supervision and neighborhood-level self-supervision smoother and less abrupt. Moreover, it prevents the drifting effect that is caused by the strong competition between instance-level self-supervision and clustering-level pseudo-supervision. Moreover, the absence of the pseudo-supervision prevents the risk of generating random features. With this novel approach, our paper introduces a Rethinking of the Deep Clustering Paradigms, denoted by R-DC. Our model is specifically designed to address three primary challenges encountered in Deep Clustering: Feature Randomness, Feature Drift, and Feature Twist. Experimental results conducted on six datasets have shown that the two-level self-supervision training yields substantial improvements.","sentences":["The recent advances in deep clustering have been made possible by significant progress in self-supervised and pseudo-supervised learning.","However, the trade-off between self-supervision and pseudo-supervision can give rise to three primary issues.","The joint training causes Feature Randomness and Feature Drift, whereas the independent training causes Feature Randomness and Feature Twist.","In essence, using pseudo-labels generates random and unreliable features.","The combination of pseudo-supervision and self-supervision drifts the reliable clustering-oriented features.","Moreover, moving from self-supervision to pseudo-supervision can twist the curved latent manifolds.","This paper addresses the limitations of existing deep clustering paradigms concerning Feature Randomness, Feature Drift, and Feature Twist.","We propose a new paradigm with a new strategy that replaces pseudo-supervision with a second round of self-supervision training.","The new strategy makes the transition between instance-level self-supervision and neighborhood-level self-supervision smoother and less abrupt.","Moreover, it prevents the drifting effect that is caused by the strong competition between instance-level self-supervision and clustering-level pseudo-supervision.","Moreover, the absence of the pseudo-supervision prevents the risk of generating random features.","With this novel approach, our paper introduces a Rethinking of the Deep Clustering Paradigms, denoted by R-DC.","Our model is specifically designed to address three primary challenges encountered in Deep Clustering: Feature Randomness, Feature Drift, and Feature Twist.","Experimental results conducted on six datasets have shown that the two-level self-supervision training yields substantial improvements."],"url":"http://arxiv.org/abs/2503.03733v1"}
{"created":"2025-03-05 18:40:19","title":"Towards Understanding Distilled Reasoning Models: A Representational Approach","abstract":"In this paper, we investigate how model distillation impacts the development of reasoning features in large language models (LLMs). To explore this, we train a crosscoder on Qwen-series models and their fine-tuned variants. Our results suggest that the crosscoder learns features corresponding to various types of reasoning, including self-reflection and computation verification. Moreover, we observe that distilled models contain unique reasoning feature directions, which could be used to steer the model into over-thinking or incisive-thinking mode. In particular, we perform analysis on four specific reasoning categories: (a) self-reflection, (b) deductive reasoning, (c) alternative reasoning, and (d) contrastive reasoning. Finally, we examine the changes in feature geometry resulting from the distillation process and find indications that larger distilled models may develop more structured representations, which correlate with enhanced distillation performance. By providing insights into how distillation modifies the model, our study contributes to enhancing the transparency and reliability of AI systems.","sentences":["In this paper, we investigate how model distillation impacts the development of reasoning features in large language models (LLMs).","To explore this, we train a crosscoder on Qwen-series models and their fine-tuned variants.","Our results suggest that the crosscoder learns features corresponding to various types of reasoning, including self-reflection and computation verification.","Moreover, we observe that distilled models contain unique reasoning feature directions, which could be used to steer the model into over-thinking or incisive-thinking mode.","In particular, we perform analysis on four specific reasoning categories: (a) self-reflection, (b) deductive reasoning, (c) alternative reasoning, and (d) contrastive reasoning.","Finally, we examine the changes in feature geometry resulting from the distillation process and find indications that larger distilled models may develop more structured representations, which correlate with enhanced distillation performance.","By providing insights into how distillation modifies the model, our study contributes to enhancing the transparency and reliability of AI systems."],"url":"http://arxiv.org/abs/2503.03730v1"}
{"created":"2025-03-05 18:37:52","title":"Graph-Augmented LSTM for Forecasting Sparse Anomalies in Graph-Structured Time Series","abstract":"Detecting anomalies in time series data is a critical task across many domains. The challenge intensifies when anomalies are sparse and the data are multivariate with relational dependencies across sensors or nodes. Traditional univariate anomaly detectors struggle to capture such cross-node dependencies, particularly in sparse anomaly settings. To address this, we propose a graph-augmented time series forecasting approach that explicitly integrates the graph of relationships among time series into an LSTM forecasting model. This enables the model to detect rare anomalies that might otherwise go unnoticed in purely univariate approaches. We evaluate the approach on two benchmark datasets - the Yahoo Webscope S5 anomaly dataset and the METR-LA traffic sensor network - and compare the performance of the Graph-Augmented LSTM against LSTM-only, ARIMA, and Prophet baselines. Results demonstrate that the graph-augmented model achieves significantly higher precision and recall, improving F1-score by up to 10% over the best baseline","sentences":["Detecting anomalies in time series data is a critical task across many domains.","The challenge intensifies when anomalies are sparse and the data are multivariate with relational dependencies across sensors or nodes.","Traditional univariate anomaly detectors struggle to capture such cross-node dependencies, particularly in sparse anomaly settings.","To address this, we propose a graph-augmented time series forecasting approach that explicitly integrates the graph of relationships among time series into an LSTM forecasting model.","This enables the model to detect rare anomalies that might otherwise go unnoticed in purely univariate approaches.","We evaluate the approach on two benchmark datasets - the Yahoo Webscope S5 anomaly dataset and the METR-LA traffic sensor network - and compare the performance of the Graph-Augmented LSTM against LSTM-only, ARIMA, and Prophet baselines.","Results demonstrate that the graph-augmented model achieves significantly higher precision and recall, improving F1-score by up to 10% over the best baseline"],"url":"http://arxiv.org/abs/2503.03729v1"}
{"created":"2025-03-05 18:28:32","title":"Active 6D Pose Estimation for Textureless Objects using Multi-View RGB Frames","abstract":"Estimating the 6D pose of textureless objects from RBG images is an important problem in robotics. Due to appearance ambiguities, rotational symmetries, and severe occlusions, single-view based 6D pose estimators are still unable to handle a wide range of objects, motivating research towards multi-view pose estimation and next-best-view prediction that addresses these limitations. In this work, we propose a comprehensive active perception framework for estimating the 6D poses of textureless objects using only RGB images. Our approach is built upon a key idea: decoupling the 6D pose estimation into a sequential two-step process can greatly improve both accuracy and efficiency. First, we estimate the 3D translation of each object, resolving scale and depth ambiguities inherent to RGB images. These estimates are then used to simplify the subsequent task of determining the 3D orientation, which we achieve through canonical scale template matching. Building on this formulation, we then introduce an active perception strategy that predicts the next best camera viewpoint to capture an RGB image, effectively reducing object pose uncertainty and enhancing pose accuracy. We evaluate our method on the public ROBI dataset as well as on a transparent object dataset that we created. When evaluated using the same camera viewpoints, our multi-view pose estimation significantly outperforms state-of-the-art approaches. Furthermore, by leveraging our next-best-view strategy, our method achieves high object pose accuracy with substantially fewer viewpoints than heuristic-based policies.","sentences":["Estimating the 6D pose of textureless objects from RBG images is an important problem in robotics.","Due to appearance ambiguities, rotational symmetries, and severe occlusions, single-view based 6D pose estimators are still unable to handle a wide range of objects, motivating research towards multi-view pose estimation and next-best-view prediction that addresses these limitations.","In this work, we propose a comprehensive active perception framework for estimating the 6D poses of textureless objects using only RGB images.","Our approach is built upon a key idea: decoupling the 6D pose estimation into a sequential two-step process can greatly improve both accuracy and efficiency.","First, we estimate the 3D translation of each object, resolving scale and depth ambiguities inherent to RGB images.","These estimates are then used to simplify the subsequent task of determining the 3D orientation, which we achieve through canonical scale template matching.","Building on this formulation, we then introduce an active perception strategy that predicts the next best camera viewpoint to capture an RGB image, effectively reducing object pose uncertainty and enhancing pose accuracy.","We evaluate our method on the public ROBI dataset as well as on a transparent object dataset that we created.","When evaluated using the same camera viewpoints, our multi-view pose estimation significantly outperforms state-of-the-art approaches.","Furthermore, by leveraging our next-best-view strategy, our method achieves high object pose accuracy with substantially fewer viewpoints than heuristic-based policies."],"url":"http://arxiv.org/abs/2503.03726v1"}
{"created":"2025-03-05 18:21:34","title":"When Radiation Meets Linux: Analyzing Soft Errors in Linux on COTS SoCs under Proton Irradiation","abstract":"The increasing use of Linux on commercial off-the-shelf (COTS) system-on-chip (SoC) in spaceborne computing inherits COTS susceptibility to radiation-induced failures like soft errors. Modern SoCs exacerbate this issue as aggressive transistor scaling reduces critical charge thresholds to induce soft errors and increases radiation effects within densely packed transistors, degrading overall reliability. Linux's monolithic architecture amplifies these risks, as tightly coupled kernel subsystems propagate errors to critical components (e.g., memory management), while limited error-correcting code (ECC) offers minimal mitigation. Furthermore, the lack of public soft error data from irradiation tests on COTS SoCs running Linux hinders reliability improvements. This study evaluates proton irradiation effects (20-50 MeV) on Linux across three COTS SoC architectures: Raspberry Pi Zero 2 W (40 nm CMOS, Cortex-A53), NXP i.MX 8M Plus (14 nm FinFET, Cortex-A53), and OrangeCrab (40 nm FPGA, RISC-V). Irradiation results show the 14 nm FinFET NXP SoC achieved 2-3x longer Linux uptime without ECC memory versus both 40 nm CMOS counterparts, partially due to FinFET's reduced charge collection. Additionally, this work presents the first cross-architecture analysis of soft error-prone Linux kernel components in modern SoCs to develop targeted mitigations. The findings establish foundational data on Linux's soft error sensitivity in COTS SoCs, guiding mission readiness for space applications.","sentences":["The increasing use of Linux on commercial off-the-shelf (COTS) system-on-chip (SoC) in spaceborne computing inherits COTS susceptibility to radiation-induced failures like soft errors.","Modern SoCs exacerbate this issue as aggressive transistor scaling reduces critical charge thresholds to induce soft errors and increases radiation effects within densely packed transistors, degrading overall reliability.","Linux's monolithic architecture amplifies these risks, as tightly coupled kernel subsystems propagate errors to critical components (e.g., memory management), while limited error-correcting code (ECC) offers minimal mitigation.","Furthermore, the lack of public soft error data from irradiation tests on COTS SoCs running Linux hinders reliability improvements.","This study evaluates proton irradiation effects (20-50 MeV) on Linux across three COTS SoC architectures: Raspberry Pi Zero 2 W (40 nm CMOS, Cortex-A53), NXP i.MX 8M Plus (14 nm FinFET, Cortex-A53), and OrangeCrab (40 nm FPGA, RISC-V).","Irradiation results show the 14 nm FinFET NXP SoC achieved 2-3x longer Linux uptime without ECC memory versus both 40 nm CMOS counterparts, partially due to FinFET's reduced charge collection.","Additionally, this work presents the first cross-architecture analysis of soft error-prone Linux kernel components in modern SoCs to develop targeted mitigations.","The findings establish foundational data on Linux's soft error sensitivity in COTS SoCs, guiding mission readiness for space applications."],"url":"http://arxiv.org/abs/2503.03722v1"}
{"created":"2025-03-05 18:10:11","title":"Machine Learning in Biomechanics: Key Applications and Limitations in Walking, Running, and Sports Movements","abstract":"This chapter provides an overview of recent and promising Machine Learning applications, i.e. pose estimation, feature estimation, event detection, data exploration & clustering, and automated classification, in gait (walking and running) and sports biomechanics. It explores the potential of Machine Learning methods to address challenges in biomechanical workflows, highlights central limitations, i.e. data and annotation availability and explainability, that need to be addressed, and emphasises the importance of interdisciplinary approaches for fully harnessing the potential of Machine Learning in gait and sports biomechanics.","sentences":["This chapter provides an overview of recent and promising Machine Learning applications, i.e. pose estimation, feature estimation, event detection, data exploration & clustering, and automated classification, in gait (walking and running) and sports biomechanics.","It explores the potential of Machine Learning methods to address challenges in biomechanical workflows, highlights central limitations, i.e. data and annotation availability and explainability, that need to be addressed, and emphasises the importance of interdisciplinary approaches for fully harnessing the potential of Machine Learning in gait and sports biomechanics."],"url":"http://arxiv.org/abs/2503.03717v1"}
{"created":"2025-03-05 18:04:30","title":"Handling Uncertainty in Health Data using Generative Algorithms","abstract":"Understanding and managing uncertainty is crucial in machine learning, especially in high-stakes domains like healthcare, where class imbalance can impact predictions. This paper introduces RIGA, a novel pipeline that mitigates class imbalance using generative AI. By converting tabular healthcare data into images, RIGA leverages models like cGAN, VQVAE, and VQGAN to generate balanced samples, improving classification performance. These representations are processed by CNNs and later transformed back into tabular format for seamless integration. This approach enhances traditional classifiers like XGBoost, improves Bayesian structure learning, and strengthens ML model robustness by generating realistic synthetic data for underrepresented classes.","sentences":["Understanding and managing uncertainty is crucial in machine learning, especially in high-stakes domains like healthcare, where class imbalance can impact predictions.","This paper introduces RIGA, a novel pipeline that mitigates class imbalance using generative AI.","By converting tabular healthcare data into images, RIGA leverages models like cGAN, VQVAE, and VQGAN to generate balanced samples, improving classification performance.","These representations are processed by CNNs and later transformed back into tabular format for seamless integration.","This approach enhances traditional classifiers like XGBoost, improves Bayesian structure learning, and strengthens ML model robustness by generating realistic synthetic data for underrepresented classes."],"url":"http://arxiv.org/abs/2503.03715v1"}
{"created":"2025-03-05 18:01:05","title":"Improving LLM Safety Alignment with Dual-Objective Optimization","abstract":"Existing training-time safety alignment techniques for large language models (LLMs) remain vulnerable to jailbreak attacks. Direct preference optimization (DPO), a widely deployed alignment method, exhibits limitations in both experimental and theoretical contexts as its loss function proves suboptimal for refusal learning. Through gradient-based analysis, we identify these shortcomings and propose an improved safety alignment that disentangles DPO objectives into two components: (1) robust refusal training, which encourages refusal even when partial unsafe generations are produced, and (2) targeted unlearning of harmful knowledge. This approach significantly increases LLM robustness against a wide range of jailbreak attacks, including prefilling, suffix, and multi-turn attacks across both in-distribution and out-of-distribution scenarios. Furthermore, we introduce a method to emphasize critical refusal tokens by incorporating a reward-based token-level weighting mechanism for refusal learning, which further improves the robustness against adversarial exploits. Our research also suggests that robustness to jailbreak attacks is correlated with token distribution shifts in the training process and internal representations of refusal and harmful tokens, offering valuable directions for future research in LLM safety alignment. The code is available at https://github.com/wicai24/DOOR-Alignment","sentences":["Existing training-time safety alignment techniques for large language models (LLMs) remain vulnerable to jailbreak attacks.","Direct preference optimization (DPO), a widely deployed alignment method, exhibits limitations in both experimental and theoretical contexts as its loss function proves suboptimal for refusal learning.","Through gradient-based analysis, we identify these shortcomings and propose an improved safety alignment that disentangles DPO objectives into two components: (1) robust refusal training, which encourages refusal even when partial unsafe generations are produced, and (2) targeted unlearning of harmful knowledge.","This approach significantly increases LLM robustness against a wide range of jailbreak attacks, including prefilling, suffix, and multi-turn attacks across both in-distribution and out-of-distribution scenarios.","Furthermore, we introduce a method to emphasize critical refusal tokens by incorporating a reward-based token-level weighting mechanism for refusal learning, which further improves the robustness against adversarial exploits.","Our research also suggests that robustness to jailbreak attacks is correlated with token distribution shifts in the training process and internal representations of refusal and harmful tokens, offering valuable directions for future research in LLM safety alignment.","The code is available at https://github.com/wicai24/DOOR-Alignment"],"url":"http://arxiv.org/abs/2503.03710v1"}
{"created":"2025-03-05 17:59:19","title":"Rethinking Video Tokenization: A Conditioned Diffusion-based Approach","abstract":"Video tokenizers, which transform videos into compact latent representations, are key to video generation. Existing video tokenizers are based on the VAE architecture and follow a paradigm where an encoder compresses videos into compact latents, and a deterministic decoder reconstructs the original videos from these latents. In this paper, we propose a novel \\underline{\\textbf{C}}onditioned \\underline{\\textbf{D}}iffusion-based video \\underline{\\textbf{T}}okenizer entitled \\textbf{\\ourmethod}, which departs from previous methods by replacing the deterministic decoder with a 3D causal diffusion model. The reverse diffusion generative process of the decoder is conditioned on the latent representations derived via the encoder. With a feature caching and sampling acceleration, the framework efficiently reconstructs high-fidelity videos of arbitrary lengths. Results show that {\\ourmethod} achieves state-of-the-art performance in video reconstruction tasks using just a single-step sampling. Even a smaller version of {\\ourmethod} still achieves reconstruction results on par with the top two baselines. Furthermore, the latent video generation model trained using {\\ourmethod} also shows superior performance.","sentences":["Video tokenizers, which transform videos into compact latent representations, are key to video generation.","Existing video tokenizers are based on the VAE architecture and follow a paradigm where an encoder compresses videos into compact latents, and a deterministic decoder reconstructs the original videos from these latents.","In this paper, we propose a novel \\underline{\\textbf{C}}onditioned \\underline{\\textbf{D}}iffusion-based video \\underline{\\textbf{T}}okenizer entitled \\textbf{\\ourmethod}, which departs from previous methods by replacing the deterministic decoder with a 3D causal diffusion model.","The reverse diffusion generative process of the decoder is conditioned on the latent representations derived via the encoder.","With a feature caching and sampling acceleration, the framework efficiently reconstructs high-fidelity videos of arbitrary lengths.","Results show that {\\ourmethod} achieves state-of-the-art performance in video reconstruction tasks using just a single-step sampling.","Even a smaller version of {\\ourmethod} still achieves reconstruction results on par with the top two baselines.","Furthermore, the latent video generation model trained using {\\ourmethod} also shows superior performance."],"url":"http://arxiv.org/abs/2503.03708v1"}
{"created":"2025-03-05 17:58:16","title":"Curating Demonstrations using Online Experience","abstract":"Many robot demonstration datasets contain heterogeneous demonstrations of varying quality. This heterogeneity may benefit policy pre-training, but can hinder robot performance when used with a final imitation learning objective. In particular, some strategies in the data may be less reliable than others or may be underrepresented in the data, leading to poor performance when such strategies are sampled at test time. Moreover, such unreliable or underrepresented strategies can be difficult even for people to discern, and sifting through demonstration datasets is time-consuming and costly. On the other hand, policy performance when trained on such demonstrations can reflect the reliability of different strategies. We thus propose for robots to self-curate based on online robot experience (Demo-SCORE). More specifically, we train and cross-validate a classifier to discern successful policy roll-outs from unsuccessful ones and use the classifier to filter heterogeneous demonstration datasets. Our experiments in simulation and the real world show that Demo-SCORE can effectively identify suboptimal demonstrations without manual curation. Notably, Demo-SCORE achieves over 15-35% higher absolute success rate in the resulting policy compared to the base policy trained with all original demonstrations.","sentences":["Many robot demonstration datasets contain heterogeneous demonstrations of varying quality.","This heterogeneity may benefit policy pre-training, but can hinder robot performance when used with a final imitation learning objective.","In particular, some strategies in the data may be less reliable than others or may be underrepresented in the data, leading to poor performance when such strategies are sampled at test time.","Moreover, such unreliable or underrepresented strategies can be difficult even for people to discern, and sifting through demonstration datasets is time-consuming and costly.","On the other hand, policy performance when trained on such demonstrations can reflect the reliability of different strategies.","We thus propose for robots to self-curate based on online robot experience (Demo-SCORE).","More specifically, we train and cross-validate a classifier to discern successful policy roll-outs from unsuccessful ones and use the classifier to filter heterogeneous demonstration datasets.","Our experiments in simulation and the real world show that Demo-SCORE can effectively identify suboptimal demonstrations without manual curation.","Notably, Demo-SCORE achieves over 15-35% higher absolute success rate in the resulting policy compared to the base policy trained with all original demonstrations."],"url":"http://arxiv.org/abs/2503.03707v1"}
{"created":"2025-03-05 17:56:49","title":"An Automated Computational Pipeline for Generating Large-Scale Cohorts of Patient-Specific Ventricular Models in Electromechanical In Silico Trials","abstract":"In recent years, human in silico trials have gained significant traction as a powerful approach to evaluate the effects of drugs, clinical interventions, and medical devices. In silico trials not only minimise patient risks but also reduce reliance on animal testing. However, the implementation of in silico trials presents several time-consuming challenges. It requires the creation of large cohorts of virtual patients. Each virtual patient is described by their anatomy with a volumetric mesh and electrophysiological and mechanical dynamics through mathematical equations and parameters. Furthermore, simulated conditions need definition including stimulation protocols and therapy evaluation. For large virtual cohorts, this requires automatic and efficient pipelines for generation of corresponding files. In this work, we present a computational pipeline to automatically create large virtual patient cohort files to conduct large-scale in silico trials through cardiac electromechanical simulations. The pipeline generates the files describing meshes, labels, and data required for the simulations directly from unprocessed surface meshes. We applied the pipeline to generate over 100 virtual patients from various datasets and performed simulations to demonstrate capacity to conduct in silico trials for virtual patients using verified and validated electrophysiology and electromechanics models for the context of use. The proposed pipeline is adaptable to accommodate different types of ventricular geometries and mesh processing tools, ensuring its versatility in handling diverse clinical datasets. By establishing an automated framework for large scale simulation studies as required for in silico trials and providing open-source code, our work aims to support scalable, personalised cardiac simulations in research and clinical applications.","sentences":["In recent years, human in silico trials have gained significant traction as a powerful approach to evaluate the effects of drugs, clinical interventions, and medical devices.","In silico trials not only minimise patient risks but also reduce reliance on animal testing.","However, the implementation of in silico trials presents several time-consuming challenges.","It requires the creation of large cohorts of virtual patients.","Each virtual patient is described by their anatomy with a volumetric mesh and electrophysiological and mechanical dynamics through mathematical equations and parameters.","Furthermore, simulated conditions need definition including stimulation protocols and therapy evaluation.","For large virtual cohorts, this requires automatic and efficient pipelines for generation of corresponding files.","In this work, we present a computational pipeline to automatically create large virtual patient cohort files to conduct large-scale in silico trials through cardiac electromechanical simulations.","The pipeline generates the files describing meshes, labels, and data required for the simulations directly from unprocessed surface meshes.","We applied the pipeline to generate over 100 virtual patients from various datasets and performed simulations to demonstrate capacity to conduct in silico trials for virtual patients using verified and validated electrophysiology and electromechanics models for the context of use.","The proposed pipeline is adaptable to accommodate different types of ventricular geometries and mesh processing tools, ensuring its versatility in handling diverse clinical datasets.","By establishing an automated framework for large scale simulation studies as required for in silico trials and providing open-source code, our work aims to support scalable, personalised cardiac simulations in research and clinical applications."],"url":"http://arxiv.org/abs/2503.03706v1"}
{"created":"2025-03-05 17:56:20","title":"Effective LLM Knowledge Learning via Model Generalization","abstract":"Large language models (LLMs) are trained on enormous documents that contain extensive world knowledge. However, it is still not well-understood how knowledge is acquired via autoregressive pre-training. This lack of understanding greatly hinders effective knowledge learning, especially for continued pretraining on up-to-date information, as this evolving information often lacks diverse repetitions like foundational knowledge. In this paper, we focus on understanding and improving LLM knowledge learning. We found and verified that knowledge learning for LLMs can be deemed as an implicit supervised task hidden in the autoregressive pre-training objective. Our findings suggest that knowledge learning for LLMs would benefit from methods designed to improve generalization ability for supervised tasks. Based on our analysis, we propose the formatting-based data augmentation to grow in-distribution samples, which does not present the risk of altering the facts embedded in documents as text paraphrasing. We also introduce sharpness-aware minimization as an effective optimization algorithm to better improve generalization. Moreover, our analysis and method can be readily extended to instruction tuning. Extensive experiment results validate our findings and demonstrate our methods' effectiveness in both continued pre-training and instruction tuning. This paper offers new perspectives and insights to interpret and design effective strategies for LLM knowledge learning.","sentences":["Large language models (LLMs) are trained on enormous documents that contain extensive world knowledge.","However, it is still not well-understood how knowledge is acquired via autoregressive pre-training.","This lack of understanding greatly hinders effective knowledge learning, especially for continued pretraining on up-to-date information, as this evolving information often lacks diverse repetitions like foundational knowledge.","In this paper, we focus on understanding and improving LLM knowledge learning.","We found and verified that knowledge learning for LLMs can be deemed as an implicit supervised task hidden in the autoregressive pre-training objective.","Our findings suggest that knowledge learning for LLMs would benefit from methods designed to improve generalization ability for supervised tasks.","Based on our analysis, we propose the formatting-based data augmentation to grow in-distribution samples, which does not present the risk of altering the facts embedded in documents as text paraphrasing.","We also introduce sharpness-aware minimization as an effective optimization algorithm to better improve generalization.","Moreover, our analysis and method can be readily extended to instruction tuning.","Extensive experiment results validate our findings and demonstrate our methods' effectiveness in both continued pre-training and instruction tuning.","This paper offers new perspectives and insights to interpret and design effective strategies for LLM knowledge learning."],"url":"http://arxiv.org/abs/2503.03705v1"}
{"created":"2025-03-05 17:53:24","title":"A Practical Memory Injection Attack against LLM Agents","abstract":"Agents based on large language models (LLMs) have demonstrated strong capabilities in a wide range of complex, real-world applications. However, LLM agents with a compromised memory bank may easily produce harmful outputs when the past records retrieved for demonstration are malicious. In this paper, we propose a novel Memory INJection Attack, MINJA, that enables the injection of malicious records into the memory bank by only interacting with the agent via queries and output observations. These malicious records are designed to elicit a sequence of malicious reasoning steps leading to undesirable agent actions when executing the victim user's query. Specifically, we introduce a sequence of bridging steps to link the victim query to the malicious reasoning steps. During the injection of the malicious record, we propose an indication prompt to guide the agent to autonomously generate our designed bridging steps. We also propose a progressive shortening strategy that gradually removes the indication prompt, such that the malicious record will be easily retrieved when processing the victim query comes after. Our extensive experiments across diverse agents demonstrate the effectiveness of MINJA in compromising agent memory. With minimal requirements for execution, MINJA enables any user to influence agent memory, highlighting practical risks of LLM agents.","sentences":["Agents based on large language models (LLMs) have demonstrated strong capabilities in a wide range of complex, real-world applications.","However, LLM agents with a compromised memory bank may easily produce harmful outputs when the past records retrieved for demonstration are malicious.","In this paper, we propose a novel Memory INJection Attack, MINJA, that enables the injection of malicious records into the memory bank by only interacting with the agent via queries and output observations.","These malicious records are designed to elicit a sequence of malicious reasoning steps leading to undesirable agent actions when executing the victim user's query.","Specifically, we introduce a sequence of bridging steps to link the victim query to the malicious reasoning steps.","During the injection of the malicious record, we propose an indication prompt to guide the agent to autonomously generate our designed bridging steps.","We also propose a progressive shortening strategy that gradually removes the indication prompt, such that the malicious record will be easily retrieved when processing the victim query comes after.","Our extensive experiments across diverse agents demonstrate the effectiveness of MINJA in compromising agent memory.","With minimal requirements for execution, MINJA enables any user to influence agent memory, highlighting practical risks of LLM agents."],"url":"http://arxiv.org/abs/2503.03704v1"}
{"created":"2025-03-05 17:53:11","title":"SoftMatcha: A Soft and Fast Pattern Matcher for Billion-Scale Corpus Searches","abstract":"Researchers and practitioners in natural language processing and computational linguistics frequently observe and analyze the real language usage in large-scale corpora. For that purpose, they often employ off-the-shelf pattern-matching tools, such as grep, and keyword-in-context concordancers, which is widely used in corpus linguistics for gathering examples. Nonetheless, these existing techniques rely on surface-level string matching, and thus they suffer from the major limitation of not being able to handle orthographic variations and paraphrasing -- notable and common phenomena in any natural language. In addition, existing continuous approaches such as dense vector search tend to be overly coarse, often retrieving texts that are unrelated but share similar topics. Given these challenges, we propose a novel algorithm that achieves \\emph{soft} (or semantic) yet efficient pattern matching by relaxing a surface-level matching with word embeddings. Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes. We have prepared an efficient implementation, and we provide an accessible web tool. Our experiments demonstrate that the proposed method (i) can execute searches on billion-scale corpora in less than a second, which is comparable in speed to surface-level string matching and dense vector search; (ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles; and (iii) can be effectively applied to corpus-linguistic analyses of Latin, a language with highly diverse inflections.","sentences":["Researchers and practitioners in natural language processing and computational linguistics frequently observe and analyze the real language usage in large-scale corpora.","For that purpose, they often employ off-the-shelf pattern-matching tools, such as grep, and keyword-in-context concordancers, which is widely used in corpus linguistics for gathering examples.","Nonetheless, these existing techniques rely on surface-level string matching, and thus they suffer from the major limitation of not being able to handle orthographic variations and paraphrasing -- notable and common phenomena in any natural language.","In addition, existing continuous approaches such as dense vector search tend to be overly coarse, often retrieving texts that are unrelated but share similar topics.","Given these challenges, we propose a novel algorithm that achieves \\emph{soft} (or semantic) yet efficient pattern matching by relaxing a surface-level matching with word embeddings.","Our algorithm is highly scalable with respect to the size of the corpus text utilizing inverted indexes.","We have prepared an efficient implementation, and we provide an accessible web tool.","Our experiments demonstrate that the proposed method (i) can execute searches on billion-scale corpora in less than a second, which is comparable in speed to surface-level string matching and dense vector search; (ii) can extract harmful instances that semantically match queries from a large set of English and Japanese Wikipedia articles; and (iii) can be effectively applied to corpus-linguistic analyses of Latin, a language with highly diverse inflections."],"url":"http://arxiv.org/abs/2503.03703v1"}
{"created":"2025-03-05 17:53:07","title":"Developing and Utilizing a Large-Scale Cantonese Dataset for Multi-Tasking in Large Language Models","abstract":"High-quality data resources play a crucial role in learning large language models (LLMs), particularly for low-resource languages like Cantonese. Despite having more than 85 million native speakers, Cantonese is still considered a low-resource language in the field of natural language processing (NLP) due to factors such as the dominance of Mandarin, lack of cohesion within the Cantonese-speaking community, diversity in character encoding and input methods, and the tendency of overseas Cantonese speakers to prefer using English. In addition, rich colloquial vocabulary of Cantonese, English loanwords, and code-switching characteristics add to the complexity of corpus collection and processing. To address these challenges, we collect Cantonese texts from a variety of sources, including open source corpora, Hong Kong-specific forums, Wikipedia, and Common Crawl data. We conduct rigorous data processing through language filtering, quality filtering, content filtering, and de-duplication steps, successfully constructing a high-quality Cantonese corpus of over 2 billion tokens for training large language models. We further refined the model through supervised fine-tuning (SFT) on curated Cantonese tasks, enhancing its ability to handle specific applications. Upon completion of the training, the model achieves state-of-the-art (SOTA) performance on four Cantonese benchmarks. After training on our dataset, the model also exhibits improved performance on other mainstream language tasks.","sentences":["High-quality data resources play a crucial role in learning large language models (LLMs), particularly for low-resource languages like Cantonese.","Despite having more than 85 million native speakers, Cantonese is still considered a low-resource language in the field of natural language processing (NLP) due to factors such as the dominance of Mandarin, lack of cohesion within the Cantonese-speaking community, diversity in character encoding and input methods, and the tendency of overseas Cantonese speakers to prefer using English.","In addition, rich colloquial vocabulary of Cantonese, English loanwords, and code-switching characteristics add to the complexity of corpus collection and processing.","To address these challenges, we collect Cantonese texts from a variety of sources, including open source corpora, Hong Kong-specific forums, Wikipedia, and Common Crawl data.","We conduct rigorous data processing through language filtering, quality filtering, content filtering, and de-duplication steps, successfully constructing a high-quality Cantonese corpus of over 2 billion tokens for training large language models.","We further refined the model through supervised fine-tuning (SFT) on curated Cantonese tasks, enhancing its ability to handle specific applications.","Upon completion of the training, the model achieves state-of-the-art (SOTA) performance on four Cantonese benchmarks.","After training on our dataset, the model also exhibits improved performance on other mainstream language tasks."],"url":"http://arxiv.org/abs/2503.03702v1"}
{"created":"2025-03-05 17:50:43","title":"AEGIS: Towards Formalized and Practical Memory-Safe Execution of C programs via MSWASM","abstract":"Programs written in unsafe languages such as C are prone to memory safety errors, which can lead to program compromises and serious real-world security consequences. Recently, Memory-Safe WebAssembly (MSWASM) is introduced as a general-purpose intermediate bytecode with built-in memory safety semantics. Programs written in C can be compiled into MSWASM to get complete memory safety protection. In this paper, we present our extensions on MSWASM, which improve its semantics and practicality. First, we formalize MSWASM semantics in Coq/Iris, extending it with inter-module interaction, showing that MSWASM provides fine-grained isolation guarantees analogous to WASM's coarse-grained isolation via linear memory. Second, we present Aegis, a system to adopt the memory safety of MSWASM for C programs in an interoperable way. Aegis pipeline generates Checked C source code from MSWASM modules to enforce spatial memory safety. Checked C is a recent binary-compatible extension of C which can provide guaranteed spatial safety. Our design allows Aegis to protect C programs that depend on legacy C libraries with no extra dependency and with low overhead. Aegis pipeline incurs 67% runtime overhead and near-zero memory overhead on PolyBenchC programs compared to native.","sentences":["Programs written in unsafe languages such as C are prone to memory safety errors, which can lead to program compromises and serious real-world security consequences.","Recently, Memory-Safe WebAssembly (MSWASM) is introduced as a general-purpose intermediate bytecode with built-in memory safety semantics.","Programs written in C can be compiled into MSWASM to get complete memory safety protection.","In this paper, we present our extensions on MSWASM, which improve its semantics and practicality.","First, we formalize MSWASM semantics in Coq/Iris, extending it with inter-module interaction, showing that MSWASM provides fine-grained isolation guarantees analogous to WASM's coarse-grained isolation via linear memory.","Second, we present Aegis, a system to adopt the memory safety of MSWASM for C programs in an interoperable way.","Aegis pipeline generates Checked C source code from MSWASM modules to enforce spatial memory safety.","Checked C is a recent binary-compatible extension of C which can provide guaranteed spatial safety.","Our design allows Aegis to protect C programs that depend on legacy C libraries with no extra dependency and with low overhead.","Aegis pipeline incurs 67% runtime overhead and near-zero memory overhead on PolyBenchC programs compared to native."],"url":"http://arxiv.org/abs/2503.03698v1"}
{"created":"2025-03-05 17:43:49","title":"ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural Faithfulness in SpArX","abstract":"In the field of Explainable Artificial Intelligence (XAI), argumentative XAI approaches have been proposed to represent the internal reasoning process of deep neural networks in a more transparent way by interpreting hidden nodes as arguements. However, as the number of layers increases, existing compression methods simplify all layers at once, which lead to high accumulative information loss. To compensate for this, we propose an iterative layer-by-layer compression technique in which each layer is compressed separately and the reduction error in the next layer is immediately compensated for, thereby improving the overall input-output and structural fidelity of the model. Experiments on the Breast Cancer Diagnosis dataset show that, compared to traditional compression, the method reduces input-output and structural unfaithfulness, and maintains a more consistent attack-support relationship in the Argumentative Explanation scheme. This is significant because it provides a new way to make complex MLP models more compact while still conveying their internal inference logic without distortion.","sentences":["In the field of Explainable Artificial Intelligence (XAI), argumentative XAI approaches have been proposed to represent the internal reasoning process of deep neural networks in a more transparent way by interpreting hidden nodes as arguements.","However, as the number of layers increases, existing compression methods simplify all layers at once, which lead to high accumulative information loss.","To compensate for this, we propose an iterative layer-by-layer compression technique in which each layer is compressed separately and the reduction error in the next layer is immediately compensated for, thereby improving the overall input-output and structural fidelity of the model.","Experiments on the Breast Cancer Diagnosis dataset show that, compared to traditional compression, the method reduces input-output and structural unfaithfulness, and maintains a more consistent attack-support relationship in the Argumentative Explanation scheme.","This is significant because it provides a new way to make complex MLP models more compact while still conveying their internal inference logic without distortion."],"url":"http://arxiv.org/abs/2503.03693v1"}
{"created":"2025-03-05 17:31:45","title":"DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidance","abstract":"Accurate and high-fidelity driving scene reconstruction demands the effective utilization of comprehensive scene information as conditional inputs. Existing methods predominantly rely on 3D bounding boxes and BEV road maps for foreground and background control, which fail to capture the full complexity of driving scenes and adequately integrate multimodal information. In this work, we present DualDiff, a dual-branch conditional diffusion model designed to enhance driving scene generation across multiple views and video sequences. Specifically, we introduce Occupancy Ray-shape Sampling (ORS) as a conditional input, offering rich foreground and background semantics alongside 3D spatial geometry to precisely control the generation of both elements. To improve the synthesis of fine-grained foreground objects, particularly complex and distant ones, we propose a Foreground-Aware Mask (FGM) denoising loss function. Additionally, we develop the Semantic Fusion Attention (SFA) mechanism to dynamically prioritize relevant information and suppress noise, enabling more effective multimodal fusion. Finally, to ensure high-quality image-to-video generation, we introduce the Reward-Guided Diffusion (RGD) framework, which maintains global consistency and semantic coherence in generated videos. Extensive experiments demonstrate that DualDiff achieves state-of-the-art (SOTA) performance across multiple datasets. On the NuScenes dataset, DualDiff reduces the FID score by 4.09% compared to the best baseline. In downstream tasks, such as BEV segmentation, our method improves vehicle mIoU by 4.50% and road mIoU by 1.70%, while in BEV 3D object detection, the foreground mAP increases by 1.46%. Code will be made available at https://github.com/yangzhaojason/DualDiff.","sentences":["Accurate and high-fidelity driving scene reconstruction demands the effective utilization of comprehensive scene information as conditional inputs.","Existing methods predominantly rely on 3D bounding boxes and BEV road maps for foreground and background control, which fail to capture the full complexity of driving scenes and adequately integrate multimodal information.","In this work, we present DualDiff, a dual-branch conditional diffusion model designed to enhance driving scene generation across multiple views and video sequences.","Specifically, we introduce Occupancy Ray-shape Sampling (ORS) as a conditional input, offering rich foreground and background semantics alongside 3D spatial geometry to precisely control the generation of both elements.","To improve the synthesis of fine-grained foreground objects, particularly complex and distant ones, we propose a Foreground-Aware Mask (FGM) denoising loss function.","Additionally, we develop the Semantic Fusion Attention (SFA) mechanism to dynamically prioritize relevant information and suppress noise, enabling more effective multimodal fusion.","Finally, to ensure high-quality image-to-video generation, we introduce the Reward-Guided Diffusion (RGD) framework, which maintains global consistency and semantic coherence in generated videos.","Extensive experiments demonstrate that DualDiff achieves state-of-the-art (SOTA) performance across multiple datasets.","On the NuScenes dataset, DualDiff reduces the FID score by 4.09% compared to the best baseline.","In downstream tasks, such as BEV segmentation, our method improves vehicle mIoU by 4.50% and road mIoU by 1.70%, while in BEV 3D object detection, the foreground mAP increases by 1.46%.","Code will be made available at https://github.com/yangzhaojason/DualDiff."],"url":"http://arxiv.org/abs/2503.03689v1"}
{"created":"2025-03-05 17:28:16","title":"Addressing Overprescribing Challenges: Fine-Tuning Large Language Models for Medication Recommendation Tasks","abstract":"Medication recommendation systems have garnered attention within healthcare for their potential to deliver personalized and efficacious drug combinations based on patient's clinical data. However, existing methodologies encounter challenges in adapting to diverse Electronic Health Records (EHR) systems and effectively utilizing unstructured data, resulting in limited generalization capabilities and suboptimal performance. Recently, interest is growing in harnessing Large Language Models (LLMs) in the medical domain to support healthcare professionals and enhance patient care. Despite the emergence of medical LLMs and their promising results in tasks like medical question answering, their practical applicability in clinical settings, particularly in medication recommendation, often remains underexplored.   In this study, we evaluate both general-purpose and medical-specific LLMs for medication recommendation tasks. Our findings reveal that LLMs frequently encounter the challenge of overprescribing, leading to heightened clinical risks and diminished medication recommendation accuracy. To address this issue, we propose Language-Assisted Medication Recommendation (LAMO), which employs a parameter-efficient fine-tuning approach to tailor open-source LLMs for optimal performance in medication recommendation scenarios. LAMO leverages the wealth of clinical information within clinical notes, a resource often underutilized in traditional methodologies. As a result of our approach, LAMO outperforms previous state-of-the-art methods by over 10% in internal validation accuracy. Furthermore, temporal and external validations demonstrate LAMO's robust generalization capabilities across various temporal and hospital contexts. Additionally, an out-of-distribution medication recommendation experiment demonstrates LAMO's remarkable accuracy even with medications outside the training data.","sentences":["Medication recommendation systems have garnered attention within healthcare for their potential to deliver personalized and efficacious drug combinations based on patient's clinical data.","However, existing methodologies encounter challenges in adapting to diverse Electronic Health Records (EHR) systems and effectively utilizing unstructured data, resulting in limited generalization capabilities and suboptimal performance.","Recently, interest is growing in harnessing Large Language Models (LLMs) in the medical domain to support healthcare professionals and enhance patient care.","Despite the emergence of medical LLMs and their promising results in tasks like medical question answering, their practical applicability in clinical settings, particularly in medication recommendation, often remains underexplored.   ","In this study, we evaluate both general-purpose and medical-specific LLMs for medication recommendation tasks.","Our findings reveal that LLMs frequently encounter the challenge of overprescribing, leading to heightened clinical risks and diminished medication recommendation accuracy.","To address this issue, we propose Language-Assisted Medication Recommendation (LAMO), which employs a parameter-efficient fine-tuning approach to tailor open-source LLMs for optimal performance in medication recommendation scenarios.","LAMO leverages the wealth of clinical information within clinical notes, a resource often underutilized in traditional methodologies.","As a result of our approach, LAMO outperforms previous state-of-the-art methods by over 10% in internal validation accuracy.","Furthermore, temporal and external validations demonstrate LAMO's robust generalization capabilities across various temporal and hospital contexts.","Additionally, an out-of-distribution medication recommendation experiment demonstrates LAMO's remarkable accuracy even with medications outside the training data."],"url":"http://arxiv.org/abs/2503.03687v1"}
{"created":"2025-03-05 17:27:59","title":"MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems","abstract":"LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks. However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability and high inference costs. In this paper, we simplify the process of building an MAS by reframing it as a generative language task, where the input is a user query and the output is a corresponding MAS. To address this novel task, we unify the representation of MAS as executable code and propose a consistency-oriented data construction pipeline to create a high-quality dataset comprising coherent and consistent query-MAS pairs. Using this dataset, we train MAS-GPT, an open-source medium-sized LLM that is capable of generating query-adaptive MAS within a single LLM inference. The generated MAS can be seamlessly applied to process user queries and deliver high-quality responses. Extensive experiments on 9 benchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms 10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high effectiveness, efficiency and strong generalization ability. Code will be available at https://github.com/rui-ye/MAS-GPT.","sentences":["LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks.","However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability and high inference costs.","In this paper, we simplify the process of building an MAS by reframing it as a generative language task, where the input is a user query and the output is a corresponding MAS.","To address this novel task, we unify the representation of MAS as executable code and propose a consistency-oriented data construction pipeline to create a high-quality dataset comprising coherent and consistent query-MAS pairs.","Using this dataset, we train MAS-GPT, an open-source medium-sized LLM that is capable of generating query-adaptive MAS within a single LLM inference.","The generated MAS can be seamlessly applied to process user queries and deliver high-quality responses.","Extensive experiments on 9 benchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms 10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high effectiveness, efficiency and strong generalization ability.","Code will be available at https://github.com/rui-ye/MAS-GPT."],"url":"http://arxiv.org/abs/2503.03686v1"}
{"created":"2025-03-05 17:25:20","title":"Towards Trustworthy Federated Learning","abstract":"This paper develops a comprehensive framework to address three critical trustworthy challenges in federated learning (FL): robustness against Byzantine attacks, fairness, and privacy preservation. To improve the system's defense against Byzantine attacks that send malicious information to bias the system's performance, we develop a Two-sided Norm Based Screening (TNBS) mechanism, which allows the central server to crop the gradients that have the l lowest norms and h highest norms. TNBS functions as a screening tool to filter out potential malicious participants whose gradients are far from the honest ones. To promote egalitarian fairness, we adopt the q-fair federated learning (q-FFL). Furthermore, we adopt a differential privacy-based scheme to prevent raw data at local clients from being inferred by curious parties. Convergence guarantees are provided for the proposed framework under different scenarios. Experimental results on real datasets demonstrate that the proposed framework effectively improves robustness and fairness while managing the trade-off between privacy and accuracy. This work appears to be the first study that experimentally and theoretically addresses fairness, privacy, and robustness in trustworthy FL.","sentences":["This paper develops a comprehensive framework to address three critical trustworthy challenges in federated learning (FL): robustness against Byzantine attacks, fairness, and privacy preservation.","To improve the system's defense against Byzantine attacks that send malicious information to bias the system's performance, we develop a Two-sided Norm Based Screening (TNBS) mechanism, which allows the central server to crop the gradients that have the l lowest norms and h highest norms.","TNBS functions as a screening tool to filter out potential malicious participants whose gradients are far from the honest ones.","To promote egalitarian fairness, we adopt the q-fair federated learning (q-FFL).","Furthermore, we adopt a differential privacy-based scheme to prevent raw data at local clients from being inferred by curious parties.","Convergence guarantees are provided for the proposed framework under different scenarios.","Experimental results on real datasets demonstrate that the proposed framework effectively improves robustness and fairness while managing the trade-off between privacy and accuracy.","This work appears to be the first study that experimentally and theoretically addresses fairness, privacy, and robustness in trustworthy FL."],"url":"http://arxiv.org/abs/2503.03684v1"}
{"created":"2025-03-05 17:22:33","title":"Quantification of Tenseness in English and Japanese Tense-Lax Vowels: A Lagrangian Model with Indicator $\u03b8_1$ and Force of Tenseness Ftense(t)","abstract":"The concept of vowel tenseness has traditionally been examined through the binary distinction of tense and lax vowels. However, no universally accepted quantitative definition of tenseness has been established in any language. Previous studies, including those by Jakobson, Fant, and Halle (1951) and Chomsky and Halle (1968), have explored the relationship between vowel tenseness and the vocal tract. Building on these foundations, Ishizaki (2019, 2022) proposed an indirect quantification of vowel tenseness using formant angles $\\theta_1$ and $\\theta_{F1}$ and their first and second derivatives, $d^Z_1(t)/dt = \\lim \\tan \\theta_1(t$) and $d^2 Z_1(t)/dt^2 = d/dt \\lim \\tan \\theta_1(t)$. This study extends this approach by investigating the potential role of a force-related parameter in determining vowel quality. Specifically, we introduce a simplified model based on the Lagrangian equation to describe the dynamic interaction of the tongue and jaw within the oral cavity during the articulation of close vowels. This model provides a theoretical framework for estimating the forces involved in vowel production across different languages, offering new insights into the physical mechanisms underlying vowel articulation. The findings suggest that this force-based perspective warrants further exploration as a key factor in phonetic and phonological studies.","sentences":["The concept of vowel tenseness has traditionally been examined through the binary distinction of tense and lax vowels.","However, no universally accepted quantitative definition of tenseness has been established in any language.","Previous studies, including those by Jakobson, Fant, and Halle (1951) and Chomsky and Halle (1968), have explored the relationship between vowel tenseness and the vocal tract.","Building on these foundations, Ishizaki (2019, 2022) proposed an indirect quantification of vowel tenseness using formant angles $\\theta_1$ and $\\theta_{F1}$ and their first and second derivatives, $d^Z_1(t)/dt = \\lim \\tan \\theta_1(t$) and $d^2 Z_1(t)/dt^2 = d/dt \\lim \\tan \\theta_1(t)$. This study extends this approach by investigating the potential role of a force-related parameter in determining vowel quality.","Specifically, we introduce a simplified model based on the Lagrangian equation to describe the dynamic interaction of the tongue and jaw within the oral cavity during the articulation of close vowels.","This model provides a theoretical framework for estimating the forces involved in vowel production across different languages, offering new insights into the physical mechanisms underlying vowel articulation.","The findings suggest that this force-based perspective warrants further exploration as a key factor in phonetic and phonological studies."],"url":"http://arxiv.org/abs/2503.03681v1"}
{"created":"2025-03-05 17:11:02","title":"Optimally Installing Strict Equilibria","abstract":"In this work, we develop a reward design framework for installing a desired behavior as a strict equilibrium across standard solution concepts: dominant strategy equilibrium, Nash equilibrium, correlated equilibrium, and coarse correlated equilibrium. We also extend our framework to capture the Markov-perfect equivalents of each solution concept. Central to our framework is a comprehensive mathematical characterization of strictly installable, based on the desired solution concept and the behavior's structure. These characterizations lead to efficient iterative algorithms, which we generalize to handle optimization objectives through linear programming. Finally, we explore how our results generalize to bounded rational agents.","sentences":["In this work, we develop a reward design framework for installing a desired behavior as a strict equilibrium across standard solution concepts: dominant strategy equilibrium, Nash equilibrium, correlated equilibrium, and coarse correlated equilibrium.","We also extend our framework to capture the Markov-perfect equivalents of each solution concept.","Central to our framework is a comprehensive mathematical characterization of strictly installable, based on the desired solution concept and the behavior's structure.","These characterizations lead to efficient iterative algorithms, which we generalize to handle optimization objectives through linear programming.","Finally, we explore how our results generalize to bounded rational agents."],"url":"http://arxiv.org/abs/2503.03676v1"}
{"created":"2025-03-05 17:03:48","title":"Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models","abstract":"We present Attentive Reasoning Queries (ARQs), a novel structured reasoning approach that significantly improves instruction-following in Large Language Models through domain-specialized reasoning blueprints. While LLMs demonstrate remarkable capabilities across diverse tasks, they often fail to maintain adherence to complex, use-case-specific instructions during multi-turn conversations, presenting challenges for business-critical applications. ARQs address this limitation by guiding LLMs through systematic reasoning steps with targeted queries that reinstate critical instructions and facilitate intermediate reasoning throughout the completion process. In extensive testing within Parlant, our framework for reliable customer-facing agents in which ARQs were born out of necessity, they achieved a 90.2% success rate across 87 test scenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct response generation (81.5%). ARQs showed particular strength in addressing persistent failure modes like guideline re-application and hallucination prevention. Our analysis also revealed that ARQs can potentially be more computationally efficient than free-form reasoning when carefully designed. These findings demonstrate that structured reasoning approaches provide effective mechanisms for controlling how LLMs process information and make decisions in complex scenarios.","sentences":["We present Attentive Reasoning Queries (ARQs), a novel structured reasoning approach that significantly improves instruction-following in Large Language Models through domain-specialized reasoning blueprints.","While LLMs demonstrate remarkable capabilities across diverse tasks, they often fail to maintain adherence to complex, use-case-specific instructions during multi-turn conversations, presenting challenges for business-critical applications.","ARQs address this limitation by guiding LLMs through systematic reasoning steps with targeted queries that reinstate critical instructions and facilitate intermediate reasoning throughout the completion process.","In extensive testing within Parlant, our framework for reliable customer-facing agents in which ARQs were born out of necessity, they achieved a 90.2% success rate across 87 test scenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct response generation (81.5%).","ARQs showed particular strength in addressing persistent failure modes like guideline re-application and hallucination prevention.","Our analysis also revealed that ARQs can potentially be more computationally efficient than free-form reasoning when carefully designed.","These findings demonstrate that structured reasoning approaches provide effective mechanisms for controlling how LLMs process information and make decisions in complex scenarios."],"url":"http://arxiv.org/abs/2503.03669v1"}
{"created":"2025-03-05 16:59:08","title":"Analogical Reasoning Inside Large Language Models: Concept Vectors and the Limits of Abstraction","abstract":"Analogical reasoning relies on conceptual abstractions, but it is unclear whether Large Language Models (LLMs) harbor such internal representations. We explore distilled representations from LLM activations and find that function vectors (FVs; Todd et al., 2024) - compact representations for in-context learning (ICL) tasks - are not invariant to simple input changes (e.g., open-ended vs. multiple-choice), suggesting they capture more than pure concepts. Using representational similarity analysis (RSA), we localize a small set of attention heads that encode invariant concept vectors (CVs) for verbal concepts like \"antonym\". These CVs function as feature detectors that operate independently of the final output - meaning that a model may form a correct internal representation yet still produce an incorrect output. Furthermore, CVs can be used to causally guide model behaviour. However, for more abstract concepts like \"previous\" and \"next\", we do not observe invariant linear representations, a finding we link to generalizability issues LLMs display within these domains.","sentences":["Analogical reasoning relies on conceptual abstractions, but it is unclear whether Large Language Models (LLMs) harbor such internal representations.","We explore distilled representations from LLM activations and find that function vectors (FVs; Todd et al., 2024) - compact representations for in-context learning (ICL) tasks - are not invariant to simple input changes (e.g., open-ended vs. multiple-choice), suggesting they capture more than pure concepts.","Using representational similarity analysis (RSA), we localize a small set of attention heads that encode invariant concept vectors (CVs) for verbal concepts like \"antonym\".","These CVs function as feature detectors that operate independently of the final output - meaning that a model may form a correct internal representation yet still produce an incorrect output.","Furthermore, CVs can be used to causally guide model behaviour.","However, for more abstract concepts like \"previous\" and \"next\", we do not observe invariant linear representations, a finding we link to generalizability issues LLMs display within these domains."],"url":"http://arxiv.org/abs/2503.03666v1"}
{"created":"2025-03-05 16:54:15","title":"A Generative Approach to High Fidelity 3D Reconstruction from Text Data","abstract":"The convergence of generative artificial intelligence and advanced computer vision technologies introduces a groundbreaking approach to transforming textual descriptions into three-dimensional representations. This research proposes a fully automated pipeline that seamlessly integrates text-to-image generation, various image processing techniques, and deep learning methods for reflection removal and 3D reconstruction. By leveraging state-of-the-art generative models like Stable Diffusion, the methodology translates natural language inputs into detailed 3D models through a multi-stage workflow.   The reconstruction process begins with the generation of high-quality images from textual prompts, followed by enhancement by a reinforcement learning agent and reflection removal using the Stable Delight model. Advanced image upscaling and background removal techniques are then applied to further enhance visual fidelity. These refined two-dimensional representations are subsequently transformed into volumetric 3D models using sophisticated machine learning algorithms, capturing intricate spatial relationships and geometric characteristics. This process achieves a highly structured and detailed output, ensuring that the final 3D models reflect both semantic accuracy and geometric precision.   This approach addresses key challenges in generative reconstruction, such as maintaining semantic coherence, managing geometric complexity, and preserving detailed visual information. Comprehensive experimental evaluations will assess reconstruction quality, semantic accuracy, and geometric fidelity across diverse domains and varying levels of complexity. By demonstrating the potential of AI-driven 3D reconstruction techniques, this research offers significant implications for fields such as augmented reality (AR), virtual reality (VR), and digital content creation.","sentences":["The convergence of generative artificial intelligence and advanced computer vision technologies introduces a groundbreaking approach to transforming textual descriptions into three-dimensional representations.","This research proposes a fully automated pipeline that seamlessly integrates text-to-image generation, various image processing techniques, and deep learning methods for reflection removal and 3D reconstruction.","By leveraging state-of-the-art generative models like Stable Diffusion, the methodology translates natural language inputs into detailed 3D models through a multi-stage workflow.   ","The reconstruction process begins with the generation of high-quality images from textual prompts, followed by enhancement by a reinforcement learning agent and reflection removal using the Stable Delight model.","Advanced image upscaling and background removal techniques are then applied to further enhance visual fidelity.","These refined two-dimensional representations are subsequently transformed into volumetric 3D models using sophisticated machine learning algorithms, capturing intricate spatial relationships and geometric characteristics.","This process achieves a highly structured and detailed output, ensuring that the final 3D models reflect both semantic accuracy and geometric precision.   ","This approach addresses key challenges in generative reconstruction, such as maintaining semantic coherence, managing geometric complexity, and preserving detailed visual information.","Comprehensive experimental evaluations will assess reconstruction quality, semantic accuracy, and geometric fidelity across diverse domains and varying levels of complexity.","By demonstrating the potential of AI-driven 3D reconstruction techniques, this research offers significant implications for fields such as augmented reality (AR), virtual reality (VR), and digital content creation."],"url":"http://arxiv.org/abs/2503.03664v1"}
{"created":"2025-03-05 16:52:34","title":"LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant","abstract":"First-person video assistants are highly anticipated to enhance our daily lives through online video dialogue. However, existing online video assistants often sacrifice assistant efficacy for real-time efficiency by processing low-frame-rate videos with coarse-grained visual features.To overcome the trade-off between efficacy and efficiency, we propose \"Fast & Slow Video-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving real-time, proactive, temporally accurate, and contextually precise responses. LION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based Response Determination evaluates frame-by-frame whether an immediate response is necessary. To enhance response determination accuracy and handle higher frame-rate inputs efficiently, we employ Token Aggregation Routing to dynamically fuse spatiotemporal features without increasing token numbers, while utilizing Token Dropping Routing to eliminate redundant features. 2)Slow Path: Multi-granularity Keyframe Augmentation optimizes keyframes during response generation. To provide comprehensive and detailed responses beyond atomic actions constrained by training data, fine-grained spatial features and human-environment interaction features are extracted through multi-granular pooling. These features are further integrated into a meticulously designed multimodal Thinking Template to guide more precise response generation. Comprehensive evaluations on online video tasks demonstrate that LION-FS achieves state-of-the-art efficacy and efficiency.","sentences":["First-person video assistants are highly anticipated to enhance our daily lives through online video dialogue.","However, existing online video assistants often sacrifice assistant efficacy for real-time efficiency by processing low-frame-rate videos with coarse-grained visual features.","To overcome the trade-off between efficacy and efficiency, we propose \"Fast & Slow Video-Language Thinker\" as an onLIne videO assistaNt, LION-FS, achieving real-time, proactive, temporally accurate, and contextually precise responses.","LION-FS adopts a two-stage optimization strategy: 1)Fast Path: Routing-Based Response Determination evaluates frame-by-frame whether an immediate response is necessary.","To enhance response determination accuracy and handle higher frame-rate inputs efficiently, we employ Token Aggregation Routing to dynamically fuse spatiotemporal features without increasing token numbers, while utilizing Token Dropping Routing to eliminate redundant features.","2)Slow Path: Multi-granularity Keyframe Augmentation optimizes keyframes during response generation.","To provide comprehensive and detailed responses beyond atomic actions constrained by training data, fine-grained spatial features and human-environment interaction features are extracted through multi-granular pooling.","These features are further integrated into a meticulously designed multimodal Thinking Template to guide more precise response generation.","Comprehensive evaluations on online video tasks demonstrate that LION-FS achieves state-of-the-art efficacy and efficiency."],"url":"http://arxiv.org/abs/2503.03663v1"}
{"created":"2025-03-05 16:52:21","title":"Adaptive Negative Damping Control for User-Dependent Multi-Terrain Walking Assistance with a Hip Exoskeleton","abstract":"Hip exoskeletons are known for their versatility in assisting users across varied scenarios. However, current assistive strategies often lack the flexibility to accommodate for individual walking patterns and adapt to diverse locomotion environments. In this work, we present a novel control strategy that adapts the mechanical impedance of the human-exoskeleton system. We design the hip assistive torques as an adaptive virtual negative damping, which is able to inject energy into the system while allowing the users to remain in control and contribute voluntarily to the movements. Experiments with five healthy subjects demonstrate that our controller reduces the metabolic cost of walking compared to free walking (average reduction of 7.2%), and it preserves the lower-limbs kinematics. Additionally, our method achieves minimal power losses from the exoskeleton across the entire gait cycle (less than 2% negative mechanical power out of the total power), ensuring synchronized action with the users' movements. Moreover, we use Bayesian Optimization to adapt the assistance strength and allow for seamless adaptation and transitions across multi-terrain environments. Our strategy achieves efficient power transmission under all conditions. Our approach demonstrates an individualized, adaptable, and straightforward controller for hip exoskeletons, advancing the development of viable, adaptive, and user-dependent control laws.","sentences":["Hip exoskeletons are known for their versatility in assisting users across varied scenarios.","However, current assistive strategies often lack the flexibility to accommodate for individual walking patterns and adapt to diverse locomotion environments.","In this work, we present a novel control strategy that adapts the mechanical impedance of the human-exoskeleton system.","We design the hip assistive torques as an adaptive virtual negative damping, which is able to inject energy into the system while allowing the users to remain in control and contribute voluntarily to the movements.","Experiments with five healthy subjects demonstrate that our controller reduces the metabolic cost of walking compared to free walking (average reduction of 7.2%), and it preserves the lower-limbs kinematics.","Additionally, our method achieves minimal power losses from the exoskeleton across the entire gait cycle (less than 2% negative mechanical power out of the total power), ensuring synchronized action with the users' movements.","Moreover, we use Bayesian Optimization to adapt the assistance strength and allow for seamless adaptation and transitions across multi-terrain environments.","Our strategy achieves efficient power transmission under all conditions.","Our approach demonstrates an individualized, adaptable, and straightforward controller for hip exoskeletons, advancing the development of viable, adaptive, and user-dependent control laws."],"url":"http://arxiv.org/abs/2503.03662v1"}
{"created":"2025-03-05 16:47:36","title":"Chunking the Critic: A Transformer-based Soft Actor-Critic with N-Step Returns","abstract":"Soft Actor-Critic (SAC) critically depends on its critic network, which typically evaluates a single state-action pair to guide policy updates. Using N-step returns is a common practice to reduce the bias in the target values of the critic. However, using N-step returns can again introduce high variance and necessitates importance sampling, often destabilizing training. Recent algorithms have also explored action chunking-such as direct action repetition and movement primitives-to enhance exploration. In this paper, we propose a Transformer-based Critic Network for SAC that integrates the N-returns framework in a stable and efficient manner. Unlike approaches that perform chunking in the actor network, we feed chunked actions into the critic network to explore potential performance gains. Our architecture leverages the Transformer's ability to process sequential information, facilitating more robust value estimation. Empirical results show that this method not only achieves efficient, stable training but also excels in sparse reward/multi-phase environments-traditionally a challenge for step-based methods. These findings underscore the promise of combining Transformer-based critics with N-returns to advance reinforcement learning performance","sentences":["Soft Actor-Critic (SAC) critically depends on its critic network, which typically evaluates a single state-action pair to guide policy updates.","Using N-step returns is a common practice to reduce the bias in the target values of the critic.","However, using N-step returns can again introduce high variance and necessitates importance sampling, often destabilizing training.","Recent algorithms have also explored action chunking-such as direct action repetition and movement primitives-to enhance exploration.","In this paper, we propose a Transformer-based Critic Network for SAC that integrates the N-returns framework in a stable and efficient manner.","Unlike approaches that perform chunking in the actor network, we feed chunked actions into the critic network to explore potential performance gains.","Our architecture leverages the Transformer's ability to process sequential information, facilitating more robust value estimation.","Empirical results show that this method not only achieves efficient, stable training but also excels in sparse reward/multi-phase environments-traditionally a challenge for step-based methods.","These findings underscore the promise of combining Transformer-based critics with N-returns to advance reinforcement learning performance"],"url":"http://arxiv.org/abs/2503.03660v1"}
{"created":"2025-03-05 16:39:04","title":"Robust Learning of Diverse Code Edits","abstract":"Software engineering activities frequently involve edits to existing code. However, contemporary code language models (LMs) lack the ability to handle diverse types of code-edit requirements. In this work, we attempt to overcome this shortcoming through (1) a novel synthetic data generation pipeline and (2) a robust model adaptation algorithm. Starting with seed code examples and diverse editing criteria, our pipeline generates high-quality samples comprising original and modified code, along with natural language instructions in different styles and verbosity. Today's code LMs come bundled with strong abilities, such as code generation and instruction following, which should not be lost due to fine-tuning. To ensure this, we propose a novel adaptation algorithm, SeleKT, that (a) leverages a dense gradient-based step to identify the weights that are most important for code editing, and (b) does a sparse projection onto the base model to avoid overfitting. Using our approach, we obtain a new series of models NextCoder (adapted from QwenCoder-2.5) that achieves strong results on five code-editing benchmarks, outperforming comparable size models and even several larger ones. We show the generality of our approach on two model families (DeepSeekCoder and QwenCoder), compare against other fine-tuning approaches, and demonstrate robustness by showing retention of code generation abilities post adaptation.","sentences":["Software engineering activities frequently involve edits to existing code.","However, contemporary code language models (LMs) lack the ability to handle diverse types of code-edit requirements.","In this work, we attempt to overcome this shortcoming through (1) a novel synthetic data generation pipeline and (2) a robust model adaptation algorithm.","Starting with seed code examples and diverse editing criteria, our pipeline generates high-quality samples comprising original and modified code, along with natural language instructions in different styles and verbosity.","Today's code LMs come bundled with strong abilities, such as code generation and instruction following, which should not be lost due to fine-tuning.","To ensure this, we propose a novel adaptation algorithm, SeleKT, that (a) leverages a dense gradient-based step to identify the weights that are most important for code editing, and (b) does a sparse projection onto the base model to avoid overfitting.","Using our approach, we obtain a new series of models NextCoder (adapted from QwenCoder-2.5) that achieves strong results on five code-editing benchmarks, outperforming comparable size models and even several larger ones.","We show the generality of our approach on two model families (DeepSeekCoder and QwenCoder), compare against other fine-tuning approaches, and demonstrate robustness by showing retention of code generation abilities post adaptation."],"url":"http://arxiv.org/abs/2503.03656v1"}
{"created":"2025-03-05 16:35:15","title":"Improving 6D Object Pose Estimation of metallic Household and Industry Objects","abstract":"6D object pose estimation suffers from reduced accuracy when applied to metallic objects. We set out to improve the state-of-the-art by addressing challenges such as reflections and specular highlights in industrial applications. Our novel BOP-compatible dataset, featuring a diverse set of metallic objects (cans, household, and industrial items) under various lighting and background conditions, provides additional geometric and visual cues. We demonstrate that these cues can be effectively leveraged to enhance overall performance. To illustrate the usefulness of the additional features, we improve upon the GDRNPP algorithm by introducing an additional keypoint prediction and material estimator head in order to improve spatial scene understanding. Evaluations on the new dataset show improved accuracy for metallic objects, supporting the hypothesis that additional geometric and visual cues can improve learning.","sentences":["6D object pose estimation suffers from reduced accuracy when applied to metallic objects.","We set out to improve the state-of-the-art by addressing challenges such as reflections and specular highlights in industrial applications.","Our novel BOP-compatible dataset, featuring a diverse set of metallic objects (cans, household, and industrial items) under various lighting and background conditions, provides additional geometric and visual cues.","We demonstrate that these cues can be effectively leveraged to enhance overall performance.","To illustrate the usefulness of the additional features, we improve upon the GDRNPP algorithm by introducing an additional keypoint prediction and material estimator head in order to improve spatial scene understanding.","Evaluations on the new dataset show improved accuracy for metallic objects, supporting the hypothesis that additional geometric and visual cues can improve learning."],"url":"http://arxiv.org/abs/2503.03655v1"}
{"created":"2025-03-05 16:32:47","title":"Improving Neutral Point of View Text Generation through Parameter-Efficient Reinforcement Learning and a Small-Scale High-Quality Dataset","abstract":"This paper describes the construction of a dataset and the evaluation of training methods to improve generative large language models' (LLMs) ability to answer queries on sensitive topics with a Neutral Point of View (NPOV), i.e., to provide significantly more informative, diverse and impartial answers. The dataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written quadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set of links to source texts elaborating the various points of view. The first key contribution of this paper is a new methodology to create such datasets through iterative rounds of human peer-critique and annotator training, which we release alongside the dataset. The second key contribution is the identification of a highly effective training regime for parameter-efficient reinforcement learning (PE-RL) to improve NPOV generation. We compare and extensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a strong baseline), SFT and RLHF.   PE-RL not only improves on overall NPOV quality compared to the strongest baseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on features linguists identify as key to separating good answers from the best answers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details, $68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification). A qualitative analysis corroborates this. Finally, our evaluation finds no statistical differences between results on topics that appear in the training dataset and those on separated evaluation topics, which provides strong evidence that our approach to training PE-RL exhibits very effective out of topic generalization.","sentences":["This paper describes the construction of a dataset and the evaluation of training methods to improve generative large language models' (LLMs) ability to answer queries on sensitive topics with a Neutral Point of View (NPOV), i.e., to provide significantly more informative, diverse and impartial answers.","The dataset, the SHQ-NPOV dataset, comprises 300 high-quality, human-written quadruplets: a query on a sensitive topic, an answer, an NPOV rating, and a set of links to source texts elaborating the various points of view.","The first key contribution of this paper is a new methodology to create such datasets through iterative rounds of human peer-critique and annotator training, which we release alongside the dataset.","The second key contribution is the identification of a highly effective training regime for parameter-efficient reinforcement learning (PE-RL) to improve NPOV generation.","We compare and extensively evaluate PE-RL and multiple baselines-including LoRA finetuning (a strong baseline), SFT and RLHF.   ","PE-RL not only improves on overall NPOV quality compared to the strongest baseline ($97.06\\%\\rightarrow 99.08\\%$), but also scores much higher on features linguists identify as key to separating good answers from the best answers ($60.25\\%\\rightarrow 85.21\\%$ for presence of supportive details, $68.74\\%\\rightarrow 91.43\\%$ for absence of oversimplification).","A qualitative analysis corroborates this.","Finally, our evaluation finds no statistical differences between results on topics that appear in the training dataset and those on separated evaluation topics, which provides strong evidence that our approach to training PE-RL exhibits very effective out of topic generalization."],"url":"http://arxiv.org/abs/2503.03654v1"}
{"created":"2025-03-05 16:27:25","title":"Token-Level Privacy in Large Language Models","abstract":"The use of language models as remote services requires transmitting private information to external providers, raising significant privacy concerns. This process not only risks exposing sensitive data to untrusted service providers but also leaves it vulnerable to interception by eavesdroppers. Existing privacy-preserving methods for natural language processing (NLP) interactions primarily rely on semantic similarity, overlooking the role of contextual information. In this work, we introduce dchi-stencil, a novel token-level privacy-preserving mechanism that integrates contextual and semantic information while ensuring strong privacy guarantees under the dchi differential privacy framework, achieving 2epsilon-dchi-privacy. By incorporating both semantic and contextual nuances, dchi-stencil achieves a robust balance between privacy and utility. We evaluate dchi-stencil using state-of-the-art language models and diverse datasets, achieving comparable and even better trade-off between utility and privacy compared to existing methods. This work highlights the potential of dchi-stencil to set a new standard for privacy-preserving NLP in modern, high-risk applications.","sentences":["The use of language models as remote services requires transmitting private information to external providers, raising significant privacy concerns.","This process not only risks exposing sensitive data to untrusted service providers but also leaves it vulnerable to interception by eavesdroppers.","Existing privacy-preserving methods for natural language processing (NLP) interactions primarily rely on semantic similarity, overlooking the role of contextual information.","In this work, we introduce dchi-stencil, a novel token-level privacy-preserving mechanism that integrates contextual and semantic information while ensuring strong privacy guarantees under the dchi differential privacy framework, achieving 2epsilon-dchi-privacy.","By incorporating both semantic and contextual nuances, dchi-stencil achieves a robust balance between privacy and utility.","We evaluate dchi-stencil using state-of-the-art language models and diverse datasets, achieving comparable and even better trade-off between utility and privacy compared to existing methods.","This work highlights the potential of dchi-stencil to set a new standard for privacy-preserving NLP in modern, high-risk applications."],"url":"http://arxiv.org/abs/2503.03652v1"}
{"created":"2025-03-05 16:26:58","title":"DoraCycle: Domain-Oriented Adaptation of Unified Generative Model in Multimodal Cycles","abstract":"Adapting generative models to specific domains presents an effective solution for satisfying specialized requirements. However, adapting to some complex domains remains challenging, especially when these domains require substantial paired data to capture the targeted distributions. Since unpaired data from a single modality, such as vision or language, is more readily available, we utilize the bidirectional mappings between vision and language learned by the unified generative model to enable training on unpaired data for domain adaptation. Specifically, we propose DoraCycle, which integrates two multimodal cycles: text-to-image-to-text and image-to-text-to-image. The model is optimized through cross-entropy loss computed at the cycle endpoints, where both endpoints share the same modality. This facilitates self-evolution of the model without reliance on annotated text-image pairs. Experimental results demonstrate that for tasks independent of paired knowledge, such as stylization, DoraCycle can effectively adapt the unified model using only unpaired data. For tasks involving new paired knowledge, such as specific identities, a combination of a small set of paired image-text examples and larger-scale unpaired data is sufficient for effective domain-oriented adaptation. The code will be released at https://github.com/showlab/DoraCycle.","sentences":["Adapting generative models to specific domains presents an effective solution for satisfying specialized requirements.","However, adapting to some complex domains remains challenging, especially when these domains require substantial paired data to capture the targeted distributions.","Since unpaired data from a single modality, such as vision or language, is more readily available, we utilize the bidirectional mappings between vision and language learned by the unified generative model to enable training on unpaired data for domain adaptation.","Specifically, we propose DoraCycle, which integrates two multimodal cycles: text-to-image-to-text and image-to-text-to-image.","The model is optimized through cross-entropy loss computed at the cycle endpoints, where both endpoints share the same modality.","This facilitates self-evolution of the model without reliance on annotated text-image pairs.","Experimental results demonstrate that for tasks independent of paired knowledge, such as stylization, DoraCycle can effectively adapt the unified model using only unpaired data.","For tasks involving new paired knowledge, such as specific identities, a combination of a small set of paired image-text examples and larger-scale unpaired data is sufficient for effective domain-oriented adaptation.","The code will be released at https://github.com/showlab/DoraCycle."],"url":"http://arxiv.org/abs/2503.03651v1"}
{"created":"2025-03-05 16:24:10","title":"Efektywne energetycznie wielodost\u0119powe przetwarzanie brzegowe w sieci 5G; Energy efficient Multi-access Edge Computing in 5G network","abstract":"Multi-access edge computing is a technique that combines the use of communication networks and remote computing resources. It allows to perform complex computational tasks for devices with low computing power while maintaining low latencies. However, it is important to effectively allocate the computing tasks to individual nodes. The work will present how the multi-access edge computing system can be integrated into the 5G network, as well as how resources can be distributed between individual nodes to minimize energy consumption. Some new degrees of freedom will be presented, which enable a significant reduction in energy consumption compared to existing solutions for independent optimization of the computation and communication parts.   --   Wielodost\\k{e}powe przetwarzanie brzegowe jest technik\\k{a} {\\l}\\k{a}cz\\k{a}c\\k{a} wykorzystanie sieci komunikacyjnych i oddalonych zasob\\'ow obliczeniowych. Pozwala wykona\\'c z{\\l}o\\.zone zadania obliczeniowe na potrzeby urz\\k{a}dze\\'n o niewielkiej mocy obliczeniowej przy zachowaniu niewielkich op\\'o\\'znie\\'n. Istotne jest jednak efektywne zarz\\k{a}dzanie przydzia{\\l}em zada\\'n obliczeniowych do poszczeg\\'olnych w\\k{e}z{\\l}\\'ow. W pracy przedstawiono jak system przetwarzania brzegowego mo\\.ze by\\'c zintegrowany z sieci\\k{a} 5G, a tak\\.ze jak mo\\.zna rozdzieli\\'c zasoby mi\\k{e}dzy poszczeg\\'olne w\\k{e}z{\\l}y, \\.zeby zminimalizowa\\'c zu\\.zycie energii. Przedstawiony zostanie szereg nowych stopni swobody, kt\\'ore umo\\.zliwiaj\\k{a} znaczne obni\\.zenie zu\\.zycia energii w stosunku do istniej\\k{a}cych rozwi\\k{a}za\\'n niezale\\.znej optymalizacji cz\\k{e}\\'sci obliczeniowej i komunikacyjnej.","sentences":["Multi-access edge computing is a technique that combines the use of communication networks and remote computing resources.","It allows to perform complex computational tasks for devices with low computing power while maintaining low latencies.","However, it is important to effectively allocate the computing tasks to individual nodes.","The work will present how the multi-access edge computing system can be integrated into the 5G network, as well as how resources can be distributed between individual nodes to minimize energy consumption.","Some new degrees of freedom will be presented, which enable a significant reduction in energy consumption compared to existing solutions for independent optimization of the computation and communication parts.   --   Wielodost\\k{e}powe przetwarzanie brzegowe jest technik\\k{a} {\\l}\\k{a}cz\\k{a}c\\k{a} wykorzystanie sieci komunikacyjnych i oddalonych zasob\\'ow obliczeniowych.","Pozwala wykona\\'c z{\\l}o\\.zone zadania obliczeniowe na potrzeby urz\\k{a}dze\\'n o niewielkiej mocy obliczeniowej przy zachowaniu niewielkich op\\'o\\'znie\\'n.","Istotne jest jednak efektywne zarz\\k{a}dzanie przydzia{\\l}em zada\\'n","obliczeniowych do poszczeg\\'olnych w\\k{e}z{\\l}\\'ow.","W pracy przedstawiono jak system przetwarzania brzegowego mo\\.ze by\\'c zintegrowany z sieci\\k{a} 5G, a tak\\.ze jak mo\\.zna rozdzieli\\'c zasoby mi\\k{e}dzy poszczeg\\'olne w\\k{e}z{\\l}y, \\.zeby zminimalizowa\\'c zu\\.zycie energii.","Przedstawiony zostanie szereg nowych stopni swobody, kt\\'ore umo\\.zliwiaj\\k{a} znaczne obni\\.zenie zu\\.zycia energii w stosunku do istniej\\k{a}cych rozwi\\k{a}za\\'n niezale\\.znej optymalizacji cz\\k{e}\\'sci obliczeniowej i komunikacyjnej."],"url":"http://arxiv.org/abs/2503.03646v1"}
{"created":"2025-03-05 16:23:15","title":"Psy-Copilot: Visual Chain of Thought for Counseling","abstract":"Large language models (LLMs) are becoming increasingly popular in the field of psychological counseling. However, when human therapists work with LLMs in therapy sessions, it is hard to understand how the model gives the answers. To address this, we have constructed Psy-COT, a graph designed to visualize the thought processes of LLMs during therapy sessions. The Psy-COT graph presents semi-structured counseling conversations alongside step-by-step annotations that capture the reasoning and insights of therapists. Moreover, we have developed Psy-Copilot, which is a conversational AI assistant designed to assist human psychological therapists in their consultations. It can offer traceable psycho-information based on retrieval, including response candidates, similar dialogue sessions, related strategies, and visual traces of results. We have also built an interactive platform for AI-assisted counseling. It has an interface that displays the relevant parts of the retrieval sub-graph. The Psy-Copilot is designed not to replace psychotherapists but to foster collaboration between AI and human therapists, thereby promoting mental health development. Our code and demo are both open-sourced and available for use.","sentences":["Large language models (LLMs) are becoming increasingly popular in the field of psychological counseling.","However, when human therapists work with LLMs in therapy sessions, it is hard to understand how the model gives the answers.","To address this, we have constructed Psy-COT, a graph designed to visualize the thought processes of LLMs during therapy sessions.","The Psy-COT graph presents semi-structured counseling conversations alongside step-by-step annotations that capture the reasoning and insights of therapists.","Moreover, we have developed Psy-Copilot, which is a conversational AI assistant designed to assist human psychological therapists in their consultations.","It can offer traceable psycho-information based on retrieval, including response candidates, similar dialogue sessions, related strategies, and visual traces of results.","We have also built an interactive platform for AI-assisted counseling.","It has an interface that displays the relevant parts of the retrieval sub-graph.","The Psy-Copilot is designed not to replace psychotherapists but to foster collaboration between AI and human therapists, thereby promoting mental health development.","Our code and demo are both open-sourced and available for use."],"url":"http://arxiv.org/abs/2503.03645v1"}
{"created":"2025-03-05 16:20:53","title":"DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms","abstract":"Dongba pictographs are the only pictographs still in use in the world. They have pictorial ideographic features, and their symbols carry rich cultural and contextual information. Due to the lack of relevant datasets, existing research has difficulty in advancing the study of semantic understanding of Dongba pictographs. To this end, we propose DongbaMIE, the first multimodal dataset for semantic understanding and extraction of Dongba pictographs. The dataset consists of Dongba pictograph images and their corresponding Chinese semantic annotations. It contains 23,530 sentence-level and 2,539 paragraph-level images, covering four semantic dimensions: objects, actions, relations, and attributes. We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL models. Experimental results show that the F1 scores of GPT-4o and Gemini in the best object extraction are only 3.16 and 3.11 respectively. The F1 score of Qwen2-VL after supervised fine-tuning is only 11.49. These results suggest that current large multimodal models still face significant challenges in accurately recognizing the diverse semantic information in Dongba pictographs. The dataset can be obtained from this URL.","sentences":["Dongba pictographs are the only pictographs still in use in the world.","They have pictorial ideographic features, and their symbols carry rich cultural and contextual information.","Due to the lack of relevant datasets, existing research has difficulty in advancing the study of semantic understanding of Dongba pictographs.","To this end, we propose DongbaMIE, the first multimodal dataset for semantic understanding and extraction of Dongba pictographs.","The dataset consists of Dongba pictograph images and their corresponding Chinese semantic annotations.","It contains 23,530 sentence-level and 2,539 paragraph-level images, covering four semantic dimensions: objects, actions, relations, and attributes.","We systematically evaluate the GPT-4o, Gemini-2.0, and Qwen2-VL models.","Experimental results show that the F1 scores of GPT-4o and Gemini in the best object extraction are only 3.16 and 3.11 respectively.","The F1 score of Qwen2-VL after supervised fine-tuning is only 11.49.","These results suggest that current large multimodal models still face significant challenges in accurately recognizing the diverse semantic information in Dongba pictographs.","The dataset can be obtained from this URL."],"url":"http://arxiv.org/abs/2503.03644v1"}
{"created":"2025-03-05 16:20:40","title":"Improved FPT Approximation Algorithms for TSP","abstract":"TSP is a classic and extensively studied problem with numerous real-world applications in artificial intelligence and operations research. It is well-known that TSP admits a constant approximation ratio on metric graphs but becomes NP-hard to approximate within any computable function $f(n)$ on general graphs. This disparity highlights a significant gap between the results on metric graphs and general graphs. Recent research has introduced some parameters to measure the ``distance'' of general graphs from being metric and explored FPT approximation algorithms parameterized by these parameters. Two commonly studied parameters are $p$, the number of vertices in triangles violating the triangle inequality, and $q$, the minimum number of vertices whose removal results in a metric graph. In this paper, we present improved FPT approximation algorithms with respect to these two parameters. For $p$, we propose an FPT algorithm with a 1.5-approximation ratio, improving upon the previous ratio of 2.5. For $q$, we significantly enhance the approximation ratio from 11 to 3, advancing the state of the art in both cases.","sentences":["TSP is a classic and extensively studied problem with numerous real-world applications in artificial intelligence and operations research.","It is well-known that TSP admits a constant approximation ratio on metric graphs but becomes NP-hard to approximate within any computable function $f(n)$ on general graphs.","This disparity highlights a significant gap between the results on metric graphs and general graphs.","Recent research has introduced some parameters to measure the ``distance'' of general graphs from being metric and explored FPT approximation algorithms parameterized by these parameters.","Two commonly studied parameters are $p$, the number of vertices in triangles violating the triangle inequality, and $q$, the minimum number of vertices whose removal results in a metric graph.","In this paper, we present improved FPT approximation algorithms with respect to these two parameters.","For $p$, we propose an FPT algorithm with a 1.5-approximation ratio, improving upon the previous ratio of 2.5.","For $q$, we significantly enhance the approximation ratio from 11 to 3, advancing the state of the art in both cases."],"url":"http://arxiv.org/abs/2503.03642v1"}
{"created":"2025-03-05 16:20:28","title":"Does More Bandwidth Really Not Matter (Much)?","abstract":"The prevailing wisdom is that more network bandwidth does not matter much and that website performance is primarily limited by network latency. However, as mobile websites become more complex and mobile network performance improves, does this adage continue to hold? To understand the effects of small changes in network bandwidth and latency on website performance, we propose a novel webpage characterization metrics, Critical Path of Improvement (CPI). We compute CPI for 45 websites and analyze it against the network performance of four mobile ISPs in 57 US cities. Our results show that 18% of websites are primarily limited by bandwidth with others limited by bandwidth to some extent. These results show that contrary to accepted wisdom, insufficient bandwidth is a limiting factor in some website/network combinations. We also offer a discussion of approaches website developers and mobile network administrators can follow to understand and mitigate bandwidth limitations to website performance.","sentences":["The prevailing wisdom is that more network bandwidth does not matter much and that website performance is primarily limited by network latency.","However, as mobile websites become more complex and mobile network performance improves, does this adage continue to hold?","To understand the effects of small changes in network bandwidth and latency on website performance, we propose a novel webpage characterization metrics, Critical Path of Improvement (CPI).","We compute CPI for 45 websites and analyze it against the network performance of four mobile ISPs in 57 US cities.","Our results show that 18% of websites are primarily limited by bandwidth with others limited by bandwidth to some extent.","These results show that contrary to accepted wisdom, insufficient bandwidth is a limiting factor in some website/network combinations.","We also offer a discussion of approaches website developers and mobile network administrators can follow to understand and mitigate bandwidth limitations to website performance."],"url":"http://arxiv.org/abs/2503.03641v1"}
{"created":"2025-03-05 16:19:56","title":"An Adaptive Underwater Image Enhancement Framework via Multi-Domain Fusion and Color Compensation","abstract":"Underwater optical imaging is severely degraded by light absorption, scattering, and color distortion, hindering visibility and accurate image analysis. This paper presents an adaptive enhancement framework integrating illumination compensation, multi-domain filtering, and dynamic color correction. A hybrid illumination compensation strategy combining CLAHE, Gamma correction, and Retinex enhances visibility. A two-stage filtering process, including spatial-domain (Gaussian, Bilateral, Guided) and frequency-domain (Fourier, Wavelet) methods, effectively reduces noise while preserving details. To correct color distortion, an adaptive color compensation (ACC) model estimates spectral attenuation and water type to combine RCP, DCP, and MUDCP dynamically. Finally, a perceptually guided color balance mechanism ensures natural color restoration. Experimental results on benchmark datasets demonstrate superior performance over state-of-the-art methods in contrast enhancement, color correction, and structural preservation, making the framework robust for underwater imaging applications.","sentences":["Underwater optical imaging is severely degraded by light absorption, scattering, and color distortion, hindering visibility and accurate image analysis.","This paper presents an adaptive enhancement framework integrating illumination compensation, multi-domain filtering, and dynamic color correction.","A hybrid illumination compensation strategy combining CLAHE, Gamma correction, and Retinex enhances visibility.","A two-stage filtering process, including spatial-domain (Gaussian, Bilateral, Guided) and frequency-domain (Fourier, Wavelet) methods, effectively reduces noise while preserving details.","To correct color distortion, an adaptive color compensation (ACC) model estimates spectral attenuation and water type to combine RCP, DCP, and MUDCP dynamically.","Finally, a perceptually guided color balance mechanism ensures natural color restoration.","Experimental results on benchmark datasets demonstrate superior performance over state-of-the-art methods in contrast enhancement, color correction, and structural preservation, making the framework robust for underwater imaging applications."],"url":"http://arxiv.org/abs/2503.03640v1"}
{"created":"2025-03-05 16:16:46","title":"4D Radar Ground Truth Augmentation with LiDAR-to-4D Radar Data Synthesis","abstract":"Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object detection, as it enhances object density by leveraging ground truth bounding boxes (GT bboxes). However, directly applying GT-Aug to 4D Radar tensor data overlooks important measurements outside the GT bboxes-such as sidelobes-leading to synthetic distributions that deviate from real-world 4D Radar data. To address this limitation, we propose 4D Radar Ground Truth Augmentation (4DR GT-Aug). Our approach first augments LiDAR data and then converts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS) module, which explicitly accounts for measurements both inside and outside GT bboxes. In doing so, it produces 4D Radar data distributions that more closely resemble real-world measurements, thereby improving object detection accuracy. Experiments on the K-Radar dataset show that the proposed method achieves improved performance compared to conventional GT-Aug in object detection for 4D Radar. The implementation code is available at https://github.com/kaist-avelab/K-Radar.","sentences":["Ground truth augmentation (GT-Aug) is a common method for LiDAR-based object detection, as it enhances object density by leveraging ground truth bounding boxes (GT bboxes).","However, directly applying GT-Aug to 4D Radar tensor data overlooks important measurements outside the GT bboxes-such as sidelobes-leading to synthetic distributions that deviate from real-world 4D Radar data.","To address this limitation, we propose 4D Radar Ground Truth Augmentation (4DR GT-Aug).","Our approach first augments LiDAR data and then converts it to 4D Radar data via a LiDAR-to-4D Radar data synthesis (L2RDaS) module, which explicitly accounts for measurements both inside and outside GT bboxes.","In doing so, it produces 4D Radar data distributions that more closely resemble real-world measurements, thereby improving object detection accuracy.","Experiments on the K-Radar dataset show that the proposed method achieves improved performance compared to conventional GT-Aug in object detection for 4D Radar.","The implementation code is available at https://github.com/kaist-avelab/K-Radar."],"url":"http://arxiv.org/abs/2503.03637v1"}
{"created":"2025-03-05 16:14:36","title":"Motion Planning and Control with Unknown Nonlinear Dynamics through Predicted Reachability","abstract":"Autonomous motion planning under unknown nonlinear dynamics presents significant challenges. An agent needs to continuously explore the system dynamics to acquire its properties, such as reachability, in order to guide system navigation adaptively. In this paper, we propose a hybrid planning-control framework designed to compute a feasible trajectory toward a target. Our approach involves partitioning the state space and approximating the system by a piecewise affine (PWA) system with constrained control inputs. By abstracting the PWA system into a directed weighted graph, we incrementally update the existence of its edges via affine system identification and reach control theory, introducing a predictive reachability condition by exploiting prior information of the unknown dynamics. Heuristic weights are assigned to edges based on whether their existence is certain or remains indeterminate. Consequently, we propose a framework that adaptively collects and analyzes data during mission execution, continually updates the predictive graph, and synthesizes a controller online based on the graph search outcomes. We demonstrate the efficacy of our approach through simulation scenarios involving a mobile robot operating in unknown terrains, with its unknown dynamics abstracted as a single integrator model.","sentences":["Autonomous motion planning under unknown nonlinear dynamics presents significant challenges.","An agent needs to continuously explore the system dynamics to acquire its properties, such as reachability, in order to guide system navigation adaptively.","In this paper, we propose a hybrid planning-control framework designed to compute a feasible trajectory toward a target.","Our approach involves partitioning the state space and approximating the system by a piecewise affine (PWA) system with constrained control inputs.","By abstracting the PWA system into a directed weighted graph, we incrementally update the existence of its edges via affine system identification and reach control theory, introducing a predictive reachability condition by exploiting prior information of the unknown dynamics.","Heuristic weights are assigned to edges based on whether their existence is certain or remains indeterminate.","Consequently, we propose a framework that adaptively collects and analyzes data during mission execution, continually updates the predictive graph, and synthesizes a controller online based on the graph search outcomes.","We demonstrate the efficacy of our approach through simulation scenarios involving a mobile robot operating in unknown terrains, with its unknown dynamics abstracted as a single integrator model."],"url":"http://arxiv.org/abs/2503.03633v1"}
{"created":"2025-03-05 16:09:30","title":"TeraSim: Uncovering Unknown Unsafe Events for Autonomous Vehicles through Generative Simulation","abstract":"Traffic simulation is essential for autonomous vehicle (AV) development, enabling comprehensive safety evaluation across diverse driving conditions. However, traditional rule-based simulators struggle to capture complex human interactions, while data-driven approaches often fail to maintain long-term behavioral realism or generate diverse safety-critical events. To address these challenges, we propose TeraSim, an open-source, high-fidelity traffic simulation platform designed to uncover unknown unsafe events and efficiently estimate AV statistical performance metrics, such as crash rates. TeraSim is designed for seamless integration with third-party physics simulators and standalone AV stacks, to construct a complete AV simulation system. Experimental results demonstrate its effectiveness in generating diverse safety-critical events involving both static and dynamic agents, identifying hidden deficiencies in AV systems, and enabling statistical performance evaluation. These findings highlight TeraSim's potential as a practical tool for AV safety assessment, benefiting researchers, developers, and policymakers. The code is available at https://github.com/mcity/TeraSim.","sentences":["Traffic simulation is essential for autonomous vehicle (AV) development, enabling comprehensive safety evaluation across diverse driving conditions.","However, traditional rule-based simulators struggle to capture complex human interactions, while data-driven approaches often fail to maintain long-term behavioral realism or generate diverse safety-critical events.","To address these challenges, we propose TeraSim, an open-source, high-fidelity traffic simulation platform designed to uncover unknown unsafe events and efficiently estimate AV statistical performance metrics, such as crash rates.","TeraSim is designed for seamless integration with third-party physics simulators and standalone AV stacks, to construct a complete AV simulation system.","Experimental results demonstrate its effectiveness in generating diverse safety-critical events involving both static and dynamic agents, identifying hidden deficiencies in AV systems, and enabling statistical performance evaluation.","These findings highlight TeraSim's potential as a practical tool for AV safety assessment, benefiting researchers, developers, and policymakers.","The code is available at https://github.com/mcity/TeraSim."],"url":"http://arxiv.org/abs/2503.03629v1"}
{"created":"2025-03-05 16:02:09","title":"It's My Data Too: Private ML for Datasets with Multi-User Training Examples","abstract":"We initiate a study of algorithms for model training with user-level differential privacy (DP), where each example may be attributed to multiple users, which we call the multi-attribution model. We first provide a carefully chosen definition of user-level DP under the multi-attribution model. Training in the multi-attribution model is facilitated by solving the contribution bounding problem, i.e. the problem of selecting a subset of the dataset for which each user is associated with a limited number of examples. We propose a greedy baseline algorithm for the contribution bounding problem. We then empirically study this algorithm for a synthetic logistic regression task and a transformer training task, including studying variants of this baseline algorithm that optimize the subset chosen using different techniques and criteria. We find that the baseline algorithm remains competitive with its variants in most settings, and build a better understanding of the practical importance of a bias-variance tradeoff inherent in solutions to the contribution bounding problem.","sentences":["We initiate a study of algorithms for model training with user-level differential privacy (DP), where each example may be attributed to multiple users, which we call the multi-attribution model.","We first provide a carefully chosen definition of user-level DP under the multi-attribution model.","Training in the multi-attribution model is facilitated by solving the contribution bounding problem, i.e. the problem of selecting a subset of the dataset for which each user is associated with a limited number of examples.","We propose a greedy baseline algorithm for the contribution bounding problem.","We then empirically study this algorithm for a synthetic logistic regression task and a transformer training task, including studying variants of this baseline algorithm that optimize the subset chosen using different techniques and criteria.","We find that the baseline algorithm remains competitive with its variants in most settings, and build a better understanding of the practical importance of a bias-variance tradeoff inherent in solutions to the contribution bounding problem."],"url":"http://arxiv.org/abs/2503.03622v1"}
{"created":"2025-03-05 15:58:24","title":"Design and Implementation of an IoT Cluster with Raspberry Pi Powered by Solar Energy: A Theoretical Approach","abstract":"This document presents the design and implementation of a low-power IoT server cluster, based on Raspberry Pi 3 Model B and powered by solar energy. The proposed architecture integrates Kubernetes (K3s) and Docker, providing an efficient, scalable, and high-performance computing environment. The cluster is designed to optimize energy consumption, leveraging a 200W solar panel system and a 100Ah lithium-ion battery to support continuous operation under favorable environmental conditions. Performance analysis was conducted based on theoretical inferences and data obtained from external sources, evaluating resource allocation, power consumption, and service availability. These analyses provide theoretical estimates of the system's operational feasibility under different scenarios. The results suggest that this system can serve as a viable and sustainable alternative for edge computing applications and cloud services, reducing dependence on traditional data centers. In addition to its positive impact on environmental sustainability by significantly reducing the carbon footprint, this solution also addresses economic concerns, as conventional data centers consume enormous amounts of energy, leading to increased demand on the power grid and higher operational costs.","sentences":["This document presents the design and implementation of a low-power IoT server cluster, based on Raspberry Pi 3 Model B and powered by solar energy.","The proposed architecture integrates Kubernetes (K3s) and Docker, providing an efficient, scalable, and high-performance computing environment.","The cluster is designed to optimize energy consumption, leveraging a 200W solar panel system and a 100Ah lithium-ion battery to support continuous operation under favorable environmental conditions.","Performance analysis was conducted based on theoretical inferences and data obtained from external sources, evaluating resource allocation, power consumption, and service availability.","These analyses provide theoretical estimates of the system's operational feasibility under different scenarios.","The results suggest that this system can serve as a viable and sustainable alternative for edge computing applications and cloud services, reducing dependence on traditional data centers.","In addition to its positive impact on environmental sustainability by significantly reducing the carbon footprint, this solution also addresses economic concerns, as conventional data centers consume enormous amounts of energy, leading to increased demand on the power grid and higher operational costs."],"url":"http://arxiv.org/abs/2503.03618v1"}
{"created":"2025-03-05 15:56:25","title":"Facilitating Asynchronous Idea Generation and Selection with Chatbots","abstract":"People can generate high-quality ideas by building on each other's ideas. By enabling individuals to contribute their ideas at their own comfortable time and method (i.e., asynchronous ideation), they can deeply engage in ideation and improve idea quality. However, running asynchronous ideation faces a practical constraint. Whereas trained human facilitators are needed to guide effective idea exchange, they cannot be continuously available to engage with individuals joining at varying hours. In this paper, we ask how chatbots can be designed to facilitate asynchronous ideation. For this, we adopted the guidelines found in the literature about human facilitators and designed two chatbots: one provides a structured ideation process, and another adapts the ideation process to individuals' ideation performance. We invited 48 participants to generate and select ideas by interacting with one of our chatbots and invited an expert facilitator to review our chatbots. We found that both chatbots can guide users to build on each other's ideas and converge them into a few satisfying ideas. However, we also found the chatbots' limitations in social interaction with collaborators, which only human facilitators can provide. Accordingly, we conclude that chatbots can be promising facilitators of asynchronous ideation, but hybrid facilitation with human facilitators would be needed to address the social aspects of collaborative ideation.","sentences":["People can generate high-quality ideas by building on each other's ideas.","By enabling individuals to contribute their ideas at their own comfortable time and method (i.e., asynchronous ideation), they can deeply engage in ideation and improve idea quality.","However, running asynchronous ideation faces a practical constraint.","Whereas trained human facilitators are needed to guide effective idea exchange, they cannot be continuously available to engage with individuals joining at varying hours.","In this paper, we ask how chatbots can be designed to facilitate asynchronous ideation.","For this, we adopted the guidelines found in the literature about human facilitators and designed two chatbots: one provides a structured ideation process, and another adapts the ideation process to individuals' ideation performance.","We invited 48 participants to generate and select ideas by interacting with one of our chatbots and invited an expert facilitator to review our chatbots.","We found that both chatbots can guide users to build on each other's ideas and converge them into a few satisfying ideas.","However, we also found the chatbots' limitations in social interaction with collaborators, which only human facilitators can provide.","Accordingly, we conclude that chatbots can be promising facilitators of asynchronous ideation, but hybrid facilitation with human facilitators would be needed to address the social aspects of collaborative ideation."],"url":"http://arxiv.org/abs/2503.03617v1"}
{"created":"2025-03-05 15:51:59","title":"CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards Zero-shot Adversarial Robustness of CLIP","abstract":"Despite its prevalent use in image-text matching tasks in a zero-shot manner, CLIP has been shown to be highly vulnerable to adversarial perturbations added onto images. Recent studies propose to finetune the vision encoder of CLIP with adversarial samples generated on the fly, and show improved robustness against adversarial attacks on a spectrum of downstream datasets, a property termed as zero-shot robustness. In this paper, we show that malicious perturbations that seek to maximise the classification loss lead to `falsely stable' images, and propose to leverage the pre-trained vision encoder of CLIP to counterattack such adversarial images during inference to achieve robustness. Our paradigm is simple and training-free, providing the first method to defend CLIP from adversarial attacks at test time, which is orthogonal to existing methods aiming to boost zero-shot adversarial robustness of CLIP. We conduct experiments across 16 classification datasets, and demonstrate stable and consistent gains compared to test-time defence methods adapted from existing adversarial robustness studies that do not rely on external networks, without noticeably impairing performance on clean images. We also show that our paradigm can be employed on CLIP models that have been adversarially finetuned to further enhance their robustness at test time. Our code is available \\href{https://github.com/Sxing2/CLIP-Test-time-Counterattacks}{here}.","sentences":["Despite its prevalent use in image-text matching tasks in a zero-shot manner, CLIP has been shown to be highly vulnerable to adversarial perturbations added onto images.","Recent studies propose to finetune the vision encoder of CLIP with adversarial samples generated on the fly, and show improved robustness against adversarial attacks on a spectrum of downstream datasets, a property termed as zero-shot robustness.","In this paper, we show that malicious perturbations that seek to maximise the classification loss lead to `falsely stable' images, and propose to leverage the pre-trained vision encoder of CLIP to counterattack such adversarial images during inference to achieve robustness.","Our paradigm is simple and training-free, providing the first method to defend CLIP from adversarial attacks at test time, which is orthogonal to existing methods aiming to boost zero-shot adversarial robustness of CLIP.","We conduct experiments across 16 classification datasets, and demonstrate stable and consistent gains compared to test-time defence methods adapted from existing adversarial robustness studies that do not rely on external networks, without noticeably impairing performance on clean images.","We also show that our paradigm can be employed on CLIP models that have been adversarially finetuned to further enhance their robustness at test time.","Our code is available \\href{https://github.com/Sxing2/CLIP-Test-time-Counterattacks}{here}."],"url":"http://arxiv.org/abs/2503.03613v1"}
{"created":"2025-03-05 15:51:21","title":"Measuring a moving target -- Innovation studies in practice","abstract":"This paper pays a tribute to Loet's work in a specific way. More than 20 years ago Loet Leydesdorff and myself designed a programme for future innovation studies 'Measuring the knowledge base - a programme of innovation studies'. Although, the funding programme we envisioned eventually did not materialise, the proposal text set out the main lines of our research collaboration over the coming decades. This paper revisits main statements of this programme and discusses their remaining validity in the light of more recent research. Core to the Leydesdorff and Scharnhorst text was a system-theoretical, evolutionary perspective on science dynamics, newly emerging structures and phenomena and addressed the question to which extent they could be meaningful studied using quantitative approaches. This paper looks into three cases - all examples of newly emerging institutional structures and related practices in science. They are all located at the interface between research and research infrastructures. While discussing how the programmatic ideas written up at the beginning of the 2000s still informs measurement attempts in those three cases, the paper also touches upon questions of epistemological foundations of quantitative studies in general. The main conclusion is that combining measurement experiments with philosophical reflection remains important.","sentences":["This paper pays a tribute to Loet's work in a specific way.","More than 20 years ago Loet Leydesdorff and myself designed a programme for future innovation studies 'Measuring the knowledge base - a programme of innovation studies'.","Although, the funding programme we envisioned eventually did not materialise, the proposal text set out the main lines of our research collaboration over the coming decades.","This paper revisits main statements of this programme and discusses their remaining validity in the light of more recent research.","Core to the Leydesdorff and Scharnhorst text was a system-theoretical, evolutionary perspective on science dynamics, newly emerging structures and phenomena and addressed the question to which extent they could be meaningful studied using quantitative approaches.","This paper looks into three cases - all examples of newly emerging institutional structures and related practices in science.","They are all located at the interface between research and research infrastructures.","While discussing how the programmatic ideas written up at the beginning of the 2000s still informs measurement attempts in those three cases, the paper also touches upon questions of epistemological foundations of quantitative studies in general.","The main conclusion is that combining measurement experiments with philosophical reflection remains important."],"url":"http://arxiv.org/abs/2503.03611v1"}
{"created":"2025-03-05 15:47:22","title":"Enhancing the Accuracy and Comprehensibility in Architectural Tactics Detection via Small Model-Augmented Prompt Engineering","abstract":"Architectural tactics (ATs), as the concrete implementation of architectural decisions in code, address non-functional requirements of software systems. Due to the implicit nature of architectural knowledge in code implementation, developers may risk inadvertently altering or removing these tactics during code modifications or optimizations. Such unintended changes can trigger architectural erosion, gradually undermining the system's original design. While many researchers have proposed machine learning-based methods to improve the accuracy of detecting ATs in code, the black-box nature and the required architectural domain knowledge pose significant challenges for developers in verifying the results. Effective verification requires not only accurate detection results but also interpretable explanations that enhance their comprehensibility. However, this is a critical gap in current research. Large language models (LLMs) can generate easily interpretable ATs detection comments if they have domain knowledge. Fine-tuning LLMs to acquire domain knowledge faces challenges such as catastrophic forgetting and hardware constraints. Thus, we propose Prmt4TD, a small model-augmented prompting framework to enhance the accuracy and comprehensibility of ATs detection. Combining fine-tuned small models with In-Context Learning can also reduce fine-tuning costs while equipping the LLM with additional domain knowledge. Prmt4TD can leverage the remarkable processing and reasoning capabilities of LLMs to generate easily interpretable ATs detection results. Our evaluation results demonstrate that Prmt4TD achieves accuracy (\\emph{F1-score}) improvement of 13\\%-23\\% on the ATs balanced dataset and enhances the comprehensibility of the detection results.","sentences":["Architectural tactics (ATs), as the concrete implementation of architectural decisions in code, address non-functional requirements of software systems.","Due to the implicit nature of architectural knowledge in code implementation, developers may risk inadvertently altering or removing these tactics during code modifications or optimizations.","Such unintended changes can trigger architectural erosion, gradually undermining the system's original design.","While many researchers have proposed machine learning-based methods to improve the accuracy of detecting ATs in code, the black-box nature and the required architectural domain knowledge pose significant challenges for developers in verifying the results.","Effective verification requires not only accurate detection results but also interpretable explanations that enhance their comprehensibility.","However, this is a critical gap in current research.","Large language models (LLMs) can generate easily interpretable ATs detection comments if they have domain knowledge.","Fine-tuning LLMs to acquire domain knowledge faces challenges such as catastrophic forgetting and hardware constraints.","Thus, we propose Prmt4TD, a small model-augmented prompting framework to enhance the accuracy and comprehensibility of ATs detection.","Combining fine-tuned small models with In-Context Learning can also reduce fine-tuning costs while equipping the LLM with additional domain knowledge.","Prmt4TD can leverage the remarkable processing and reasoning capabilities of LLMs to generate easily interpretable ATs detection results.","Our evaluation results demonstrate that Prmt4TD achieves accuracy (\\emph{F1-score}) improvement of 13\\%-23\\% on the ATs balanced dataset and enhances the comprehensibility of the detection results."],"url":"http://arxiv.org/abs/2503.03609v1"}
{"created":"2025-03-05 15:44:21","title":"Psy-Insight: Explainable Multi-turn Bilingual Dataset for Mental Health Counseling","abstract":"The in-context learning capabilities of large language models (LLMs) show great potential in mental health support. However, the lack of counseling datasets, particularly in Chinese corpora, restricts their application in this field. To address this, we constructed Psy-Insight, the first mental health-oriented explainable multi-task bilingual dataset. We collected face-to-face multi-turn counseling dialogues, which are annotated with multi-task labels and conversation process explanations. Our annotations include psychotherapy, emotion, strategy, and topic labels, as well as turn-level reasoning and session-level guidance. Psy-Insight is not only suitable for tasks such as label recognition but also meets the need for training LLMs to act as empathetic counselors through logical reasoning. Experiments show that training LLMs on Psy-Insight enables the models to not only mimic the conversation style but also understand the underlying strategies and reasoning of counseling.","sentences":["The in-context learning capabilities of large language models (LLMs) show great potential in mental health support.","However, the lack of counseling datasets, particularly in Chinese corpora, restricts their application in this field.","To address this, we constructed Psy-Insight, the first mental health-oriented explainable multi-task bilingual dataset.","We collected face-to-face multi-turn counseling dialogues, which are annotated with multi-task labels and conversation process explanations.","Our annotations include psychotherapy, emotion, strategy, and topic labels, as well as turn-level reasoning and session-level guidance.","Psy-Insight is not only suitable for tasks such as label recognition but also meets the need for training LLMs to act as empathetic counselors through logical reasoning.","Experiments show that training LLMs on Psy-Insight enables the models to not only mimic the conversation style but also understand the underlying strategies and reasoning of counseling."],"url":"http://arxiv.org/abs/2503.03607v1"}
{"created":"2025-03-05 15:42:37","title":"Decoupled Recommender Systems: Exploring Alternative Recommender Ecosystem Designs","abstract":"Recommender ecosystems are an emerging subject of research. Such research examines how the characteristics of algorithms, recommendation consumers, and item providers influence system dynamics and long-term outcomes. One architectural possibility that has not yet been widely explored in this line of research is the consequences of a configuration in which recommendation algorithms are decoupled from the platforms they serve. This is sometimes called \"the friendly neighborhood algorithm store\" or \"middleware\" model. We are particularly interested in how such architectures might offer a range of different distributions of utility across consumers, providers, and recommendation platforms. In this paper, we create a model of a recommendation ecosystem that incorporates algorithm choice and examine the outcomes of such a design.","sentences":["Recommender ecosystems are an emerging subject of research.","Such research examines how the characteristics of algorithms, recommendation consumers, and item providers influence system dynamics and long-term outcomes.","One architectural possibility that has not yet been widely explored in this line of research is the consequences of a configuration in which recommendation algorithms are decoupled from the platforms they serve.","This is sometimes called \"the friendly neighborhood algorithm store\" or \"middleware\" model.","We are particularly interested in how such architectures might offer a range of different distributions of utility across consumers, providers, and recommendation platforms.","In this paper, we create a model of a recommendation ecosystem that incorporates algorithm choice and examine the outcomes of such a design."],"url":"http://arxiv.org/abs/2503.03606v1"}
{"created":"2025-03-05 15:33:52","title":"Feature-Level Insights into Artificial Text Detection with Sparse Autoencoders","abstract":"Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs). Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or guarantees effective generalization to new LLMs. Interpretability plays a crucial role in achieving this goal. In this study, we enhance ATD interpretability by using Sparse Autoencoders (SAE) to extract features from Gemma-2-2b residual stream. We identify both interpretable and efficient features, analyzing their semantics and relevance through domain- and model-specific statistics, a steering approach, and manual or LLM-based interpretation. Our methods offer valuable insights into how texts from various models differ from human-written content. We show that modern LLMs have a distinct writing style, especially in information-dense domains, even though they can produce human-like outputs with personalized prompts.","sentences":["Artificial Text Detection (ATD) is becoming increasingly important with the rise of advanced Large Language Models (LLMs).","Despite numerous efforts, no single algorithm performs consistently well across different types of unseen text or guarantees effective generalization to new LLMs.","Interpretability plays a crucial role in achieving this goal.","In this study, we enhance ATD interpretability by using Sparse Autoencoders (SAE) to extract features from Gemma-2-2b residual stream.","We identify both interpretable and efficient features, analyzing their semantics and relevance through domain- and model-specific statistics, a steering approach, and manual or LLM-based interpretation.","Our methods offer valuable insights into how texts from various models differ from human-written content.","We show that modern LLMs have a distinct writing style, especially in information-dense domains, even though they can produce human-like outputs with personalized prompts."],"url":"http://arxiv.org/abs/2503.03601v1"}
{"created":"2025-03-05 15:32:38","title":"REGRACE: A Robust and Efficient Graph-based Re-localization Algorithm using Consistency Evaluation","abstract":"Loop closures are essential for correcting odometry drift and creating consistent maps, especially in the context of large-scale navigation. Current methods using dense point clouds for accurate place recognition do not scale well due to computationally expensive scan-to-scan comparisons. Alternative object-centric approaches are more efficient but often struggle with sensitivity to viewpoint variation. In this work, we introduce REGRACE, a novel approach that addresses these challenges of scalability and perspective difference in re-localization by using LiDAR-based submaps. We introduce rotation-invariant features for each labeled object and enhance them with neighborhood context through a graph neural network. To identify potential revisits, we employ a scalable bag-of-words approach, pooling one learned global feature per submap. Additionally, we define a revisit with geometrical consistency cues rather than embedding distance, allowing us to recognize far-away loop closures. Our evaluations demonstrate that REGRACE achieves similar results compared to state-of-the-art place recognition and registration baselines while being twice as fast.","sentences":["Loop closures are essential for correcting odometry drift and creating consistent maps, especially in the context of large-scale navigation.","Current methods using dense point clouds for accurate place recognition do not scale well due to computationally expensive scan-to-scan comparisons.","Alternative object-centric approaches are more efficient but often struggle with sensitivity to viewpoint variation.","In this work, we introduce REGRACE, a novel approach that addresses these challenges of scalability and perspective difference in re-localization by using LiDAR-based submaps.","We introduce rotation-invariant features for each labeled object and enhance them with neighborhood context through a graph neural network.","To identify potential revisits, we employ a scalable bag-of-words approach, pooling one learned global feature per submap.","Additionally, we define a revisit with geometrical consistency cues rather than embedding distance, allowing us to recognize far-away loop closures.","Our evaluations demonstrate that REGRACE achieves similar results compared to state-of-the-art place recognition and registration baselines while being twice as fast."],"url":"http://arxiv.org/abs/2503.03599v1"}
{"created":"2025-03-05 15:28:50","title":"Towards Understanding Text Hallucination of Diffusion Models via Local Generation Bias","abstract":"Score-based diffusion models have achieved incredible performance in generating realistic images, audio, and video data. While these models produce high-quality samples with impressive details, they often introduce unrealistic artifacts, such as distorted fingers or hallucinated texts with no meaning. This paper focuses on textual hallucinations, where diffusion models correctly generate individual symbols but assemble them in a nonsensical manner. Through experimental probing, we consistently observe that such phenomenon is attributed it to the network's local generation bias. Denoising networks tend to produce outputs that rely heavily on highly correlated local regions, particularly when different dimensions of the data distribution are nearly pairwise independent. This behavior leads to a generation process that decomposes the global distribution into separate, independent distributions for each symbol, ultimately failing to capture the global structure, including underlying grammar. Intriguingly, this bias persists across various denoising network architectures including MLP and transformers which have the structure to model global dependency. These findings also provide insights into understanding other types of hallucinations, extending beyond text, as a result of implicit biases in the denoising models. Additionally, we theoretically analyze the training dynamics for a specific case involving a two-layer MLP learning parity points on a hypercube, offering an explanation of its underlying mechanism.","sentences":["Score-based diffusion models have achieved incredible performance in generating realistic images, audio, and video data.","While these models produce high-quality samples with impressive details, they often introduce unrealistic artifacts, such as distorted fingers or hallucinated texts with no meaning.","This paper focuses on textual hallucinations, where diffusion models correctly generate individual symbols but assemble them in a nonsensical manner.","Through experimental probing, we consistently observe that such phenomenon is attributed it to the network's local generation bias.","Denoising networks tend to produce outputs that rely heavily on highly correlated local regions, particularly when different dimensions of the data distribution are nearly pairwise independent.","This behavior leads to a generation process that decomposes the global distribution into separate, independent distributions for each symbol, ultimately failing to capture the global structure, including underlying grammar.","Intriguingly, this bias persists across various denoising network architectures including MLP and transformers which have the structure to model global dependency.","These findings also provide insights into understanding other types of hallucinations, extending beyond text, as a result of implicit biases in the denoising models.","Additionally, we theoretically analyze the training dynamics for a specific case involving a two-layer MLP learning parity points on a hypercube, offering an explanation of its underlying mechanism."],"url":"http://arxiv.org/abs/2503.03595v1"}
{"created":"2025-03-05 15:27:36","title":"Small but Mighty: Enhancing Time Series Forecasting with Lightweight LLMs","abstract":"While LLMs have demonstrated remarkable potential in time series forecasting, their practical deployment remains constrained by excessive computational demands and memory footprints. Existing LLM-based approaches typically suffer from three critical limitations: Inefficient parameter utilization in handling numerical time series patterns; Modality misalignment between continuous temporal signals and discrete text embeddings; and Inflexibility for real-time expert knowledge integration. We present SMETimes, the first systematic investigation of sub-3B parameter SLMs for efficient and accurate time series forecasting. Our approach centers on three key innovations: A statistically-enhanced prompting mechanism that bridges numerical time series with textual semantics through descriptive statistical features; A adaptive fusion embedding architecture that aligns temporal patterns with language model token spaces through learnable parameters; And a dynamic mixture-of-experts framework enabled by SLMs' computational efficiency, adaptively combining base predictions with domain-specific models. Extensive evaluations across seven benchmark datasets demonstrate that our 3B-parameter SLM achieves state-of-the-art performance on five primary datasets while maintaining 3.8x faster training and 5.2x lower memory consumption compared to 7B-parameter LLM baselines. Notably, the proposed model exhibits better learning capabilities, achieving 12.3% lower MSE than conventional LLM. Ablation studies validate that our statistical prompting and cross-modal fusion modules respectively contribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks. By redefining the efficiency-accuracy trade-off landscape, this work establishes SLMs as viable alternatives to resource-intensive LLMs for practical time series forecasting. Code and models are available at https://github.com/xiyan1234567/SMETimes.","sentences":["While LLMs have demonstrated remarkable potential in time series forecasting, their practical deployment remains constrained by excessive computational demands and memory footprints.","Existing LLM-based approaches typically suffer from three critical limitations: Inefficient parameter utilization in handling numerical time series patterns; Modality misalignment between continuous temporal signals and discrete text embeddings; and Inflexibility for real-time expert knowledge integration.","We present SMETimes, the first systematic investigation of sub-3B parameter SLMs for efficient and accurate time series forecasting.","Our approach centers on three key innovations: A statistically-enhanced prompting mechanism that bridges numerical time series with textual semantics through descriptive statistical features; A adaptive fusion embedding architecture that aligns temporal patterns with language model token spaces through learnable parameters; And a dynamic mixture-of-experts framework enabled by SLMs' computational efficiency, adaptively combining base predictions with domain-specific models.","Extensive evaluations across seven benchmark datasets demonstrate that our 3B-parameter SLM achieves state-of-the-art performance on five primary datasets while maintaining 3.8x faster training and 5.2x lower memory consumption compared to 7B-parameter LLM baselines.","Notably, the proposed model exhibits better learning capabilities, achieving 12.3% lower MSE than conventional LLM.","Ablation studies validate that our statistical prompting and cross-modal fusion modules respectively contribute 15.7% and 18.2% error reduction in long-horizon forecasting tasks.","By redefining the efficiency-accuracy trade-off landscape, this work establishes SLMs as viable alternatives to resource-intensive LLMs for practical time series forecasting.","Code and models are available at https://github.com/xiyan1234567/SMETimes."],"url":"http://arxiv.org/abs/2503.03594v1"}
{"created":"2025-03-05 15:26:59","title":"English K_Quantization of LLMs Does Not Disproportionately Diminish Multilingual Performance","abstract":"For consumer usage of locally deployed LLMs, the GGUF format and k_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware. The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference. This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases. In the vast majority of quants available online, this document is primarily written in English. It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices. This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian. All experiments related to k_quantization yielded non-significant results (In all cases p > 0.237) indicating that current quantization practices do not disproportionately harm multilingual performance.","sentences":["For consumer usage of locally deployed LLMs, the GGUF format and k_quantization are invaluable tools for maintaining the performance of the original model while reducing it to sizes deployable with consumer-grade hardware.","The number of bits dedicated to each weight from the original model is reduced based on how important they are thought to be during model inference.","This importance is arrived at through the application of an 'importance matrix'-a relatively small text document meant to be representative of the LLM's standard use-cases.","In the vast majority of quants available online, this document is primarily written in English.","It was therefore an open question whether performance on English language tasks was preserved through the sacrifice of multilingual performance and whether it can be preserved with alternate importance matrices.","This article investigates these hypotheses by quantizing Llama3.3 70B on importance matrices written in three languages (English, Norwegian, and Malayalam) and evaluating them on the MixEval dataset in both English and Norwegian.","All experiments related to k_quantization yielded non-significant results (In all cases p > 0.237) indicating that current quantization practices do not disproportionately harm multilingual performance."],"url":"http://arxiv.org/abs/2503.03592v1"}
{"created":"2025-03-05 15:24:37","title":"Digital Twin-Enabled Blockage-Aware Dynamic mmWave Multi-Hop V2X Communication","abstract":"Millimeter wave (mmWave) technology in vehicle-to-everything (V2X) communication offers unprecedented data rates and low latency, but faces significant reliability challenges due to signal blockages and limited range. This paper introduces a novel system for managing dynamic multi-hop mmWave V2X communications in complex blocking environments. We present a system architecture that integrates a mobility digital twin (DT) with the multi-hop routing control plane, providing a comprehensive, real-time view of the network and its surrounding traffic environment. This integration enables the control plane to make informed routing decisions based on rich contextual data about vehicles, infrastructure, and potential signal blockages. Leveraging this DT-enhanced architecture, we propose an advanced routing algorithm that combines high-precision environmental data with trajectory prediction to achieve blockage-aware mmWave multi-hop V2X routing. Our algorithm anticipates network topology changes and adapts topology dynamically to maintain reliable connections. We evaluate our approach through proof-of-concept simulations using a mobility DT of the Nishishinjuku area. Results demonstrate that our DT-enabled routing strategy significantly outperforms conventional methods in maintaining reliable mmWave V2X connections across various traffic scenarios, including fully connected and mixed traffic environments.","sentences":["Millimeter wave (mmWave) technology in vehicle-to-everything (V2X) communication offers unprecedented data rates and low latency, but faces significant reliability challenges due to signal blockages and limited range.","This paper introduces a novel system for managing dynamic multi-hop mmWave V2X communications in complex blocking environments.","We present a system architecture that integrates a mobility digital twin (DT) with the multi-hop routing control plane, providing a comprehensive, real-time view of the network and its surrounding traffic environment.","This integration enables the control plane to make informed routing decisions based on rich contextual data about vehicles, infrastructure, and potential signal blockages.","Leveraging this DT-enhanced architecture, we propose an advanced routing algorithm that combines high-precision environmental data with trajectory prediction to achieve blockage-aware mmWave multi-hop V2X routing.","Our algorithm anticipates network topology changes and adapts topology dynamically to maintain reliable connections.","We evaluate our approach through proof-of-concept simulations using a mobility DT of the Nishishinjuku area.","Results demonstrate that our DT-enabled routing strategy significantly outperforms conventional methods in maintaining reliable mmWave V2X connections across various traffic scenarios, including fully connected and mixed traffic environments."],"url":"http://arxiv.org/abs/2503.03590v1"}
{"created":"2025-03-05 15:24:11","title":"PowerAttention: Exponentially Scaling of Receptive Fields for Effective Sparse Attention","abstract":"Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic complexity of the attention mechanism when processing long contexts. Sparse attention methods offer a promising solution, but existing approaches often suffer from incomplete effective context and/or require complex implementation of pipeline. We present a comprehensive analysis of sparse attention for autoregressive LLMs from the respective of receptive field, recognize the suboptimal nature of existing methods for expanding the receptive field, and introduce PowerAttention, a novel sparse attention design that facilitates effective and complete context extension through the theoretical analysis. PowerAttention achieves exponential receptive field growth in $d$-layer LLMs, allowing each output token to attend to $2^d$ tokens, ensuring completeness and continuity of the receptive field. Experiments demonstrate that PowerAttention outperforms existing static sparse attention methods by $5\\sim 40\\%$, especially on tasks demanding long-range dependencies like Passkey Retrieval and RULER, while maintaining a comparable time complexity to sliding window attention. Efficiency evaluations further highlight PowerAttention's superior speedup in both prefilling and decoding phases compared with dynamic sparse attentions and full attention ($3.0\\times$ faster on 128K context), making it a highly effective and user-friendly solution for processing long sequences in LLMs.","sentences":["Large Language Models (LLMs) face efficiency bottlenecks due to the quadratic complexity of the attention mechanism when processing long contexts.","Sparse attention methods offer a promising solution, but existing approaches often suffer from incomplete effective context and/or require complex implementation of pipeline.","We present a comprehensive analysis of sparse attention for autoregressive LLMs from the respective of receptive field, recognize the suboptimal nature of existing methods for expanding the receptive field, and introduce PowerAttention, a novel sparse attention design that facilitates effective and complete context extension through the theoretical analysis.","PowerAttention achieves exponential receptive field growth in $d$-layer LLMs, allowing each output token to attend to $2^d$ tokens, ensuring completeness and continuity of the receptive field.","Experiments demonstrate that PowerAttention outperforms existing static sparse attention methods by $5\\sim 40\\%$, especially on tasks demanding long-range dependencies like Passkey Retrieval and RULER, while maintaining a comparable time complexity to sliding window attention.","Efficiency evaluations further highlight PowerAttention's superior speedup in both prefilling and decoding phases compared with dynamic sparse attentions and full attention ($3.0\\times$ faster on 128K context), making it a highly effective and user-friendly solution for processing long sequences in LLMs."],"url":"http://arxiv.org/abs/2503.03588v1"}
{"created":"2025-03-05 15:22:35","title":"\"You don't need a university degree to comprehend data protection this way\": LLM-Powered Interactive Privacy Policy Assessment","abstract":"Protecting online privacy requires users to engage with and comprehend website privacy policies, but many policies are difficult and tedious to read. We present the first qualitative user study on Large Language Model (LLM)-driven privacy policy assessment. To this end, we build and evaluate an LLM-based privacy policy assessment browser extension, which helps users understand the essence of a lengthy, complex privacy policy while browsing. The tool integrates a dashboard and an LLM chat. In our qualitative user study (N=22), we evaluate usability, understandability of the information our tool provides, and its impacts on awareness. While providing a comprehensible quick overview and a chat for in-depth discussion improves privacy awareness, users note issues with building trust in the tool. From our insights, we derive important design implications to guide future policy analysis tools.","sentences":["Protecting online privacy requires users to engage with and comprehend website privacy policies, but many policies are difficult and tedious to read.","We present the first qualitative user study on Large Language Model (LLM)-driven privacy policy assessment.","To this end, we build and evaluate an LLM-based privacy policy assessment browser extension, which helps users understand the essence of a lengthy, complex privacy policy while browsing.","The tool integrates a dashboard and an LLM chat.","In our qualitative user study (N=22), we evaluate usability, understandability of the information our tool provides, and its impacts on awareness.","While providing a comprehensible quick overview and a chat for in-depth discussion improves privacy awareness, users note issues with building trust in the tool.","From our insights, we derive important design implications to guide future policy analysis tools."],"url":"http://arxiv.org/abs/2503.03587v1"}
{"created":"2025-03-05 15:22:24","title":"Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories","abstract":"Large Language Models (LLMs) have shown promise in software vulnerability detection, particularly on function-level benchmarks like Devign and BigVul. However, real-world detection requires interprocedural analysis, as vulnerabilities often emerge through multi-hop function calls rather than isolated functions. While repository-level benchmarks like ReposVul and VulEval introduce interprocedural context, they remain computationally expensive, lack pairwise evaluation of vulnerability fixes, and explore limited context retrieval, limiting their practicality.   We introduce JitVul, a JIT vulnerability detection benchmark linking each function to its vulnerability-introducing and fixing commits. Built from 879 CVEs spanning 91 vulnerability types, JitVul enables comprehensive evaluation of detection capabilities. Our results show that ReAct Agents, leveraging thought-action-observation and interprocedural context, perform better than LLMs in distinguishing vulnerable from benign code. While prompting strategies like Chain-of-Thought help LLMs, ReAct Agents require further refinement. Both methods show inconsistencies, either misidentifying vulnerabilities or over-analyzing security guards, indicating significant room for improvement.","sentences":["Large Language Models (LLMs) have shown promise in software vulnerability detection, particularly on function-level benchmarks like Devign and BigVul.","However, real-world detection requires interprocedural analysis, as vulnerabilities often emerge through multi-hop function calls rather than isolated functions.","While repository-level benchmarks like ReposVul and VulEval introduce interprocedural context, they remain computationally expensive, lack pairwise evaluation of vulnerability fixes, and explore limited context retrieval, limiting their practicality.   ","We introduce JitVul, a JIT vulnerability detection benchmark linking each function to its vulnerability-introducing and fixing commits.","Built from 879 CVEs spanning 91 vulnerability types, JitVul enables comprehensive evaluation of detection capabilities.","Our results show that ReAct Agents, leveraging thought-action-observation and interprocedural context, perform better than LLMs in distinguishing vulnerable from benign code.","While prompting strategies like Chain-of-Thought help LLMs, ReAct Agents require further refinement.","Both methods show inconsistencies, either misidentifying vulnerabilities or over-analyzing security guards, indicating significant room for improvement."],"url":"http://arxiv.org/abs/2503.03586v1"}
{"created":"2025-03-05 15:17:18","title":"Scaling Crowdsourced Election Monitoring: Construction and Evaluation of Classification Models for Multilingual and Cross-Domain Classification Settings","abstract":"The adoption of crowdsourced election monitoring as a complementary alternative to traditional election monitoring is on the rise. Yet, its reliance on digital response volunteers to manually process incoming election reports poses a significant scaling bottleneck. In this paper, we address the challenge of scaling crowdsourced election monitoring by advancing the task of automated classification of crowdsourced election reports to multilingual and cross-domain classification settings. We propose a two-step classification approach of first identifying informative reports and then categorising them into distinct information types. We conduct classification experiments using multilingual transformer models such as XLM-RoBERTa and multilingual embeddings such as SBERT, augmented with linguistically motivated features. Our approach achieves F1-Scores of 77\\% for informativeness detection and 75\\% for information type classification. We conduct cross-domain experiments, applying models trained in a source electoral domain to a new target electoral domain in zero-shot and few-shot classification settings. Our results show promising potential for model transfer across electoral domains, with F1-Scores of 59\\% in zero-shot and 63\\% in few-shot settings. However, our analysis also reveals a performance bias in detecting informative English reports over Swahili, likely due to imbalances in the training data, indicating a need for caution when deploying classification models in real-world election scenarios.","sentences":["The adoption of crowdsourced election monitoring as a complementary alternative to traditional election monitoring is on the rise.","Yet, its reliance on digital response volunteers to manually process incoming election reports poses a significant scaling bottleneck.","In this paper, we address the challenge of scaling crowdsourced election monitoring by advancing the task of automated classification of crowdsourced election reports to multilingual and cross-domain classification settings.","We propose a two-step classification approach of first identifying informative reports and then categorising them into distinct information types.","We conduct classification experiments using multilingual transformer models such as XLM-RoBERTa and multilingual embeddings such as SBERT, augmented with linguistically motivated features.","Our approach achieves F1-Scores of 77\\% for informativeness detection and 75\\% for information type classification.","We conduct cross-domain experiments, applying models trained in a source electoral domain to a new target electoral domain in zero-shot and few-shot classification settings.","Our results show promising potential for model transfer across electoral domains, with F1-Scores of 59\\% in zero-shot and 63\\% in few-shot settings.","However, our analysis also reveals a performance bias in detecting informative English reports over Swahili, likely due to imbalances in the training data, indicating a need for caution when deploying classification models in real-world election scenarios."],"url":"http://arxiv.org/abs/2503.03582v1"}
{"created":"2025-03-05 15:13:54","title":"A Generative System for Robot-to-Human Handovers: from Intent Inference to Spatial Configuration Imagery","abstract":"We propose a novel system for robot-to-human object handover that emulates human coworker interactions. Unlike most existing studies that focus primarily on grasping strategies and motion planning, our system focus on 1. inferring human handover intents, 2. imagining spatial handover configuration. The first one integrates multimodal perception-combining visual and verbal cues-to infer human intent. The second one using a diffusion-based model to generate the handover configuration, involving the spacial relationship among robot's gripper, the object, and the human hand, thereby mimicking the cognitive process of motor imagery. Experimental results demonstrate that our approach effectively interprets human cues and achieves fluent, human-like handovers, offering a promising solution for collaborative robotics. Code, videos, and data are available at: https://i3handover.github.io.","sentences":["We propose a novel system for robot-to-human object handover that emulates human coworker interactions.","Unlike most existing studies that focus primarily on grasping strategies and motion planning, our system focus on 1.","inferring human handover intents, 2.","imagining spatial handover configuration.","The first one integrates multimodal perception-combining visual and verbal cues-to infer human intent.","The second one using a diffusion-based model to generate the handover configuration, involving the spacial relationship among robot's gripper, the object, and the human hand, thereby mimicking the cognitive process of motor imagery.","Experimental results demonstrate that our approach effectively interprets human cues and achieves fluent, human-like handovers, offering a promising solution for collaborative robotics.","Code, videos, and data are available at: https://i3handover.github.io."],"url":"http://arxiv.org/abs/2503.03579v1"}
{"created":"2025-03-05 15:02:58","title":"Saturated Drawings of Geometric Thickness k","abstract":"We investigate saturated geometric drawings of graphs with geometric thickness $k$, where no edge can be added without increasing $k$. We establish lower and upper bounds on the number of edges in such drawings if the vertices lie in convex position. We also study the more restricted version where edges are precolored, and for $k=2$ the case for vertices in non-convex position.","sentences":["We investigate saturated geometric drawings of graphs with geometric thickness $k$, where no edge can be added without increasing $k$. We establish lower and upper bounds on the number of edges in such drawings if the vertices lie in convex position.","We also study the more restricted version where edges are precolored, and for $k=2$ the case for vertices in non-convex position."],"url":"http://arxiv.org/abs/2503.03577v1"}
{"created":"2025-03-05 15:02:46","title":"Optimal Decision Tree Pruning Revisited: Algorithms and Complexity","abstract":"We present a comprehensive classical and parameterized complexity analysis of decision tree pruning operations, extending recent research on the complexity of learning small decision trees. Thereby, we offer new insights into the computational challenges of decision tree simplification, a crucial aspect of developing interpretable and efficient machine learning models. We focus on fundamental pruning operations of subtree replacement and raising, which are used in heuristics. Surprisingly, while optimal pruning can be performed in polynomial time for subtree replacement, the problem is NP-complete for subtree raising. Therefore, we identify parameters and combinations thereof that lead to fixed-parameter tractability or hardness, establishing a precise borderline between these complexity classes. For example, while subtree raising is hard for small domain size $D$ or number $d$ of features, it can be solved in $D^{2d} \\cdot |I|^{O(1)}$ time, where $|I|$ is the input size. We complement our theoretical findings with preliminary experimental results, demonstrating the practical implications of our analysis.","sentences":["We present a comprehensive classical and parameterized complexity analysis of decision tree pruning operations, extending recent research on the complexity of learning small decision trees.","Thereby, we offer new insights into the computational challenges of decision tree simplification, a crucial aspect of developing interpretable and efficient machine learning models.","We focus on fundamental pruning operations of subtree replacement and raising, which are used in heuristics.","Surprisingly, while optimal pruning can be performed in polynomial time for subtree replacement, the problem is NP-complete for subtree raising.","Therefore, we identify parameters and combinations thereof that lead to fixed-parameter tractability or hardness, establishing a precise borderline between these complexity classes.","For example, while subtree raising is hard for small domain size $D$ or number $d$ of features, it can be solved in $D^{2d} \\cdot |I|^{O(1)}$ time, where $|I|$ is the input size.","We complement our theoretical findings with preliminary experimental results, demonstrating the practical implications of our analysis."],"url":"http://arxiv.org/abs/2503.03576v1"}
{"created":"2025-03-05 15:01:56","title":"Olympus: A Jumping Quadruped for Planetary Exploration Utilizing Reinforcement Learning for In-Flight Attitude Control","abstract":"Exploring planetary bodies with lower gravity, such as the moon and Mars, allows legged robots to utilize jumping as an efficient form of locomotion thus giving them a valuable advantage over traditional rovers for exploration. Motivated by this fact, this paper presents the design, simulation, and learning-based \"in-flight\" attitude control of Olympus, a jumping legged robot tailored to the gravity of Mars. First, the design requirements are outlined followed by detailing how simulation enabled optimizing the robot's design - from its legs to the overall configuration - towards high vertical jumping, forward jumping distance, and in-flight attitude reorientation. Subsequently, the reinforcement learning policy used to track desired in-flight attitude maneuvers is presented. Successfully crossing the sim2real gap, extensive experimental studies of attitude reorientation tests are demonstrated.","sentences":["Exploring planetary bodies with lower gravity, such as the moon and Mars, allows legged robots to utilize jumping as an efficient form of locomotion thus giving them a valuable advantage over traditional rovers for exploration.","Motivated by this fact, this paper presents the design, simulation, and learning-based \"in-flight\" attitude control of Olympus, a jumping legged robot tailored to the gravity of Mars.","First, the design requirements are outlined followed by detailing how simulation enabled optimizing the robot's design - from its legs to the overall configuration - towards high vertical jumping, forward jumping distance, and in-flight attitude reorientation.","Subsequently, the reinforcement learning policy used to track desired in-flight attitude maneuvers is presented.","Successfully crossing the sim2real gap, extensive experimental studies of attitude reorientation tests are demonstrated."],"url":"http://arxiv.org/abs/2503.03574v1"}
{"created":"2025-03-05 15:00:39","title":"Domain Consistent Industrial Decarbonisation of Global Coal Power Plants","abstract":"Machine learning and optimisation techniques (MLOPT) hold significant potential to accelerate the decarbonisation of industrial systems by enabling data-driven operational improvements. However, the practical application of MLOPT in industrial settings is often hindered by a lack of domain compliance and system-specific consistency, resulting in suboptimal solutions with limited real-world applicability. To address this challenge, we propose a novel human-in-the-loop (HITL) constraint-based optimisation framework that integrates domain expertise with data-driven methods, ensuring solutions are both technically sound and operationally feasible. We demonstrate the efficacy of this framework through a case study focused on enhancing the thermal efficiency and reducing the turbine heat rate of a 660 MW supercritical coal-fired power plant. By embedding domain knowledge as constraints within the optimisation process, our approach yields solutions that align with the plant's operational patterns and are seamlessly integrated into its control systems. Empirical validation confirms a mean improvement in thermal efficiency of 0.64\\% and a mean reduction in turbine heat rate of 93 kJ/kWh. Scaling our analysis to 59 global coal power plants with comparable capacity and fuel type, we estimate a cumulative lifetime reduction of 156.4 million tons of carbon emissions. These results underscore the transformative potential of our HITL-MLOPT framework in delivering domain-compliant, implementable solutions for industrial decarbonisation, offering a scalable pathway to mitigate the environmental impact of coal-based power generation worldwide.","sentences":["Machine learning and optimisation techniques (MLOPT) hold significant potential to accelerate the decarbonisation of industrial systems by enabling data-driven operational improvements.","However, the practical application of MLOPT in industrial settings is often hindered by a lack of domain compliance and system-specific consistency, resulting in suboptimal solutions with limited real-world applicability.","To address this challenge, we propose a novel human-in-the-loop (HITL) constraint-based optimisation framework that integrates domain expertise with data-driven methods, ensuring solutions are both technically sound and operationally feasible.","We demonstrate the efficacy of this framework through a case study focused on enhancing the thermal efficiency and reducing the turbine heat rate of a 660 MW supercritical coal-fired power plant.","By embedding domain knowledge as constraints within the optimisation process, our approach yields solutions that align with the plant's operational patterns and are seamlessly integrated into its control systems.","Empirical validation confirms a mean improvement in thermal efficiency of 0.64\\% and a mean reduction in turbine heat rate of 93 kJ/kWh.","Scaling our analysis to 59 global coal power plants with comparable capacity and fuel type, we estimate a cumulative lifetime reduction of 156.4 million tons of carbon emissions.","These results underscore the transformative potential of our HITL-MLOPT framework in delivering domain-compliant, implementable solutions for industrial decarbonisation, offering a scalable pathway to mitigate the environmental impact of coal-based power generation worldwide."],"url":"http://arxiv.org/abs/2503.03571v1"}
{"created":"2025-03-05 14:58:53","title":"Towards an Emotion-Aware Metaverse: A Human-Centric Shipboard Fire Drill Simulator","abstract":"Traditional XR and Metaverse applications prioritize user experience (UX) for adoption and success but often overlook a crucial aspect of user interaction: emotions. This article addresses this gap by presenting an emotion-aware Metaverse application: a Virtual Reality (VR) fire drill simulator designed to prepare crews for shipboard emergencies. The simulator detects emotions in real time, assessing trainees responses under stress to improve learning outcomes. Its architecture incorporates eye-tracking and facial expression analysis via Meta Quest Pro headsets. The system features four levels whose difficulty is increased progressively to evaluate user decision-making and emotional resilience. The system was evaluated in two experimental phases. The first phase identified challenges, such as navigation issues and lack of visual guidance. These insights led to an improved second version with a better user interface, visual cues and a real-time task tracker. Performance metrics like completion times, task efficiency and emotional responses were analyzed. The obtained results show that trainees with prior VR or gaming experience navigated the scenarios more efficiently. Moreover, the addition of task-tracking visuals and navigation guidance significantly improved user performance, reducing task completion times between 14.18\\% and 32.72\\%. Emotional responses were captured, revealing that some participants were engaged, while others acted indifferently, indicating the need for more immersive elements. Overall, this article provides useful guidelines for creating the next generation of emotion-aware Metaverse applications.","sentences":["Traditional XR and Metaverse applications prioritize user experience (UX) for adoption and success but often overlook a crucial aspect of user interaction: emotions.","This article addresses this gap by presenting an emotion-aware Metaverse application: a Virtual Reality (VR) fire drill simulator designed to prepare crews for shipboard emergencies.","The simulator detects emotions in real time, assessing trainees responses under stress to improve learning outcomes.","Its architecture incorporates eye-tracking and facial expression analysis via Meta Quest Pro headsets.","The system features four levels whose difficulty is increased progressively to evaluate user decision-making and emotional resilience.","The system was evaluated in two experimental phases.","The first phase identified challenges, such as navigation issues and lack of visual guidance.","These insights led to an improved second version with a better user interface, visual cues and a real-time task tracker.","Performance metrics like completion times, task efficiency and emotional responses were analyzed.","The obtained results show that trainees with prior VR or gaming experience navigated the scenarios more efficiently.","Moreover, the addition of task-tracking visuals and navigation guidance significantly improved user performance, reducing task completion times between 14.18\\% and 32.72\\%.","Emotional responses were captured, revealing that some participants were engaged, while others acted indifferently, indicating the need for more immersive elements.","Overall, this article provides useful guidelines for creating the next generation of emotion-aware Metaverse applications."],"url":"http://arxiv.org/abs/2503.03570v1"}
{"created":"2025-03-05 14:56:39","title":"Novel Complexity Results for Temporal Separators with Deadlines","abstract":"We consider two variants, (s,z,l)-Temporal Separator and (s,z,l)-Temporal Cut, respectively, of the vertex separator and the edge cut problem in temporal graphs. The goal is to remove the minimum number of vertices (temporal edges, respectively) in order to delete all the temporal paths that have time travel at most l between a source vertex s and target vertex z. First, we solve an open problem in the literature showing that (s,z,l)-Temporal Separator is NP-complete even when the underlying graph has pathwidth bounded by four. We complement this result showing that (s,z,l)-Temporal Separator can be solved in polynomial time for graphs of pathwidth bounded by three. Then we consider the approximability of (s,z,l)-Temporal Separator and we show that it cannot be approximated within factor$2^{\\Omega(\\log^{1-\\varepsilon}|V|)}$ for any constant $\\varepsilon> 0$, unless $NP \\subseteq ZPP$ (V is the vertex set of the input temporal graph) and that the strict version is approximable within factor l - 1 (we show also that it is unliklely that this factor can be improved). Then we consider the (s,z,l)-Temporal Cut problem, we show that it is APX-hard and we present a $2 \\log_2(2\\ell)$ approximation algorithm.","sentences":["We consider two variants, (s,z,l)-Temporal Separator and (s,z,l)-Temporal Cut, respectively, of the vertex separator and the edge cut problem in temporal graphs.","The goal is to remove the minimum number of vertices (temporal edges, respectively) in order to delete all the temporal paths that have time travel at most l between a source vertex s and target vertex z.","First, we solve an open problem in the literature showing that (s,z,l)-Temporal Separator is NP-complete even when the underlying graph has pathwidth bounded by four.","We complement this result showing that (s,z,l)-Temporal Separator can be solved in polynomial time for graphs of pathwidth bounded by three.","Then we consider the approximability of (s,z,l)-Temporal Separator and we show that it cannot be approximated within factor$2^{\\Omega(\\log^{1-\\varepsilon}|V|)}$ for any constant $\\varepsilon> 0$, unless $NP \\subseteq ZPP$ (V is the vertex set of the input temporal graph) and that the strict version is approximable within factor l - 1 (we show also that it is unliklely that this factor can be improved).","Then we consider the (s,z,l)-Temporal Cut problem, we show that it is APX-hard and we present a $2 \\log_2(2\\ell)$ approximation algorithm."],"url":"http://arxiv.org/abs/2503.03568v1"}
{"created":"2025-03-05 14:51:46","title":"A Conceptual Model for Attributions in Event-Centric Knowledge Graphs","abstract":"The use of narratives as a means of fusing information from knowledge graphs (KGs) into a coherent line of argumentation has been the subject of recent investigation. Narratives are especially useful in event-centric knowledge graphs in that they provide a means to connect different real-world events and categorize them by well-known narrations. However, specifically for controversial events, a problem in information fusion arises, namely, multiple viewpoints regarding the validity of certain event aspects, e.g., regarding the role a participant takes in an event, may exist. Expressing those viewpoints in KGs is challenging because disputed information provided by different viewpoints may introduce inconsistencies. Hence, most KGs only feature a single view on the contained information, hampering the effectiveness of narrative information access. This paper is an extension of our original work and introduces attributions, i.e., parameterized predicates that allow for the representation of facts that are only valid in a specific viewpoint. For this, we develop a conceptual model that allows for the representation of viewpoint-dependent information. As an extension, we enhance the model by a conception of viewpoint-compatibility. Based on this, we deepen our original deliberations on the model's effects on information fusion and provide additional grounding in the literature.","sentences":["The use of narratives as a means of fusing information from knowledge graphs (KGs) into a coherent line of argumentation has been the subject of recent investigation.","Narratives are especially useful in event-centric knowledge graphs in that they provide a means to connect different real-world events and categorize them by well-known narrations.","However, specifically for controversial events, a problem in information fusion arises, namely, multiple viewpoints regarding the validity of certain event aspects, e.g., regarding the role a participant takes in an event, may exist.","Expressing those viewpoints in KGs is challenging because disputed information provided by different viewpoints may introduce inconsistencies.","Hence, most KGs only feature a single view on the contained information, hampering the effectiveness of narrative information access.","This paper is an extension of our original work and introduces attributions, i.e., parameterized predicates that allow for the representation of facts that are only valid in a specific viewpoint.","For this, we develop a conceptual model that allows for the representation of viewpoint-dependent information.","As an extension, we enhance the model by a conception of viewpoint-compatibility.","Based on this, we deepen our original deliberations on the model's effects on information fusion and provide additional grounding in the literature."],"url":"http://arxiv.org/abs/2503.03563v1"}
{"created":"2025-03-05 14:49:08","title":"Towards Visual Discrimination and Reasoning of Real-World Physical Dynamics: Physics-Grounded Anomaly Detection","abstract":"Humans detect real-world object anomalies by perceiving, interacting, and reasoning based on object-conditioned physical knowledge. The long-term goal of Industrial Anomaly Detection (IAD) is to enable machines to autonomously replicate this skill. However, current IAD algorithms are largely developed and tested on static, semantically simple datasets, which diverge from real-world scenarios where physical understanding and reasoning are essential.To bridge this gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the first large-scale, real-world, physics-grounded video dataset for industrial anomaly detection. Collected using a real robot arm and motor, Phys-AD provides a diverse set of dynamic, semantically rich scenarios. The dataset includes more than 6400 videos across 22 real-world object categories, interacting with robot arms and motors, and exhibits 47 types of anomalies. Anomaly detection in Phys-AD requires visual reasoning, combining both physical knowledge and video content to determine object abnormality.We benchmark state-of-the-art anomaly detection methods under three settings: unsupervised AD, weakly-supervised AD, and video-understanding AD, highlighting their limitations in handling physics-grounded anomalies. Additionally, we introduce the Physics Anomaly Explanation (PAEval) metric, designed to assess the ability of visual-language foundation models to not only detect anomalies but also provide accurate explanations for their underlying physical causes. Our dataset and benchmark will be publicly available.","sentences":["Humans detect real-world object anomalies by perceiving, interacting, and reasoning based on object-conditioned physical knowledge.","The long-term goal of Industrial Anomaly Detection (IAD) is to enable machines to autonomously replicate this skill.","However, current IAD algorithms are largely developed and tested on static, semantically simple datasets, which diverge from real-world scenarios where physical understanding and reasoning are essential.","To bridge this gap, we introduce the Physics Anomaly Detection (Phys-AD) dataset, the first large-scale, real-world, physics-grounded video dataset for industrial anomaly detection.","Collected using a real robot arm and motor, Phys-AD provides a diverse set of dynamic, semantically rich scenarios.","The dataset includes more than 6400 videos across 22 real-world object categories, interacting with robot arms and motors, and exhibits 47 types of anomalies.","Anomaly detection in Phys-AD requires visual reasoning, combining both physical knowledge and video content to determine object abnormality.","We benchmark state-of-the-art anomaly detection methods under three settings: unsupervised AD, weakly-supervised AD, and video-understanding AD, highlighting their limitations in handling physics-grounded anomalies.","Additionally, we introduce the Physics Anomaly Explanation (PAEval) metric, designed to assess the ability of visual-language foundation models to not only detect anomalies but also provide accurate explanations for their underlying physical causes.","Our dataset and benchmark will be publicly available."],"url":"http://arxiv.org/abs/2503.03562v1"}
{"created":"2025-03-05 14:46:33","title":"Optimal Beamforming for Multi-Target Multi-User ISAC Exploiting Prior Information: How Many Sensing Beams Are Needed?","abstract":"This paper studies a multi-target multi-user integrated sensing and communication (ISAC) system where a multi-antenna base station (BS) communicates with multiple single-antenna users in the downlink and senses the unknown and random angle information of multiple targets based on their reflected echo signals at the BS receiver as well as their prior probability information. We focus on a general beamforming structure with both communication beams and dedicated sensing beams, whose design is highly non-trivial as more sensing beams provide more flexibility in sensing, but introduce extra interference to communication. To resolve this trade-off, we first characterize the periodic posterior Cram\\'er-Rao bound (PCRB) as a lower bound of the mean-cyclic error (MCE) in multi-target sensing. Then, we optimize the beamforming to minimize the maximum periodic PCRB among all targets to ensure fairness, subject to individual communication rate constraints at multiple users. Despite the non-convexity of this problem, we propose a general construction method for the optimal solution by leveraging semi-definite relaxation (SDR), and derive a general bound on the number of sensing beams needed. Moreover, we unveil specific structures of the optimal solution in various cases, where tighter bounds on the number of sensing beams needed are derived (e.g., no or at most one sensing beam is needed under stringent rate constraints or with homogeneous targets). Next, we study the beamforming optimization to minimize the sum periodic PCRB under user rate constraints. By applying SDR, we propose a general construction method for the optimal solution and its specific structures which yield lower computational complexities. We derive a general bound and various tighter bounds on the number of sensing beams needed. Numerical results validate our analysis and effectiveness of our proposed beamforming designs.","sentences":["This paper studies a multi-target multi-user integrated sensing and communication (ISAC) system where a multi-antenna base station (BS) communicates with multiple single-antenna users in the downlink and senses the unknown and random angle information of multiple targets based on their reflected echo signals at the BS receiver as well as their prior probability information.","We focus on a general beamforming structure with both communication beams and dedicated sensing beams, whose design is highly non-trivial as more sensing beams provide more flexibility in sensing, but introduce extra interference to communication.","To resolve this trade-off, we first characterize the periodic posterior Cram\\'er-Rao bound (PCRB) as a lower bound of the mean-cyclic error (MCE) in multi-target sensing.","Then, we optimize the beamforming to minimize the maximum periodic PCRB among all targets to ensure fairness, subject to individual communication rate constraints at multiple users.","Despite the non-convexity of this problem, we propose a general construction method for the optimal solution by leveraging semi-definite relaxation (SDR), and derive a general bound on the number of sensing beams needed.","Moreover, we unveil specific structures of the optimal solution in various cases, where tighter bounds on the number of sensing beams needed are derived (e.g., no or at most one sensing beam is needed under stringent rate constraints or with homogeneous targets).","Next, we study the beamforming optimization to minimize the sum periodic PCRB under user rate constraints.","By applying SDR, we propose a general construction method for the optimal solution and its specific structures which yield lower computational complexities.","We derive a general bound and various tighter bounds on the number of sensing beams needed.","Numerical results validate our analysis and effectiveness of our proposed beamforming designs."],"url":"http://arxiv.org/abs/2503.03560v1"}
{"created":"2025-03-05 14:45:32","title":"High-Quality Virtual Single-Viewpoint Surgical Video: Geometric Autocalibration of Multiple Cameras in Surgical Lights","abstract":"Occlusion-free video generation is challenging due to surgeons' obstructions in the camera field of view. Prior work has addressed this issue by installing multiple cameras on a surgical light, hoping some cameras will observe the surgical field with less occlusion. However, this special camera setup poses a new imaging challenge since camera configurations can change every time surgeons move the light, and manual image alignment is required. This paper proposes an algorithm to automate this alignment task. The proposed method detects frames where the lighting system moves, realigns them, and selects the camera with the least occlusion. This algorithm results in a stabilized video with less occlusion. Quantitative results show that our method outperforms conventional approaches. A user study involving medical doctors also confirmed the superiority of our method.","sentences":["Occlusion-free video generation is challenging due to surgeons' obstructions in the camera field of view.","Prior work has addressed this issue by installing multiple cameras on a surgical light, hoping some cameras will observe the surgical field with less occlusion.","However, this special camera setup poses a new imaging challenge since camera configurations can change every time surgeons move the light, and manual image alignment is required.","This paper proposes an algorithm to automate this alignment task.","The proposed method detects frames where the lighting system moves, realigns them, and selects the camera with the least occlusion.","This algorithm results in a stabilized video with less occlusion.","Quantitative results show that our method outperforms conventional approaches.","A user study involving medical doctors also confirmed the superiority of our method."],"url":"http://arxiv.org/abs/2503.03558v1"}
{"created":"2025-03-05 14:44:53","title":"Afford-X: Generalizable and Slim Affordance Reasoning for Task-oriented Manipulation","abstract":"Object affordance reasoning, the ability to infer object functionalities based on physical properties, is fundamental for task-oriented planning and activities in both humans and Artificial Intelligence (AI). This capability, required for planning and executing daily activities in a task-oriented manner, relies on commonsense knowledge of object physics and functionalities, extending beyond simple object recognition. Current computational models for affordance reasoning from perception lack generalizability, limiting their applicability in novel scenarios. Meanwhile, comprehensive Large Language Models (LLMs) with emerging reasoning capabilities are challenging to deploy on local devices for task-oriented manipulations. Here, we introduce LVIS-Aff, a large-scale dataset comprising 1,496 tasks and 119k images, designed to enhance the generalizability of affordance reasoning from perception. Utilizing this dataset, we develop Afford-X, an end-to-end trainable affordance reasoning model that incorporates Verb Attention and Bi-Fusion modules to improve multi-modal understanding. This model achieves up to a 12.1% performance improvement over the best-reported results from non-LLM methods, while also demonstrating a 1.2% enhancement compared to our previous conference paper. Additionally, it maintains a compact 187M parameter size and infers nearly 50 times faster than the GPT-4V API. Our work demonstrates the potential for efficient, generalizable affordance reasoning models that can be deployed on local devices for task-oriented manipulations. We showcase Afford-X's effectiveness in enabling task-oriented manipulations for robots across various tasks and environments, underscoring its efficiency and broad implications for advancing robotics and AI systems in real-world applications.","sentences":["Object affordance reasoning, the ability to infer object functionalities based on physical properties, is fundamental for task-oriented planning and activities in both humans and Artificial Intelligence (AI).","This capability, required for planning and executing daily activities in a task-oriented manner, relies on commonsense knowledge of object physics and functionalities, extending beyond simple object recognition.","Current computational models for affordance reasoning from perception lack generalizability, limiting their applicability in novel scenarios.","Meanwhile, comprehensive Large Language Models (LLMs) with emerging reasoning capabilities are challenging to deploy on local devices for task-oriented manipulations.","Here, we introduce LVIS-Aff, a large-scale dataset comprising 1,496 tasks and 119k images, designed to enhance the generalizability of affordance reasoning from perception.","Utilizing this dataset, we develop Afford-X, an end-to-end trainable affordance reasoning model that incorporates Verb Attention and Bi-Fusion modules to improve multi-modal understanding.","This model achieves up to a 12.1% performance improvement over the best-reported results from non-LLM methods, while also demonstrating a 1.2% enhancement compared to our previous conference paper.","Additionally, it maintains a compact 187M parameter size and infers nearly 50 times faster than the GPT-4V API.","Our work demonstrates the potential for efficient, generalizable affordance reasoning models that can be deployed on local devices for task-oriented manipulations.","We showcase Afford-X's effectiveness in enabling task-oriented manipulations for robots across various tasks and environments, underscoring its efficiency and broad implications for advancing robotics and AI systems in real-world applications."],"url":"http://arxiv.org/abs/2503.03556v1"}
{"created":"2025-03-05 14:41:59","title":"A Graph Width Perspective on Partially Ordered Hamiltonian Paths","abstract":"We consider the problem of finding a Hamiltonian path with precedence constraints in the form of a partial order on the vertex set. This problem is known as Partially Ordered Hamiltonian Path Problem (POHPP). Here, we study the complexity for graph width parameters for which the ordinary Hamiltonian Path problem is in $\\mathsf{FPT}$. We show that POHPP is $\\mathsf{NP}$-complete for graphs of pathwidth 4. We complement this result by giving polynomial-time algorithms for graphs of pathwidth 3 and treewidth 2. Furthermore, we show that POHPP is $\\mathsf{NP}$-hard for graphs of clique cover number 2 and $\\mathsf{W[1]}$-hard for some distance-to-$\\mathcal{G}$ parameters, including distance to path and distance to clique. In addition, we present $\\mathsf{XP}$ and $\\mathsf{FPT}$ algorithms for parameters such as distance to block and feedback edge set number.","sentences":["We consider the problem of finding a Hamiltonian path with precedence constraints in the form of a partial order on the vertex set.","This problem is known as Partially Ordered Hamiltonian Path Problem (POHPP).","Here, we study the complexity for graph width parameters for which the ordinary Hamiltonian Path problem is in $\\mathsf{FPT}$. We show that POHPP is $\\mathsf{NP}$-complete for graphs of pathwidth 4.","We complement this result by giving polynomial-time algorithms for graphs of pathwidth 3 and treewidth 2.","Furthermore, we show that POHPP is $\\mathsf{NP}$-hard for graphs of clique cover number 2 and $\\mathsf{W[1]}$-hard for some distance-to-$\\mathcal{G}$ parameters, including distance to path and distance to clique.","In addition, we present $\\mathsf{XP}$ and $\\mathsf{FPT}$ algorithms for parameters such as distance to block and feedback edge set number."],"url":"http://arxiv.org/abs/2503.03553v1"}
{"created":"2025-03-05 14:32:32","title":"Simulation-Based Performance Evaluation of 3D Object Detection Methods with Deep Learning for a LiDAR Point Cloud Dataset in a SOTIF-related Use Case","abstract":"Safety of the Intended Functionality (SOTIF) addresses sensor performance limitations and deep learning-based object detection insufficiencies to ensure the intended functionality of Automated Driving Systems (ADS). This paper presents a methodology examining the adaptability and performance evaluation of the 3D object detection methods on a LiDAR point cloud dataset generated by simulating a SOTIF-related Use Case. The major contributions of this paper include defining and modelling a SOTIF-related Use Case with 21 diverse weather conditions and generating a LiDAR point cloud dataset suitable for application of 3D object detection methods. The dataset consists of 547 frames, encompassing clear, cloudy, rainy weather conditions, corresponding to different times of the day, including noon, sunset, and night. Employing MMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art (SOTA) 3D object detection methods is evaluated and compared by testing the pre-trained Deep Learning (DL) models on the generated dataset using Average Precision (AP) and Recall metrics.","sentences":["Safety of the Intended Functionality (SOTIF) addresses sensor performance limitations and deep learning-based object detection insufficiencies to ensure the intended functionality of Automated Driving Systems (ADS).","This paper presents a methodology examining the adaptability and performance evaluation of the 3D object detection methods on a LiDAR point cloud dataset generated by simulating a SOTIF-related Use Case.","The major contributions of this paper include defining and modelling a SOTIF-related Use Case with 21 diverse weather conditions and generating a LiDAR point cloud dataset suitable for application of 3D object detection methods.","The dataset consists of 547 frames, encompassing clear, cloudy, rainy weather conditions, corresponding to different times of the day, including noon, sunset, and night.","Employing MMDetection3D and OpenPCDET toolkits, the performance of State-of-the-Art (SOTA) 3D object detection methods is evaluated and compared by testing the pre-trained Deep Learning (DL) models on the generated dataset using Average Precision (AP) and Recall metrics."],"url":"http://arxiv.org/abs/2503.03548v1"}
