{"created":"2025-03-10 16:13:47","title":"Force Aware Branch Manipulation To Assist Agricultural Tasks","abstract":"This study presents a methodology to safely manipulate branches to aid various agricultural tasks. Humans in a real agricultural environment often manipulate branches to perform agricultural tasks effectively, but current agricultural robots lack this capability. This proposed strategy to manipulate branches can aid in different precision agriculture tasks, such as fruit picking in dense foliage, pollinating flowers under occlusion, and moving overhanging vines and branches for navigation. The proposed method modifies RRT* to plan a path that satisfies the branch geometric constraints and obeys branch deformable characteristics. Re-planning is done to obtain a path that helps the robot exert force within a desired range so that branches are not damaged during manipulation. Experimentally, this method achieved a success rate of 78\\% across 50 trials, successfully moving a branch from different starting points to a target region.","sentences":["This study presents a methodology to safely manipulate branches to aid various agricultural tasks.","Humans in a real agricultural environment often manipulate branches to perform agricultural tasks effectively, but current agricultural robots lack this capability.","This proposed strategy to manipulate branches can aid in different precision agriculture tasks, such as fruit picking in dense foliage, pollinating flowers under occlusion, and moving overhanging vines and branches for navigation.","The proposed method modifies RRT* to plan a path that satisfies the branch geometric constraints and obeys branch deformable characteristics.","Re-planning is done to obtain a path that helps the robot exert force within a desired range so that branches are not damaged during manipulation.","Experimentally, this method achieved a success rate of 78\\% across 50 trials, successfully moving a branch from different starting points to a target region."],"url":"http://arxiv.org/abs/2503.07497v1"}
{"created":"2025-03-10 16:13:45","title":"Securing External Deeper-than-black-box GPAI Evaluations","abstract":"This paper examines the critical challenges and potential solutions for conducting secure and effective external evaluations of general-purpose AI (GPAI) models. With the exponential growth in size, capability, reach and accompanying risk of these models, ensuring accountability, safety, and public trust requires frameworks that go beyond traditional black-box methods. The discussion begins with an analysis of the need for deeper-than-black-box evaluations (Section I), emphasizing the importance of understanding model internals to uncover latent risks and ensure compliance with ethical and regulatory standards. Building on this foundation, Section II addresses the security considerations of remote evaluations, outlining the threat landscape, technical solutions, and safeguards necessary to protect both evaluators and proprietary model data. Finally, Section III synthesizes these insights into actionable recommendations and future directions, aiming to establish a robust, scalable, and transparent framework for external assessments in GPAI governance.","sentences":["This paper examines the critical challenges and potential solutions for conducting secure and effective external evaluations of general-purpose AI (GPAI) models.","With the exponential growth in size, capability, reach and accompanying risk of these models, ensuring accountability, safety, and public trust requires frameworks that go beyond traditional black-box methods.","The discussion begins with an analysis of the need for deeper-than-black-box evaluations (Section I), emphasizing the importance of understanding model internals to uncover latent risks and ensure compliance with ethical and regulatory standards.","Building on this foundation, Section II addresses the security considerations of remote evaluations, outlining the threat landscape, technical solutions, and safeguards necessary to protect both evaluators and proprietary model data.","Finally, Section III synthesizes these insights into actionable recommendations and future directions, aiming to establish a robust, scalable, and transparent framework for external assessments in GPAI governance."],"url":"http://arxiv.org/abs/2503.07496v1"}
{"created":"2025-03-10 16:12:50","title":"V2Flow: Unifying Visual Tokenization and Large Language Model Vocabularies for Autoregressive Image Generation","abstract":"We propose V2Flow, a novel tokenizer that produces discrete visual tokens capable of high-fidelity reconstruction, while ensuring structural and latent distribution alignment with the vocabulary space of large language models (LLMs). Leveraging this tight visual-vocabulary coupling, V2Flow enables autoregressive visual generation on top of existing LLMs. Our approach formulates visual tokenization as a flow-matching problem, aiming to learn a mapping from a standard normal prior to the continuous image distribution, conditioned on token sequences embedded within the LLMs vocabulary space. The effectiveness of V2Flow stems from two core designs. First, we propose a Visual Vocabulary resampler, which compresses visual data into compact token sequences, with each represented as a soft categorical distribution over LLM's vocabulary. This allows seamless integration of visual tokens into existing LLMs for autoregressive visual generation. Second, we present a masked autoregressive Rectified-Flow decoder, employing a masked transformer encoder-decoder to refine visual tokens into contextually enriched embeddings. These embeddings then condition a dedicated velocity field for precise reconstruction. Additionally, an autoregressive rectified-flow sampling strategy is incorporated, ensuring flexible sequence lengths while preserving competitive reconstruction quality. Extensive experiments show that V2Flow outperforms mainstream VQ-based tokenizers and facilitates autoregressive visual generation on top of existing. https://github.com/zhangguiwei610/V2Flow","sentences":["We propose V2Flow, a novel tokenizer that produces discrete visual tokens capable of high-fidelity reconstruction, while ensuring structural and latent distribution alignment with the vocabulary space of large language models (LLMs).","Leveraging this tight visual-vocabulary coupling, V2Flow enables autoregressive visual generation on top of existing LLMs.","Our approach formulates visual tokenization as a flow-matching problem, aiming to learn a mapping from a standard normal prior to the continuous image distribution, conditioned on token sequences embedded within the LLMs vocabulary space.","The effectiveness of V2Flow stems from two core designs.","First, we propose a Visual Vocabulary resampler, which compresses visual data into compact token sequences, with each represented as a soft categorical distribution over LLM's vocabulary.","This allows seamless integration of visual tokens into existing LLMs for autoregressive visual generation.","Second, we present a masked autoregressive Rectified-Flow decoder, employing a masked transformer encoder-decoder to refine visual tokens into contextually enriched embeddings.","These embeddings then condition a dedicated velocity field for precise reconstruction.","Additionally, an autoregressive rectified-flow sampling strategy is incorporated, ensuring flexible sequence lengths while preserving competitive reconstruction quality.","Extensive experiments show that V2Flow outperforms mainstream VQ-based tokenizers and facilitates autoregressive visual generation on top of existing.","https://github.com/zhangguiwei610/V2Flow"],"url":"http://arxiv.org/abs/2503.07493v1"}
{"created":"2025-03-10 16:12:13","title":"Blind-Wayfarer: A Minimalist, Probing-Driven Framework for Resilient Navigation in Perception-Degraded Environments","abstract":"Navigating autonomous robots through dense forests and rugged terrains is especially daunting when exteroceptive sensors -- such as cameras and LiDAR sensors -- fail under occlusions, low-light conditions, or sensor noise. We present Blind-Wayfarer, a probing-driven navigation framework inspired by maze-solving algorithms that relies primarily on a compass to robustly traverse complex, unstructured environments. In 1,000 simulated forest experiments, Blind-Wayfarer achieved a 99.7% success rate. In real-world tests in two distinct scenarios -- with rover platforms of different sizes -- our approach successfully escaped forest entrapments in all 20 trials. Remarkably, our framework also enabled a robot to escape a dense woodland, traveling from 45 m inside the forest to a paved pathway at its edge. These findings highlight the potential of probing-based methods for reliable navigation in challenging perception-degraded field conditions. Videos and code are available on our website https://sites.google.com/view/blind-wayfarer","sentences":["Navigating autonomous robots through dense forests and rugged terrains is especially daunting when exteroceptive sensors -- such as cameras and LiDAR sensors -- fail under occlusions, low-light conditions, or sensor noise.","We present Blind-Wayfarer, a probing-driven navigation framework inspired by maze-solving algorithms that relies primarily on a compass to robustly traverse complex, unstructured environments.","In 1,000 simulated forest experiments, Blind-Wayfarer achieved a 99.7% success rate.","In real-world tests in two distinct scenarios -- with rover platforms of different sizes -- our approach successfully escaped forest entrapments in all 20 trials.","Remarkably, our framework also enabled a robot to escape a dense woodland, traveling from 45 m inside the forest to a paved pathway at its edge.","These findings highlight the potential of probing-based methods for reliable navigation in challenging perception-degraded field conditions.","Videos and code are available on our website https://sites.google.com/view/blind-wayfarer"],"url":"http://arxiv.org/abs/2503.07492v1"}
{"created":"2025-03-10 16:08:47","title":"Destination Calculus: A Linear \u03bb-Calculus for Purely Functional Memory Writes","abstract":"Destination passing -- aka. out parameters -- is taking a parameter to fill rather than returning a result from a function. Due to its apparently imperative nature, destination passing has struggled to find its way to pure functional programming. In this paper, we present a pure functional calculus with destinations at its core. Our calculus subsumes all the similar systems, and can be used to reason about their correctness or extension. In addition, our calculus can express programs that were previously not known to be expressible in a pure language. This is guaranteed by a modal type system where modes are used to manage both linearity and scopes. Type safety of our core calculus was proved formally with the Coq proof assistant.","sentences":["Destination passing -- aka.","out parameters -- is taking a parameter to fill rather than returning a result from a function.","Due to its apparently imperative nature, destination passing has struggled to find its way to pure functional programming.","In this paper, we present a pure functional calculus with destinations at its core.","Our calculus subsumes all the similar systems, and can be used to reason about their correctness or extension.","In addition, our calculus can express programs that were previously not known to be expressible in a pure language.","This is guaranteed by a modal type system where modes are used to manage both linearity and scopes.","Type safety of our core calculus was proved formally with the Coq proof assistant."],"url":"http://arxiv.org/abs/2503.07489v1"}
