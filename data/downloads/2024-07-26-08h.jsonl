{"created":"2024-07-25 17:59:48","title":"Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis","abstract":"Assessing the robustness of multimodal models against adversarial examples is an important aspect for the safety of its users. We craft L0-norm perturbation attacks on the preprocessed input images. We launch them in a black-box setup against four multimodal models and two unimodal DNNs, considering both targeted and untargeted misclassification. Our attacks target less than 0.04% of perturbed image area and integrate different spatial positioning of perturbed pixels: sparse positioning and pixels arranged in different contiguous shapes (row, column, diagonal, and patch). To the best of our knowledge, we are the first to assess the robustness of three state-of-the-art multimodal models (ALIGN, AltCLIP, GroupViT) against different sparse and contiguous pixel distribution perturbations. The obtained results indicate that unimodal DNNs are more robust than multimodal models. Furthermore, models using CNN-based Image Encoder are more vulnerable than models with ViT - for untargeted attacks, we obtain a 99% success rate by perturbing less than 0.02% of the image area.","sentences":["Assessing the robustness of multimodal models against adversarial examples is an important aspect for the safety of its users.","We craft L0-norm perturbation attacks on the preprocessed input images.","We launch them in a black-box setup against four multimodal models and two unimodal DNNs, considering both targeted and untargeted misclassification.","Our attacks target less than 0.04% of perturbed image area and integrate different spatial positioning of perturbed pixels: sparse positioning and pixels arranged in different contiguous shapes (row, column, diagonal, and patch).","To the best of our knowledge, we are the first to assess the robustness of three state-of-the-art multimodal models (ALIGN, AltCLIP, GroupViT) against different sparse and contiguous pixel distribution perturbations.","The obtained results indicate that unimodal DNNs are more robust than multimodal models.","Furthermore, models using CNN-based Image Encoder are more vulnerable than models with ViT - for untargeted attacks, we obtain a 99% success rate by perturbing less than 0.02% of the image area."],"url":"http://arxiv.org/abs/2407.18251v1"}
{"created":"2024-07-25 17:59:31","title":"Trajectory-aligned Space-time Tokens for Few-shot Action Recognition","abstract":"We propose a simple yet effective approach for few-shot action recognition, emphasizing the disentanglement of motion and appearance representations. By harnessing recent progress in tracking, specifically point trajectories and self-supervised representation learning, we build trajectory-aligned tokens (TATs) that capture motion and appearance information. This approach significantly reduces the data requirements while retaining essential information. To process these representations, we use a Masked Space-time Transformer that effectively learns to aggregate information to facilitate few-shot action recognition. We demonstrate state-of-the-art results on few-shot action recognition across multiple datasets. Our project page is available at https://www.cs.umd.edu/~pulkit/tats","sentences":["We propose a simple yet effective approach for few-shot action recognition, emphasizing the disentanglement of motion and appearance representations.","By harnessing recent progress in tracking, specifically point trajectories and self-supervised representation learning, we build trajectory-aligned tokens (TATs) that capture motion and appearance information.","This approach significantly reduces the data requirements while retaining essential information.","To process these representations, we use a Masked Space-time Transformer that effectively learns to aggregate information to facilitate few-shot action recognition.","We demonstrate state-of-the-art results on few-shot action recognition across multiple datasets.","Our project page is available at https://www.cs.umd.edu/~pulkit/tats"],"url":"http://arxiv.org/abs/2407.18249v1"}
{"created":"2024-07-25 17:59:16","title":"Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning","abstract":"Effective training of language models (LMs) for mathematical reasoning tasks demands high-quality supervised fine-tuning data. Besides obtaining annotations from human experts, a common alternative is sampling from larger and more powerful LMs. However, this knowledge distillation approach can be costly and unstable, particularly when relying on closed-source, proprietary LMs like GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate that the reasoning abilities of small-scale LMs can be enhanced through self-training, a process where models learn from their own outputs. We also show that the conventional self-training can be further augmented by a preference learning algorithm called Direct Preference Optimization (DPO). By integrating DPO into self-training, we leverage preference data to guide LMs towards more accurate and diverse chain-of-thought reasoning. We evaluate our method across various mathematical reasoning tasks using different base models. Our experiments show that this approach not only improves LMs' reasoning performance but also offers a more cost-effective and scalable solution compared to relying on large proprietary LMs.","sentences":["Effective training of language models (LMs) for mathematical reasoning tasks demands high-quality supervised fine-tuning data.","Besides obtaining annotations from human experts, a common alternative is sampling from larger and more powerful LMs.","However, this knowledge distillation approach can be costly and unstable, particularly when relying on closed-source, proprietary LMs like GPT-4, whose behaviors are often unpredictable.","In this work, we demonstrate that the reasoning abilities of small-scale LMs can be enhanced through self-training, a process where models learn from their own outputs.","We also show that the conventional self-training can be further augmented by a preference learning algorithm called Direct Preference Optimization (DPO).","By integrating DPO into self-training, we leverage preference data to guide LMs towards more accurate and diverse chain-of-thought reasoning.","We evaluate our method across various mathematical reasoning tasks using different base models.","Our experiments show that this approach not only improves LMs' reasoning performance but also offers a more cost-effective and scalable solution compared to relying on large proprietary LMs."],"url":"http://arxiv.org/abs/2407.18248v1"}
{"created":"2024-07-25 17:59:13","title":"RegionDrag: Fast Region-Based Image Editing with Diffusion Models","abstract":"Point-drag-based image editing methods, like DragDiffusion, have attracted significant attention. However, point-drag-based approaches suffer from computational overhead and misinterpretation of user intentions due to the sparsity of point-based editing instructions. In this paper, we propose a region-based copy-and-paste dragging method, RegionDrag, to overcome these limitations. RegionDrag allows users to express their editing instructions in the form of handle and target regions, enabling more precise control and alleviating ambiguity. In addition, region-based operations complete editing in one iteration and are much faster than point-drag-based methods. We also incorporate the attention-swapping technique for enhanced stability during editing. To validate our approach, we extend existing point-drag-based datasets with region-based dragging instructions. Experimental results demonstrate that RegionDrag outperforms existing point-drag-based approaches in terms of speed, accuracy, and alignment with user intentions. Remarkably, RegionDrag completes the edit on an image with a resolution of 512x512 in less than 2 seconds, which is more than 100x faster than DragDiffusion, while achieving better performance. Project page: https://visual-ai.github.io/regiondrag.","sentences":["Point-drag-based image editing methods, like DragDiffusion, have attracted significant attention.","However, point-drag-based approaches suffer from computational overhead and misinterpretation of user intentions due to the sparsity of point-based editing instructions.","In this paper, we propose a region-based copy-and-paste dragging method, RegionDrag, to overcome these limitations.","RegionDrag allows users to express their editing instructions in the form of handle and target regions, enabling more precise control and alleviating ambiguity.","In addition, region-based operations complete editing in one iteration and are much faster than point-drag-based methods.","We also incorporate the attention-swapping technique for enhanced stability during editing.","To validate our approach, we extend existing point-drag-based datasets with region-based dragging instructions.","Experimental results demonstrate that RegionDrag outperforms existing point-drag-based approaches in terms of speed, accuracy, and alignment with user intentions.","Remarkably, RegionDrag completes the edit on an image with a resolution of 512x512 in less than 2 seconds, which is more than 100x faster than DragDiffusion, while achieving better performance.","Project page: https://visual-ai.github.io/regiondrag."],"url":"http://arxiv.org/abs/2407.18247v1"}
{"created":"2024-07-25 17:58:17","title":"VGGHeads: A Large-Scale Synthetic Dataset for 3D Human Heads","abstract":"Human head detection, keypoint estimation, and 3D head model fitting are important tasks with many applications. However, traditional real-world datasets often suffer from bias, privacy, and ethical concerns, and they have been recorded in laboratory environments, which makes it difficult for trained models to generalize. Here, we introduce VGGHeads -- a large scale synthetic dataset generated with diffusion models for human head detection and 3D mesh estimation. Our dataset comprises over 1 million high-resolution images, each annotated with detailed 3D head meshes, facial landmarks, and bounding boxes. Using this dataset we introduce a new model architecture capable of simultaneous heads detection and head meshes reconstruction from a single image in a single step. Through extensive experimental evaluations, we demonstrate that models trained on our synthetic data achieve strong performance on real images. Furthermore, the versatility of our dataset makes it applicable across a broad spectrum of tasks, offering a general and comprehensive representation of human heads. Additionally, we provide detailed information about the synthetic data generation pipeline, enabling it to be re-used for other tasks and domains.","sentences":["Human head detection, keypoint estimation, and 3D head model fitting are important tasks with many applications.","However, traditional real-world datasets often suffer from bias, privacy, and ethical concerns, and they have been recorded in laboratory environments, which makes it difficult for trained models to generalize.","Here, we introduce VGGHeads -- a large scale synthetic dataset generated with diffusion models for human head detection and 3D mesh estimation.","Our dataset comprises over 1 million high-resolution images, each annotated with detailed 3D head meshes, facial landmarks, and bounding boxes.","Using this dataset we introduce a new model architecture capable of simultaneous heads detection and head meshes reconstruction from a single image in a single step.","Through extensive experimental evaluations, we demonstrate that models trained on our synthetic data achieve strong performance on real images.","Furthermore, the versatility of our dataset makes it applicable across a broad spectrum of tasks, offering a general and comprehensive representation of human heads.","Additionally, we provide detailed information about the synthetic data generation pipeline, enabling it to be re-used for other tasks and domains."],"url":"http://arxiv.org/abs/2407.18245v1"}
{"created":"2024-07-25 17:58:03","title":"RefMask3D: Language-Guided Transformer for 3D Referring Segmentation","abstract":"3D referring segmentation is an emerging and challenging vision-language task that aims to segment the object described by a natural language expression in a point cloud scene. The key challenge behind this task is vision-language feature fusion and alignment. In this work, we propose RefMask3D to explore the comprehensive multi-modal feature interaction and understanding. First, we propose a Geometry-Enhanced Group-Word Attention to integrate language with geometrically coherent sub-clouds through cross-modal group-word attention, which effectively addresses the challenges posed by the sparse and irregular nature of point clouds. Then, we introduce a Linguistic Primitives Construction to produce semantic primitives representing distinct semantic attributes, which greatly enhance the vision-language understanding at the decoding stage. Furthermore, we introduce an Object Cluster Module that analyzes the interrelationships among linguistic primitives to consolidate their insights and pinpoint common characteristics, helping to capture holistic information and enhance the precision of target identification. The proposed RefMask3D achieves new state-of-the-art performance on 3D referring segmentation, 3D visual grounding, and also 2D referring image segmentation. Especially, RefMask3D outperforms previous state-of-the-art method by a large margin of 3.16% mIoU} on the challenging ScanRefer dataset. Code is available at https://github.com/heshuting555/RefMask3D.","sentences":["3D referring segmentation is an emerging and challenging vision-language task that aims to segment the object described by a natural language expression in a point cloud scene.","The key challenge behind this task is vision-language feature fusion and alignment.","In this work, we propose RefMask3D to explore the comprehensive multi-modal feature interaction and understanding.","First, we propose a Geometry-Enhanced Group-Word Attention to integrate language with geometrically coherent sub-clouds through cross-modal group-word attention, which effectively addresses the challenges posed by the sparse and irregular nature of point clouds.","Then, we introduce a Linguistic Primitives Construction to produce semantic primitives representing distinct semantic attributes, which greatly enhance the vision-language understanding at the decoding stage.","Furthermore, we introduce an Object Cluster Module that analyzes the interrelationships among linguistic primitives to consolidate their insights and pinpoint common characteristics, helping to capture holistic information and enhance the precision of target identification.","The proposed RefMask3D achieves new state-of-the-art performance on 3D referring segmentation, 3D visual grounding, and also 2D referring image segmentation.","Especially, RefMask3D outperforms previous state-of-the-art method by a large margin of 3.16% mIoU} on the challenging ScanRefer dataset.","Code is available at https://github.com/heshuting555/RefMask3D."],"url":"http://arxiv.org/abs/2407.18244v1"}
{"created":"2024-07-25 17:57:48","title":"BIV-Priv-Seg: Locating Private Content in Images Taken by People With Visual Impairments","abstract":"Individuals who are blind or have low vision (BLV) are at a heightened risk of sharing private information if they share photographs they have taken. To facilitate developing technologies that can help preserve privacy, we introduce BIV-Priv-Seg, the first localization dataset originating from people with visual impairments that shows private content. It contains 1,028 images with segmentation annotations for 16 private object categories. We first characterize BIV-Priv-Seg and then evaluate modern models' performance for locating private content in the dataset. We find modern models struggle most with locating private objects that are not salient, small, and lack text as well as recognizing when private content is absent from an image. We facilitate future extensions by sharing our new dataset with the evaluation server at https://vizwiz.org/tasks-and-datasets/object-localization.","sentences":["Individuals who are blind or have low vision (BLV) are at a heightened risk of sharing private information if they share photographs they have taken.","To facilitate developing technologies that can help preserve privacy, we introduce BIV-Priv-Seg, the first localization dataset originating from people with visual impairments that shows private content.","It contains 1,028 images with segmentation annotations for 16 private object categories.","We first characterize BIV-Priv-Seg and then evaluate modern models' performance for locating private content in the dataset.","We find modern models struggle most with locating private objects that are not salient, small, and lack text as well as recognizing when private content is absent from an image.","We facilitate future extensions by sharing our new dataset with the evaluation server at https://vizwiz.org/tasks-and-datasets/object-localization."],"url":"http://arxiv.org/abs/2407.18243v1"}
{"created":"2024-07-25 17:57:12","title":"LoRA-Pro: Are Low-Rank Adapters Properly Optimized?","abstract":"Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method for parameter-efficient fine-tuning foundation models by re-parameterizing the original matrix into the product of two low-rank matrices. Despite its efficiency, LoRA often yields inferior performance compared to full fine-tuning. In this paper, we propose LoRA-Pro to bridge this performance gap. Firstly, we delve into the optimization processes in LoRA and full fine-tuning. We reveal that while LoRA employs low-rank approximation, it neglects to approximate the optimization process of full fine-tuning. To address this, we introduce a novel concept called the \"equivalent gradient.\" This virtual gradient makes the optimization process on the re-parameterized matrix equivalent to LoRA, which can be used to quantify the differences between LoRA and full fine-tuning. The equivalent gradient is derived from the gradients of matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the differences between the equivalent gradient and the gradient obtained from full fine-tuning during the optimization process. By solving this objective, we derive optimal closed-form solutions for updating matrices $A$ and $B$. Our method constrains the optimization process, shrinking the performance gap between LoRA and full fine-tuning. Extensive experiments on natural language processing tasks validate the effectiveness of our method.","sentences":["Low-Rank Adaptation, also known as LoRA, has emerged as a prominent method for parameter-efficient fine-tuning foundation models by re-parameterizing the original matrix into the product of two low-rank matrices.","Despite its efficiency, LoRA often yields inferior performance compared to full fine-tuning.","In this paper, we propose LoRA-Pro to bridge this performance gap.","Firstly, we delve into the optimization processes in LoRA and full fine-tuning.","We reveal that while LoRA employs low-rank approximation, it neglects to approximate the optimization process of full fine-tuning.","To address this, we introduce a novel concept called the \"equivalent gradient.\"","This virtual gradient makes the optimization process on the re-parameterized matrix equivalent to LoRA, which can be used to quantify the differences between LoRA and full fine-tuning.","The equivalent gradient is derived from the gradients of matrices $A$ and $B$. To narrow the performance gap, our approach minimizes the differences between the equivalent gradient and the gradient obtained from full fine-tuning during the optimization process.","By solving this objective, we derive optimal closed-form solutions for updating matrices $A$ and $B$. Our method constrains the optimization process, shrinking the performance gap between LoRA and full fine-tuning.","Extensive experiments on natural language processing tasks validate the effectiveness of our method."],"url":"http://arxiv.org/abs/2407.18242v1"}
{"created":"2024-07-25 17:55:33","title":"Numerical Literals in Link Prediction: A Critical Examination of Models and Datasets","abstract":"Link Prediction(LP) is an essential task over Knowledge Graphs(KGs), traditionally focussed on using and predicting the relations between entities. Textual entity descriptions have already been shown to be valuable, but models that incorporate numerical literals have shown minor improvements on existing benchmark datasets. It is unclear whether a model is actually better in using numerical literals, or better capable of utilizing the graph structure. This raises doubts about the effectiveness of these methods and about the suitability of the existing benchmark datasets.   We propose a methodology to evaluate LP models that incorporate numerical literals. We propose i) a new synthetic dataset to better understand how well these models use numerical literals and ii) dataset ablations strategies to investigate potential difficulties with the existing datasets. We identify a prevalent trend: many models underutilize literal information and potentially rely on additional parameters for performance gains. Our investigation highlights the need for more extensive evaluations when releasing new models and datasets.","sentences":["Link Prediction(LP) is an essential task over Knowledge Graphs(KGs), traditionally focussed on using and predicting the relations between entities.","Textual entity descriptions have already been shown to be valuable, but models that incorporate numerical literals have shown minor improvements on existing benchmark datasets.","It is unclear whether a model is actually better in using numerical literals, or better capable of utilizing the graph structure.","This raises doubts about the effectiveness of these methods and about the suitability of the existing benchmark datasets.   ","We propose a methodology to evaluate LP models that incorporate numerical literals.","We propose i) a new synthetic dataset to better understand how well these models use numerical literals and ii) dataset ablations strategies to investigate potential difficulties with the existing datasets.","We identify a prevalent trend: many models underutilize literal information and potentially rely on additional parameters for performance gains.","Our investigation highlights the need for more extensive evaluations when releasing new models and datasets."],"url":"http://arxiv.org/abs/2407.18241v1"}
{"created":"2024-07-25 17:54:58","title":"CodedVO: Coded Visual Odometry","abstract":"Autonomous robots often rely on monocular cameras for odometry estimation and navigation. However, the scale ambiguity problem presents a critical barrier to effective monocular visual odometry. In this paper, we present CodedVO, a novel monocular visual odometry method that overcomes the scale ambiguity problem by employing custom optics to physically encode metric depth information into imagery. By incorporating this information into our odometry pipeline, we achieve state-of-the-art performance in monocular visual odometry with a known scale. We evaluate our method in diverse indoor environments and demonstrate its robustness and adaptability. We achieve a 0.08m average trajectory error in odometry evaluation on the ICL-NUIM indoor odometry dataset.","sentences":["Autonomous robots often rely on monocular cameras for odometry estimation and navigation.","However, the scale ambiguity problem presents a critical barrier to effective monocular visual odometry.","In this paper, we present CodedVO, a novel monocular visual odometry method that overcomes the scale ambiguity problem by employing custom optics to physically encode metric depth information into imagery.","By incorporating this information into our odometry pipeline, we achieve state-of-the-art performance in monocular visual odometry with a known scale.","We evaluate our method in diverse indoor environments and demonstrate its robustness and adaptability.","We achieve a 0.08m average trajectory error in odometry evaluation on the ICL-NUIM indoor odometry dataset."],"url":"http://arxiv.org/abs/2407.18240v1"}
{"created":"2024-07-25 17:50:32","title":"LION: Linear Group RNN for 3D Object Detection in Point Clouds","abstract":"The benefit of transformers in large-scale 3D point cloud perception tasks, such as 3D object detection, is limited by their quadratic computation cost when modeling long-range relationships. In contrast, linear RNNs have low computational complexity and are suitable for long-range modeling. Toward this goal, we propose a simple and effective window-based framework built on LInear grOup RNN (i.e., perform linear RNN for grouped features) for accurate 3D object detection, called LION. The key property is to allow sufficient feature interaction in a much larger group than transformer-based methods. However, effectively applying linear group RNN to 3D object detection in highly sparse point clouds is not trivial due to its limitation in handling spatial modeling. To tackle this problem, we simply introduce a 3D spatial feature descriptor and integrate it into the linear group RNN operators to enhance their spatial features rather than blindly increasing the number of scanning orders for voxel features. To further address the challenge in highly sparse point clouds, we propose a 3D voxel generation strategy to densify foreground features thanks to linear group RNN as a natural property of auto-regressive models. Extensive experiments verify the effectiveness of the proposed components and the generalization of our LION on different linear group RNN operators including Mamba, RWKV, and RetNet. Furthermore, it is worth mentioning that our LION-Mamba achieves state-of-the-art on Waymo, nuScenes, Argoverse V2, and ONCE dataset. Last but not least, our method supports kinds of advanced linear RNN operators (e.g., RetNet, RWKV, Mamba, xLSTM and TTT) on small but popular KITTI dataset for a quick experience with our linear RNN-based framework.","sentences":["The benefit of transformers in large-scale 3D point cloud perception tasks, such as 3D object detection, is limited by their quadratic computation cost when modeling long-range relationships.","In contrast, linear RNNs have low computational complexity and are suitable for long-range modeling.","Toward this goal, we propose a simple and effective window-based framework built on LInear grOup RNN (i.e., perform linear RNN for grouped features) for accurate 3D object detection, called LION.","The key property is to allow sufficient feature interaction in a much larger group than transformer-based methods.","However, effectively applying linear group RNN to 3D object detection in highly sparse point clouds is not trivial due to its limitation in handling spatial modeling.","To tackle this problem, we simply introduce a 3D spatial feature descriptor and integrate it into the linear group RNN operators to enhance their spatial features rather than blindly increasing the number of scanning orders for voxel features.","To further address the challenge in highly sparse point clouds, we propose a 3D voxel generation strategy to densify foreground features thanks to linear group RNN as a natural property of auto-regressive models.","Extensive experiments verify the effectiveness of the proposed components and the generalization of our LION on different linear group RNN operators including Mamba, RWKV, and RetNet.","Furthermore, it is worth mentioning that our LION-Mamba achieves state-of-the-art on Waymo, nuScenes, Argoverse V2, and ONCE dataset.","Last but not least, our method supports kinds of advanced linear RNN operators (e.g., RetNet, RWKV, Mamba, xLSTM and TTT) on small but popular KITTI dataset for a quick experience with our linear RNN-based framework."],"url":"http://arxiv.org/abs/2407.18232v1"}
{"created":"2024-07-25 17:47:49","title":"Parameterized Algorithms on Integer Sets with Small Doubling: Integer Programming, Subset Sum and k-SUM","abstract":"We study the parameterized complexity of algorithmic problems whose input is an integer set $A$ in terms of the doubling constant $C := |A + A|/|A|$, a fundamental measure of additive structure. We present evidence that this new parameterization is algorithmically useful in the form of new results for two difficult, well-studied problems: Integer Programming and Subset Sum.   First, we show that determining the feasibility of bounded Integer Programs is a tractable problem when parameterized in the doubling constant. Specifically, we prove that the feasibility of an integer program $I$ with $n$ polynomially-bounded variables and $m$ constraints can be determined in time $n^{O_C(1)} poly(|I|)$ when the column set of the constraint matrix has doubling constant $C$.   Second, we show that the Subset Sum and Unbounded Subset Sum problems can be solved in time $n^{O_C(1)}$ and $n^{O_C(\\log \\log \\log n)}$, respectively, where the $O_C$ notation hides functions that depend only on the doubling constant $C$. We also show the equivalence of achieving an FPT algorithm for Subset Sum with bounded doubling and achieving a milestone result for the parameterized complexity of Box ILP. Finally, we design near-linear time algorithms for $k$-SUM as well as tight lower bounds for 4-SUM and nearly tight lower bounds for $k$-SUM, under the $k$-SUM conjecture.   Several of our results rely on a new proof that Freiman's Theorem, a central result in additive combinatorics, can be made efficiently constructive. This result may be of independent interest.","sentences":["We study the parameterized complexity of algorithmic problems whose input is an integer set $A$ in terms of the doubling constant $C := |A + A|/|A|$, a fundamental measure of additive structure.","We present evidence that this new parameterization is algorithmically useful in the form of new results for two difficult, well-studied problems: Integer Programming and Subset Sum.   ","First, we show that determining the feasibility of bounded Integer Programs is a tractable problem when parameterized in the doubling constant.","Specifically, we prove that the feasibility of an integer program $I$ with $n$ polynomially-bounded variables and $m$ constraints can be determined in time $n^{O_C(1)} poly(|I|)$ when the column set of the constraint matrix has doubling constant $C$.   ","Second, we show that the Subset Sum and Unbounded Subset Sum problems can be solved in time $n^{O_C(1)}$ and $n^{O_C(\\log \\log \\log n)}$, respectively, where the $O_C$ notation hides functions that depend only on the doubling constant $C$.","We also show the equivalence of achieving an FPT algorithm for Subset Sum with bounded doubling and achieving a milestone result for the parameterized complexity of Box ILP.","Finally, we design near-linear time algorithms for $k$-SUM as well as tight lower bounds for 4-SUM and nearly tight lower bounds for $k$-SUM, under the $k$-SUM conjecture.   ","Several of our results rely on a new proof that Freiman's Theorem, a central result in additive combinatorics, can be made efficiently constructive.","This result may be of independent interest."],"url":"http://arxiv.org/abs/2407.18228v1"}
{"created":"2024-07-25 17:46:38","title":"Automated Ensemble Multimodal Machine Learning for Healthcare","abstract":"The application of machine learning in medicine and healthcare has led to the creation of numerous diagnostic and prognostic models. However, despite their success, current approaches generally issue predictions using data from a single modality. This stands in stark contrast with clinician decision-making which employs diverse information from multiple sources. While several multimodal machine learning approaches exist, significant challenges in developing multimodal systems remain that are hindering clinical adoption. In this paper, we introduce a multimodal framework, AutoPrognosis-M, that enables the integration of structured clinical (tabular) data and medical imaging using automated machine learning. AutoPrognosis-M incorporates 17 imaging models, including convolutional neural networks and vision transformers, and three distinct multimodal fusion strategies. In an illustrative application using a multimodal skin lesion dataset, we highlight the importance of multimodal machine learning and the power of combining multiple fusion strategies using ensemble learning. We have open-sourced our framework as a tool for the community and hope it will accelerate the uptake of multimodal machine learning in healthcare and spur further innovation.","sentences":["The application of machine learning in medicine and healthcare has led to the creation of numerous diagnostic and prognostic models.","However, despite their success, current approaches generally issue predictions using data from a single modality.","This stands in stark contrast with clinician decision-making which employs diverse information from multiple sources.","While several multimodal machine learning approaches exist, significant challenges in developing multimodal systems remain that are hindering clinical adoption.","In this paper, we introduce a multimodal framework, AutoPrognosis-M, that enables the integration of structured clinical (tabular) data and medical imaging using automated machine learning.","AutoPrognosis-M incorporates 17 imaging models, including convolutional neural networks and vision transformers, and three distinct multimodal fusion strategies.","In an illustrative application using a multimodal skin lesion dataset, we highlight the importance of multimodal machine learning and the power of combining multiple fusion strategies using ensemble learning.","We have open-sourced our framework as a tool for the community and hope it will accelerate the uptake of multimodal machine learning in healthcare and spur further innovation."],"url":"http://arxiv.org/abs/2407.18227v1"}
{"created":"2024-07-25 17:36:18","title":"Detecting and explaining (in)equivalence of context-free grammars","abstract":"We propose a scalable framework for deciding, proving, and explaining (in)equivalence of context-free grammars. We present an implementation of the framework and evaluate it on large data sets collected within educational support systems. Even though the equivalence problem for context-free languages is undecidable in general, the framework is able to handle a large portion of these datasets. It introduces and combines techniques from several areas, such as an abstract grammar transformation language to identify equivalent grammars as well as sufficiently similar inequivalent grammars, theory-based comparison algorithms for a large class of context-free languages, and a graph-theory-inspired grammar canonization that allows to efficiently identify isomorphic grammars.","sentences":["We propose a scalable framework for deciding, proving, and explaining (in)equivalence of context-free grammars.","We present an implementation of the framework and evaluate it on large data sets collected within educational support systems.","Even though the equivalence problem for context-free languages is undecidable in general, the framework is able to handle a large portion of these datasets.","It introduces and combines techniques from several areas, such as an abstract grammar transformation language to identify equivalent grammars as well as sufficiently similar inequivalent grammars, theory-based comparison algorithms for a large class of context-free languages, and a graph-theory-inspired grammar canonization that allows to efficiently identify isomorphic grammars."],"url":"http://arxiv.org/abs/2407.18220v1"}
{"created":"2024-07-25 17:35:59","title":"Recursive Introspection: Teaching Language Model Agents How to Self-Improve","abstract":"A central piece in enabling intelligent agentic behavior in foundation models is to make them capable of introspecting upon their behavior, reasoning, and correcting their mistakes as more computation or interaction is available. Even the strongest proprietary large language models (LLMs) do not quite exhibit the ability of continually improving their responses sequentially, even in scenarios where they are explicitly told that they are making a mistake. In this paper, we develop RISE: Recursive IntroSpEction, an approach for fine-tuning LLMs to introduce this capability, despite prior work hypothesizing that this capability may not be possible to attain. Our approach prescribes an iterative fine-tuning procedure, which attempts to teach the model how to alter its response after having executed previously unsuccessful attempts to solve a hard test-time problem, with optionally additional environment feedback. RISE poses fine-tuning for a single-turn prompt as solving a multi-turn Markov decision process (MDP), where the initial state is the prompt. Inspired by principles in online imitation learning and reinforcement learning, we propose strategies for multi-turn data collection and training so as to imbue an LLM with the capability to recursively detect and correct its previous mistakes in subsequent iterations. Our experiments show that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation. We also find that RISE scales well, often attaining larger benefits with more capable models. Our analysis shows that RISE makes meaningful improvements to responses to arrive at the correct solution for challenging prompts, without disrupting one-turn abilities as a result of expressing more complex distributions.","sentences":["A central piece in enabling intelligent agentic behavior in foundation models is to make them capable of introspecting upon their behavior, reasoning, and correcting their mistakes as more computation or interaction is available.","Even the strongest proprietary large language models (LLMs) do not quite exhibit the ability of continually improving their responses sequentially, even in scenarios where they are explicitly told that they are making a mistake.","In this paper, we develop RISE: Recursive IntroSpEction, an approach for fine-tuning LLMs to introduce this capability, despite prior work hypothesizing that this capability may not be possible to attain.","Our approach prescribes an iterative fine-tuning procedure, which attempts to teach the model how to alter its response after having executed previously unsuccessful attempts to solve a hard test-time problem, with optionally additional environment feedback.","RISE poses fine-tuning for a single-turn prompt as solving a multi-turn Markov decision process (MDP), where the initial state is the prompt.","Inspired by principles in online imitation learning and reinforcement learning, we propose strategies for multi-turn data collection and training so as to imbue an LLM with the capability to recursively detect and correct its previous mistakes in subsequent iterations.","Our experiments show that RISE enables Llama2, Llama3, and Mistral models to improve themselves with more turns on math reasoning tasks, outperforming several single-turn strategies given an equal amount of inference-time computation.","We also find that RISE scales well, often attaining larger benefits with more capable models.","Our analysis shows that RISE makes meaningful improvements to responses to arrive at the correct solution for challenging prompts, without disrupting one-turn abilities as a result of expressing more complex distributions."],"url":"http://arxiv.org/abs/2407.18219v1"}
{"created":"2024-07-25 17:35:11","title":"An NKCS Model of Bookchins Communalism","abstract":"The NKCS model was introduced to explore coevolutionary systems, that is, systems in which multiple species are closely interconnected. The fitness landscapes of the species are coupled to a controllable amount, where the underlying properties of the individual landscapes are also controllable. No previous work has explored the use of hierarchical control within the model. This paper explores the effects of using a confederation, based on Bookchins communalism, and a single point of global control. Significant changes in behaviour from the traditional model are seen across the parameter space.","sentences":["The NKCS model was introduced to explore coevolutionary systems, that is, systems in which multiple species are closely interconnected.","The fitness landscapes of the species are coupled to a controllable amount, where the underlying properties of the individual landscapes are also controllable.","No previous work has explored the use of hierarchical control within the model.","This paper explores the effects of using a confederation, based on Bookchins communalism, and a single point of global control.","Significant changes in behaviour from the traditional model are seen across the parameter space."],"url":"http://arxiv.org/abs/2407.18218v1"}
{"created":"2024-07-25 17:32:17","title":"Fast computation of the period and of the shortest cover of a string using its Character-Distance-Sampling representation","abstract":"Computing regularities in strings is essential for a better understanding of their structures. Among regularities, periods and covers are the easiest to compute and the more informative. Lately new interesting string matching results have been achieved using different sampling techniques. One of these technique, called Character-Distance-Sampling (\\texttt{CDS}) consists of representing a string by storing the distance between the positions of selected characters called pivots. Here we select as pivots only the first character of the string and use its \\texttt{CDS} representation for computing its period and its shortest cover. Experimental results show that the proposed methods are much faster than classical methods for computing these two features.","sentences":["Computing regularities in strings is essential for a better understanding of their structures.","Among regularities, periods and covers are the easiest to compute and the more informative.","Lately new interesting string matching results have been achieved using different sampling techniques.","One of these technique, called Character-Distance-Sampling (\\texttt{CDS}) consists of representing a string by storing the distance between the positions of selected characters called pivots.","Here we select as pivots only the first character of the string and use its \\texttt{CDS} representation for computing its period and its shortest cover.","Experimental results show that the proposed methods are much faster than classical methods for computing these two features."],"url":"http://arxiv.org/abs/2407.18216v1"}
{"created":"2024-07-25 17:28:30","title":"Tool-Assisted Learning of Computational Reductions","abstract":"Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science.","sentences":["Computational reductions are an important and powerful concept in computer science.","However, they are difficult for many students to grasp.","In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems.","We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science."],"url":"http://arxiv.org/abs/2407.18215v1"}
{"created":"2024-07-25 17:26:41","title":"Exploring Scaling Trends in LLM Robustness","abstract":"Language model capabilities predictably improve from scaling a model's size and training data. Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities. Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse. Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale? We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses.","sentences":["Language model capabilities predictably improve from scaling a model's size and training data.","Motivated by this, increasingly large language models have been trained, yielding an array of impressive capabilities.","Yet these models are vulnerable to adversarial prompts, such as \"jailbreaks\" that hijack models to perform undesired behaviors, posing a significant risk of misuse.","Prior work indicates that computer vision models become more robust with model and data scaling, raising the question: does language model robustness also improve with scale?","We study this question empirically, finding that larger models respond substantially better to adversarial training, but there is little to no benefit from model scale in the absence of explicit defenses."],"url":"http://arxiv.org/abs/2407.18213v1"}
{"created":"2024-07-25 17:18:28","title":"SuperFlow: A Fully-Customized RTL-to-GDS Design Automation Flow for Adiabatic Quantum-Flux-Parametron Superconducting Circuits","abstract":"Superconducting circuits, like Adiabatic Quantum-Flux-Parametron (AQFP), offer exceptional energy efficiency but face challenges in physical design due to sophisticated spacing and timing constraints. Current design tools often neglect the importance of constraint adherence throughout the entire design flow. In this paper, we propose SuperFlow, a fully-customized RTL-to-GDS design flow tailored for AQFP devices. SuperFlow leverages a synthesis tool based on CMOS technology to transform any input RTL netlist to an AQFP-based netlist. Subsequently, we devise a novel place-and-route procedure that simultaneously considers wirelength, timing, and routability for AQFP circuits. The process culminates in the generation of the AQFP circuit layout, followed by a Design Rule Check (DRC) to identify and rectify any layout violations. Our experimental results demonstrate that SuperFlow achieves 12.8% wirelength improvement on average and 12.1% better timing quality compared with previous state-of-the-art placers for AQFP circuits.","sentences":["Superconducting circuits, like Adiabatic Quantum-Flux-Parametron (AQFP), offer exceptional energy efficiency but face challenges in physical design due to sophisticated spacing and timing constraints.","Current design tools often neglect the importance of constraint adherence throughout the entire design flow.","In this paper, we propose SuperFlow, a fully-customized RTL-to-GDS design flow tailored for AQFP devices.","SuperFlow leverages a synthesis tool based on CMOS technology to transform any input RTL netlist to an AQFP-based netlist.","Subsequently, we devise a novel place-and-route procedure that simultaneously considers wirelength, timing, and routability for AQFP circuits.","The process culminates in the generation of the AQFP circuit layout, followed by a Design Rule Check (DRC) to identify and rectify any layout violations.","Our experimental results demonstrate that SuperFlow achieves 12.8% wirelength improvement on average and 12.1% better timing quality compared with previous state-of-the-art placers for AQFP circuits."],"url":"http://arxiv.org/abs/2407.18209v1"}
{"created":"2024-07-25 17:17:10","title":"Geometry Fidelity for Spherical Images","abstract":"Spherical or omni-directional images offer an immersive visual format appealing to a wide range of computer vision applications. However, geometric properties of spherical images pose a major challenge for models and metrics designed for ordinary 2D images. Here, we show that direct application of Fr\\'echet Inception Distance (FID) is insufficient for quantifying geometric fidelity in spherical images. We introduce two quantitative metrics accounting for geometric constraints, namely Omnidirectional FID (OmniFID) and Discontinuity Score (DS). OmniFID is an extension of FID tailored to additionally capture field-of-view requirements of the spherical format by leveraging cubemap projections. DS is a kernel-based seam alignment score of continuity across borders of 2D representations of spherical images. In experiments, OmniFID and DS quantify geometry fidelity issues that are undetected by FID.","sentences":["Spherical or omni-directional images offer an immersive visual format appealing to a wide range of computer vision applications.","However, geometric properties of spherical images pose a major challenge for models and metrics designed for ordinary 2D images.","Here, we show that direct application of Fr\\'echet Inception Distance (FID) is insufficient for quantifying geometric fidelity in spherical images.","We introduce two quantitative metrics accounting for geometric constraints, namely Omnidirectional FID (OmniFID) and Discontinuity Score (DS).","OmniFID is an extension of FID tailored to additionally capture field-of-view requirements of the spherical format by leveraging cubemap projections.","DS is a kernel-based seam alignment score of continuity across borders of 2D representations of spherical images.","In experiments, OmniFID and DS quantify geometry fidelity issues that are undetected by FID."],"url":"http://arxiv.org/abs/2407.18207v1"}
{"created":"2024-07-25 17:09:26","title":"Semi-Classical Subspaces, The No Synchronization Law, and More","abstract":"This paper looks at the intersection of algorithmic information theory and physics, namely quantum mechanics, thermodynamics, and black holes. We discuss theorems which characterize the barrier between the quantum world and the classical realm. The notion of a \"semi-classical subspace\" is introduced. The No Synchronization Law is detailed, which says separate and isolated physical systems evolving over time cannot have thermodynamic algorithmic entropies that are in synch. We look at future work involving the Kolmogorov complexity of black holes.","sentences":["This paper looks at the intersection of algorithmic information theory and physics, namely quantum mechanics, thermodynamics, and black holes.","We discuss theorems which characterize the barrier between the quantum world and the classical realm.","The notion of a \"semi-classical subspace\" is introduced.","The No Synchronization Law is detailed, which says separate and isolated physical systems evolving over time cannot have thermodynamic algorithmic entropies that are in synch.","We look at future work involving the Kolmogorov complexity of black holes."],"url":"http://arxiv.org/abs/2407.18201v1"}
{"created":"2024-07-25 17:09:22","title":"Sparse Incremental Aggregation in Multi-Hop Federated Learning","abstract":"This paper investigates federated learning (FL) in a multi-hop communication setup, such as in constellations with inter-satellite links. In this setup, part of the FL clients are responsible for forwarding other client's results to the parameter server. Instead of using conventional routing, the communication efficiency can be improved significantly by using in-network model aggregation at each intermediate hop, known as incremental aggregation (IA). Prior works [1] have indicated diminishing gains for IA under gradient sparsification. Here we study this issue and propose several novel correlated sparsification methods for IA. Numerical results show that, for some of these algorithms, the full potential of IA is still available under sparsification without impairing convergence. We demonstrate a 15x improvement in communication efficiency over conventional routing and a 11x improvement over state-of-the-art (SoA) sparse IA.","sentences":["This paper investigates federated learning (FL) in a multi-hop communication setup, such as in constellations with inter-satellite links.","In this setup, part of the FL clients are responsible for forwarding other client's results to the parameter server.","Instead of using conventional routing, the communication efficiency can be improved significantly by using in-network model aggregation at each intermediate hop, known as incremental aggregation (IA).","Prior works","[1] have indicated diminishing gains for IA under gradient sparsification.","Here we study this issue and propose several novel correlated sparsification methods for IA.","Numerical results show that, for some of these algorithms, the full potential of IA is still available under sparsification without impairing convergence.","We demonstrate a 15x improvement in communication efficiency over conventional routing and a 11x improvement over state-of-the-art (SoA) sparse IA."],"url":"http://arxiv.org/abs/2407.18200v1"}
{"created":"2024-07-25 16:43:56","title":"AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction","abstract":"Epitope identification is vital for antibody design yet challenging due to the inherent variability in antibodies. While many deep learning methods have been developed for general protein binding site prediction tasks, whether they work for epitope prediction remains an understudied research question. The challenge is also heightened by the lack of a consistent evaluation pipeline with sufficient dataset size and epitope diversity. We introduce a filtered antibody-antigen complex structure dataset, AsEP (Antibody-specific Epitope Prediction). AsEP is the largest of its kind and provides clustered epitope groups, allowing the community to develop and test novel epitope prediction methods. AsEP comes with an easy-to-use interface in Python and pre-built graph representations of each antibody-antigen complex while also supporting customizable embedding methods. Based on this new dataset, we benchmarked various representative general protein-binding site prediction methods and find that their performances are not satisfactory as expected for epitope prediction. We thus propose a new method, WALLE, that leverages both protein language models and graph neural networks. WALLE demonstrate about 5X performance gain over existing methods. Our empirical findings evidence that epitope prediction benefits from combining sequential embeddings provided by language models and geometrical information from graph representations, providing a guideline for future method design. In addition, we reformulate the task as bipartite link prediction, allowing easy model performance attribution and interpretability. We open-source our data and code at https://github.com/biochunan/AsEP-dataset.","sentences":["Epitope identification is vital for antibody design yet challenging due to the inherent variability in antibodies.","While many deep learning methods have been developed for general protein binding site prediction tasks, whether they work for epitope prediction remains an understudied research question.","The challenge is also heightened by the lack of a consistent evaluation pipeline with sufficient dataset size and epitope diversity.","We introduce a filtered antibody-antigen complex structure dataset, AsEP (Antibody-specific Epitope Prediction).","AsEP is the largest of its kind and provides clustered epitope groups, allowing the community to develop and test novel epitope prediction methods.","AsEP comes with an easy-to-use interface in Python and pre-built graph representations of each antibody-antigen complex while also supporting customizable embedding methods.","Based on this new dataset, we benchmarked various representative general protein-binding site prediction methods and find that their performances are not satisfactory as expected for epitope prediction.","We thus propose a new method, WALLE, that leverages both protein language models and graph neural networks.","WALLE demonstrate about 5X performance gain over existing methods.","Our empirical findings evidence that epitope prediction benefits from combining sequential embeddings provided by language models and geometrical information from graph representations, providing a guideline for future method design.","In addition, we reformulate the task as bipartite link prediction, allowing easy model performance attribution and interpretability.","We open-source our data and code at https://github.com/biochunan/AsEP-dataset."],"url":"http://arxiv.org/abs/2407.18184v1"}
{"created":"2024-07-25 16:42:36","title":"Signaling Rate and Performance of RIS Reconfiguration and Handover Management in Next Generation Mobile Networks","abstract":"We consider the problem of signaling rate and performance for an efficient control and management of RIS reconfigurations and handover in next generation mobile networks. To this end, we first analytically determine the rates of RIS reconfigurations and handover using a stochastic geometry network model. We derive closed-form expressions of these rates while taking into account static obstacles (both known and unknown), self-blockage, RIS location density, and variations in the angle and direction of user mobility. Based on the rates derived, we analyze the signaling rates of a sample novel signaling protocol, which we propose as an extension of an handover signaling protocol standard in mobile networks. The results quantify the impact of known and unknown obstacles on the RIS and handover reconfiguration rate as function of device density and mobility. We use the proposed analysis to evaluate the signaling overhead due to RIS reconfigurations, as well as to dimension the related RIS control plane server capacity in the network management system. To the best of our knowledge, this is the first analytical model to derive the closed form expressions of RIS reconfiguration rates, along with handover rates, and relate its statistical properties to the signaling rate and performance in next generation mobile networks.","sentences":["We consider the problem of signaling rate and performance for an efficient control and management of RIS reconfigurations and handover in next generation mobile networks.","To this end, we first analytically determine the rates of RIS reconfigurations and handover using a stochastic geometry network model.","We derive closed-form expressions of these rates while taking into account static obstacles (both known and unknown), self-blockage, RIS location density, and variations in the angle and direction of user mobility.","Based on the rates derived, we analyze the signaling rates of a sample novel signaling protocol, which we propose as an extension of an handover signaling protocol standard in mobile networks.","The results quantify the impact of known and unknown obstacles on the RIS and handover reconfiguration rate as function of device density and mobility.","We use the proposed analysis to evaluate the signaling overhead due to RIS reconfigurations, as well as to dimension the related RIS control plane server capacity in the network management system.","To the best of our knowledge, this is the first analytical model to derive the closed form expressions of RIS reconfiguration rates, along with handover rates, and relate its statistical properties to the signaling rate and performance in next generation mobile networks."],"url":"http://arxiv.org/abs/2407.18183v1"}
{"created":"2024-07-25 16:42:08","title":"Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning","abstract":"Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing (scRNA-seq) data is a complex challenge that requires capturing the intricate relationships between genes and their regulatory interactions. In this study, we tackle this challenge by leveraging the single-cell BERT-based pre-trained transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to augment structured biological knowledge from existing GRNs. We introduce a novel joint graph learning approach that combines the rich contextual representations learned by pre-trained single-cell language models with the structured knowledge encoded in GRNs using graph neural networks (GNNs). By integrating these two modalities, our approach effectively reasons over boththe gene expression level constraints provided by the scRNA-seq data and the structured biological knowledge inherent in GRNs. We evaluate our method on human cell benchmark datasets from the BEELINE study with cell type-specific ground truth networks. The results demonstrate superior performance over current state-of-the-art baselines, offering a deeper understanding of cellular regulatory mechanisms.","sentences":["Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing (scRNA-seq) data is a complex challenge that requires capturing the intricate relationships between genes and their regulatory interactions.","In this study, we tackle this challenge by leveraging the single-cell BERT-based pre-trained transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to augment structured biological knowledge from existing GRNs.","We introduce a novel joint graph learning approach that combines the rich contextual representations learned by pre-trained single-cell language models with the structured knowledge encoded in GRNs using graph neural networks (GNNs).","By integrating these two modalities, our approach effectively reasons over boththe gene expression level constraints provided by the scRNA-seq data and the structured biological knowledge inherent in GRNs.","We evaluate our method on human cell benchmark datasets from the BEELINE study with cell type-specific ground truth networks.","The results demonstrate superior performance over current state-of-the-art baselines, offering a deeper understanding of cellular regulatory mechanisms."],"url":"http://arxiv.org/abs/2407.18181v1"}
{"created":"2024-07-25 16:37:07","title":"PianoMime: Learning a Generalist, Dexterous Piano Player from Internet Demonstrations","abstract":"In this work, we introduce PianoMime, a framework for training a piano-playing agent using internet demonstrations. The internet is a promising source of large-scale demonstrations for training our robot agents. In particular, for the case of piano-playing, Youtube is full of videos of professional pianists playing a wide myriad of songs. In our work, we leverage these demonstrations to learn a generalist piano-playing agent capable of playing any arbitrary song. Our framework is divided into three parts: a data preparation phase to extract the informative features from the Youtube videos, a policy learning phase to train song-specific expert policies from the demonstrations and a policy distillation phase to distil the policies into a single generalist agent. We explore different policy designs to represent the agent and evaluate the influence of the amount of training data on the generalization capability of the agent to novel songs not available in the dataset. We show that we are able to learn a policy with up to 56\\% F1 score on unseen songs.","sentences":["In this work, we introduce PianoMime, a framework for training a piano-playing agent using internet demonstrations.","The internet is a promising source of large-scale demonstrations for training our robot agents.","In particular, for the case of piano-playing, Youtube is full of videos of professional pianists playing a wide myriad of songs.","In our work, we leverage these demonstrations to learn a generalist piano-playing agent capable of playing any arbitrary song.","Our framework is divided into three parts: a data preparation phase to extract the informative features from the Youtube videos, a policy learning phase to train song-specific expert policies from the demonstrations and a policy distillation phase to distil the policies into a single generalist agent.","We explore different policy designs to represent the agent and evaluate the influence of the amount of training data on the generalization capability of the agent to novel songs not available in the dataset.","We show that we are able to learn a policy with up to 56\\% F1 score on unseen songs."],"url":"http://arxiv.org/abs/2407.18178v1"}
{"created":"2024-07-25 16:35:46","title":"Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers","abstract":"Vision transformers (ViTs) have demonstrated their superior accuracy for computer vision tasks compared to convolutional neural networks (CNNs). However, ViT models are often computation-intensive for efficient deployment on resource-limited edge devices. This work proposes Quasar-ViT, a hardware-oriented quantization-aware architecture search framework for ViTs, to design efficient ViT models for hardware implementation while preserving the accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible mixed-precision quantization scheme, mixed-precision weight entanglement, and supernet layer scaling techniques. Then, it applies an efficient hardware-oriented search algorithm, integrated with hardware latency and resource modeling, to determine a series of optimal subnets from supernet under different inference latency targets. Finally, we propose a series of model-adaptive designs on the FPGA platform to support the architecture search and mitigate the gap between the theoretical computation reduction and the practical inference speedup. Our searched models achieve 101.5, 159.6, and 251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet dataset, consistently outperforming prior works.","sentences":["Vision transformers (ViTs) have demonstrated their superior accuracy for computer vision tasks compared to convolutional neural networks (CNNs).","However, ViT models are often computation-intensive for efficient deployment on resource-limited edge devices.","This work proposes Quasar-ViT, a hardware-oriented quantization-aware architecture search framework for ViTs, to design efficient ViT models for hardware implementation while preserving the accuracy.","First, Quasar-ViT trains a supernet using our row-wise flexible mixed-precision quantization scheme, mixed-precision weight entanglement, and supernet layer scaling techniques.","Then, it applies an efficient hardware-oriented search algorithm, integrated with hardware latency and resource modeling, to determine a series of optimal subnets from supernet under different inference latency targets.","Finally, we propose a series of model-adaptive designs on the FPGA platform to support the architecture search and mitigate the gap between the theoretical computation reduction and the practical inference speedup.","Our searched models achieve 101.5, 159.6, and 251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet dataset, consistently outperforming prior works."],"url":"http://arxiv.org/abs/2407.18175v1"}
{"created":"2024-07-25 16:33:35","title":"RIDA: A Robust Attack Framework on Incomplete Graphs","abstract":"Graph Neural Networks (GNNs) are vital in data science but are increasingly susceptible to adversarial attacks. To help researchers develop more robust GNN models, it's essential to focus on designing strong attack models as foundational benchmarks and guiding references. Among adversarial attacks, gray-box poisoning attacks are noteworthy due to their effectiveness and fewer constraints. These attacks exploit GNNs' need for retraining on updated data, thereby impacting their performance by perturbing these datasets. However, current research overlooks the real-world scenario of incomplete graphs.To address this gap, we introduce the Robust Incomplete Deep Attack Framework (RIDA). It is the first algorithm for robust gray-box poisoning attacks on incomplete graphs. The approach innovatively aggregates distant vertex information and ensures powerful data utilization.Extensive tests against 9 SOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in handling incompleteness and high attack performance on the incomplete graph.","sentences":["Graph Neural Networks (GNNs) are vital in data science but are increasingly susceptible to adversarial attacks.","To help researchers develop more robust GNN models, it's essential to focus on designing strong attack models as foundational benchmarks and guiding references.","Among adversarial attacks, gray-box poisoning attacks are noteworthy due to their effectiveness and fewer constraints.","These attacks exploit GNNs' need for retraining on updated data, thereby impacting their performance by perturbing these datasets.","However, current research overlooks the real-world scenario of incomplete graphs.","To address this gap, we introduce the Robust Incomplete Deep Attack Framework (RIDA).","It is the first algorithm for robust gray-box poisoning attacks on incomplete graphs.","The approach innovatively aggregates distant vertex information and ensures powerful data utilization.","Extensive tests against 9 SOTA baselines on 3 real-world datasets demonstrate RIDA's superiority in handling incompleteness and high attack performance on the incomplete graph."],"url":"http://arxiv.org/abs/2407.18170v1"}
{"created":"2024-07-25 16:32:35","title":"In Search of Metrics to Guide Developer-Based Refactoring Recommendations","abstract":"Context. Source code refactoring is a well-established approach to improving source code quality without compromising its external behavior. Motivation. The literature described the benefits of refactoring, yet its application in practice is threatened by the high cost of time, resource allocation, and effort required to perform it continuously. Providing refactoring recommendations closer to what developers perceive as relevant may support the broader application of refactoring in practice and drive prioritization efforts. Aim. In this paper, we aim to foster the design of a developer-based refactoring recommender, proposing an empirical study into the metrics that study the developer's willingness to apply refactoring operations. We build upon previous work describing the developer's motivations for refactoring and investigate how product and process metrics may grasp those motivations. Expected Results. We will quantify the value of product and process metrics in grasping developers' motivations to perform refactoring, thus providing a catalog of metrics for developer-based refactoring recommenders to use.","sentences":["Context.","Source code refactoring is a well-established approach to improving source code quality without compromising its external behavior.","Motivation.","The literature described the benefits of refactoring, yet its application in practice is threatened by the high cost of time, resource allocation, and effort required to perform it continuously.","Providing refactoring recommendations closer to what developers perceive as relevant may support the broader application of refactoring in practice and drive prioritization efforts.","Aim.","In this paper, we aim to foster the design of a developer-based refactoring recommender, proposing an empirical study into the metrics that study the developer's willingness to apply refactoring operations.","We build upon previous work describing the developer's motivations for refactoring and investigate how product and process metrics may grasp those motivations.","Expected Results.","We will quantify the value of product and process metrics in grasping developers' motivations to perform refactoring, thus providing a catalog of metrics for developer-based refactoring recommenders to use."],"url":"http://arxiv.org/abs/2407.18169v1"}
{"created":"2024-07-25 16:11:56","title":"Enhanced Privacy Bound for Shuffle Model with Personalized Privacy","abstract":"The shuffle model of Differential Privacy (DP) is an enhanced privacy protocol which introduces an intermediate trusted server between local users and a central data curator. It significantly amplifies the central DP guarantee by anonymizing and shuffling the local randomized data. Yet, deriving a tight privacy bound is challenging due to its complicated randomization protocol. While most existing work are focused on unified local privacy settings, this work focuses on deriving the central privacy bound for a more practical setting where personalized local privacy is required by each user. To bound the privacy after shuffling, we first need to capture the probability of each user generating clones of the neighboring data points. Second, we need to quantify the indistinguishability between two distributions of the number of clones on neighboring datasets. Existing works either inaccurately capture the probability, or underestimate the indistinguishability between neighboring datasets. Motivated by this, we develop a more precise analysis, which yields a general and tighter bound for arbitrary DP mechanisms. Firstly, we derive the clone-generating probability by hypothesis testing %from a randomizer-specific perspective, which leads to a more accurate characterization of the probability. Secondly, we analyze the indistinguishability in the context of $f$-DP, where the convexity of the distributions is leveraged to achieve a tighter privacy bound. Theoretical and numerical results demonstrate that our bound remarkably outperforms the existing results in the literature.","sentences":["The shuffle model of Differential Privacy (DP) is an enhanced privacy protocol which introduces an intermediate trusted server between local users and a central data curator.","It significantly amplifies the central DP guarantee by anonymizing and shuffling the local randomized data.","Yet, deriving a tight privacy bound is challenging due to its complicated randomization protocol.","While most existing work are focused on unified local privacy settings, this work focuses on deriving the central privacy bound for a more practical setting where personalized local privacy is required by each user.","To bound the privacy after shuffling, we first need to capture the probability of each user generating clones of the neighboring data points.","Second, we need to quantify the indistinguishability between two distributions of the number of clones on neighboring datasets.","Existing works either inaccurately capture the probability, or underestimate the indistinguishability between neighboring datasets.","Motivated by this, we develop a more precise analysis, which yields a general and tighter bound for arbitrary DP mechanisms.","Firstly, we derive the clone-generating probability by hypothesis testing %from a randomizer-specific perspective, which leads to a more accurate characterization of the probability.","Secondly, we analyze the indistinguishability in the context of $f$-DP, where the convexity of the distributions is leveraged to achieve a tighter privacy bound.","Theoretical and numerical results demonstrate that our bound remarkably outperforms the existing results in the literature."],"url":"http://arxiv.org/abs/2407.18157v1"}
{"created":"2024-07-25 16:07:49","title":"Test2VA: Reusing GUI Test Cases for Voice Assistant Features Development in Mobile Applications","abstract":"Voice Assistant (VA) in smartphones has become very popular with millions of users nowadays. A key trend is the rise of custom VA embedding, which enables users to perform the customized tasks of their favorite app through voice control. However, with such a great demand, little effort has been made to support app developers in VA development. Moreover, many user-oriented VA control approaches even increase the programming burden on developers. To reduce the workload and improve code efficiency, in this paper, we propose a novel approach, Test2VA, that reuses the test code of an application to support its VA development. Specifically, Test2VA extracts the task completion pattern from the GUI test code and then generates an execution method to perform the same task in general. To identify the pattern, Test2VA uses a mutation-based exploration to detect the mutable GUI event in the test case and later parameterize it in the VA method. We conducted an evaluation on 48 test cases from eight real-world applications. The results show that Test2VA correctly detects 75.68% of the mutable events from 48 original test cases and then generates 33 methods and have them successfully executed and manually examined.","sentences":["Voice Assistant (VA) in smartphones has become very popular with millions of users nowadays.","A key trend is the rise of custom VA embedding, which enables users to perform the customized tasks of their favorite app through voice control.","However, with such a great demand, little effort has been made to support app developers in VA development.","Moreover, many user-oriented VA control approaches even increase the programming burden on developers.","To reduce the workload and improve code efficiency, in this paper, we propose a novel approach, Test2VA, that reuses the test code of an application to support its VA development.","Specifically, Test2VA extracts the task completion pattern from the GUI test code and then generates an execution method to perform the same task in general.","To identify the pattern, Test2VA uses a mutation-based exploration to detect the mutable GUI event in the test case and later parameterize it in the VA method.","We conducted an evaluation on 48 test cases from eight real-world applications.","The results show that Test2VA correctly detects 75.68% of the mutable events from 48 original test cases and then generates 33 methods and have them successfully executed and manually examined."],"url":"http://arxiv.org/abs/2407.18155v1"}
{"created":"2024-07-25 15:58:56","title":"StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests","abstract":"The life cycle of machine learning (ML) applications consists of two stages: model development and model deployment. However, traditional ML systems (e.g., training-specific or inference-specific systems) focus on one particular stage or phase of the life cycle of ML applications. These systems often aim at optimizing model training or accelerating model inference, and they frequently assume homogeneous infrastructure, which may not always reflect real-world scenarios that include cloud data centers, local servers, containers, and serverless platforms. We present StraightLine, an end-to-end resource-aware scheduler that schedules the optimal resources (e.g., container, virtual machine, or serverless) for different ML application requests in a hybrid infrastructure. The key innovation is an empirical dynamic placing algorithm that intelligently places requests based on their unique characteristics (e.g., request frequency, input data size, and data distribution). In contrast to existing ML systems, StraightLine offers end-to-end resource-aware placement, thereby it can significantly reduce response time and failure rate for model deployment when facing different computing resources in the hybrid infrastructure.","sentences":["The life cycle of machine learning (ML) applications consists of two stages: model development and model deployment.","However, traditional ML systems (e.g., training-specific or inference-specific systems) focus on one particular stage or phase of the life cycle of ML applications.","These systems often aim at optimizing model training or accelerating model inference, and they frequently assume homogeneous infrastructure, which may not always reflect real-world scenarios that include cloud data centers, local servers, containers, and serverless platforms.","We present StraightLine, an end-to-end resource-aware scheduler that schedules the optimal resources (e.g., container, virtual machine, or serverless) for different ML application requests in a hybrid infrastructure.","The key innovation is an empirical dynamic placing algorithm that intelligently places requests based on their unique characteristics (e.g., request frequency, input data size, and data distribution).","In contrast to existing ML systems, StraightLine offers end-to-end resource-aware placement, thereby it can significantly reduce response time and failure rate for model deployment when facing different computing resources in the hybrid infrastructure."],"url":"http://arxiv.org/abs/2407.18148v1"}
{"created":"2024-07-25 15:58:19","title":"The FIGNEWS Shared Task on News Media Narratives","abstract":"We present an overview of the FIGNEWS shared task, organized as part of the ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses bias and propaganda annotation in multilingual news posts. We focus on the early days of the Israel War on Gaza as a case study. The task aims to foster collaboration in developing annotation guidelines for subjective tasks by creating frameworks for analyzing diverse narratives highlighting potential bias and propaganda. In a spirit of fostering and encouraging diversity, we address the problem from a multilingual perspective, namely within five languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams participated in two annotation subtasks: bias (16 teams) and propaganda (6 teams). The teams competed in four evaluation tracks: guidelines development, annotation quality, annotation quantity, and consistency. Collectively, the teams produced 129,800 data points. Key findings and implications for the field are discussed.","sentences":["We present an overview of the FIGNEWS shared task, organized as part of the ArabicNLP 2024 conference co-located with ACL 2024.","The shared task addresses bias and propaganda annotation in multilingual news posts.","We focus on the early days of the Israel War on Gaza as a case study.","The task aims to foster collaboration in developing annotation guidelines for subjective tasks by creating frameworks for analyzing diverse narratives highlighting potential bias and propaganda.","In a spirit of fostering and encouraging diversity, we address the problem from a multilingual perspective, namely within five languages: English, French, Arabic, Hebrew, and Hindi.","A total of 17 teams participated in two annotation subtasks: bias (16 teams) and propaganda (6 teams).","The teams competed in four evaluation tracks: guidelines development, annotation quality, annotation quantity, and consistency.","Collectively, the teams produced 129,800 data points.","Key findings and implications for the field are discussed."],"url":"http://arxiv.org/abs/2407.18147v1"}
{"created":"2024-07-25 15:52:39","title":"Adaptable Deep Joint Source-and-Channel Coding for Small Satellite Applications","abstract":"Earth observation with small satellites serves a wide range of relevant applications. However, significant advances in sensor technology (e.g., higher resolution, multiple spectrums beyond visible light) in combination with challenging channel characteristics lead to a communication bottleneck when transmitting the collected data to Earth. Recently, joint source coding, channel coding, and modulation based on neuronal networks has been proposed to combine image compression and communication. Though this approach achieves promising results when applied to standard terrestrial channel models, it remains an open question whether it is suitable for the more complicated and quickly varying satellite communication channel. In this paper, we consider a detailed satellite channel model accounting for different shadowing conditions and train an encoder-decoder architecture with realistic Sentinel-2 satellite imagery. In addition, to reduce the overhead associated with applying multiple neural networks for various channel states, we leverage attention modules and train a single adaptable neural network that covers a wide range of different channel conditions. Our evaluation results show that the proposed approach achieves similar performance when compared to less space-efficient schemes that utilize separate neuronal networks for differing channel conditions.","sentences":["Earth observation with small satellites serves a wide range of relevant applications.","However, significant advances in sensor technology (e.g., higher resolution, multiple spectrums beyond visible light) in combination with challenging channel characteristics lead to a communication bottleneck when transmitting the collected data to Earth.","Recently, joint source coding, channel coding, and modulation based on neuronal networks has been proposed to combine image compression and communication.","Though this approach achieves promising results when applied to standard terrestrial channel models, it remains an open question whether it is suitable for the more complicated and quickly varying satellite communication channel.","In this paper, we consider a detailed satellite channel model accounting for different shadowing conditions and train an encoder-decoder architecture with realistic Sentinel-2 satellite imagery.","In addition, to reduce the overhead associated with applying multiple neural networks for various channel states, we leverage attention modules and train a single adaptable neural network that covers a wide range of different channel conditions.","Our evaluation results show that the proposed approach achieves similar performance when compared to less space-efficient schemes that utilize separate neuronal networks for differing channel conditions."],"url":"http://arxiv.org/abs/2407.18146v1"}
{"created":"2024-07-25 15:49:26","title":"Taxonomy-Aware Continual Semantic Segmentation in Hyperbolic Spaces for Open-World Perception","abstract":"Semantic segmentation models are typically trained on a fixed set of classes, limiting their applicability in open-world scenarios. Class-incremental semantic segmentation aims to update models with emerging new classes while preventing catastrophic forgetting of previously learned ones. However, existing methods impose strict rigidity on old classes, reducing their effectiveness in learning new incremental classes. In this work, we propose Taxonomy-Oriented Poincar\\'e-regularized Incremental-Class Segmentation (TOPICS) that learns feature embeddings in hyperbolic space following explicit taxonomy-tree structures. This supervision provides plasticity for old classes, updating ancestors based on new classes while integrating new classes at fitting positions. Additionally, we maintain implicit class relational constraints on the geometric basis of the Poincar\\'e ball. This ensures that the latent space can continuously adapt to new constraints while maintaining a robust structure to combat catastrophic forgetting. We also establish eight realistic incremental learning protocols for autonomous driving scenarios, where novel classes can originate from known classes or the background. Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0 benchmarks demonstrate that it achieves state-of-the-art performance. We make the code and trained models publicly available at http://topics.cs.uni-freiburg.de.","sentences":["Semantic segmentation models are typically trained on a fixed set of classes, limiting their applicability in open-world scenarios.","Class-incremental semantic segmentation aims to update models with emerging new classes while preventing catastrophic forgetting of previously learned ones.","However, existing methods impose strict rigidity on old classes, reducing their effectiveness in learning new incremental classes.","In this work, we propose Taxonomy-Oriented Poincar\\'e-regularized Incremental-Class Segmentation (TOPICS) that learns feature embeddings in hyperbolic space following explicit taxonomy-tree structures.","This supervision provides plasticity for old classes, updating ancestors based on new classes while integrating new classes at fitting positions.","Additionally, we maintain implicit class relational constraints on the geometric basis of the Poincar\\'e ball.","This ensures that the latent space can continuously adapt to new constraints while maintaining a robust structure to combat catastrophic forgetting.","We also establish eight realistic incremental learning protocols for autonomous driving scenarios, where novel classes can originate from known classes or the background.","Extensive evaluations of TOPICS on the Cityscapes and Mapillary Vistas 2.0 benchmarks demonstrate that it achieves state-of-the-art performance.","We make the code and trained models publicly available at http://topics.cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2407.18145v1"}
{"created":"2024-07-25 15:48:24","title":"Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation","abstract":"Entropy Regularisation is a widely adopted technique that enhances policy optimisation performance and stability. A notable form of entropy regularisation is augmenting the objective with an entropy term, thereby simultaneously optimising the expected return and the entropy. This framework, known as maximum entropy reinforcement learning (MaxEnt RL), has shown theoretical and empirical successes. However, its practical application in straightforward on-policy actor-critic settings remains surprisingly underexplored. We hypothesise that this is due to the difficulty of managing the entropy reward in practice. This paper proposes a simple method of separating the entropy objective from the MaxEnt RL objective, which facilitates the implementation of MaxEnt RL in on-policy settings. Our empirical evaluations demonstrate that extending Proximal Policy Optimisation (PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework improves policy optimisation performance in both MuJoCo and Procgen tasks. Additionally, our results highlight MaxEnt RL's capacity to enhance generalisation.","sentences":["Entropy Regularisation is a widely adopted technique that enhances policy optimisation performance and stability.","A notable form of entropy regularisation is augmenting the objective with an entropy term, thereby simultaneously optimising the expected return and the entropy.","This framework, known as maximum entropy reinforcement learning (MaxEnt RL), has shown theoretical and empirical successes.","However, its practical application in straightforward on-policy actor-critic settings remains surprisingly underexplored.","We hypothesise that this is due to the difficulty of managing the entropy reward in practice.","This paper proposes a simple method of separating the entropy objective from the MaxEnt RL objective, which facilitates the implementation of MaxEnt RL in on-policy settings.","Our empirical evaluations demonstrate that extending Proximal Policy Optimisation (PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework improves policy optimisation performance in both MuJoCo and Procgen tasks.","Additionally, our results highlight MaxEnt RL's capacity to enhance generalisation."],"url":"http://arxiv.org/abs/2407.18143v1"}
{"created":"2024-07-25 15:45:17","title":"IRIS: Wireless Ring for Vision-based Smart Home Interaction","abstract":"Integrating cameras into wireless smart rings has been challenging due to size and power constraints. We introduce IRIS, the first wireless vision-enabled smart ring system for smart home interactions. Equipped with a camera, Bluetooth radio, inertial measurement unit (IMU), and an onboard battery, IRIS meets the small size, weight, and power (SWaP) requirements for ring devices. IRIS is context-aware, adapting its gesture set to the detected device, and can last for 16-24 hours on a single charge. IRIS leverages the scene semantics to achieve instance-level device recognition. In a study involving 23 participants, IRIS consistently outpaced voice commands, with a higher proportion of participants expressing a preference for IRIS over voice commands regarding toggling a device's state, granular control, and social acceptability. Our work pushes the boundary of what is possible with ring form-factor devices, addressing system challenges and opening up novel interaction capabilities.","sentences":["Integrating cameras into wireless smart rings has been challenging due to size and power constraints.","We introduce IRIS, the first wireless vision-enabled smart ring system for smart home interactions.","Equipped with a camera, Bluetooth radio, inertial measurement unit (IMU), and an onboard battery, IRIS meets the small size, weight, and power (SWaP) requirements for ring devices.","IRIS is context-aware, adapting its gesture set to the detected device, and can last for 16-24 hours on a single charge.","IRIS leverages the scene semantics to achieve instance-level device recognition.","In a study involving 23 participants, IRIS consistently outpaced voice commands, with a higher proportion of participants expressing a preference for IRIS over voice commands regarding toggling a device's state, granular control, and social acceptability.","Our work pushes the boundary of what is possible with ring form-factor devices, addressing system challenges and opening up novel interaction capabilities."],"url":"http://arxiv.org/abs/2407.18141v1"}
{"created":"2024-07-25 15:44:06","title":"Influence Vectors Control for Robots Using Cellular-like Binary Actuators","abstract":"Robots using cellular-like redundant binary actuators could outmatch electric-gearmotor robotic systems in terms of reliability, force-to-weight ratio and cost. This paper presents a robust fault tolerant control scheme that is designed to meet the control challenges encountered by such robots, i.e., discrete actuator inputs, complex system modeling and cross-coupling between actuators. In the proposed scheme, a desired vectorial system output, such as a position or a force, is commanded by recruiting actuators based on their influence vectors on the output. No analytical model of the system is needed; influence vectors are identified experimentally by sequentially activating each actuator. For position control tasks, the controller uses a probabilistic approach and a genetic algorithm to determine an optimal combination of actuators to recruit. For motion control tasks, the controller uses a sliding mode approach and independent recruiting decision for each actuator. Experimental results on a four degrees of freedom binary manipulator with twenty actuators confirm the method's effectiveness, and its ability to tolerate massive perturbations and numerous actuator failures.","sentences":["Robots using cellular-like redundant binary actuators could outmatch electric-gearmotor robotic systems in terms of reliability, force-to-weight ratio and cost.","This paper presents a robust fault tolerant control scheme that is designed to meet the control challenges encountered by such robots, i.e., discrete actuator inputs, complex system modeling and cross-coupling between actuators.","In the proposed scheme, a desired vectorial system output, such as a position or a force, is commanded by recruiting actuators based on their influence vectors on the output.","No analytical model of the system is needed; influence vectors are identified experimentally by sequentially activating each actuator.","For position control tasks, the controller uses a probabilistic approach and a genetic algorithm to determine an optimal combination of actuators to recruit.","For motion control tasks, the controller uses a sliding mode approach and independent recruiting decision for each actuator.","Experimental results on a four degrees of freedom binary manipulator with twenty actuators confirm the method's effectiveness, and its ability to tolerate massive perturbations and numerous actuator failures."],"url":"http://arxiv.org/abs/2407.18140v1"}
{"created":"2024-07-25 15:42:46","title":"XS-VID: An Extremely Small Video Object Detection Dataset","abstract":"Small Video Object Detection (SVOD) is a crucial subfield in modern computer vision, essential for early object discovery and detection. However, existing SVOD datasets are scarce and suffer from issues such as insufficiently small objects, limited object categories, and lack of scene diversity, leading to unitary application scenarios for corresponding methods. To address this gap, we develop the XS-VID dataset, which comprises aerial data from various periods and scenes, and annotates eight major object categories. To further evaluate existing methods for detecting extremely small objects, XS-VID extensively collects three types of objects with smaller pixel areas: extremely small (\\textit{es}, $0\\sim12^2$), relatively small (\\textit{rs}, $12^2\\sim20^2$), and generally small (\\textit{gs}, $20^2\\sim32^2$). XS-VID offers unprecedented breadth and depth in covering and quantifying minuscule objects, significantly enriching the scene and object diversity in the dataset. Extensive validations on XS-VID and the publicly available VisDrone2019VID dataset show that existing methods struggle with small object detection and significantly underperform compared to general object detectors. Leveraging the strengths of previous methods and addressing their weaknesses, we propose YOLOFT, which enhances local feature associations and integrates temporal motion features, significantly improving the accuracy and stability of SVOD. Our datasets and benchmarks are available at \\url{https://gjhhust.github.io/XS-VID/}.","sentences":["Small Video Object Detection (SVOD) is a crucial subfield in modern computer vision, essential for early object discovery and detection.","However, existing SVOD datasets are scarce and suffer from issues such as insufficiently small objects, limited object categories, and lack of scene diversity, leading to unitary application scenarios for corresponding methods.","To address this gap, we develop the XS-VID dataset, which comprises aerial data from various periods and scenes, and annotates eight major object categories.","To further evaluate existing methods for detecting extremely small objects, XS-VID extensively collects three types of objects with smaller pixel areas: extremely small (\\textit{es}, $0\\sim12^2$), relatively small (\\textit{rs}, $12^2\\sim20^2$), and generally small (\\textit{gs}, $20^2\\sim32^2$).","XS-VID offers unprecedented breadth and depth in covering and quantifying minuscule objects, significantly enriching the scene and object diversity in the dataset.","Extensive validations on XS-VID and the publicly available VisDrone2019VID dataset show that existing methods struggle with small object detection and significantly underperform compared to general object detectors.","Leveraging the strengths of previous methods and addressing their weaknesses, we propose YOLOFT, which enhances local feature associations and integrates temporal motion features, significantly improving the accuracy and stability of SVOD.","Our datasets and benchmarks are available at \\url{https://gjhhust.github.io/XS-VID/}."],"url":"http://arxiv.org/abs/2407.18137v1"}
{"created":"2024-07-25 15:38:16","title":"$\\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs","abstract":"Learning good representations involves capturing the diverse ways in which data samples relate. Contrastive loss - an objective matching related samples - underlies methods from self-supervised to multimodal learning. Contrastive losses, however, can be viewed more broadly as modifying a similarity graph to indicate how samples should relate in the embedding space. This view reveals a shortcoming in contrastive learning: the similarity graph is binary, as only one sample is the related positive sample. Crucially, similarities \\textit{across} samples are ignored. Based on this observation, we revise the standard contrastive loss to explicitly encode how a sample relates to others. We experiment with this new objective, called $\\mathbb{X}$-Sample Contrastive, to train vision models based on similarities in class or text caption descriptions. Our study spans three scales: ImageNet-1k with 1 million, CC3M with 3 million, and CC12M with 12 million samples. The representations learned via our objective outperform both contrastive self-supervised and vision-language models trained on the same data across a range of tasks. When training on CC12M, we outperform CLIP by $0.6\\%$ on both ImageNet and ImageNet Real. Our objective appears to work particularly well in lower-data regimes, with gains over CLIP of $16.8\\%$ on ImageNet and $18.1\\%$ on ImageNet Real when training with CC3M. Finally, our objective seems to encourage the model to learn representations that separate objects from their attributes and backgrounds, with gains of $3.3$-$5.6$\\% over CLIP on ImageNet9. We hope the proposed solution takes a small step towards developing richer learning objectives for understanding sample relations in foundation models.","sentences":["Learning good representations involves capturing the diverse ways in which data samples relate.","Contrastive loss - an objective matching related samples - underlies methods from self-supervised to multimodal learning.","Contrastive losses, however, can be viewed more broadly as modifying a similarity graph to indicate how samples should relate in the embedding space.","This view reveals a shortcoming in contrastive learning: the similarity graph is binary, as only one sample is the related positive sample.","Crucially, similarities \\textit{across} samples are ignored.","Based on this observation, we revise the standard contrastive loss to explicitly encode how a sample relates to others.","We experiment with this new objective, called $\\mathbb{X}$-Sample Contrastive, to train vision models based on similarities in class or text caption descriptions.","Our study spans three scales: ImageNet-1k with 1 million, CC3M with 3 million, and CC12M with 12 million samples.","The representations learned via our objective outperform both contrastive self-supervised and vision-language models trained on the same data across a range of tasks.","When training on CC12M, we outperform CLIP by $0.6\\%$ on both ImageNet and ImageNet Real.","Our objective appears to work particularly well in lower-data regimes, with gains over CLIP of $16.8\\%$ on ImageNet and $18.1\\%$ on ImageNet Real when training with CC3M. Finally, our objective seems to encourage the model to learn representations that separate objects from their attributes and backgrounds, with gains of $3.3$-$5.6$\\% over CLIP on ImageNet9.","We hope the proposed solution takes a small step towards developing richer learning objectives for understanding sample relations in foundation models."],"url":"http://arxiv.org/abs/2407.18134v1"}
{"created":"2024-07-25 15:37:26","title":"Reachability for Multi-Priced Timed Automata with Positive and Negative Rates","abstract":"Multi-priced timed automata (MPTA) are timed automata with observer   variables whose derivatives can change from one location to another.   Observers are write-only variables, that is, they do not affect the control   flow of the automaton; thus MPTA lie between timed and hybrid   automata in expressiveness. Previous work considered observers with   non-negative slope in every location. In this paper we treat   observers that have both positive and negative rates. Our   main result is an algorithm to decide a gap version of the   reachability problem for this variant of MPTA. We translate the   gap reachability problem into a gap satisfiability problem for mixed   integer-real systems of nonlinear constraints. Our main technical   contribution -- a result of independent interest -- is a procedure   to solve such contraints via a combination of branch-and-bound   and relaxation-and-rounding.","sentences":["Multi-priced timed automata (MPTA) are timed automata with observer   variables whose derivatives can change from one location to another.   ","Observers are write-only variables, that is, they do not affect the control   flow of the automaton; thus MPTA lie between timed and hybrid   automata in expressiveness.","Previous work considered observers with   non-negative slope in every location.","In this paper we treat   observers that have both positive and negative rates.","Our   main result is an algorithm to decide a gap version of the   reachability problem for this variant of MPTA.","We translate the   gap reachability problem into a gap satisfiability problem for mixed   integer-real systems of nonlinear constraints.","Our main technical   contribution -- a result of independent interest -- is a procedure   to solve such contraints via a combination of branch-and-bound   and relaxation-and-rounding."],"url":"http://arxiv.org/abs/2407.18131v1"}
{"created":"2024-07-25 15:36:48","title":"Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic","abstract":"Recent advancements have significantly enhanced the capabilities of Multimodal Large Language Models (MLLMs) in generating and understanding image-to-text content. Despite these successes, progress is predominantly limited to English due to the scarcity of high quality multimodal resources in other languages. This limitation impedes the development of competitive models in languages such as Arabic. To alleviate this situation, we introduce an efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced language model based on LLaMA-2 to facilitate multimodal interactions. Dallah demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning six Arabic dialects, Dallah showcases its capability to handle complex dialectal interactions incorporating both textual and visual elements. The model excels in two benchmark tests: one evaluating its performance on Modern Standard Arabic (MSA) and another specifically designed to assess dialectal responses. Beyond its robust performance in multimodal interaction tasks, Dallah has the potential to pave the way for further development of dialect-aware Arabic MLLMs.","sentences":["Recent advancements have significantly enhanced the capabilities of Multimodal Large Language Models (MLLMs) in generating and understanding image-to-text content.","Despite these successes, progress is predominantly limited to English due to the scarcity of high quality multimodal resources in other languages.","This limitation impedes the development of competitive models in languages such as Arabic.","To alleviate this situation, we introduce an efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced language model based on LLaMA-2 to facilitate multimodal interactions.","Dallah demonstrates state-of-the-art performance in Arabic MLLMs.","Through fine-tuning six Arabic dialects, Dallah showcases its capability to handle complex dialectal interactions incorporating both textual and visual elements.","The model excels in two benchmark tests: one evaluating its performance on Modern Standard Arabic (MSA) and another specifically designed to assess dialectal responses.","Beyond its robust performance in multimodal interaction tasks, Dallah has the potential to pave the way for further development of dialect-aware Arabic MLLMs."],"url":"http://arxiv.org/abs/2407.18129v1"}
{"created":"2024-07-25 15:35:44","title":"Estimating Earthquake Magnitude in Sentinel-1 Imagery via Ranking","abstract":"Earthquakes are commonly estimated using physical seismic stations, however, due to the installation requirements and costs of these stations, global coverage quickly becomes impractical. An efficient and lower-cost alternative is to develop machine learning models to globally monitor earth observation data to pinpoint regions impacted by these natural disasters. However, due to the small amount of historically recorded earthquakes, this becomes a low-data regime problem requiring algorithmic improvements to achieve peak performance when learning to regress earthquake magnitude. In this paper, we propose to pose the estimation of earthquake magnitudes as a metric-learning problem, training models to not only estimate earthquake magnitude from Sentinel-1 satellite imagery but to additionally rank pairwise samples. Our experiments show at max a 30%+ improvement in MAE over prior regression-only based methods, particularly transformer-based architectures.","sentences":["Earthquakes are commonly estimated using physical seismic stations, however, due to the installation requirements and costs of these stations, global coverage quickly becomes impractical.","An efficient and lower-cost alternative is to develop machine learning models to globally monitor earth observation data to pinpoint regions impacted by these natural disasters.","However, due to the small amount of historically recorded earthquakes, this becomes a low-data regime problem requiring algorithmic improvements to achieve peak performance when learning to regress earthquake magnitude.","In this paper, we propose to pose the estimation of earthquake magnitudes as a metric-learning problem, training models to not only estimate earthquake magnitude from Sentinel-1 satellite imagery but to additionally rank pairwise samples.","Our experiments show at max a 30%+ improvement in MAE over prior regression-only based methods, particularly transformer-based architectures."],"url":"http://arxiv.org/abs/2407.18128v1"}
{"created":"2024-07-25 15:32:59","title":"Self-supervised pre-training with diffusion model for few-shot landmark detection in x-ray images","abstract":"In the last few years, deep neural networks have been extensively applied in the medical domain for different tasks, ranging from image classification and segmentation to landmark detection. However, the application of these technologies in the medical domain is often hindered by data scarcity, both in terms of available annotations and images. This study introduces a new self-supervised pre-training protocol based on diffusion models for landmark detection in x-ray images. Our results show that the proposed self-supervised framework can provide accurate landmark detection with a minimal number of available annotated training images (up to 50), outperforming ImageNet supervised pre-training and state-of-the-art self-supervised pre-trainings for three popular x-ray benchmark datasets. To our knowledge, this is the first exploration of diffusion models for self-supervised learning in landmark detection, which may offer a valuable pre-training approach in few-shot regimes, for mitigating data scarcity.","sentences":["In the last few years, deep neural networks have been extensively applied in the medical domain for different tasks, ranging from image classification and segmentation to landmark detection.","However, the application of these technologies in the medical domain is often hindered by data scarcity, both in terms of available annotations and images.","This study introduces a new self-supervised pre-training protocol based on diffusion models for landmark detection in x-ray images.","Our results show that the proposed self-supervised framework can provide accurate landmark detection with a minimal number of available annotated training images (up to 50), outperforming ImageNet supervised pre-training and state-of-the-art self-supervised pre-trainings for three popular x-ray benchmark datasets.","To our knowledge, this is the first exploration of diffusion models for self-supervised learning in landmark detection, which may offer a valuable pre-training approach in few-shot regimes, for mitigating data scarcity."],"url":"http://arxiv.org/abs/2407.18125v1"}
{"created":"2024-07-25 15:31:38","title":"PIR Codes, Unequal-Data-Demand Codes, and the Griesmer Bound","abstract":"Unequal Error-Protecting (UEP) codes are error-correcting (EC) codes designed to protect some parts of the encoded data better than other parts. Here, we introduce a similar generalization of PIR codes that we call Unequal-Data-Demand (UDD) PIR codes. These codes are PIR-type codes designed for the scenario where some parts of the encoded data are in higher demand than other parts. We generalize various results for PIR codes to UDD codes. Our main contribution is a new approach to the Griesmer bound for linear EC codes involving an Integer Linear Programming (ILP) problem that generalizes to linear UEP codes and linear UDD PIR codes.","sentences":["Unequal Error-Protecting (UEP) codes are error-correcting (EC) codes designed to protect some parts of the encoded data better than other parts.","Here, we introduce a similar generalization of PIR codes that we call Unequal-Data-Demand (UDD)","PIR codes.","These codes are PIR-type codes designed for the scenario where some parts of the encoded data are in higher demand than other parts.","We generalize various results for PIR codes to UDD codes.","Our main contribution is a new approach to the Griesmer bound for linear EC codes involving an Integer Linear Programming (ILP) problem that generalizes to linear UEP codes and linear UDD PIR codes."],"url":"http://arxiv.org/abs/2407.18124v1"}
{"created":"2024-07-25 15:29:14","title":"On de Bruijn Arrays Codes, Part I: Nonlinear Codes","abstract":"A de Bruijn arrays code is a set of $r \\times s$ binary doubly-periodic arrays such that each binary $n \\times m$ matrix is contained exactly once as a window in one of the arrays. Such a set of arrays can be viewed as a two-dimensional generalization of a perfect factor in the de Bruijn graph. Necessary conditions for the existence of such arrays are given. Several direct constructions and recursive constructions for such arrays are given. A framework for a theory of two-dimensional feedback shift register which is akin to (one-dimensional) feedback shift registers is suggested.","sentences":["A de Bruijn arrays code is a set of $r \\times s$ binary doubly-periodic arrays such that each binary $n \\times m$ matrix is contained exactly once as a window in one of the arrays.","Such a set of arrays can be viewed as a two-dimensional generalization of a perfect factor in the de Bruijn graph.","Necessary conditions for the existence of such arrays are given.","Several direct constructions and recursive constructions for such arrays are given.","A framework for a theory of two-dimensional feedback shift register which is akin to (one-dimensional) feedback shift registers is suggested."],"url":"http://arxiv.org/abs/2407.18122v1"}
{"created":"2024-07-25 15:29:05","title":"Efficient Inference of Vision Instruction-Following Models with Elastic Cache","abstract":"In the field of instruction-following large vision-language models (LVLMs), the efficient deployment of these models faces challenges, notably due to the high memory demands of their key-value (KV) caches. Conventional cache management strategies for LLMs focus on cache eviction, which often fails to address the specific needs of multimodal instruction-following models. Recognizing this gap, in this paper, we introduce Elastic Cache, a novel approach that benefits from applying distinct acceleration methods for instruction encoding and output generation stages. We investigate the metrics of importance in different stages and propose an importance-driven cache merging strategy to prune redundancy caches. Instead of discarding less important caches, our strategy identifies important key/value vectors as anchor points. Surrounding less important caches are then merged with these anchors, enhancing the preservation of contextual information in the KV caches while yielding an arbitrary acceleration ratio. For instruction encoding, we utilize the frequency to evaluate the importance of caches. Regarding output generation, we prioritize tokens based on their distance with an offset, by which both the initial and most recent tokens are retained. Results on a range of LVLMs demonstrate that Elastic Cache not only boosts efficiency but also notably outperforms existing pruning methods in language generation across various tasks. Code is available at https://github.com/liuzuyan/ElasticCache","sentences":["In the field of instruction-following large vision-language models (LVLMs), the efficient deployment of these models faces challenges, notably due to the high memory demands of their key-value (KV) caches.","Conventional cache management strategies for LLMs focus on cache eviction, which often fails to address the specific needs of multimodal instruction-following models.","Recognizing this gap, in this paper, we introduce Elastic Cache, a novel approach that benefits from applying distinct acceleration methods for instruction encoding and output generation stages.","We investigate the metrics of importance in different stages and propose an importance-driven cache merging strategy to prune redundancy caches.","Instead of discarding less important caches, our strategy identifies important key/value vectors as anchor points.","Surrounding less important caches are then merged with these anchors, enhancing the preservation of contextual information in the KV caches while yielding an arbitrary acceleration ratio.","For instruction encoding, we utilize the frequency to evaluate the importance of caches.","Regarding output generation, we prioritize tokens based on their distance with an offset, by which both the initial and most recent tokens are retained.","Results on a range of LVLMs demonstrate that Elastic Cache not only boosts efficiency but also notably outperforms existing pruning methods in language generation across various tasks.","Code is available at https://github.com/liuzuyan/ElasticCache"],"url":"http://arxiv.org/abs/2407.18121v1"}
{"created":"2024-07-25 15:27:08","title":"Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification","abstract":"Analyses of transformer-based models have shown that they encode a variety of linguistic information from their textual input. While these analyses have shed a light on the relation between linguistic information on one side, and internal architecture and parameters on the other, a question remains unanswered: how is this linguistic information reflected in sentence embeddings? Using datasets consisting of sentences with known structure, we test to what degree information about chunks (in particular noun, verb or prepositional phrases), such as grammatical number, or semantic role, can be localized in sentence embeddings. Our results show that such information is not distributed over the entire sentence embedding, but rather it is encoded in specific regions. Understanding how the information from an input text is compressed into sentence embeddings helps understand current transformer models and help build future explainable neural models.","sentences":["Analyses of transformer-based models have shown that they encode a variety of linguistic information from their textual input.","While these analyses have shed a light on the relation between linguistic information on one side, and internal architecture and parameters on the other, a question remains unanswered: how is this linguistic information reflected in sentence embeddings?","Using datasets consisting of sentences with known structure, we test to what degree information about chunks (in particular noun, verb or prepositional phrases), such as grammatical number, or semantic role, can be localized in sentence embeddings.","Our results show that such information is not distributed over the entire sentence embedding, but rather it is encoded in specific regions.","Understanding how the information from an input text is compressed into sentence embeddings helps understand current transformer models and help build future explainable neural models."],"url":"http://arxiv.org/abs/2407.18119v1"}
{"created":"2024-07-25 15:21:54","title":"Unsupervised Training of Neural Cellular Automata on Edge Devices","abstract":"The disparity in access to machine learning tools for medical imaging across different regions significantly limits the potential for universal healthcare innovation, particularly in remote areas. Our research addresses this issue by implementing Neural Cellular Automata (NCA) training directly on smartphones for accessible X-ray lung segmentation. We confirm the practicality and feasibility of deploying and training these advanced models on five Android devices, improving medical diagnostics accessibility and bridging the tech divide to extend machine learning benefits in medical imaging to low- and middle-income countries (LMICs). We further enhance this approach with an unsupervised adaptation method using the novel Variance-Weighted Segmentation Loss (VWSL), which efficiently learns from unlabeled data by minimizing the variance from multiple NCA predictions. This strategy notably improves model adaptability and performance across diverse medical imaging contexts without the need for extensive computational resources or labeled datasets, effectively lowering the participation threshold. Our methodology, tested on three multisite X-ray datasets -- Padchest, ChestX-ray8, and MIMIC-III -- demonstrates improvements in segmentation Dice accuracy by 0.7 to 2.8%, compared to the classic Med-NCA. Additionally, in extreme cases where no digital copy is available and images must be captured by a phone from an X-ray lightbox or monitor, VWSL enhances Dice accuracy by 5-20%, demonstrating the method's robustness even with suboptimal image sources.","sentences":["The disparity in access to machine learning tools for medical imaging across different regions significantly limits the potential for universal healthcare innovation, particularly in remote areas.","Our research addresses this issue by implementing Neural Cellular Automata (NCA) training directly on smartphones for accessible X-ray lung segmentation.","We confirm the practicality and feasibility of deploying and training these advanced models on five Android devices, improving medical diagnostics accessibility and bridging the tech divide to extend machine learning benefits in medical imaging to low- and middle-income countries (LMICs).","We further enhance this approach with an unsupervised adaptation method using the novel Variance-Weighted Segmentation Loss (VWSL), which efficiently learns from unlabeled data by minimizing the variance from multiple NCA predictions.","This strategy notably improves model adaptability and performance across diverse medical imaging contexts without the need for extensive computational resources or labeled datasets, effectively lowering the participation threshold.","Our methodology, tested on three multisite X-ray datasets -- Padchest, ChestX-ray8, and MIMIC-III -- demonstrates improvements in segmentation Dice accuracy by 0.7 to 2.8%, compared to the classic Med-NCA.","Additionally, in extreme cases where no digital copy is available and images must be captured by a phone from an X-ray lightbox or monitor, VWSL enhances Dice accuracy by 5-20%, demonstrating the method's robustness even with suboptimal image sources."],"url":"http://arxiv.org/abs/2407.18114v1"}
{"created":"2024-07-25 15:20:58","title":"Keypoint Promptable Re-Identification","abstract":"Occluded Person Re-Identification (ReID) is a metric learning task that involves matching occluded individuals based on their appearance. While many studies have tackled occlusions caused by objects, multi-person occlusions remain less explored. In this work, we identify and address a critical challenge overlooked by previous occluded ReID methods: the Multi-Person Ambiguity (MPA) arising when multiple individuals are visible in the same bounding box, making it impossible to determine the intended ReID target among the candidates. Inspired by recent work on prompting in vision, we introduce Keypoint Promptable ReID (KPR), a novel formulation of the ReID problem that explicitly complements the input bounding box with a set of semantic keypoints indicating the intended target. Since promptable re-identification is an unexplored paradigm, existing ReID datasets lack the pixel-level annotations necessary for prompting. To bridge this gap and foster further research on this topic, we introduce Occluded-PoseTrack ReID, a novel ReID dataset with keypoints labels, that features strong inter-person occlusions. Furthermore, we release custom keypoint labels for four popular ReID benchmarks. Experiments on person retrieval, but also on pose tracking, demonstrate that our method systematically surpasses previous state-of-the-art approaches on various occluded scenarios. Our code, dataset and annotations are available at https://github.com/VlSomers/keypoint_promptable_reidentification.","sentences":["Occluded Person Re-Identification (ReID) is a metric learning task that involves matching occluded individuals based on their appearance.","While many studies have tackled occlusions caused by objects, multi-person occlusions remain less explored.","In this work, we identify and address a critical challenge overlooked by previous occluded ReID methods: the Multi-Person Ambiguity (MPA) arising when multiple individuals are visible in the same bounding box, making it impossible to determine the intended ReID target among the candidates.","Inspired by recent work on prompting in vision, we introduce Keypoint Promptable ReID (KPR), a novel formulation of the ReID problem that explicitly complements the input bounding box with a set of semantic keypoints indicating the intended target.","Since promptable re-identification is an unexplored paradigm, existing ReID datasets lack the pixel-level annotations necessary for prompting.","To bridge this gap and foster further research on this topic, we introduce Occluded-PoseTrack ReID, a novel ReID dataset with keypoints labels, that features strong inter-person occlusions.","Furthermore, we release custom keypoint labels for four popular ReID benchmarks.","Experiments on person retrieval, but also on pose tracking, demonstrate that our method systematically surpasses previous state-of-the-art approaches on various occluded scenarios.","Our code, dataset and annotations are available at https://github.com/VlSomers/keypoint_promptable_reidentification."],"url":"http://arxiv.org/abs/2407.18112v1"}
{"created":"2024-07-25 15:18:47","title":"MapTune: Advancing ASIC Technology Mapping via Reinforcement Learning Guided Library Tuning","abstract":"Technology mapping involves mapping logical circuits to a library of cells. Traditionally, the full technology library is used, leading to a large search space and potential overhead. Motivated by randomly sampled technology mapping case studies, we propose MapTune framework that addresses this challenge by utilizing reinforcement learning to make design-specific choices during cell selection. By learning from the environment, MapTune refines the cell selection process, resulting in a reduced search space and potentially improved mapping quality.   The effectiveness of MapTune is evaluated on a wide range of benchmarks, different technology libraries and technology mappers. The experimental results demonstrate that MapTune achieves higher mapping accuracy and reducing delay/area across diverse circuit designs, technology libraries and mappers. The paper also discusses the Pareto-Optimal exploration and confirms the perpetual delay-area trade-off. Conducted on benchmark suites ISCAS 85/89, ITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and post-sizing quality-of-results (QoR) have been significantly improved, with average Area-Delay Product (ADP) improvement of 22.54\\% among all different exploration settings in MapTune. The improvements are consistently remained for four different technologies (7nm, 45nm, 130nm, and 180 nm) and two different mappers.","sentences":["Technology mapping involves mapping logical circuits to a library of cells.","Traditionally, the full technology library is used, leading to a large search space and potential overhead.","Motivated by randomly sampled technology mapping case studies, we propose MapTune framework that addresses this challenge by utilizing reinforcement learning to make design-specific choices during cell selection.","By learning from the environment, MapTune refines the cell selection process, resulting in a reduced search space and potentially improved mapping quality.   ","The effectiveness of MapTune is evaluated on a wide range of benchmarks, different technology libraries and technology mappers.","The experimental results demonstrate that MapTune achieves higher mapping accuracy and reducing delay/area across diverse circuit designs, technology libraries and mappers.","The paper also discusses the Pareto-Optimal exploration and confirms the perpetual delay-area trade-off.","Conducted on benchmark suites ISCAS 85/89, ITC/ISCAS 99, VTR8.0 and EPFL benchmarks, the post-technology mapping and post-sizing quality-of-results (QoR) have been significantly improved, with average Area-Delay Product (ADP) improvement of 22.54\\% among all different exploration settings in MapTune.","The improvements are consistently remained for four different technologies (7nm, 45nm, 130nm, and 180 nm) and two different mappers."],"url":"http://arxiv.org/abs/2407.18110v1"}
{"created":"2024-07-25 15:12:46","title":"Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics","abstract":"We present a data-driven machine-learning approach for modeling space-time socioeconomic dynamics. Through coarse-graining fine-scale observations, our modeling framework simplifies these complex systems to a set of tractable mechanistic relationships -- in the form of ordinary differential equations -- while preserving critical system behaviors. This approach allows for expedited 'what if' studies and sensitivity analyses, essential for informed policy-making. Our findings, from a case study of Baltimore, MD, indicate that this machine learning-augmented coarse-grained model serves as a powerful instrument for deciphering the complex interactions between social factors, geography, and exogenous stressors, offering a valuable asset for system forecasting and resilience planning.","sentences":["We present a data-driven machine-learning approach for modeling space-time socioeconomic dynamics.","Through coarse-graining fine-scale observations, our modeling framework simplifies these complex systems to a set of tractable mechanistic relationships -- in the form of ordinary differential equations -- while preserving critical system behaviors.","This approach allows for expedited 'what if' studies and sensitivity analyses, essential for informed policy-making.","Our findings, from a case study of Baltimore, MD, indicate that this machine learning-augmented coarse-grained model serves as a powerful instrument for deciphering the complex interactions between social factors, geography, and exogenous stressors, offering a valuable asset for system forecasting and resilience planning."],"url":"http://arxiv.org/abs/2407.18108v1"}
{"created":"2024-07-25 15:03:36","title":"DINOv2 Rocks Geological Image Analysis: Classification, Segmentation, and Interpretability","abstract":"This study investigates the interpretability, classification, and segmentation of CT-scan images of rock samples, with a particular focus on the application of DINOv2 within Geosciences. We compared various segmentation techniques to evaluate their efficacy, efficiency, and adaptability in geological image analysis. The methods assessed include the Otsu thresholding method, clustering techniques (K-means and fuzzy C-means), a supervised machine learning approach (Random Forest), and deep learning methods (UNet and DINOv2). We tested these methods using ten binary sandstone datasets and three multi-class calcite datasets. To begin, we provide a thorough interpretability analysis of DINOv2's features in the geoscientific context, discussing its suitability and inherent ability to process CT-scanned rock data. In terms of classification, the out-of-the-box DINOv2 demonstrates an impressive capability to perfectly classify rock images, even when the CT scans are out of its original training set. Regarding segmentation, thresholding and unsupervised methods, while fast, perform poorly despite image preprocessing, whereas supervised methods show better results. We underscore the computational demands of deep learning but highlight its minimal intervention, superior generalization, and performance without additional image preprocessing. Additionally, we observe a lack of correlation between a network's depth or the number of parameters and its performance. Our results show that a LoRA fine-tuned DINOv2 excels in out-of-distribution segmentation and significantly outperforms other methods in multi-class segmentation. By systematically comparing these methods, we identify the most efficient strategy for meticulous and laborious segmentation tasks. DINOv2 proves advantageous, achieving segmentations that could be described as \"better than ground-truth\" against relatively small training sets.","sentences":["This study investigates the interpretability, classification, and segmentation of CT-scan images of rock samples, with a particular focus on the application of DINOv2 within Geosciences.","We compared various segmentation techniques to evaluate their efficacy, efficiency, and adaptability in geological image analysis.","The methods assessed include the Otsu thresholding method, clustering techniques (K-means and fuzzy C-means), a supervised machine learning approach (Random Forest), and deep learning methods (UNet and DINOv2).","We tested these methods using ten binary sandstone datasets and three multi-class calcite datasets.","To begin, we provide a thorough interpretability analysis of DINOv2's features in the geoscientific context, discussing its suitability and inherent ability to process CT-scanned rock data.","In terms of classification, the out-of-the-box DINOv2 demonstrates an impressive capability to perfectly classify rock images, even when the CT scans are out of its original training set.","Regarding segmentation, thresholding and unsupervised methods, while fast, perform poorly despite image preprocessing, whereas supervised methods show better results.","We underscore the computational demands of deep learning but highlight its minimal intervention, superior generalization, and performance without additional image preprocessing.","Additionally, we observe a lack of correlation between a network's depth or the number of parameters and its performance.","Our results show that a LoRA fine-tuned DINOv2 excels in out-of-distribution segmentation and significantly outperforms other methods in multi-class segmentation.","By systematically comparing these methods, we identify the most efficient strategy for meticulous and laborious segmentation tasks.","DINOv2 proves advantageous, achieving segmentations that could be described as \"better than ground-truth\" against relatively small training sets."],"url":"http://arxiv.org/abs/2407.18100v1"}
{"created":"2024-07-25 15:03:33","title":"Unraveling the Web of Disinformation: Exploring the Larger Context of State-Sponsored Influence Campaigns on Twitter","abstract":"Social media platforms offer unprecedented opportunities for connectivity and exchange of ideas; however, they also serve as fertile grounds for the dissemination of disinformation. Over the years, there has been a rise in state-sponsored campaigns aiming to spread disinformation and sway public opinion on sensitive topics through designated accounts, known as troll accounts. Past works on detecting accounts belonging to state-backed operations focus on a single campaign. While campaign-specific detection techniques are easier to build, there is no work done on developing systems that are campaign-agnostic and offer generalized detection of troll accounts unaffected by the biases of the specific campaign they belong to. In this paper, we identify several strategies adopted across different state actors and present a system that leverages them to detect accounts from previously unseen campaigns. We study 19 state-sponsored disinformation campaigns that took place on Twitter, originating from various countries. The strategies include sending automated messages through popular scheduling services, retweeting and sharing selective content and using fake versions of verified applications for pushing content. By translating these traits into a feature set, we build a machine learning-based classifier that can correctly identify up to 94% of accounts from unseen campaigns. Additionally, we run our system in the wild and find more accounts that could potentially belong to state-backed operations. We also present case studies to highlight the similarity between the accounts found by our system and those identified by Twitter.","sentences":["Social media platforms offer unprecedented opportunities for connectivity and exchange of ideas; however, they also serve as fertile grounds for the dissemination of disinformation.","Over the years, there has been a rise in state-sponsored campaigns aiming to spread disinformation and sway public opinion on sensitive topics through designated accounts, known as troll accounts.","Past works on detecting accounts belonging to state-backed operations focus on a single campaign.","While campaign-specific detection techniques are easier to build, there is no work done on developing systems that are campaign-agnostic and offer generalized detection of troll accounts unaffected by the biases of the specific campaign they belong to.","In this paper, we identify several strategies adopted across different state actors and present a system that leverages them to detect accounts from previously unseen campaigns.","We study 19 state-sponsored disinformation campaigns that took place on Twitter, originating from various countries.","The strategies include sending automated messages through popular scheduling services, retweeting and sharing selective content and using fake versions of verified applications for pushing content.","By translating these traits into a feature set, we build a machine learning-based classifier that can correctly identify up to 94% of accounts from unseen campaigns.","Additionally, we run our system in the wild and find more accounts that could potentially belong to state-backed operations.","We also present case studies to highlight the similarity between the accounts found by our system and those identified by Twitter."],"url":"http://arxiv.org/abs/2407.18098v1"}
{"created":"2024-07-25 15:02:24","title":"SSTD: Stripe-Like Space Target Detection using Single-Point Supervision","abstract":"Stripe-like space target detection (SSTD) plays a key role in enhancing space situational awareness and assessing spacecraft behaviour. This domain faces three challenges: the lack of publicly available datasets, interference from stray light and stars, and the variability of stripe-like targets, which complicates pixel-level annotation. In response, we introduces `AstroStripeSet', a pioneering dataset designed for SSTD, aiming to bridge the gap in academic resources and advance research in SSTD. Furthermore, we propose a novel pseudo-label evolution teacher-student framework with single-point supervision. This framework starts with generating initial pseudo-labels using the zero-shot capabilities of the Segment Anything Model (SAM) in a single-point setting, and refines these labels iteratively. In our framework, the fine-tuned StripeSAM serves as the teacher and the newly developed StripeNet as the student, consistently improving segmentation performance by improving the quality of pseudo-labels. We also introduce `GeoDice', a new loss function customized for the linear characteristics of stripe-like targets. Extensive experiments show that the performance of our approach matches fully supervised methods on all evaluation metrics, establishing a new state-of-the-art (SOTA) benchmark. Our dataset and code will be made publicly available.","sentences":["Stripe-like space target detection (SSTD) plays a key role in enhancing space situational awareness and assessing spacecraft behaviour.","This domain faces three challenges: the lack of publicly available datasets, interference from stray light and stars, and the variability of stripe-like targets, which complicates pixel-level annotation.","In response, we introduces `AstroStripeSet', a pioneering dataset designed for SSTD, aiming to bridge the gap in academic resources and advance research in SSTD.","Furthermore, we propose a novel pseudo-label evolution teacher-student framework with single-point supervision.","This framework starts with generating initial pseudo-labels using the zero-shot capabilities of the Segment Anything Model (SAM) in a single-point setting, and refines these labels iteratively.","In our framework, the fine-tuned StripeSAM serves as the teacher and the newly developed StripeNet as the student, consistently improving segmentation performance by improving the quality of pseudo-labels.","We also introduce `GeoDice', a new loss function customized for the linear characteristics of stripe-like targets.","Extensive experiments show that the performance of our approach matches fully supervised methods on all evaluation metrics, establishing a new state-of-the-art (SOTA) benchmark.","Our dataset and code will be made publicly available."],"url":"http://arxiv.org/abs/2407.18097v1"}
{"created":"2024-07-25 15:01:56","title":"Privacy Threats and Countermeasures in Federated Learning for Internet of Things: A Systematic Review","abstract":"Federated Learning (FL) in the Internet of Things (IoT) environments can enhance machine learning by utilising decentralised data, but at the same time, it might introduce significant privacy and security concerns due to the constrained nature of IoT devices. This represents a research challenge that we aim to address in this paper. We systematically analysed recent literature to identify privacy threats in FL within IoT environments, and evaluate the defensive measures that can be employed to mitigate these threats. Using a Systematic Literature Review (SLR) approach, we searched five publication databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating relevant papers published between 2017 and April 2024, a period which spans from the introduction of FL until now. Guided by the PRISMA protocol, we selected 49 papers to focus our systematic review on. We analysed these papers, paying special attention to the privacy threats and defensive measures -- specifically within the context of IoT -- using inclusion and exclusion criteria tailored to highlight recent advances and critical insights. We identified various privacy threats, including inference attacks, poisoning attacks, and eavesdropping, along with defensive measures such as Differential Privacy and Secure Multi-Party Computation. These defences were evaluated for their effectiveness in protecting privacy without compromising the functional integrity of FL in IoT settings. Our review underscores the necessity for robust and efficient privacy-preserving strategies tailored for IoT environments. Notably, there is a need for strategies against replay, evasion, and model stealing attacks. Exploring lightweight defensive measures and emerging technologies such as blockchain may help improve the privacy of FL in IoT, leading to the creation of FL models that can operate under variable network conditions.","sentences":["Federated Learning (FL) in the Internet of Things (IoT) environments can enhance machine learning by utilising decentralised data, but at the same time, it might introduce significant privacy and security concerns due to the constrained nature of IoT devices.","This represents a research challenge that we aim to address in this paper.","We systematically analysed recent literature to identify privacy threats in FL within IoT environments, and evaluate the defensive measures that can be employed to mitigate these threats.","Using a Systematic Literature Review (SLR) approach, we searched five publication databases (Scopus, IEEE Xplore, Wiley, ACM, and Science Direct), collating relevant papers published between 2017 and April 2024, a period which spans from the introduction of FL until now.","Guided by the PRISMA protocol, we selected 49 papers to focus our systematic review on.","We analysed these papers, paying special attention to the privacy threats and defensive measures -- specifically within the context of IoT -- using inclusion and exclusion criteria tailored to highlight recent advances and critical insights.","We identified various privacy threats, including inference attacks, poisoning attacks, and eavesdropping, along with defensive measures such as Differential Privacy and Secure Multi-Party Computation.","These defences were evaluated for their effectiveness in protecting privacy without compromising the functional integrity of FL in IoT settings.","Our review underscores the necessity for robust and efficient privacy-preserving strategies tailored for IoT environments.","Notably, there is a need for strategies against replay, evasion, and model stealing attacks.","Exploring lightweight defensive measures and emerging technologies such as blockchain may help improve the privacy of FL in IoT, leading to the creation of FL models that can operate under variable network conditions."],"url":"http://arxiv.org/abs/2407.18096v1"}
{"created":"2024-07-25 15:00:12","title":"Strategic Cost Selection in Participatory Budgeting","abstract":"We study strategic behavior of project proposers in the context of approval-based participatory budgeting (PB). In our model we assume that the votes are fixed and known and the proposers want to set as high project prices as possible, provided that their projects get selected and the prices are not below the minimum costs of their delivery. We study the existence of pure Nash equilibria (NE) in such games, focusing on the AV/Cost, Phragm\\'en, and Method of Equal Shares rules. Furthermore, we report an experimental study of strategic cost selection on real-life PB election data.","sentences":["We study strategic behavior of project proposers in the context of approval-based participatory budgeting (PB).","In our model we assume that the votes are fixed and known and the proposers want to set as high project prices as possible, provided that their projects get selected and the prices are not below the minimum costs of their delivery.","We study the existence of pure Nash equilibria (NE) in such games, focusing on the AV/Cost, Phragm\\'en, and Method of Equal Shares rules.","Furthermore, we report an experimental study of strategic cost selection on real-life PB election data."],"url":"http://arxiv.org/abs/2407.18092v1"}
{"created":"2024-07-25 14:55:11","title":"On the Minimisation of Deterministic and History-Deterministic Generalised (co)B\u00fcchi Automata","abstract":"We present a polynomial-time algorithm minimising the number of states of history-deterministic generalised coB\\\"uchi automata, building on the work of Abu Radi and Kupferman on coB\\\"uchi automata. On the other hand, we establish that the minimisation problem for both deterministic and history-deterministic generalised B\\\"uchi automata is NP-complete, as well as the problem of minimising at the same time the number of states and colours of history-deterministic generalised coB\\\"uchi automata.","sentences":["We present a polynomial-time algorithm minimising the number of states of history-deterministic generalised coB\\\"uchi automata, building on the work of Abu Radi and Kupferman on coB\\\"uchi automata.","On the other hand, we establish that the minimisation problem for both deterministic and history-deterministic generalised B\\\"uchi automata is NP-complete, as well as the problem of minimising at the same time the number of states and colours of history-deterministic generalised coB\\\"uchi automata."],"url":"http://arxiv.org/abs/2407.18090v1"}
{"created":"2024-07-25 14:49:12","title":"Revealing urban area from mobile positioning data","abstract":"Researchers face the trade-off between publishing mobility data along with their papers while simultaneously protecting the privacy of the individuals. In addition to the fundamental anonymization process, other techniques, such as spatial discretization and, in certain cases, location concealing or complete removal, are applied to achieve these dual objectives. The primary research question is whether concealing the observation area is an adequate form of protection or whether human mobility patterns in urban areas are inherently revealing of location. The characteristics of the mobility data, such as the number of activity records or the number of unique users in a given spatial unit, reveal the silhouette of the urban landscape, which can be used to infer the identity of the city in question. It was demonstrated that even without disclosing the exact location, the patterns of human mobility can still reveal the urban area from which the data was collected. The presented locating method was tested on other cities using different open data sets and against coarser spatial discretization units. While publishing mobility data is essential for research, it was demonstrated that concealing the observation area is insufficient to prevent the identification of the urban area. Furthermore, using larger discretization units alone is an ineffective solution to the problem of the observation area re-identification. Instead of obscuring the observation area, noise should be added to the trajectories to prevent user identification.","sentences":["Researchers face the trade-off between publishing mobility data along with their papers while simultaneously protecting the privacy of the individuals.","In addition to the fundamental anonymization process, other techniques, such as spatial discretization and, in certain cases, location concealing or complete removal, are applied to achieve these dual objectives.","The primary research question is whether concealing the observation area is an adequate form of protection or whether human mobility patterns in urban areas are inherently revealing of location.","The characteristics of the mobility data, such as the number of activity records or the number of unique users in a given spatial unit, reveal the silhouette of the urban landscape, which can be used to infer the identity of the city in question.","It was demonstrated that even without disclosing the exact location, the patterns of human mobility can still reveal the urban area from which the data was collected.","The presented locating method was tested on other cities using different open data sets and against coarser spatial discretization units.","While publishing mobility data is essential for research, it was demonstrated that concealing the observation area is insufficient to prevent the identification of the urban area.","Furthermore, using larger discretization units alone is an ineffective solution to the problem of the observation area re-identification.","Instead of obscuring the observation area, noise should be added to the trajectories to prevent user identification."],"url":"http://arxiv.org/abs/2407.18086v1"}
{"created":"2024-07-25 14:47:41","title":"On the Design of Ethereum Data Availability Sampling: A Comprehensive Simulation Study","abstract":"This paper presents an in-depth exploration of Data Availability Sampling (DAS) and sharding mechanisms within decentralized systems through simulation-based analysis. DAS, a pivotal concept in blockchain technology and decentralized networks, is thoroughly examined to unravel its intricacies and assess its impact on system performance. Through the development of a simulator tailored explicitly for DAS, we embark on a comprehensive investigation into the parameters that influence system behavior and efficiency. A series of experiments are conducted within the simulated environment to validate theoretical formulations and dissect the interplay of DAS parameters. This includes an exploration of approaches such as custody by row, variations in validators per node, and malicious nodes. The outcomes of these experiments furnish insights into the efficacy of DAS protocols and pave the way for the formulation of optimization strategies geared towards enhancing decentralized network performance. Moreover, the findings serve as guidelines for future research endeavors, offering a nuanced understanding of the complexities inherent in decentralized systems. This study not only contributes to the theoretical understanding of DAS but also offers practical implications for the design, implementation, and optimization of decentralized systems.","sentences":["This paper presents an in-depth exploration of Data Availability Sampling (DAS) and sharding mechanisms within decentralized systems through simulation-based analysis.","DAS, a pivotal concept in blockchain technology and decentralized networks, is thoroughly examined to unravel its intricacies and assess its impact on system performance.","Through the development of a simulator tailored explicitly for DAS, we embark on a comprehensive investigation into the parameters that influence system behavior and efficiency.","A series of experiments are conducted within the simulated environment to validate theoretical formulations and dissect the interplay of DAS parameters.","This includes an exploration of approaches such as custody by row, variations in validators per node, and malicious nodes.","The outcomes of these experiments furnish insights into the efficacy of DAS protocols and pave the way for the formulation of optimization strategies geared towards enhancing decentralized network performance.","Moreover, the findings serve as guidelines for future research endeavors, offering a nuanced understanding of the complexities inherent in decentralized systems.","This study not only contributes to the theoretical understanding of DAS but also offers practical implications for the design, implementation, and optimization of decentralized systems."],"url":"http://arxiv.org/abs/2407.18085v1"}
{"created":"2024-07-25 14:36:18","title":"PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization","abstract":"The recent emergence of Large Language Models (LLMs) has heralded a new era of human-AI interaction. These sophisticated models, exemplified by Chat-GPT and its successors, have exhibited remarkable capabilities in language understanding. However, as these LLMs have undergone exponential growth, a crucial dimension that remains understudied is the personalization of these models. Large foundation models such as GPT-3 etc. focus on creating a universal model that serves a broad range of tasks and users. This approach emphasizes the model's generalization capabilities, treating users as a collective rather than as distinct individuals. While practical for many common applications, this one-size-fits-all approach often fails to address the rich tapestry of human diversity and individual needs. To explore this issue we introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP models for user personalization. \\datasetname{} consists of a series of user-centered tasks containing diverse and individualized expressions where the preferences of users can potentially differ for the same input. Using PEFT-U, we explore the challenge of efficiently personalizing LLMs to accommodate user-specific preferences in the context of diverse user-centered tasks.","sentences":["The recent emergence of Large Language Models (LLMs) has heralded a new era of human-AI interaction.","These sophisticated models, exemplified by Chat-GPT and its successors, have exhibited remarkable capabilities in language understanding.","However, as these LLMs have undergone exponential growth, a crucial dimension that remains understudied is the personalization of these models.","Large foundation models such as GPT-3 etc. focus on creating a universal model that serves a broad range of tasks and users.","This approach emphasizes the model's generalization capabilities, treating users as a collective rather than as distinct individuals.","While practical for many common applications, this one-size-fits-all approach often fails to address the rich tapestry of human diversity and individual needs.","To explore this issue we introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP models for user personalization.","\\datasetname{} consists of a series of user-centered tasks containing diverse and individualized expressions where the preferences of users can potentially differ for the same input.","Using PEFT-U, we explore the challenge of efficiently personalizing LLMs to accommodate user-specific preferences in the context of diverse user-centered tasks."],"url":"http://arxiv.org/abs/2407.18078v1"}
{"created":"2024-07-25 14:28:58","title":"Principal-Agent Reinforcement Learning","abstract":"Contracts are the economic framework which allows a principal to delegate a task to an agent -- despite misaligned interests, and even without directly observing the agent's actions. In many modern reinforcement learning settings, self-interested agents learn to perform a multi-stage task delegated to them by a principal. We explore the significant potential of utilizing contracts to incentivize the agents. We model the delegated task as an MDP, and study a stochastic game between the principal and agent where the principal learns what contracts to use, and the agent learns an MDP policy in response. We present a learning-based algorithm for optimizing the principal's contracts, which provably converges to the subgame-perfect equilibrium of the principal-agent game. A deep RL implementation allows us to apply our method to very large MDPs with unknown transition dynamics. We extend our approach to multiple agents, and demonstrate its relevance to resolving a canonical sequential social dilemma with minimal intervention to agent rewards.","sentences":["Contracts are the economic framework which allows a principal to delegate a task to an agent -- despite misaligned interests, and even without directly observing the agent's actions.","In many modern reinforcement learning settings, self-interested agents learn to perform a multi-stage task delegated to them by a principal.","We explore the significant potential of utilizing contracts to incentivize the agents.","We model the delegated task as an MDP, and study a stochastic game between the principal and agent where the principal learns what contracts to use, and the agent learns an MDP policy in response.","We present a learning-based algorithm for optimizing the principal's contracts, which provably converges to the subgame-perfect equilibrium of the principal-agent game.","A deep RL implementation allows us to apply our method to very large MDPs with unknown transition dynamics.","We extend our approach to multiple agents, and demonstrate its relevance to resolving a canonical sequential social dilemma with minimal intervention to agent rewards."],"url":"http://arxiv.org/abs/2407.18074v1"}
{"created":"2024-07-25 14:24:57","title":"C2P: Featuring Large Language Models with Causal Reasoning","abstract":"Causal reasoning is the primary bottleneck that Large Language Models (LLMs) must overcome to attain human-level intelligence. To address this, we introduce the Causal Chain of Prompting (C2P) as the first reasoning framework that equips current LLMs with causal reasoning capabilities. C2P operates autonomously, avoiding reliance on external tools or modules during both the causal learning and reasoning phases, and can be seamlessly implemented during the training or fine-tuning of LLMs. Experimental results across various benchmark datasets demonstrate a significant improvement in causal learning and subsequent reasoning accuracy of LLMs. We illustrate how C2P enhances LLMs' ability to causally reason in real-world scenarios, addressing complex problems in fields such as healthcare, medicine, economics, education, social sciences, environmental science, and marketing. With few-shot learning, GPT-4 Turbo using C2P with as few as six examples achieves significant performance improvements, boasting over a 33% increase in reasoning accuracy over the most state-of-the-art LLMs, which perform nearly randomly in similar circumstances. This demonstrates the transformative potential of integrating C2P into LLM training or fine-tuning processes, thereby empowering these models with advanced causal reasoning capabilities.","sentences":["Causal reasoning is the primary bottleneck that Large Language Models (LLMs) must overcome to attain human-level intelligence.","To address this, we introduce the Causal Chain of Prompting (C2P) as the first reasoning framework that equips current LLMs with causal reasoning capabilities.","C2P operates autonomously, avoiding reliance on external tools or modules during both the causal learning and reasoning phases, and can be seamlessly implemented during the training or fine-tuning of LLMs.","Experimental results across various benchmark datasets demonstrate a significant improvement in causal learning and subsequent reasoning accuracy of LLMs.","We illustrate how C2P enhances LLMs' ability to causally reason in real-world scenarios, addressing complex problems in fields such as healthcare, medicine, economics, education, social sciences, environmental science, and marketing.","With few-shot learning, GPT-4 Turbo using C2P with as few as six examples achieves significant performance improvements, boasting over a 33% increase in reasoning accuracy over the most state-of-the-art LLMs, which perform nearly randomly in similar circumstances.","This demonstrates the transformative potential of integrating C2P into LLM training or fine-tuning processes, thereby empowering these models with advanced causal reasoning capabilities."],"url":"http://arxiv.org/abs/2407.18069v1"}
{"created":"2024-07-25 14:21:50","title":"HVM-1: Large-scale video models pretrained with nearly 5000 hours of human-like video data","abstract":"We introduce Human-like Video Models (HVM-1), large-scale video models pretrained with nearly 5000 hours of curated human-like video data (mostly egocentric, temporally extended, continuous video recordings), using the spatiotemporal masked autoencoder (ST-MAE) algorithm. We release two 633M parameter models trained at spatial resolutions of 224x224 and 448x448 pixels. We evaluate the performance of these models in downstream few-shot video and image recognition tasks and compare them against a model pretrained with 1330 hours of short action-oriented video clips from YouTube (Kinetics-700). HVM-1 models perform competitively against the Kinetics-700 pretrained model in downstream evaluations despite substantial qualitative differences between the spatiotemporal characteristics of the corresponding pretraining datasets. HVM-1 models also learn more accurate and more robust object representations compared to models pretrained with the image-based MAE algorithm on the same data, demonstrating the potential benefits of learning to predict temporal regularities in natural videos for learning better object representations.","sentences":["We introduce Human-like Video Models (HVM-1), large-scale video models pretrained with nearly 5000 hours of curated human-like video data (mostly egocentric, temporally extended, continuous video recordings), using the spatiotemporal masked autoencoder (ST-MAE) algorithm.","We release two 633M parameter models trained at spatial resolutions of 224x224 and 448x448 pixels.","We evaluate the performance of these models in downstream few-shot video and image recognition tasks and compare them against a model pretrained with 1330 hours of short action-oriented video clips from YouTube (Kinetics-700).","HVM-1 models perform competitively against the Kinetics-700 pretrained model in downstream evaluations despite substantial qualitative differences between the spatiotemporal characteristics of the corresponding pretraining datasets.","HVM-1 models also learn more accurate and more robust object representations compared to models pretrained with the image-based MAE algorithm on the same data, demonstrating the potential benefits of learning to predict temporal regularities in natural videos for learning better object representations."],"url":"http://arxiv.org/abs/2407.18067v1"}
{"created":"2024-07-25 14:19:59","title":"Multi-Agent Deep Reinforcement Learning for Resilience Optimization in 5G RAN","abstract":"Resilience is defined as the ability of a network to resist, adapt, and quickly recover from disruptions, and to continue to maintain an acceptable level of services from users' perspective. With the advent of future radio networks, including advanced 5G and upcoming 6G, critical services become integral to future networks, requiring uninterrupted service delivery for end users. Unfortunately, with the growing network complexity, user mobility and diversity, it becomes challenging to scale current resilience management techniques that rely on local optimizations to large dense network deployments. This paper aims to address this problem by globally optimizing the resilience of a dense multi-cell network based on multi-agent deep reinforcement learning. Specifically, our proposed solution can dynamically tilt cell antennas and reconfigure transmit power to mitigate outages and increase both coverage and service availability. A multi-objective optimization problem is formulated to simultaneously satisfy resiliency constraints while maximizing the service quality in the network area in order to minimize the impact of outages on neighbouring cells. Extensive simulations then demonstrate that with our proposed solution, the average service availability in terms of user throughput can be increased by up to 50-60% on average, while reaching a coverage availability of 99% in best cases.","sentences":["Resilience is defined as the ability of a network to resist, adapt, and quickly recover from disruptions, and to continue to maintain an acceptable level of services from users' perspective.","With the advent of future radio networks, including advanced 5G and upcoming 6G, critical services become integral to future networks, requiring uninterrupted service delivery for end users.","Unfortunately, with the growing network complexity, user mobility and diversity, it becomes challenging to scale current resilience management techniques that rely on local optimizations to large dense network deployments.","This paper aims to address this problem by globally optimizing the resilience of a dense multi-cell network based on multi-agent deep reinforcement learning.","Specifically, our proposed solution can dynamically tilt cell antennas and reconfigure transmit power to mitigate outages and increase both coverage and service availability.","A multi-objective optimization problem is formulated to simultaneously satisfy resiliency constraints while maximizing the service quality in the network area in order to minimize the impact of outages on neighbouring cells.","Extensive simulations then demonstrate that with our proposed solution, the average service availability in terms of user throughput can be increased by up to 50-60% on average, while reaching a coverage availability of 99% in best cases."],"url":"http://arxiv.org/abs/2407.18066v1"}
{"created":"2024-07-25 14:19:35","title":"ComPeer: A Generative Conversational Agent for Proactive Peer Support","abstract":"Conversational Agents (CAs) acting as peer supporters have been widely studied and demonstrated beneficial for people's mental health. However, previous peer support CAs either are user-initiated or follow predefined rules to initiate the conversations, which may discourage users to engage and build relationships with the CAs for long-term benefits. In this paper, we develop ComPeer, a generative CA that can proactively offer adaptive peer support to users. ComPeer leverages large language models to detect and reflect significant events in the dialogue, enabling it to strategically plan the timing and content of proactive care. In addition, ComPeer incorporates peer support strategies, conversation history, and its persona into the generative messages. Our one-week between-subjects study (N=24) demonstrates ComPeer's strength in providing peer support over time and boosting users' engagement compared to a baseline user-initiated CA.","sentences":["Conversational Agents (CAs) acting as peer supporters have been widely studied and demonstrated beneficial for people's mental health.","However, previous peer support CAs either are user-initiated or follow predefined rules to initiate the conversations, which may discourage users to engage and build relationships with the CAs for long-term benefits.","In this paper, we develop ComPeer, a generative CA that can proactively offer adaptive peer support to users.","ComPeer leverages large language models to detect and reflect significant events in the dialogue, enabling it to strategically plan the timing and content of proactive care.","In addition, ComPeer incorporates peer support strategies, conversation history, and its persona into the generative messages.","Our one-week between-subjects study (N=24) demonstrates ComPeer's strength in providing peer support over time and boosting users' engagement compared to a baseline user-initiated CA."],"url":"http://arxiv.org/abs/2407.18064v1"}
{"created":"2024-07-25 14:17:56","title":"Audio Entailment: Assessing Deductive Reasoning for Audio Understanding","abstract":"Recent literature uses language to build foundation models for audio. These Audio-Language Models (ALMs) are trained on a vast number of audio-text pairs and show remarkable performance in tasks including Text-to-Audio Retrieval, Captioning, and Question Answering. However, their ability to engage in more complex open-ended tasks, like Interactive Question-Answering, requires proficiency in logical reasoning -- a skill not yet benchmarked. We introduce the novel task of Audio Entailment to evaluate an ALM's deductive reasoning ability. This task assesses whether a text description (hypothesis) of audio content can be deduced from an audio recording (premise), with potential conclusions being entailment, neutral, or contradiction, depending on the sufficiency of the evidence. We create two datasets for this task with audio recordings sourced from two audio captioning datasets -- AudioCaps and Clotho -- and hypotheses generated using Large Language Models (LLMs). We benchmark state-of-the-art ALMs and find deficiencies in logical reasoning with both zero-shot and linear probe evaluations. Finally, we propose \"caption-before-reason\", an intermediate step of captioning that improves the zero-shot and linear-probe performance of ALMs by an absolute 6% and 3%, respectively.","sentences":["Recent literature uses language to build foundation models for audio.","These Audio-Language Models (ALMs) are trained on a vast number of audio-text pairs and show remarkable performance in tasks including Text-to-Audio Retrieval, Captioning, and Question Answering.","However, their ability to engage in more complex open-ended tasks, like Interactive Question-Answering, requires proficiency in logical reasoning -- a skill not yet benchmarked.","We introduce the novel task of Audio Entailment to evaluate an ALM's deductive reasoning ability.","This task assesses whether a text description (hypothesis) of audio content can be deduced from an audio recording (premise), with potential conclusions being entailment, neutral, or contradiction, depending on the sufficiency of the evidence.","We create two datasets for this task with audio recordings sourced from two audio captioning datasets -- AudioCaps and Clotho -- and hypotheses generated using Large Language Models (LLMs).","We benchmark state-of-the-art ALMs and find deficiencies in logical reasoning with both zero-shot and linear probe evaluations.","Finally, we propose \"caption-before-reason\", an intermediate step of captioning that improves the zero-shot and linear-probe performance of ALMs by an absolute 6% and 3%, respectively."],"url":"http://arxiv.org/abs/2407.18062v1"}
{"created":"2024-07-25 14:16:08","title":"Difficulty Estimation and Simplification of French Text Using LLMs","abstract":"We leverage generative large language models for language learning applications, focusing on estimating the difficulty of foreign language texts and simplifying them to lower difficulty levels. We frame both tasks as prediction problems and develop a difficulty classification model using labeled examples, transfer learning, and large language models, demonstrating superior accuracy compared to previous approaches. For simplification, we evaluate the trade-off between simplification quality and meaning preservation, comparing zero-shot and fine-tuned performances of large language models. We show that meaningful text simplifications can be obtained with limited fine-tuning. Our experiments are conducted on French texts, but our methods are language-agnostic and directly applicable to other foreign languages.","sentences":["We leverage generative large language models for language learning applications, focusing on estimating the difficulty of foreign language texts and simplifying them to lower difficulty levels.","We frame both tasks as prediction problems and develop a difficulty classification model using labeled examples, transfer learning, and large language models, demonstrating superior accuracy compared to previous approaches.","For simplification, we evaluate the trade-off between simplification quality and meaning preservation, comparing zero-shot and fine-tuned performances of large language models.","We show that meaningful text simplifications can be obtained with limited fine-tuning.","Our experiments are conducted on French texts, but our methods are language-agnostic and directly applicable to other foreign languages."],"url":"http://arxiv.org/abs/2407.18061v1"}
{"created":"2024-07-25 14:16:02","title":"Cross-Vendor Reproducibility of Radiomics-based Machine Learning Models for Computer-aided Diagnosis","abstract":"Background: The reproducibility of machine-learning models in prostate cancer detection across different MRI vendors remains a significant challenge. Methods: This study investigates Support Vector Machines (SVM) and Random Forest (RF) models trained on radiomic features extracted from T2-weighted MRI images using Pyradiomics and MRCradiomics libraries. Feature selection was performed using the maximum relevance minimum redundancy (MRMR) technique. We aimed to enhance clinical decision support through multimodal learning and feature fusion. Results: Our SVM model, utilizing combined features from Pyradiomics and MRCradiomics, achieved an AUC of 0.74 on the Multi-Improd dataset (Siemens scanner) but decreased to 0.60 on the Philips test set. The RF model showed similar trends, with notable robustness for models using Pyradiomics features alone (AUC of 0.78 on Philips). Conclusions: These findings demonstrate the potential of multimodal feature integration to improve the robustness and generalizability of machine-learning models for clinical decision support in prostate cancer detection. This study marks a significant step towards developing reliable AI-driven diagnostic tools that maintain efficacy across various imaging platforms.","sentences":["Background: The reproducibility of machine-learning models in prostate cancer detection across different MRI vendors remains a significant challenge.","Methods: This study investigates Support Vector Machines (SVM) and Random Forest (RF) models trained on radiomic features extracted from T2-weighted MRI images using Pyradiomics and MRCradiomics libraries.","Feature selection was performed using the maximum relevance minimum redundancy (MRMR) technique.","We aimed to enhance clinical decision support through multimodal learning and feature fusion.","Results: Our SVM model, utilizing combined features from Pyradiomics and MRCradiomics, achieved an AUC of 0.74 on the Multi-Improd dataset (Siemens scanner) but decreased to 0.60 on the Philips test set.","The RF model showed similar trends, with notable robustness for models using Pyradiomics features alone (AUC of 0.78 on Philips).","Conclusions: These findings demonstrate the potential of multimodal feature integration to improve the robustness and generalizability of machine-learning models for clinical decision support in prostate cancer detection.","This study marks a significant step towards developing reliable AI-driven diagnostic tools that maintain efficacy across various imaging platforms."],"url":"http://arxiv.org/abs/2407.18060v1"}
{"created":"2024-07-25 14:15:05","title":"I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition","abstract":"Music two-tower multimodal systems integrate audio and text modalities into a joint audio-text space, enabling direct comparison between songs and their corresponding labels. These systems enable new approaches for classification and retrieval, leveraging both modalities. Despite the promising results they have shown for zero-shot classification and retrieval tasks, closer inspection of the embeddings is needed. This paper evaluates the inherent zero-shot properties of joint audio-text spaces for the case-study of instrument recognition. We present an evaluation and analysis of two-tower systems for zero-shot instrument recognition and a detailed analysis of the properties of the pre-joint and joint embeddings spaces. Our findings suggest that audio encoders alone demonstrate good quality, while challenges remain within the text encoder or joint space projection. Specifically, two-tower systems exhibit sensitivity towards specific words, favoring generic prompts over musically informed ones. Despite the large size of textual encoders, they do not yet leverage additional textual context or infer instruments accurately from their descriptions. Lastly, a novel approach for quantifying the semantic meaningfulness of the textual space leveraging an instrument ontology is proposed. This method reveals deficiencies in the systems' understanding of instruments and provides evidence of the need for fine-tuning text encoders on musical data.","sentences":["Music two-tower multimodal systems integrate audio and text modalities into a joint audio-text space, enabling direct comparison between songs and their corresponding labels.","These systems enable new approaches for classification and retrieval, leveraging both modalities.","Despite the promising results they have shown for zero-shot classification and retrieval tasks, closer inspection of the embeddings is needed.","This paper evaluates the inherent zero-shot properties of joint audio-text spaces for the case-study of instrument recognition.","We present an evaluation and analysis of two-tower systems for zero-shot instrument recognition and a detailed analysis of the properties of the pre-joint and joint embeddings spaces.","Our findings suggest that audio encoders alone demonstrate good quality, while challenges remain within the text encoder or joint space projection.","Specifically, two-tower systems exhibit sensitivity towards specific words, favoring generic prompts over musically informed ones.","Despite the large size of textual encoders, they do not yet leverage additional textual context or infer instruments accurately from their descriptions.","Lastly, a novel approach for quantifying the semantic meaningfulness of the textual space leveraging an instrument ontology is proposed.","This method reveals deficiencies in the systems' understanding of instruments and provides evidence of the need for fine-tuning text encoders on musical data."],"url":"http://arxiv.org/abs/2407.18058v1"}
{"created":"2024-07-25 13:53:48","title":"GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution","abstract":"Implicit neural representations (INRs) have significantly advanced the field of arbitrary-scale super-resolution (ASSR) of images. Most existing INR-based ASSR networks first extract features from the given low-resolution image using an encoder, and then render the super-resolved result via a multi-layer perceptron decoder. Although these approaches have shown promising results, their performance is constrained by the limited representation ability of discrete latent codes in the encoded features. In this paper, we propose a novel ASSR method named GaussianSR that overcomes this limitation through 2D Gaussian Splatting (2DGS). Unlike traditional methods that treat pixels as discrete points, GaussianSR represents each pixel as a continuous Gaussian field. The encoded features are simultaneously refined and upsampled by rendering the mutually stacked Gaussian fields. As a result, long-range dependencies are established to enhance representation ability. In addition, a classifier is developed to dynamically assign Gaussian kernels to all pixels to further improve flexibility. All components of GaussianSR (i.e., encoder, classifier, Gaussian kernels, and decoder) are jointly learned end-to-end. Experiments demonstrate that GaussianSR achieves superior ASSR performance with fewer parameters than existing methods while enjoying interpretable and content-aware feature aggregations.","sentences":["Implicit neural representations (INRs) have significantly advanced the field of arbitrary-scale super-resolution (ASSR) of images.","Most existing INR-based ASSR networks first extract features from the given low-resolution image using an encoder, and then render the super-resolved result via a multi-layer perceptron decoder.","Although these approaches have shown promising results, their performance is constrained by the limited representation ability of discrete latent codes in the encoded features.","In this paper, we propose a novel ASSR method named GaussianSR that overcomes this limitation through 2D Gaussian Splatting (2DGS).","Unlike traditional methods that treat pixels as discrete points, GaussianSR represents each pixel as a continuous Gaussian field.","The encoded features are simultaneously refined and upsampled by rendering the mutually stacked Gaussian fields.","As a result, long-range dependencies are established to enhance representation ability.","In addition, a classifier is developed to dynamically assign Gaussian kernels to all pixels to further improve flexibility.","All components of GaussianSR (i.e., encoder, classifier, Gaussian kernels, and decoder) are jointly learned end-to-end.","Experiments demonstrate that GaussianSR achieves superior ASSR performance with fewer parameters than existing methods while enjoying interpretable and content-aware feature aggregations."],"url":"http://arxiv.org/abs/2407.18046v1"}
