{"created":"2024-08-21 17:59:32","title":"GRAB: A Challenging GRaph Analysis Benchmark for Large Multimodal Models","abstract":"Large multimodal models (LMMs) have exhibited proficiencies across many visual tasks. Although numerous well-known benchmarks exist to evaluate model performance, they increasingly have insufficient headroom. As such, there is a pressing need for a new generation of benchmarks challenging enough for the next generation of LMMs. One area that LMMs show potential is graph analysis, specifically, the tasks an analyst might typically perform when interpreting figures such as estimating the mean, intercepts or correlations of functions and data series. In this work, we introduce GRAB, a graph analysis benchmark, fit for current and future frontier LMMs. Our benchmark is entirely synthetic, ensuring high-quality, noise-free questions. GRAB is comprised of 2170 questions, covering four tasks and 23 graph properties. We evaluate 20 LMMs on GRAB, finding it to be a challenging benchmark, with the highest performing model attaining a score of just 21.7%. Finally, we conduct various ablations to investigate where the models succeed and struggle. We release GRAB to encourage progress in this important, growing domain.","sentences":["Large multimodal models (LMMs) have exhibited proficiencies across many visual tasks.","Although numerous well-known benchmarks exist to evaluate model performance, they increasingly have insufficient headroom.","As such, there is a pressing need for a new generation of benchmarks challenging enough for the next generation of LMMs.","One area that LMMs show potential is graph analysis, specifically, the tasks an analyst might typically perform when interpreting figures such as estimating the mean, intercepts or correlations of functions and data series.","In this work, we introduce GRAB, a graph analysis benchmark, fit for current and future frontier LMMs.","Our benchmark is entirely synthetic, ensuring high-quality, noise-free questions.","GRAB is comprised of 2170 questions, covering four tasks and 23 graph properties.","We evaluate 20 LMMs on GRAB, finding it to be a challenging benchmark, with the highest performing model attaining a score of just 21.7%.","Finally, we conduct various ablations to investigate where the models succeed and struggle.","We release GRAB to encourage progress in this important, growing domain."],"url":"http://arxiv.org/abs/2408.11817v1"}
{"created":"2024-08-21 17:59:31","title":"Efficient Exploration and Discriminative World Model Learning with an Object-Centric Abstraction","abstract":"In the face of difficult exploration problems in reinforcement learning, we study whether giving an agent an object-centric mapping (describing a set of items and their attributes) allow for more efficient learning. We found this problem is best solved hierarchically by modelling items at a higher level of state abstraction to pixels, and attribute change at a higher level of temporal abstraction to primitive actions. This abstraction simplifies the transition dynamic by making specific future states easier to predict. We make use of this to propose a fully model-based algorithm that learns a discriminative world model, plans to explore efficiently with only a count-based intrinsic reward, and can subsequently plan to reach any discovered (abstract) states.   We demonstrate the model's ability to (i) efficiently solve single tasks, (ii) transfer zero-shot and few-shot across item types and environments, and (iii) plan across long horizons. Across a suite of 2D crafting and MiniHack environments, we empirically show our model significantly out-performs state-of-the-art low-level methods (without abstraction), as well as performant model-free and model-based methods using the same abstraction. Finally, we show how to reinforce learn low level object-perturbing policies, as well as supervise learn the object mapping itself.","sentences":["In the face of difficult exploration problems in reinforcement learning, we study whether giving an agent an object-centric mapping (describing a set of items and their attributes) allow for more efficient learning.","We found this problem is best solved hierarchically by modelling items at a higher level of state abstraction to pixels, and attribute change at a higher level of temporal abstraction to primitive actions.","This abstraction simplifies the transition dynamic by making specific future states easier to predict.","We make use of this to propose a fully model-based algorithm that learns a discriminative world model, plans to explore efficiently with only a count-based intrinsic reward, and can subsequently plan to reach any discovered (abstract) states.   ","We demonstrate the model's ability to (i) efficiently solve single tasks, (ii) transfer zero-shot and few-shot across item types and environments, and (iii) plan across long horizons.","Across a suite of 2D crafting and MiniHack environments, we empirically show our model significantly out-performs state-of-the-art low-level methods (without abstraction), as well as performant model-free and model-based methods using the same abstraction.","Finally, we show how to reinforce learn low level object-perturbing policies, as well as supervise learn the object mapping itself."],"url":"http://arxiv.org/abs/2408.11816v1"}
{"created":"2024-08-21 17:59:05","title":"Great Memory, Shallow Reasoning: Limits of $k$NN-LMs","abstract":"$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval with next-word prediction, have demonstrated strong performance in language modeling as well as downstream NLP benchmarks. These results have led researchers to argue that models trained on poor quality or outdated data could perform well by employing a $k$NN extension that has access to a higher-quality datastore. In this work, we ask whether this improved ability to recall information really translates into downstream abilities. We extensively evaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment classification and commonsense reasoning to multi-hop reasoning. Results show that $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in the input is sufficient for determining the output, but struggle with reasoning tasks that require integrating multiple pieces of information to derive new knowledge. We further demonstrate through oracle experiments and qualitative analysis that even with perfect retrieval, $k$NN-LMs still fail to determine the correct answers, placing an upper bound on their reasoning performance. Code and datastores are released at https://github.com/GSYfate/knnlm-limits/.","sentences":["$K$-nearest neighbor language models ($k$NN-LMs), which integrate retrieval with next-word prediction, have demonstrated strong performance in language modeling as well as downstream NLP benchmarks.","These results have led researchers to argue that models trained on poor quality or outdated data could perform well by employing a $k$NN extension that has access to a higher-quality datastore.","In this work, we ask whether this improved ability to recall information really translates into downstream abilities.","We extensively evaluate $k$NN-LMs on a diverse set of tasks, ranging from sentiment classification and commonsense reasoning to multi-hop reasoning.","Results show that $k$NN-LMs excel at memory-intensive tasks, where utilizing the patterns in the input is sufficient for determining the output, but struggle with reasoning tasks that require integrating multiple pieces of information to derive new knowledge.","We further demonstrate through oracle experiments and qualitative analysis that even with perfect retrieval, $k$NN-LMs still fail to determine the correct answers, placing an upper bound on their reasoning performance.","Code and datastores are released at https://github.com/GSYfate/knnlm-limits/."],"url":"http://arxiv.org/abs/2408.11815v1"}
{"created":"2024-08-21 17:58:49","title":"SynPlay: Importing Real-world Diversity for a Synthetic Human Dataset","abstract":"We introduce Synthetic Playground (SynPlay), a new synthetic human dataset that aims to bring out the diversity of human appearance in the real world. We focus on two factors to achieve a level of diversity that has not yet been seen in previous works: i) realistic human motions and poses and ii) multiple camera viewpoints towards human instances. We first use a game engine and its library-provided elementary motions to create games where virtual players can take less-constrained and natural movements while following the game rules (i.e., rule-guided motion design as opposed to detail-guided design). We then augment the elementary motions with real human motions captured with a motion capture device. To render various human appearances in the games from multiple viewpoints, we use seven virtual cameras encompassing the ground and aerial views, capturing abundant aerial-vs-ground and dynamic-vs-static attributes of the scene. Through extensive and carefully-designed experiments, we show that using SynPlay in model training leads to enhanced accuracy over existing synthetic datasets for human detection and segmentation. The benefit of SynPlay becomes even greater for tasks in the data-scarce regime, such as few-shot and cross-domain learning tasks. These results clearly demonstrate that SynPlay can be used as an essential dataset with rich attributes of complex human appearances and poses suitable for model pretraining. SynPlay dataset comprising over 73k images and 6.5M human instances, is available for download at https://synplaydataset.github.io/.","sentences":["We introduce Synthetic Playground (SynPlay), a new synthetic human dataset that aims to bring out the diversity of human appearance in the real world.","We focus on two factors to achieve a level of diversity that has not yet been seen in previous works: i) realistic human motions and poses and ii) multiple camera viewpoints towards human instances.","We first use a game engine and its library-provided elementary motions to create games where virtual players can take less-constrained and natural movements while following the game rules (i.e., rule-guided motion design as opposed to detail-guided design).","We then augment the elementary motions with real human motions captured with a motion capture device.","To render various human appearances in the games from multiple viewpoints, we use seven virtual cameras encompassing the ground and aerial views, capturing abundant aerial-vs-ground and dynamic-vs-static attributes of the scene.","Through extensive and carefully-designed experiments, we show that using SynPlay in model training leads to enhanced accuracy over existing synthetic datasets for human detection and segmentation.","The benefit of SynPlay becomes even greater for tasks in the data-scarce regime, such as few-shot and cross-domain learning tasks.","These results clearly demonstrate that SynPlay can be used as an essential dataset with rich attributes of complex human appearances and poses suitable for model pretraining.","SynPlay dataset comprising over 73k images and 6.5M human instances, is available for download at https://synplaydataset.github.io/."],"url":"http://arxiv.org/abs/2408.11814v1"}
{"created":"2024-08-21 17:58:02","title":"SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs","abstract":"Multimodal Large Language Models (MLLMs) have recently demonstrated remarkable perceptual and reasoning abilities, typically comprising a Vision Encoder, an Adapter, and a Large Language Model (LLM). The adapter serves as the critical bridge between the visual and language components. However, training adapters with image-level supervision often results in significant misalignment, undermining the LLMs' capabilities and limiting the potential of Multimodal LLMs. To address this, we introduce Supervised Embedding Alignment (SEA), a token-level alignment method that leverages vision-language pre-trained models, such as CLIP, to align visual tokens with the LLM's embedding space through contrastive learning. This approach ensures a more coherent integration of visual and language representations, enhancing the performance and interpretability of multimodal LLMs while preserving their inherent capabilities. Extensive experiments show that SEA effectively improves MLLMs, particularly for smaller models, without adding extra data or inference computation. SEA also lays the groundwork for developing more general and adaptable solutions to enhance multimodal systems.","sentences":["Multimodal Large Language Models (MLLMs) have recently demonstrated remarkable perceptual and reasoning abilities, typically comprising a Vision Encoder, an Adapter, and a Large Language Model (LLM).","The adapter serves as the critical bridge between the visual and language components.","However, training adapters with image-level supervision often results in significant misalignment, undermining the LLMs' capabilities and limiting the potential of Multimodal LLMs.","To address this, we introduce Supervised Embedding Alignment (SEA), a token-level alignment method that leverages vision-language pre-trained models, such as CLIP, to align visual tokens with the LLM's embedding space through contrastive learning.","This approach ensures a more coherent integration of visual and language representations, enhancing the performance and interpretability of multimodal LLMs while preserving their inherent capabilities.","Extensive experiments show that SEA effectively improves MLLMs, particularly for smaller models, without adding extra data or inference computation.","SEA also lays the groundwork for developing more general and adaptable solutions to enhance multimodal systems."],"url":"http://arxiv.org/abs/2408.11813v1"}
{"created":"2024-08-21 17:57:51","title":"Scaling Cross-Embodied Learning: One Policy for Manipulation, Navigation, Locomotion and Aviation","abstract":"Modern machine learning systems rely on large datasets to attain broad generalization, and this often poses a challenge in robot learning, where each robotic platform and task might have only a small dataset. By training a single policy across many different kinds of robots, a robot learning method can leverage much broader and more diverse datasets, which in turn can lead to better generalization and robustness. However, training a single policy on multi-robot data is challenging because robots can have widely varying sensors, actuators, and control frequencies. We propose CrossFormer, a scalable and flexible transformer-based policy that can consume data from any embodiment. We train CrossFormer on the largest and most diverse dataset to date, 900K trajectories across 20 different robot embodiments. We demonstrate that the same network weights can control vastly different robots, including single and dual arm manipulation systems, wheeled robots, quadcopters, and quadrupeds. Unlike prior work, our model does not require manual alignment of the observation or action spaces. Extensive experiments in the real world show that our method matches the performance of specialist policies tailored for each embodiment, while also significantly outperforming the prior state of the art in cross-embodiment learning.","sentences":["Modern machine learning systems rely on large datasets to attain broad generalization, and this often poses a challenge in robot learning, where each robotic platform and task might have only a small dataset.","By training a single policy across many different kinds of robots, a robot learning method can leverage much broader and more diverse datasets, which in turn can lead to better generalization and robustness.","However, training a single policy on multi-robot data is challenging because robots can have widely varying sensors, actuators, and control frequencies.","We propose CrossFormer, a scalable and flexible transformer-based policy that can consume data from any embodiment.","We train CrossFormer on the largest and most diverse dataset to date, 900K trajectories across 20 different robot embodiments.","We demonstrate that the same network weights can control vastly different robots, including single and dual arm manipulation systems, wheeled robots, quadcopters, and quadrupeds.","Unlike prior work, our model does not require manual alignment of the observation or action spaces.","Extensive experiments in the real world show that our method matches the performance of specialist policies tailored for each embodiment, while also significantly outperforming the prior state of the art in cross-embodiment learning."],"url":"http://arxiv.org/abs/2408.11812v1"}
{"created":"2024-08-21 17:57:06","title":"EmbodiedSAM: Online Segment Any 3D Thing in Real Time","abstract":"Embodied tasks require the agent to fully understand 3D scenes simultaneously with its exploration, so an online, real-time, fine-grained and highly-generalized 3D perception model is desperately needed. Since high-quality 3D data is limited, directly training such a model in 3D is almost infeasible. Meanwhile, vision foundation models (VFM) has revolutionized the field of 2D computer vision with superior performance, which makes the use of VFM to assist embodied 3D perception a promising direction. However, most existing VFM-assisted 3D perception methods are either offline or too slow that cannot be applied in practical embodied tasks. In this paper, we aim to leverage Segment Anything Model (SAM) for real-time 3D instance segmentation in an online setting. This is a challenging problem since future frames are not available in the input streaming RGB-D video, and an instance may be observed in several frames so object matching between frames is required. To address these challenges, we first propose a geometric-aware query lifting module to represent the 2D masks generated by SAM by 3D-aware queries, which is then iteratively refined by a dual-level query decoder. In this way, the 2D masks are transferred to fine-grained shapes on 3D point clouds. Benefit from the query representation for 3D masks, we can compute the similarity matrix between the 3D masks from different views by efficient matrix operation, which enables real-time inference. Experiments on ScanNet, ScanNet200, SceneNN and 3RScan show our method achieves leading performance even compared with offline methods. Our method also demonstrates great generalization ability in several zero-shot dataset transferring experiments and show great potential in open-vocabulary and data-efficient setting. Code and demo are available at https://xuxw98.github.io/ESAM/, with only one RTX 3090 GPU required for training and evaluation.","sentences":["Embodied tasks require the agent to fully understand 3D scenes simultaneously with its exploration, so an online, real-time, fine-grained and highly-generalized 3D perception model is desperately needed.","Since high-quality 3D data is limited, directly training such a model in 3D is almost infeasible.","Meanwhile, vision foundation models (VFM) has revolutionized the field of 2D computer vision with superior performance, which makes the use of VFM to assist embodied 3D perception a promising direction.","However, most existing VFM-assisted 3D perception methods are either offline or too slow that cannot be applied in practical embodied tasks.","In this paper, we aim to leverage Segment Anything Model (SAM) for real-time 3D instance segmentation in an online setting.","This is a challenging problem since future frames are not available in the input streaming RGB-D video, and an instance may be observed in several frames so object matching between frames is required.","To address these challenges, we first propose a geometric-aware query lifting module to represent the 2D masks generated by SAM by 3D-aware queries, which is then iteratively refined by a dual-level query decoder.","In this way, the 2D masks are transferred to fine-grained shapes on 3D point clouds.","Benefit from the query representation for 3D masks, we can compute the similarity matrix between the 3D masks from different views by efficient matrix operation, which enables real-time inference.","Experiments on ScanNet, ScanNet200, SceneNN and 3RScan show our method achieves leading performance even compared with offline methods.","Our method also demonstrates great generalization ability in several zero-shot dataset transferring experiments and show great potential in open-vocabulary and data-efficient setting.","Code and demo are available at https://xuxw98.github.io/ESAM/, with only one RTX 3090 GPU required for training and evaluation."],"url":"http://arxiv.org/abs/2408.11811v1"}
{"created":"2024-08-21 17:56:34","title":"Pixel Is Not A Barrier: An Effective Evasion Attack for Pixel-Domain Diffusion Models","abstract":"Diffusion Models have emerged as powerful generative models for high-quality image synthesis, with many subsequent image editing techniques based on them. However, the ease of text-based image editing introduces significant risks, such as malicious editing for scams or intellectual property infringement. Previous works have attempted to safeguard images from diffusion-based editing by adding imperceptible perturbations. These methods are costly and specifically target prevalent Latent Diffusion Models (LDMs), while Pixel-domain Diffusion Models (PDMs) remain largely unexplored and robust against such attacks. Our work addresses this gap by proposing a novel attacking framework with a feature representation attack loss that exploits vulnerabilities in denoising UNets and a latent optimization strategy to enhance the naturalness of protected images. Extensive experiments demonstrate the effectiveness of our approach in attacking dominant PDM-based editing methods (e.g., SDEdit) while maintaining reasonable protection fidelity and robustness against common defense methods. Additionally, our framework is extensible to LDMs, achieving comparable performance to existing approaches.","sentences":["Diffusion Models have emerged as powerful generative models for high-quality image synthesis, with many subsequent image editing techniques based on them.","However, the ease of text-based image editing introduces significant risks, such as malicious editing for scams or intellectual property infringement.","Previous works have attempted to safeguard images from diffusion-based editing by adding imperceptible perturbations.","These methods are costly and specifically target prevalent Latent Diffusion Models (LDMs), while Pixel-domain Diffusion Models (PDMs) remain largely unexplored and robust against such attacks.","Our work addresses this gap by proposing a novel attacking framework with a feature representation attack loss that exploits vulnerabilities in denoising UNets and a latent optimization strategy to enhance the naturalness of protected images.","Extensive experiments demonstrate the effectiveness of our approach in attacking dominant PDM-based editing methods (e.g., SDEdit) while maintaining reasonable protection fidelity and robustness against common defense methods.","Additionally, our framework is extensible to LDMs, achieving comparable performance to existing approaches."],"url":"http://arxiv.org/abs/2408.11810v1"}
{"created":"2024-08-21 17:54:04","title":"Informed, Constrained, Aligned: A Field Analysis on Degeneracy-aware Point Cloud Registration in the Wild","abstract":"The ICP registration algorithm has been a preferred method for LiDAR-based robot localization for nearly a decade. However, even in modern SLAM solutions, ICP can degrade and become unreliable in geometrically ill-conditioned environments. Current solutions primarily focus on utilizing additional sources of information, such as external odometry, to either replace the degenerate directions of the optimization solution or add additional constraints in a sensor-fusion setup afterward. In response, this work investigates and compares new and existing degeneracy mitigation methods for robust LiDAR-based localization and analyzes the efficacy of these approaches in degenerate environments for the first time in the literature at this scale. Specifically, this work proposes and investigates i) the incorporation of different types of constraints into the ICP algorithm, ii) the effect of using active or passive degeneracy mitigation techniques, and iii) the choice of utilizing global point cloud registration methods on the ill-conditioned ICP problem in LiDAR degenerate environments. The study results are validated through multiple real-world field and simulated experiments. The analysis shows that active optimization degeneracy mitigation is necessary and advantageous in the absence of reliable external estimate assistance for LiDAR-SLAM. Furthermore, introducing degeneracy-aware hard constraints in the optimization before or during the optimization is shown to perform better in the wild than by including the constraints after. Moreover, with heuristic fine-tuned parameters, soft constraints can provide equal or better results in complex ill-conditioned scenarios. The implementations used in the analysis of this work are made publicly available to the community.","sentences":["The ICP registration algorithm has been a preferred method for LiDAR-based robot localization for nearly a decade.","However, even in modern SLAM solutions, ICP can degrade and become unreliable in geometrically ill-conditioned environments.","Current solutions primarily focus on utilizing additional sources of information, such as external odometry, to either replace the degenerate directions of the optimization solution or add additional constraints in a sensor-fusion setup afterward.","In response, this work investigates and compares new and existing degeneracy mitigation methods for robust LiDAR-based localization and analyzes the efficacy of these approaches in degenerate environments for the first time in the literature at this scale.","Specifically, this work proposes and investigates i) the incorporation of different types of constraints into the ICP algorithm, ii) the effect of using active or passive degeneracy mitigation techniques, and iii) the choice of utilizing global point cloud registration methods on the ill-conditioned ICP problem in LiDAR degenerate environments.","The study results are validated through multiple real-world field and simulated experiments.","The analysis shows that active optimization degeneracy mitigation is necessary and advantageous in the absence of reliable external estimate assistance for LiDAR-SLAM.","Furthermore, introducing degeneracy-aware hard constraints in the optimization before or during the optimization is shown to perform better in the wild than by including the constraints after.","Moreover, with heuristic fine-tuned parameters, soft constraints can provide equal or better results in complex ill-conditioned scenarios.","The implementations used in the analysis of this work are made publicly available to the community."],"url":"http://arxiv.org/abs/2408.11809v1"}
{"created":"2024-08-21 17:48:41","title":"Counting simplicial pairs in hypergraphs","abstract":"We present two ways to measure the simplicial nature of a hypergraph: the simplicial ratio and the simplicial matrix. We show that the simplicial ratio captures the frequency, as well as the rarity, of simplicial interactions in a hypergraph while the simplicial matrix provides more fine-grained details. We then compute the simplicial ratio, as well as the simplicial matrix, for 10 real-world hypergraphs and, from the data collected, hypothesize that simplicial interactions are more and more deliberate as edge size increases. We then present a new Chung-Lu model that includes a parameter controlling (in expectation) the frequency of simplicial interactions. We use this new model, as well as the real-world hypergraphs, to show that multiple stochastic processes exhibit different behaviour when performed on simplicial hypergraphs vs. non-simplicial hypergraphs.","sentences":["We present two ways to measure the simplicial nature of a hypergraph: the simplicial ratio and the simplicial matrix.","We show that the simplicial ratio captures the frequency, as well as the rarity, of simplicial interactions in a hypergraph while the simplicial matrix provides more fine-grained details.","We then compute the simplicial ratio, as well as the simplicial matrix, for 10 real-world hypergraphs and, from the data collected, hypothesize that simplicial interactions are more and more deliberate as edge size increases.","We then present a new Chung-Lu model that includes a parameter controlling (in expectation) the frequency of simplicial interactions.","We use this new model, as well as the real-world hypergraphs, to show that multiple stochastic processes exhibit different behaviour when performed on simplicial hypergraphs vs. non-simplicial hypergraphs."],"url":"http://arxiv.org/abs/2408.11806v1"}
{"created":"2024-08-21 17:48:31","title":"ACE: A Cross-Platform Visual-Exoskeletons System for Low-Cost Dexterous Teleoperation","abstract":"Learning from demonstrations has shown to be an effective approach to robotic manipulation, especially with the recently collected large-scale robot data with teleoperation systems. Building an efficient teleoperation system across diverse robot platforms has become more crucial than ever. However, there is a notable lack of cost-effective and user-friendly teleoperation systems for different end-effectors, e.g., anthropomorphic robot hands and grippers, that can operate across multiple platforms. To address this issue, we develop ACE, a cross-platform visual-exoskeleton system for low-cost dexterous teleoperation. Our system utilizes a hand-facing camera to capture 3D hand poses and an exoskeleton mounted on a portable base, enabling accurate real-time capture of both finger and wrist poses. Compared to previous systems, which often require hardware customization according to different robots, our single system can generalize to humanoid hands, arm-hands, arm-gripper, and quadruped-gripper systems with high-precision teleoperation. This enables imitation learning for complex manipulation tasks on diverse platforms.","sentences":["Learning from demonstrations has shown to be an effective approach to robotic manipulation, especially with the recently collected large-scale robot data with teleoperation systems.","Building an efficient teleoperation system across diverse robot platforms has become more crucial than ever.","However, there is a notable lack of cost-effective and user-friendly teleoperation systems for different end-effectors, e.g., anthropomorphic robot hands and grippers, that can operate across multiple platforms.","To address this issue, we develop ACE, a cross-platform visual-exoskeleton system for low-cost dexterous teleoperation.","Our system utilizes a hand-facing camera to capture 3D hand poses and an exoskeleton mounted on a portable base, enabling accurate real-time capture of both finger and wrist poses.","Compared to previous systems, which often require hardware customization according to different robots, our single system can generalize to humanoid hands, arm-hands, arm-gripper, and quadruped-gripper systems with high-precision teleoperation.","This enables imitation learning for complex manipulation tasks on diverse platforms."],"url":"http://arxiv.org/abs/2408.11805v1"}
{"created":"2024-08-21 17:48:01","title":"Approaching Deep Learning through the Spectral Dynamics of Weights","abstract":"We propose an empirical approach centered on the spectral dynamics of weights -- the behavior of singular values and vectors during optimization -- to unify and clarify several phenomena in deep learning. We identify a consistent bias in optimization across various experiments, from small-scale ``grokking'' to large-scale tasks like image classification with ConvNets, image generation with UNets, speech recognition with LSTMs, and language modeling with Transformers. We also demonstrate that weight decay enhances this bias beyond its role as a norm regularizer, even in practical systems. Moreover, we show that these spectral dynamics distinguish memorizing networks from generalizing ones, offering a novel perspective on this longstanding conundrum. Additionally, we leverage spectral dynamics to explore the emergence of well-performing sparse subnetworks (lottery tickets) and the structure of the loss surface through linear mode connectivity. Our findings suggest that spectral dynamics provide a coherent framework to better understand the behavior of neural networks across diverse settings.","sentences":["We propose an empirical approach centered on the spectral dynamics of weights -- the behavior of singular values and vectors during optimization -- to unify and clarify several phenomena in deep learning.","We identify a consistent bias in optimization across various experiments, from small-scale ``grokking'' to large-scale tasks like image classification with ConvNets, image generation with UNets, speech recognition with LSTMs, and language modeling with Transformers.","We also demonstrate that weight decay enhances this bias beyond its role as a norm regularizer, even in practical systems.","Moreover, we show that these spectral dynamics distinguish memorizing networks from generalizing ones, offering a novel perspective on this longstanding conundrum.","Additionally, we leverage spectral dynamics to explore the emergence of well-performing sparse subnetworks (lottery tickets) and the structure of the loss surface through linear mode connectivity.","Our findings suggest that spectral dynamics provide a coherent framework to better understand the behavior of neural networks across diverse settings."],"url":"http://arxiv.org/abs/2408.11804v1"}
{"created":"2024-08-21 17:43:15","title":"Story3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models","abstract":"Traditional visual storytelling is complex, requiring specialized knowledge and substantial resources, yet often constrained by human creativity and creation precision. While Large Language Models (LLMs) enhance visual storytelling, current approaches often limit themselves to 2D visuals or oversimplify stories through motion synthesis and behavioral simulation, failing to create comprehensive, multi-dimensional narratives. To this end, we present Story3D-Agent, a pioneering approach that leverages the capabilities of LLMs to transform provided narratives into 3D-rendered visualizations. By integrating procedural modeling, our approach enables precise control over multi-character actions and motions, as well as diverse decorative elements, ensuring the long-range and dynamic 3D representation. Furthermore, our method supports narrative extension through logical reasoning, ensuring that generated content remains consistent with existing conditions. We have thoroughly evaluated our Story3D-Agent to validate its effectiveness, offering a basic framework to advance 3D story representation.","sentences":["Traditional visual storytelling is complex, requiring specialized knowledge and substantial resources, yet often constrained by human creativity and creation precision.","While Large Language Models (LLMs) enhance visual storytelling, current approaches often limit themselves to 2D visuals or oversimplify stories through motion synthesis and behavioral simulation, failing to create comprehensive, multi-dimensional narratives.","To this end, we present Story3D-Agent, a pioneering approach that leverages the capabilities of LLMs to transform provided narratives into 3D-rendered visualizations.","By integrating procedural modeling, our approach enables precise control over multi-character actions and motions, as well as diverse decorative elements, ensuring the long-range and dynamic 3D representation.","Furthermore, our method supports narrative extension through logical reasoning, ensuring that generated content remains consistent with existing conditions.","We have thoroughly evaluated our Story3D-Agent to validate its effectiveness, offering a basic framework to advance 3D story representation."],"url":"http://arxiv.org/abs/2408.11801v1"}
{"created":"2024-08-21 17:43:11","title":"PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain","abstract":"In the rapidly evolving landscape of Natural Language Processing (NLP) and text generation, the emergence of Retrieval Augmented Generation (RAG) presents a promising avenue for improving the quality and reliability of generated text by leveraging information retrieved from user specified database. Benchmarking is essential to evaluate and compare the performance of the different RAG configurations in terms of retriever and generator, providing insights into their effectiveness, scalability, and suitability for the specific domain and applications. In this paper, we present a comprehensive framework to generate a domain relevant RAG benchmark. Our framework is based on automatic question-answer generation with Human (domain experts)-AI Large Language Model (LLM) teaming. As a case study, we demonstrate the framework by introducing PermitQA, a first-of-its-kind benchmark on the wind siting and permitting domain which comprises of multiple scientific documents/reports related to environmental impact of wind energy projects. Our framework systematically evaluates RAG performance using diverse metrics and multiple question types with varying complexity level. We also demonstrate the performance of different models on our benchmark.","sentences":["In the rapidly evolving landscape of Natural Language Processing (NLP) and text generation, the emergence of Retrieval Augmented Generation (RAG) presents a promising avenue for improving the quality and reliability of generated text by leveraging information retrieved from user specified database.","Benchmarking is essential to evaluate and compare the performance of the different RAG configurations in terms of retriever and generator, providing insights into their effectiveness, scalability, and suitability for the specific domain and applications.","In this paper, we present a comprehensive framework to generate a domain relevant RAG benchmark.","Our framework is based on automatic question-answer generation with Human (domain experts)-AI Large Language Model (LLM) teaming.","As a case study, we demonstrate the framework by introducing PermitQA, a first-of-its-kind benchmark on the wind siting and permitting domain which comprises of multiple scientific documents/reports related to environmental impact of wind energy projects.","Our framework systematically evaluates RAG performance using diverse metrics and multiple question types with varying complexity level.","We also demonstrate the performance of different models on our benchmark."],"url":"http://arxiv.org/abs/2408.11800v1"}
{"created":"2024-08-21 17:42:17","title":"Practical token pruning for foundation models in few-shot conversational virtual assistant systems","abstract":"In an enterprise Virtual Assistant (VA) system, intent classification is the crucial component that determines how a user input is handled based on what the user wants. The VA system is expected to be a cost-efficient SaaS service with low training and inference time while achieving high accuracy even with a small number of training samples. We pretrain a transformer-based sentence embedding model with a contrastive learning objective and leverage the embedding of the model as features when training intent classification models. Our approach achieves the state-of-the-art results for few-shot scenarios and performs better than other commercial solutions on popular intent classification benchmarks. However, generating features via a transformer-based model increases the inference time, especially for longer user inputs, due to the quadratic runtime of the transformer's attention mechanism. On top of model distillation, we introduce a practical multi-task adaptation approach that configures dynamic token pruning without the need for task-specific training for intent classification. We demonstrate that this approach improves the inference speed of popular sentence transformer models without affecting model performance.","sentences":["In an enterprise Virtual Assistant (VA) system, intent classification is the crucial component that determines how a user input is handled based on what the user wants.","The VA system is expected to be a cost-efficient SaaS service with low training and inference time while achieving high accuracy even with a small number of training samples.","We pretrain a transformer-based sentence embedding model with a contrastive learning objective and leverage the embedding of the model as features when training intent classification models.","Our approach achieves the state-of-the-art results for few-shot scenarios and performs better than other commercial solutions on popular intent classification benchmarks.","However, generating features via a transformer-based model increases the inference time, especially for longer user inputs, due to the quadratic runtime of the transformer's attention mechanism.","On top of model distillation, we introduce a practical multi-task adaptation approach that configures dynamic token pruning without the need for task-specific training for intent classification.","We demonstrate that this approach improves the inference speed of popular sentence transformer models without affecting model performance."],"url":"http://arxiv.org/abs/2408.11799v1"}
{"created":"2024-08-21 17:41:42","title":"An Advanced Microscopic Energy Consumption Model for Automated Vehicle:Development, Calibration, Verification","abstract":"The automated vehicle (AV) equipped with the Adaptive Cruise Control (ACC) system is expected to reduce the fuel consumption for the intelligent transportation system. This paper presents the Advanced ACC-Micro (AA-Micro) model, a new energy consumption model based on micro trajectory data, calibrated and verified by empirical data. Utilizing a commercial AV equipped with the ACC system as the test platform, experiments were conducted at the Columbus 151 Speedway, capturing data from multiple ACC and Human-Driven (HV) test runs. The calibrated AA-Micro model integrates features from traditional energy consumption models and demonstrates superior goodness of fit, achieving an impressive 90% accuracy in predicting ACC system energy consumption without overfitting. A comprehensive statistical evaluation of the AA-Micro model's applicability and adaptability in predicting energy consumption and vehicle trajectories indicated strong model consistency and reliability for ACC vehicles, evidenced by minimal variance in RMSE values and uniform RSS distributions. Conversely, significant discrepancies were observed when applying the model to HV data, underscoring the necessity for specialized models to accurately predict energy consumption for HV and ACC systems, potentially due to their distinct energy consumption characteristics.","sentences":["The automated vehicle (AV) equipped with the Adaptive Cruise Control (ACC) system is expected to reduce the fuel consumption for the intelligent transportation system.","This paper presents the Advanced ACC-Micro (AA-Micro) model, a new energy consumption model based on micro trajectory data, calibrated and verified by empirical data.","Utilizing a commercial AV equipped with the ACC system as the test platform, experiments were conducted at the Columbus 151 Speedway, capturing data from multiple ACC and Human-Driven (HV) test runs.","The calibrated AA-Micro model integrates features from traditional energy consumption models and demonstrates superior goodness of fit, achieving an impressive 90% accuracy in predicting ACC system energy consumption without overfitting.","A comprehensive statistical evaluation of the AA-Micro model's applicability and adaptability in predicting energy consumption and vehicle trajectories indicated strong model consistency and reliability for ACC vehicles, evidenced by minimal variance in RMSE values and uniform RSS distributions.","Conversely, significant discrepancies were observed when applying the model to HV data, underscoring the necessity for specialized models to accurately predict energy consumption for HV and ACC systems, potentially due to their distinct energy consumption characteristics."],"url":"http://arxiv.org/abs/2408.11797v1"}
{"created":"2024-08-21 17:38:48","title":"LLM Pruning and Distillation in Practice: The Minitron Approach","abstract":"We present a comprehensive report on compressing the Llama 3.1 8B and Mistral NeMo 12B models to 4B and 8B parameters, respectively, using pruning and distillation. We explore two distinct pruning strategies: (1) depth pruning and (2) joint hidden/attention/MLP (width) pruning, and evaluate the results on common benchmarks from the LM Evaluation Harness. The models are then aligned with NeMo Aligner and tested in instruct-tuned versions. This approach produces a compelling 4B model from Llama 3.1 8B and a state-of-the-art Mistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo 12B. We found that with no access to the original data, it is beneficial to slightly fine-tune teacher models on the distillation dataset. We open-source our base model weights on Hugging Face with a permissive license.","sentences":["We present a comprehensive report on compressing the Llama 3.1 8B and Mistral NeMo 12B models to 4B and 8B parameters, respectively, using pruning and distillation.","We explore two distinct pruning strategies: (1) depth pruning and (2) joint hidden/attention/MLP (width) pruning, and evaluate the results on common benchmarks from the LM Evaluation Harness.","The models are then aligned with NeMo Aligner and tested in instruct-tuned versions.","This approach produces a compelling 4B model from Llama 3.1 8B and a state-of-the-art Mistral-NeMo-Minitron-8B (MN-Minitron-8B for brevity) model from Mistral NeMo 12B.","We found that with no access to the original data, it is beneficial to slightly fine-tune teacher models on the distillation dataset.","We open-source our base model weights on Hugging Face with a permissive license."],"url":"http://arxiv.org/abs/2408.11796v1"}
{"created":"2024-08-21 17:36:37","title":"EE-MLLM: A Data-Efficient and Compute-Efficient Multimodal Large Language Model","abstract":"In the realm of multimodal research, numerous studies leverage substantial image-text pairs to conduct modal alignment learning, transforming Large Language Models (LLMs) into Multimodal LLMs and excelling in a variety of visual-language tasks. The prevailing methodologies primarily fall into two categories: self-attention-based and cross-attention-based methods. While self-attention-based methods offer superior data efficiency due to their simple MLP architecture, they often suffer from lower computational efficiency due to concatenating visual and textual tokens as input for LLM. Conversely, cross-attention-based methods, although less data-efficient due to additional learnable parameters, exhibit higher computational efficiency by avoiding long sequence input for LLM. To address these trade-offs, we introduce the Data-Efficient and Compute-Efficient Multimodal Large Language Model (EE-MLLM). Without introducing additional modules or learnable parameters, EE-MLLM achieves both data and compute efficiency. Specifically, we modify the original self-attention mechanism in MLLM to a composite attention mechanism. This mechanism has two key characteristics: 1) Eliminating the computational overhead of self-attention within visual tokens to achieve compute efficiency, and 2) Reusing the weights on each layer of LLM to facilitate effective modality alignment between vision and language for data efficiency. Experimental results demonstrate the effectiveness of EE-MLLM across a range of benchmarks, including general-purpose datasets like MMBench and SeedBench, as well as fine-grained tasks such as TextVQA and DocVQA.","sentences":["In the realm of multimodal research, numerous studies leverage substantial image-text pairs to conduct modal alignment learning, transforming Large Language Models (LLMs) into Multimodal LLMs and excelling in a variety of visual-language tasks.","The prevailing methodologies primarily fall into two categories: self-attention-based and cross-attention-based methods.","While self-attention-based methods offer superior data efficiency due to their simple MLP architecture, they often suffer from lower computational efficiency due to concatenating visual and textual tokens as input for LLM.","Conversely, cross-attention-based methods, although less data-efficient due to additional learnable parameters, exhibit higher computational efficiency by avoiding long sequence input for LLM.","To address these trade-offs, we introduce the Data-Efficient and Compute-Efficient Multimodal Large Language Model (EE-MLLM).","Without introducing additional modules or learnable parameters, EE-MLLM achieves both data and compute efficiency.","Specifically, we modify the original self-attention mechanism in MLLM to a composite attention mechanism.","This mechanism has two key characteristics: 1) Eliminating the computational overhead of self-attention within visual tokens to achieve compute efficiency, and 2) Reusing the weights on each layer of LLM to facilitate effective modality alignment between vision and language for data efficiency.","Experimental results demonstrate the effectiveness of EE-MLLM across a range of benchmarks, including general-purpose datasets like MMBench and SeedBench, as well as fine-grained tasks such as TextVQA and DocVQA."],"url":"http://arxiv.org/abs/2408.11795v1"}
{"created":"2024-08-21 17:25:45","title":"Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design","abstract":"Molecular property prediction and generative design via deep learning models has been the subject of intense research given its potential to accelerate development of new, high-performance materials. More recently, these workflows have been significantly augmented with the advent of large language models (LLMs) and systems of LLM-driven agents capable of utilizing pre-trained models to make predictions in the context of more complex research tasks. While effective, there is still room for substantial improvement within the agentic systems on the retrieval of salient information for material design tasks. Moreover, alternative uses of predictive deep learning models, such as leveraging their latent representations to facilitate cross-modal retrieval augmented generation within agentic systems to enable task-specific materials design, has remained unexplored. Herein, we demonstrate that large, pre-trained chemistry foundation models can serve as a basis for enabling semantic chemistry information retrieval for both small-molecules, complex polymeric materials, and reactions. Additionally, we show the use of chemistry foundation models in conjunction with image models such as OpenCLIP facilitate unprecedented queries and information retrieval across multiple characterization data domains. Finally, we demonstrate the integration of these systems within multi-agent systems to facilitate structure and topological-based natural language queries and information retrieval for complex research tasks.","sentences":["Molecular property prediction and generative design via deep learning models has been the subject of intense research given its potential to accelerate development of new, high-performance materials.","More recently, these workflows have been significantly augmented with the advent of large language models (LLMs) and systems of LLM-driven agents capable of utilizing pre-trained models to make predictions in the context of more complex research tasks.","While effective, there is still room for substantial improvement within the agentic systems on the retrieval of salient information for material design tasks.","Moreover, alternative uses of predictive deep learning models, such as leveraging their latent representations to facilitate cross-modal retrieval augmented generation within agentic systems to enable task-specific materials design, has remained unexplored.","Herein, we demonstrate that large, pre-trained chemistry foundation models can serve as a basis for enabling semantic chemistry information retrieval for both small-molecules, complex polymeric materials, and reactions.","Additionally, we show the use of chemistry foundation models in conjunction with image models such as OpenCLIP facilitate unprecedented queries and information retrieval across multiple characterization data domains.","Finally, we demonstrate the integration of these systems within multi-agent systems to facilitate structure and topological-based natural language queries and information retrieval for complex research tasks."],"url":"http://arxiv.org/abs/2408.11793v1"}
{"created":"2024-08-21 17:25:40","title":"Optical ISAC: Fundamental Performance Limits and Transceiver Design","abstract":"This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point (P2P) system with single-input single-output for communication and single-input multiple-output for sensing (SISO-SIMO-C/S) within an integrated sensing and communication (ISAC) framework. We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors. Our results show these estimators converge to the Bayesian Cramer-Rao bound (BCRB) as sensing antennas increase. We also demonstrate that the achievable rate-CRB (AR-CRB) serves as an outer bound (OB) for the optimal C-D region. To optimize input distribution across the Pareto boundary of the C-D region, we propose two algorithms: an iterative Blahut-Arimoto algorithm (BAA)-type method and a memory-efficient closed-form (CF) approach, including a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions. Additionally, we extend and modify the Deterministic-Random Tradeoff (DRT) to this optical ISAC context.","sentences":["This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point (P2P) system with single-input single-output for communication and single-input multiple-output for sensing (SISO-SIMO-C/S) within an integrated sensing and communication (ISAC) framework.","We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors.","Our results show these estimators converge to the Bayesian Cramer-Rao bound (BCRB) as sensing antennas increase.","We also demonstrate that the achievable rate-CRB (AR-CRB) serves as an outer bound (OB) for the optimal C-D region.","To optimize input distribution across the Pareto boundary of the C-D region, we propose two algorithms: an iterative Blahut-Arimoto algorithm (BAA)-type method and a memory-efficient closed-form (CF) approach, including a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions.","Additionally, we extend and modify the Deterministic-Random Tradeoff (DRT) to this optical ISAC context."],"url":"http://arxiv.org/abs/2408.11792v1"}
{"created":"2024-08-21 17:24:15","title":"Critique-out-Loud Reward Models","abstract":"Traditionally, reward models used for reinforcement learning from human feedback (RLHF) are trained to directly predict preference scores without leveraging the generation capabilities of the underlying large language model (LLM). This limits the capabilities of reward models as they must reason implicitly about the quality of a response, i.e., preference modeling must be performed in a single forward pass through the model. To enable reward models to reason explicitly about the quality of a response, we introduce Critique-out-Loud (CLoud) reward models. CLoud reward models operate by first generating a natural language critique of the assistant's response that is then used to predict a scalar reward for the quality of the response. We demonstrate the success of CLoud reward models for both Llama-3-8B and 70B base models: compared to classic reward models CLoud reward models improve pairwise preference classification accuracy on RewardBench by 4.65 and 5.84 percentage points for the 8B and 70B base models respectively. Furthermore, CLoud reward models lead to a Pareto improvement for win rate on ArenaHard when used as the scoring model for Best-of-N. Finally, we explore how to exploit the dynamic inference compute capabilities of CLoud reward models by performing self-consistency decoding for reward prediction.","sentences":["Traditionally, reward models used for reinforcement learning from human feedback (RLHF) are trained to directly predict preference scores without leveraging the generation capabilities of the underlying large language model (LLM).","This limits the capabilities of reward models as they must reason implicitly about the quality of a response, i.e., preference modeling must be performed in a single forward pass through the model.","To enable reward models to reason explicitly about the quality of a response, we introduce Critique-out-Loud (CLoud) reward models.","CLoud reward models operate by first generating a natural language critique of the assistant's response that is then used to predict a scalar reward for the quality of the response.","We demonstrate the success of CLoud reward models for both Llama-3-8B and 70B base models: compared to classic reward models CLoud reward models improve pairwise preference classification accuracy on RewardBench by 4.65 and 5.84 percentage points for the 8B and 70B base models respectively.","Furthermore, CLoud reward models lead to a Pareto improvement for win rate on ArenaHard when used as the scoring model for Best-of-N. Finally, we explore how to exploit the dynamic inference compute capabilities of CLoud reward models by performing self-consistency decoding for reward prediction."],"url":"http://arxiv.org/abs/2408.11791v1"}
{"created":"2024-08-21 17:21:13","title":"DreamFactory: Pioneering Multi-Scene Long Video Generation with a Multi-Agent Framework","abstract":"Current video generation models excel at creating short, realistic clips, but struggle with longer, multi-scene videos. We introduce \\texttt{DreamFactory}, an LLM-based framework that tackles this challenge. \\texttt{DreamFactory} leverages multi-agent collaboration principles and a Key Frames Iteration Design Method to ensure consistency and style across long videos. It utilizes Chain of Thought (COT) to address uncertainties inherent in large language models. \\texttt{DreamFactory} generates long, stylistically coherent, and complex videos. Evaluating these long-form videos presents a challenge. We propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene Style Consistency Score. To further research in this area, we contribute the Multi-Scene Videos Dataset containing over 150 human-rated videos.","sentences":["Current video generation models excel at creating short, realistic clips, but struggle with longer, multi-scene videos.","We introduce \\texttt{DreamFactory}, an LLM-based framework that tackles this challenge.","\\texttt{DreamFactory} leverages multi-agent collaboration principles and a Key Frames Iteration Design Method to ensure consistency and style across long videos.","It utilizes Chain of Thought (COT) to address uncertainties inherent in large language models.","\\texttt{DreamFactory} generates long, stylistically coherent, and complex videos.","Evaluating these long-form videos presents a challenge.","We propose novel metrics such as Cross-Scene Face Distance Score and Cross-Scene Style Consistency Score.","To further research in this area, we contribute the Multi-Scene Videos Dataset containing over 150 human-rated videos."],"url":"http://arxiv.org/abs/2408.11788v1"}
{"created":"2024-08-21 17:16:21","title":"Timeline and Boundary Guided Diffusion Network for Video Shadow Detection","abstract":"Video Shadow Detection (VSD) aims to detect the shadow masks with frame sequence. Existing works suffer from inefficient temporal learning. Moreover, few works address the VSD problem by considering the characteristic (i.e., boundary) of shadow. Motivated by this, we propose a Timeline and Boundary Guided Diffusion (TBGDiff) network for VSD where we take account of the past-future temporal guidance and boundary information jointly. In detail, we design a Dual Scale Aggregation (DSA) module for better temporal understanding by rethinking the affinity of the long-term and short-term frames for the clipped video. Next, we introduce Shadow Boundary Aware Attention (SBAA) to utilize the edge contexts for capturing the characteristics of shadows. Moreover, we are the first to introduce the Diffusion model for VSD in which we explore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance for Diffusion to conduct shadow detection. Benefiting from these designs, our model can not only capture the temporal information but also the shadow property. Extensive experiments show that the performance of our approach overtakes the state-of-the-art methods, verifying the effectiveness of our components. We release the codes, weights, and results at \\url{https://github.com/haipengzhou856/TBGDiff}.","sentences":["Video Shadow Detection (VSD) aims to detect the shadow masks with frame sequence.","Existing works suffer from inefficient temporal learning.","Moreover, few works address the VSD problem by considering the characteristic (i.e., boundary) of shadow.","Motivated by this, we propose a Timeline and Boundary Guided Diffusion (TBGDiff) network for VSD where we take account of the past-future temporal guidance and boundary information jointly.","In detail, we design a Dual Scale Aggregation (DSA) module for better temporal understanding by rethinking the affinity of the long-term and short-term frames for the clipped video.","Next, we introduce Shadow Boundary Aware Attention (SBAA) to utilize the edge contexts for capturing the characteristics of shadows.","Moreover, we are the first to introduce the Diffusion model for VSD in which we explore a Space-Time Encoded Embedding (STEE) to inject the temporal guidance for Diffusion to conduct shadow detection.","Benefiting from these designs, our model can not only capture the temporal information but also the shadow property.","Extensive experiments show that the performance of our approach overtakes the state-of-the-art methods, verifying the effectiveness of our components.","We release the codes, weights, and results at \\url{https://github.com/haipengzhou856/TBGDiff}."],"url":"http://arxiv.org/abs/2408.11785v1"}
{"created":"2024-08-21 17:12:40","title":"RFID based Health Adherence Medicine Case Using Fair Federated Learning","abstract":"Medication nonadherence significantly reduces the effectiveness of therapies, yet it remains prevalent among patients. Nonadherence has been linked to adverse outcomes, including increased risks of mortality and hospitalization. Although various methods exist to help patients track medication schedules, such as the Intelligent Drug Administration System (IDAS) and Smart Blister, these tools often face challenges that hinder their commercial viability. Building on the principles of dosage measurement and information communication in IoT, we introduce the Smart Pill Case a smart health adherence tool that leverages RFID-based data recording and NFC-based data extraction. This system incorporates a load cell for precise dosage measurement and features an Android app to monitor medication intake, offer suggestions, and issue warnings. To enhance the effectiveness and personalization of the Smart Pill Case, we propose integrating federated learning into the system. Federated learning allows the Smart Pill Case to learn from medication adherence patterns across multiple users without compromising individual privacy. By training machine learning models on decentralized data collected from various Smart Pill Cases, the system can continuously improve its recommendations and warnings, adapting to the diverse needs and behaviors of users. This approach not only enhances the tools ability to support medication adherence but also ensures that sensitive user data remains secure and private.","sentences":["Medication nonadherence significantly reduces the effectiveness of therapies, yet it remains prevalent among patients.","Nonadherence has been linked to adverse outcomes, including increased risks of mortality and hospitalization.","Although various methods exist to help patients track medication schedules, such as the Intelligent Drug Administration System (IDAS) and Smart Blister, these tools often face challenges that hinder their commercial viability.","Building on the principles of dosage measurement and information communication in IoT, we introduce the Smart Pill Case a smart health adherence tool that leverages RFID-based data recording and NFC-based data extraction.","This system incorporates a load cell for precise dosage measurement and features an Android app to monitor medication intake, offer suggestions, and issue warnings.","To enhance the effectiveness and personalization of the Smart Pill Case, we propose integrating federated learning into the system.","Federated learning allows the Smart Pill Case to learn from medication adherence patterns across multiple users without compromising individual privacy.","By training machine learning models on decentralized data collected from various Smart Pill Cases, the system can continuously improve its recommendations and warnings, adapting to the diverse needs and behaviors of users.","This approach not only enhances the tools ability to support medication adherence but also ensures that sensitive user data remains secure and private."],"url":"http://arxiv.org/abs/2408.11782v1"}
{"created":"2024-08-21 17:09:00","title":"Personality Alignment of Large Language Models","abstract":"Current methods for aligning large language models (LLMs) typically aim to reflect general human values and behaviors, but they often fail to capture the unique characteristics and preferences of individual users. To address this gap, we introduce the concept of Personality Alignment. This approach tailors LLMs' responses and decisions to match the specific preferences of individual users or closely related groups. Inspired by psychometrics, we created the Personality Alignment with Personality Inventories (PAPI) dataset, which includes data from 300,000 real subjects, each providing behavioral preferences based on the Big Five Personality Factors. This dataset allows us to quantitatively evaluate the extent to which LLMs can align with each subject's behavioral patterns. Recognizing the challenges of personality alignments: such as limited personal data, diverse preferences, and scalability requirements: we developed an activation intervention optimization method. This method enhances LLMs' ability to efficiently align with individual behavioral preferences using minimal data and computational resources. Remarkably, our method, PAS, achieves superior performance while requiring only 1/5 of the optimization time compared to DPO, offering practical value for personality alignment. Our work paves the way for future AI systems to make decisions and reason in truly personality ways, enhancing the relevance and meaning of AI interactions for each user and advancing human-centered artificial intelligence.The code has released in \\url{https://github.com/zhu-minjun/PAlign}.","sentences":["Current methods for aligning large language models (LLMs) typically aim to reflect general human values and behaviors, but they often fail to capture the unique characteristics and preferences of individual users.","To address this gap, we introduce the concept of Personality Alignment.","This approach tailors LLMs' responses and decisions to match the specific preferences of individual users or closely related groups.","Inspired by psychometrics, we created the Personality Alignment with Personality Inventories (PAPI) dataset, which includes data from 300,000 real subjects, each providing behavioral preferences based on the Big Five Personality Factors.","This dataset allows us to quantitatively evaluate the extent to which LLMs can align with each subject's behavioral patterns.","Recognizing the challenges of personality alignments: such as limited personal data, diverse preferences, and scalability requirements: we developed an activation intervention optimization method.","This method enhances LLMs' ability to efficiently align with individual behavioral preferences using minimal data and computational resources.","Remarkably, our method, PAS, achieves superior performance while requiring only 1/5 of the optimization time compared to DPO, offering practical value for personality alignment.","Our work paves the way for future AI systems to make decisions and reason in truly personality ways, enhancing the relevance and meaning of AI interactions for each user and advancing human-centered artificial intelligence.","The code has released in \\url{https://github.com/zhu-minjun/PAlign}."],"url":"http://arxiv.org/abs/2408.11779v1"}
{"created":"2024-08-21 17:08:05","title":"Sum of Squares Circuits","abstract":"Designing expressive generative models that support exact and efficient inference is a core question in probabilistic ML. Probabilistic circuits (PCs) offer a framework where this tractability-vs-expressiveness trade-off can be analyzed theoretically. Recently, squared PCs encoding subtractive mixtures via negative parameters have emerged as tractable models that can be exponentially more expressive than monotonic PCs, i.e., PCs with positive parameters only. In this paper, we provide a more precise theoretical characterization of the expressiveness relationships among these models. First, we prove that squared PCs can be less expressive than monotonic ones. Second, we formalize a novel class of PCs -- sum of squares PCs -- that can be exponentially more expressive than both squared and monotonic PCs. Around sum of squares PCs, we build an expressiveness hierarchy that allows us to precisely unify and separate different tractable model classes such as Born Machines and PSD models, and other recently introduced tractable probabilistic models by using complex parameters. Finally, we empirically show the effectiveness of sum of squares circuits in performing distribution estimation.","sentences":["Designing expressive generative models that support exact and efficient inference is a core question in probabilistic ML.","Probabilistic circuits (PCs) offer a framework where this tractability-vs-expressiveness trade-off can be analyzed theoretically.","Recently, squared PCs encoding subtractive mixtures via negative parameters have emerged as tractable models that can be exponentially more expressive than monotonic PCs, i.e., PCs with positive parameters only.","In this paper, we provide a more precise theoretical characterization of the expressiveness relationships among these models.","First, we prove that squared PCs can be less expressive than monotonic ones.","Second, we formalize a novel class of PCs -- sum of squares PCs -- that can be exponentially more expressive than both squared and monotonic PCs.","Around sum of squares PCs, we build an expressiveness hierarchy that allows us to precisely unify and separate different tractable model classes such as Born Machines and PSD models, and other recently introduced tractable probabilistic models by using complex parameters.","Finally, we empirically show the effectiveness of sum of squares circuits in performing distribution estimation."],"url":"http://arxiv.org/abs/2408.11778v1"}
{"created":"2024-08-21 17:06:18","title":"CI/CD Efforts for Validation, Verification and Benchmarking OpenMP Implementations","abstract":"Software developers must adapt to keep up with the changing capabilities of platforms so that they can utilize the power of High- Performance Computers (HPC), including exascale systems. OpenMP, a directive-based parallel programming model, allows developers to include directives to existing C, C++, or Fortran code to allow node level parallelism without compromising performance. This paper describes our CI/CD efforts to provide easy evaluation of the support of OpenMP across different compilers using existing testsuites and benchmark suites on HPC platforms. Our main contributions include (1) the set of a Continuous Integration (CI) and Continuous Development (CD) workflow that captures bugs and provides faster feedback to compiler developers, (2) an evaluation of OpenMP (offloading) implementations supported by AMD, HPE, GNU, LLVM, and Intel, and (3) evaluation of the quality of compilers across different heterogeneous HPC platforms. With the comprehensive testing through the CI/CD workflow, we aim to provide a comprehensive understanding of the current state of OpenMP (offloading) support in different compilers and heterogeneous platforms consisting of CPUs and GPUs from NVIDIA, AMD, and Intel.","sentences":["Software developers must adapt to keep up with the changing capabilities of platforms so that they can utilize the power of High- Performance Computers (HPC), including exascale systems.","OpenMP, a directive-based parallel programming model, allows developers to include directives to existing C, C++, or Fortran code to allow node level parallelism without compromising performance.","This paper describes our CI/CD efforts to provide easy evaluation of the support of OpenMP across different compilers using existing testsuites and benchmark suites on HPC platforms.","Our main contributions include (1) the set of a Continuous Integration (CI) and Continuous Development (CD) workflow that captures bugs and provides faster feedback to compiler developers, (2) an evaluation of OpenMP (offloading) implementations supported by AMD, HPE, GNU, LLVM, and Intel, and (3) evaluation of the quality of compilers across different heterogeneous HPC platforms.","With the comprehensive testing through the CI/CD workflow, we aim to provide a comprehensive understanding of the current state of OpenMP (offloading) support in different compilers and heterogeneous platforms consisting of CPUs and GPUs from NVIDIA, AMD, and Intel."],"url":"http://arxiv.org/abs/2408.11777v1"}
{"created":"2024-08-21 17:00:05","title":"Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards","abstract":"Recent studies show that large language models (LLMs) struggle with technical standards in telecommunications. We propose a fine-tuned retrieval-augmented generation (RAG) system based on the Phi-2 small language model (SLM) to serve as an oracle for communication networks. Our developed system leverages forward-looking semantic chunking to adaptively determine parsing breakpoints based on embedding similarity, enabling effective processing of diverse document formats. To handle the challenge of multiple similar contexts in technical standards, we employ a re-ranking algorithm to prioritize the most relevant retrieved chunks. Recognizing the limitations of Phi-2's small context window, we implement a recent technique, namely SelfExtend, to expand the context window during inference, which not only boosts the performance but also can accommodate a wider range of user queries and design requirements from customers to specialized technicians. For fine-tuning, we utilize the low-rank adaptation (LoRA) technique to enhance computational efficiency during training and enable effective fine-tuning on small datasets. Our comprehensive experiments demonstrate substantial improvements over existing question-answering approaches in the telecom domain, achieving performance that exceeds larger language models such as GPT-4 (which is about 880 times larger in size). This work presents a novel approach to leveraging SLMs for communication networks, offering a balance of efficiency and performance. This work can serve as a foundation towards agentic language models for networks.","sentences":["Recent studies show that large language models (LLMs) struggle with technical standards in telecommunications.","We propose a fine-tuned retrieval-augmented generation (RAG) system based on the Phi-2 small language model (SLM) to serve as an oracle for communication networks.","Our developed system leverages forward-looking semantic chunking to adaptively determine parsing breakpoints based on embedding similarity, enabling effective processing of diverse document formats.","To handle the challenge of multiple similar contexts in technical standards, we employ a re-ranking algorithm to prioritize the most relevant retrieved chunks.","Recognizing the limitations of Phi-2's small context window, we implement a recent technique, namely SelfExtend, to expand the context window during inference, which not only boosts the performance but also can accommodate a wider range of user queries and design requirements from customers to specialized technicians.","For fine-tuning, we utilize the low-rank adaptation (LoRA) technique to enhance computational efficiency during training and enable effective fine-tuning on small datasets.","Our comprehensive experiments demonstrate substantial improvements over existing question-answering approaches in the telecom domain, achieving performance that exceeds larger language models such as GPT-4 (which is about 880 times larger in size).","This work presents a novel approach to leveraging SLMs for communication networks, offering a balance of efficiency and performance.","This work can serve as a foundation towards agentic language models for networks."],"url":"http://arxiv.org/abs/2408.11775v1"}
{"created":"2024-08-21 16:54:22","title":"VIRIS: Simulating indoor airborne transmission combining architectural design and people movement","abstract":"A Viral Infection Risk Indoor Simulator (VIRIS) has been developed to quickly assess and compare mitigations for airborne disease spread. This agent-based simulator combines people movement in an indoor space, viral transmission modelling and detailed architectural design, and it is powered by topologicpy, an open-source Python library. VIRIS generates very fast predictions of the viral concentration and the spatiotemporal infection risk for individuals as they move through a given space. The simulator is validated with data from a courtroom superspreader event. A sensitivity study for unknown parameter values is also performed. We compare several non-pharmaceutical interventions (NPIs) issued in UK government guidance, for two indoor settings: a care home and a supermarket. Additionally, we have developed the user-friendly VIRIS web app that allows quick exploration of diverse scenarios of interest and visualisation, allowing policymakers, architects and space managers to easily design or assess infection risk in an indoor space.","sentences":["A Viral Infection Risk Indoor Simulator (VIRIS) has been developed to quickly assess and compare mitigations for airborne disease spread.","This agent-based simulator combines people movement in an indoor space, viral transmission modelling and detailed architectural design, and it is powered by topologicpy, an open-source Python library.","VIRIS generates very fast predictions of the viral concentration and the spatiotemporal infection risk for individuals as they move through a given space.","The simulator is validated with data from a courtroom superspreader event.","A sensitivity study for unknown parameter values is also performed.","We compare several non-pharmaceutical interventions (NPIs) issued in UK government guidance, for two indoor settings: a care home and a supermarket.","Additionally, we have developed the user-friendly VIRIS web app that allows quick exploration of diverse scenarios of interest and visualisation, allowing policymakers, architects and space managers to easily design or assess infection risk in an indoor space."],"url":"http://arxiv.org/abs/2408.11772v1"}
{"created":"2024-08-21 16:46:30","title":"Decoding Pedestrian Stress on Urban Streets using Electrodermal Activity Monitoring in Virtual Immersive Reality","abstract":"The pedestrian stress level is shown to significantly influence human cognitive processes and, subsequently, decision-making, e.g., the decision to select a gap and cross a street. This paper systematically studies the stress experienced by a pedestrian when crossing a street under different experimental manipulations by monitoring the ElectroDermal Activity (EDA) using the Galvanic Skin Response (GSR) sensor. To fulfil the research objectives, a dynamic and immersive virtual reality (VR) platform was used, which is suitable for eliciting and capturing pedestrian's emotional responses in conjunction with monitoring their EDA. A total of 171 individuals participated in the experiment, tasked to cross a two-way street at mid-block with no signal control. Mixed effects models were employed to compare the influence of socio-demographics, social influence, vehicle technology, environment, road design, and traffic variables on the stress levels of the participants. The results indicated that having a street median in the middle of the road operates as a refuge and significantly reduced stress. Younger participants were (18-24 years) calmer than the relatively older participants (55-65 years). Arousal levels were higher when it came to the characteristics of the avatar (virtual pedestrian) in the simulation, especially for those avatars with adventurous traits. The pedestrian location influenced stress since the stress was higher on the street while crossing than waiting on the sidewalk. Significant causes of arousal were fear of accidents and an actual accident for pedestrians. The estimated random effects show a high degree of physical and mental learning by the participants while going through the scenarios.","sentences":["The pedestrian stress level is shown to significantly influence human cognitive processes and, subsequently, decision-making, e.g., the decision to select a gap and cross a street.","This paper systematically studies the stress experienced by a pedestrian when crossing a street under different experimental manipulations by monitoring the ElectroDermal Activity (EDA) using the Galvanic Skin Response (GSR) sensor.","To fulfil the research objectives, a dynamic and immersive virtual reality (VR) platform was used, which is suitable for eliciting and capturing pedestrian's emotional responses in conjunction with monitoring their EDA.","A total of 171 individuals participated in the experiment, tasked to cross a two-way street at mid-block with no signal control.","Mixed effects models were employed to compare the influence of socio-demographics, social influence, vehicle technology, environment, road design, and traffic variables on the stress levels of the participants.","The results indicated that having a street median in the middle of the road operates as a refuge and significantly reduced stress.","Younger participants were (18-24 years) calmer than the relatively older participants (55-65 years).","Arousal levels were higher when it came to the characteristics of the avatar (virtual pedestrian) in the simulation, especially for those avatars with adventurous traits.","The pedestrian location influenced stress since the stress was higher on the street while crossing than waiting on the sidewalk.","Significant causes of arousal were fear of accidents and an actual accident for pedestrians.","The estimated random effects show a high degree of physical and mental learning by the participants while going through the scenarios."],"url":"http://arxiv.org/abs/2408.11769v1"}
{"created":"2024-08-21 16:42:58","title":"Embedding Ordinality to Binary Loss Function for Improving Solar Flare Forecasting","abstract":"In this paper, we propose a novel loss function aimed at optimizing the binary flare prediction problem by embedding the intrinsic ordinal flare characteristics into the binary cross-entropy (BCE) loss function. This modification is intended to provide the model with better guidance based on the ordinal characteristics of the data and improve the overall performance of the models. For our experiments, we employ a ResNet34-based model with transfer learning to predict $\\geq$M-class flares by utilizing the shape-based features of magnetograms of active region (AR) patches spanning from $-$90$^{\\circ}$ to $+$90$^{\\circ}$ of solar longitude as our input data. We use a composite skill score (CSS) as our evaluation metric, which is calculated as the geometric mean of the True Skill Score (TSS) and the Heidke Skill Score (HSS) to rank and compare our models' performance. The primary contributions of this work are as follows: (i) We introduce a novel approach to encode ordinality into a binary loss function showing an application to solar flare prediction, (ii) We enhance solar flare forecasting by enabling flare predictions for each AR across the entire solar disk, without any longitudinal restrictions, and evaluate and compare performance. (iii) Our candidate model, optimized with the proposed loss function, shows an improvement of $\\sim$7%, $\\sim$4%, and $\\sim$3% for AR patches within $\\pm$30$^\\circ$, $\\pm$60$^\\circ$, and $\\pm$90$^\\circ$ of solar longitude, respectively in terms of CSS, when compared with standard BCE. Additionally, we demonstrate the ability to issue flare forecasts for ARs in near-limb regions (regions between $\\pm$60$^{\\circ}$ to $\\pm$90$^{\\circ}$) with a CSS=0.34 (TSS=0.50 and HSS=0.23), expanding the scope of AR-based models for solar flare prediction. This advances the reliability of solar flare forecasts, leading to more effective prediction capabilities.","sentences":["In this paper, we propose a novel loss function aimed at optimizing the binary flare prediction problem by embedding the intrinsic ordinal flare characteristics into the binary cross-entropy (BCE) loss function.","This modification is intended to provide the model with better guidance based on the ordinal characteristics of the data and improve the overall performance of the models.","For our experiments, we employ a ResNet34-based model with transfer learning to predict $\\geq$M-class flares by utilizing the shape-based features of magnetograms of active region (AR) patches spanning from $-$90$^{\\circ}$ to $+$90$^{\\circ}$ of solar longitude as our input data.","We use a composite skill score (CSS) as our evaluation metric, which is calculated as the geometric mean of the True Skill Score (TSS) and the Heidke Skill Score (HSS) to rank and compare our models' performance.","The primary contributions of this work are as follows: (i) We introduce a novel approach to encode ordinality into a binary loss function showing an application to solar flare prediction, (ii) We enhance solar flare forecasting by enabling flare predictions for each AR across the entire solar disk, without any longitudinal restrictions, and evaluate and compare performance.","(iii) Our candidate model, optimized with the proposed loss function, shows an improvement of $\\sim$7%, $\\sim$4%, and $\\sim$3% for AR patches within $\\pm$30$^\\circ$, $\\pm$60$^\\circ$, and $\\pm$90$^\\circ$ of solar longitude, respectively in terms of CSS, when compared with standard BCE.","Additionally, we demonstrate the ability to issue flare forecasts for ARs in near-limb regions (regions between $\\pm$60$^{\\circ}$ to $\\pm$90$^{\\circ}$) with a CSS=0.34 (TSS=0.50 and HSS=0.23), expanding the scope of AR-based models for solar flare prediction.","This advances the reliability of solar flare forecasts, leading to more effective prediction capabilities."],"url":"http://arxiv.org/abs/2408.11768v1"}
{"created":"2024-08-21 16:39:47","title":"Do We Really Need to Drop Items with Missing Modalities in Multimodal Recommendation?","abstract":"Generally, items with missing modalities are dropped in multimodal recommendation. However, with this work, we question this procedure, highlighting that it would further damage the pipeline of any multimodal recommender system. First, we show that the lack of (some) modalities is, in fact, a widely-diffused phenomenon in multimodal recommendation. Second, we propose a pipeline that imputes missing multimodal features in recommendation by leveraging traditional imputation strategies in machine learning. Then, given the graph structure of the recommendation data, we also propose three more effective imputation solutions that leverage the item-item co-purchase graph and the multimodal similarities of co-interacted items. Our method can be plugged into any multimodal RSs in the literature working as an untrained pre-processing phase, showing (through extensive experiments) that any data pre-filtering is not only unnecessary but also harmful to the performance.","sentences":["Generally, items with missing modalities are dropped in multimodal recommendation.","However, with this work, we question this procedure, highlighting that it would further damage the pipeline of any multimodal recommender system.","First, we show that the lack of (some) modalities is, in fact, a widely-diffused phenomenon in multimodal recommendation.","Second, we propose a pipeline that imputes missing multimodal features in recommendation by leveraging traditional imputation strategies in machine learning.","Then, given the graph structure of the recommendation data, we also propose three more effective imputation solutions that leverage the item-item co-purchase graph and the multimodal similarities of co-interacted items.","Our method can be plugged into any multimodal RSs in the literature working as an untrained pre-processing phase, showing (through extensive experiments) that any data pre-filtering is not only unnecessary but also harmful to the performance."],"url":"http://arxiv.org/abs/2408.11767v1"}
{"created":"2024-08-21 16:39:25","title":"Esports Training in StarCraft II: Stance Stability and Grip Strength","abstract":"Esports are a mostly sedentary activity. There is a growing need for investigation into how biomechanical and physical abilities can be optimized for esports through training. One such research avenue concerns the ability of esports players to perform balance tasks due to the prolonged sedentary states that are required to reach the top echelon of performance.   Our aim for this work is to describe and compare physical abilities (balance, grip strength, and self-reported training habits) of top Polish StarCraft~2 tournament players.   Esports players differed significantly from the reference group in their ability to balance on one leg. Additionally, in a grip strength test, the esports group fared worse than the reference group in all consecutive attempts.   Despite self-reported physical activity in the esports group, player fitness requires further research. Training optimization could offset the issues arising from sedentary activity, and intensifying esports training so it could take less time overall.","sentences":["Esports are a mostly sedentary activity.","There is a growing need for investigation into how biomechanical and physical abilities can be optimized for esports through training.","One such research avenue concerns the ability of esports players to perform balance tasks due to the prolonged sedentary states that are required to reach the top echelon of performance.   ","Our aim for this work is to describe and compare physical abilities (balance, grip strength, and self-reported training habits) of top Polish StarCraft~2 tournament players.   ","Esports players differed significantly from the reference group in their ability to balance on one leg.","Additionally, in a grip strength test, the esports group fared worse than the reference group in all consecutive attempts.   ","Despite self-reported physical activity in the esports group, player fitness requires further research.","Training optimization could offset the issues arising from sedentary activity, and intensifying esports training so it could take less time overall."],"url":"http://arxiv.org/abs/2408.11764v1"}
{"created":"2024-08-21 16:34:53","title":"A Novel Evaluation Perspective on GNNs-based Recommender Systems through the Topology of the User-Item Graph","abstract":"Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation. As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance. Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure. Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance. To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN). Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures. We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured. Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models.","sentences":["Recently, graph neural networks (GNNs)-based recommender systems have encountered great success in recommendation.","As the number of GNNs approaches rises, some works have started questioning the theoretical and empirical reasons behind their superior performance.","Nevertheless, this investigation still disregards that GNNs treat the recommendation data as a topological graph structure.","Building on this assumption, in this work, we provide a novel evaluation perspective on GNNs-based recommendation, which investigates the impact of the graph topology on the recommendation performance.","To this end, we select some (topological) properties of the recommendation data and three GNNs-based recommender systems (i.e., LightGCN, DGCF, and SVD-GCN).","Then, starting from three popular recommendation datasets (i.e., Yelp2018, Gowalla, and Amazon-Book) we sample them to obtain 1,800 size-reduced datasets that still resemble the original ones but can encompass a wider range of topological structures.","We use this procedure to build a large pool of samples for which data characteristics and recommendation performance of the selected GNNs models are measured.","Through an explanatory framework, we find strong correspondences between graph topology and GNNs performance, offering a novel evaluation perspective on these models."],"url":"http://arxiv.org/abs/2408.11762v1"}
{"created":"2024-08-21 16:34:21","title":"D-RMGPT: Robot-assisted collaborative tasks driven by large multimodal models","abstract":"Collaborative robots are increasingly popular for assisting humans at work and daily tasks. However, designing and setting up interfaces for human-robot collaboration is challenging, requiring the integration of multiple components, from perception and robot task control to the hardware itself. Frequently, this leads to highly customized solutions that rely on large amounts of costly training data, diverging from the ideal of flexible and general interfaces that empower robots to perceive and adapt to unstructured environments where they can naturally collaborate with humans. To overcome these challenges, this paper presents the Detection-Robot Management GPT (D-RMGPT), a robot-assisted assembly planner based on Large Multimodal Models (LMM). This system can assist inexperienced operators in assembly tasks without requiring any markers or previous training. D-RMGPT is composed of DetGPT-V and R-ManGPT. DetGPT-V, based on GPT-4V(vision), perceives the surrounding environment through one-shot analysis of prompted images of the current assembly stage and the list of components to be assembled. It identifies which components have already been assembled by analysing their features and assembly requirements. R-ManGPT, based on GPT-4, plans the next component to be assembled and generates the robot's discrete actions to deliver it to the human co-worker. Experimental tests on assembling a toy aircraft demonstrated that D-RMGPT is flexible and intuitive to use, achieving an assembly success rate of 83% while reducing the assembly time for inexperienced operators by 33% compared to the manual process. http://robotics-and-ai.github.io/LMMmodels/","sentences":["Collaborative robots are increasingly popular for assisting humans at work and daily tasks.","However, designing and setting up interfaces for human-robot collaboration is challenging, requiring the integration of multiple components, from perception and robot task control to the hardware itself.","Frequently, this leads to highly customized solutions that rely on large amounts of costly training data, diverging from the ideal of flexible and general interfaces that empower robots to perceive and adapt to unstructured environments where they can naturally collaborate with humans.","To overcome these challenges, this paper presents the Detection-Robot Management GPT (D-RMGPT), a robot-assisted assembly planner based on Large Multimodal Models (LMM).","This system can assist inexperienced operators in assembly tasks without requiring any markers or previous training.","D-RMGPT is composed of DetGPT-V and R-ManGPT.","DetGPT-V, based on GPT-4V(vision), perceives the surrounding environment through one-shot analysis of prompted images of the current assembly stage and the list of components to be assembled.","It identifies which components have already been assembled by analysing their features and assembly requirements.","R-ManGPT, based on GPT-4, plans the next component to be assembled and generates the robot's discrete actions to deliver it to the human co-worker.","Experimental tests on assembling a toy aircraft demonstrated that D-RMGPT is flexible and intuitive to use, achieving an assembly success rate of 83% while reducing the assembly time for inexperienced operators by 33% compared to the manual process.","http://robotics-and-ai.github.io/LMMmodels/"],"url":"http://arxiv.org/abs/2408.11761v1"}
{"created":"2024-08-21 16:32:03","title":"SBDet: A Symmetry-Breaking Object Detector via Relaxed Rotation-Equivariance","abstract":"Introducing Group Equivariant Convolution (GConv) empowers models to explore symmetries hidden in visual data, improving their performance. However, in real-world scenarios, objects or scenes often exhibit perturbations of a symmetric system, specifically a deviation from a symmetric architecture, which can be characterized by a non-trivial action of a symmetry group, known as Symmetry-Breaking. Traditional GConv methods are limited by the strict operation rules in the group space, only ensuring features remain strictly equivariant under limited group transformations, making it difficult to adapt to Symmetry-Breaking or non-rigid transformations. Motivated by this, we introduce a novel Relaxed Rotation GConv (R2GConv) with our defined Relaxed Rotation-Equivariant group $\\mathbf{R}_4$. Furthermore, we propose a Relaxed Rotation-Equivariant Network (R2Net) as the backbone and further develop the Symmetry-Breaking Object Detector (SBDet) for 2D object detection built upon it. Experiments demonstrate the effectiveness of our proposed R2GConv in natural image classification tasks, and SBDet achieves excellent performance in object detection tasks with improved generalization capabilities and robustness.","sentences":["Introducing Group Equivariant Convolution (GConv) empowers models to explore symmetries hidden in visual data, improving their performance.","However, in real-world scenarios, objects or scenes often exhibit perturbations of a symmetric system, specifically a deviation from a symmetric architecture, which can be characterized by a non-trivial action of a symmetry group, known as Symmetry-Breaking.","Traditional GConv methods are limited by the strict operation rules in the group space, only ensuring features remain strictly equivariant under limited group transformations, making it difficult to adapt to Symmetry-Breaking or non-rigid transformations.","Motivated by this, we introduce a novel Relaxed Rotation GConv (R2GConv) with our defined Relaxed Rotation-Equivariant group $\\mathbf{R}_4$. Furthermore, we propose a Relaxed Rotation-Equivariant Network (R2Net) as the backbone and further develop the Symmetry-Breaking Object Detector (SBDet) for 2D object detection built upon it.","Experiments demonstrate the effectiveness of our proposed R2GConv in natural image classification tasks, and SBDet achieves excellent performance in object detection tasks with improved generalization capabilities and robustness."],"url":"http://arxiv.org/abs/2408.11760v1"}
{"created":"2024-08-21 16:30:45","title":"MambaCSR: Dual-Interleaved Scanning for Compressed Image Super-Resolution With SSMs","abstract":"We present MambaCSR, a simple but effective framework based on Mamba for the challenging compressed image super-resolution (CSR) task. Particularly, the scanning strategies of Mamba are crucial for effective contextual knowledge modeling in the restoration process despite it relying on selective state space modeling for all tokens. In this work, we propose an efficient dual-interleaved scanning paradigm (DIS) for CSR, which is composed of two scanning strategies: (i) hierarchical interleaved scanning is designed to comprehensively capture and utilize the most potential contextual information within an image by simultaneously taking advantage of the local window-based and sequential scanning methods; (ii) horizontal-to-vertical interleaved scanning is proposed to reduce the computational cost by leaving the redundancy between the scanning of different directions. To overcome the non-uniform compression artifacts, we also propose position-aligned cross-scale scanning to model multi-scale contextual information. Experimental results on multiple benchmarks have shown the great performance of our MambaCSR in the compressed image super-resolution task. The code will be soon available in~\\textcolor{magenta}{\\url{https://github.com/renyulin-f/MambaCSR}}.","sentences":["We present MambaCSR, a simple but effective framework based on Mamba for the challenging compressed image super-resolution (CSR) task.","Particularly, the scanning strategies of Mamba are crucial for effective contextual knowledge modeling in the restoration process despite it relying on selective state space modeling for all tokens.","In this work, we propose an efficient dual-interleaved scanning paradigm (DIS) for CSR, which is composed of two scanning strategies: (i) hierarchical interleaved scanning is designed to comprehensively capture and utilize the most potential contextual information within an image by simultaneously taking advantage of the local window-based and sequential scanning methods; (ii) horizontal-to-vertical interleaved scanning is proposed to reduce the computational cost by leaving the redundancy between the scanning of different directions.","To overcome the non-uniform compression artifacts, we also propose position-aligned cross-scale scanning to model multi-scale contextual information.","Experimental results on multiple benchmarks have shown the great performance of our MambaCSR in the compressed image super-resolution task.","The code will be soon available in~\\textcolor{magenta}{\\url{https://github.com/renyulin-f/MambaCSR}}."],"url":"http://arxiv.org/abs/2408.11758v1"}
{"created":"2024-08-21 16:25:54","title":"On the Distortion of Committee Election with 1-Euclidean Preferences and Few Distance Queries","abstract":"We consider committee election of $k \\geq 3$ (out of $m \\geq k+1$) candidates, where the voters and the candidates are associated with locations on the real line. Each voter's cardinal preferences over candidates correspond to her distance to the candidate locations, and each voter's cardinal preferences over committees is defined as her distance to the nearest candidate elected in the committee. We consider a setting where the true distances and the locations are unknown. We can nevertheless have access to degraded information which consists of an order of candidates for each voter. We investigate the best possible distortion (a worst-case performance criterion) wrt. the social cost achieved by deterministic committee election rules based on ordinal preferences submitted by $n$ voters and few additional distance queries. We show that for any $k \\geq 3$, the best possible distortion of any deterministic algorithm that uses at most $k-3$ distance queries cannot be bounded by any function of $n$, $m$ and $k$. We present deterministic algorithms for $k$-committee election with distortion of $O(n)$ with $O(k)$ distance queries and $O(1)$ with $O(k \\log n)$ distance queries.","sentences":["We consider committee election of $k \\geq 3$ (out of $m \\geq k+1$) candidates, where the voters and the candidates are associated with locations on the real line.","Each voter's cardinal preferences over candidates correspond to her distance to the candidate locations, and each voter's cardinal preferences over committees is defined as her distance to the nearest candidate elected in the committee.","We consider a setting where the true distances and the locations are unknown.","We can nevertheless have access to degraded information which consists of an order of candidates for each voter.","We investigate the best possible distortion (a worst-case performance criterion) wrt.","the social cost achieved by deterministic committee election rules based on ordinal preferences submitted by $n$ voters and few additional distance queries.","We show that for any $k \\geq 3$, the best possible distortion of any deterministic algorithm that uses at most $k-3$ distance queries cannot be bounded by any function of $n$, $m$ and $k$. We present deterministic algorithms for $k$-committee election with distortion of $O(n)$ with $O(k)$ distance queries and $O(1)$ with $O(k \\log n)$ distance queries."],"url":"http://arxiv.org/abs/2408.11755v1"}
{"created":"2024-08-21 16:22:51","title":"Bayesian Optimization Framework for Efficient Fleet Design in Autonomous Multi-Robot Exploration","abstract":"This study addresses the challenge of fleet design optimization in the context of heterogeneous multi-robot fleets, aiming to obtain feasible designs that balance performance and costs. In the domain of autonomous multi-robot exploration, reinforcement learning agents play a central role, offering adaptability to complex terrains and facilitating collaboration among robots. However, modifying the fleet composition results in changes in the learned behavior, and training multi-robot systems using multi-agent reinforcement learning is expensive. Therefore, an exhaustive evaluation of each potential fleet design is infeasible. To tackle these hurdles, we introduce Bayesian Optimization for Fleet Design (BOFD), a framework leveraging multi-objective Bayesian Optimization to explore fleets on the Pareto front of performance and cost while accounting for uncertainty in the design space. Moreover, we establish a sub-linear bound for cumulative regret, supporting BOFD's robustness and efficacy. Extensive benchmark experiments in synthetic and simulated environments demonstrate the superiority of our framework over state-of-the-art methods, achieving efficient fleet designs with minimal fleet evaluations.","sentences":["This study addresses the challenge of fleet design optimization in the context of heterogeneous multi-robot fleets, aiming to obtain feasible designs that balance performance and costs.","In the domain of autonomous multi-robot exploration, reinforcement learning agents play a central role, offering adaptability to complex terrains and facilitating collaboration among robots.","However, modifying the fleet composition results in changes in the learned behavior, and training multi-robot systems using multi-agent reinforcement learning is expensive.","Therefore, an exhaustive evaluation of each potential fleet design is infeasible.","To tackle these hurdles, we introduce Bayesian Optimization for Fleet Design (BOFD), a framework leveraging multi-objective Bayesian Optimization to explore fleets on the Pareto front of performance and cost while accounting for uncertainty in the design space.","Moreover, we establish a sub-linear bound for cumulative regret, supporting BOFD's robustness and efficacy.","Extensive benchmark experiments in synthetic and simulated environments demonstrate the superiority of our framework over state-of-the-art methods, achieving efficient fleet designs with minimal fleet evaluations."],"url":"http://arxiv.org/abs/2408.11751v1"}
{"created":"2024-08-21 16:16:34","title":"Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks","abstract":"Large Language Models (LLMs) are susceptible to malicious influence by cyber attackers through intrusions such as adversarial, backdoor, and embedding inversion attacks. In response, the burgeoning field of LLM Security aims to study and defend against such threats. Thus far, the majority of works in this area have focused on monolingual English models, however, emerging research suggests that multilingual LLMs may be more vulnerable to various attacks than their monolingual counterparts. While previous work has investigated embedding inversion over a small subset of European languages, it is challenging to extrapolate these findings to languages from different linguistic families and with differing scripts. To this end, we explore the security of multilingual LLMs in the context of embedding inversion attacks and investigate cross-lingual and cross-script inversion across 20 languages, spanning over 8 language families and 12 scripts. Our findings indicate that languages written in Arabic script and Cyrillic script are particularly vulnerable to embedding inversion, as are languages within the Indo-Aryan language family. We further observe that inversion models tend to suffer from language confusion, sometimes greatly reducing the efficacy of an attack. Accordingly, we systematically explore this bottleneck for inversion models, uncovering predictable patterns which could be leveraged by attackers. Ultimately, this study aims to further the field's understanding of the outstanding security vulnerabilities facing multilingual LLMs and raise awareness for the languages most at risk of negative impact from these attacks.","sentences":["Large Language Models (LLMs) are susceptible to malicious influence by cyber attackers through intrusions such as adversarial, backdoor, and embedding inversion attacks.","In response, the burgeoning field of LLM Security aims to study and defend against such threats.","Thus far, the majority of works in this area have focused on monolingual English models, however, emerging research suggests that multilingual LLMs may be more vulnerable to various attacks than their monolingual counterparts.","While previous work has investigated embedding inversion over a small subset of European languages, it is challenging to extrapolate these findings to languages from different linguistic families and with differing scripts.","To this end, we explore the security of multilingual LLMs in the context of embedding inversion attacks and investigate cross-lingual and cross-script inversion across 20 languages, spanning over 8 language families and 12 scripts.","Our findings indicate that languages written in Arabic script and Cyrillic script are particularly vulnerable to embedding inversion, as are languages within the Indo-Aryan language family.","We further observe that inversion models tend to suffer from language confusion, sometimes greatly reducing the efficacy of an attack.","Accordingly, we systematically explore this bottleneck for inversion models, uncovering predictable patterns which could be leveraged by attackers.","Ultimately, this study aims to further the field's understanding of the outstanding security vulnerabilities facing multilingual LLMs and raise awareness for the languages most at risk of negative impact from these attacks."],"url":"http://arxiv.org/abs/2408.11749v1"}
{"created":"2024-08-21 16:16:18","title":"DH-Bench: Probing Depth and Height Perception of Large Visual-Language Models","abstract":"Geometric understanding is crucial for navigating and interacting with our environment. While large Vision Language Models (VLMs) demonstrate impressive capabilities, deploying them in real-world scenarios necessitates a comparable geometric understanding in visual perception. In this work, we focus on the geometric comprehension of these models; specifically targeting the depths and heights of objects within a scene. Our observations reveal that, although VLMs excel in basic geometric properties perception such as shape and size, they encounter significant challenges in reasoning about the depth and height of objects. To address this, we introduce a suite of benchmark datasets encompassing Synthetic 2D, Synthetic 3D, and Real-World scenarios to rigorously evaluate these aspects. We benchmark 17 state-of-the-art VLMs using these datasets and find that they consistently struggle with both depth and height perception. Our key insights include detailed analyses of the shortcomings in depth and height reasoning capabilities of VLMs and the inherent bias present in these models. This study aims to pave the way for the development of VLMs with enhanced geometric understanding, crucial for real-world applications. The code and datasets for our benchmarks will be available at \\url{https://tinyurl.com/DH-Bench1}.","sentences":["Geometric understanding is crucial for navigating and interacting with our environment.","While large Vision Language Models (VLMs) demonstrate impressive capabilities, deploying them in real-world scenarios necessitates a comparable geometric understanding in visual perception.","In this work, we focus on the geometric comprehension of these models; specifically targeting the depths and heights of objects within a scene.","Our observations reveal that, although VLMs excel in basic geometric properties perception such as shape and size, they encounter significant challenges in reasoning about the depth and height of objects.","To address this, we introduce a suite of benchmark datasets encompassing Synthetic 2D, Synthetic 3D, and Real-World scenarios to rigorously evaluate these aspects.","We benchmark 17 state-of-the-art VLMs using these datasets and find that they consistently struggle with both depth and height perception.","Our key insights include detailed analyses of the shortcomings in depth and height reasoning capabilities of VLMs and the inherent bias present in these models.","This study aims to pave the way for the development of VLMs with enhanced geometric understanding, crucial for real-world applications.","The code and datasets for our benchmarks will be available at \\url{https://tinyurl.com/DH-Bench1}."],"url":"http://arxiv.org/abs/2408.11748v1"}
{"created":"2024-08-21 16:14:11","title":"Open-Ended 3D Point Cloud Instance Segmentation","abstract":"Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently demonstrated their ability to generalize to unseen objects. However, these methods still depend on predefined class names during testing, restricting the autonomy of agents. To mitigate this constraint, we propose a novel problem termed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the necessity for predefined class names during testing. Moreover, we contribute a comprehensive set of strong baselines, derived from OV-3DIS approaches and leveraging 2D Multimodal Large Language Models. To assess the performance of our OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the semantic and geometric quality of predicted masks and their associated class names, alongside the standard AP score. Our approach demonstrates significant performance improvements over the baselines on the ScanNet200 and ScanNet++ datasets. Remarkably, our method surpasses the performance of Open3DIS, the current state-of-the-art method in OV-3DIS, even in the absence of ground-truth object class names.","sentences":["Open-Vocab 3D Instance Segmentation methods (OV-3DIS) have recently demonstrated their ability to generalize to unseen objects.","However, these methods still depend on predefined class names during testing, restricting the autonomy of agents.","To mitigate this constraint, we propose a novel problem termed Open-Ended 3D Instance Segmentation (OE-3DIS), which eliminates the necessity for predefined class names during testing.","Moreover, we contribute a comprehensive set of strong baselines, derived from OV-3DIS approaches and leveraging 2D Multimodal Large Language Models.","To assess the performance of our OE-3DIS system, we introduce a novel Open-Ended score, evaluating both the semantic and geometric quality of predicted masks and their associated class names, alongside the standard AP score.","Our approach demonstrates significant performance improvements over the baselines on the ScanNet200 and ScanNet++ datasets.","Remarkably, our method surpasses the performance of Open3DIS, the current state-of-the-art method in OV-3DIS, even in the absence of ground-truth object class names."],"url":"http://arxiv.org/abs/2408.11747v1"}
{"created":"2024-08-21 16:13:16","title":"Mixed Sparsity Training: Achieving 4$\\times$ FLOP Reduction for Transformer Pretraining","abstract":"Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands. With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster. However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75\\%$ of Floating Point Operations (FLOPs) while maintaining performance. MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration. The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections. Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently. Our experiment on GPT-2 showcases a FLOP reduction of $4\\times$ without compromising performance.","sentences":["Large language models (LLMs) have made significant strides in complex tasks, yet their widespread adoption is impeded by substantial computational demands.","With hundreds of billion parameters, transformer-based LLMs necessitate months of pretraining across a high-end GPU cluster.","However, this paper reveals a compelling finding: transformers exhibit considerable redundancy in pretraining computations, which motivates our proposed solution, Mixed Sparsity Training (MST), an efficient pretraining method that can reduce about $75\\%$ of Floating Point Operations (FLOPs) while maintaining performance.","MST integrates dynamic sparse training (DST) with Sparsity Variation (SV) and Hybrid Sparse Attention (HSA) during pretraining, involving three distinct phases: warm-up, ultra-sparsification, and restoration.","The warm-up phase transforms the dense model into a sparse one, and the restoration phase reinstates connections.","Throughout these phases, the model is trained with a dynamically evolving sparse topology and an HSA mechanism to maintain performance and minimize training FLOPs concurrently.","Our experiment on GPT-2 showcases a FLOP reduction of $4\\times$ without compromising performance."],"url":"http://arxiv.org/abs/2408.11746v1"}
{"created":"2024-08-21 16:11:59","title":"FocusLLM: Scaling LLM's Context by Parallel Decoding","abstract":"Empowering LLMs with the ability to utilize useful information from a long context is crucial for many downstream applications. However, achieving long context lengths with the conventional transformer architecture requires substantial training and inference resources. In this paper, we present FocusLLM, a framework designed to extend the context length of any decoder-only LLM, enabling the model to focus on relevant information from very long sequences. FocusLLM processes long text inputs by dividing them into chunks based on the model's original context length to alleviate the issue of attention distraction. Then, it appends the local context to each chunk as a prompt to extract essential information from each chunk based on a novel parallel decoding mechanism, and ultimately integrates the extracted information into the local context. FocusLLM stands out for great training efficiency and versatility: trained with an 8K input length with much less training cost than previous methods, FocusLLM exhibits superior performance across downstream long-context tasks and maintains strong language modeling ability when handling extensive long texts, even up to 400K tokens. Our code is available at https://github.com/leezythu/FocusLLM.","sentences":["Empowering LLMs with the ability to utilize useful information from a long context is crucial for many downstream applications.","However, achieving long context lengths with the conventional transformer architecture requires substantial training and inference resources.","In this paper, we present FocusLLM, a framework designed to extend the context length of any decoder-only LLM, enabling the model to focus on relevant information from very long sequences.","FocusLLM processes long text inputs by dividing them into chunks based on the model's original context length to alleviate the issue of attention distraction.","Then, it appends the local context to each chunk as a prompt to extract essential information from each chunk based on a novel parallel decoding mechanism, and ultimately integrates the extracted information into the local context.","FocusLLM stands out for great training efficiency and versatility: trained with an 8K input length with much less training cost than previous methods, FocusLLM exhibits superior performance across downstream long-context tasks and maintains strong language modeling ability when handling extensive long texts, even up to 400K tokens.","Our code is available at https://github.com/leezythu/FocusLLM."],"url":"http://arxiv.org/abs/2408.11745v1"}
{"created":"2024-08-21 16:11:01","title":"JieHua Paintings Style Feature Extracting Model using Stable Diffusion with ControlNet","abstract":"This study proposes a novel approach to extract stylistic features of Jiehua: the utilization of the Fine-tuned Stable Diffusion Model with ControlNet (FSDMC) to refine depiction techniques from artists' Jiehua. The training data for FSDMC is based on the opensource Jiehua artist's work collected from the Internet, which were subsequently manually constructed in the format of (Original Image, Canny Edge Features, Text Prompt). By employing the optimal hyperparameters identified in this paper, it was observed FSDMC outperforms CycleGAN, another mainstream style transfer model. FSDMC achieves FID of 3.27 on the dataset and also surpasses CycleGAN in terms of expert evaluation. This not only demonstrates the model's high effectiveness in extracting Jiehua's style features, but also preserves the original pre-trained semantic information. The findings of this study suggest that the application of FSDMC with appropriate hyperparameters can enhance the efficacy of the Stable Diffusion Model in the field of traditional art style migration tasks, particularly within the context of Jiehua.","sentences":["This study proposes a novel approach to extract stylistic features of Jiehua: the utilization of the Fine-tuned Stable Diffusion Model with ControlNet (FSDMC) to refine depiction techniques from artists' Jiehua.","The training data for FSDMC is based on the opensource Jiehua artist's work collected from the Internet, which were subsequently manually constructed in the format of (Original Image, Canny Edge Features, Text Prompt).","By employing the optimal hyperparameters identified in this paper, it was observed FSDMC outperforms CycleGAN, another mainstream style transfer model.","FSDMC achieves FID of 3.27 on the dataset and also surpasses CycleGAN in terms of expert evaluation.","This not only demonstrates the model's high effectiveness in extracting Jiehua's style features, but also preserves the original pre-trained semantic information.","The findings of this study suggest that the application of FSDMC with appropriate hyperparameters can enhance the efficacy of the Stable Diffusion Model in the field of traditional art style migration tasks, particularly within the context of Jiehua."],"url":"http://arxiv.org/abs/2408.11744v1"}
{"created":"2024-08-21 16:10:41","title":"MARLIN: Mixed-Precision Auto-Regressive Parallel Inference on Large Language Models","abstract":"As inference on Large Language Models (LLMs) emerges as an important workload in machine learning applications, weight quantization has become a standard technique for efficient GPU deployment. Quantization not only reduces model size, but has also been shown to yield substantial speedups for single-user inference, due to reduced memory movement, with low accuracy impact. Yet, it remains open whether speedups are achievable also in \\emph{batched} settings with multiple parallel clients, which are highly relevant for practical serving. It is unclear whether GPU kernels can be designed to remain practically memory-bound, while supporting the substantially increased compute requirements of batched workloads.   This paper resolves this question positively by describing the design of Mixed-precision Auto-Regressive LINear kernels, called MARLIN. Concretely, given a model whose weights are compressed via quantization to, e.g., 4 bits per element, MARLIN shows that batchsizes up to 16-32 can be supported with close to maximum ($4\\times$) quantization speedup, and larger batchsizes up to 64-128 with gradually decreasing, but still significant, acceleration. MARLIN accomplishes this via a combination of techniques, such as asynchronous memory access, complex task scheduling and pipelining, and bespoke quantization support. Our experiments show that MARLIN's near-optimal performance on individual LLM layers across different scenarios can also lead to end-to-end LLM inference speedups (of up to $2.8\\times$) when integrated with the popular vLLM serving engine. Finally, MARLIN is extensible to further compression techniques, like NVIDIA 2:4 sparsity, leading to additional speedups.","sentences":["As inference on Large Language Models (LLMs) emerges as an important workload in machine learning applications, weight quantization has become a standard technique for efficient GPU deployment.","Quantization not only reduces model size, but has also been shown to yield substantial speedups for single-user inference, due to reduced memory movement, with low accuracy impact.","Yet, it remains open whether speedups are achievable also in \\emph{batched} settings with multiple parallel clients, which are highly relevant for practical serving.","It is unclear whether GPU kernels can be designed to remain practically memory-bound, while supporting the substantially increased compute requirements of batched workloads.   ","This paper resolves this question positively by describing the design of Mixed-precision Auto-Regressive LINear kernels, called MARLIN.","Concretely, given a model whose weights are compressed via quantization to, e.g., 4 bits per element, MARLIN shows that batchsizes up to 16-32 can be supported with close to maximum ($4\\times$) quantization speedup, and larger batchsizes up to 64-128 with gradually decreasing, but still significant, acceleration.","MARLIN accomplishes this via a combination of techniques, such as asynchronous memory access, complex task scheduling and pipelining, and bespoke quantization support.","Our experiments show that MARLIN's near-optimal performance on individual LLM layers across different scenarios can also lead to end-to-end LLM inference speedups (of up to $2.8\\times$) when integrated with the popular vLLM serving engine.","Finally, MARLIN is extensible to further compression techniques, like NVIDIA 2:4 sparsity, leading to additional speedups."],"url":"http://arxiv.org/abs/2408.11743v1"}
{"created":"2024-08-21 16:07:49","title":"CluMo: Cluster-based Modality Fusion Prompt for Continual Learning in Visual Question Answering","abstract":"Large vision-language models (VLMs) have shown significant performance boost in various application domains. However, adopting them to deal with several sequentially encountered tasks has been challenging because finetuning a VLM on a task normally leads to reducing its generalization power and the capacity of learning new tasks as well as causing catastrophic forgetting on previously learned tasks. Enabling using VLMs in multimodal continual learning (CL) settings can help to address such scenarios. To improve generalization capacity and prevent catastrophic forgetting, we propose a novel prompt-based CL method for VLMs, namely $\\textbf{Clu}$ster-based $\\textbf{Mo}$dality Fusion Prompt (\\textbf{CluMo}). We design a novel \\textbf{Key-Key-Prompt} pair, where each prompt is associated with a visual prompt key and a textual prompt key. We adopt a two-stage training strategy. During the first stage, the single-modal keys are trained via $K$-means clustering algorithm to help select the best semantically matched prompt. During the second stage, the prompt keys are frozen, the selected prompt is attached to the input for training the VLM in the CL scenario. Experiments on two benchmarks demonstrate that our method achieves SOTA performance.","sentences":["Large vision-language models (VLMs) have shown significant performance boost in various application domains.","However, adopting them to deal with several sequentially encountered tasks has been challenging because finetuning a VLM on a task normally leads to reducing its generalization power and the capacity of learning new tasks as well as causing catastrophic forgetting on previously learned tasks.","Enabling using VLMs in multimodal continual learning (CL) settings can help to address such scenarios.","To improve generalization capacity and prevent catastrophic forgetting, we propose a novel prompt-based CL method for VLMs, namely $\\textbf{Clu}$ster-based $\\textbf{Mo}$dality Fusion Prompt (\\textbf{CluMo}).","We design a novel \\textbf{Key-Key-Prompt} pair, where each prompt is associated with a visual prompt key and a textual prompt key.","We adopt a two-stage training strategy.","During the first stage, the single-modal keys are trained via $K$-means clustering algorithm to help select the best semantically matched prompt.","During the second stage, the prompt keys are frozen, the selected prompt is attached to the input for training the VLM in the CL scenario.","Experiments on two benchmarks demonstrate that our method achieves SOTA performance."],"url":"http://arxiv.org/abs/2408.11742v1"}
{"created":"2024-08-21 15:59:33","title":"Clinical Insights: A Comprehensive Review of Language Models in Medicine","abstract":"This paper provides a detailed examination of the advancements and applications of large language models in the healthcare sector, with a particular emphasis on clinical applications. The study traces the evolution of LLMs from their foundational technologies to the latest developments in domain-specific models and multimodal integration. It explores the technical progression from encoder-based models requiring fine-tuning to sophisticated approaches that integrate textual, visual, and auditory data, thereby facilitating comprehensive AI solutions in healthcare. The paper discusses both the opportunities these technologies present for enhancing clinical efficiency and the challenges they pose in terms of ethics, data privacy, and implementation. Additionally, it critically evaluates the deployment strategies of LLMs, emphasizing the necessity of open-source models to ensure data privacy and adaptability within healthcare environments. Future research directions are proposed, focusing on empirical studies to evaluate the real-world efficacy of LLMs in healthcare and the development of open datasets for further research. This review aims to provide a comprehensive resource for both newcomers and multidisciplinary researchers interested in the intersection of AI and healthcare.","sentences":["This paper provides a detailed examination of the advancements and applications of large language models in the healthcare sector, with a particular emphasis on clinical applications.","The study traces the evolution of LLMs from their foundational technologies to the latest developments in domain-specific models and multimodal integration.","It explores the technical progression from encoder-based models requiring fine-tuning to sophisticated approaches that integrate textual, visual, and auditory data, thereby facilitating comprehensive AI solutions in healthcare.","The paper discusses both the opportunities these technologies present for enhancing clinical efficiency and the challenges they pose in terms of ethics, data privacy, and implementation.","Additionally, it critically evaluates the deployment strategies of LLMs, emphasizing the necessity of open-source models to ensure data privacy and adaptability within healthcare environments.","Future research directions are proposed, focusing on empirical studies to evaluate the real-world efficacy of LLMs in healthcare and the development of open datasets for further research.","This review aims to provide a comprehensive resource for both newcomers and multidisciplinary researchers interested in the intersection of AI and healthcare."],"url":"http://arxiv.org/abs/2408.11735v1"}
{"created":"2024-08-21 15:57:24","title":"Enhancing Cross-Modal Medical Image Segmentation through Compositionality","abstract":"Cross-modal medical image segmentation presents a significant challenge, as different imaging modalities produce images with varying resolutions, contrasts, and appearances of anatomical structures. We introduce compositionality as an inductive bias in a cross-modal segmentation network to improve segmentation performance and interpretability while reducing complexity. The proposed network is an end-to-end cross-modal segmentation framework that enforces compositionality on the learned representations using learnable von Mises-Fisher kernels. These kernels facilitate content-style disentanglement in the learned representations, resulting in compositional content representations that are inherently interpretable and effectively disentangle different anatomical structures. The experimental results demonstrate enhanced segmentation performance and reduced computational costs on multiple medical datasets. Additionally, we demonstrate the interpretability of the learned compositional features. Code and checkpoints will be publicly available at: https://github.com/Trustworthy-AI-UU-NKI/Cross-Modal-Segmentation.","sentences":["Cross-modal medical image segmentation presents a significant challenge, as different imaging modalities produce images with varying resolutions, contrasts, and appearances of anatomical structures.","We introduce compositionality as an inductive bias in a cross-modal segmentation network to improve segmentation performance and interpretability while reducing complexity.","The proposed network is an end-to-end cross-modal segmentation framework that enforces compositionality on the learned representations using learnable von Mises-Fisher kernels.","These kernels facilitate content-style disentanglement in the learned representations, resulting in compositional content representations that are inherently interpretable and effectively disentangle different anatomical structures.","The experimental results demonstrate enhanced segmentation performance and reduced computational costs on multiple medical datasets.","Additionally, we demonstrate the interpretability of the learned compositional features.","Code and checkpoints will be publicly available at: https://github.com/Trustworthy-AI-UU-NKI/Cross-Modal-Segmentation."],"url":"http://arxiv.org/abs/2408.11733v1"}
{"created":"2024-08-21 15:54:19","title":"Effective Wordle Heuristics","abstract":"While previous researchers have performed an exhaustive search to determine an optimal Wordle strategy, that computation is very time consuming and produced a strategy using words that are unfamiliar to most people. With Wordle solutions being gradually eliminated (with a new puzzle each day and no reuse), an improved strategy could be generated each day, but the computation time makes a daily exhaustive search impractical. This paper shows that simple heuristics allow for fast generation of effective strategies and that little is lost by guessing only words that are possible solution words rather than more obscure words.","sentences":["While previous researchers have performed an exhaustive search to determine an optimal Wordle strategy, that computation is very time consuming and produced a strategy using words that are unfamiliar to most people.","With Wordle solutions being gradually eliminated (with a new puzzle each day and no reuse), an improved strategy could be generated each day, but the computation time makes a daily exhaustive search impractical.","This paper shows that simple heuristics allow for fast generation of effective strategies and that little is lost by guessing only words that are possible solution words rather than more obscure words."],"url":"http://arxiv.org/abs/2408.11730v1"}
{"created":"2024-08-21 15:54:17","title":"LLM4VV: Exploring LLM-as-a-Judge for Validation and Verification Testsuites","abstract":"Large Language Models (LLM) are evolving and have significantly revolutionized the landscape of software development. If used well, they can significantly accelerate the software development cycle. At the same time, the community is very cautious of the models being trained on biased or sensitive data, which can lead to biased outputs along with the inadvertent release of confidential information. Additionally, the carbon footprints and the un-explainability of these black box models continue to raise questions about the usability of LLMs.   With the abundance of opportunities LLMs have to offer, this paper explores the idea of judging tests used to evaluate compiler implementations of directive-based programming models as well as probe into the black box of LLMs. Based on our results, utilizing an agent-based prompting approach and setting up a validation pipeline structure drastically increased the quality of DeepSeek Coder, the LLM chosen for the evaluation purposes.","sentences":["Large Language Models (LLM) are evolving and have significantly revolutionized the landscape of software development.","If used well, they can significantly accelerate the software development cycle.","At the same time, the community is very cautious of the models being trained on biased or sensitive data, which can lead to biased outputs along with the inadvertent release of confidential information.","Additionally, the carbon footprints and the un-explainability of these black box models continue to raise questions about the usability of LLMs.   ","With the abundance of opportunities LLMs have to offer, this paper explores the idea of judging tests used to evaluate compiler implementations of directive-based programming models as well as probe into the black box of LLMs.","Based on our results, utilizing an agent-based prompting approach and setting up a validation pipeline structure drastically increased the quality of DeepSeek Coder, the LLM chosen for the evaluation purposes."],"url":"http://arxiv.org/abs/2408.11729v1"}
{"created":"2024-08-21 15:54:04","title":"Efficient Detection of Toxic Prompts in Large Language Models","abstract":"Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation. However, these models can be exploited by malicious individuals who craft toxic prompts to elicit harmful or unethical responses. These individuals often employ jailbreaking techniques to bypass safety mechanisms, highlighting the need for robust toxic prompt detection methods. Existing detection techniques, both blackbox and whitebox, face challenges related to the diversity of toxic prompts, scalability, and computational efficiency. In response, we propose ToxicDetector, a lightweight greybox method designed to efficiently detect toxic prompts in LLMs. ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP) classifier for prompt classification. Our evaluation on various versions of the LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector achieves a high accuracy of 96.39\\% and a low false positive rate of 2.00\\%, outperforming state-of-the-art methods. Additionally, ToxicDetector's processing time of 0.0780 seconds per prompt makes it highly suitable for real-time applications. ToxicDetector achieves high accuracy, efficiency, and scalability, making it a practical method for toxic prompt detection in LLMs.","sentences":["Large language models (LLMs) like ChatGPT and Gemini have significantly advanced natural language processing, enabling various applications such as chatbots and automated content generation.","However, these models can be exploited by malicious individuals who craft toxic prompts to elicit harmful or unethical responses.","These individuals often employ jailbreaking techniques to bypass safety mechanisms, highlighting the need for robust toxic prompt detection methods.","Existing detection techniques, both blackbox and whitebox, face challenges related to the diversity of toxic prompts, scalability, and computational efficiency.","In response, we propose ToxicDetector, a lightweight greybox method designed to efficiently detect toxic prompts in LLMs.","ToxicDetector leverages LLMs to create toxic concept prompts, uses embedding vectors to form feature vectors, and employs a Multi-Layer Perceptron (MLP) classifier for prompt classification.","Our evaluation on various versions of the LLama models, Gemma-2, and multiple datasets demonstrates that ToxicDetector achieves a high accuracy of 96.39\\% and a low false positive rate of 2.00\\%, outperforming state-of-the-art methods.","Additionally, ToxicDetector's processing time of 0.0780 seconds per prompt makes it highly suitable for real-time applications.","ToxicDetector achieves high accuracy, efficiency, and scalability, making it a practical method for toxic prompt detection in LLMs."],"url":"http://arxiv.org/abs/2408.11727v1"}
{"created":"2024-08-21 15:52:10","title":"Cultural Windows: Towards a Workflow for Immersive Journeys into Global Living Spaces","abstract":"\"Cultural Windows\" is a research initiative designed to enrich cross-cultural understanding through immersive extended reality (XR) experiences. This project proposes a workflow for deploying AR and VR platforms, allowing users to explore living spaces from diverse cultures and socio-economic statuses. The process involves 3D scanning of culturally significant objects, creating accurate models of living spaces, and integrating them into immersive systems to facilitate engagement with global living designs. Targeted at individuals curious about how people live in different parts of the world, the project aims to expand cross-cultural understanding and design perspectives, providing insights into the effectiveness of immersive technologies in cultural education. By detailing its conceptual framework, \"Cultural Windows\" aims to enhance comprehension and appreciation of global domestic aesthetics by comparing participants' perceptions with immersive, realistic representations of living spaces from different cultures. This can help bridge the gap between preconceived notions and the actual appearance and feel of these spaces.","sentences":["\"Cultural Windows\" is a research initiative designed to enrich cross-cultural understanding through immersive extended reality (XR) experiences.","This project proposes a workflow for deploying AR and VR platforms, allowing users to explore living spaces from diverse cultures and socio-economic statuses.","The process involves 3D scanning of culturally significant objects, creating accurate models of living spaces, and integrating them into immersive systems to facilitate engagement with global living designs.","Targeted at individuals curious about how people live in different parts of the world, the project aims to expand cross-cultural understanding and design perspectives, providing insights into the effectiveness of immersive technologies in cultural education.","By detailing its conceptual framework, \"Cultural Windows\" aims to enhance comprehension and appreciation of global domestic aesthetics by comparing participants' perceptions with immersive, realistic representations of living spaces from different cultures.","This can help bridge the gap between preconceived notions and the actual appearance and feel of these spaces."],"url":"http://arxiv.org/abs/2408.11723v1"}
{"created":"2024-08-21 15:51:46","title":"Iterative Object Count Optimization for Text-to-image Diffusion Models","abstract":"We address a persistent challenge in text-to-image models: accurately generating a specified number of objects. Current models, which learn from image-text pairs, inherently struggle with counting, as training data cannot depict every possible number of objects for any given object. To solve this, we propose optimizing the generated image based on a counting loss derived from a counting model that aggregates an object\\'s potential. Employing an out-of-the-box counting model is challenging for two reasons: first, the model requires a scaling hyperparameter for the potential aggregation that varies depending on the viewpoint of the objects, and second, classifier guidance techniques require modified models that operate on noisy intermediate diffusion steps. To address these challenges, we propose an iterated online training mode that improves the accuracy of inferred images while altering the text conditioning embedding and dynamically adjusting hyperparameters. Our method offers three key advantages: (i) it can consider non-derivable counting techniques based on detection models, (ii) it is a zero-shot plug-and-play solution facilitating rapid changes to the counting techniques and image generation methods, and (iii) the optimized counting token can be reused to generate accurate images without additional optimization. We evaluate the generation of various objects and show significant improvements in accuracy. The project page is available at https://ozzafar.github.io/count_token.","sentences":["We address a persistent challenge in text-to-image models: accurately generating a specified number of objects.","Current models, which learn from image-text pairs, inherently struggle with counting, as training data cannot depict every possible number of objects for any given object.","To solve this, we propose optimizing the generated image based on a counting loss derived from a counting model that aggregates an object\\'s potential.","Employing an out-of-the-box counting model is challenging for two reasons: first, the model requires a scaling hyperparameter for the potential aggregation that varies depending on the viewpoint of the objects, and second, classifier guidance techniques require modified models that operate on noisy intermediate diffusion steps.","To address these challenges, we propose an iterated online training mode that improves the accuracy of inferred images while altering the text conditioning embedding and dynamically adjusting hyperparameters.","Our method offers three key advantages: (i) it can consider non-derivable counting techniques based on detection models, (ii) it is a zero-shot plug-and-play solution facilitating rapid changes to the counting techniques and image generation methods, and (iii) the optimized counting token can be reused to generate accurate images without additional optimization.","We evaluate the generation of various objects and show significant improvements in accuracy.","The project page is available at https://ozzafar.github.io/count_token."],"url":"http://arxiv.org/abs/2408.11721v1"}
{"created":"2024-08-21 15:50:37","title":"On Learnable Parameters of Optimal and Suboptimal Deep Learning Models","abstract":"We scrutinize the structural and operational aspects of deep learning models, particularly focusing on the nuances of learnable parameters (weight) statistics, distribution, node interaction, and visualization. By establishing correlations between variance in weight patterns and overall network performance, we investigate the varying (optimal and suboptimal) performances of various deep-learning models. Our empirical analysis extends across widely recognized datasets such as MNIST, Fashion-MNIST, and CIFAR-10, and various deep learning models such as deep neural networks (DNNs), convolutional neural networks (CNNs), and vision transformer (ViT), enabling us to pinpoint characteristics of learnable parameters that correlate with successful networks. Through extensive experiments on the diverse architectures of deep learning models, we shed light on the critical factors that influence the functionality and efficiency of DNNs. Our findings reveal that successful networks, irrespective of datasets or models, are invariably similar to other successful networks in their converged weights statistics and distribution, while poor-performing networks vary in their weights. In addition, our research shows that the learnable parameters of widely varied deep learning models such as DNN, CNN, and ViT exhibit similar learning characteristics.","sentences":["We scrutinize the structural and operational aspects of deep learning models, particularly focusing on the nuances of learnable parameters (weight) statistics, distribution, node interaction, and visualization.","By establishing correlations between variance in weight patterns and overall network performance, we investigate the varying (optimal and suboptimal) performances of various deep-learning models.","Our empirical analysis extends across widely recognized datasets such as MNIST, Fashion-MNIST, and CIFAR-10, and various deep learning models such as deep neural networks (DNNs), convolutional neural networks (CNNs), and vision transformer (ViT), enabling us to pinpoint characteristics of learnable parameters that correlate with successful networks.","Through extensive experiments on the diverse architectures of deep learning models, we shed light on the critical factors that influence the functionality and efficiency of DNNs.","Our findings reveal that successful networks, irrespective of datasets or models, are invariably similar to other successful networks in their converged weights statistics and distribution, while poor-performing networks vary in their weights.","In addition, our research shows that the learnable parameters of widely varied deep learning models such as DNN, CNN, and ViT exhibit similar learning characteristics."],"url":"http://arxiv.org/abs/2408.11720v1"}
{"created":"2024-08-21 15:36:18","title":"A Category-Theoretic Perspective on Higher-Order Approximation Fixpoint Theory (Extended Version)","abstract":"Approximation Fixpoint Theory (AFT) is an algebraic framework designed to study the semantics of non-monotonic logics. Despite its success, AFT is not readily applicable to higher-order definitions. To solve such an issue, we devise a formal mathematical framework employing concepts drawn from Category Theory. In particular, we make use of the notion of Cartesian closed category to inductively construct higher-order approximation spaces while preserving the structures necessary for the correct application of AFT. We show that this novel theoretical approach extends standard AFT to a higher-order environment, and generalizes the AFT setting of arXiv:1804.08335 .","sentences":["Approximation Fixpoint Theory (AFT) is an algebraic framework designed to study the semantics of non-monotonic logics.","Despite its success, AFT is not readily applicable to higher-order definitions.","To solve such an issue, we devise a formal mathematical framework employing concepts drawn from Category Theory.","In particular, we make use of the notion of Cartesian closed category to inductively construct higher-order approximation spaces while preserving the structures necessary for the correct application of AFT.","We show that this novel theoretical approach extends standard AFT to a higher-order environment, and generalizes the AFT setting of arXiv:1804.08335 ."],"url":"http://arxiv.org/abs/2408.11712v1"}
{"created":"2024-08-21 15:35:37","title":"ControlCol: Controllability in Automatic Speaker Video Colorization","abstract":"Adding color to black-and-white speaker videos automatically is a highly desirable technique. It is an artistic process that requires interactivity with humans for the best results. Many existing automatic video colorization systems provide little opportunity for the user to guide the colorization process. In this work, we introduce a novel automatic speaker video colorization system which provides controllability to the user while also maintaining high colorization quality relative to state-of-the-art techniques. We name this system ControlCol. ControlCol performs 3.5% better than the previous state-of-the-art DeOldify on the Grid and Lombard Grid datasets when PSNR, SSIM, FID and FVD are used as metrics. This result is also supported by our human evaluation, where in a head-to-head comparison, ControlCol is preferred 90% of the time to DeOldify. Example videos can be seen in the supplementary material.","sentences":["Adding color to black-and-white speaker videos automatically is a highly desirable technique.","It is an artistic process that requires interactivity with humans for the best results.","Many existing automatic video colorization systems provide little opportunity for the user to guide the colorization process.","In this work, we introduce a novel automatic speaker video colorization system which provides controllability to the user while also maintaining high colorization quality relative to state-of-the-art techniques.","We name this system ControlCol.","ControlCol performs 3.5% better than the previous state-of-the-art DeOldify on the Grid and Lombard Grid datasets when PSNR, SSIM, FID and FVD are used as metrics.","This result is also supported by our human evaluation, where in a head-to-head comparison, ControlCol is preferred 90% of the time to DeOldify.","Example videos can be seen in the supplementary material."],"url":"http://arxiv.org/abs/2408.11711v1"}
{"created":"2024-08-21 15:35:34","title":"Leveraging Large Language Models for Enhancing the Understandability of Generated Unit Tests","abstract":"Automated unit test generators, particularly search-based software testing tools like EvoSuite, are capable of generating tests with high coverage. Although these generators alleviate the burden of writing unit tests, they often pose challenges for software engineers in terms of understanding the generated tests. To address this, we introduce UTGen, which combines search-based software testing and large language models to enhance the understandability of automatically generated test cases. We achieve this enhancement through contextualizing test data, improving identifier naming, and adding descriptive comments. Through a controlled experiment with 32 participants from both academia and industry, we investigate how the understandability of unit tests affects a software engineer's ability to perform bug-fixing tasks. We selected bug-fixing to simulate a real-world scenario that emphasizes the importance of understandable test cases. We observe that participants working on assignments with UTGen test cases fix up to 33% more bugs and use up to 20% less time when compared to baseline test cases. From the post-test questionnaire, we gathered that participants found that enhanced test names, test data, and variable names improved their bug-fixing process.","sentences":["Automated unit test generators, particularly search-based software testing tools like EvoSuite, are capable of generating tests with high coverage.","Although these generators alleviate the burden of writing unit tests, they often pose challenges for software engineers in terms of understanding the generated tests.","To address this, we introduce UTGen, which combines search-based software testing and large language models to enhance the understandability of automatically generated test cases.","We achieve this enhancement through contextualizing test data, improving identifier naming, and adding descriptive comments.","Through a controlled experiment with 32 participants from both academia and industry, we investigate how the understandability of unit tests affects a software engineer's ability to perform bug-fixing tasks.","We selected bug-fixing to simulate a real-world scenario that emphasizes the importance of understandable test cases.","We observe that participants working on assignments with UTGen test cases fix up to 33% more bugs and use up to 20% less time when compared to baseline test cases.","From the post-test questionnaire, we gathered that participants found that enhanced test names, test data, and variable names improved their bug-fixing process."],"url":"http://arxiv.org/abs/2408.11710v1"}
{"created":"2024-08-21 15:30:35","title":"FRAP: Faithful and Realistic Text-to-Image Generation with Adaptive Prompt Weighting","abstract":"Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt. However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt's semantics. Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images. In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images. We design an online algorithm to adaptively update each token's weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs. Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&B on the COCO-Subject dataset. Furthermore, through visual comparisons and evaluation on the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances. We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality.","sentences":["Text-to-image (T2I) diffusion models have demonstrated impressive capabilities in generating high-quality images given a text prompt.","However, ensuring the prompt-image alignment remains a considerable challenge, i.e., generating images that faithfully align with the prompt's semantics.","Recent works attempt to improve the faithfulness by optimizing the latent code, which potentially could cause the latent code to go out-of-distribution and thus produce unrealistic images.","In this paper, we propose FRAP, a simple, yet effective approach based on adaptively adjusting the per-token prompt weights to improve prompt-image alignment and authenticity of the generated images.","We design an online algorithm to adaptively update each token's weight coefficient, which is achieved by minimizing a unified objective function that encourages object presence and the binding of object-modifier pairs.","Through extensive evaluations, we show FRAP generates images with significantly higher prompt-image alignment to prompts from complex datasets, while having a lower average latency compared to recent latent code optimization methods, e.g., 4 seconds faster than D&B on the COCO-Subject dataset.","Furthermore, through visual comparisons and evaluation on the CLIP-IQA-Real metric, we show that FRAP not only improves prompt-image alignment but also generates more authentic images with realistic appearances.","We also explore combining FRAP with prompt rewriting LLM to recover their degraded prompt-image alignment, where we observe improvements in both prompt-image alignment and image quality."],"url":"http://arxiv.org/abs/2408.11706v1"}
{"created":"2024-08-21 15:24:40","title":"Supervised Representation Learning towards Generalizable Assembly State Recognition","abstract":"Assembly state recognition facilitates the execution of assembly procedures, offering feedback to enhance efficiency and minimize errors. However, recognizing assembly states poses challenges in scalability, since parts are frequently updated, and the robustness to execution errors remains underexplored. To address these challenges, this paper proposes an approach based on representation learning and the novel intermediate-state informed loss function modification (ISIL). ISIL leverages unlabeled transitions between states and demonstrates significant improvements in clustering and classification performance for all tested architectures and losses. Despite being trained exclusively on images without execution errors, thorough analysis on error states demonstrates that our approach accurately distinguishes between correct states and states with various types of execution errors. The integration of the proposed algorithm can offer meaningful assistance to workers and mitigate unexpected losses due to procedural mishaps in industrial settings. The code is available at: https://timschoonbeek.github.io/state_rec","sentences":["Assembly state recognition facilitates the execution of assembly procedures, offering feedback to enhance efficiency and minimize errors.","However, recognizing assembly states poses challenges in scalability, since parts are frequently updated, and the robustness to execution errors remains underexplored.","To address these challenges, this paper proposes an approach based on representation learning and the novel intermediate-state informed loss function modification (ISIL).","ISIL leverages unlabeled transitions between states and demonstrates significant improvements in clustering and classification performance for all tested architectures and losses.","Despite being trained exclusively on images without execution errors, thorough analysis on error states demonstrates that our approach accurately distinguishes between correct states and states with various types of execution errors.","The integration of the proposed algorithm can offer meaningful assistance to workers and mitigate unexpected losses due to procedural mishaps in industrial settings.","The code is available at: https://timschoonbeek.github.io/state_rec"],"url":"http://arxiv.org/abs/2408.11700v1"}
{"created":"2024-08-21 15:22:43","title":"Automating Semantic Analysis of System Assurance Cases using Goal-directed ASP","abstract":"Assurance cases offer a structured way to present arguments and evidence for certification of systems where safety and security are critical. However, creating and evaluating these assurance cases can be complex and challenging, even for systems of moderate complexity. Therefore, there is a growing need to develop new automation methods for these tasks. While most existing assurance case tools focus on automating structural aspects, they lack the ability to fully assess the semantic coherence and correctness of the assurance arguments.   In prior work, we introduced the Assurance 2.0 framework that prioritizes the reasoning process, evidence utilization, and explicit delineation of counter-claims (defeaters) and counter-evidence. In this paper, we present our approach to enhancing Assurance 2.0 with semantic rule-based analysis capabilities using common-sense reasoning and answer set programming solvers, specifically s(CASP). By employing these analysis techniques, we examine the unique semantic aspects of assurance cases, such as logical consistency, adequacy, indefeasibility, etc. The application of these analyses provides both system developers and evaluators with increased confidence about the assurance case.","sentences":["Assurance cases offer a structured way to present arguments and evidence for certification of systems where safety and security are critical.","However, creating and evaluating these assurance cases can be complex and challenging, even for systems of moderate complexity.","Therefore, there is a growing need to develop new automation methods for these tasks.","While most existing assurance case tools focus on automating structural aspects, they lack the ability to fully assess the semantic coherence and correctness of the assurance arguments.   ","In prior work, we introduced the Assurance 2.0 framework that prioritizes the reasoning process, evidence utilization, and explicit delineation of counter-claims (defeaters) and counter-evidence.","In this paper, we present our approach to enhancing Assurance 2.0 with semantic rule-based analysis capabilities using common-sense reasoning and answer set programming solvers, specifically s(CASP).","By employing these analysis techniques, we examine the unique semantic aspects of assurance cases, such as logical consistency, adequacy, indefeasibility, etc.","The application of these analyses provides both system developers and evaluators with increased confidence about the assurance case."],"url":"http://arxiv.org/abs/2408.11699v1"}
{"created":"2024-08-21 15:21:27","title":"Robust 3D Gaussian Splatting for Novel View Synthesis in Presence of Distractors","abstract":"3D Gaussian Splatting has shown impressive novel view synthesis results; nonetheless, it is vulnerable to dynamic objects polluting the input data of an otherwise static scene, so called distractors. Distractors have severe impact on the rendering quality as they get represented as view-dependent effects or result in floating artifacts. Our goal is to identify and ignore such distractors during the 3D Gaussian optimization to obtain a clean reconstruction. To this end, we take a self-supervised approach that looks at the image residuals during the optimization to determine areas that have likely been falsified by a distractor. In addition, we leverage a pretrained segmentation network to provide object awareness, enabling more accurate exclusion of distractors. This way, we obtain segmentation masks of distractors to effectively ignore them in the loss formulation. We demonstrate that our approach is robust to various distractors and strongly improves rendering quality on distractor-polluted scenes, improving PSNR by 1.86dB compared to 3D Gaussian Splatting.","sentences":["3D Gaussian Splatting has shown impressive novel view synthesis results; nonetheless, it is vulnerable to dynamic objects polluting the input data of an otherwise static scene, so called distractors.","Distractors have severe impact on the rendering quality as they get represented as view-dependent effects or result in floating artifacts.","Our goal is to identify and ignore such distractors during the 3D Gaussian optimization to obtain a clean reconstruction.","To this end, we take a self-supervised approach that looks at the image residuals during the optimization to determine areas that have likely been falsified by a distractor.","In addition, we leverage a pretrained segmentation network to provide object awareness, enabling more accurate exclusion of distractors.","This way, we obtain segmentation masks of distractors to effectively ignore them in the loss formulation.","We demonstrate that our approach is robust to various distractors and strongly improves rendering quality on distractor-polluted scenes, improving PSNR by 1.86dB compared to 3D Gaussian Splatting."],"url":"http://arxiv.org/abs/2408.11697v1"}
{"created":"2024-08-21 15:10:50","title":"Physics-informed Discovery of State Variables in Second-Order and Hamiltonian Systems","abstract":"The modeling of dynamical systems is a pervasive concern for not only describing but also predicting and controlling natural phenomena and engineered systems. Current data-driven approaches often assume prior knowledge of the relevant state variables or result in overparameterized state spaces. Boyuan Chen and his co-authors proposed a neural network model that estimates the degrees of freedom and attempts to discover the state variables of a dynamical system. Despite its innovative approach, this baseline model lacks a connection to the physical principles governing the systems it analyzes, leading to unreliable state variables.   This research proposes a method that leverages the physical characteristics of second-order Hamiltonian systems to constrain the baseline model. The proposed model outperforms the baseline model in identifying a minimal set of non-redundant and interpretable state variables.","sentences":["The modeling of dynamical systems is a pervasive concern for not only describing but also predicting and controlling natural phenomena and engineered systems.","Current data-driven approaches often assume prior knowledge of the relevant state variables or result in overparameterized state spaces.","Boyuan Chen and his co-authors proposed a neural network model that estimates the degrees of freedom and attempts to discover the state variables of a dynamical system.","Despite its innovative approach, this baseline model lacks a connection to the physical principles governing the systems it analyzes, leading to unreliable state variables.   ","This research proposes a method that leverages the physical characteristics of second-order Hamiltonian systems to constrain the baseline model.","The proposed model outperforms the baseline model in identifying a minimal set of non-redundant and interpretable state variables."],"url":"http://arxiv.org/abs/2408.11691v1"}
{"created":"2024-08-21 15:10:09","title":"Collaborative Robot Arm Inserting Nasopharyngeal Swabs with Admittance Control","abstract":"The nasopharyngeal (NP) swab sample test, commonly used to detect COVID-19 and other respiratory illnesses, involves moving a swab through the nasal cavity to collect samples from the nasopharynx. While typically this is done by human healthcare workers, there is a significant societal interest to enable robots to do this test to reduce exposure to patients and to free up human resources. The task is challenging from the robotics perspective because of the dexterity and safety requirements. While other works have implemented specific hardware solutions, our research differentiates itself by using a ubiquitous rigid robotic arm. This work presents a case study where we investigate the strengths and challenges using compliant control system to accomplish NP swab tests with such a robotic configuration. To accomplish this, we designed a force sensing end-effector that integrates with the proposed torque controlled compliant control loop. We then conducted experiments where the robot inserted NP swabs into a 3D printed nasal cavity phantom. Ultimately, we found that the compliant control system outperformed a basic position controller and shows promise for human use. However, further efforts are needed to ensure the initial alignment with the nostril and to address head motion.","sentences":["The nasopharyngeal (NP) swab sample test, commonly used to detect COVID-19 and other respiratory illnesses, involves moving a swab through the nasal cavity to collect samples from the nasopharynx.","While typically this is done by human healthcare workers, there is a significant societal interest to enable robots to do this test to reduce exposure to patients and to free up human resources.","The task is challenging from the robotics perspective because of the dexterity and safety requirements.","While other works have implemented specific hardware solutions, our research differentiates itself by using a ubiquitous rigid robotic arm.","This work presents a case study where we investigate the strengths and challenges using compliant control system to accomplish NP swab tests with such a robotic configuration.","To accomplish this, we designed a force sensing end-effector that integrates with the proposed torque controlled compliant control loop.","We then conducted experiments where the robot inserted NP swabs into a 3D printed nasal cavity phantom.","Ultimately, we found that the compliant control system outperformed a basic position controller and shows promise for human use.","However, further efforts are needed to ensure the initial alignment with the nostril and to address head motion."],"url":"http://arxiv.org/abs/2408.11688v1"}
{"created":"2024-08-21 15:09:09","title":"Interpretable Long-term Action Quality Assessment","abstract":"Long-term Action Quality Assessment (AQA) evaluates the execution of activities in videos. However, the length presents challenges in fine-grained interpretability, with current AQA methods typically producing a single score by averaging clip features, lacking detailed semantic meanings of individual clips. Long-term videos pose additional difficulty due to the complexity and diversity of actions, exacerbating interpretability challenges. While query-based transformer networks offer promising long-term modeling capabilities, their interpretability in AQA remains unsatisfactory due to a phenomenon we term Temporal Skipping, where the model skips self-attention layers to prevent output degradation. To address this, we propose an attention loss function and a query initialization method to enhance performance and interpretability. Additionally, we introduce a weight-score regression module designed to approximate the scoring patterns observed in human judgments and replace conventional single-score regression, improving the rationality of interpretability. Our approach achieves state-of-the-art results on three real-world, long-term AQA benchmarks. Our code is available at: https://github.com/dx199771/Interpretability-AQA","sentences":["Long-term Action Quality Assessment (AQA) evaluates the execution of activities in videos.","However, the length presents challenges in fine-grained interpretability, with current AQA methods typically producing a single score by averaging clip features, lacking detailed semantic meanings of individual clips.","Long-term videos pose additional difficulty due to the complexity and diversity of actions, exacerbating interpretability challenges.","While query-based transformer networks offer promising long-term modeling capabilities, their interpretability in AQA remains unsatisfactory due to a phenomenon we term Temporal Skipping, where the model skips self-attention layers to prevent output degradation.","To address this, we propose an attention loss function and a query initialization method to enhance performance and interpretability.","Additionally, we introduce a weight-score regression module designed to approximate the scoring patterns observed in human judgments and replace conventional single-score regression, improving the rationality of interpretability.","Our approach achieves state-of-the-art results on three real-world, long-term AQA benchmarks.","Our code is available at: https://github.com/dx199771/Interpretability-AQA"],"url":"http://arxiv.org/abs/2408.11687v1"}
{"created":"2024-08-21 15:00:16","title":"First line of defense: A robust first layer mitigates adversarial attacks","abstract":"Adversarial training (AT) incurs significant computational overhead, leading to growing interest in designing inherently robust architectures. We demonstrate that a carefully designed first layer of the neural network can serve as an implicit adversarial noise filter (ANF). This filter is created using a combination of large kernel size, increased convolution filters, and a maxpool operation. We show that integrating this filter as the first layer in architectures such as ResNet, VGG, and EfficientNet results in adversarially robust networks. Our approach achieves higher adversarial accuracies than existing natively robust architectures without AT and is competitive with adversarial-trained architectures across a wide range of datasets. Supporting our findings, we show that (a) the decision regions for our method have better margins, (b) the visualized loss surfaces are smoother, (c) the modified peak signal-to-noise ratio (mPSNR) values at the output of the ANF are higher, (d) high-frequency components are more attenuated, and (e) architectures incorporating ANF exhibit better denoising in Gaussian noise compared to baseline architectures. Code for all our experiments are available at \\url{https://github.com/janani-suresh-97/first-line-defence.git}.","sentences":["Adversarial training (AT) incurs significant computational overhead, leading to growing interest in designing inherently robust architectures.","We demonstrate that a carefully designed first layer of the neural network can serve as an implicit adversarial noise filter (ANF).","This filter is created using a combination of large kernel size, increased convolution filters, and a maxpool operation.","We show that integrating this filter as the first layer in architectures such as ResNet, VGG, and EfficientNet results in adversarially robust networks.","Our approach achieves higher adversarial accuracies than existing natively robust architectures without AT and is competitive with adversarial-trained architectures across a wide range of datasets.","Supporting our findings, we show that (a) the decision regions for our method have better margins, (b) the visualized loss surfaces are smoother, (c) the modified peak signal-to-noise ratio (mPSNR) values at the output of the ANF are higher, (d) high-frequency components are more attenuated, and (e) architectures incorporating ANF exhibit better denoising in Gaussian noise compared to baseline architectures.","Code for all our experiments are available at \\url{https://github.com/janani-suresh-97/first-line-defence.git}."],"url":"http://arxiv.org/abs/2408.11680v1"}
{"created":"2024-08-21 14:58:29","title":"Exploring Robustness of Visual State Space model against Backdoor Attacks","abstract":"Visual State Space Model (VSS) has demonstrated remarkable performance in various computer vision tasks. However, in the process of development, backdoor attacks have brought severe challenges to security. Such attacks cause an infected model to predict target labels when a specific trigger is activated, while the model behaves normally on benign samples. In this paper, we conduct systematic experiments to comprehend on robustness of VSS through the lens of backdoor attacks, specifically how the state space model (SSM) mechanism affects robustness. We first investigate the vulnerability of VSS to different backdoor triggers and reveal that the SSM mechanism, which captures contextual information within patches, makes the VSS model more susceptible to backdoor triggers compared to models without SSM. Furthermore, we analyze the sensitivity of the VSS model to patch processing techniques and discover that these triggers are effectively disrupted. Based on these observations, we consider an effective backdoor for the VSS model that recurs in each patch to resist patch perturbations. Extensive experiments across three datasets and various backdoor attacks reveal that the VSS model performs comparably to Transformers (ViTs) but is less robust than the Gated CNNs, which comprise only stacked Gated CNN blocks without SSM.","sentences":["Visual State Space Model (VSS) has demonstrated remarkable performance in various computer vision tasks.","However, in the process of development, backdoor attacks have brought severe challenges to security.","Such attacks cause an infected model to predict target labels when a specific trigger is activated, while the model behaves normally on benign samples.","In this paper, we conduct systematic experiments to comprehend on robustness of VSS through the lens of backdoor attacks, specifically how the state space model (SSM) mechanism affects robustness.","We first investigate the vulnerability of VSS to different backdoor triggers and reveal that the SSM mechanism, which captures contextual information within patches, makes the VSS model more susceptible to backdoor triggers compared to models without SSM.","Furthermore, we analyze the sensitivity of the VSS model to patch processing techniques and discover that these triggers are effectively disrupted.","Based on these observations, we consider an effective backdoor for the VSS model that recurs in each patch to resist patch perturbations.","Extensive experiments across three datasets and various backdoor attacks reveal that the VSS model performs comparably to Transformers (ViTs) but is less robust than the Gated CNNs, which comprise only stacked Gated CNN blocks without SSM."],"url":"http://arxiv.org/abs/2408.11679v1"}
{"created":"2024-08-21 14:50:37","title":"Improved Visual Saliency of Graph Clusters with Orderable Node-Link Layouts","abstract":"Graphs are often used to model relationships between entities. The identification and visualization of clusters in graphs enable insight discovery in many application areas, such as life sciences and social sciences. Force-directed graph layouts promote the visual saliency of clusters, as they bring adjacent nodes closer together, and push non-adjacent nodes apart. At the same time, matrices can effectively show clusters when a suitable row/column ordering is applied, but are less appealing to untrained users not providing an intuitive node-link metaphor. It is thus worth exploring layouts combining the strengths of the node-link metaphor and node ordering. In this work, we study the impact of node ordering on the visual saliency of clusters in orderable node-link diagrams, namely radial diagrams, arc diagrams and symmetric arc diagrams. Through a crowdsourced controlled experiment, we show that users can count clusters consistently more accurately, and to a large extent faster, with orderable node-link diagrams than with three state-of-the art force-directed layout algorithms, i.e., `Linlog', `Backbone' and `sfdp'. The measured advantage is greater in case of low cluster separability and/or low compactness. A free copy of this paper and all supplemental materials are available at https://osf.io/kc3dg/.","sentences":["Graphs are often used to model relationships between entities.","The identification and visualization of clusters in graphs enable insight discovery in many application areas, such as life sciences and social sciences.","Force-directed graph layouts promote the visual saliency of clusters, as they bring adjacent nodes closer together, and push non-adjacent nodes apart.","At the same time, matrices can effectively show clusters when a suitable row/column ordering is applied, but are less appealing to untrained users not providing an intuitive node-link metaphor.","It is thus worth exploring layouts combining the strengths of the node-link metaphor and node ordering.","In this work, we study the impact of node ordering on the visual saliency of clusters in orderable node-link diagrams, namely radial diagrams, arc diagrams and symmetric arc diagrams.","Through a crowdsourced controlled experiment, we show that users can count clusters consistently more accurately, and to a large extent faster, with orderable node-link diagrams than with three state-of-the art force-directed layout algorithms, i.e., `Linlog', `Backbone' and `sfdp'.","The measured advantage is greater in case of low cluster separability and/or low compactness.","A free copy of this paper and all supplemental materials are available at https://osf.io/kc3dg/."],"url":"http://arxiv.org/abs/2408.11673v1"}
{"created":"2024-08-21 14:39:34","title":"The Problems with Proxies: Making Data Work Visible through Requester Practices","abstract":"Fairness in AI and ML systems is increasingly linked to the proper treatment and recognition of data workers involved in training dataset development. Yet, those who collect and annotate the data, and thus have the most intimate knowledge of its development, are often excluded from critical discussions. This exclusion prevents data annotators, who are domain experts, from contributing effectively to dataset contextualization. Our investigation into the hiring and engagement practices of 52 data work requesters on platforms like Amazon Mechanical Turk reveals a gap: requesters frequently hold naive or unchallenged notions of worker identities and capabilities and rely on ad-hoc qualification tasks that fail to respect the workers' expertise. These practices not only undermine the quality of data but also the ethical standards of AI development. To rectify these issues, we advocate for policy changes to enhance how data annotation tasks are designed and managed and to ensure data workers are treated with the respect they deserve.","sentences":["Fairness in AI and ML systems is increasingly linked to the proper treatment and recognition of data workers involved in training dataset development.","Yet, those who collect and annotate the data, and thus have the most intimate knowledge of its development, are often excluded from critical discussions.","This exclusion prevents data annotators, who are domain experts, from contributing effectively to dataset contextualization.","Our investigation into the hiring and engagement practices of 52 data work requesters on platforms like Amazon Mechanical Turk reveals a gap: requesters frequently hold naive or unchallenged notions of worker identities and capabilities and rely on ad-hoc qualification tasks that fail to respect the workers' expertise.","These practices not only undermine the quality of data but also the ethical standards of AI development.","To rectify these issues, we advocate for policy changes to enhance how data annotation tasks are designed and managed and to ensure data workers are treated with the respect they deserve."],"url":"http://arxiv.org/abs/2408.11667v1"}
{"created":"2024-08-21 14:39:14","title":"Online state vector reduction during model predictive control with gradient-based trajectory optimisation","abstract":"Non-prehensile manipulation in high-dimensional systems is challenging for a variety of reasons, one of the main reasons is the computationally long planning times that come with a large state space. Trajectory optimisation algorithms have proved their utility in a wide variety of tasks, but, like most methods struggle scaling to the high dimensional systems ubiquitous to non-prehensile manipulation in clutter as well as deformable object manipulation. We reason that, during manipulation, different degrees of freedom will become more or less important to the task over time as the system evolves. We leverage this idea to reduce the number of degrees of freedom considered in a trajectory optimisation problem, to reduce planning times. This idea is particularly relevant in the context of model predictive control (MPC) where the cost landscape of the optimisation problem is constantly evolving. We provide simulation results under asynchronous MPC and show our methods are capable of achieving better overall performance due to the decreased policy lag whilst still being able to optimise trajectories effectively.","sentences":["Non-prehensile manipulation in high-dimensional systems is challenging for a variety of reasons, one of the main reasons is the computationally long planning times that come with a large state space.","Trajectory optimisation algorithms have proved their utility in a wide variety of tasks, but, like most methods struggle scaling to the high dimensional systems ubiquitous to non-prehensile manipulation in clutter as well as deformable object manipulation.","We reason that, during manipulation, different degrees of freedom will become more or less important to the task over time as the system evolves.","We leverage this idea to reduce the number of degrees of freedom considered in a trajectory optimisation problem, to reduce planning times.","This idea is particularly relevant in the context of model predictive control (MPC) where the cost landscape of the optimisation problem is constantly evolving.","We provide simulation results under asynchronous MPC and show our methods are capable of achieving better overall performance due to the decreased policy lag whilst still being able to optimise trajectories effectively."],"url":"http://arxiv.org/abs/2408.11665v1"}
{"created":"2024-08-21 14:38:03","title":"A Systematic Literature Review on the Use of Blockchain Technology in Transition to a Circular Economy","abstract":"The circular economy has the potential to increase resource efficiency and minimize waste through the 4R framework of reducing, reusing, recycling, and recovering. Blockchain technology is currently considered a valuable aid in the transition to a circular economy. Its decentralized and tamper-resistant nature enables the construction of transparent and secure supply chain management systems, thereby improving product accountability and traceability. However, the full potential of blockchain technology in circular economy models will not be realized until a number of concerns, including scalability, interoperability, data protection, and regulatory and legal issues, are addressed. More research and stakeholder participation are required to overcome these limitations and achieve the benefits of blockchain technology in promoting a circular economy. This article presents a systematic literature review (SLR) that identified industry use cases for blockchain-driven circular economy models and offered architectures to minimize resource consumption, prices, and inefficiencies while encouraging the reuse, recycling, and recovery of end-of-life products. Three main outcomes emerged from our review of 41 documents, which included scholarly publications, Twitter-linked information, and Google results. The relationship between blockchain and the 4R framework for circular economy; discussion the terminology and various forms of blockchain and circular economy; and identification of the challenges and obstacles that blockchain technology may face in enabling a circular economy. This research shows how blockchain technology can help with the transition to a circular economy. Yet, it emphasizes the importance of additional study and stakeholder participation to overcome potential hurdles and obstacles in implementing blockchain-driven circular economy models.","sentences":["The circular economy has the potential to increase resource efficiency and minimize waste through the 4R framework of reducing, reusing, recycling, and recovering.","Blockchain technology is currently considered a valuable aid in the transition to a circular economy.","Its decentralized and tamper-resistant nature enables the construction of transparent and secure supply chain management systems, thereby improving product accountability and traceability.","However, the full potential of blockchain technology in circular economy models will not be realized until a number of concerns, including scalability, interoperability, data protection, and regulatory and legal issues, are addressed.","More research and stakeholder participation are required to overcome these limitations and achieve the benefits of blockchain technology in promoting a circular economy.","This article presents a systematic literature review (SLR) that identified industry use cases for blockchain-driven circular economy models and offered architectures to minimize resource consumption, prices, and inefficiencies while encouraging the reuse, recycling, and recovery of end-of-life products.","Three main outcomes emerged from our review of 41 documents, which included scholarly publications, Twitter-linked information, and Google results.","The relationship between blockchain and the 4R framework for circular economy; discussion the terminology and various forms of blockchain and circular economy; and identification of the challenges and obstacles that blockchain technology may face in enabling a circular economy.","This research shows how blockchain technology can help with the transition to a circular economy.","Yet, it emphasizes the importance of additional study and stakeholder participation to overcome potential hurdles and obstacles in implementing blockchain-driven circular economy models."],"url":"http://arxiv.org/abs/2408.11664v1"}
{"created":"2024-08-21 14:37:50","title":"Optimizing Federated Graph Learning with Inherent Structural Knowledge and Dual-Densely Connected GNNs","abstract":"Federated Graph Learning (FGL) is an emerging technology that enables clients to collaboratively train powerful Graph Neural Networks (GNNs) in a distributed manner without exposing their private data. Nevertheless, FGL still faces the challenge of the severe non-Independent and Identically Distributed (non-IID) nature of graphs, which possess diverse node and edge structures, especially across varied domains. Thus, exploring the knowledge inherent in these structures becomes significantly crucial. Existing methods, however, either overlook the inherent structural knowledge in graph data or capture it at the cost of significantly increased resource demands (e.g., FLOPs and communication bandwidth), which can be detrimental to distributed paradigms. Inspired by this, we propose FedDense, a novel FGL framework that optimizes the utilization efficiency of inherent structural knowledge. To better acquire knowledge of diverse and underexploited structures, FedDense first explicitly encodes the structural knowledge inherent within graph data itself alongside node features. Besides, FedDense introduces a Dual-Densely Connected (DDC) GNN architecture that exploits the multi-scale (i.e., one-hop to multi-hop) feature and structure insights embedded in the aggregated feature maps at each layer. In addition to the exploitation of inherent structures, we consider resource limitations in FGL, devising exceedingly narrow layers atop the DDC architecture and adopting a selective parameter sharing strategy to reduce resource costs substantially. We conduct extensive experiments using 15 datasets across 4 different domains, demonstrating that FedDense consistently surpasses baselines by a large margin in training performance, while demanding minimal resources.","sentences":["Federated Graph Learning (FGL) is an emerging technology that enables clients to collaboratively train powerful Graph Neural Networks (GNNs) in a distributed manner without exposing their private data.","Nevertheless, FGL still faces the challenge of the severe non-Independent and Identically Distributed (non-IID) nature of graphs, which possess diverse node and edge structures, especially across varied domains.","Thus, exploring the knowledge inherent in these structures becomes significantly crucial.","Existing methods, however, either overlook the inherent structural knowledge in graph data or capture it at the cost of significantly increased resource demands (e.g., FLOPs and communication bandwidth), which can be detrimental to distributed paradigms.","Inspired by this, we propose FedDense, a novel FGL framework that optimizes the utilization efficiency of inherent structural knowledge.","To better acquire knowledge of diverse and underexploited structures, FedDense first explicitly encodes the structural knowledge inherent within graph data itself alongside node features.","Besides, FedDense introduces a Dual-Densely Connected (DDC) GNN architecture that exploits the multi-scale (i.e., one-hop to multi-hop) feature and structure insights embedded in the aggregated feature maps at each layer.","In addition to the exploitation of inherent structures, we consider resource limitations in FGL, devising exceedingly narrow layers atop the DDC architecture and adopting a selective parameter sharing strategy to reduce resource costs substantially.","We conduct extensive experiments using 15 datasets across 4 different domains, demonstrating that FedDense consistently surpasses baselines by a large margin in training performance, while demanding minimal resources."],"url":"http://arxiv.org/abs/2408.11662v1"}
{"created":"2024-08-21 14:34:22","title":"Anteumbler: Non-Invasive Antenna Orientation Error Measurement for WiFi APs","abstract":"The performance of WiFi-based localization systems is affected by the spatial accuracy of WiFi AP. Compared with the imprecision of AP location and antenna separation, the imprecision of AP's or antenna's orientation is more important in real scenarios, including AP rotation and antenna irregular tilt. In this paper, we propose Anteumbler that non-invasively, accurately and efficiently measures the orientation of each antenna in physical space. Based on the fact that the received power is maximized when a Tx-Rx antenna pair is perfectly aligned, we construct a spatial angle model that can obtain the antennas' orientations without prior knowledge. However, the sampling points of traversing the spatial angle need to cover the entire space. We use the orthogonality of antenna directivity and polarization and adopt an iterative algorithm to reduce the sampling points by hundreds of times, which greatly improves the efficiency. To achieve the required antenna orientation accuracy, we eliminate the influence of propagation distance using a dual plane intersection model and filter out ambient noise. Our real-world experiments with six antenna types, two antenna layouts and two antenna separations show that Anteumbler achieves median errors below 6 degree for both elevation and azimuth angles, and is robust to NLoS and dynamic environments. Last but not least, for the reverse localization system, we deploy Anteumbler over LocAP and reduce the antenna separation error by 10 mm, while for the user localization system, we deploy Anteumbler over SpotFi and reduce the user localization error by more than 1 m.","sentences":["The performance of WiFi-based localization systems is affected by the spatial accuracy of WiFi AP.","Compared with the imprecision of AP location and antenna separation, the imprecision of AP's or antenna's orientation is more important in real scenarios, including AP rotation and antenna irregular tilt.","In this paper, we propose Anteumbler that non-invasively, accurately and efficiently measures the orientation of each antenna in physical space.","Based on the fact that the received power is maximized when a Tx-Rx antenna pair is perfectly aligned, we construct a spatial angle model that can obtain the antennas' orientations without prior knowledge.","However, the sampling points of traversing the spatial angle need to cover the entire space.","We use the orthogonality of antenna directivity and polarization and adopt an iterative algorithm to reduce the sampling points by hundreds of times, which greatly improves the efficiency.","To achieve the required antenna orientation accuracy, we eliminate the influence of propagation distance using a dual plane intersection model and filter out ambient noise.","Our real-world experiments with six antenna types, two antenna layouts and two antenna separations show that Anteumbler achieves median errors below 6 degree for both elevation and azimuth angles, and is robust to NLoS and dynamic environments.","Last but not least, for the reverse localization system, we deploy Anteumbler over LocAP and reduce the antenna separation error by 10 mm, while for the user localization system, we deploy Anteumbler over SpotFi and reduce the user localization error by more than 1 m."],"url":"http://arxiv.org/abs/2408.11660v1"}
{"created":"2024-08-21 14:27:36","title":"Macformer: Transformer with Random Maclaurin Feature Attention","abstract":"Random feature attention (RFA) adopts random fourier feature (RFF) methods to approximate the softmax function, resulting in a linear time and space attention mechanism that enables the construction of an efficient Transformer. Inspired by RFA, we propose Macformer, a Transformer architecture that employs random Maclaurin features (RMF) to approximate various dot-product kernels, thereby accelerating attention computations for long sequence. Macformer consists of Random Maclaurin Feature Attention (RMFA) and pre-post Scaling Batch Normalization (ppSBN), the former is an unbiased approximation for dot-product kernelized attention and the later is a two-stage regularization mechanism guaranteeing the error of RMFA. We conducted toy experiments to demonstrate the efficiency of RMFA and ppSBN, and experiments on long range arena (LRA) benchmark to validate the acceleration and accuracy of Macformer with different dot-product kernels. Experiment results of Macformer are consistent with our theoretical analysis.","sentences":["Random feature attention (RFA) adopts random fourier feature (RFF) methods to approximate the softmax function, resulting in a linear time and space attention mechanism that enables the construction of an efficient Transformer.","Inspired by RFA, we propose Macformer, a Transformer architecture that employs random Maclaurin features (RMF) to approximate various dot-product kernels, thereby accelerating attention computations for long sequence.","Macformer consists of Random Maclaurin Feature Attention (RMFA) and pre-post Scaling Batch Normalization (ppSBN), the former is an unbiased approximation for dot-product kernelized attention and the later is a two-stage regularization mechanism guaranteeing the error of RMFA.","We conducted toy experiments to demonstrate the efficiency of RMFA and ppSBN, and experiments on long range arena (LRA) benchmark to validate the acceleration and accuracy of Macformer with different dot-product kernels.","Experiment results of Macformer are consistent with our theoretical analysis."],"url":"http://arxiv.org/abs/2408.11656v1"}
{"created":"2024-08-21 14:24:30","title":"Boolean basis, formula size, and number of modal operators","abstract":"Is it possible to write significantly smaller formulae when using Boolean operators other than those of the De Morgan basis (and, or, not, and the constants)? For propositional logic, a negative answer was given by Pratt: formulae over one set of operators can always be translated into an equivalent formula over any other complete set of operators with only polynomial increase in size. Surprisingly, for modal logic the picture is different: we show that elimination of bi-implication is only possible at the cost of an exponential number of occurrences of the modal operator $\\lozenge$ and therefore of an exponential increase in formula size, i.e., the De Morgan basis and its extension by bi-implication differ in succinctness. Moreover, we prove that any complete set of Boolean operators agrees in succinctness with the De Morgan basis or with its extension by bi-implication. More precisely, these results are shown for the modal logic $\\mathrm{T}$ (and therefore for $\\mathrm{K}$). We complement them showing that the modal logic $\\mathrm{S5}$ behaves as propositional logic: the choice of Boolean operators has no significant impact on the size of formulae.","sentences":["Is it possible to write significantly smaller formulae when using Boolean operators other than those of the De Morgan basis (and, or, not, and the constants)?","For propositional logic, a negative answer was given by Pratt: formulae over one set of operators can always be translated into an equivalent formula over any other complete set of operators with only polynomial increase in size.","Surprisingly, for modal logic the picture is different: we show that elimination of bi-implication is only possible at the cost of an exponential number of occurrences of the modal operator $\\lozenge$ and therefore of an exponential increase in formula size, i.e., the De Morgan basis and its extension by bi-implication differ in succinctness.","Moreover, we prove that any complete set of Boolean operators agrees in succinctness with the De Morgan basis or with its extension by bi-implication.","More precisely, these results are shown for the modal logic $\\mathrm{T}$ (and therefore for $\\mathrm{K}$).","We complement them showing that the modal logic $\\mathrm{S5}$ behaves as propositional logic: the choice of Boolean operators has no significant impact on the size of formulae."],"url":"http://arxiv.org/abs/2408.11651v1"}
{"created":"2024-08-21 14:24:04","title":"CIPHER: Cybersecurity Intelligent Penetration-testing Helper for Ethical Researcher","abstract":"Penetration testing, a critical component of cybersecurity, typically requires extensive time and effort to find vulnerabilities. Beginners in this field often benefit from collaborative approaches with the community or experts. To address this, we develop CIPHER (Cybersecurity Intelligent Penetration-testing Helper for Ethical Researchers), a large language model specifically trained to assist in penetration testing tasks. We trained CIPHER using over 300 high-quality write-ups of vulnerable machines, hacking techniques, and documentation of open-source penetration testing tools. Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR) Flow augmentation, a novel method to augment penetration testing write-ups to establish a fully automated pentesting simulation benchmark tailored for large language models. This approach fills a significant gap in traditional cybersecurity Q\\&A benchmarks and provides a realistic and rigorous standard for evaluating AI's technical knowledge, reasoning capabilities, and practical utility in dynamic penetration testing scenarios. In our assessments, CIPHER achieved the best overall performance in providing accurate suggestion responses compared to other open-source penetration testing models of similar size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B Chat, particularly on insane difficulty machine setups. This demonstrates that the current capabilities of general LLMs are insufficient for effectively guiding users through the penetration testing process. We also discuss the potential for improvement through scaling and the development of better benchmarks using FARR Flow augmentation results. Our benchmark will be released publicly at https://github.com/ibndias/CIPHER.","sentences":["Penetration testing, a critical component of cybersecurity, typically requires extensive time and effort to find vulnerabilities.","Beginners in this field often benefit from collaborative approaches with the community or experts.","To address this, we develop CIPHER (Cybersecurity Intelligent Penetration-testing Helper for Ethical Researchers), a large language model specifically trained to assist in penetration testing tasks.","We trained CIPHER using over 300 high-quality write-ups of vulnerable machines, hacking techniques, and documentation of open-source penetration testing tools.","Additionally, we introduced the Findings, Action, Reasoning, and Results (FARR) Flow augmentation, a novel method to augment penetration testing write-ups to establish a fully automated pentesting simulation benchmark tailored for large language models.","This approach fills a significant gap in traditional cybersecurity Q\\&A benchmarks and provides a realistic and rigorous standard for evaluating AI's technical knowledge, reasoning capabilities, and practical utility in dynamic penetration testing scenarios.","In our assessments, CIPHER achieved the best overall performance in providing accurate suggestion responses compared to other open-source penetration testing models of similar size and even larger state-of-the-art models like Llama 3 70B and Qwen1.5 72B Chat, particularly on insane difficulty machine setups.","This demonstrates that the current capabilities of general LLMs are insufficient for effectively guiding users through the penetration testing process.","We also discuss the potential for improvement through scaling and the development of better benchmarks using FARR Flow augmentation results.","Our benchmark will be released publicly at https://github.com/ibndias/CIPHER."],"url":"http://arxiv.org/abs/2408.11650v1"}
{"created":"2024-08-21 14:21:53","title":"Video-to-Text Pedestrian Monitoring (VTPM): Leveraging Computer Vision and Large Language Models for Privacy-Preserve Pedestrian Activity Monitoring at Intersections","abstract":"Computer vision has advanced research methodologies, enhancing system services across various fields. It is a core component in traffic monitoring systems for improving road safety; however, these monitoring systems don't preserve the privacy of pedestrians who appear in the videos, potentially revealing their identities. Addressing this issue, our paper introduces Video-to-Text Pedestrian Monitoring (VTPM), which monitors pedestrian movements at intersections and generates real-time textual reports, including traffic signal and weather information. VTPM uses computer vision models for pedestrian detection and tracking, achieving a latency of 0.05 seconds per video frame. Additionally, it detects crossing violations with 90.2% accuracy by incorporating traffic signal data. The proposed framework is equipped with Phi-3 mini-4k to generate real-time textual reports of pedestrian activity while stating safety concerns like crossing violations, conflicts, and the impact of weather on their behavior with latency of 0.33 seconds. To enhance comprehensive analysis of the generated textual reports, Phi-3 medium is fine-tuned for historical analysis of these generated textual reports. This fine-tuning enables more reliable analysis about the pedestrian safety at intersections, effectively detecting patterns and safety critical events. The proposed VTPM offers a more efficient alternative to video footage by using textual reports reducing memory usage, saving up to 253 million percent, eliminating privacy issues, and enabling comprehensive interactive historical analysis.","sentences":["Computer vision has advanced research methodologies, enhancing system services across various fields.","It is a core component in traffic monitoring systems for improving road safety; however, these monitoring systems don't preserve the privacy of pedestrians who appear in the videos, potentially revealing their identities.","Addressing this issue, our paper introduces Video-to-Text Pedestrian Monitoring (VTPM), which monitors pedestrian movements at intersections and generates real-time textual reports, including traffic signal and weather information.","VTPM uses computer vision models for pedestrian detection and tracking, achieving a latency of 0.05 seconds per video frame.","Additionally, it detects crossing violations with 90.2% accuracy by incorporating traffic signal data.","The proposed framework is equipped with Phi-3 mini-4k to generate real-time textual reports of pedestrian activity while stating safety concerns like crossing violations, conflicts, and the impact of weather on their behavior with latency of 0.33 seconds.","To enhance comprehensive analysis of the generated textual reports, Phi-3 medium is fine-tuned for historical analysis of these generated textual reports.","This fine-tuning enables more reliable analysis about the pedestrian safety at intersections, effectively detecting patterns and safety critical events.","The proposed VTPM offers a more efficient alternative to video footage by using textual reports reducing memory usage, saving up to 253 million percent, eliminating privacy issues, and enabling comprehensive interactive historical analysis."],"url":"http://arxiv.org/abs/2408.11649v1"}
{"created":"2024-08-21 14:17:24","title":"Mathematical Information Retrieval: Search and Question Answering","abstract":"Mathematical information is essential for technical work, but its creation, interpretation, and search are challenging. To help address these challenges, researchers have developed multimodal search engines and mathematical question answering systems. This book begins with a simple framework characterizing the information tasks that people and systems perform as we work to answer math-related questions. The framework is used to organize and relate the other core topics of the book, including interactions between people and systems, representing math formulas in sources, and evaluation. We close with some key questions and concrete directions for future work. This book is intended for use by students, instructors, and researchers, and those who simply wish that it was easier to find and use mathematical information","sentences":["Mathematical information is essential for technical work, but its creation, interpretation, and search are challenging.","To help address these challenges, researchers have developed multimodal search engines and mathematical question answering systems.","This book begins with a simple framework characterizing the information tasks that people and systems perform as we work to answer math-related questions.","The framework is used to organize and relate the other core topics of the book, including interactions between people and systems, representing math formulas in sources, and evaluation.","We close with some key questions and concrete directions for future work.","This book is intended for use by students, instructors, and researchers, and those who simply wish that it was easier to find and use mathematical information"],"url":"http://arxiv.org/abs/2408.11646v1"}
{"created":"2024-08-21 14:06:22","title":"Private Counting of Distinct Elements in the Turnstile Model and Extensions","abstract":"Privately counting distinct elements in a stream is a fundamental data analysis problem with many applications in machine learning. In the turnstile model, Jain et al. [NeurIPS2023] initiated the study of this problem parameterized by the maximum flippancy of any element, i.e., the number of times that the count of an element changes from 0 to above 0 or vice versa. They give an item-level $(\\epsilon,\\delta)$-differentially private algorithm whose additive error is tight with respect to that parameterization. In this work, we show that a very simple algorithm based on the sparse vector technique achieves a tight additive error for item-level $(\\epsilon,\\delta)$-differential privacy and item-level $\\epsilon$-differential privacy with regards to a different parameterization, namely the sum of all flippancies. Our second result is a bound which shows that for a large class of algorithms, including all existing differentially private algorithms for this problem, the lower bound from item-level differential privacy extends to event-level differential privacy. This partially answers an open question by Jain et al. [NeurIPS2023].","sentences":["Privately counting distinct elements in a stream is a fundamental data analysis problem with many applications in machine learning.","In the turnstile model, Jain et al.","[NeurIPS2023] initiated the study of this problem parameterized by the maximum flippancy of any element, i.e., the number of times that the count of an element changes from 0 to above 0 or vice versa.","They give an item-level $(\\epsilon,\\delta)$-differentially private algorithm whose additive error is tight with respect to that parameterization.","In this work, we show that a very simple algorithm based on the sparse vector technique achieves a tight additive error for item-level $(\\epsilon,\\delta)$-differential privacy and item-level $\\epsilon$-differential privacy with regards to a different parameterization, namely the sum of all flippancies.","Our second result is a bound which shows that for a large class of algorithms, including all existing differentially private algorithms for this problem, the lower bound from item-level differential privacy extends to event-level differential privacy.","This partially answers an open question by Jain et al.","[NeurIPS2023]."],"url":"http://arxiv.org/abs/2408.11637v1"}
{"created":"2024-08-21 14:05:35","title":"Cost-Effective Big Data Orchestration Using Dagster: A Multi-Platform Approach","abstract":"The rapid advancement of big data technologies has underscored the need for robust and efficient data processing solutions. Traditional Spark-based Platform-as-a-Service (PaaS) solutions, such as Databricks and Amazon Web Services Elastic MapReduce, provide powerful analytics capabilities but often result in high operational costs and vendor lock-in issues. These platforms, while user-friendly, can lead to significant inefficiencies due to their cost structures and lack of transparent pricing. This paper introduces a cost-effective and flexible orchestration framework using Dagster. Our solution aims to reduce dependency on any single PaaS provider by integrating various Spark execution environments. We demonstrate how Dagster's orchestration capabilities can enhance data processing efficiency, enforce best coding practices, and significantly reduce operational costs. In our implementation, we achieved a 12% performance improvement over EMR and a 40% cost reduction compared to DBR, translating to over 300 euros saved per pipeline run. Our goal is to provide a flexible, developer-controlled computing environment that maintains or improves performance and scalability while mitigating the risks associated with vendor lock-in. The proposed framework supports rapid prototyping and testing, which is essential for continuous development and operational efficiency, contributing to a more sustainable model of large data processing.","sentences":["The rapid advancement of big data technologies has underscored the need for robust and efficient data processing solutions.","Traditional Spark-based Platform-as-a-Service (PaaS) solutions, such as Databricks and Amazon Web Services Elastic MapReduce, provide powerful analytics capabilities but often result in high operational costs and vendor lock-in issues.","These platforms, while user-friendly, can lead to significant inefficiencies due to their cost structures and lack of transparent pricing.","This paper introduces a cost-effective and flexible orchestration framework using Dagster.","Our solution aims to reduce dependency on any single PaaS provider by integrating various Spark execution environments.","We demonstrate how Dagster's orchestration capabilities can enhance data processing efficiency, enforce best coding practices, and significantly reduce operational costs.","In our implementation, we achieved a 12% performance improvement over EMR and a 40% cost reduction compared to DBR, translating to over 300 euros saved per pipeline run.","Our goal is to provide a flexible, developer-controlled computing environment that maintains or improves performance and scalability while mitigating the risks associated with vendor lock-in.","The proposed framework supports rapid prototyping and testing, which is essential for continuous development and operational efficiency, contributing to a more sustainable model of large data processing."],"url":"http://arxiv.org/abs/2408.11635v1"}
{"created":"2024-08-21 14:04:00","title":"Optimizing Interpretable Decision Tree Policies for Reinforcement Learning","abstract":"Reinforcement learning techniques leveraging deep learning have made tremendous progress in recent years. However, the complexity of neural networks prevents practitioners from understanding their behavior. Decision trees have gained increased attention in supervised learning for their inherent interpretability, enabling modelers to understand the exact prediction process after learning. This paper considers the problem of optimizing interpretable decision tree policies to replace neural networks in reinforcement learning settings. Previous works have relaxed the tree structure, restricted to optimizing only tree leaves, or applied imitation learning techniques to approximately copy the behavior of a neural network policy with a decision tree. We propose the Decision Tree Policy Optimization (DTPO) algorithm that directly optimizes the complete decision tree using policy gradients. Our technique uses established decision tree heuristics for regression to perform policy optimization. We empirically show that DTPO is a competitive algorithm compared to imitation learning algorithms for optimizing decision tree policies in reinforcement learning.","sentences":["Reinforcement learning techniques leveraging deep learning have made tremendous progress in recent years.","However, the complexity of neural networks prevents practitioners from understanding their behavior.","Decision trees have gained increased attention in supervised learning for their inherent interpretability, enabling modelers to understand the exact prediction process after learning.","This paper considers the problem of optimizing interpretable decision tree policies to replace neural networks in reinforcement learning settings.","Previous works have relaxed the tree structure, restricted to optimizing only tree leaves, or applied imitation learning techniques to approximately copy the behavior of a neural network policy with a decision tree.","We propose the Decision Tree Policy Optimization (DTPO) algorithm that directly optimizes the complete decision tree using policy gradients.","Our technique uses established decision tree heuristics for regression to perform policy optimization.","We empirically show that DTPO is a competitive algorithm compared to imitation learning algorithms for optimizing decision tree policies in reinforcement learning."],"url":"http://arxiv.org/abs/2408.11632v1"}
{"created":"2024-08-21 14:01:46","title":"Uncovering and Mitigating the Impact of Frozen Package Versions for Fixed-Release Linux","abstract":"Towards understanding the ecosystem gap of fixed-release Linux that is caused by the evolution of mirrors, we conducted a comprehensive study of the Debian ecosystem. This study involved the collection of Debian packages and the construction of the dependency graph of the Debian ecosystem. Utilizing historic snapshots of Debian mirrors, we were able to recover the evolution of the dependency graph for all Debian releases, including obsolete ones. Through the analysis of the dependency graph and its evolution, we investigated from two key aspects: (1) compatibility issues and (2) security threats in the Debian ecosystem. Our findings provide valuable insights into the use and design of Linux package managers. To address the challenges revealed in the empirical study and bridge the ecosystem gap between releases, we propose a novel package management approach allowing for separate dependency environments based on native Debian mirrors. We present a working prototype, named ccenv, which can effectively remedy the inadequacy of current tools.","sentences":["Towards understanding the ecosystem gap of fixed-release Linux that is caused by the evolution of mirrors, we conducted a comprehensive study of the Debian ecosystem.","This study involved the collection of Debian packages and the construction of the dependency graph of the Debian ecosystem.","Utilizing historic snapshots of Debian mirrors, we were able to recover the evolution of the dependency graph for all Debian releases, including obsolete ones.","Through the analysis of the dependency graph and its evolution, we investigated from two key aspects: (1) compatibility issues and (2) security threats in the Debian ecosystem.","Our findings provide valuable insights into the use and design of Linux package managers.","To address the challenges revealed in the empirical study and bridge the ecosystem gap between releases, we propose a novel package management approach allowing for separate dependency environments based on native Debian mirrors.","We present a working prototype, named ccenv, which can effectively remedy the inadequacy of current tools."],"url":"http://arxiv.org/abs/2408.11631v1"}
{"created":"2024-08-21 14:00:22","title":"A Markovian Model for Learning-to-Optimize","abstract":"We present a probabilistic model for stochastic iterative algorithms with the use case of optimization algorithms in mind. Based on this model, we present PAC-Bayesian generalization bounds for functions that are defined on the trajectory of the learned algorithm, for example, the expected (non-asymptotic) convergence rate and the expected time to reach the stopping criterion. Thus, not only does this model allow for learning stochastic algorithms based on their empirical performance, it also yields results about their actual convergence rate and their actual convergence time. We stress that, since the model is valid in a more general setting than learning-to-optimize, it is of interest for other fields of application, too. Finally, we conduct five practically relevant experiments, showing the validity of our claims.","sentences":["We present a probabilistic model for stochastic iterative algorithms with the use case of optimization algorithms in mind.","Based on this model, we present PAC-Bayesian generalization bounds for functions that are defined on the trajectory of the learned algorithm, for example, the expected (non-asymptotic) convergence rate and the expected time to reach the stopping criterion.","Thus, not only does this model allow for learning stochastic algorithms based on their empirical performance, it also yields results about their actual convergence rate and their actual convergence time.","We stress that, since the model is valid in a more general setting than learning-to-optimize, it is of interest for other fields of application, too.","Finally, we conduct five practically relevant experiments, showing the validity of our claims."],"url":"http://arxiv.org/abs/2408.11629v1"}
{"created":"2024-08-21 13:56:06","title":"Runtime Verification via Rational Monitor with Imperfect Information","abstract":"Trusting software systems, particularly autonomous ones, is challenging. To address this, formal verification techniques can ensure these systems behave as expected. Runtime Verification (RV) is a leading, lightweight method for verifying system behaviour during execution. However, traditional RV assumes perfect information, meaning the monitoring component perceives everything accurately. This assumption often fails, especially with autonomous systems operating in real-world environments where sensors might be faulty. Additionally, traditional RV considers the monitor to be passive, lacking the capability to interpret the system's information and thus unable to address incomplete data. In this work, we extend standard RV of Linear Temporal Logic properties to accommodate scenarios where the monitor has imperfect information and behaves rationally. We outline the necessary engineering steps to update the verification pipeline and demonstrate our implementation in a case study involving robotic systems.","sentences":["Trusting software systems, particularly autonomous ones, is challenging.","To address this, formal verification techniques can ensure these systems behave as expected.","Runtime Verification (RV) is a leading, lightweight method for verifying system behaviour during execution.","However, traditional RV assumes perfect information, meaning the monitoring component perceives everything accurately.","This assumption often fails, especially with autonomous systems operating in real-world environments where sensors might be faulty.","Additionally, traditional RV considers the monitor to be passive, lacking the capability to interpret the system's information and thus unable to address incomplete data.","In this work, we extend standard RV of Linear Temporal Logic properties to accommodate scenarios where the monitor has imperfect information and behaves rationally.","We outline the necessary engineering steps to update the verification pipeline and demonstrate our implementation in a case study involving robotic systems."],"url":"http://arxiv.org/abs/2408.11627v1"}
{"created":"2024-08-21 13:48:00","title":"End-to-End Cost-Effective Incentive Recommendation under Budget Constraint with Uplift Modeling","abstract":"In modern online platforms, incentives are essential factors that enhance user engagement and increase platform revenue. Over recent years, uplift modeling has been introduced as a strategic approach to assign incentives to individual customers. Especially in many real-world applications, online platforms can only incentivize customers with specific budget constraints. This problem can be reformulated as the multi-choice knapsack problem. This optimization aims to select the optimal incentive for each customer to maximize the return on investment. Recent works in this field frequently tackle the budget allocation problem using a two-stage approach. However, this solution is confronted with the following challenges: (1) The causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases. (2) An optimality gap between the two stages results in inferior sub-optimal allocation performance due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint. To address these challenges, we propose a novel End-to-End Cost-Effective Incentive Recommendation (E3IR) model under budget constraints. Specifically, our methods consist of two modules, i.e., the uplift prediction module and the differentiable allocation module. In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (i.e., monotonic and smooth). We incorporate integer linear programming (ILP) as a differentiable layer input in the allocation module. Furthermore, we conduct extensive experiments on public and real product datasets, demonstrating that our E3IR improves allocation performance compared to existing two-stage approaches.","sentences":["In modern online platforms, incentives are essential factors that enhance user engagement and increase platform revenue.","Over recent years, uplift modeling has been introduced as a strategic approach to assign incentives to individual customers.","Especially in many real-world applications, online platforms can only incentivize customers with specific budget constraints.","This problem can be reformulated as the multi-choice knapsack problem.","This optimization aims to select the optimal incentive for each customer to maximize the return on investment.","Recent works in this field frequently tackle the budget allocation problem using a two-stage approach.","However, this solution is confronted with the following challenges: (1) The causal inference methods often ignore the domain knowledge in online marketing, where the expected response curve of a customer should be monotonic and smooth as the incentive increases.","(2) An optimality gap between the two stages results in inferior sub-optimal allocation performance due to the loss of the incentive recommendation information for the uplift prediction under the limited budget constraint.","To address these challenges, we propose a novel End-to-End Cost-Effective Incentive Recommendation (E3IR) model under budget constraints.","Specifically, our methods consist of two modules, i.e., the uplift prediction module and the differentiable allocation module.","In the uplift prediction module, we construct prediction heads to capture the incremental improvement between adjacent treatments with the marketing domain constraints (i.e., monotonic and smooth).","We incorporate integer linear programming (ILP) as a differentiable layer input in the allocation module.","Furthermore, we conduct extensive experiments on public and real product datasets, demonstrating that our E3IR improves allocation performance compared to existing two-stage approaches."],"url":"http://arxiv.org/abs/2408.11623v1"}
{"created":"2024-08-21 13:47:01","title":"Annealed Sinkhorn for Optimal Transport: convergence, regularization path and debiasing","abstract":"Sinkhorn's algorithm is a method of choice to solve large-scale optimal transport (OT) problems. In this context, it involves an inverse temperature parameter $\\beta$ that determines the speed-accuracy trade-off. To improve this trade-off, practitioners often use a variant of this algorithm, Annealed Sinkhorn, that uses an nondecreasing sequence $(\\beta_t)_{t\\in \\mathbb{N}}$ where $t$ is the iteration count. However, besides for the schedule $\\beta_t=\\Theta(\\log t)$ which is impractically slow, it is not known whether this variant is guaranteed to actually solve OT. Our first contribution answers this question: we show that a concave annealing schedule asymptotically solves OT if and only if $\\beta_t\\to+\\infty$ and $\\beta_t-\\beta_{t-1}\\to 0$. The proof is based on an equivalence with Online Mirror Descent and further suggests that the iterates of Annealed Sinkhorn follow the solutions of a sequence of relaxed, entropic OT problems, the regularization path. An analysis of this path reveals that, in addition to the well-known \"entropic\" error in $\\Theta(\\beta^{-1}_t)$, the annealing procedure induces a \"relaxation\" error in $\\Theta(\\beta_{t}-\\beta_{t-1})$. The best error trade-off is achieved with the schedule $\\beta_t = \\Theta(\\sqrt{t})$ which, albeit slow, is a universal limitation of this method. Going beyond this limitation, we propose a simple modification of Annealed Sinkhorn that reduces the relaxation error, and therefore enables faster annealing schedules. In toy experiments, we observe the effectiveness of our Debiased Annealed Sinkhorn's algorithm: a single run of this algorithm spans the whole speed-accuracy Pareto front of the standard Sinkhorn's algorithm.","sentences":["Sinkhorn's algorithm is a method of choice to solve large-scale optimal transport (OT) problems.","In this context, it involves an inverse temperature parameter $\\beta$ that determines the speed-accuracy trade-off.","To improve this trade-off, practitioners often use a variant of this algorithm, Annealed Sinkhorn, that uses an nondecreasing sequence $(\\beta_t)_{t\\in \\mathbb{N}}$ where $t$ is the iteration count.","However, besides for the schedule $\\beta_t=\\Theta(\\log t)$ which is impractically slow, it is not known whether this variant is guaranteed to actually solve OT.","Our first contribution answers this question: we show that a concave annealing schedule asymptotically solves OT","if and only if $\\beta_t\\to+\\infty$ and $\\beta_t-\\beta_{t-1}\\to 0$.","The proof is based on an equivalence with Online Mirror Descent and further suggests that the iterates of Annealed Sinkhorn follow the solutions of a sequence of relaxed, entropic OT problems, the regularization path.","An analysis of this path reveals that, in addition to the well-known \"entropic\" error in $\\Theta(\\beta^{-1}_t)$, the annealing procedure induces a \"relaxation\" error in $\\Theta(\\beta_{t}-\\beta_{t-1})$. The best error trade-off is achieved with the schedule $\\beta_t = \\Theta(\\sqrt{t})$ which, albeit slow, is a universal limitation of this method.","Going beyond this limitation, we propose a simple modification of Annealed Sinkhorn that reduces the relaxation error, and therefore enables faster annealing schedules.","In toy experiments, we observe the effectiveness of our Debiased Annealed Sinkhorn's algorithm: a single run of this algorithm spans the whole speed-accuracy Pareto front of the standard Sinkhorn's algorithm."],"url":"http://arxiv.org/abs/2408.11620v1"}
