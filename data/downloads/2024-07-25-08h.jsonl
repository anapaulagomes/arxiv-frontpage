{"created":"2024-07-24 17:59:43","title":"SV4D: Dynamic 3D Content Generation with Multi-Frame and Multi-View Consistency","abstract":"We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation. Unlike previous methods that rely on separately trained generative models for video generation and novel view synthesis, we design a unified diffusion model to generate novel view videos of dynamic 3D objects. Specifically, given a monocular reference video, SV4D generates novel views for each video frame that are temporally consistent. We then use the generated novel view videos to optimize an implicit 4D representation (dynamic NeRF) efficiently, without the need for cumbersome SDS-based optimization used in most prior works. To train our unified novel view video generation model, we curated a dynamic 3D object dataset from the existing Objaverse dataset. Extensive experimental results on multiple datasets and user studies demonstrate SV4D's state-of-the-art performance on novel-view video synthesis as well as 4D generation compared to prior works.","sentences":["We present Stable Video 4D (SV4D), a latent video diffusion model for multi-frame and multi-view consistent dynamic 3D content generation.","Unlike previous methods that rely on separately trained generative models for video generation and novel view synthesis, we design a unified diffusion model to generate novel view videos of dynamic 3D objects.","Specifically, given a monocular reference video, SV4D generates novel views for each video frame that are temporally consistent.","We then use the generated novel view videos to optimize an implicit 4D representation (dynamic NeRF) efficiently, without the need for cumbersome SDS-based optimization used in most prior works.","To train our unified novel view video generation model, we curated a dynamic 3D object dataset from the existing Objaverse dataset.","Extensive experimental results on multiple datasets and user studies demonstrate SV4D's state-of-the-art performance on novel-view video synthesis as well as 4D generation compared to prior works."],"url":"http://arxiv.org/abs/2407.17470v1"}
{"created":"2024-07-24 17:59:07","title":"I Could've Asked That: Reformulating Unanswerable Questions","abstract":"When seeking information from unfamiliar documents, users frequently pose questions that cannot be answered by the documents. While existing large language models (LLMs) identify these unanswerable questions, they do not assist users in reformulating their questions, thereby reducing their overall utility. We curate CouldAsk, an evaluation benchmark composed of existing and new datasets for document-grounded question answering, specifically designed to study reformulating unanswerable questions. We evaluate state-of-the-art open-source and proprietary LLMs on CouldAsk. The results demonstrate the limited capabilities of these models in reformulating questions. Specifically, GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the time, respectively. Error analysis shows that 62% of the unsuccessful reformulations stem from the models merely rephrasing the questions or even generating identical questions. We publicly release the benchmark and the code to reproduce the experiments.","sentences":["When seeking information from unfamiliar documents, users frequently pose questions that cannot be answered by the documents.","While existing large language models (LLMs) identify these unanswerable questions, they do not assist users in reformulating their questions, thereby reducing their overall utility.","We curate CouldAsk, an evaluation benchmark composed of existing and new datasets for document-grounded question answering, specifically designed to study reformulating unanswerable questions.","We evaluate state-of-the-art open-source and proprietary LLMs on CouldAsk.","The results demonstrate the limited capabilities of these models in reformulating questions.","Specifically, GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the time, respectively.","Error analysis shows that 62% of the unsuccessful reformulations stem from the models merely rephrasing the questions or even generating identical questions.","We publicly release the benchmark and the code to reproduce the experiments."],"url":"http://arxiv.org/abs/2407.17469v1"}
{"created":"2024-07-24 17:59:05","title":"WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries","abstract":"While hallucinations of large language models (LLMs) prevail as a major challenge, existing evaluation benchmarks on factuality do not cover the diverse domains of knowledge that the real-world users of LLMs seek information about. To bridge this gap, we introduce WildHallucinations, a benchmark that evaluates factuality. It does so by prompting LLMs to generate information about entities mined from user-chatbot conversations in the wild. These generations are then automatically fact-checked against a systematically curated knowledge source collected from web search. Notably, half of these real-world entities do not have associated Wikipedia pages. We evaluate 118,785 generations from 15 LLMs on 7,919 entities. We find that LLMs consistently hallucinate more on entities without Wikipedia pages and exhibit varying hallucination rates across different domains. Finally, given the same base models, adding a retrieval component only slightly reduces hallucinations but does not eliminate hallucinations.","sentences":["While hallucinations of large language models (LLMs) prevail as a major challenge, existing evaluation benchmarks on factuality do not cover the diverse domains of knowledge that the real-world users of LLMs seek information about.","To bridge this gap, we introduce WildHallucinations, a benchmark that evaluates factuality.","It does so by prompting LLMs to generate information about entities mined from user-chatbot conversations in the wild.","These generations are then automatically fact-checked against a systematically curated knowledge source collected from web search.","Notably, half of these real-world entities do not have associated Wikipedia pages.","We evaluate 118,785 generations from 15 LLMs on 7,919 entities.","We find that LLMs consistently hallucinate more on entities without Wikipedia pages and exhibit varying hallucination rates across different domains.","Finally, given the same base models, adding a retrieval component only slightly reduces hallucinations but does not eliminate hallucinations."],"url":"http://arxiv.org/abs/2407.17468v1"}
{"created":"2024-07-24 17:59:02","title":"CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models","abstract":"Large Language Models (LLMs) excel in diverse tasks but often underperform in specialized fields due to limited domain-specific or proprietary corpus. Continual pre-training (CPT) enhances LLM capabilities by imbuing new domain-specific or proprietary knowledge while replaying general corpus to prevent catastrophic forgetting. The data mixture ratio of general corpus and domain-specific corpus, however, has been chosen heuristically, leading to sub-optimal training efficiency in practice. In this context, we attempt to re-visit the scaling behavior of LLMs under the hood of CPT, and discover a power-law relationship between loss, mixture ratio, and training tokens scale. We formalize the trade-off between general and domain-specific capabilities, leading to a well-defined Critical Mixture Ratio (CMR) of general and domain data. By striking the balance, CMR maintains the model's general ability and achieves the desired domain transfer, ensuring the highest utilization of available resources. Therefore, if we value the balance between efficiency and effectiveness, CMR can be consider as the optimal mixture ratio.Through extensive experiments, we ascertain the predictability of CMR, and propose CMR scaling law and have substantiated its generalization. These findings offer practical guidelines for optimizing LLM training in specialized domains, ensuring both general and domain-specific performance while efficiently managing training resources.","sentences":["Large Language Models (LLMs) excel in diverse tasks but often underperform in specialized fields due to limited domain-specific or proprietary corpus.","Continual pre-training (CPT) enhances LLM capabilities by imbuing new domain-specific or proprietary knowledge while replaying general corpus to prevent catastrophic forgetting.","The data mixture ratio of general corpus and domain-specific corpus, however, has been chosen heuristically, leading to sub-optimal training efficiency in practice.","In this context, we attempt to re-visit the scaling behavior of LLMs under the hood of CPT, and discover a power-law relationship between loss, mixture ratio, and training tokens scale.","We formalize the trade-off between general and domain-specific capabilities, leading to a well-defined Critical Mixture Ratio (CMR) of general and domain data.","By striking the balance, CMR maintains the model's general ability and achieves the desired domain transfer, ensuring the highest utilization of available resources.","Therefore, if we value the balance between efficiency and effectiveness, CMR can be consider as the optimal mixture ratio.","Through extensive experiments, we ascertain the predictability of CMR, and propose CMR scaling law and have substantiated its generalization.","These findings offer practical guidelines for optimizing LLM training in specialized domains, ensuring both general and domain-specific performance while efficiently managing training resources."],"url":"http://arxiv.org/abs/2407.17467v1"}
{"created":"2024-07-24 17:58:49","title":"Traversing Pareto Optimal Policies: Provably Efficient Multi-Objective Reinforcement Learning","abstract":"This paper investigates multi-objective reinforcement learning (MORL), which focuses on learning Pareto optimal policies in the presence of multiple reward functions. Despite MORL's significant empirical success, there is still a lack of satisfactory understanding of various MORL optimization targets and efficient learning algorithms. Our work offers a systematic analysis of several optimization targets to assess their abilities to find all Pareto optimal policies and controllability over learned policies by the preferences for different objectives. We then identify Tchebycheff scalarization as a favorable scalarization method for MORL. Considering the non-smoothness of Tchebycheff scalarization, we reformulate its minimization problem into a new min-max-max optimization problem. Then, for the stochastic policy class, we propose efficient algorithms using this reformulation to learn Pareto optimal policies. We first propose an online UCB-based algorithm to achieve an $\\varepsilon$ learning error with an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ sample complexity for a single given preference. To further reduce the cost of environment exploration under different preferences, we propose a preference-free framework that first explores the environment without pre-defined preferences and then generates solutions for any number of preferences. We prove that it only requires an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ exploration complexity in the exploration phase and demands no additional exploration afterward. Lastly, we analyze the smooth Tchebycheff scalarization, an extension of Tchebycheff scalarization, which is proved to be more advantageous in distinguishing the Pareto optimal policies from other weakly Pareto optimal policies based on entry values of preference vectors. Furthermore, we extend our algorithms and theoretical analysis to accommodate this optimization target.","sentences":["This paper investigates multi-objective reinforcement learning (MORL), which focuses on learning Pareto optimal policies in the presence of multiple reward functions.","Despite MORL's significant empirical success, there is still a lack of satisfactory understanding of various MORL optimization targets and efficient learning algorithms.","Our work offers a systematic analysis of several optimization targets to assess their abilities to find all Pareto optimal policies and controllability over learned policies by the preferences for different objectives.","We then identify Tchebycheff scalarization as a favorable scalarization method for MORL.","Considering the non-smoothness of Tchebycheff scalarization, we reformulate its minimization problem into a new min-max-max optimization problem.","Then, for the stochastic policy class, we propose efficient algorithms using this reformulation to learn Pareto optimal policies.","We first propose an online UCB-based algorithm to achieve an $\\varepsilon$ learning error with an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ sample complexity for a single given preference.","To further reduce the cost of environment exploration under different preferences, we propose a preference-free framework that first explores the environment without pre-defined preferences and then generates solutions for any number of preferences.","We prove that it only requires an $\\tilde{\\mathcal{O}}(\\varepsilon^{-2})$ exploration complexity in the exploration phase and demands no additional exploration afterward.","Lastly, we analyze the smooth Tchebycheff scalarization, an extension of Tchebycheff scalarization, which is proved to be more advantageous in distinguishing the Pareto optimal policies from other weakly Pareto optimal policies based on entry values of preference vectors.","Furthermore, we extend our algorithms and theoretical analysis to accommodate this optimization target."],"url":"http://arxiv.org/abs/2407.17466v1"}
{"created":"2024-07-24 17:58:42","title":"u-$\u03bc$P: The Unit-Scaled Maximal Update Parametrization","abstract":"The Maximal Update Parametrization ($\\mu$P) aims to make the optimal hyperparameters (HPs) of a model independent of its size, allowing them to be swept using a cheap proxy model rather than the full-size target model. We present a new scheme, u-$\\mu$P, which improves upon $\\mu$P by combining it with Unit Scaling, a method for designing models that makes them easy to train in low-precision. The two techniques have a natural affinity: $\\mu$P ensures that the scale of activations is independent of model size, and Unit Scaling ensures that activations, weights and gradients begin training with a scale of one. This synthesis opens the door to a simpler scheme, whose default values are near-optimal. This in turn facilitates a more efficient sweeping strategy, with u-$\\mu$P models reaching a lower loss than comparable $\\mu$P models and working out-of-the-box in FP8.","sentences":["The Maximal Update Parametrization ($\\mu$P) aims to make the optimal hyperparameters (HPs) of a model independent of its size, allowing them to be swept using a cheap proxy model rather than the full-size target model.","We present a new scheme, u-$\\mu$P, which improves upon $\\mu$P by combining it with Unit Scaling, a method for designing models that makes them easy to train in low-precision.","The two techniques have a natural affinity: $\\mu$P ensures that the scale of activations is independent of model size, and Unit Scaling ensures that activations, weights and gradients begin training with a scale of one.","This synthesis opens the door to a simpler scheme, whose default values are near-optimal.","This in turn facilitates a more efficient sweeping strategy, with u-$\\mu$P models reaching a lower loss than comparable $\\mu$P models and working out-of-the-box in FP8."],"url":"http://arxiv.org/abs/2407.17465v1"}
{"created":"2024-07-24 17:58:41","title":"Toward human-centered shared autonomy AI paradigms for human-robot teaming in healthcare","abstract":"With recent advancements in AI and computation tools, intelligent paradigms emerged to empower different fields such as healthcare robots with new capabilities. Advanced AI robotic algorithms (e.g., reinforcement learning) can be trained and developed to autonomously make individual decisions to achieve a desired and usually fixed goal. However, such independent decisions and goal achievements might not be ideal for a healthcare robot that usually interacts with a dynamic end-user or a patient. In such a complex human-robot interaction (teaming) framework, the dynamic user continuously wants to be involved in decision-making as well as introducing new goals while interacting with their present environment in real-time. To address this challenge, an adaptive shared autonomy AI paradigm is required to be developed for the two interactive agents (Human & AI agents) with a foundation based on human-centered factors to avoid any possible ethical issues and guarantee no harm to humanity.","sentences":["With recent advancements in AI and computation tools, intelligent paradigms emerged to empower different fields such as healthcare robots with new capabilities.","Advanced AI robotic algorithms (e.g., reinforcement learning) can be trained and developed to autonomously make individual decisions to achieve a desired and usually fixed goal.","However, such independent decisions and goal achievements might not be ideal for a healthcare robot that usually interacts with a dynamic end-user or a patient.","In such a complex human-robot interaction (teaming) framework, the dynamic user continuously wants to be involved in decision-making as well as introducing new goals while interacting with their present environment in real-time.","To address this challenge, an adaptive shared autonomy AI paradigm is required to be developed for the two interactive agents (Human & AI agents) with a foundation based on human-centered factors to avoid any possible ethical issues and guarantee no harm to humanity."],"url":"http://arxiv.org/abs/2407.17464v1"}
{"created":"2024-07-24 17:57:21","title":"SoNIC: Safe Social Navigation with Adaptive Conformal Inference and Constrained Reinforcement Learning","abstract":"Reinforcement Learning (RL) has enabled social robots to generate trajectories without human-designed rules or interventions, which makes it more effective than hard-coded systems for generalizing to complex real-world scenarios. However, social navigation is a safety-critical task that requires robots to avoid collisions with pedestrians while previous RL-based solutions fall short in safety performance in complex environments. To enhance the safety of RL policies, to the best of our knowledge, we propose the first algorithm, SoNIC, that integrates adaptive conformal inference (ACI) with constrained reinforcement learning (CRL) to learn safe policies for social navigation. More specifically, our method augments RL observations with ACI-generated nonconformity scores and provides explicit guidance for agents to leverage the uncertainty metrics to avoid safety-critical areas by incorporating safety constraints with spatial relaxation. Our method outperforms state-of-the-art baselines in terms of both safety and adherence to social norms by a large margin and demonstrates much stronger robustness to out-of-distribution scenarios. Our code and video demos are available on our project website: https://sonic-social-nav.github.io/.","sentences":["Reinforcement Learning (RL) has enabled social robots to generate trajectories without human-designed rules or interventions, which makes it more effective than hard-coded systems for generalizing to complex real-world scenarios.","However, social navigation is a safety-critical task that requires robots to avoid collisions with pedestrians while previous RL-based solutions fall short in safety performance in complex environments.","To enhance the safety of RL policies, to the best of our knowledge, we propose the first algorithm, SoNIC, that integrates adaptive conformal inference (ACI) with constrained reinforcement learning (CRL) to learn safe policies for social navigation.","More specifically, our method augments RL observations with ACI-generated nonconformity scores and provides explicit guidance for agents to leverage the uncertainty metrics to avoid safety-critical areas by incorporating safety constraints with spatial relaxation.","Our method outperforms state-of-the-art baselines in terms of both safety and adherence to social norms by a large margin and demonstrates much stronger robustness to out-of-distribution scenarios.","Our code and video demos are available on our project website: https://sonic-social-nav.github.io/."],"url":"http://arxiv.org/abs/2407.17460v1"}
{"created":"2024-07-24 17:54:07","title":"Hidden or Inferred: Fair Learning-To-Rank with Unknown Demographics","abstract":"As learning-to-rank models are increasingly deployed for decision-making in areas with profound life implications, the FairML community has been developing fair learning-to-rank (LTR) models. These models rely on the availability of sensitive demographic features such as race or sex. However, in practice, regulatory obstacles and privacy concerns protect this data from collection and use. As a result, practitioners may either need to promote fairness despite the absence of these features or turn to demographic inference tools to attempt to infer them. Given that these tools are fallible, this paper aims to further understand how errors in demographic inference impact the fairness performance of popular fair LTR strategies. In which cases would it be better to keep such demographic attributes hidden from models versus infer them? We examine a spectrum of fair LTR strategies ranging from fair LTR with and without demographic features hidden versus inferred to fairness-unaware LTR followed by fair re-ranking. We conduct a controlled empirical investigation modeling different levels of inference errors by systematically perturbing the inferred sensitive attribute. We also perform three case studies with real-world datasets and popular open-source inference methods. Our findings reveal that as inference noise grows, LTR-based methods that incorporate fairness considerations into the learning process may increase bias. In contrast, fair re-ranking strategies are more robust to inference errors. All source code, data, and experimental artifacts of our experimental study are available here: https://github.com/sewen007/hoiltr.git","sentences":["As learning-to-rank models are increasingly deployed for decision-making in areas with profound life implications, the FairML community has been developing fair learning-to-rank (LTR) models.","These models rely on the availability of sensitive demographic features such as race or sex.","However, in practice, regulatory obstacles and privacy concerns protect this data from collection and use.","As a result, practitioners may either need to promote fairness despite the absence of these features or turn to demographic inference tools to attempt to infer them.","Given that these tools are fallible, this paper aims to further understand how errors in demographic inference impact the fairness performance of popular fair LTR strategies.","In which cases would it be better to keep such demographic attributes hidden from models versus infer them?","We examine a spectrum of fair LTR strategies ranging from fair LTR with and without demographic features hidden versus inferred to fairness-unaware LTR followed by fair re-ranking.","We conduct a controlled empirical investigation modeling different levels of inference errors by systematically perturbing the inferred sensitive attribute.","We also perform three case studies with real-world datasets and popular open-source inference methods.","Our findings reveal that as inference noise grows, LTR-based methods that incorporate fairness considerations into the learning process may increase bias.","In contrast, fair re-ranking strategies are more robust to inference errors.","All source code, data, and experimental artifacts of our experimental study are available here: https://github.com/sewen007/hoiltr.git"],"url":"http://arxiv.org/abs/2407.17459v1"}
{"created":"2024-07-24 17:50:54","title":"EuroCropsML: A Time Series Benchmark Dataset For Few-Shot Crop Type Classification","abstract":"We introduce EuroCropsML, an analysis-ready remote sensing machine learning dataset for time series crop type classification of agricultural parcels in Europe. It is the first dataset designed to benchmark transnational few-shot crop type classification algorithms that supports advancements in algorithmic development and research comparability. It comprises 706 683 multi-class labeled data points across 176 classes, featuring annual time series of per-parcel median pixel values from Sentinel-2 L1C data for 2021, along with crop type labels and spatial coordinates. Based on the open-source EuroCrops collection, EuroCropsML is publicly available on Zenodo.","sentences":["We introduce EuroCropsML, an analysis-ready remote sensing machine learning dataset for time series crop type classification of agricultural parcels in Europe.","It is the first dataset designed to benchmark transnational few-shot crop type classification algorithms that supports advancements in algorithmic development and research comparability.","It comprises 706 683 multi-class labeled data points across 176 classes, featuring annual time series of per-parcel median pixel values from Sentinel-2 L1C data for 2021, along with crop type labels and spatial coordinates.","Based on the open-source EuroCrops collection, EuroCropsML is publicly available on Zenodo."],"url":"http://arxiv.org/abs/2407.17458v1"}
{"created":"2024-07-24 17:50:24","title":"Why Machines Can't Be Moral: Turing's Halting Problem and the Moral Limits of Artificial Intelligence","abstract":"In this essay, I argue that explicit ethical machines, whose moral principles are inferred through a bottom-up approach, are unable to replicate human-like moral reasoning and cannot be considered moral agents. By utilizing Alan Turing's theory of computation, I demonstrate that moral reasoning is computationally intractable by these machines due to the halting problem. I address the frontiers of machine ethics by formalizing moral problems into 'algorithmic moral questions' and by exploring moral psychology's dual-process model. While the nature of Turing Machines theoretically allows artificial agents to engage in recursive moral reasoning, critical limitations are introduced by the halting problem, which states that it is impossible to predict with certainty whether a computational process will halt. A thought experiment involving a military drone illustrates this issue, showing that an artificial agent might fail to decide between actions due to the halting problem, which limits the agent's ability to make decisions in all instances, undermining its moral agency.","sentences":["In this essay, I argue that explicit ethical machines, whose moral principles are inferred through a bottom-up approach, are unable to replicate human-like moral reasoning and cannot be considered moral agents.","By utilizing Alan Turing's theory of computation, I demonstrate that moral reasoning is computationally intractable by these machines due to the halting problem.","I address the frontiers of machine ethics by formalizing moral problems into 'algorithmic moral questions' and by exploring moral psychology's dual-process model.","While the nature of Turing Machines theoretically allows artificial agents to engage in recursive moral reasoning, critical limitations are introduced by the halting problem, which states that it is impossible to predict with certainty whether a computational process will halt.","A thought experiment involving a military drone illustrates this issue, showing that an artificial agent might fail to decide between actions due to the halting problem, which limits the agent's ability to make decisions in all instances, undermining its moral agency."],"url":"http://arxiv.org/abs/2407.16890v1"}
{"created":"2024-07-24 17:50:00","title":"CSCPR: Cross-Source-Context Indoor RGB-D Place Recognition","abstract":"We present a new algorithm, Cross-Source-Context Place Recognition (CSCPR), for RGB-D indoor place recognition that integrates global retrieval and reranking into a single end-to-end model. Unlike prior approaches that primarily focus on the RGB domain, CSCPR is designed to handle the RGB-D data. We extend the Context-of-Clusters (CoCs) for handling noisy colorized point clouds and introduce two novel modules for reranking: the Self-Context Cluster (SCC) and Cross Source Context Cluster (CSCC), which enhance feature representation and match query-database pairs based on local features, respectively. We also present two new datasets, ScanNetIPR and ARKitIPR. Our experiments demonstrate that CSCPR significantly outperforms state-of-the-art models on these datasets by at least 36.5% in Recall@1 at ScanNet-PR dataset and 44% in new datasets. Code and datasets will be released.","sentences":["We present a new algorithm, Cross-Source-Context Place Recognition (CSCPR), for RGB-D indoor place recognition that integrates global retrieval and reranking into a single end-to-end model.","Unlike prior approaches that primarily focus on the RGB domain, CSCPR is designed to handle the RGB-D data.","We extend the Context-of-Clusters (CoCs) for handling noisy colorized point clouds and introduce two novel modules for reranking: the Self-Context Cluster (SCC) and Cross Source Context Cluster (CSCC), which enhance feature representation and match query-database pairs based on local features, respectively.","We also present two new datasets, ScanNetIPR and ARKitIPR.","Our experiments demonstrate that CSCPR significantly outperforms state-of-the-art models on these datasets by at least 36.5% in Recall@1 at ScanNet-PR dataset and 44% in new datasets.","Code and datasets will be released."],"url":"http://arxiv.org/abs/2407.17457v1"}
{"created":"2024-07-24 17:41:32","title":"Automated Explanation Selection for Scientific Discovery","abstract":"Automated reasoning is a key technology in the young but rapidly growing field of Explainable Artificial Intelligence (XAI). Explanability helps build trust in artificial intelligence systems beyond their mere predictive accuracy and robustness. In this paper, we propose a cycle of scientific discovery that combines machine learning with automated reasoning for the generation and the selection of explanations. We present a taxonomy of explanation selection problems that draws on insights from sociology and cognitive science. These selection criteria subsume existing notions and extend them with new properties.","sentences":["Automated reasoning is a key technology in the young but rapidly growing field of Explainable Artificial Intelligence (XAI).","Explanability helps build trust in artificial intelligence systems beyond their mere predictive accuracy and robustness.","In this paper, we propose a cycle of scientific discovery that combines machine learning with automated reasoning for the generation and the selection of explanations.","We present a taxonomy of explanation selection problems that draws on insights from sociology and cognitive science.","These selection criteria subsume existing notions and extend them with new properties."],"url":"http://arxiv.org/abs/2407.17454v1"}
{"created":"2024-07-24 17:37:05","title":"$VILA^2$: VILA Augmented VILA","abstract":"Visual language models (VLMs) have rapidly progressed, driven by the success of large language models (LLMs). While model architectures and training infrastructures advance rapidly, data curation remains under-explored. When data quantity and quality become a bottleneck, existing work either directly crawls more raw data from the Internet that does not have a guarantee of data quality or distills from black-box commercial models (e.g., GPT-4V / Gemini) causing the performance upper bounded by that model. In this work, we introduce a novel approach that includes a self-augment step and a specialist-augment step to iteratively improve data quality and model performance. In the self-augment step, a VLM recaptions its own pretraining data to enhance data quality, and then retrains from scratch using this refined dataset to improve model performance. This process can iterate for several rounds. Once self-augmentation saturates, we employ several specialist VLMs finetuned from the self-augmented VLM with domain-specific expertise, to further infuse specialist knowledge into the generalist VLM through task-oriented recaptioning and retraining. With the combined self-augmented and specialist-augmented training, we introduce $VILA^2$ (VILA-augmented-VILA), a VLM family that consistently improves the accuracy on a wide range of tasks over prior art, and achieves new state-of-the-art results on MMMU leaderboard among open-sourced models.","sentences":["Visual language models (VLMs) have rapidly progressed, driven by the success of large language models (LLMs).","While model architectures and training infrastructures advance rapidly, data curation remains under-explored.","When data quantity and quality become a bottleneck, existing work either directly crawls more raw data from the Internet that does not have a guarantee of data quality or distills from black-box commercial models (e.g., GPT-4V / Gemini) causing the performance upper bounded by that model.","In this work, we introduce a novel approach that includes a self-augment step and a specialist-augment step to iteratively improve data quality and model performance.","In the self-augment step, a VLM recaptions its own pretraining data to enhance data quality, and then retrains from scratch using this refined dataset to improve model performance.","This process can iterate for several rounds.","Once self-augmentation saturates, we employ several specialist VLMs finetuned from the self-augmented VLM with domain-specific expertise, to further infuse specialist knowledge into the generalist VLM through task-oriented recaptioning and retraining.","With the combined self-augmented and specialist-augmented training, we introduce $VILA^2$ (VILA-augmented-VILA), a VLM family that consistently improves the accuracy on a wide range of tasks over prior art, and achieves new state-of-the-art results on MMMU leaderboard among open-sourced models."],"url":"http://arxiv.org/abs/2407.17453v1"}
{"created":"2024-07-24 17:31:48","title":"BlueTempNet: A Temporal Multi-network Dataset of Social Interactions in Bluesky Social","abstract":"Decentralized social media platforms like Bluesky Social (Bluesky) have made it possible to publicly disclose some user behaviors with millisecond-level precision. Embracing Bluesky's principles of open-source and open-data, we present the first collection of the temporal dynamics of user-driven social interactions. BlueTempNet integrates multiple types of networks into a single multi-network, including user-to-user interactions (following and blocking users) and user-to-community interactions (creating and joining communities). Communities are user-formed groups in custom Feeds, where users subscribe to posts aligned with their interests. Following Bluesky's public data policy, we collect existing Bluesky Feeds, including the users who liked and generated these Feeds, and provide tools to gather users' social interactions within a date range. This data-collection strategy captures past user behaviors and supports the future data collection of user behavior.","sentences":["Decentralized social media platforms like Bluesky Social (Bluesky) have made it possible to publicly disclose some user behaviors with millisecond-level precision.","Embracing Bluesky's principles of open-source and open-data, we present the first collection of the temporal dynamics of user-driven social interactions.","BlueTempNet integrates multiple types of networks into a single multi-network, including user-to-user interactions (following and blocking users) and user-to-community interactions (creating and joining communities).","Communities are user-formed groups in custom Feeds, where users subscribe to posts aligned with their interests.","Following Bluesky's public data policy, we collect existing Bluesky Feeds, including the users who liked and generated these Feeds, and provide tools to gather users' social interactions within a date range.","This data-collection strategy captures past user behaviors and supports the future data collection of user behavior."],"url":"http://arxiv.org/abs/2407.17451v1"}
{"created":"2024-07-24 17:30:21","title":"Looking at Model Debiasing through the Lens of Anomaly Detection","abstract":"It is widely recognized that deep neural networks are sensitive to bias in the data. This means that during training these models are likely to learn spurious correlations between data and labels, resulting in limited generalization abilities and low performance. In this context, model debiasing approaches can be devised aiming at reducing the model's dependency on such unwanted correlations, either leveraging the knowledge of bias information or not. In this work, we focus on the latter and more realistic scenario, showing the importance of accurately predicting the bias-conflicting and bias-aligned samples to obtain compelling performance in bias mitigation. On this ground, we propose to conceive the problem of model bias from an out-of-distribution perspective, introducing a new bias identification method based on anomaly detection. We claim that when data is mostly biased, bias-conflicting samples can be regarded as outliers with respect to the bias-aligned distribution in the feature space of a biased model, thus allowing for precisely detecting them with an anomaly detection method. Coupling the proposed bias identification approach with bias-conflicting data upsampling and augmentation in a two-step strategy, we reach state-of-the-art performance on synthetic and real benchmark datasets. Ultimately, our proposed approach shows that the data bias issue does not necessarily require complex debiasing methods, given that an accurate bias identification procedure is defined.","sentences":["It is widely recognized that deep neural networks are sensitive to bias in the data.","This means that during training these models are likely to learn spurious correlations between data and labels, resulting in limited generalization abilities and low performance.","In this context, model debiasing approaches can be devised aiming at reducing the model's dependency on such unwanted correlations, either leveraging the knowledge of bias information or not.","In this work, we focus on the latter and more realistic scenario, showing the importance of accurately predicting the bias-conflicting and bias-aligned samples to obtain compelling performance in bias mitigation.","On this ground, we propose to conceive the problem of model bias from an out-of-distribution perspective, introducing a new bias identification method based on anomaly detection.","We claim that when data is mostly biased, bias-conflicting samples can be regarded as outliers with respect to the bias-aligned distribution in the feature space of a biased model, thus allowing for precisely detecting them with an anomaly detection method.","Coupling the proposed bias identification approach with bias-conflicting data upsampling and augmentation in a two-step strategy, we reach state-of-the-art performance on synthetic and real benchmark datasets.","Ultimately, our proposed approach shows that the data bias issue does not necessarily require complex debiasing methods, given that an accurate bias identification procedure is defined."],"url":"http://arxiv.org/abs/2407.17449v1"}
{"created":"2024-07-24 17:23:18","title":"Fluent Student-Teacher Redteaming","abstract":"Many publicly available language models have been safety tuned to reduce the likelihood of toxic or liability-inducing text. Users or security analysts attempt to jailbreak or redteam these models with adversarial prompts which cause compliance with requests. One attack method is to apply discrete optimization techniques to the prompt. However, the resulting attack strings are often gibberish text, easily filtered by defenders due to high measured perplexity, and may fail for unseen tasks and/or well-tuned models. In this work, we improve existing algorithms (primarily GCG and BEAST) to develop powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our technique centers around a new distillation-based approach that encourages the victim model to emulate a toxified finetune, either in terms of output probabilities or internal activations. To encourage human-fluent attacks, we add a multi-model perplexity penalty and a repetition penalty to the objective. We also enhance optimizer strength by allowing token insertions, token swaps, and token deletions and by using longer attack sequences. The resulting process is able to reliably jailbreak the most difficult target models with prompts that appear similar to human-written prompts. On Advbench we achieve attack success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while maintaining model-measured perplexity $<33$; we achieve $95$% attack success for Phi-3, though with higher perplexity. We also find a universally-optimized single fluent prompt that induces $>88$% compliance on previously unseen tasks across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box models.","sentences":["Many publicly available language models have been safety tuned to reduce the likelihood of toxic or liability-inducing text.","Users or security analysts attempt to jailbreak or redteam these models with adversarial prompts which cause compliance with requests.","One attack method is to apply discrete optimization techniques to the prompt.","However, the resulting attack strings are often gibberish text, easily filtered by defenders due to high measured perplexity, and may fail for unseen tasks and/or well-tuned models.","In this work, we improve existing algorithms (primarily GCG and BEAST) to develop powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3.","Our technique centers around a new distillation-based approach that encourages the victim model to emulate a toxified finetune, either in terms of output probabilities or internal activations.","To encourage human-fluent attacks, we add a multi-model perplexity penalty and a repetition penalty to the objective.","We also enhance optimizer strength by allowing token insertions, token swaps, and token deletions and by using longer attack sequences.","The resulting process is able to reliably jailbreak the most difficult target models with prompts that appear similar to human-written prompts.","On Advbench we achieve attack success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while maintaining model-measured perplexity $<33$; we achieve $95$% attack success for Phi-3, though with higher perplexity.","We also find a universally-optimized single fluent prompt that induces $>88$% compliance on previously unseen tasks across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box models."],"url":"http://arxiv.org/abs/2407.17447v1"}
{"created":"2024-07-24 17:19:58","title":"AHMF: Adaptive Hybrid-Memory-Fusion Model for Driver Attention Prediction","abstract":"Accurate driver attention prediction can serve as a critical reference for intelligent vehicles in understanding traffic scenes and making informed driving decisions. Though existing studies on driver attention prediction improved performance by incorporating advanced saliency detection techniques, they overlooked the opportunity to achieve human-inspired prediction by analyzing driving tasks from a cognitive science perspective. During driving, drivers' working memory and long-term memory play crucial roles in scene comprehension and experience retrieval, respectively. Together, they form situational awareness, facilitating drivers to quickly understand the current traffic situation and make optimal decisions based on past driving experiences. To explicitly integrate these two types of memory, this paper proposes an Adaptive Hybrid-Memory-Fusion (AHMF) driver attention prediction model to achieve more human-like predictions. Specifically, the model first encodes information about specific hazardous stimuli in the current scene to form working memories. Then, it adaptively retrieves similar situational experiences from the long-term memory for final prediction. Utilizing domain adaptation techniques, the model performs parallel training across multiple datasets, thereby enriching the accumulated driving experience within the long-term memory module. Compared to existing models, our model demonstrates significant improvements across various metrics on multiple public datasets, proving the effectiveness of integrating hybrid memories in driver attention prediction.","sentences":["Accurate driver attention prediction can serve as a critical reference for intelligent vehicles in understanding traffic scenes and making informed driving decisions.","Though existing studies on driver attention prediction improved performance by incorporating advanced saliency detection techniques, they overlooked the opportunity to achieve human-inspired prediction by analyzing driving tasks from a cognitive science perspective.","During driving, drivers' working memory and long-term memory play crucial roles in scene comprehension and experience retrieval, respectively.","Together, they form situational awareness, facilitating drivers to quickly understand the current traffic situation and make optimal decisions based on past driving experiences.","To explicitly integrate these two types of memory, this paper proposes an Adaptive Hybrid-Memory-Fusion (AHMF) driver attention prediction model to achieve more human-like predictions.","Specifically, the model first encodes information about specific hazardous stimuli in the current scene to form working memories.","Then, it adaptively retrieves similar situational experiences from the long-term memory for final prediction.","Utilizing domain adaptation techniques, the model performs parallel training across multiple datasets, thereby enriching the accumulated driving experience within the long-term memory module.","Compared to existing models, our model demonstrates significant improvements across various metrics on multiple public datasets, proving the effectiveness of integrating hybrid memories in driver attention prediction."],"url":"http://arxiv.org/abs/2407.17442v1"}
{"created":"2024-07-24 17:16:17","title":"Generative AI in Evidence-Based Software Engineering: A White Paper","abstract":"Context. In less than a year practitioners and researchers witnessed a rapid and wide implementation of Generative Artificial Intelligence. The daily availability of new models proposed by practitioners and researchers has enabled quick adoption. Textual GAIs capabilities enable researchers worldwide to explore new generative scenarios simplifying and hastening all timeconsuming text generation and analysis tasks.   Motivation. The exponentially growing number of publications in our field with the increased accessibility to information due to digital libraries makes conducting systematic literature reviews and mapping studies an effort and timeinsensitive task Stemmed from this challenge we investigated and envisioned the role of GAIs in evidencebased software engineering.   Future Directions. Based on our current investigation we will follow up the vision with the creation and empirical validation of a comprehensive suite of models to effectively support EBSE researchers","sentences":["Context.","In less than a year practitioners and researchers witnessed a rapid and wide implementation of Generative Artificial Intelligence.","The daily availability of new models proposed by practitioners and researchers has enabled quick adoption.","Textual GAIs capabilities enable researchers worldwide to explore new generative scenarios simplifying and hastening all timeconsuming text generation and analysis tasks.   ","Motivation.","The exponentially growing number of publications in our field with the increased accessibility to information due to digital libraries makes conducting systematic literature reviews and mapping studies an effort and timeinsensitive task Stemmed from this challenge we investigated and envisioned the role of GAIs in evidencebased software engineering.   ","Future Directions.","Based on our current investigation we will follow up the vision with the creation and empirical validation of a comprehensive suite of models to effectively support EBSE researchers"],"url":"http://arxiv.org/abs/2407.17440v1"}
{"created":"2024-07-24 17:15:58","title":"HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation","abstract":"Human image animation involves generating videos from a character photo, allowing user control and unlocking potential for video and movie production. While recent approaches yield impressive results using high-quality training data, the inaccessibility of these datasets hampers fair and transparent benchmarking. Moreover, these approaches prioritize 2D human motion and overlook the significance of camera motions in videos, leading to limited control and unstable video generation.To demystify the training data, we present HumanVid, the first large-scale high-quality dataset tailored for human image animation, which combines crafted real-world and synthetic data. For the real-world data, we compile a vast collection of copyright-free real-world videos from the internet. Through a carefully designed rule-based filtering strategy, we ensure the inclusion of high-quality videos, resulting in a collection of 20K human-centric videos in 1080P resolution. Human and camera motion annotation is accomplished using a 2D pose estimator and a SLAM-based method. For the synthetic data, we gather 2,300 copyright-free 3D avatar assets to augment existing available 3D assets. Notably, we introduce a rule-based camera trajectory generation method, enabling the synthetic pipeline to incorporate diverse and precise camera motion annotation, which can rarely be found in real-world data. To verify the effectiveness of HumanVid, we establish a baseline model named CamAnimate, short for Camera-controllable Human Animation, that considers both human and camera motions as conditions. Through extensive experimentation, we demonstrate that such simple baseline training on our HumanVid achieves state-of-the-art performance in controlling both human pose and camera motions, setting a new benchmark. Code and data will be publicly available at \\url{https://github.com/zhenzhiwang/HumanVid/}.","sentences":["Human image animation involves generating videos from a character photo, allowing user control and unlocking potential for video and movie production.","While recent approaches yield impressive results using high-quality training data, the inaccessibility of these datasets hampers fair and transparent benchmarking.","Moreover, these approaches prioritize 2D human motion and overlook the significance of camera motions in videos, leading to limited control and unstable video generation.","To demystify the training data, we present HumanVid, the first large-scale high-quality dataset tailored for human image animation, which combines crafted real-world and synthetic data.","For the real-world data, we compile a vast collection of copyright-free real-world videos from the internet.","Through a carefully designed rule-based filtering strategy, we ensure the inclusion of high-quality videos, resulting in a collection of 20K human-centric videos in 1080P resolution.","Human and camera motion annotation is accomplished using a 2D pose estimator and a SLAM-based method.","For the synthetic data, we gather 2,300 copyright-free 3D avatar assets to augment existing available 3D assets.","Notably, we introduce a rule-based camera trajectory generation method, enabling the synthetic pipeline to incorporate diverse and precise camera motion annotation, which can rarely be found in real-world data.","To verify the effectiveness of HumanVid, we establish a baseline model named CamAnimate, short for Camera-controllable Human Animation, that considers both human and camera motions as conditions.","Through extensive experimentation, we demonstrate that such simple baseline training on our HumanVid achieves state-of-the-art performance in controlling both human pose and camera motions, setting a new benchmark.","Code and data will be publicly available at \\url{https://github.com/zhenzhiwang/HumanVid/}."],"url":"http://arxiv.org/abs/2407.17438v1"}
{"created":"2024-07-24 17:13:31","title":"Nerva: a Truly Sparse Implementation of Neural Networks","abstract":"We introduce Nerva, a fast neural network library under development in C++. It supports sparsity by using the sparse matrix operations of Intel's Math Kernel Library (MKL), which eliminates the need for binary masks. We show that Nerva significantly decreases training time and memory usage while reaching equivalent accuracy to PyTorch. We run static sparse experiments with an MLP on CIFAR-10. On high sparsity levels like $99\\%$, the runtime is reduced by a factor of $4\\times$ compared to a PyTorch model using masks. Similar to other popular frameworks such as PyTorch and Keras, Nerva offers a Python interface for users to work with.","sentences":["We introduce Nerva, a fast neural network library under development in C++.","It supports sparsity by using the sparse matrix operations of Intel's Math Kernel Library (MKL), which eliminates the need for binary masks.","We show that Nerva significantly decreases training time and memory usage while reaching equivalent accuracy to PyTorch.","We run static sparse experiments with an MLP on CIFAR-10.","On high sparsity levels like $99\\%$, the runtime is reduced by a factor of $4\\times$ compared to a PyTorch model using masks.","Similar to other popular frameworks such as PyTorch and Keras, Nerva offers a Python interface for users to work with."],"url":"http://arxiv.org/abs/2407.17437v1"}
{"created":"2024-07-24 17:06:21","title":"An FPGA-Based Open-Source Hardware-Software Framework for Side-Channel Security Research","abstract":"Attacks based on side-channel analysis (SCA) pose a severe security threat to modern computing platforms, further exacerbated on IoT devices by their pervasiveness and handling of private and critical data. Designing SCA-resistant computing platforms requires a significant additional effort in the early stages of the IoT devices' life cycle, which is severely constrained by strict time-to-market deadlines and tight budgets. This manuscript introduces a hardware-software framework meant for SCA research on FPGA targets. It delivers an IoT-class system-on-chip (SoC) that includes a RISC-V CPU, provides observability and controllability through an ad-hoc debug infrastructure to facilitate SCA attacks and evaluate the platform's security, and streamlines the deployment of SCA countermeasures through dedicated hardware and software features such as a DFS actuator and FreeRTOS support. The open-source release of the framework includes the SoC, the scripts to configure the computing platform, compile a target application, and assess the SCA security, as well as a suite of state-of-the-art SCA attacks and countermeasures. The goal is to foster its adoption and novel developments in the field, empowering designers and researchers to focus on studying SCA countermeasures and attacks while relying on a sound and stable hardware-software platform as the foundation for their research.","sentences":["Attacks based on side-channel analysis (SCA) pose a severe security threat to modern computing platforms, further exacerbated on IoT devices by their pervasiveness and handling of private and critical data.","Designing SCA-resistant computing platforms requires a significant additional effort in the early stages of the IoT devices' life cycle, which is severely constrained by strict time-to-market deadlines and tight budgets.","This manuscript introduces a hardware-software framework meant for SCA research on FPGA targets.","It delivers an IoT-class system-on-chip (SoC) that includes a RISC-V CPU, provides observability and controllability through an ad-hoc debug infrastructure to facilitate SCA attacks and evaluate the platform's security, and streamlines the deployment of SCA countermeasures through dedicated hardware and software features such as a DFS actuator and FreeRTOS support.","The open-source release of the framework includes the SoC, the scripts to configure the computing platform, compile a target application, and assess the SCA security, as well as a suite of state-of-the-art SCA attacks and countermeasures.","The goal is to foster its adoption and novel developments in the field, empowering designers and researchers to focus on studying SCA countermeasures and attacks while relying on a sound and stable hardware-software platform as the foundation for their research."],"url":"http://arxiv.org/abs/2407.17432v1"}
{"created":"2024-07-24 17:06:19","title":"ProvenanceWidgets: A Library of UI Control Elements to Track and Dynamically Overlay Analytic Provenance","abstract":"We present ProvenanceWidgets, a Javascript library of UI control elements such as radio buttons, checkboxes, and dropdowns to track and dynamically overlay a user's analytic provenance. These in situ overlays not only save screen space but also minimize the amount of time and effort needed to access the same information from elsewhere in the UI. In this paper, we discuss how we design modular UI control elements to track how often and how recently a user interacts with them and design visual overlays showing an aggregated summary as well as a detailed temporal history. We demonstrate the capability of ProvenanceWidgets by recreating three prior widget libraries: (1) Scented Widgets, (2) Phosphor objects, and (3) Dynamic Query Widgets. We also evaluated its expressiveness and conducted case studies with visualization developers to evaluate its effectiveness. We find that ProvenanceWidgets enables developers to implement custom provenance-tracking applications effectively. ProvenanceWidgets is available as open-source software at https://github.com/ProvenanceWidgets to help application developers build custom provenance-based systems.","sentences":["We present ProvenanceWidgets, a Javascript library of UI control elements such as radio buttons, checkboxes, and dropdowns to track and dynamically overlay a user's analytic provenance.","These in situ overlays not only save screen space but also minimize the amount of time and effort needed to access the same information from elsewhere in the UI.","In this paper, we discuss how we design modular UI control elements to track how often and how recently a user interacts with them and design visual overlays showing an aggregated summary as well as a detailed temporal history.","We demonstrate the capability of ProvenanceWidgets by recreating three prior widget libraries: (1) Scented Widgets, (2) Phosphor objects, and (3) Dynamic Query Widgets.","We also evaluated its expressiveness and conducted case studies with visualization developers to evaluate its effectiveness.","We find that ProvenanceWidgets enables developers to implement custom provenance-tracking applications effectively.","ProvenanceWidgets is available as open-source software at https://github.com/ProvenanceWidgets to help application developers build custom provenance-based systems."],"url":"http://arxiv.org/abs/2407.17431v1"}
{"created":"2024-07-24 16:53:17","title":"3D Gaussian Splatting: Survey, Technologies, Challenges, and Opportunities","abstract":"3D Gaussian Splatting (3DGS) has emerged as a prominent technique with the potential to become a mainstream method for 3D representations. It can effectively transform multi-view images into explicit 3D Gaussian representations through efficient training, and achieve real-time rendering of novel views. This survey aims to analyze existing 3DGS-related works from multiple intersecting perspectives, including related tasks, technologies, challenges, and opportunities. The primary objective is to provide newcomers with a rapid understanding of the field and to assist researchers in methodically organizing existing technologies and challenges. Specifically, we delve into the optimization, application, and extension of 3DGS, categorizing them based on their focuses or motivations. Additionally, we summarize and classify nine types of technical modules and corresponding improvements identified in existing works. Based on these analyses, we further examine the common challenges and technologies across various tasks, proposing potential research opportunities.","sentences":["3D Gaussian Splatting (3DGS) has emerged as a prominent technique with the potential to become a mainstream method for 3D representations.","It can effectively transform multi-view images into explicit 3D Gaussian representations through efficient training, and achieve real-time rendering of novel views.","This survey aims to analyze existing 3DGS-related works from multiple intersecting perspectives, including related tasks, technologies, challenges, and opportunities.","The primary objective is to provide newcomers with a rapid understanding of the field and to assist researchers in methodically organizing existing technologies and challenges.","Specifically, we delve into the optimization, application, and extension of 3DGS, categorizing them based on their focuses or motivations.","Additionally, we summarize and classify nine types of technical modules and corresponding improvements identified in existing works.","Based on these analyses, we further examine the common challenges and technologies across various tasks, proposing potential research opportunities."],"url":"http://arxiv.org/abs/2407.17418v1"}
{"created":"2024-07-24 16:53:09","title":"Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text. However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material. In this paper, we first investigate the effectiveness of watermarking LLMs as a deterrent against the generation of copyrighted texts. Through theoretical analysis and empirical evaluation, we demonstrate that incorporating watermarks into LLMs significantly reduces the likelihood of generating copyrighted content, thereby addressing a critical concern in the deployment of LLMs. Additionally, we explore the impact of watermarking on Membership Inference Attacks (MIAs), which aim to discern whether a sample was part of the pretraining dataset and may be used to detect copyright violations. Surprisingly, we find that watermarking adversely affects the success rate of MIAs, complicating the task of detecting copyrighted text in the pretraining dataset. Finally, we propose an adaptive technique to improve the success rate of a recent MIA under watermarking. Our findings underscore the importance of developing adaptive methods to study critical problems in LLMs with potential legal implications.","sentences":["Large Language Models (LLMs) have demonstrated impressive capabilities in generating diverse and contextually rich text.","However, concerns regarding copyright infringement arise as LLMs may inadvertently produce copyrighted material.","In this paper, we first investigate the effectiveness of watermarking LLMs as a deterrent against the generation of copyrighted texts.","Through theoretical analysis and empirical evaluation, we demonstrate that incorporating watermarks into LLMs significantly reduces the likelihood of generating copyrighted content, thereby addressing a critical concern in the deployment of LLMs.","Additionally, we explore the impact of watermarking on Membership Inference Attacks (MIAs), which aim to discern whether a sample was part of the pretraining dataset and may be used to detect copyright violations.","Surprisingly, we find that watermarking adversely affects the success rate of MIAs, complicating the task of detecting copyrighted text in the pretraining dataset.","Finally, we propose an adaptive technique to improve the success rate of a recent MIA under watermarking.","Our findings underscore the importance of developing adaptive methods to study critical problems in LLMs with potential legal implications."],"url":"http://arxiv.org/abs/2407.17417v1"}
{"created":"2024-07-24 16:47:45","title":"(PASS) Visual Prompt Locates Good Structure Sparsity through a Recurrent HyperNetwork","abstract":"Large-scale neural networks have demonstrated remarkable performance in different domains like vision and language processing, although at the cost of massive computation resources. As illustrated by compression literature, structural model pruning is a prominent algorithm to encourage model efficiency, thanks to its acceleration-friendly sparsity patterns. One of the key questions of structural pruning is how to estimate the channel significance. In parallel, work on data-centric AI has shown that prompting-based techniques enable impressive generalization of large language models across diverse downstream tasks. In this paper, we investigate a charming possibility - \\textit{leveraging visual prompts to capture the channel importance and derive high-quality structural sparsity}. To this end, we propose a novel algorithmic framework, namely \\texttt{PASS}. It is a tailored hyper-network to take both visual prompts and network weight statistics as input, and output layer-wise channel sparsity in a recurrent manner. Such designs consider the intrinsic channel dependency between layers. Comprehensive experiments across multiple network architectures and six datasets demonstrate the superiority of \\texttt{PASS} in locating good structural sparsity. For example, at the same FLOPs level, \\texttt{PASS} subnetworks achieve $1\\%\\sim 3\\%$ better accuracy on Food101 dataset; or with a similar performance of $80\\%$ accuracy, \\texttt{PASS} subnetworks obtain $0.35\\times$ more speedup than the baselines.","sentences":["Large-scale neural networks have demonstrated remarkable performance in different domains like vision and language processing, although at the cost of massive computation resources.","As illustrated by compression literature, structural model pruning is a prominent algorithm to encourage model efficiency, thanks to its acceleration-friendly sparsity patterns.","One of the key questions of structural pruning is how to estimate the channel significance.","In parallel, work on data-centric AI has shown that prompting-based techniques enable impressive generalization of large language models across diverse downstream tasks.","In this paper, we investigate a charming possibility - \\textit{leveraging visual prompts to capture the channel importance and derive high-quality structural sparsity}.","To this end, we propose a novel algorithmic framework, namely \\texttt{PASS}.","It is a tailored hyper-network to take both visual prompts and network weight statistics as input, and output layer-wise channel sparsity in a recurrent manner.","Such designs consider the intrinsic channel dependency between layers.","Comprehensive experiments across multiple network architectures and six datasets demonstrate the superiority of \\texttt{PASS} in locating good structural sparsity.","For example, at the same FLOPs level, \\texttt{PASS} subnetworks achieve $1\\%\\sim 3\\%$ better accuracy on Food101 dataset; or with a similar performance of $80\\%$ accuracy, \\texttt{PASS} subnetworks obtain $0.35\\times$ more speedup than the baselines."],"url":"http://arxiv.org/abs/2407.17412v1"}
{"created":"2024-07-24 16:43:38","title":"Generation of Training Data from HD Maps in the Lanelet2 Framework","abstract":"Using HD maps directly as training data for machine learning tasks has seen a massive surge in popularity and shown promising results, e.g. in the field of map perception. Despite that, a standardized HD map framework supporting all parts of map-based automated driving and training label generation from map data does not exist. Furthermore, feeding map perception models with map data as part of the input during real-time inference is not addressed by the research community. In order to fill this gap, we presentlanelet2_ml_converter, an integrated extension to the HD map framework Lanelet2, widely used in automated driving systems by academia and industry. With this addition Lanelet2 unifies map based automated driving, machine learning inference and training, all from a single source of map data and format. Requirements for a unified framework are analyzed and the implementation of these requirements is described. The usability of labels in state of the art machine learning is demonstrated with application examples from the field of map perception. The source code is available embedded in the Lanelet2 framework under https://github.com/fzi-forschungszentrum-informatik/Lanelet2/tree/feature_ml_converter","sentences":["Using HD maps directly as training data for machine learning tasks has seen a massive surge in popularity and shown promising results, e.g. in the field of map perception.","Despite that, a standardized HD map framework supporting all parts of map-based automated driving and training label generation from map data does not exist.","Furthermore, feeding map perception models with map data as part of the input during real-time inference is not addressed by the research community.","In order to fill this gap, we presentlanelet2_ml_converter, an integrated extension to the HD map framework Lanelet2, widely used in automated driving systems by academia and industry.","With this addition Lanelet2 unifies map based automated driving, machine learning inference and training, all from a single source of map data and format.","Requirements for a unified framework are analyzed and the implementation of these requirements is described.","The usability of labels in state of the art machine learning is demonstrated with application examples from the field of map perception.","The source code is available embedded in the Lanelet2 framework under https://github.com/fzi-forschungszentrum-informatik/Lanelet2/tree/feature_ml_converter"],"url":"http://arxiv.org/abs/2407.17409v1"}
{"created":"2024-07-24 16:38:38","title":"Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models","abstract":"Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences. While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of Transformer language model with explicit dependency-based inductive bias. DTGs simulate dependency transition systems with constrained attention patterns by modifying attention masks, incorporate the stack information through relative positional encoding, and augment dependency arc representation with a combination of token embeddings and operation embeddings. When trained on a dataset of sentences annotated with dependency trees, DTGs achieve better generalization while maintaining comparable perplexity with Transformer language model baselines. DTGs also outperform recent constituency-based models, showing that dependency can better guide Transformer language models. Our code is released at https://github.com/zhaoyd1/Dep_Transformer_Grammars.","sentences":["Syntactic Transformer language models aim to achieve better generalization through simultaneously modeling syntax trees and sentences.","While prior work has been focusing on adding constituency-based structures to Transformers, we introduce Dependency Transformer Grammars (DTGs), a new class of Transformer language model with explicit dependency-based inductive bias.","DTGs simulate dependency transition systems with constrained attention patterns by modifying attention masks, incorporate the stack information through relative positional encoding, and augment dependency arc representation with a combination of token embeddings and operation embeddings.","When trained on a dataset of sentences annotated with dependency trees, DTGs achieve better generalization while maintaining comparable perplexity with Transformer language model baselines.","DTGs also outperform recent constituency-based models, showing that dependency can better guide Transformer language models.","Our code is released at https://github.com/zhaoyd1/Dep_Transformer_Grammars."],"url":"http://arxiv.org/abs/2407.17406v1"}
{"created":"2024-07-24 16:36:02","title":"Grammar-based Game Description Generation using Large Language Models","abstract":"To lower the barriers to game design development, automated game design, which generates game designs through computational processes, has been explored. In automated game design, machine learning-based techniques such as evolutionary algorithms have achieved success. Benefiting from the remarkable advancements in deep learning, applications in computer vision and natural language processing have progressed in level generation. However, due to the limited amount of data in game design, the application of deep learning has been insufficient for tasks such as game description generation. To pioneer a new approach for handling limited data in automated game design, we focus on the in-context learning of large language models (LLMs). LLMs can capture the features of a task from a few demonstration examples and apply the capabilities acquired during pre-training. We introduce the grammar of game descriptions, which effectively structures the game design space, into the LLMs' reasoning process. Grammar helps LLMs capture the characteristics of the complex task of game description generation. Furthermore, we propose a decoding method that iteratively improves the generated output by leveraging the grammar. Our experiments demonstrate that this approach performs well in generating game descriptions.","sentences":["To lower the barriers to game design development, automated game design, which generates game designs through computational processes, has been explored.","In automated game design, machine learning-based techniques such as evolutionary algorithms have achieved success.","Benefiting from the remarkable advancements in deep learning, applications in computer vision and natural language processing have progressed in level generation.","However, due to the limited amount of data in game design, the application of deep learning has been insufficient for tasks such as game description generation.","To pioneer a new approach for handling limited data in automated game design, we focus on the in-context learning of large language models (LLMs).","LLMs can capture the features of a task from a few demonstration examples and apply the capabilities acquired during pre-training.","We introduce the grammar of game descriptions, which effectively structures the game design space, into the LLMs' reasoning process.","Grammar helps LLMs capture the characteristics of the complex task of game description generation.","Furthermore, we propose a decoding method that iteratively improves the generated output by leveraging the grammar.","Our experiments demonstrate that this approach performs well in generating game descriptions."],"url":"http://arxiv.org/abs/2407.17404v1"}
{"created":"2024-07-24 16:23:46","title":"Self-Calibrated Variance-Stabilizing Transformations for Real-World Image Denoising","abstract":"Supervised deep learning has become the method of choice for image denoising. It involves the training of neural networks on large datasets composed of pairs of noisy and clean images. However, the necessity of training data that are specific to the targeted application constrains the widespread use of denoising networks. Recently, several approaches have been developed to overcome this difficulty by whether artificially generating realistic clean/noisy image pairs, or training exclusively on noisy images. In this paper, we show that, contrary to popular belief, denoising networks specialized in the removal of Gaussian noise can be efficiently leveraged in favor of real-world image denoising, even without additional training. For this to happen, an appropriate variance-stabilizing transform (VST) has to be applied beforehand. We propose an algorithm termed Noise2VST for the learning of such a model-free VST. Our approach requires only the input noisy image and an off-the-shelf Gaussian denoiser. We demonstrate through extensive experiments the efficiency and superiority of Noise2VST in comparison to existing methods trained in the absence of specific clean/noisy pairs.","sentences":["Supervised deep learning has become the method of choice for image denoising.","It involves the training of neural networks on large datasets composed of pairs of noisy and clean images.","However, the necessity of training data that are specific to the targeted application constrains the widespread use of denoising networks.","Recently, several approaches have been developed to overcome this difficulty by whether artificially generating realistic clean/noisy image pairs, or training exclusively on noisy images.","In this paper, we show that, contrary to popular belief, denoising networks specialized in the removal of Gaussian noise can be efficiently leveraged in favor of real-world image denoising, even without additional training.","For this to happen, an appropriate variance-stabilizing transform (VST) has to be applied beforehand.","We propose an algorithm termed Noise2VST for the learning of such a model-free VST.","Our approach requires only the input noisy image and an off-the-shelf Gaussian denoiser.","We demonstrate through extensive experiments the efficiency and superiority of Noise2VST in comparison to existing methods trained in the absence of specific clean/noisy pairs."],"url":"http://arxiv.org/abs/2407.17399v1"}
{"created":"2024-07-24 16:22:27","title":"3D Question Answering for City Scene Understanding","abstract":"3D multimodal question answering (MQA) plays a crucial role in scene understanding by enabling intelligent agents to comprehend their surroundings in 3D environments. While existing research has primarily focused on indoor household tasks and outdoor roadside autonomous driving tasks, there has been limited exploration of city-level scene understanding tasks. Furthermore, existing research faces challenges in understanding city scenes, due to the absence of spatial semantic information and human-environment interaction information at the city level.To address these challenges, we investigate 3D MQA from both dataset and method perspectives. From the dataset perspective, we introduce a novel 3D MQA dataset named City-3DQA for city-level scene understanding, which is the first dataset to incorporate scene semantic and human-environment interactive tasks within the city. From the method perspective, we propose a Scene graph enhanced City-level Understanding method (Sg-CityU), which utilizes the scene graph to introduce the spatial semantic. A new benchmark is reported and our proposed Sg-CityU achieves accuracy of 63.94 % and 63.76 % in different settings of City-3DQA. Compared to indoor 3D MQA methods and zero-shot using advanced large language models (LLMs), Sg-CityU demonstrates state-of-the-art (SOTA) performance in robustness and generalization.","sentences":["3D multimodal question answering (MQA) plays a crucial role in scene understanding by enabling intelligent agents to comprehend their surroundings in 3D environments.","While existing research has primarily focused on indoor household tasks and outdoor roadside autonomous driving tasks, there has been limited exploration of city-level scene understanding tasks.","Furthermore, existing research faces challenges in understanding city scenes, due to the absence of spatial semantic information and human-environment interaction information at the city level.","To address these challenges, we investigate 3D MQA from both dataset and method perspectives.","From the dataset perspective, we introduce a novel 3D MQA dataset named City-3DQA for city-level scene understanding, which is the first dataset to incorporate scene semantic and human-environment interactive tasks within the city.","From the method perspective, we propose a Scene graph enhanced City-level Understanding method (Sg-CityU), which utilizes the scene graph to introduce the spatial semantic.","A new benchmark is reported and our proposed Sg-CityU achieves accuracy of 63.94 % and 63.76 % in different settings of City-3DQA.","Compared to indoor 3D MQA methods and zero-shot using advanced large language models (LLMs), Sg-CityU demonstrates state-of-the-art (SOTA) performance in robustness and generalization."],"url":"http://arxiv.org/abs/2407.17398v1"}
{"created":"2024-07-24 16:17:15","title":"Systematic Reasoning About Relational Domains With Graph Neural Networks","abstract":"Developing models that can learn to reason is a notoriously challenging problem. We focus on reasoning in relational domains, where the use of Graph Neural Networks (GNNs) seems like a natural choice. However, previous work on reasoning with GNNs has shown that such models tend to fail when presented with test examples that require longer inference chains than those seen during training. This suggests that GNNs lack the ability to generalize from training examples in a systematic way, which would fundamentally limit their reasoning abilities. A common solution is to instead rely on neuro-symbolic methods, which are capable of reasoning in a systematic way by design. Unfortunately, the scalability of such methods is often limited and they tend to rely on overly strong assumptions, e.g.\\ that queries can be answered by inspecting a single relational path. In this paper, we revisit the idea of reasoning with GNNs, showing that systematic generalization is possible as long as the right inductive bias is provided. In particular, we argue that node embeddings should be treated as epistemic states and that GNN should be parameterised accordingly. We propose a simple GNN architecture which is based on this view and show that it is capable of achieving state-of-the-art results. We furthermore introduce a benchmark which requires models to aggregate evidence from multiple relational paths. We show that existing neuro-symbolic approaches fail on this benchmark, whereas our considered GNN model learns to reason accurately.","sentences":["Developing models that can learn to reason is a notoriously challenging problem.","We focus on reasoning in relational domains, where the use of Graph Neural Networks (GNNs) seems like a natural choice.","However, previous work on reasoning with GNNs has shown that such models tend to fail when presented with test examples that require longer inference chains than those seen during training.","This suggests that GNNs lack the ability to generalize from training examples in a systematic way, which would fundamentally limit their reasoning abilities.","A common solution is to instead rely on neuro-symbolic methods, which are capable of reasoning in a systematic way by design.","Unfortunately, the scalability of such methods is often limited and they tend to rely on overly strong assumptions, e.g.\\ that queries can be answered by inspecting a single relational path.","In this paper, we revisit the idea of reasoning with GNNs, showing that systematic generalization is possible as long as the right inductive bias is provided.","In particular, we argue that node embeddings should be treated as epistemic states and that GNN should be parameterised accordingly.","We propose a simple GNN architecture which is based on this view and show that it is capable of achieving state-of-the-art results.","We furthermore introduce a benchmark which requires models to aggregate evidence from multiple relational paths.","We show that existing neuro-symbolic approaches fail on this benchmark, whereas our considered GNN model learns to reason accurately."],"url":"http://arxiv.org/abs/2407.17396v1"}
{"created":"2024-07-24 16:17:14","title":"Five reasons against assuming a data-generating distribution in Machine Learning","abstract":"Machine Learning research, as most of Statistics, heavily relies on the concept of a data-generating probability distribution. As data points are thought to be sampled from such a distribution, we can learn from observed data about this distribution and, thus, predict future data points drawn from it (with some probability of success). Drawing on scholarship across disciplines, we here argue that this framework is not always a good model. Not only do such true probability distributions not exist; the framework can also be misleading and obscure both the choices made and the goals pursued in machine learning practice. We suggest an alternative framework that focuses on finite populations rather than abstract distributions; while classical learning theory can be left almost unchanged, it opens new opportunities, especially to model sampling. We compile these considerations into five reasons for modelling machine learning -- in some settings -- with finite distributions rather than generative distributions, both to be more faithful to practice and to provide novel theoretical insights.","sentences":["Machine Learning research, as most of Statistics, heavily relies on the concept of a data-generating probability distribution.","As data points are thought to be sampled from such a distribution, we can learn from observed data about this distribution and, thus, predict future data points drawn from it (with some probability of success).","Drawing on scholarship across disciplines, we here argue that this framework is not always a good model.","Not only do such true probability distributions not exist; the framework can also be misleading and obscure both the choices made and the goals pursued in machine learning practice.","We suggest an alternative framework that focuses on finite populations rather than abstract distributions; while classical learning theory can be left almost unchanged, it opens new opportunities, especially to model sampling.","We compile these considerations into five reasons for modelling machine learning -- in some settings -- with finite distributions rather than generative distributions, both to be more faithful to practice and to provide novel theoretical insights."],"url":"http://arxiv.org/abs/2407.17395v1"}
{"created":"2024-07-24 16:17:03","title":"Towards Practical Finite Sample Bounds for Motion Planning in TAMP","abstract":"When using sampling-based motion planners, such as PRMs, in configuration spaces, it is difficult to determine how many samples are required for the PRM to find a solution consistently. This is relevant in Task and Motion Planning (TAMP), where many motion planning problems must be solved in sequence. We attempt to solve this problem by proving an upper bound on the number of samples that are sufficient, with high probability, to find a solution by drawing on prior work in deterministic sampling and sample complexity theory. We also introduce a numerical algorithm to compute a tighter number of samples based on the proof of the sample complexity theorem we apply to derive our bound. Our experiments show that our numerical bounding algorithm is tight within two orders of magnitude on planar planning problems and becomes looser as the problem's dimensionality increases. When deployed as a heuristic to schedule samples in a TAMP planner, we also observe planning time improvements in planar problems. While our experiments show much work remains to tighten our bounds, the ideas presented in this paper are a step towards a practical sample bound.","sentences":["When using sampling-based motion planners, such as PRMs, in configuration spaces, it is difficult to determine how many samples are required for the PRM to find a solution consistently.","This is relevant in Task and Motion Planning (TAMP), where many motion planning problems must be solved in sequence.","We attempt to solve this problem by proving an upper bound on the number of samples that are sufficient, with high probability, to find a solution by drawing on prior work in deterministic sampling and sample complexity theory.","We also introduce a numerical algorithm to compute a tighter number of samples based on the proof of the sample complexity theorem we apply to derive our bound.","Our experiments show that our numerical bounding algorithm is tight within two orders of magnitude on planar planning problems and becomes looser as the problem's dimensionality increases.","When deployed as a heuristic to schedule samples in a TAMP planner, we also observe planning time improvements in planar problems.","While our experiments show much work remains to tighten our bounds, the ideas presented in this paper are a step towards a practical sample bound."],"url":"http://arxiv.org/abs/2407.17394v1"}
{"created":"2024-07-24 16:14:43","title":"Sampling-Based Hierarchical Trajectory Planning for Formation Flight","abstract":"Formation flight of unmanned aerial vehicles (UAVs) poses significant challenges in terms of safety and formation keeping, particularly in cluttered environments. However, existing methods often struggle to simultaneously satisfy these two critical requirements. To address this issue, this paper proposes a sampling-based trajectory planning method with a hierarchical structure for formation flight in dense obstacle environments. To ensure reliable local sensing information sharing among UAVs, each UAV generates a safe flight corridor (SFC), which is transmitted to the leader UAV. Subsequently, a sampling-based formation guidance path generation method is designed as the front-end strategy, steering the formation to fly in the desired shape safely with the formation connectivity provided by the SFCs. Furthermore, a model predictive path integral (MPPI) based distributed trajectory optimization method is developed as the back-end part, which ensures the smoothness, safety and dynamics feasibility of the executable trajectory. To validate the efficiency of the developed algorithm, comprehensive simulation comparisons are conducted. The supplementary simulation video can be seen at https://www.youtube.com/watch?v=xSxbUN0tn1M.","sentences":["Formation flight of unmanned aerial vehicles (UAVs) poses significant challenges in terms of safety and formation keeping, particularly in cluttered environments.","However, existing methods often struggle to simultaneously satisfy these two critical requirements.","To address this issue, this paper proposes a sampling-based trajectory planning method with a hierarchical structure for formation flight in dense obstacle environments.","To ensure reliable local sensing information sharing among UAVs, each UAV generates a safe flight corridor (SFC), which is transmitted to the leader UAV.","Subsequently, a sampling-based formation guidance path generation method is designed as the front-end strategy, steering the formation to fly in the desired shape safely with the formation connectivity provided by the SFCs.","Furthermore, a model predictive path integral (MPPI) based distributed trajectory optimization method is developed as the back-end part, which ensures the smoothness, safety and dynamics feasibility of the executable trajectory.","To validate the efficiency of the developed algorithm, comprehensive simulation comparisons are conducted.","The supplementary simulation video can be seen at https://www.youtube.com/watch?v=xSxbUN0tn1M."],"url":"http://arxiv.org/abs/2407.17392v1"}
{"created":"2024-07-24 16:14:38","title":"Tutorial: Object as a Service (OaaS) Serverless Cloud Computing Paradigm","abstract":"While the first generation of cloud computing systems mitigated the job of system administrators, the next generation of cloud computing systems is emerging to mitigate the burden for cloud developers -- facilitating the development of cloud-native applications. This paradigm shift is primarily happening by offering higher-level serverless abstractions, such as Function as a Service (FaaS). Although FaaS has successfully abstracted developers from the cloud resource management details, it falls short in abstracting the management of both data (i.e., state) and the non-functional aspects, such as Quality of Service (QoS) requirements. The lack of such abstractions implies developer intervention and is counterproductive to the objective of mitigating the burden of cloud-native application development. To further streamline cloud-native application development, we present Object-as-a-Service (OaaS) -- a serverless paradigm that borrows the object-oriented programming concepts to encapsulate application logic and data in addition to non-functional requirements into a single deployment package, thereby streamlining provider-agnostic cloud-native application development. We realized the OaaS paradigm through the development of an open-source platform called Oparaca. In this tutorial, we will present the concept and design of the OaaS paradigm and its implementation -- the Oparaca platform. Then, we give a tutorial on developing and deploying the application on the Oparaca platform and discuss its benefits and its optimal configurations to avoid potential overheads.","sentences":["While the first generation of cloud computing systems mitigated the job of system administrators, the next generation of cloud computing systems is emerging to mitigate the burden for cloud developers -- facilitating the development of cloud-native applications.","This paradigm shift is primarily happening by offering higher-level serverless abstractions, such as Function as a Service (FaaS).","Although FaaS has successfully abstracted developers from the cloud resource management details, it falls short in abstracting the management of both data (i.e., state) and the non-functional aspects, such as Quality of Service (QoS) requirements.","The lack of such abstractions implies developer intervention and is counterproductive to the objective of mitigating the burden of cloud-native application development.","To further streamline cloud-native application development, we present Object-as-a-Service (OaaS) -- a serverless paradigm that borrows the object-oriented programming concepts to encapsulate application logic and data in addition to non-functional requirements into a single deployment package, thereby streamlining provider-agnostic cloud-native application development.","We realized the OaaS paradigm through the development of an open-source platform called Oparaca.","In this tutorial, we will present the concept and design of the OaaS paradigm and its implementation -- the Oparaca platform.","Then, we give a tutorial on developing and deploying the application on the Oparaca platform and discuss its benefits and its optimal configurations to avoid potential overheads."],"url":"http://arxiv.org/abs/2407.17391v1"}
{"created":"2024-07-24 16:14:15","title":"CovScore: Evaluation of Multi-Document Abstractive Title Set Generation","abstract":"This paper introduces CovScore, an automatic reference-less methodology for evaluating thematic title sets, extracted from a corpus of documents. While such extraction methods are widely used, evaluating their effectiveness remains an open question. Moreover, some existing practices heavily rely on slow and laborious human annotation procedures. Inspired by recently introduced LLM-based judge methods, we propose a novel methodology that decomposes quality into five main metrics along different aspects of evaluation. This framing simplifies and expedites the manual evaluation process and enables automatic and independent LLM-based evaluation. As a test case, we apply our approach to a corpus of Holocaust survivor testimonies, motivated both by its relevance to title set extraction and by the moral significance of this pursuit. We validate the methodology by experimenting with naturalistic and synthetic title set generation systems and compare their performance with the methodology.","sentences":["This paper introduces CovScore, an automatic reference-less methodology for evaluating thematic title sets, extracted from a corpus of documents.","While such extraction methods are widely used, evaluating their effectiveness remains an open question.","Moreover, some existing practices heavily rely on slow and laborious human annotation procedures.","Inspired by recently introduced LLM-based judge methods, we propose a novel methodology that decomposes quality into five main metrics along different aspects of evaluation.","This framing simplifies and expedites the manual evaluation process and enables automatic and independent LLM-based evaluation.","As a test case, we apply our approach to a corpus of Holocaust survivor testimonies, motivated both by its relevance to title set extraction and by the moral significance of this pursuit.","We validate the methodology by experimenting with naturalistic and synthetic title set generation systems and compare their performance with the methodology."],"url":"http://arxiv.org/abs/2407.17390v1"}
{"created":"2024-07-24 16:11:39","title":"PERSONA: A Reproducible Testbed for Pluralistic Alignment","abstract":"The rapid advancement of language models (LMs) necessitates robust alignment with diverse user values. However, current preference optimization approaches often fail to capture the plurality of user opinions, instead reinforcing majority viewpoints and marginalizing minority perspectives. We introduce PERSONA, a reproducible test bed designed to evaluate and improve pluralistic alignment of LMs. We procedurally generate diverse user profiles from US census data, resulting in 1,586 synthetic personas with varied demographic and idiosyncratic attributes. We then generate a large-scale evaluation dataset containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic personas. Leveraging this dataset, we systematically evaluate LM capabilities in role-playing diverse users, verified through human judges, and the establishment of both a benchmark, PERSONA Bench, for pluralistic alignment approaches as well as an extensive dataset to create new and future benchmarks. The full dataset and benchmarks are available here: https://www.synthlabs.ai/research/persona.","sentences":["The rapid advancement of language models (LMs) necessitates robust alignment with diverse user values.","However, current preference optimization approaches often fail to capture the plurality of user opinions, instead reinforcing majority viewpoints and marginalizing minority perspectives.","We introduce PERSONA, a reproducible test bed designed to evaluate and improve pluralistic alignment of LMs.","We procedurally generate diverse user profiles from US census data, resulting in 1,586 synthetic personas with varied demographic and idiosyncratic attributes.","We then generate a large-scale evaluation dataset containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic personas.","Leveraging this dataset, we systematically evaluate LM capabilities in role-playing diverse users, verified through human judges, and the establishment of both a benchmark, PERSONA Bench, for pluralistic alignment approaches as well as an extensive dataset to create new and future benchmarks.","The full dataset and benchmarks are available here: https://www.synthlabs.ai/research/persona."],"url":"http://arxiv.org/abs/2407.17387v1"}
{"created":"2024-07-24 16:07:11","title":"A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance","abstract":"Writing, as an omnipresent form of human communication, permeates nearly every aspect of contemporary life. Consequently, inaccuracies or errors in written communication can lead to profound consequences, ranging from financial losses to potentially life-threatening situations. Spelling mistakes, among the most prevalent writing errors, are frequently encountered due to various factors. This research aims to identify and rectify diverse spelling errors in text using neural networks, specifically leveraging the Bidirectional Encoder Representations from Transformers (BERT) masked language model. To achieve this goal, we compiled a comprehensive dataset encompassing both non-real-word and real-word errors after categorizing different types of spelling mistakes. Subsequently, multiple pre-trained BERT models were employed. To ensure optimal performance in correcting misspelling errors, we propose a combined approach utilizing the BERT masked language model and Levenshtein distance. The results from our evaluation data demonstrate that the system presented herein exhibits remarkable capabilities in identifying and rectifying spelling mistakes, often surpassing existing systems tailored for the Persian language.","sentences":["Writing, as an omnipresent form of human communication, permeates nearly every aspect of contemporary life.","Consequently, inaccuracies or errors in written communication can lead to profound consequences, ranging from financial losses to potentially life-threatening situations.","Spelling mistakes, among the most prevalent writing errors, are frequently encountered due to various factors.","This research aims to identify and rectify diverse spelling errors in text using neural networks, specifically leveraging the Bidirectional Encoder Representations from Transformers (BERT) masked language model.","To achieve this goal, we compiled a comprehensive dataset encompassing both non-real-word and real-word errors after categorizing different types of spelling mistakes.","Subsequently, multiple pre-trained BERT models were employed.","To ensure optimal performance in correcting misspelling errors, we propose a combined approach utilizing the BERT masked language model and Levenshtein distance.","The results from our evaluation data demonstrate that the system presented herein exhibits remarkable capabilities in identifying and rectifying spelling mistakes, often surpassing existing systems tailored for the Persian language."],"url":"http://arxiv.org/abs/2407.17383v1"}
{"created":"2024-07-24 15:59:01","title":"MMRA: A Benchmark for Multi-granularity Multi-image Relational Association","abstract":"Given the remarkable success that large visual language models (LVLMs) have achieved in image perception tasks, the endeavor to make LVMLs perceive the world like humans is drawing increasing attention. Current multi-modal benchmarks mainly focus on the objective fact or certain topic related potential knowledge within a image, but overlook the associative relations between multiple images. Therefore, we define a multi-image relation association task, and meticulously curate \\textbf{MMRA} benchmark, a \\textbf{M}ulti-granularity \\textbf{M}ulti-image \\textbf{R}elational \\textbf{A}ssociation benchmark, consisted of \\textbf{1026} samples. In order to systematically and comprehensively evaluate mainstream LVLMs, we establish an associational relation system among images that contain \\textbf{11 subtasks} (e.g, UsageSimilarity, SubEvent, etc.) at two granularity levels (i.e., \"\\textbf{image}\" and \"\\textbf{entity}\") according to the relations in ConceptNet. Our experiments demonstrate that, on our MMRA benchmark, current mainstream LVLMs all have their own advantages and disadvantages across different subtasks. It is worth noting that, at the entity level, the performance of all models is worse than that of them at the image level, indicating that the fine-grained multi-image perception task is still challenging for LVLMs. The tasks related to spatial perception are relatively difficult for LVLMs to handle. Furthermore, we find that LVMLs exhibit a good ability to perceive image details, and the key to enhancing their multi-image association capability is to strengthen the reasoning ability of their language model component. All our codes and data are released at htt\\url{https://github.com/Wusiwei0410/MMRA}.","sentences":["Given the remarkable success that large visual language models (LVLMs) have achieved in image perception tasks, the endeavor to make LVMLs perceive the world like humans is drawing increasing attention.","Current multi-modal benchmarks mainly focus on the objective fact or certain topic related potential knowledge within a image, but overlook the associative relations between multiple images.","Therefore, we define a multi-image relation association task, and meticulously curate \\textbf{MMRA} benchmark, a \\textbf{M}ulti-granularity \\textbf{M}ulti-image \\textbf{R}elational \\textbf{A}ssociation benchmark, consisted of \\textbf{1026} samples.","In order to systematically and comprehensively evaluate mainstream LVLMs, we establish an associational relation system among images that contain \\textbf{11 subtasks} (e.g, UsageSimilarity, SubEvent, etc.)","at two granularity levels (i.e., \"\\textbf{image}\" and \"\\textbf{entity}\") according to the relations in ConceptNet.","Our experiments demonstrate that, on our MMRA benchmark, current mainstream LVLMs all have their own advantages and disadvantages across different subtasks.","It is worth noting that, at the entity level, the performance of all models is worse than that of them at the image level, indicating that the fine-grained multi-image perception task is still challenging for LVLMs.","The tasks related to spatial perception are relatively difficult for LVLMs to handle.","Furthermore, we find that LVMLs exhibit a good ability to perceive image details, and the key to enhancing their multi-image association capability is to strengthen the reasoning ability of their language model component.","All our codes and data are released at htt\\url{https://github.com/Wusiwei0410/MMRA}."],"url":"http://arxiv.org/abs/2407.17379v1"}
{"created":"2024-07-24 15:58:24","title":"PrevPredMap: Exploring Temporal Modeling with Previous Predictions for Online Vectorized HD Map Construction","abstract":"Temporal information is crucial for detecting occluded instances. Existing temporal representations have progressed from BEV or PV features to more compact query features. Compared to these aforementioned features, predictions offer the highest level of abstraction, providing explicit information. In the context of online vectorized HD map construction, this unique characteristic of predictions is potentially advantageous for long-term temporal modeling and the integration of map priors. This paper introduces PrevPredMap, a pioneering temporal modeling framework that leverages previous predictions for constructing online vectorized HD maps. We have meticulously crafted two essential modules for PrevPredMap: the previous-predictions-based query generator and the dynamic-position-query decoder. Specifically, the previous-predictions-based query generator is designed to separately encode different types of information from previous predictions, which are then effectively utilized by the dynamic-position-query decoder to generate current predictions. Furthermore, we have developed a dual-mode strategy to ensure PrevPredMap's robust performance across both single-frame and temporal modes. Extensive experiments demonstrate that PrevPredMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets. Code will be available at https://github.com/pnnnnnnn/PrevPredMap.","sentences":["Temporal information is crucial for detecting occluded instances.","Existing temporal representations have progressed from BEV or PV features to more compact query features.","Compared to these aforementioned features, predictions offer the highest level of abstraction, providing explicit information.","In the context of online vectorized HD map construction, this unique characteristic of predictions is potentially advantageous for long-term temporal modeling and the integration of map priors.","This paper introduces PrevPredMap, a pioneering temporal modeling framework that leverages previous predictions for constructing online vectorized HD maps.","We have meticulously crafted two essential modules for PrevPredMap: the previous-predictions-based query generator and the dynamic-position-query decoder.","Specifically, the previous-predictions-based query generator is designed to separately encode different types of information from previous predictions, which are then effectively utilized by the dynamic-position-query decoder to generate current predictions.","Furthermore, we have developed a dual-mode strategy to ensure PrevPredMap's robust performance across both single-frame and temporal modes.","Extensive experiments demonstrate that PrevPredMap achieves state-of-the-art performance on the nuScenes and Argoverse2 datasets.","Code will be available at https://github.com/pnnnnnnn/PrevPredMap."],"url":"http://arxiv.org/abs/2407.17378v1"}
{"created":"2024-07-24 15:57:55","title":"Entropy Reweighted Conformal Classification","abstract":"Conformal Prediction (CP) is a powerful framework for constructing prediction sets with guaranteed coverage. However, recent studies have shown that integrating confidence calibration with CP can lead to a degradation in efficiency. In this paper, We propose an adaptive approach that considers the classifier's uncertainty and employs entropy-based reweighting to enhance the efficiency of prediction sets for conformal classification. Our experimental results demonstrate that this method significantly improves efficiency.","sentences":["Conformal Prediction (CP) is a powerful framework for constructing prediction sets with guaranteed coverage.","However, recent studies have shown that integrating confidence calibration with CP can lead to a degradation in efficiency.","In this paper, We propose an adaptive approach that considers the classifier's uncertainty and employs entropy-based reweighting to enhance the efficiency of prediction sets for conformal classification.","Our experimental results demonstrate that this method significantly improves efficiency."],"url":"http://arxiv.org/abs/2407.17377v1"}
{"created":"2024-07-24 15:53:04","title":"Co-designing an AI Impact Assessment Report Template with AI Practitioners and AI Compliance Experts","abstract":"In the evolving landscape of AI regulation, it is crucial for companies to conduct impact assessments and document their compliance through comprehensive reports. However, current reports lack grounding in regulations and often focus on specific aspects like privacy in relation to AI systems, without addressing the real-world uses of these systems. Moreover, there is no systematic effort to design and evaluate these reports with both AI practitioners and AI compliance experts. To address this gap, we conducted an iterative co-design process with 14 AI practitioners and 6 AI compliance experts and proposed a template for impact assessment reports grounded in the EU AI Act, NIST's AI Risk Management Framework, and ISO 42001 AI Management System. We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company. A user study with 8 AI practitioners from the same company and 5 AI compliance experts from industry and academia revealed that our template effectively provides necessary information for impact assessments and documents the broad impacts of AI systems. Participants envisioned using the template not only at the pre-deployment stage for compliance but also as a tool to guide the design stage of AI uses.","sentences":["In the evolving landscape of AI regulation, it is crucial for companies to conduct impact assessments and document their compliance through comprehensive reports.","However, current reports lack grounding in regulations and often focus on specific aspects like privacy in relation to AI systems, without addressing the real-world uses of these systems.","Moreover, there is no systematic effort to design and evaluate these reports with both AI practitioners and AI compliance experts.","To address this gap, we conducted an iterative co-design process with 14 AI practitioners and 6 AI compliance experts and proposed a template for impact assessment reports grounded in the EU AI Act, NIST's AI Risk Management Framework, and ISO 42001 AI Management System.","We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company.","A user study with 8 AI practitioners from the same company and 5 AI compliance experts from industry and academia revealed that our template effectively provides necessary information for impact assessments and documents the broad impacts of AI systems.","Participants envisioned using the template not only at the pre-deployment stage for compliance but also as a tool to guide the design stage of AI uses."],"url":"http://arxiv.org/abs/2407.17374v1"}
{"created":"2024-07-24 15:44:35","title":"De Bruijn Sequences with Minimum Discrepancy","abstract":"The discrepancy of a binary string is the maximum (absolute) difference between the number of ones and the number of zeroes over all possible substrings of the given binary string. In this note we determine the minimal discrepancy that a binary de Bruijn sequence of order $n$ can achieve, which is $n$. This was an open problem until now. We give an algorithm that constructs a binary de Bruijn sequence with minimal discrepancy. A slight modification of this algorithm deals with arbitrary alphabets and yields de Bruijn sequences of order $n$ with discrepancy at most $1$ above the trivial lower bound $n$.","sentences":["The discrepancy of a binary string is the maximum (absolute) difference between the number of ones and the number of zeroes over all possible substrings of the given binary string.","In this note we determine the minimal discrepancy that a binary de Bruijn sequence of order $n$ can achieve, which is $n$. This was an open problem until now.","We give an algorithm that constructs a binary de Bruijn sequence with minimal discrepancy.","A slight modification of this algorithm deals with arbitrary alphabets and yields de Bruijn sequences of order $n$ with discrepancy at most $1$ above the trivial lower bound $n$."],"url":"http://arxiv.org/abs/2407.17367v1"}
{"created":"2024-07-24 15:42:34","title":"ViPer: Visual Personalization of Generative Models via Individual Preference Learning","abstract":"Different users find different images generated for the same prompt desirable. This gives rise to personalized image generation which involves creating images aligned with an individual's visual preference. Current generative models are, however, unpersonalized, as they are tuned to produce outputs that appeal to a broad audience. Using them to generate images aligned with individual users relies on iterative manual prompt engineering by the user which is inefficient and undesirable. We propose to personalize the image generation process by first capturing the generic preferences of the user in a one-time process by inviting them to comment on a small selection of images, explaining why they like or dislike each. Based on these comments, we infer a user's structured liked and disliked visual attributes, i.e., their visual preference, using a large language model. These attributes are used to guide a text-to-image model toward producing images that are tuned towards the individual user's visual preference. Through a series of user studies and large language model guided evaluations, we demonstrate that the proposed method results in generations that are well aligned with individual users' visual preferences.","sentences":["Different users find different images generated for the same prompt desirable.","This gives rise to personalized image generation which involves creating images aligned with an individual's visual preference.","Current generative models are, however, unpersonalized, as they are tuned to produce outputs that appeal to a broad audience.","Using them to generate images aligned with individual users relies on iterative manual prompt engineering by the user which is inefficient and undesirable.","We propose to personalize the image generation process by first capturing the generic preferences of the user in a one-time process by inviting them to comment on a small selection of images, explaining why they like or dislike each.","Based on these comments, we infer a user's structured liked and disliked visual attributes, i.e., their visual preference, using a large language model.","These attributes are used to guide a text-to-image model toward producing images that are tuned towards the individual user's visual preference.","Through a series of user studies and large language model guided evaluations, we demonstrate that the proposed method results in generations that are well aligned with individual users' visual preferences."],"url":"http://arxiv.org/abs/2407.17365v1"}
{"created":"2024-07-24 15:41:15","title":"Reliability on QR codes and Reed-Solomon codes","abstract":"This study addresses the use of Reed-Solomon error correction codes in QR codes to enhance resilience against failures. To fully grasp this approach, a basic cryptographic context is provided, necessary for understanding Reed-Solomon codes. The study begins by defining a code and explores key outcomes for codes with additional properties, such as linearity. The theoretical framework is further developed with specific definitions and examples of Reed-Solomon codes, presented as a particular variant of BCH codes. Additionally, the structure of QR codes is analyzed, encompassing different versions and how data is represented in the form of black and white pixels within an image. Finally, an inherent vulnerability of Reed-Solomon Codes, and particularly of QR codes, related to selective manipulation of modules is examined. This vulnerability leverages the error correction mechanisms present in Reed-Solomon codes.","sentences":["This study addresses the use of Reed-Solomon error correction codes in QR codes to enhance resilience against failures.","To fully grasp this approach, a basic cryptographic context is provided, necessary for understanding Reed-Solomon codes.","The study begins by defining a code and explores key outcomes for codes with additional properties, such as linearity.","The theoretical framework is further developed with specific definitions and examples of Reed-Solomon codes, presented as a particular variant of BCH codes.","Additionally, the structure of QR codes is analyzed, encompassing different versions and how data is represented in the form of black and white pixels within an image.","Finally, an inherent vulnerability of Reed-Solomon Codes, and particularly of QR codes, related to selective manipulation of modules is examined.","This vulnerability leverages the error correction mechanisms present in Reed-Solomon codes."],"url":"http://arxiv.org/abs/2407.17364v1"}
{"created":"2024-07-24 15:38:20","title":"MuST: Multi-Scale Transformers for Surgical Phase Recognition","abstract":"Phase recognition in surgical videos is crucial for enhancing computer-aided surgical systems as it enables automated understanding of sequential procedural stages. Existing methods often rely on fixed temporal windows for video analysis to identify dynamic surgical phases. Thus, they struggle to simultaneously capture short-, mid-, and long-term information necessary to fully understand complex surgical procedures. To address these issues, we propose Multi-Scale Transformers for Surgical Phase Recognition (MuST), a novel Transformer-based approach that combines a Multi-Term Frame encoder with a Temporal Consistency Module to capture information across multiple temporal scales of a surgical video. Our Multi-Term Frame Encoder computes interdependencies across a hierarchy of temporal scales by sampling sequences at increasing strides around the frame of interest. Furthermore, we employ a long-term Transformer encoder over the frame embeddings to further enhance long-term reasoning. MuST achieves higher performance than previous state-of-the-art methods on three different public benchmarks.","sentences":["Phase recognition in surgical videos is crucial for enhancing computer-aided surgical systems as it enables automated understanding of sequential procedural stages.","Existing methods often rely on fixed temporal windows for video analysis to identify dynamic surgical phases.","Thus, they struggle to simultaneously capture short-, mid-, and long-term information necessary to fully understand complex surgical procedures.","To address these issues, we propose Multi-Scale Transformers for Surgical Phase Recognition (MuST), a novel Transformer-based approach that combines a Multi-Term Frame encoder with a Temporal Consistency Module to capture information across multiple temporal scales of a surgical video.","Our Multi-Term Frame Encoder computes interdependencies across a hierarchy of temporal scales by sampling sequences at increasing strides around the frame of interest.","Furthermore, we employ a long-term Transformer encoder over the frame embeddings to further enhance long-term reasoning.","MuST achieves higher performance than previous state-of-the-art methods on three different public benchmarks."],"url":"http://arxiv.org/abs/2407.17361v1"}
{"created":"2024-07-24 15:30:12","title":"Quantile Learn-Then-Test: Quantile-Based Risk Control for Hyperparameter Optimization","abstract":"The increasing adoption of Artificial Intelligence (AI) in engineering problems calls for the development of calibration methods capable of offering robust statistical reliability guarantees. The calibration of black box AI models is carried out via the optimization of hyperparameters dictating architecture, optimization, and/or inference configuration. Prior work has introduced learn-then-test (LTT), a calibration procedure for hyperparameter optimization (HPO) that provides statistical guarantees on average performance measures. Recognizing the importance of controlling risk-aware objectives in engineering contexts, this work introduces a variant of LTT that is designed to provide statistical guarantees on quantiles of a risk measure. We illustrate the practical advantages of this approach by applying the proposed algorithm to a radio access scheduling problem.","sentences":["The increasing adoption of Artificial Intelligence (AI) in engineering problems calls for the development of calibration methods capable of offering robust statistical reliability guarantees.","The calibration of black box AI models is carried out via the optimization of hyperparameters dictating architecture, optimization, and/or inference configuration.","Prior work has introduced learn-then-test (LTT), a calibration procedure for hyperparameter optimization (HPO) that provides statistical guarantees on average performance measures.","Recognizing the importance of controlling risk-aware objectives in engineering contexts, this work introduces a variant of LTT that is designed to provide statistical guarantees on quantiles of a risk measure.","We illustrate the practical advantages of this approach by applying the proposed algorithm to a radio access scheduling problem."],"url":"http://arxiv.org/abs/2407.17358v1"}
{"created":"2024-07-24 15:28:08","title":"Gradient-based inference of abstract task representations for generalization in neural networks","abstract":"Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals. The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction). Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity. We investigate if such benefits might extend to neural networks trained with task abstractions. For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition). To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework. We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI). Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations. Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting. Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples.","sentences":["Humans and many animals show remarkably adaptive behavior and can respond differently to the same input depending on their internal goals.","The brain not only represents the intermediate abstractions needed to perform a computation but also actively maintains a representation of the computation itself (task abstraction).","Such separation of the computation and its abstraction is associated with faster learning, flexible decision-making, and broad generalization capacity.","We investigate if such benefits might extend to neural networks trained with task abstractions.","For such benefits to emerge, one needs a task inference mechanism that possesses two crucial abilities: First, the ability to infer abstract task representations when no longer explicitly provided (task inference), and second, manipulate task representations to adapt to novel problems (task recomposition).","To tackle this, we cast task inference as an optimization problem from a variational inference perspective and ground our approach in an expectation-maximization framework.","We show that gradients backpropagated through a neural network to a task representation layer are an efficient heuristic to infer current task demands, a process we refer to as gradient-based inference (GBI).","Further iterative optimization of the task representation layer allows for recomposing abstractions to adapt to novel situations.","Using a toy example, a novel image classifier, and a language model, we demonstrate that GBI provides higher learning efficiency and generalization to novel tasks and limits forgetting.","Moreover, we show that GBI has unique advantages such as preserving information for uncertainty estimation and detecting out-of-distribution samples."],"url":"http://arxiv.org/abs/2407.17356v1"}
{"created":"2024-07-24 15:27:21","title":"Deep Spherical Superpixels","abstract":"Over the years, the use of superpixel segmentation has become very popular in various applications, serving as a preprocessing step to reduce data size by adapting to the content of the image, regardless of its semantic content. While the superpixel segmentation of standard planar images, captured with a 90{\\deg} field of view, has been extensively studied, there has been limited focus on dedicated methods to omnidirectional or spherical images, captured with a 360{\\deg} field of view. In this study, we introduce the first deep learning-based superpixel segmentation approach tailored for omnidirectional images called DSS (for Deep Spherical Superpixels). Our methodology leverages on spherical CNN architectures and the differentiable K-means clustering paradigm for superpixels, to generate superpixels that follow the spherical geometry. Additionally, we propose to use data augmentation techniques specifically designed for 360{\\deg} images, enabling our model to efficiently learn from a limited set of annotated omnidirectional data. Our extensive validation across two datasets demonstrates that taking into account the inherent circular geometry of such images into our framework improves the segmentation performance over traditional and deep learning-based superpixel methods. Our code is available online.","sentences":["Over the years, the use of superpixel segmentation has become very popular in various applications, serving as a preprocessing step to reduce data size by adapting to the content of the image, regardless of its semantic content.","While the superpixel segmentation of standard planar images, captured with a 90{\\deg} field of view, has been extensively studied, there has been limited focus on dedicated methods to omnidirectional or spherical images, captured with a 360{\\deg} field of view.","In this study, we introduce the first deep learning-based superpixel segmentation approach tailored for omnidirectional images called DSS (for Deep Spherical Superpixels).","Our methodology leverages on spherical CNN architectures and the differentiable K-means clustering paradigm for superpixels, to generate superpixels that follow the spherical geometry.","Additionally, we propose to use data augmentation techniques specifically designed for 360{\\deg} images, enabling our model to efficiently learn from a limited set of annotated omnidirectional data.","Our extensive validation across two datasets demonstrates that taking into account the inherent circular geometry of such images into our framework improves the segmentation performance over traditional and deep learning-based superpixel methods.","Our code is available online."],"url":"http://arxiv.org/abs/2407.17354v1"}
{"created":"2024-07-24 15:26:01","title":"Scalify: scale propagation for efficient low-precision LLM training","abstract":"Low-precision formats such as float8 have been introduced in machine learning accelerated hardware to improve computational efficiency for large language models training and inference. Nevertheless, adoption by the ML community has been slowed down by the complex, and sometimes brittle, techniques required to match higher precision training accuracy. In this work, we present Scalify, a end-to-end scale propagation paradigm for computational graphs, generalizing and formalizing existing tensor scaling methods. Experiment results show that Scalify supports out-of-the-box float8 matrix multiplication and gradients representation, as well as float16 optimizer state storage. Our JAX implementation of Scalify is open-sourced at https://github.com/graphcore-research/jax-scalify","sentences":["Low-precision formats such as float8 have been introduced in machine learning accelerated hardware to improve computational efficiency for large language models training and inference.","Nevertheless, adoption by the ML community has been slowed down by the complex, and sometimes brittle, techniques required to match higher precision training accuracy.","In this work, we present Scalify, a end-to-end scale propagation paradigm for computational graphs, generalizing and formalizing existing tensor scaling methods.","Experiment results show that Scalify supports out-of-the-box float8 matrix multiplication and gradients representation, as well as float16 optimizer state storage.","Our JAX implementation of Scalify is open-sourced at https://github.com/graphcore-research/jax-scalify"],"url":"http://arxiv.org/abs/2407.17353v1"}
{"created":"2024-07-24 15:18:17","title":"Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching","abstract":"With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (\\texttt{SocraticLLM}), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named \\texttt{SocraticMATH}, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of \\texttt{SocraticLLM} by comparing it with several strong generative models. The codes and datasets are available on \\url{https://github.com/ECNU-ICALK/SocraticMath}.","sentences":["With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success.","However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy.","In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (\\texttt{SocraticLLM}), which guides learners toward profound thinking with clarity and self-discovery via conversation.","We collect and release a high-quality mathematical teaching dataset, named \\texttt{SocraticMATH}, which provides Socratic-style conversations of problems with extra knowledge.","Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization.","Experimental results show the great advantages of \\texttt{SocraticLLM} by comparing it with several strong generative models.","The codes and datasets are available on \\url{https://github.com/ECNU-ICALK/SocraticMath}."],"url":"http://arxiv.org/abs/2407.17349v1"}
{"created":"2024-07-24 15:17:55","title":"DexGANGrasp: Dexterous Generative Adversarial Grasping Synthesis for Task-Oriented Manipulation","abstract":"We introduce DexGanGrasp, a dexterous grasping synthesis method that generates and evaluates grasps with single view in real time. DexGanGrasp comprises a Conditional Generative Adversarial Networks (cGANs)-based DexGenerator to generate dexterous grasps and a discriminator-like DexEvalautor to assess the stability of these grasps. Extensive simulation and real-world expriments showcases the effectiveness of our proposed method, outperforming the baseline FFHNet with an 18.57% higher success rate in real-world evaluation. We further extend DexGanGrasp to DexAfford-Prompt, an open-vocabulary affordance grounding pipeline for dexterous grasping leveraging Multimodal Large Language Models (MLLMs) and Vision Language Models (VLMs), to achieve task-oriented grasping with successful real-world deployments.","sentences":["We introduce DexGanGrasp, a dexterous grasping synthesis method that generates and evaluates grasps with single view in real time.","DexGanGrasp comprises a Conditional Generative Adversarial Networks (cGANs)-based DexGenerator to generate dexterous grasps and a discriminator-like DexEvalautor to assess the stability of these grasps.","Extensive simulation and real-world expriments showcases the effectiveness of our proposed method, outperforming the baseline FFHNet with an 18.57% higher success rate in real-world evaluation.","We further extend DexGanGrasp to DexAfford-Prompt, an open-vocabulary affordance grounding pipeline for dexterous grasping leveraging Multimodal Large Language Models (MLLMs) and Vision Language Models (VLMs), to achieve task-oriented grasping with successful real-world deployments."],"url":"http://arxiv.org/abs/2407.17348v1"}
{"created":"2024-07-24 15:14:48","title":"Insider Threats Mitigation: Role of Penetration Testing","abstract":"Conventional security solutions are insufficient to address the urgent cybersecurity challenge posed by insider attacks. While a great deal of research has been done in this area, our systematic literature analysis attempts to give readers a thorough grasp of penetration testing's role in reducing insider risks. We aim to arrange and integrate the body of knowledge on insider threat prevention by using a grounded theory approach for a thorough literature review. This analysis classifies and evaluates the approaches used in penetration testing today, including how well they uncover and mitigate insider threats and how well they work in tandem with other security procedures. Additionally, we look at how penetration testing is used in different industries, present case studies with real-world implementations, and discuss the obstacles and constraints that businesses must overcome. This study aims to improve the knowledge of penetration testing as a critical part of insider threat defense, helping to create more comprehensive and successful security policies.","sentences":["Conventional security solutions are insufficient to address the urgent cybersecurity challenge posed by insider attacks.","While a great deal of research has been done in this area, our systematic literature analysis attempts to give readers a thorough grasp of penetration testing's role in reducing insider risks.","We aim to arrange and integrate the body of knowledge on insider threat prevention by using a grounded theory approach for a thorough literature review.","This analysis classifies and evaluates the approaches used in penetration testing today, including how well they uncover and mitigate insider threats and how well they work in tandem with other security procedures.","Additionally, we look at how penetration testing is used in different industries, present case studies with real-world implementations, and discuss the obstacles and constraints that businesses must overcome.","This study aims to improve the knowledge of penetration testing as a critical part of insider threat defense, helping to create more comprehensive and successful security policies."],"url":"http://arxiv.org/abs/2407.17346v1"}
{"created":"2024-07-24 15:13:12","title":"Label Alignment and Reassignment with Generalist Large Language Model for Enhanced Cross-Domain Named Entity Recognition","abstract":"Named entity recognition on the in-domain supervised and few-shot settings have been extensively discussed in the NLP community and made significant progress. However, cross-domain NER, a more common task in practical scenarios, still poses a challenge for most NER methods. Previous research efforts in that area primarily focus on knowledge transfer such as correlate label information from source to target domains but few works pay attention to the problem of label conflict. In this study, we introduce a label alignment and reassignment approach, namely LAR, to address this issue for enhanced cross-domain named entity recognition, which includes two core procedures: label alignment between source and target domains and label reassignment for type inference. The process of label reassignment can significantly be enhanced by integrating with an advanced large-scale language model such as ChatGPT. We conduct an extensive range of experiments on NER datasets involving both supervised and zero-shot scenarios. Empirical experimental results demonstrate the validation of our method with remarkable performance under the supervised and zero-shot out-of-domain settings compared to SOTA methods.","sentences":["Named entity recognition on the in-domain supervised and few-shot settings have been extensively discussed in the NLP community and made significant progress.","However, cross-domain NER, a more common task in practical scenarios, still poses a challenge for most NER methods.","Previous research efforts in that area primarily focus on knowledge transfer such as correlate label information from source to target domains but few works pay attention to the problem of label conflict.","In this study, we introduce a label alignment and reassignment approach, namely LAR, to address this issue for enhanced cross-domain named entity recognition, which includes two core procedures: label alignment between source and target domains and label reassignment for type inference.","The process of label reassignment can significantly be enhanced by integrating with an advanced large-scale language model such as ChatGPT.","We conduct an extensive range of experiments on NER datasets involving both supervised and zero-shot scenarios.","Empirical experimental results demonstrate the validation of our method with remarkable performance under the supervised and zero-shot out-of-domain settings compared to SOTA methods."],"url":"http://arxiv.org/abs/2407.17344v1"}
{"created":"2024-07-24 15:04:00","title":"Preliminary study on artificial intelligence methods for cybersecurity threat detection in computer networks based on raw data packets","abstract":"Most of the intrusion detection methods in computer networks are based on traffic flow characteristics. However, this approach may not fully exploit the potential of deep learning algorithms to directly extract features and patterns from raw packets. Moreover, it impedes real-time monitoring due to the necessity of waiting for the processing pipeline to complete and introduces dependencies on additional software components.   In this paper, we investigate deep learning methodologies capable of detecting attacks in real-time directly from raw packet data within network traffic. We propose a novel approach where packets are stacked into windows and separately recognised, with a 2D image representation suitable for processing with computer vision models. Our investigation utilizes the CIC IDS-2017 dataset, which includes both benign traffic and prevalent real-world attacks, providing a comprehensive foundation for our research.","sentences":["Most of the intrusion detection methods in computer networks are based on traffic flow characteristics.","However, this approach may not fully exploit the potential of deep learning algorithms to directly extract features and patterns from raw packets.","Moreover, it impedes real-time monitoring due to the necessity of waiting for the processing pipeline to complete and introduces dependencies on additional software components.   ","In this paper, we investigate deep learning methodologies capable of detecting attacks in real-time directly from raw packet data within network traffic.","We propose a novel approach where packets are stacked into windows and separately recognised, with a 2D image representation suitable for processing with computer vision models.","Our investigation utilizes the CIC IDS-2017 dataset, which includes both benign traffic and prevalent real-world attacks, providing a comprehensive foundation for our research."],"url":"http://arxiv.org/abs/2407.17339v1"}
{"created":"2024-07-24 15:02:09","title":"Cascaded Light Propagation Volumes using Spherical Radial Basis Functions","abstract":"This paper introduces a contribution made to one of the newest methods for simulating indirect lighting in dynamic scenes , the cascaded light propagation volumes . Our contribution consists on using Spherical Radial Basis Functions instead of Spherical Harmonic, since the first achieves much better results when many coefficients are used. We explain how to integrate the Spherical Radial Basis Functions with the cascaded light propagation volumes, and evaluate our technique against the same implementation, but with Spherical harmonics.","sentences":["This paper introduces a contribution made to one of the newest methods for simulating indirect lighting in dynamic scenes , the cascaded light propagation volumes .","Our contribution consists on using Spherical Radial Basis Functions instead of Spherical Harmonic, since the first achieves much better results when many coefficients are used.","We explain how to integrate the Spherical Radial Basis Functions with the cascaded light propagation volumes, and evaluate our technique against the same implementation, but with Spherical harmonics."],"url":"http://arxiv.org/abs/2407.17336v1"}
{"created":"2024-07-24 14:55:37","title":"Global and Local Confidence Based Fraud Detection Graph Neural Network","abstract":"This paper presents the Global and Local Confidence Graph Neural Network (GLC-GNN), an innovative approach to graph-based anomaly detection that addresses the challenges of heterophily and camouflage in fraudulent activities. By introducing a prototype to encapsulate the global features of a graph and calculating a Global Confidence (GC) value for each node, GLC-GNN effectively distinguishes between benign and fraudulent nodes. The model leverages GC to generate attention values for message aggregation, enhancing its ability to capture both homophily and heterophily. Through extensive experiments on four open datasets, GLC-GNN demonstrates superior performance over state-of-the-art models in accuracy and convergence speed, while maintaining a compact model size and expedited training process. The integration of global and local confidence measures in GLC-GNN offers a robust solution for detecting anomalies in graphs, with significant implications for fraud detection across diverse domains.","sentences":["This paper presents the Global and Local Confidence Graph Neural Network (GLC-GNN), an innovative approach to graph-based anomaly detection that addresses the challenges of heterophily and camouflage in fraudulent activities.","By introducing a prototype to encapsulate the global features of a graph and calculating a Global Confidence (GC) value for each node, GLC-GNN effectively distinguishes between benign and fraudulent nodes.","The model leverages GC to generate attention values for message aggregation, enhancing its ability to capture both homophily and heterophily.","Through extensive experiments on four open datasets, GLC-GNN demonstrates superior performance over state-of-the-art models in accuracy and convergence speed, while maintaining a compact model size and expedited training process.","The integration of global and local confidence measures in GLC-GNN offers a robust solution for detecting anomalies in graphs, with significant implications for fraud detection across diverse domains."],"url":"http://arxiv.org/abs/2407.17333v1"}
{"created":"2024-07-24 14:54:49","title":"A Systematic Analytical Design Procedure for Distributed Amplifiers","abstract":"In this paper we present a simple while comprehensive analytical design procedure for distributed amplifiers. Distributed amplifiers are attractive for designers due to their wideband capability. When designing a distributed amplifier, the first question that comes to mind is how wide the bandwidth can be. This paper answers this question by using the self-matching and low-pass properties of a distributed amplifier. Self-matching property of a distributed power amplifier is an interesting point that distinguishes it from other types of power amplifiers that are usually based on input and output matching networks. Here the estimation of the bandwidth of a distributed amplifier structure is discussed. The equations that are used in this paper can bring good insight and they can assist designers. Furthermore, we have explained the frequency behavior of a tapered distributed amplifier analytically for the first time. In order to validate the approach presented here, we have used published designs including our previously published design as practical examples. The flowchart of the design procedure is also provided.","sentences":["In this paper we present a simple while comprehensive analytical design procedure for distributed amplifiers.","Distributed amplifiers are attractive for designers due to their wideband capability.","When designing a distributed amplifier, the first question that comes to mind is how wide the bandwidth can be.","This paper answers this question by using the self-matching and low-pass properties of a distributed amplifier.","Self-matching property of a distributed power amplifier is an interesting point that distinguishes it from other types of power amplifiers that are usually based on input and output matching networks.","Here the estimation of the bandwidth of a distributed amplifier structure is discussed.","The equations that are used in this paper can bring good insight and they can assist designers.","Furthermore, we have explained the frequency behavior of a tapered distributed amplifier analytically for the first time.","In order to validate the approach presented here, we have used published designs including our previously published design as practical examples.","The flowchart of the design procedure is also provided."],"url":"http://arxiv.org/abs/2407.17332v1"}
{"created":"2024-07-24 14:54:16","title":"Multi-label Cluster Discrimination for Visual Representation Learning","abstract":"Contrastive Language Image Pre-training (CLIP) has recently demonstrated success across various tasks due to superior feature representation empowered by image-text contrastive learning. However, the instance discrimination method used by CLIP can hardly encode the semantic structure of training data. To handle this limitation, cluster discrimination has been proposed through iterative cluster assignment and classification. Nevertheless, most cluster discrimination approaches only define a single pseudo-label for each image, neglecting multi-label signals in the image. In this paper, we propose a novel Multi-Label Cluster Discrimination method named MLCD to enhance representation learning. In the clustering step, we first cluster the large-scale LAION-400M dataset into one million centers based on off-the-shelf embedding features. Considering that natural images frequently contain multiple visual objects or attributes, we select the multiple closest centers as auxiliary class labels. In the discrimination step, we design a novel multi-label classification loss, which elegantly separates losses from positive classes and negative classes, and alleviates ambiguity on decision boundary. We validate the proposed multi-label cluster discrimination method with experiments on different scales of models and pre-training datasets. Experimental results show that our method achieves state-of-the-art performance on multiple downstream tasks including linear probe, zero-shot classification, and image-text retrieval.","sentences":["Contrastive Language Image Pre-training (CLIP) has recently demonstrated success across various tasks due to superior feature representation empowered by image-text contrastive learning.","However, the instance discrimination method used by CLIP can hardly encode the semantic structure of training data.","To handle this limitation, cluster discrimination has been proposed through iterative cluster assignment and classification.","Nevertheless, most cluster discrimination approaches only define a single pseudo-label for each image, neglecting multi-label signals in the image.","In this paper, we propose a novel Multi-Label Cluster Discrimination method named MLCD to enhance representation learning.","In the clustering step, we first cluster the large-scale LAION-400M dataset into one million centers based on off-the-shelf embedding features.","Considering that natural images frequently contain multiple visual objects or attributes, we select the multiple closest centers as auxiliary class labels.","In the discrimination step, we design a novel multi-label classification loss, which elegantly separates losses from positive classes and negative classes, and alleviates ambiguity on decision boundary.","We validate the proposed multi-label cluster discrimination method with experiments on different scales of models and pre-training datasets.","Experimental results show that our method achieves state-of-the-art performance on multiple downstream tasks including linear probe, zero-shot classification, and image-text retrieval."],"url":"http://arxiv.org/abs/2407.17331v1"}
{"created":"2024-07-24 14:52:18","title":"DarSwin-Unet: Distortion Aware Encoder-Decoder Architecture","abstract":"Wide-angle fisheye images are becoming increasingly common for perception tasks in applications such as robotics, security, and mobility (e.g. drones, avionics). However, current models often either ignore the distortions in wide-angle images or are not suitable to perform pixel-level tasks. In this paper, we present an encoder-decoder model based on a radial transformer architecture that adapts to distortions in wide-angle lenses by leveraging the physical characteristics defined by the radial distortion profile. In contrast to the original model, which only performs classification tasks, we introduce a U-Net architecture, DarSwin-Unet, designed for pixel level tasks. Furthermore, we propose a novel strategy that minimizes sparsity when sampling the image for creating its input tokens. Our approach enhances the model capability to handle pixel-level tasks in wide-angle fisheye images, making it more effective for real-world applications. Compared to other baselines, DarSwin-Unet achieves the best results across different datasets, with significant gains when trained on bounded levels of distortions (very low, low, medium, and high) and tested on all, including out-of-distribution distortions. We demonstrate its performance on depth estimation and show through extensive experiments that DarSwin-Unet can perform zero-shot adaptation to unseen distortions of different wide-angle lenses.","sentences":["Wide-angle fisheye images are becoming increasingly common for perception tasks in applications such as robotics, security, and mobility (e.g. drones, avionics).","However, current models often either ignore the distortions in wide-angle images or are not suitable to perform pixel-level tasks.","In this paper, we present an encoder-decoder model based on a radial transformer architecture that adapts to distortions in wide-angle lenses by leveraging the physical characteristics defined by the radial distortion profile.","In contrast to the original model, which only performs classification tasks, we introduce a U-Net architecture, DarSwin-Unet, designed for pixel level tasks.","Furthermore, we propose a novel strategy that minimizes sparsity when sampling the image for creating its input tokens.","Our approach enhances the model capability to handle pixel-level tasks in wide-angle fisheye images, making it more effective for real-world applications.","Compared to other baselines, DarSwin-Unet achieves the best results across different datasets, with significant gains when trained on bounded levels of distortions (very low, low, medium, and high) and tested on all, including out-of-distribution distortions.","We demonstrate its performance on depth estimation and show through extensive experiments that DarSwin-Unet can perform zero-shot adaptation to unseen distortions of different wide-angle lenses."],"url":"http://arxiv.org/abs/2407.17328v1"}
{"created":"2024-07-24 14:45:07","title":"Energy Efficiency Optimization in Integrated Satellite-Terrestrial UAV-Enabled Cell-Free Massive MIMO","abstract":"Integrating cell-free massive MIMO (CF-mMIMO) into satellite-unmanned aerial vehicle (UAV) networks offers an effective solution for enhancing connectivity. In this setup, UAVs serve as access points (APs) of a terrestrial CF-mMIMO network extending the satellite network capabilities, thereby ensuring robust, high-quality communication links. In this work, we propose a successive convex approximation algorithm for maximizing the downlink energy efficiency (EE) at the UAVs under per-UAV power budget and user quality-of-service constraints. We derive a closed-form expression for the EE that accounts for maximum-ratio transmission and statistical channel knowledge at the users. Simulation results show the effectiveness of the proposed algorithm in maximizing the EE at the UAV layer. Moreover, we observe that a few tens of UAVs transmitting with a fine-tuned power are sufficient to empower the service of satellite networks and significantly increase the spectral efficiency.","sentences":["Integrating cell-free massive MIMO (CF-mMIMO) into satellite-unmanned aerial vehicle (UAV) networks offers an effective solution for enhancing connectivity.","In this setup, UAVs serve as access points (APs) of a terrestrial CF-mMIMO network extending the satellite network capabilities, thereby ensuring robust, high-quality communication links.","In this work, we propose a successive convex approximation algorithm for maximizing the downlink energy efficiency (EE) at the UAVs under per-UAV power budget and user quality-of-service constraints.","We derive a closed-form expression for the EE that accounts for maximum-ratio transmission and statistical channel knowledge at the users.","Simulation results show the effectiveness of the proposed algorithm in maximizing the EE at the UAV layer.","Moreover, we observe that a few tens of UAVs transmitting with a fine-tuned power are sufficient to empower the service of satellite networks and significantly increase the spectral efficiency."],"url":"http://arxiv.org/abs/2407.17321v1"}
{"created":"2024-07-24 14:41:27","title":"Exploring Commercial Vehicle Detouring Patterns through the Application of Probe Trajectory Data","abstract":"Understanding motorist detouring behavior is critical for both traffic operations and planning applications. However, measuring real-world detouring behavior is challenging due to the need to track the movement of individual vehicles. Recent developments in high-resolution vehicle trajectory data have enabled transportation professionals to observe real-world detouring behaviors without the need to install and maintain hardware such as license plate reading cameras. This paper investigates the feasibility of vehicle probe trajectory data to capture commercial motor vehicle (CMV) detouring behavior under three unique case studies. Before doing so, a validation analysis was conducted to investigate the ability of CMV probe trajectory data to represent overall CMV volumes at well-calibrated count stations near virtual weigh stations (VWS) in Maryland. The validation analysis showed strong positive correlations (above 0.75) at all VWS stations. Upon validating the data, a methodology was applied to assess CMV detour behaviors associated with CMV enforcement activities, congestion avoidance, and incident induced temporary road closures.","sentences":["Understanding motorist detouring behavior is critical for both traffic operations and planning applications.","However, measuring real-world detouring behavior is challenging due to the need to track the movement of individual vehicles.","Recent developments in high-resolution vehicle trajectory data have enabled transportation professionals to observe real-world detouring behaviors without the need to install and maintain hardware such as license plate reading cameras.","This paper investigates the feasibility of vehicle probe trajectory data to capture commercial motor vehicle (CMV) detouring behavior under three unique case studies.","Before doing so, a validation analysis was conducted to investigate the ability of CMV probe trajectory data to represent overall CMV volumes at well-calibrated count stations near virtual weigh stations (VWS) in Maryland.","The validation analysis showed strong positive correlations (above 0.75) at all VWS stations.","Upon validating the data, a methodology was applied to assess CMV detour behaviors associated with CMV enforcement activities, congestion avoidance, and incident induced temporary road closures."],"url":"http://arxiv.org/abs/2407.17319v1"}
{"created":"2024-07-24 14:39:24","title":"Lossy Data Compression By Adaptive Mesh Coarsening","abstract":"Today's scientific simulations, for example in the high-performance exascale sector, produce huge amounts of data. Due to limited I/O bandwidth and available storage space, there is the necessity to reduce scientific data of high performance computing applications. Error-bounded lossy compression has been proven to be an effective approach tackling the trade-off between accuracy and storage space. Within this work, we are exploring and discussing error-bounded lossy compression solely based on adaptive mesh refinement techniques. This compression technique is not only easily integrated into existing adaptive mesh refinement applications but also suits as a general lossy compression approach for arbitrary data in form of multi-dimensional arrays, irrespective of the data type. Moreover, these techniques permit the exclusion of regions of interest and even allows for nested error domains during the compression. The described data compression technique is presented exemplary on ERA5 data.","sentences":["Today's scientific simulations, for example in the high-performance exascale sector, produce huge amounts of data.","Due to limited I/O bandwidth and available storage space, there is the necessity to reduce scientific data of high performance computing applications.","Error-bounded lossy compression has been proven to be an effective approach tackling the trade-off between accuracy and storage space.","Within this work, we are exploring and discussing error-bounded lossy compression solely based on adaptive mesh refinement techniques.","This compression technique is not only easily integrated into existing adaptive mesh refinement applications but also suits as a general lossy compression approach for arbitrary data in form of multi-dimensional arrays, irrespective of the data type.","Moreover, these techniques permit the exclusion of regions of interest and even allows for nested error domains during the compression.","The described data compression technique is presented exemplary on ERA5 data."],"url":"http://arxiv.org/abs/2407.17316v1"}
{"created":"2024-07-24 14:38:03","title":"Edge-Cloud Continuum Orchestration of Critical Services: A Smart-City Approach","abstract":"Smart-city services are typically developed as closed systems within each city's vertical, communicating and interacting with cloud services while remaining isolated within each provider's domain. With the emergence of 5G private domains and the introduction of new M2M services focusing on autonomous systems, there is a shift from the cloud-based approach to a distributed edge computing paradigm, in a \\textit{continuum} orchestration. However, an essential component is missing. Current orchestration tools, designed for cloud-based deployments, lack robust workload isolation, fail to meet timing constraints, and are not tailored to the resource-constrained nature of edge devices. Therefore, new orchestration methods are needed to support MEC environments. The work presented in this paper addresses this gap. Based on the real needs of a smart-city testbed - the Aveiro Living Lab-, we developed a set of orchestration components to facilitate the seamless orchestration of both cloud and edge-based services, encompassing both critical and non-critical services. This work extends the current Kubernetes orchestration platform to include a novel location-specific resource definition, a custom scheduler to accommodate real-time and legacy services, continuous service monitoring to detect sub-optimal states, and a refined load balancing mechanism that prioritizes the fastest response times.","sentences":["Smart-city services are typically developed as closed systems within each city's vertical, communicating and interacting with cloud services while remaining isolated within each provider's domain.","With the emergence of 5G private domains and the introduction of new M2M services focusing on autonomous systems, there is a shift from the cloud-based approach to a distributed edge computing paradigm, in a \\textit{continuum} orchestration.","However, an essential component is missing.","Current orchestration tools, designed for cloud-based deployments, lack robust workload isolation, fail to meet timing constraints, and are not tailored to the resource-constrained nature of edge devices.","Therefore, new orchestration methods are needed to support MEC environments.","The work presented in this paper addresses this gap.","Based on the real needs of a smart-city testbed - the Aveiro Living Lab-, we developed a set of orchestration components to facilitate the seamless orchestration of both cloud and edge-based services, encompassing both critical and non-critical services.","This work extends the current Kubernetes orchestration platform to include a novel location-specific resource definition, a custom scheduler to accommodate real-time and legacy services, continuous service monitoring to detect sub-optimal states, and a refined load balancing mechanism that prioritizes the fastest response times."],"url":"http://arxiv.org/abs/2407.17314v1"}
{"created":"2024-07-24 14:29:05","title":"Physical Adversarial Attack on Monocular Depth Estimation via Shape-Varying Patches","abstract":"Adversarial attacks against monocular depth estimation (MDE) systems pose significant challenges, particularly in safety-critical applications such as autonomous driving. Existing patch-based adversarial attacks for MDE are confined to the vicinity of the patch, making it difficult to affect the entire target. To address this limitation, we propose a physics-based adversarial attack on monocular depth estimation, employing a framework called Attack with Shape-Varying Patches (ASP), aiming to optimize patch content, shape, and position to maximize effectiveness. We introduce various mask shapes, including quadrilateral, rectangular, and circular masks, to enhance the flexibility and efficiency of the attack. Furthermore, we propose a new loss function to extend the influence of the patch beyond the overlapping regions. Experimental results demonstrate that our attack method generates an average depth error of 18 meters on the target car with a patch area of 1/9, affecting over 98\\% of the target area.","sentences":["Adversarial attacks against monocular depth estimation (MDE) systems pose significant challenges, particularly in safety-critical applications such as autonomous driving.","Existing patch-based adversarial attacks for MDE are confined to the vicinity of the patch, making it difficult to affect the entire target.","To address this limitation, we propose a physics-based adversarial attack on monocular depth estimation, employing a framework called Attack with Shape-Varying Patches (ASP), aiming to optimize patch content, shape, and position to maximize effectiveness.","We introduce various mask shapes, including quadrilateral, rectangular, and circular masks, to enhance the flexibility and efficiency of the attack.","Furthermore, we propose a new loss function to extend the influence of the patch beyond the overlapping regions.","Experimental results demonstrate that our attack method generates an average depth error of 18 meters on the target car with a patch area of 1/9, affecting over 98\\% of the target area."],"url":"http://arxiv.org/abs/2407.17312v1"}
{"created":"2024-07-24 14:28:24","title":"The Magnificent Seven Challenges and Opportunities in Domain-Specific Accelerator Design for Autonomous Systems","abstract":"The end of Moore's Law and Dennard Scaling has combined with advances in agile hardware design to foster a golden age of domain-specific acceleration. However, this new frontier of computing opportunities is not without pitfalls. As computer architects approach unfamiliar domains, we have seen common themes emerge in the challenges that can hinder progress in the development of useful acceleration. In this work, we present the Magnificent Seven Challenges in domain-specific accelerator design that can guide adventurous architects to contribute meaningfully to novel application domains. Although these challenges appear across domains ranging from ML to genomics, we examine them through the lens of autonomous systems as a motivating example in this work. To that end, we identify opportunities for the path forward in a successful domain-specific accelerator design from these challenges.","sentences":["The end of Moore's Law and Dennard Scaling has combined with advances in agile hardware design to foster a golden age of domain-specific acceleration.","However, this new frontier of computing opportunities is not without pitfalls.","As computer architects approach unfamiliar domains, we have seen common themes emerge in the challenges that can hinder progress in the development of useful acceleration.","In this work, we present the Magnificent Seven Challenges in domain-specific accelerator design that can guide adventurous architects to contribute meaningfully to novel application domains.","Although these challenges appear across domains ranging from ML to genomics, we examine them through the lens of autonomous systems as a motivating example in this work.","To that end, we identify opportunities for the path forward in a successful domain-specific accelerator design from these challenges."],"url":"http://arxiv.org/abs/2407.17311v1"}
{"created":"2024-07-24 14:22:55","title":"LangOcc: Self-Supervised Open Vocabulary Occupancy Estimation via Volume Rendering","abstract":"Semantic occupancy has recently gained significant traction as a prominent method for 3D scene representation. However, most existing camera-based methods rely on costly datasets with fine-grained 3D voxel labels or LiDAR scans for training, which limits their practicality and scalability, raising the need for self-supervised approaches in this domain. Moreover, most methods are tied to a predefined set of classes which they can detect. In this work we present a novel approach for open vocabulary occupancy estimation called \\textit{LangOcc}, that is trained only via camera images, and can detect arbitrary semantics via vision-language alignment. In particular, we distill the knowledge of the strong vision-language aligned encoder CLIP into a 3D occupancy model via differentiable volume rendering. Our model estimates vision-language aligned features in a 3D voxel grid using only images. It is trained in a self-supervised manner by rendering our estimations back to 2D space, where ground-truth features can be computed. This training mechanism automatically supervises the scene geometry, allowing for a straight-forward and powerful training method without any explicit geometry supervision. LangOcc outperforms LiDAR-supervised competitors in open vocabulary occupancy by a large margin, solely relying on vision-based training. We also achieve state-of-the-art results in self-supervised semantic occupancy estimation on the Occ3D-nuScenes dataset, despite not being limited to a specific set of categories, thus demonstrating the effectiveness of our proposed vision-language training.","sentences":["Semantic occupancy has recently gained significant traction as a prominent method for 3D scene representation.","However, most existing camera-based methods rely on costly datasets with fine-grained 3D voxel labels or LiDAR scans for training, which limits their practicality and scalability, raising the need for self-supervised approaches in this domain.","Moreover, most methods are tied to a predefined set of classes which they can detect.","In this work we present a novel approach for open vocabulary occupancy estimation called \\textit{LangOcc}, that is trained only via camera images, and can detect arbitrary semantics via vision-language alignment.","In particular, we distill the knowledge of the strong vision-language aligned encoder CLIP into a 3D occupancy model via differentiable volume rendering.","Our model estimates vision-language aligned features in a 3D voxel grid using only images.","It is trained in a self-supervised manner by rendering our estimations back to 2D space, where ground-truth features can be computed.","This training mechanism automatically supervises the scene geometry, allowing for a straight-forward and powerful training method without any explicit geometry supervision.","LangOcc outperforms LiDAR-supervised competitors in open vocabulary occupancy by a large margin, solely relying on vision-based training.","We also achieve state-of-the-art results in self-supervised semantic occupancy estimation on the Occ3D-nuScenes dataset, despite not being limited to a specific set of categories, thus demonstrating the effectiveness of our proposed vision-language training."],"url":"http://arxiv.org/abs/2407.17310v1"}
{"created":"2024-07-24 14:20:59","title":"Continual Learning in Bio-plausible Spiking Neural Networks with Hebbian and Spike Timing Dependent Plasticity: A Survey and Perspective","abstract":"Recently, the use bio-plausible learning techniques such as Hebbian and Spike-Timing-Dependent Plasticity (STDP) have drawn significant attention for the design of compute-efficient AI systems that can continuously learn on-line at the edge. A key differentiating factor regarding this emerging class of neuromorphic continual learning system lies in the fact that learning must be carried using a data stream received in its natural order, as opposed to conventional gradient-based offline training where a static training dataset is assumed available a priori and randomly shuffled to make the training set independent and identically distributed (i.i.d). In contrast, the emerging class of neuromorphic continual learning systems covered in this survey must learn to integrate new information on the fly in a non-i.i.d manner, which makes these systems subject to catastrophic forgetting. In order to build the next generation of neuromorphic AI systems that can continuously learn at the edge, a growing number of research groups are studying the use of bio-plausible Hebbian neural network architectures and Spiking Neural Networks (SNNs) equipped with STDP learning. However, since this research field is still emerging, there is a need for providing a holistic view of the different approaches proposed in literature so far. To this end, this survey covers a number of recent works in the field of neuromorphic continual learning; provides background theory to help interested researchers to quickly learn the key concepts; and discusses important future research questions in light of the different works covered in this paper. It is hoped that this survey will contribute towards future research in the field of neuromorphic continual learning.","sentences":["Recently, the use bio-plausible learning techniques such as Hebbian and Spike-Timing-Dependent Plasticity (STDP) have drawn significant attention for the design of compute-efficient AI systems that can continuously learn on-line at the edge.","A key differentiating factor regarding this emerging class of neuromorphic continual learning system lies in the fact that learning must be carried using a data stream received in its natural order, as opposed to conventional gradient-based offline training where a static training dataset is assumed available a priori and randomly shuffled to make the training set independent and identically distributed (i.i.d).","In contrast, the emerging class of neuromorphic continual learning systems covered in this survey must learn to integrate new information on the fly in a non-i.i.d manner, which makes these systems subject to catastrophic forgetting.","In order to build the next generation of neuromorphic AI systems that can continuously learn at the edge, a growing number of research groups are studying the use of bio-plausible Hebbian neural network architectures and Spiking Neural Networks (SNNs) equipped with STDP learning.","However, since this research field is still emerging, there is a need for providing a holistic view of the different approaches proposed in literature so far.","To this end, this survey covers a number of recent works in the field of neuromorphic continual learning; provides background theory to help interested researchers to quickly learn the key concepts; and discusses important future research questions in light of the different works covered in this paper.","It is hoped that this survey will contribute towards future research in the field of neuromorphic continual learning."],"url":"http://arxiv.org/abs/2407.17305v1"}
{"created":"2024-07-24 14:17:16","title":"MoveLight: Enhancing Traffic Signal Control through Movement-Centric Deep Reinforcement Learning","abstract":"This paper introduces MoveLight, a novel traffic signal control system that enhances urban traffic management through movement-centric deep reinforcement learning. By leveraging detailed real-time data and advanced machine learning techniques, MoveLight overcomes the limitations of traditional traffic signal control methods. It employs a lane-level control approach using the FRAP algorithm to achieve dynamic and adaptive traffic signal control, optimizing traffic flow, reducing congestion, and improving overall efficiency. Our research demonstrates the scalability and effectiveness of MoveLight across single intersections, arterial roads, and network levels. Experimental results using real-world datasets from Cologne and Hangzhou show significant improvements in metrics such as queue length, delay, and throughput compared to existing methods. This study highlights the transformative potential of deep reinforcement learning in intelligent traffic signal control, setting a new standard for sustainable and efficient urban transportation systems.","sentences":["This paper introduces MoveLight, a novel traffic signal control system that enhances urban traffic management through movement-centric deep reinforcement learning.","By leveraging detailed real-time data and advanced machine learning techniques, MoveLight overcomes the limitations of traditional traffic signal control methods.","It employs a lane-level control approach using the FRAP algorithm to achieve dynamic and adaptive traffic signal control, optimizing traffic flow, reducing congestion, and improving overall efficiency.","Our research demonstrates the scalability and effectiveness of MoveLight across single intersections, arterial roads, and network levels.","Experimental results using real-world datasets from Cologne and Hangzhou show significant improvements in metrics such as queue length, delay, and throughput compared to existing methods.","This study highlights the transformative potential of deep reinforcement learning in intelligent traffic signal control, setting a new standard for sustainable and efficient urban transportation systems."],"url":"http://arxiv.org/abs/2407.17303v1"}
{"created":"2024-07-24 14:02:20","title":"How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?","abstract":"In this study, we address the growing issue of misleading charts, a prevalent problem that undermines the integrity of information dissemination. Misleading charts can distort the viewer's perception of data, leading to misinterpretations and decisions based on false information. The development of effective automatic detection methods for misleading charts is an urgent field of research. The recent advancement of multimodal Large Language Models (LLMs) has introduced a promising direction for addressing this challenge. We explored the capabilities of these models in analyzing complex charts and assessing the impact of different prompting strategies on the models' analyses. We utilized a dataset of misleading charts collected from the internet by prior research and crafted nine distinct prompts, ranging from simple to complex, to test the ability of four different multimodal LLMs in detecting over 21 different chart issues. Through three experiments--from initial exploration to detailed analysis--we progressively gained insights into how to effectively prompt LLMs to identify misleading charts and developed strategies to address the scalability challenges encountered as we expanded our detection range from the initial five issues to 21 issues in the final experiment. Our findings reveal that multimodal LLMs possess a strong capability for chart comprehension and critical thinking in data interpretation. There is significant potential in employing multimodal LLMs to counter misleading information by supporting critical thinking and enhancing visualization literacy. This study demonstrates the applicability of LLMs in addressing the pressing concern of misleading charts.","sentences":["In this study, we address the growing issue of misleading charts, a prevalent problem that undermines the integrity of information dissemination.","Misleading charts can distort the viewer's perception of data, leading to misinterpretations and decisions based on false information.","The development of effective automatic detection methods for misleading charts is an urgent field of research.","The recent advancement of multimodal Large Language Models (LLMs) has introduced a promising direction for addressing this challenge.","We explored the capabilities of these models in analyzing complex charts and assessing the impact of different prompting strategies on the models' analyses.","We utilized a dataset of misleading charts collected from the internet by prior research and crafted nine distinct prompts, ranging from simple to complex, to test the ability of four different multimodal LLMs in detecting over 21 different chart issues.","Through three experiments--from initial exploration to detailed analysis--we progressively gained insights into how to effectively prompt LLMs to identify misleading charts and developed strategies to address the scalability challenges encountered as we expanded our detection range from the initial five issues to 21 issues in the final experiment.","Our findings reveal that multimodal LLMs possess a strong capability for chart comprehension and critical thinking in data interpretation.","There is significant potential in employing multimodal LLMs to counter misleading information by supporting critical thinking and enhancing visualization literacy.","This study demonstrates the applicability of LLMs in addressing the pressing concern of misleading charts."],"url":"http://arxiv.org/abs/2407.17291v1"}
{"created":"2024-07-24 14:00:02","title":"Static and Dynamic Verification of OCaml Programs: The Gospel Ecosystem (Extended Version)","abstract":"We present our work on the collaborative use of dynamic and static analysis tools for the verification of software written in the OCaml language. We build upon Gospel, a specification language for OCaml that can be used both in dynamic and static analyses. We employ Ortac, for runtime assertion checking, and Cameleer and CFML for the deductive verification of OCaml code. We report on the use of such tools to build a case study of collaborative analysis of a non-trivial OCaml program. This shows how these tools nicely complement each others, while at the same highlights the differences when writing specification targeting dynamic or static analysis methods.","sentences":["We present our work on the collaborative use of dynamic and static analysis tools for the verification of software written in the OCaml language.","We build upon Gospel, a specification language for OCaml that can be used both in dynamic and static analyses.","We employ Ortac, for runtime assertion checking, and Cameleer and CFML for the deductive verification of OCaml code.","We report on the use of such tools to build a case study of collaborative analysis of a non-trivial OCaml program.","This shows how these tools nicely complement each others, while at the same highlights the differences when writing specification targeting dynamic or static analysis methods."],"url":"http://arxiv.org/abs/2407.17289v1"}
{"created":"2024-07-24 13:56:56","title":"Software Defined Vehicles for Development of Deterministic Services","abstract":"With modern vehicles evolving with more features, services, complex systems, with more sensors, actuators, and processing units, it is essential to think about vehicles not only as means of transportation that may tend towards full autonomy, but also as adaptive objects, that suit themselves to the needs of occupants. Vehicular services can be developed to support these adaptations. However, the increasing complexity of vehicular service development, even with current standardizations and best practices and guidelines, are insufficient to tackle the high complexity of development, with expectations of up to 1 (U.S.) billion lines of code for a fully (level 5) autonomous vehicle. Within this survey, the paradigm of Deterministic Software Defined Vehicles is explored towards increasing the quality and easiness of the development of services for automotive. Towards this, a proposed vision with four pillars is also provided: the deterministic network configurator, the data layer configurator, and the hypervisor configurator and the vehicle abstraction layer, all coordinated by a software orchestrator.","sentences":["With modern vehicles evolving with more features, services, complex systems, with more sensors, actuators, and processing units, it is essential to think about vehicles not only as means of transportation that may tend towards full autonomy, but also as adaptive objects, that suit themselves to the needs of occupants.","Vehicular services can be developed to support these adaptations.","However, the increasing complexity of vehicular service development, even with current standardizations and best practices and guidelines, are insufficient to tackle the high complexity of development, with expectations of up to 1 (U.S.) billion lines of code for a fully (level 5) autonomous vehicle.","Within this survey, the paradigm of Deterministic Software Defined Vehicles is explored towards increasing the quality and easiness of the development of services for automotive.","Towards this, a proposed vision with four pillars is also provided: the deterministic network configurator, the data layer configurator, and the hypervisor configurator and the vehicle abstraction layer, all coordinated by a software orchestrator."],"url":"http://arxiv.org/abs/2407.17287v1"}
{"created":"2024-07-24 13:50:21","title":"A Novel Two-Step Fine-Tuning Pipeline for Cold-Start Active Learning in Text Classification Tasks","abstract":"This is the first work to investigate the effectiveness of BERT-based contextual embeddings in active learning (AL) tasks on cold-start scenarios, where traditional fine-tuning is infeasible due to the absence of labeled data. Our primary contribution is the proposal of a more robust fine-tuning pipeline - DoTCAL - that diminishes the reliance on labeled data in AL using two steps: (1) fully leveraging unlabeled data through domain adaptation of the embeddings via masked language modeling and (2) further adjusting model weights using labeled data selected by AL. Our evaluation contrasts BERT-based embeddings with other prevalent text representation paradigms, including Bag of Words (BoW), Latent Semantic Indexing (LSI), and FastText, at two critical stages of the AL process: instance selection and classification. Experiments conducted on eight ATC benchmarks with varying AL budgets (number of labeled instances) and number of instances (about 5,000 to 300,000) demonstrate DoTCAL's superior effectiveness, achieving up to a 33% improvement in Macro-F1 while reducing labeling efforts by half compared to the traditional one-step method. We also found that in several tasks, BoW and LSI (due to information aggregation) produce results superior (up to 59% ) to BERT, especially in low-budget scenarios and hard-to-classify tasks, which is quite surprising.","sentences":["This is the first work to investigate the effectiveness of BERT-based contextual embeddings in active learning (AL) tasks on cold-start scenarios, where traditional fine-tuning is infeasible due to the absence of labeled data.","Our primary contribution is the proposal of a more robust fine-tuning pipeline - DoTCAL - that diminishes the reliance on labeled data in AL using two steps: (1) fully leveraging unlabeled data through domain adaptation of the embeddings via masked language modeling and (2) further adjusting model weights using labeled data selected by AL.","Our evaluation contrasts BERT-based embeddings with other prevalent text representation paradigms, including Bag of Words (BoW), Latent Semantic Indexing (LSI), and FastText, at two critical stages of the AL process: instance selection and classification.","Experiments conducted on eight ATC benchmarks with varying AL budgets (number of labeled instances) and number of instances (about 5,000 to 300,000) demonstrate DoTCAL's superior effectiveness, achieving up to a 33% improvement in Macro-F1 while reducing labeling efforts by half compared to the traditional one-step method.","We also found that in several tasks, BoW and LSI (due to information aggregation) produce results superior (up to 59% ) to BERT, especially in low-budget scenarios and hard-to-classify tasks, which is quite surprising."],"url":"http://arxiv.org/abs/2407.17284v1"}
{"created":"2024-07-24 13:42:46","title":"Bridging Trust into the Blockchain: A Systematic Review on On-Chain Identity","abstract":"The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain. This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity). A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers. These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources. The relevant articles were then systematically analyzed based on a set of screening questions. The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities. On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches. The technologies and architectures used by the authors are also highlighted. Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain. Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities.","sentences":["The ongoing regulation of blockchain-based services and applications requires the identification of users who are issuing transactions on the blockchain.","This systematic review explores the current status, identifies research gaps, and outlines future research directions for establishing trusted and privacy-compliant identities on the blockchain (on-chain identity).","A systematic search term was applied across various scientific databases, collecting 2232 potentially relevant research papers.","These papers were narrowed down in two methodologically executed steps to 98 and finally to 13 relevant sources.","The relevant articles were then systematically analyzed based on a set of screening questions.","The results of the selected studies have provided insightful findings on the mechanisms of on-chain identities.","On-chain identities are established using zero-knowledge proofs, public key infrastructure/certificates, and web of trust approaches.","The technologies and architectures used by the authors are also highlighted.","Trust has emerged as a key research gap, manifesting in two ways: firstly, a gap in how to trust the digital identity representation of a physical human; secondly, a gap in how to trust identity providers that issue identity confirmations on-chain.","Potential future research avenues are suggested to help fill the current gaps in establishing trust and on-chain identities."],"url":"http://arxiv.org/abs/2407.17276v1"}
{"created":"2024-07-24 13:41:32","title":"Reacting on human stubbornness in human-machine trajectory planning","abstract":"In this paper, a method for a cooperative trajectory planning between a human and an automation is extended by a behavioral model of the human. This model can characterize the stubbornness of the human, which measures how strong the human adheres to his preferred trajectory. Accordingly, a static model is introduced indicating a link between the force in haptically coupled human-robot interactions and humans's stubbornness. The introduced stubbornness parameter enables an application-independent reaction of the automation for the cooperative trajectory planning. Simulation results in the context of human-machine cooperation in a care application show that the proposed behavioral model can quantitatively estimate the stubbornness of the interacting human, enabling a more targeted adaptation of the automation to the human behavior.","sentences":["In this paper, a method for a cooperative trajectory planning between a human and an automation is extended by a behavioral model of the human.","This model can characterize the stubbornness of the human, which measures how strong the human adheres to his preferred trajectory.","Accordingly, a static model is introduced indicating a link between the force in haptically coupled human-robot interactions and humans's stubbornness.","The introduced stubbornness parameter enables an application-independent reaction of the automation for the cooperative trajectory planning.","Simulation results in the context of human-machine cooperation in a care application show that the proposed behavioral model can quantitatively estimate the stubbornness of the interacting human, enabling a more targeted adaptation of the automation to the human behavior."],"url":"http://arxiv.org/abs/2407.17275v1"}
{"created":"2024-07-24 13:39:51","title":"Revolutionizing Text-to-Image Retrieval as Autoregressive Token-to-Voken Generation","abstract":"Text-to-image retrieval is a fundamental task in multimedia processing, aiming to retrieve semantically relevant cross-modal content. Traditional studies have typically approached this task as a discriminative problem, matching the text and image via the cross-attention mechanism (one-tower framework) or in a common embedding space (two-tower framework). Recently, generative cross-modal retrieval has emerged as a new research line, which assigns images with unique string identifiers and generates the target identifier as the retrieval target. Despite its great potential, existing generative approaches are limited due to the following issues: insufficient visual information in identifiers, misalignment with high-level semantics, and learning gap towards the retrieval target. To address the above issues, we propose an autoregressive voken generation method, named AVG. AVG tokenizes images into vokens, i.e., visual tokens, and innovatively formulates the text-to-image retrieval task as a token-to-voken generation problem. AVG discretizes an image into a sequence of vokens as the identifier of the image, while maintaining the alignment with both the visual information and high-level semantics of the image. Additionally, to bridge the learning gap between generative training and the retrieval target, we incorporate discriminative training to modify the learning direction during token-to-voken training. Extensive experiments demonstrate that AVG achieves superior results in both effectiveness and efficiency.","sentences":["Text-to-image retrieval is a fundamental task in multimedia processing, aiming to retrieve semantically relevant cross-modal content.","Traditional studies have typically approached this task as a discriminative problem, matching the text and image via the cross-attention mechanism (one-tower framework) or in a common embedding space (two-tower framework).","Recently, generative cross-modal retrieval has emerged as a new research line, which assigns images with unique string identifiers and generates the target identifier as the retrieval target.","Despite its great potential, existing generative approaches are limited due to the following issues: insufficient visual information in identifiers, misalignment with high-level semantics, and learning gap towards the retrieval target.","To address the above issues, we propose an autoregressive voken generation method, named AVG.","AVG tokenizes images into vokens, i.e., visual tokens, and innovatively formulates the text-to-image retrieval task as a token-to-voken generation problem.","AVG discretizes an image into a sequence of vokens as the identifier of the image, while maintaining the alignment with both the visual information and high-level semantics of the image.","Additionally, to bridge the learning gap between generative training and the retrieval target, we incorporate discriminative training to modify the learning direction during token-to-voken training.","Extensive experiments demonstrate that AVG achieves superior results in both effectiveness and efficiency."],"url":"http://arxiv.org/abs/2407.17274v1"}
{"created":"2024-07-24 13:39:26","title":"Component Matching as a Graph Matching Problem","abstract":"The development of an IT strategy and ensuring that it is the best possible one for business is a key problem many organizations face. This problem is that of linking business architecture to IT architecture in general and application architecture specifically. In our earlier work we proposed Category theory as the formal language to unify the business and IT worlds with the ability to represent the concepts and relations between the two in a unified way. We used rCOS as the underlying model for the specification of interfaces, contracts, and components. The concept of pseudo-category was then utilized to represent the business and application architecture specifications and the relationships contained within. Contracts are used for the specification of both IT and Business architecture components. The linkages between them is now established using the matching of the business component contracts with the application component contracts. Typically, the matching was based on manual process, in this paper we extend the work by considering automated component matching process. In this paper we provide implementation of the matching process using graph matching.","sentences":["The development of an IT strategy and ensuring that it is the best possible one for business is a key problem many organizations face.","This problem is that of linking business architecture to IT architecture in general and application architecture specifically.","In our earlier work we proposed Category theory as the formal language to unify the business and IT worlds with the ability to represent the concepts and relations between the two in a unified way.","We used rCOS as the underlying model for the specification of interfaces, contracts, and components.","The concept of pseudo-category was then utilized to represent the business and application architecture specifications and the relationships contained within.","Contracts are used for the specification of both IT and Business architecture components.","The linkages between them is now established using the matching of the business component contracts with the application component contracts.","Typically, the matching was based on manual process, in this paper we extend the work by considering automated component matching process.","In this paper we provide implementation of the matching process using graph matching."],"url":"http://arxiv.org/abs/2407.17273v1"}
{"created":"2024-07-24 13:39:07","title":"DenseTrack: Drone-based Crowd Tracking via Density-aware Motion-appearance Synergy","abstract":"Drone-based crowd tracking faces difficulties in accurately identifying and monitoring objects from an aerial perspective, largely due to their small size and close proximity to each other, which complicates both localization and tracking. To address these challenges, we present the Density-aware Tracking (DenseTrack) framework. DenseTrack capitalizes on crowd counting to precisely determine object locations, blending visual and motion cues to improve the tracking of small-scale objects. It specifically addresses the problem of cross-frame motion to enhance tracking accuracy and dependability. DenseTrack employs crowd density estimates as anchors for exact object localization within video frames. These estimates are merged with motion and position information from the tracking network, with motion offsets serving as key tracking cues. Moreover, DenseTrack enhances the ability to distinguish small-scale objects using insights from the visual-language model, integrating appearance with motion cues. The framework utilizes the Hungarian algorithm to ensure the accurate matching of individuals across frames. Demonstrated on DroneCrowd dataset, our approach exhibits superior performance, confirming its effectiveness in scenarios captured by drones.","sentences":["Drone-based crowd tracking faces difficulties in accurately identifying and monitoring objects from an aerial perspective, largely due to their small size and close proximity to each other, which complicates both localization and tracking.","To address these challenges, we present the Density-aware Tracking (DenseTrack) framework.","DenseTrack capitalizes on crowd counting to precisely determine object locations, blending visual and motion cues to improve the tracking of small-scale objects.","It specifically addresses the problem of cross-frame motion to enhance tracking accuracy and dependability.","DenseTrack employs crowd density estimates as anchors for exact object localization within video frames.","These estimates are merged with motion and position information from the tracking network, with motion offsets serving as key tracking cues.","Moreover, DenseTrack enhances the ability to distinguish small-scale objects using insights from the visual-language model, integrating appearance with motion cues.","The framework utilizes the Hungarian algorithm to ensure the accurate matching of individuals across frames.","Demonstrated on DroneCrowd dataset, our approach exhibits superior performance, confirming its effectiveness in scenarios captured by drones."],"url":"http://arxiv.org/abs/2407.17272v1"}
{"created":"2024-07-24 13:35:35","title":"Advanced Penetration Testing for Enhancing 5G Security","abstract":"Advances in fifth-generation (5G) networks enable unprecedented reliability, speed, and connectivity compared to previous mobile networks. These advancements can revolutionize various sectors by supporting applications requiring real-time data processing. However, the rapid deployment and integration of 5G networks bring security concerns that must be addressed to operate these infrastructures safely. This paper reviews penetration testing approaches for identifying security vulnerabilities in 5G networks. Penetration testing is an ethical hacking technique used to simulate a network's security posture in the event of cyberattacks. This review highlights the capabilities, advantages, and limitations of recent 5G-targeting security tools for penetration testing. It examines ways adversaries exploit vulnerabilities in 5G networks, covering tactics and strategies targeted at 5G features. A key topic explored is the comparison of penetration testing methods for 5G and earlier generations. The article delves into the unique characteristics of 5G, including massive MIMO, edge computing, and network slicing, and how these aspects require new penetration testing methods. Understanding these differences helps develop more effective security solutions tailored to 5G networks. Our research also indicates that 5G penetration testing should use a multithreaded approach for addressing current security challenges. Furthermore, this paper includes case studies illustrating practical challenges and limitations in real-world applications of penetration testing in 5G networks. A comparative analysis of penetration testing tools for 5G networks highlights their effectiveness in mitigating vulnerabilities, emphasizing the need for advanced security measures against evolving cyber threats in 5G deployment.","sentences":["Advances in fifth-generation (5G) networks enable unprecedented reliability, speed, and connectivity compared to previous mobile networks.","These advancements can revolutionize various sectors by supporting applications requiring real-time data processing.","However, the rapid deployment and integration of 5G networks bring security concerns that must be addressed to operate these infrastructures safely.","This paper reviews penetration testing approaches for identifying security vulnerabilities in 5G networks.","Penetration testing is an ethical hacking technique used to simulate a network's security posture in the event of cyberattacks.","This review highlights the capabilities, advantages, and limitations of recent 5G-targeting security tools for penetration testing.","It examines ways adversaries exploit vulnerabilities in 5G networks, covering tactics and strategies targeted at 5G features.","A key topic explored is the comparison of penetration testing methods for 5G and earlier generations.","The article delves into the unique characteristics of 5G, including massive MIMO, edge computing, and network slicing, and how these aspects require new penetration testing methods.","Understanding these differences helps develop more effective security solutions tailored to 5G networks.","Our research also indicates that 5G penetration testing should use a multithreaded approach for addressing current security challenges.","Furthermore, this paper includes case studies illustrating practical challenges and limitations in real-world applications of penetration testing in 5G networks.","A comparative analysis of penetration testing tools for 5G networks highlights their effectiveness in mitigating vulnerabilities, emphasizing the need for advanced security measures against evolving cyber threats in 5G deployment."],"url":"http://arxiv.org/abs/2407.17269v1"}
{"created":"2024-07-24 13:30:46","title":"M4: Multi-Proxy Multi-Gate Mixture of Experts Network for Multiple Instance Learning in Histopathology Image Analysis","abstract":"Multiple instance learning (MIL) has been successfully applied for whole slide images (WSIs) analysis in computational pathology, enabling a wide range of prediction tasks from tumor subtyping to inferring genetic mutations and multi-omics biomarkers. However, existing MIL methods predominantly focus on single-task learning, resulting in not only overall low efficiency but also the overlook of inter-task relatedness. To address these issues, we proposed an adapted architecture of Multi-gate Mixture-of-experts with Multi-proxy for Multiple instance learning (M4), and applied this framework for simultaneous prediction of multiple genetic mutations from WSIs. The proposed M4 model has two main innovations: (1) utilizing a mixture of experts with multiple gating strategies for multi-genetic mutation prediction on a single pathological slide; (2) constructing multi-proxy expert network and gate network for comprehensive and effective modeling of pathological image information. Our model achieved significant improvements across five tested TCGA datasets in comparison to current state-of-the-art single-task methods. The code is available at:https://github.com/Bigyehahaha/M4.","sentences":["Multiple instance learning (MIL) has been successfully applied for whole slide images (WSIs) analysis in computational pathology, enabling a wide range of prediction tasks from tumor subtyping to inferring genetic mutations and multi-omics biomarkers.","However, existing MIL methods predominantly focus on single-task learning, resulting in not only overall low efficiency but also the overlook of inter-task relatedness.","To address these issues, we proposed an adapted architecture of Multi-gate Mixture-of-experts with Multi-proxy for Multiple instance learning (M4), and applied this framework for simultaneous prediction of multiple genetic mutations from WSIs.","The proposed M4 model has two main innovations: (1) utilizing a mixture of experts with multiple gating strategies for multi-genetic mutation prediction on a single pathological slide; (2) constructing multi-proxy expert network and gate network for comprehensive and effective modeling of pathological image information.","Our model achieved significant improvements across five tested TCGA datasets in comparison to current state-of-the-art single-task methods.","The code is available at:https://github.com/Bigyehahaha/M4."],"url":"http://arxiv.org/abs/2407.17267v1"}
{"created":"2024-07-24 13:29:17","title":"SCIsegV2: A Universal Tool for Segmentation of Intramedullary Lesions in Spinal Cord Injury","abstract":"Spinal cord injury (SCI) is a devastating incidence leading to permanent paralysis and loss of sensory-motor functions potentially resulting in the formation of lesions within the spinal cord. Imaging biomarkers obtained from magnetic resonance imaging (MRI) scans can predict the functional recovery of individuals with SCI and help choose the optimal treatment strategy. Currently, most studies employ manual quantification of these MRI-derived biomarkers, which is a subjective and tedious task. In this work, we propose (i) a universal tool for the automatic segmentation of intramedullary SCI lesions, dubbed \\texttt{SCIsegV2}, and (ii) a method to automatically compute the width of the tissue bridges from the segmented lesion. Tissue bridges represent the spared spinal tissue adjacent to the lesion, which is associated with functional recovery in SCI patients. The tool was trained and validated on a heterogeneous dataset from 7 sites comprising patients from different SCI phases (acute, sub-acute, and chronic) and etiologies (traumatic SCI, ischemic SCI, and degenerative cervical myelopathy). Tissue bridges quantified automatically did not significantly differ from those computed manually, suggesting that the proposed automatic tool can be used to derive relevant MRI biomarkers. \\texttt{SCIsegV2} and the automatic tissue bridges computation are open-source and available in Spinal Cord Toolbox (v6.4 and above) via the \\texttt{sct\\_deepseg -task seg\\_sc\\_lesion\\_t2w\\_sci} and \\texttt{sct\\_analyze\\_lesion} functions, respectively.","sentences":["Spinal cord injury (SCI) is a devastating incidence leading to permanent paralysis and loss of sensory-motor functions potentially resulting in the formation of lesions within the spinal cord.","Imaging biomarkers obtained from magnetic resonance imaging (MRI) scans can predict the functional recovery of individuals with SCI and help choose the optimal treatment strategy.","Currently, most studies employ manual quantification of these MRI-derived biomarkers, which is a subjective and tedious task.","In this work, we propose (i) a universal tool for the automatic segmentation of intramedullary SCI lesions, dubbed \\texttt{SCIsegV2}, and (ii) a method to automatically compute the width of the tissue bridges from the segmented lesion.","Tissue bridges represent the spared spinal tissue adjacent to the lesion, which is associated with functional recovery in SCI patients.","The tool was trained and validated on a heterogeneous dataset from 7 sites comprising patients from different SCI phases (acute, sub-acute, and chronic) and etiologies (traumatic SCI, ischemic SCI, and degenerative cervical myelopathy).","Tissue bridges quantified automatically did not significantly differ from those computed manually, suggesting that the proposed automatic tool can be used to derive relevant MRI biomarkers.","\\texttt{SCIsegV2} and the automatic tissue bridges computation are open-source and available in Spinal Cord Toolbox (v6.4 and above) via the \\texttt{sct\\_deepseg -task seg\\_sc\\_lesion\\_t2w\\_sci} and \\texttt{sct\\_analyze\\_lesion} functions, respectively."],"url":"http://arxiv.org/abs/2407.17265v1"}
{"created":"2024-07-24 13:24:25","title":"Embedding-Free Transformer with Inference Spatial Reduction for Efficient Semantic Segmentation","abstract":"We present an Encoder-Decoder Attention Transformer, EDAFormer, which consists of the Embedding-Free Transformer (EFT) encoder and the all-attention decoder leveraging our Embedding-Free Attention (EFA) structure. The proposed EFA is a novel global context modeling mechanism that focuses on functioning the global non-linearity, not the specific roles of the query, key and value. For the decoder, we explore the optimized structure for considering the globality, which can improve the semantic segmentation performance. In addition, we propose a novel Inference Spatial Reduction (ISR) method for the computational efficiency. Different from the previous spatial reduction attention methods, our ISR method further reduces the key-value resolution at the inference phase, which can mitigate the computation-performance trade-off gap for the efficient semantic segmentation. Our EDAFormer shows the state-of-the-art performance with the efficient computation compared to the existing transformer-based semantic segmentation models in three public benchmarks, including ADE20K, Cityscapes and COCO-Stuff. Furthermore, our ISR method reduces the computational cost by up to 61% with minimal mIoU performance degradation on Cityscapes dataset. The code is available at https://github.com/hyunwoo137/EDAFormer.","sentences":["We present an Encoder-Decoder Attention Transformer, EDAFormer, which consists of the Embedding-Free Transformer (EFT) encoder and the all-attention decoder leveraging our Embedding-Free Attention (EFA) structure.","The proposed EFA is a novel global context modeling mechanism that focuses on functioning the global non-linearity, not the specific roles of the query, key and value.","For the decoder, we explore the optimized structure for considering the globality, which can improve the semantic segmentation performance.","In addition, we propose a novel Inference Spatial Reduction (ISR) method for the computational efficiency.","Different from the previous spatial reduction attention methods, our ISR method further reduces the key-value resolution at the inference phase, which can mitigate the computation-performance trade-off gap for the efficient semantic segmentation.","Our EDAFormer shows the state-of-the-art performance with the efficient computation compared to the existing transformer-based semantic segmentation models in three public benchmarks, including ADE20K, Cityscapes and COCO-Stuff.","Furthermore, our ISR method reduces the computational cost by up to 61% with minimal mIoU performance degradation on Cityscapes dataset.","The code is available at https://github.com/hyunwoo137/EDAFormer."],"url":"http://arxiv.org/abs/2407.17261v1"}
{"created":"2024-07-24 13:21:49","title":"Spatial Conceptual Modeling: Anchoring Knowledge in the Real World","abstract":"This paper introduces the concept of spatial conceptual modeling, which allows anchoring mental world knowledge in the physical world using augmented reality technologies. For a first formal characterization, we describe a mapping from the spatial information concepts location, field, object, network, and event, as used in spatial computing, to conceptual modeling concepts using the FDMM formalism. This allows to identify necessary adaptations at the metamodeling level to make the approach applicable to arbitrary types of spatial conceptual modeling languages. Finally, possible application areas of spatial conceptual modeling in the medical domain, manufacturing and engineering, physical IT architectures and smart homes, supply chain management and logistics, civil engineering, and smart cities and cultural heritage are discussed.","sentences":["This paper introduces the concept of spatial conceptual modeling, which allows anchoring mental world knowledge in the physical world using augmented reality technologies.","For a first formal characterization, we describe a mapping from the spatial information concepts location, field, object, network, and event, as used in spatial computing, to conceptual modeling concepts using the FDMM formalism.","This allows to identify necessary adaptations at the metamodeling level to make the approach applicable to arbitrary types of spatial conceptual modeling languages.","Finally, possible application areas of spatial conceptual modeling in the medical domain, manufacturing and engineering, physical IT architectures and smart homes, supply chain management and logistics, civil engineering, and smart cities and cultural heritage are discussed."],"url":"http://arxiv.org/abs/2407.17259v1"}
