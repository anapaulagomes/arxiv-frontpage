{"created":"2025-02-25 18:59:46","title":"Allocating Variance to Maximize Expectation","abstract":"We design efficient approximation algorithms for maximizing the expectation of the supremum of families of Gaussian random variables. In particular, let $\\mathrm{OPT}:=\\max_{\\sigma_1,\\cdots,\\sigma_n}\\mathbb{E}\\left[\\sum_{j=1}^{m}\\max_{i\\in S_j} X_i\\right]$, where $X_i$ are Gaussian, $S_j\\subset[n]$ and $\\sum_i\\sigma_i^2=1$, then our theoretical results include:   - We characterize the optimal variance allocation -- it concentrates on a small subset of variables as $|S_j|$ increases,   - A polynomial time approximation scheme (PTAS) for computing $\\mathrm{OPT}$ when $m=1$, and   - An $O(\\log n)$ approximation algorithm for computing $\\mathrm{OPT}$ for general $m>1$.   Such expectation maximization problems occur in diverse applications, ranging from utility maximization in auctions markets to learning mixture models in quantitative genetics.","sentences":["We design efficient approximation algorithms for maximizing the expectation of the supremum of families of Gaussian random variables.","In particular, let $\\mathrm{OPT}:=\\max_{\\sigma_1,\\cdots,\\sigma_n}\\mathbb{E}\\left[\\sum_{j=1}^{m}\\max_{i\\in S_j} X_i\\right]$, where $X_i$ are Gaussian, $S_j\\subset[n]$ and $\\sum_i\\sigma_i^2=1$, then our theoretical results include:   - We characterize the optimal variance allocation -- it concentrates on a small subset of variables as $|S_j|$ increases,   - A polynomial time approximation scheme (PTAS) for computing $\\mathrm{OPT}$ when $m=1$, and   - An $O(\\log n)$ approximation algorithm for computing $\\mathrm{OPT}$ for general $m>1$.   Such expectation maximization problems occur in diverse applications, ranging from utility maximization in auctions markets to learning mixture models in quantitative genetics."],"url":"http://arxiv.org/abs/2502.18463v1"}
{"created":"2025-02-25 18:59:13","title":"Scalable Equilibrium Sampling with Sequential Boltzmann Generators","abstract":"Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann generators tackle this problem by pairing powerful normalizing flows with importance sampling to obtain statistically independent samples under the target distribution. In this paper, we extend the Boltzmann generator framework and introduce Sequential Boltzmann generators (SBG) with two key improvements. The first is a highly efficient non-equivariant Transformer-based normalizing flow operating directly on all-atom Cartesian coordinates. In contrast to equivariant continuous flows of prior methods, we leverage exactly invertible non-equivariant architectures which are highly efficient both during sample generation and likelihood computation. As a result, this unlocks more sophisticated inference strategies beyond standard importance sampling. More precisely, as a second key improvement we perform inference-time scaling of flow samples using annealed Langevin dynamics which transports samples toward the target distribution leading to lower variance (annealed) importance weights which enable higher fidelity resampling with sequential Monte Carlo. SBG achieves state-of-the-art performance w.r.t. all metrics on molecular systems, demonstrating the first equilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides that were so far intractable for prior Boltzmann generators.","sentences":["Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics.","Boltzmann generators tackle this problem by pairing powerful normalizing flows with importance sampling to obtain statistically independent samples under the target distribution.","In this paper, we extend the Boltzmann generator framework and introduce Sequential Boltzmann generators (SBG) with two key improvements.","The first is a highly efficient non-equivariant Transformer-based normalizing flow operating directly on all-atom Cartesian coordinates.","In contrast to equivariant continuous flows of prior methods, we leverage exactly invertible non-equivariant architectures which are highly efficient both during sample generation and likelihood computation.","As a result, this unlocks more sophisticated inference strategies beyond standard importance sampling.","More precisely, as a second key improvement we perform inference-time scaling of flow samples using annealed Langevin dynamics which transports samples toward the target distribution leading to lower variance (annealed) importance weights which enable higher fidelity resampling with sequential Monte Carlo.","SBG achieves state-of-the-art performance w.r.t.","all metrics on molecular systems, demonstrating the first equilibrium sampling in Cartesian coordinates of tri, tetra, and hexapeptides that were so far intractable for prior Boltzmann generators."],"url":"http://arxiv.org/abs/2502.18462v1"}
{"created":"2025-02-25 18:59:12","title":"K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs","abstract":"Recent studies have explored combining different LoRAs to jointly generate learned style and content. However, existing methods either fail to effectively preserve both the original subject and style simultaneously or require additional training. In this paper, we argue that the intrinsic properties of LoRA can effectively guide diffusion models in merging learned subject and style. Building on this insight, we propose K-LoRA, a simple yet effective training-free LoRA fusion approach. In each attention layer, K-LoRA compares the Top-K elements in each LoRA to be fused, determining which LoRA to select for optimal fusion. This selection mechanism ensures that the most representative features of both subject and style are retained during the fusion process, effectively balancing their contributions. Experimental results demonstrate that the proposed method effectively integrates the subject and style information learned by the original LoRAs, outperforming state-of-the-art training-based approaches in both qualitative and quantitative results.","sentences":["Recent studies have explored combining different LoRAs to jointly generate learned style and content.","However, existing methods either fail to effectively preserve both the original subject and style simultaneously or require additional training.","In this paper, we argue that the intrinsic properties of LoRA can effectively guide diffusion models in merging learned subject and style.","Building on this insight, we propose K-LoRA, a simple yet effective training-free LoRA fusion approach.","In each attention layer, K-LoRA compares the Top-K elements in each LoRA to be fused, determining which LoRA to select for optimal fusion.","This selection mechanism ensures that the most representative features of both subject and style are retained during the fusion process, effectively balancing their contributions.","Experimental results demonstrate that the proposed method effectively integrates the subject and style information learned by the original LoRAs, outperforming state-of-the-art training-based approaches in both qualitative and quantitative results."],"url":"http://arxiv.org/abs/2502.18461v1"}
{"created":"2025-02-25 18:59:07","title":"DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers","abstract":"Large language models (LLMs) have demonstrated strong effectiveness and robustness while fine-tuned as dense retrievers. However, their large parameter size brings significant inference time computational challenges, including high encoding costs for large-scale corpora and increased query latency, limiting their practical deployment. While smaller retrievers offer better efficiency, they often fail to generalize effectively with limited supervised fine-tuning data. In this work, we introduce DRAMA, a training framework that leverages LLMs to train smaller generalizable dense retrievers. In particular, we adopt pruned LLMs as the backbone and train on diverse LLM-augmented data in a single-stage contrastive learning setup. Experiments show that DRAMA offers better multilingual and long-context capabilities than traditional encoder-based retrievers, and achieves strong performance across multiple tasks and languages. These highlight the potential of connecting the training of smaller retrievers with the growing advancements in LLMs, bridging the gap between efficiency and generalization.","sentences":["Large language models (LLMs) have demonstrated strong effectiveness and robustness while fine-tuned as dense retrievers.","However, their large parameter size brings significant inference time computational challenges, including high encoding costs for large-scale corpora and increased query latency, limiting their practical deployment.","While smaller retrievers offer better efficiency, they often fail to generalize effectively with limited supervised fine-tuning data.","In this work, we introduce DRAMA, a training framework that leverages LLMs to train smaller generalizable dense retrievers.","In particular, we adopt pruned LLMs as the backbone and train on diverse LLM-augmented data in a single-stage contrastive learning setup.","Experiments show that DRAMA offers better multilingual and long-context capabilities than traditional encoder-based retrievers, and achieves strong performance across multiple tasks and languages.","These highlight the potential of connecting the training of smaller retrievers with the growing advancements in LLMs, bridging the gap between efficiency and generalization."],"url":"http://arxiv.org/abs/2502.18460v1"}
{"created":"2025-02-25 18:57:06","title":"LLM-Based Design Pattern Detection","abstract":"Detecting design pattern instances in unfamiliar codebases remains a challenging yet essential task for improving software quality and maintainability. Traditional static analysis tools often struggle with the complexity, variability, and lack of explicit annotations that characterize real-world pattern implementations. In this paper, we present a novel approach leveraging Large Language Models to automatically identify design pattern instances across diverse codebases. Our method focuses on recognizing the roles classes play within the pattern instances. By providing clearer insights into software structure and intent, this research aims to support developers, improve comprehension, and streamline tasks such as refactoring, maintenance, and adherence to best practices.","sentences":["Detecting design pattern instances in unfamiliar codebases remains a challenging yet essential task for improving software quality and maintainability.","Traditional static analysis tools often struggle with the complexity, variability, and lack of explicit annotations that characterize real-world pattern implementations.","In this paper, we present a novel approach leveraging Large Language Models to automatically identify design pattern instances across diverse codebases.","Our method focuses on recognizing the roles classes play within the pattern instances.","By providing clearer insights into software structure and intent, this research aims to support developers, improve comprehension, and streamline tasks such as refactoring, maintenance, and adherence to best practices."],"url":"http://arxiv.org/abs/2502.18458v1"}
{"created":"2025-02-25 18:55:21","title":"Assessing the Maturity of Cybersecurity Education in Virginia and the Impact of State Level Investment","abstract":"With a global shortage of cybersecurity students with the education and experience necessary to fill more than 3 million jobs, cybersecurity education is an international problem. Significant research within this field has explored this problem in depth, identifying a variety of shortcomings in the cybersecurity educational pipeline including lack of certifications, security clearances, and appropriate educational opportunities within institutions of higher education. Additional research has built on this, exploring specific gaps within what cybersecurity opportunities are provided within institutions of higher education. We build an ordinal scale for assessing this, the cybersecurity education maturity model scale (CEMMs), and provide evidence of reliability and validity. We then calculate the CEMMs score for all public four-year universities in the state of Virginia between 2017 and 2025, with 2017 marking a year in which the state started the Commonwealth Cyber Initiative (CCI). We find that the scale proposed provides a consistent and reliable way to compare the cybersecurity offerings available between universities. When comparing year to year average CEMMs score, we find that public four year universities in Virginia are increasing their program offerings in the area of cybersecurity, with potential to make an impact on the cybersecurity jobs gap.","sentences":["With a global shortage of cybersecurity students with the education and experience necessary to fill more than 3 million jobs, cybersecurity education is an international problem.","Significant research within this field has explored this problem in depth, identifying a variety of shortcomings in the cybersecurity educational pipeline including lack of certifications, security clearances, and appropriate educational opportunities within institutions of higher education.","Additional research has built on this, exploring specific gaps within what cybersecurity opportunities are provided within institutions of higher education.","We build an ordinal scale for assessing this, the cybersecurity education maturity model scale (CEMMs), and provide evidence of reliability and validity.","We then calculate the CEMMs score for all public four-year universities in the state of Virginia between 2017 and 2025, with 2017 marking a year in which the state started the Commonwealth Cyber Initiative (CCI).","We find that the scale proposed provides a consistent and reliable way to compare the cybersecurity offerings available between universities.","When comparing year to year average CEMMs score, we find that public four year universities in Virginia are increasing their program offerings in the area of cybersecurity, with potential to make an impact on the cybersecurity jobs gap."],"url":"http://arxiv.org/abs/2502.18456v1"}
{"created":"2025-02-25 18:52:28","title":"Evaluating the Effectiveness of Small Language Models in Detecting Refactoring Bugs","abstract":"Popular IDEs frequently contain bugs in their refactoring implementations. Ensuring that a transformation preserves a program's behavior is a complex task. Traditional detection methods rely on predefined preconditions for each refactoring type, limiting their scalability and adaptability to new transformations. These methods often require extensive static and dynamic analyses, which are computationally expensive, time-consuming, and may still fail to detect certain refactoring bugs. This study evaluates the effectiveness of Small Language Models (SLMs) in detecting two types of refactoring bugs in Java and Python: (i) transformations that introduce errors or behavioral changes (Type I) and (ii) transformations unnecessarily blocked by IDEs despite being valid (Type II). We assess whether Llama 3.2 3B, Mistral 7B, Gemma 2 9B, DeepSeek-R1 14B, Phi-4 14B, o1-mini, and o3-mini-high can accurately detect 100 refactoring bugs reported in widely used Java and Python IDEs, such as Eclipse and NetBeans. The study covers 16 refactoring types and employs zero-shot prompting on consumer-grade hardware to evaluate the models' ability to reason about refactoring correctness without explicit prior training. The proprietary o3-mini-high model achieved the highest detection rate, identifying 84.3% of Type I bugs. The open-source Phi-4 14B performed comparably well, demonstrating strong effectiveness across both bug types. However, o3-mini-high struggled with Type II bugs, correctly identifying and applying valid but blocked transformations in only 40% of cases. The findings highlight the potential of SLMs for efficiently detecting refactoring bugs, particularly in verifying behavioral changes. Additionally, SLMs offer a more adaptable solution capable of generalizing across different refactoring types and programming languages, addressing key limitations of traditional approaches.","sentences":["Popular IDEs frequently contain bugs in their refactoring implementations.","Ensuring that a transformation preserves a program's behavior is a complex task.","Traditional detection methods rely on predefined preconditions for each refactoring type, limiting their scalability and adaptability to new transformations.","These methods often require extensive static and dynamic analyses, which are computationally expensive, time-consuming, and may still fail to detect certain refactoring bugs.","This study evaluates the effectiveness of Small Language Models (SLMs) in detecting two types of refactoring bugs in Java and Python: (i) transformations that introduce errors or behavioral changes (Type I) and (ii) transformations unnecessarily blocked by IDEs despite being valid (Type II).","We assess whether Llama 3.2 3B, Mistral 7B, Gemma 2 9B, DeepSeek-R1 14B, Phi-4 14B, o1-mini, and o3-mini-high can accurately detect 100 refactoring bugs reported in widely used Java and Python IDEs, such as Eclipse and NetBeans.","The study covers 16 refactoring types and employs zero-shot prompting on consumer-grade hardware to evaluate the models' ability to reason about refactoring correctness without explicit prior training.","The proprietary o3-mini-high model achieved the highest detection rate, identifying 84.3% of Type I bugs.","The open-source Phi-4 14B performed comparably well, demonstrating strong effectiveness across both bug types.","However, o3-mini-high struggled with Type II bugs, correctly identifying and applying valid but blocked transformations in only 40% of cases.","The findings highlight the potential of SLMs for efficiently detecting refactoring bugs, particularly in verifying behavioral changes.","Additionally, SLMs offer a more adaptable solution capable of generalizing across different refactoring types and programming languages, addressing key limitations of traditional approaches."],"url":"http://arxiv.org/abs/2502.18454v1"}
{"created":"2025-02-25 18:51:06","title":"FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response","abstract":"Large Language Models (LLMs) have the potential for substantial common sense reasoning. However, these capabilities are often emergent in larger models. This means smaller models that can be run locally are less helpful and capable with respect to certain reasoning tasks. To meet our problem space requirements, we fine-tune smaller LLMs to disaster domains, as these domains involve complex and low-frequency physical common sense knowledge. We introduce a pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models, where domain experts and linguists combine their knowledge to make high-quality seed data that is used to generate synthetic data for fine-tuning. We create a set of 130 seed instructions for synthetic generation, a synthetic dataset of 25000 instructions, and 119 evaluation instructions relating to both general and earthquake-specific object affordances. We fine-tune several LLaMa and Mistral instruction-tuned models and find that FRIDA models outperform their base models at a variety of sizes. We then run an ablation study to understand which kinds of synthetic data most affect performance and find that training physical state and object function common sense knowledge alone improves over FRIDA models trained on all data. We conclude that the FRIDA pipeline is capable of instilling general common sense, but needs to be augmented with information retrieval for specific domain knowledge.","sentences":["Large Language Models (LLMs) have the potential for substantial common sense reasoning.","However, these capabilities are often emergent in larger models.","This means smaller models that can be run locally are less helpful and capable with respect to certain reasoning tasks.","To meet our problem space requirements, we fine-tune smaller LLMs to disaster domains, as these domains involve complex and low-frequency physical common sense knowledge.","We introduce a pipeline to create Field Ready Instruction Decoding Agent (FRIDA) models, where domain experts and linguists combine their knowledge to make high-quality seed data that is used to generate synthetic data for fine-tuning.","We create a set of 130 seed instructions for synthetic generation, a synthetic dataset of 25000 instructions, and 119 evaluation instructions relating to both general and earthquake-specific object affordances.","We fine-tune several LLaMa and Mistral instruction-tuned models and find that FRIDA models outperform their base models at a variety of sizes.","We then run an ablation study to understand which kinds of synthetic data most affect performance and find that training physical state and object function common sense knowledge alone improves over FRIDA models trained on all data.","We conclude that the FRIDA pipeline is capable of instilling general common sense, but needs to be augmented with information retrieval for specific domain knowledge."],"url":"http://arxiv.org/abs/2502.18452v1"}
{"created":"2025-02-25 18:45:04","title":"SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution","abstract":"The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs). While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, this paper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for real-world software engineering. Leveraging a lightweight rule-based reward (e.g., the similarity score between ground-truth and LLM-generated solutions), SWE-RL enables LLMs to autonomously recover a developer's reasoning processes and solutions by learning from extensive open-source software evolution data -- the record of a software's entire lifecycle, including its code snapshots, code changes, and events such as issues and pull requests. Trained on top of Llama 3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve rate on SWE-bench Verified -- a human-verified collection of real-world GitHub issues. To our knowledge, this is the best performance reported for medium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs like GPT-4o. Surprisingly, despite performing RL solely on software evolution data, Llama3-SWE-RL has even emerged with generalized reasoning skills. For example, it shows improved results on five out-of-domain tasks, namely, function coding, library use, code reasoning, mathematics, and general language understanding, whereas a supervised-finetuning baseline even leads to performance degradation on average. Overall, SWE-RL opens up a new direction to improve the reasoning capabilities of LLMs through reinforcement learning on massive software engineering data.","sentences":["The recent DeepSeek-R1 release has demonstrated the immense potential of reinforcement learning (RL) in enhancing the general reasoning capabilities of large language models (LLMs).","While DeepSeek-R1 and other follow-up work primarily focus on applying RL to competitive coding and math problems, this paper introduces SWE-RL, the first approach to scale RL-based LLM reasoning for real-world software engineering.","Leveraging a lightweight rule-based reward (e.g., the similarity score between ground-truth and LLM-generated solutions), SWE-RL enables LLMs to autonomously recover a developer's reasoning processes and solutions by learning from extensive open-source software evolution data -- the record of a software's entire lifecycle, including its code snapshots, code changes, and events such as issues and pull requests.","Trained on top of Llama 3, our resulting reasoning model, Llama3-SWE-RL-70B, achieves a 41.0% solve rate on SWE-bench Verified -- a human-verified collection of real-world GitHub issues.","To our knowledge, this is the best performance reported for medium-sized (<100B) LLMs to date, even comparable to leading proprietary LLMs like GPT-4o.","Surprisingly, despite performing RL solely on software evolution data, Llama3-SWE-RL has even emerged with generalized reasoning skills.","For example, it shows improved results on five out-of-domain tasks, namely, function coding, library use, code reasoning, mathematics, and general language understanding, whereas a supervised-finetuning baseline even leads to performance degradation on average.","Overall, SWE-RL opens up a new direction to improve the reasoning capabilities of LLMs through reinforcement learning on massive software engineering data."],"url":"http://arxiv.org/abs/2502.18449v1"}
{"created":"2025-02-25 18:42:26","title":"Disambiguate First Parse Later: Generating Interpretations for Ambiguity Resolution in Semantic Parsing","abstract":"Handling ambiguity and underspecification is an important challenge in natural language interfaces, particularly for tasks like text-to-SQL semantic parsing. We propose a modular approach that resolves ambiguity using natural language interpretations before mapping these to logical forms (e.g., SQL queries). Although LLMs excel at parsing unambiguous utterances, they show strong biases for ambiguous ones, typically predicting only preferred interpretations. We constructively exploit this bias to generate an initial set of preferred disambiguations and then apply a specialized infilling model to identify and generate missing interpretations. To train the infilling model, we introduce an annotation method that uses SQL execution to validate different meanings. Our approach improves interpretation coverage and generalizes across datasets with different annotation styles, database structures, and ambiguity types.","sentences":["Handling ambiguity and underspecification is an important challenge in natural language interfaces, particularly for tasks like text-to-SQL semantic parsing.","We propose a modular approach that resolves ambiguity using natural language interpretations before mapping these to logical forms (e.g., SQL queries).","Although LLMs excel at parsing unambiguous utterances, they show strong biases for ambiguous ones, typically predicting only preferred interpretations.","We constructively exploit this bias to generate an initial set of preferred disambiguations and then apply a specialized infilling model to identify and generate missing interpretations.","To train the infilling model, we introduce an annotation method that uses SQL execution to validate different meanings.","Our approach improves interpretation coverage and generalizes across datasets with different annotation styles, database structures, and ambiguity types."],"url":"http://arxiv.org/abs/2502.18448v1"}
{"created":"2025-02-25 18:42:05","title":"Supervised Reward Inference","abstract":"Existing approaches to reward inference from behavior typically assume that humans provide demonstrations according to specific models of behavior. However, humans often indicate their goals through a wide range of behaviors, from actions that are suboptimal due to poor planning or execution to behaviors which are intended to communicate goals rather than achieve them. We propose that supervised learning offers a unified framework to infer reward functions from any class of behavior, and show that such an approach is asymptotically Bayes-optimal under mild assumptions. Experiments on simulated robotic manipulation tasks show that our method can efficiently infer rewards from a wide variety of arbitrarily suboptimal demonstrations.","sentences":["Existing approaches to reward inference from behavior typically assume that humans provide demonstrations according to specific models of behavior.","However, humans often indicate their goals through a wide range of behaviors, from actions that are suboptimal due to poor planning or execution to behaviors which are intended to communicate goals rather than achieve them.","We propose that supervised learning offers a unified framework to infer reward functions from any class of behavior, and show that such an approach is asymptotically Bayes-optimal under mild assumptions.","Experiments on simulated robotic manipulation tasks show that our method can efficiently infer rewards from a wide variety of arbitrarily suboptimal demonstrations."],"url":"http://arxiv.org/abs/2502.18447v1"}
{"created":"2025-02-25 18:38:38","title":"olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models","abstract":"PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models. However, these documents come in a diversity of types with differing formats and visual layouts that pose a challenge when attempting to extract and faithfully represent the underlying content for language model use. We present olmOCR, an open-source Python toolkit for processing PDFs into clean, linearized plain text in natural reading order while preserving structured content like sections, tables, lists, equations, and more. Our toolkit runs a fine-tuned 7B vision language model (VLM) trained on a sample of 260,000 pages from over 100,000 crawled PDFs with diverse properties, including graphics, handwritten text and poor quality scans. olmOCR is optimized for large-scale batch processing, able to scale flexibly to different hardware setups and convert a million PDF pages for only $190 USD. We release all components of olmOCR including VLM weights, data and training code, as well as inference code built on serving frameworks including vLLM and SGLang.","sentences":["PDF documents have the potential to provide trillions of novel, high-quality tokens for training language models.","However, these documents come in a diversity of types with differing formats and visual layouts that pose a challenge when attempting to extract and faithfully represent the underlying content for language model use.","We present olmOCR, an open-source Python toolkit for processing PDFs into clean, linearized plain text in natural reading order while preserving structured content like sections, tables, lists, equations, and more.","Our toolkit runs a fine-tuned 7B vision language model (VLM) trained on a sample of 260,000 pages from over 100,000 crawled PDFs with diverse properties, including graphics, handwritten text and poor quality scans.","olmOCR is optimized for large-scale batch processing, able to scale flexibly to different hardware setups and convert a million PDF pages for only $190 USD.","We release all components of olmOCR including VLM weights, data and training code, as well as inference code built on serving frameworks including vLLM and SGLang."],"url":"http://arxiv.org/abs/2502.18443v1"}
{"created":"2025-02-25 18:33:52","title":"The Introduction of README and CONTRIBUTING Files in Open Source Software Development","abstract":"README and CONTRIBUTING files can serve as the first point of contact for potential contributors to free/libre and open source software (FLOSS) projects. Prominent open source software organizations such as Mozilla, GitHub, and the Linux Foundation advocate that projects provide community-focused and process-oriented documentation early to foster recruitment and activity. In this paper we investigate the introduction of these documents in FLOSS projects, including whether early documentation conforms to these recommendations or explains subsequent activity. We use a novel dataset of FLOSS projects packaged by the Debian GNU/Linux distribution and conduct a quantitative analysis to examine README (n=4226) and CONTRIBUTING (n=714) files when they are first published into projects' repositories. We find that projects create minimal READMEs proactively, but often publish CONTRIBUTING files following an influx of contributions. The initial versions of these files rarely focus on community development, instead containing descriptions of project procedure for library usage or code contribution. The findings suggest that FLOSS projects do not create documentation with community-building in mind, but rather favor brevity and standardized instructions.","sentences":["README and CONTRIBUTING files can serve as the first point of contact for potential contributors to free/libre and open source software (FLOSS) projects.","Prominent open source software organizations such as Mozilla, GitHub, and the Linux Foundation advocate that projects provide community-focused and process-oriented documentation early to foster recruitment and activity.","In this paper we investigate the introduction of these documents in FLOSS projects, including whether early documentation conforms to these recommendations or explains subsequent activity.","We use a novel dataset of FLOSS projects packaged by the Debian GNU/Linux distribution and conduct a quantitative analysis to examine README (n=4226) and CONTRIBUTING (n=714) files when they are first published into projects' repositories.","We find that projects create minimal READMEs proactively, but often publish CONTRIBUTING files following an influx of contributions.","The initial versions of these files rarely focus on community development, instead containing descriptions of project procedure for library usage or code contribution.","The findings suggest that FLOSS projects do not create documentation with community-building in mind, but rather favor brevity and standardized instructions."],"url":"http://arxiv.org/abs/2502.18440v1"}
{"created":"2025-02-25 18:33:48","title":"MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning","abstract":"Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.","sentences":["Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential.","However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently.","In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks.","In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer.","In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions.","The score serves as the co-training reward, and is then maximized through multi-agent RL.","Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization.","Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration.","In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains."],"url":"http://arxiv.org/abs/2502.18439v1"}
{"created":"2025-02-25 18:31:55","title":"ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies","abstract":"In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories. It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world. We conducted several experiments using ToMCAT in a simulated cooking domain. Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance. We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them.","sentences":["In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories.","It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world.","We conducted several experiments using ToMCAT in a simulated cooking domain.","Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance.","We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them."],"url":"http://arxiv.org/abs/2502.18438v1"}
{"created":"2025-02-25 18:31:03","title":"CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing","abstract":"A number of recent studies have focused on developing surgical simulation platforms to train machine learning (ML) agents or models with synthetic data for surgical assistance. While existing platforms excel at tasks such as rigid body manipulation and soft body deformation, they struggle to simulate more complex soft body behaviors like cutting and suturing. A key challenge lies in modeling soft body fracture and splitting using the finite-element method (FEM), which is the predominant approach in current platforms. Additionally, the two-way suture needle/thread contact inside a soft body is further complicated when using FEM. In this work, we use the material point method (MPM) for such challenging simulations and propose new rigid geometries and soft-rigid contact methods specifically designed for them. We introduce CRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solvers and incorporates surgical geometries for cutting and suturing, serving as a specialized physics engine for surgical applications. It is further integrated into Unity, requiring minimal modifications to existing projects for soft body simulation. We demonstrate the simulator's capabilities in real-time simulation of cutting and suturing on soft tissue and provide an initial performance evaluation of different MPM solvers when simulating varying numbers of particles.","sentences":["A number of recent studies have focused on developing surgical simulation platforms to train machine learning (ML) agents or models with synthetic data for surgical assistance.","While existing platforms excel at tasks such as rigid body manipulation and soft body deformation, they struggle to simulate more complex soft body behaviors like cutting and suturing.","A key challenge lies in modeling soft body fracture and splitting using the finite-element method (FEM), which is the predominant approach in current platforms.","Additionally, the two-way suture needle/thread contact inside a soft body is further complicated when using FEM.","In this work, we use the material point method (MPM) for such challenging simulations and propose new rigid geometries and soft-rigid contact methods specifically designed for them.","We introduce CRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solvers and incorporates surgical geometries for cutting and suturing, serving as a specialized physics engine for surgical applications.","It is further integrated into Unity, requiring minimal modifications to existing projects for soft body simulation.","We demonstrate the simulator's capabilities in real-time simulation of cutting and suturing on soft tissue and provide an initial performance evaluation of different MPM solvers when simulating varying numbers of particles."],"url":"http://arxiv.org/abs/2502.18437v1"}
{"created":"2025-02-25 18:30:25","title":"Reversal Blessing: Thinking Backward May Outpace Thinking Forward in Multi-choice Questions","abstract":"Language models usually use left-to-right (L2R) autoregressive factorization. However, L2R factorization may not always be the best inductive bias. Therefore, we investigate whether alternative factorizations of the text distribution could be beneficial in some tasks. We investigate right-to-left (R2L) training as a compelling alternative, focusing on multiple-choice questions (MCQs) as a test bed for knowledge extraction and reasoning. Through extensive experiments across various model sizes (2B-8B parameters) and training datasets, we find that R2L models can significantly outperform L2R models on several MCQ benchmarks, including logical reasoning, commonsense understanding, and truthfulness assessment tasks. Our analysis reveals that this performance difference may be fundamentally linked to multiple factors including calibration, computability and directional conditional entropy. We ablate the impact of these factors through controlled simulation studies using arithmetic tasks, where the impacting factors can be better disentangled. Our work demonstrates that exploring alternative factorizations of the text distribution can lead to improvements in LLM capabilities and provides theoretical insights into optimal factorization towards approximating human language distribution, and when each reasoning order might be more advantageous.","sentences":["Language models usually use left-to-right (L2R) autoregressive factorization.","However, L2R factorization may not always be the best inductive bias.","Therefore, we investigate whether alternative factorizations of the text distribution could be beneficial in some tasks.","We investigate right-to-left (R2L) training as a compelling alternative, focusing on multiple-choice questions (MCQs) as a test bed for knowledge extraction and reasoning.","Through extensive experiments across various model sizes (2B-8B parameters) and training datasets, we find that R2L models can significantly outperform L2R models on several MCQ benchmarks, including logical reasoning, commonsense understanding, and truthfulness assessment tasks.","Our analysis reveals that this performance difference may be fundamentally linked to multiple factors including calibration, computability and directional conditional entropy.","We ablate the impact of these factors through controlled simulation studies using arithmetic tasks, where the impacting factors can be better disentangled.","Our work demonstrates that exploring alternative factorizations of the text distribution can lead to improvements in LLM capabilities and provides theoretical insights into optimal factorization towards approximating human language distribution, and when each reasoning order might be more advantageous."],"url":"http://arxiv.org/abs/2502.18435v1"}
{"created":"2025-02-25 18:29:38","title":"Exploring Gender Disparities in Automatic Speech Recognition Technology","abstract":"This study investigates factors influencing Automatic Speech Recognition (ASR) systems' fairness and performance across genders, beyond the conventional examination of demographics. Using the LibriSpeech dataset and the Whisper small model, we analyze how performance varies across different gender representations in training data. Our findings suggest a complex interplay between the gender ratio in training data and ASR performance. Optimal fairness occurs at specific gender distributions rather than a simple 50-50 split. Furthermore, our findings suggest that factors like pitch variability can significantly affect ASR accuracy. This research contributes to a deeper understanding of biases in ASR systems, highlighting the importance of carefully curated training data in mitigating gender bias.","sentences":["This study investigates factors influencing Automatic Speech Recognition (ASR) systems' fairness and performance across genders, beyond the conventional examination of demographics.","Using the LibriSpeech dataset and the Whisper small model, we analyze how performance varies across different gender representations in training data.","Our findings suggest a complex interplay between the gender ratio in training data and ASR performance.","Optimal fairness occurs at specific gender distributions rather than a simple 50-50 split.","Furthermore, our findings suggest that factors like pitch variability can significantly affect ASR accuracy.","This research contributes to a deeper understanding of biases in ASR systems, highlighting the importance of carefully curated training data in mitigating gender bias."],"url":"http://arxiv.org/abs/2502.18434v1"}
{"created":"2025-02-25 18:26:48","title":"TextGames: Learning to Self-Play Text-Based Puzzle Games via Language Model Reasoning","abstract":"Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems. In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning. Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection. Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks. In contrast, humans are capable of solving all tasks when given sufficient time. Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently. Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems.","sentences":["Reasoning is a fundamental capability of large language models (LLMs), enabling them to comprehend, analyze, and solve complex problems.","In this paper, we introduce TextGames, an innovative benchmark specifically crafted to assess LLMs through demanding text-based games that require advanced skills in pattern recognition, spatial awareness, arithmetic, and logical reasoning.","Our analysis probes LLMs' performance in both single-turn and multi-turn reasoning, and their abilities in leveraging feedback to correct subsequent answers through self-reflection.","Our findings reveal that, although LLMs exhibit proficiency in addressing most easy and medium-level problems, they face significant challenges with more difficult tasks.","In contrast, humans are capable of solving all tasks when given sufficient time.","Moreover, we observe that LLMs show improved performance in multi-turn predictions through self-reflection, yet they still struggle with sequencing, counting, and following complex rules consistently.","Additionally, models optimized for reasoning outperform pre-trained LLMs that prioritize instruction following, highlighting the crucial role of reasoning skills in addressing highly complex problems."],"url":"http://arxiv.org/abs/2502.18431v1"}
{"created":"2025-02-25 18:24:47","title":"Random Number Generation from Pulsars","abstract":"Pulsars exhibit signals with precise inter-arrival times that are on the order of milliseconds to seconds depending on the individual pulsar. There is subtle variation in the timing of pulsar signals, primarily due to the presence of gravitational waves, intrinsic variance in the period of the pulsar, and errors in the realization of Terrestrial Time (TT). Traditionally, these variations are dismissed as noise in high-precision timing experiments. In this paper, we show that these variations serve as a natural entropy source for the creation of Random Number Generators (RNG). We also explore the effects of using randomness extractors to increase the entropy of random bits extracted from Pulsar timing data. To evaluate the quality of the Pulsar RNG, we model its entropy as a $k$-source and use well-known cryptographic results to show its closeness to a theoretically ideal uniformly random source. To remain consistent with prior work, we also show that the Pulsar RNG passes well-known statistical tests such as the NIST test suite.","sentences":["Pulsars exhibit signals with precise inter-arrival times that are on the order of milliseconds to seconds depending on the individual pulsar.","There is subtle variation in the timing of pulsar signals, primarily due to the presence of gravitational waves, intrinsic variance in the period of the pulsar, and errors in the realization of Terrestrial Time (TT).","Traditionally, these variations are dismissed as noise in high-precision timing experiments.","In this paper, we show that these variations serve as a natural entropy source for the creation of Random Number Generators (RNG).","We also explore the effects of using randomness extractors to increase the entropy of random bits extracted from Pulsar timing data.","To evaluate the quality of the Pulsar RNG, we model its entropy as a $k$-source and use well-known cryptographic results to show its closeness to a theoretically ideal uniformly random source.","To remain consistent with prior work, we also show that the Pulsar RNG passes well-known statistical tests such as the NIST test suite."],"url":"http://arxiv.org/abs/2502.18430v1"}
{"created":"2025-02-25 18:21:30","title":"Is OpenAlex Suitable for Research Quality Evaluation and Which Citation Indicator is Best?","abstract":"This article compares (1) citation analysis with OpenAlex and Scopus, testing their citation counts, document type/coverage and subject classifications and (2) three citation-based indicators: raw counts, (field and year) Normalised Citation Scores (NCS) and Normalised Log-transformed Citation Scores (NLCS). Methods (1&2): The indicators calculated from 28.6 million articles were compared through 8,704 correlations on two gold standards for 97,816 UK Research Excellence Framework (REF) 2021 articles. The primary gold standard is ChatGPT scores, and the secondary is the average REF2021 expert review score for the department submitting the article. Results: (1) OpenAlex provides better citation counts than Scopus and its inclusive document classification/scope does not seem to cause substantial field normalisation problems. The broadest OpenAlex classification scheme provides the best indicators. (2) Counterintuitively, raw citation counts are at least as good as nearly all field normalised indicators, and better for single years, and NCS is better than NLCS. (1&2) There are substantial field differences. Thus, (1) OpenAlex is suitable for citation analysis in most fields and (2) the major citation-based indicators seem to work counterintuitively compared to quality judgements. Field normalisation seems ineffective because more cited fields tend to produce higher quality work, affecting interdisciplinary research or within-field topic differences.","sentences":["This article compares (1) citation analysis with OpenAlex and Scopus, testing their citation counts, document type/coverage and subject classifications and (2) three citation-based indicators: raw counts, (field and year)","Normalised Citation Scores (NCS) and Normalised Log-transformed Citation Scores (NLCS).","Methods (1&2): The indicators calculated from 28.6 million articles were compared through 8,704 correlations on two gold standards for 97,816 UK Research Excellence Framework (REF) 2021 articles.","The primary gold standard is ChatGPT scores, and the secondary is the average REF2021 expert review score for the department submitting the article.","Results: (1) OpenAlex provides better citation counts than Scopus and its inclusive document classification/scope does not seem to cause substantial field normalisation problems.","The broadest OpenAlex classification scheme provides the best indicators.","(2) Counterintuitively, raw citation counts are at least as good as nearly all field normalised indicators, and better for single years, and NCS is better than NLCS.","(1&2)","There are substantial field differences.","Thus, (1) OpenAlex is suitable for citation analysis in most fields and (2) the major citation-based indicators seem to work counterintuitively compared to quality judgements.","Field normalisation seems ineffective because more cited fields tend to produce higher quality work, affecting interdisciplinary research or within-field topic differences."],"url":"http://arxiv.org/abs/2502.18427v1"}
{"created":"2025-02-25 18:20:20","title":"PyEvalAI: AI-assisted evaluation of Jupyter Notebooks for immediate personalized feedback","abstract":"Grading student assignments in STEM courses is a laborious and repetitive task for tutors, often requiring a week to assess an entire class. For students, this delay of feedback prevents iterating on incorrect solutions, hampers learning, and increases stress when exercise scores determine admission to the final exam. Recent advances in AI-assisted education, such as automated grading and tutoring systems, aim to address these challenges by providing immediate feedback and reducing grading workload. However, existing solutions often fall short due to privacy concerns, reliance on proprietary closed-source models, lack of support for combining Markdown, LaTeX and Python code, or excluding course tutors from the grading process. To overcome these limitations, we introduce PyEvalAI, an AI-assisted evaluation system, which automatically scores Jupyter notebooks using a combination of unit tests and a locally hosted language model to preserve privacy. Our approach is free, open-source, and ensures tutors maintain full control over the grading process. A case study demonstrates its effectiveness in improving feedback speed and grading efficiency for exercises in a university-level course on numerics.","sentences":["Grading student assignments in STEM courses is a laborious and repetitive task for tutors, often requiring a week to assess an entire class.","For students, this delay of feedback prevents iterating on incorrect solutions, hampers learning, and increases stress when exercise scores determine admission to the final exam.","Recent advances in AI-assisted education, such as automated grading and tutoring systems, aim to address these challenges by providing immediate feedback and reducing grading workload.","However, existing solutions often fall short due to privacy concerns, reliance on proprietary closed-source models, lack of support for combining Markdown, LaTeX and Python code, or excluding course tutors from the grading process.","To overcome these limitations, we introduce PyEvalAI, an AI-assisted evaluation system, which automatically scores Jupyter notebooks using a combination of unit tests and a locally hosted language model to preserve privacy.","Our approach is free, open-source, and ensures tutors maintain full control over the grading process.","A case study demonstrates its effectiveness in improving feedback speed and grading efficiency for exercises in a university-level course on numerics."],"url":"http://arxiv.org/abs/2502.18425v1"}
{"created":"2025-02-25 18:20:00","title":"Compressing Language Models for Specialized Domains","abstract":"Compression techniques such as pruning and quantization offer a solution for more efficient deployment of language models (LMs), albeit with small performance drops in benchmark performance. However, general-purpose LM compression methods can negatively affect performance in specialized domains (e.g. biomedical or legal). Recent work has sought to address this, yet requires computationally expensive full-parameter fine-tuning. To this end, we propose cross-calibration, a novel training-free approach for improving the domain performance of compressed LMs. Our approach effectively leverages Hessian-based sensitivity to identify weights that are influential for both in-domain and general performance. Through extensive experimentation, we demonstrate that cross-calibration substantially outperforms existing approaches on domain-specific tasks, without compromising general performance. Notably, these gains come without additional computational overhead, displaying remarkable potential towards extracting domain-specialized compressed models from general-purpose LMs.","sentences":["Compression techniques such as pruning and quantization offer a solution for more efficient deployment of language models (LMs), albeit with small performance drops in benchmark performance.","However, general-purpose LM compression methods can negatively affect performance in specialized domains (e.g. biomedical or legal).","Recent work has sought to address this, yet requires computationally expensive full-parameter fine-tuning.","To this end, we propose cross-calibration, a novel training-free approach for improving the domain performance of compressed LMs.","Our approach effectively leverages Hessian-based sensitivity to identify weights that are influential for both in-domain and general performance.","Through extensive experimentation, we demonstrate that cross-calibration substantially outperforms existing approaches on domain-specific tasks, without compromising general performance.","Notably, these gains come without additional computational overhead, displaying remarkable potential towards extracting domain-specialized compressed models from general-purpose LMs."],"url":"http://arxiv.org/abs/2502.18424v1"}
{"created":"2025-02-25 18:19:57","title":"Retrieval Dexterity: Efficient Object Retrieval in Clutters with Dexterous Hand","abstract":"Retrieving objects buried beneath multiple objects is not only challenging but also time-consuming. Performing manipulation in such environments presents significant difficulty due to complex contact relationships. Existing methods typically address this task by sequentially grasping and removing each occluding object, resulting in lengthy execution times and requiring impractical grasping capabilities for every occluding object. In this paper, we present a dexterous arm-hand system for efficient object retrieval in multi-object stacked environments. Our approach leverages large-scale parallel reinforcement learning within diverse and carefully designed cluttered environments to train policies. These policies demonstrate emergent manipulation skills (e.g., pushing, stirring, and poking) that efficiently clear occluding objects to expose sufficient surface area of the target object. We conduct extensive evaluations across a set of over 10 household objects in diverse clutter configurations, demonstrating superior retrieval performance and efficiency for both trained and unseen objects. Furthermore, we successfully transfer the learned policies to a real-world dexterous multi-fingered robot system, validating their practical applicability in real-world scenarios. Videos can be found on our project website https://ChangWinde.github.io/RetrDex.","sentences":["Retrieving objects buried beneath multiple objects is not only challenging but also time-consuming.","Performing manipulation in such environments presents significant difficulty due to complex contact relationships.","Existing methods typically address this task by sequentially grasping and removing each occluding object, resulting in lengthy execution times and requiring impractical grasping capabilities for every occluding object.","In this paper, we present a dexterous arm-hand system for efficient object retrieval in multi-object stacked environments.","Our approach leverages large-scale parallel reinforcement learning within diverse and carefully designed cluttered environments to train policies.","These policies demonstrate emergent manipulation skills (e.g., pushing, stirring, and poking) that efficiently clear occluding objects to expose sufficient surface area of the target object.","We conduct extensive evaluations across a set of over 10 household objects in diverse clutter configurations, demonstrating superior retrieval performance and efficiency for both trained and unseen objects.","Furthermore, we successfully transfer the learned policies to a real-world dexterous multi-fingered robot system, validating their practical applicability in real-world scenarios.","Videos can be found on our project website https://ChangWinde.github.io/RetrDex."],"url":"http://arxiv.org/abs/2502.18423v1"}
{"created":"2025-02-25 18:14:06","title":"Rank1: Test-Time Compute for Reranking in Information Retrieval","abstract":"We introduce Rank1, the first reranking model trained to take advantage of test-time compute. Rank1 demonstrates the applicability within retrieval of using a reasoning language model (i.e. OpenAI's o1, Deepseek's R1, etc.) for distillation in order to rapidly improve the performance of a smaller model. We gather and open-source a dataset of more than 600,000 examples of R1 reasoning traces from queries and passages in MS MARCO. Models trained on this dataset show: (1) state-of-the-art performance on advanced reasoning and instruction following datasets; (2) work remarkably well out of distribution due to the ability to respond to user-input prompts; and (3) have explainable reasoning chains that can be given to users or RAG-based systems. Further, we demonstrate that quantized versions of these models retain strong performance while using less compute/memory. Overall, Rank1 shows that test-time compute allows for a fundamentally new type of explainable and performant reranker model for search.","sentences":["We introduce Rank1, the first reranking model trained to take advantage of test-time compute.","Rank1 demonstrates the applicability within retrieval of using a reasoning language model (i.e. OpenAI's o1, Deepseek's R1, etc.) for distillation in order to rapidly improve the performance of a smaller model.","We gather and open-source a dataset of more than 600,000 examples of R1 reasoning traces from queries and passages in MS MARCO.","Models trained on this dataset show: (1) state-of-the-art performance on advanced reasoning and instruction following datasets; (2) work remarkably well out of distribution due to the ability to respond to user-input prompts; and (3) have explainable reasoning chains that can be given to users or RAG-based systems.","Further, we demonstrate that quantized versions of these models retain strong performance while using less compute/memory.","Overall, Rank1 shows that test-time compute allows for a fundamentally new type of explainable and performant reranker model for search."],"url":"http://arxiv.org/abs/2502.18418v1"}
{"created":"2025-02-25 18:13:55","title":"GHOST 2.0: generative high-fidelity one shot transfer of heads","abstract":"While the task of face swapping has recently gained attention in the research community, a related problem of head swapping remains largely unexplored. In addition to skin color transfer, head swap poses extra challenges, such as the need to preserve structural information of the whole head during synthesis and inpaint gaps between swapped head and background. In this paper, we address these concerns with GHOST 2.0, which consists of two problem-specific modules. First, we introduce enhanced Aligner model for head reenactment, which preserves identity information at multiple scales and is robust to extreme pose variations. Secondly, we use a Blender module that seamlessly integrates the reenacted head into the target background by transferring skin color and inpainting mismatched regions. Both modules outperform the baselines on the corresponding tasks, allowing to achieve state of the art results in head swapping. We also tackle complex cases, such as large difference in hair styles of source and target.","sentences":["While the task of face swapping has recently gained attention in the research community, a related problem of head swapping remains largely unexplored.","In addition to skin color transfer, head swap poses extra challenges, such as the need to preserve structural information of the whole head during synthesis and inpaint gaps between swapped head and background.","In this paper, we address these concerns with GHOST 2.0, which consists of two problem-specific modules.","First, we introduce enhanced Aligner model for head reenactment, which preserves identity information at multiple scales and is robust to extreme pose variations.","Secondly, we use a Blender module that seamlessly integrates the reenacted head into the target background by transferring skin color and inpainting mismatched regions.","Both modules outperform the baselines on the corresponding tasks, allowing to achieve state of the art results in head swapping.","We also tackle complex cases, such as large difference in hair styles of source and target."],"url":"http://arxiv.org/abs/2502.18417v1"}
{"created":"2025-02-25 18:12:08","title":"MedKAN: An Advanced Kolmogorov-Arnold Network for Medical Image Classification","abstract":"Recent advancements in deep learning for image classification predominantly rely on convolutional neural networks (CNNs) or Transformer-based architectures. However, these models face notable challenges in medical imaging, particularly in capturing intricate texture details and contextual features. Kolmogorov-Arnold Networks (KANs) represent a novel class of architectures that enhance nonlinear transformation modeling, offering improved representation of complex features. In this work, we present MedKAN, a medical image classification framework built upon KAN and its convolutional extensions. MedKAN features two core modules: the Local Information KAN (LIK) module for fine-grained feature extraction and the Global Information KAN (GIK) module for global context integration. By combining these modules, MedKAN achieves robust feature modeling and fusion. To address diverse computational needs, we introduce three scalable variants--MedKAN-S, MedKAN-B, and MedKAN-L. Experimental results on nine public medical imaging datasets demonstrate that MedKAN achieves superior performance compared to CNN- and Transformer-based models, highlighting its effectiveness and generalizability in medical image analysis.","sentences":["Recent advancements in deep learning for image classification predominantly rely on convolutional neural networks (CNNs) or Transformer-based architectures.","However, these models face notable challenges in medical imaging, particularly in capturing intricate texture details and contextual features.","Kolmogorov-Arnold Networks (KANs) represent a novel class of architectures that enhance nonlinear transformation modeling, offering improved representation of complex features.","In this work, we present MedKAN, a medical image classification framework built upon KAN and its convolutional extensions.","MedKAN features two core modules: the Local Information KAN (LIK) module for fine-grained feature extraction and the Global Information KAN (GIK) module for global context integration.","By combining these modules, MedKAN achieves robust feature modeling and fusion.","To address diverse computational needs, we introduce three scalable variants--MedKAN-S, MedKAN-B, and MedKAN-L. Experimental results on nine public medical imaging datasets demonstrate that MedKAN achieves superior performance compared to CNN- and Transformer-based models, highlighting its effectiveness and generalizability in medical image analysis."],"url":"http://arxiv.org/abs/2502.18416v1"}
{"created":"2025-02-25 18:11:37","title":"GLEAN: Generalized Category Discovery with Diverse and Quality-Enhanced LLM Feedback","abstract":"Generalized Category Discovery (GCD) is a practical and challenging open-world task that aims to recognize both known and novel categories in unlabeled data using limited labeled data from known categories. Due to the lack of supervision, previous GCD methods face significant challenges, such as difficulty in rectifying errors for confusing instances, and inability to effectively uncover and leverage the semantic meanings of discovered clusters. Therefore, additional annotations are usually required for real-world applicability. However, human annotation is extremely costly and inefficient. To address these issues, we propose GLEAN, a unified framework for generalized category discovery that actively learns from diverse and quality-enhanced LLM feedback. Our approach leverages three different types of LLM feedback to: (1) improve instance-level contrastive features, (2) generate category descriptions, and (3) align uncertain instances with LLM-selected category descriptions. Extensive experiments demonstrate the superior performance of \\MethodName over state-of-the-art models across diverse datasets, metrics, and supervision settings. Our code is available at https://github.com/amazon-science/Glean.","sentences":["Generalized Category Discovery (GCD) is a practical and challenging open-world task that aims to recognize both known and novel categories in unlabeled data using limited labeled data from known categories.","Due to the lack of supervision, previous GCD methods face significant challenges, such as difficulty in rectifying errors for confusing instances, and inability to effectively uncover and leverage the semantic meanings of discovered clusters.","Therefore, additional annotations are usually required for real-world applicability.","However, human annotation is extremely costly and inefficient.","To address these issues, we propose GLEAN, a unified framework for generalized category discovery that actively learns from diverse and quality-enhanced LLM feedback.","Our approach leverages three different types of LLM feedback to: (1) improve instance-level contrastive features, (2) generate category descriptions, and (3) align uncertain instances with LLM-selected category descriptions.","Extensive experiments demonstrate the superior performance of \\MethodName over state-of-the-art models across diverse datasets, metrics, and supervision settings.","Our code is available at https://github.com/amazon-science/Glean."],"url":"http://arxiv.org/abs/2502.18414v1"}
{"created":"2025-02-25 18:06:18","title":"When Benchmarks Talk: Re-Evaluating Code LLMs with Interactive Feedback","abstract":"Programming is a fundamentally interactive process, yet coding assistants are often evaluated using static benchmarks that fail to measure how well models collaborate with users. We introduce an interactive evaluation pipeline to examine how LLMs incorporate different types of feedback in a collaborative setting. Specifically, we perturb static coding benchmarks so that the code model must interact with a simulated user to retrieve key information about the problem. We find that interaction significantly affects model performance, as the relative rankings of 10 models across 3 datasets often vary between static and interactive settings, despite models being fairly robust to feedback that contains errors. We also observe that even when different feedback types are equally effective with respect to performance, they can impact model behaviors such as (1) how models respond to higher- vs. lower-quality feedback and (2) whether models prioritize aesthetic vs. functional edits. Our work aims to \"re-evaluate\" model coding capabilities through an interactive lens toward bridging the gap between existing evaluations and real-world usage.","sentences":["Programming is a fundamentally interactive process, yet coding assistants are often evaluated using static benchmarks that fail to measure how well models collaborate with users.","We introduce an interactive evaluation pipeline to examine how LLMs incorporate different types of feedback in a collaborative setting.","Specifically, we perturb static coding benchmarks so that the code model must interact with a simulated user to retrieve key information about the problem.","We find that interaction significantly affects model performance, as the relative rankings of 10 models across 3 datasets often vary between static and interactive settings, despite models being fairly robust to feedback that contains errors.","We also observe that even when different feedback types are equally effective with respect to performance, they can impact model behaviors such as (1) how models respond to higher- vs. lower-quality feedback and (2) whether models prioritize aesthetic vs. functional edits.","Our work aims to \"re-evaluate\" model coding capabilities through an interactive lens toward bridging the gap between existing evaluations and real-world usage."],"url":"http://arxiv.org/abs/2502.18413v1"}
{"created":"2025-02-25 18:05:46","title":"Comparative Analysis of MDL-VAE vs. Standard VAE on 202 Years of Gynecological Data","abstract":"This study presents a comparative evaluation of a Variational Autoencoder (VAE) enhanced with Minimum Description Length (MDL) regularization against a Standard Autoencoder for reconstructing high-dimensional gynecological data. The MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE) and more structured latent representations, driven by effective KL divergence regularization. Statistical analyses confirm these performance improvements are significant. Furthermore, the MDL-VAE shows consistent training and validation losses and achieves efficient inference times, underscoring its robustness and practical viability. Our findings suggest that incorporating MDL principles into VAE architectures can substantially improve data reconstruction and generalization, making it a promising approach for advanced applications in healthcare data modeling and analysis.","sentences":["This study presents a comparative evaluation of a Variational Autoencoder (VAE) enhanced with Minimum Description Length (MDL) regularization against a Standard Autoencoder for reconstructing high-dimensional gynecological data.","The MDL-VAE exhibits significantly lower reconstruction errors (MSE, MAE, RMSE) and more structured latent representations, driven by effective KL divergence regularization.","Statistical analyses confirm these performance improvements are significant.","Furthermore, the MDL-VAE shows consistent training and validation losses and achieves efficient inference times, underscoring its robustness and practical viability.","Our findings suggest that incorporating MDL principles into VAE architectures can substantially improve data reconstruction and generalization, making it a promising approach for advanced applications in healthcare data modeling and analysis."],"url":"http://arxiv.org/abs/2502.18412v1"}
{"created":"2025-02-25 18:05:14","title":"OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference","abstract":"Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment. This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featuring diverse images, complex questions, and varied response formats to improve MLLMs' alignment with human preferences. We also present MM-AlignBench, a human-annotated benchmark specifically designed to evaluate MLLMs' alignment with human values. Experimental results show that finetuning MLLMs with OmniAlign-V, using Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO), significantly enhances human preference alignment while maintaining or enhancing performance on standard VQA benchmarks, preserving their fundamental capabilities. Our datasets, benchmark, code and checkpoints have been released at https://github.com/PhoenixZ810/OmniAlign-V.","sentences":["Recent advancements in open-source multi-modal large language models (MLLMs) have primarily focused on enhancing foundational capabilities, leaving a significant gap in human preference alignment.","This paper introduces OmniAlign-V, a comprehensive dataset of 200K high-quality training samples featuring diverse images, complex questions, and varied response formats to improve MLLMs' alignment with human preferences.","We also present MM-AlignBench, a human-annotated benchmark specifically designed to evaluate MLLMs' alignment with human values.","Experimental results show that finetuning MLLMs with OmniAlign-V, using Supervised Fine-Tuning (SFT) or Direct Preference Optimization (DPO), significantly enhances human preference alignment while maintaining or enhancing performance on standard VQA benchmarks, preserving their fundamental capabilities.","Our datasets, benchmark, code and checkpoints have been released at https://github.com/PhoenixZ810/OmniAlign-V."],"url":"http://arxiv.org/abs/2502.18411v1"}
{"created":"2025-02-25 18:04:45","title":"TSKANMixer: Kolmogorov-Arnold Networks with MLP-Mixer Model for Time Series Forecasting","abstract":"Time series forecasting has long been a focus of research across diverse fields, including economics, energy, healthcare, and traffic management. Recent works have introduced innovative architectures for time series models, such as the Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs) to enhance prediction accuracy by effectively capturing both spatial and temporal dependencies within the data. In this paper, we investigate the capabilities of the Kolmogorov-Arnold Networks (KANs) for time-series forecasting by modifying TSMixer with a KAN layer (TSKANMixer). Experimental results demonstrate that TSKANMixer tends to improve prediction accuracy over the original TSMixer across multiple datasets, ranking among the top-performing models compared to other time series approaches. Our results show that the KANs are promising alternatives to improve the performance of time series forecasting by replacing or extending traditional MLPs.","sentences":["Time series forecasting has long been a focus of research across diverse fields, including economics, energy, healthcare, and traffic management.","Recent works have introduced innovative architectures for time series models, such as the Time-Series Mixer (TSMixer), which leverages multi-layer perceptrons (MLPs) to enhance prediction accuracy by effectively capturing both spatial and temporal dependencies within the data.","In this paper, we investigate the capabilities of the Kolmogorov-Arnold Networks (KANs) for time-series forecasting by modifying TSMixer with a KAN layer (TSKANMixer).","Experimental results demonstrate that TSKANMixer tends to improve prediction accuracy over the original TSMixer across multiple datasets, ranking among the top-performing models compared to other time series approaches.","Our results show that the KANs are promising alternatives to improve the performance of time series forecasting by replacing or extending traditional MLPs."],"url":"http://arxiv.org/abs/2502.18410v1"}
{"created":"2025-02-25 17:58:02","title":"AgentRM: Enhancing Agent Generalization with Reward Modeling","abstract":"Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area.","sentences":["Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor.","Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability.","In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model.","Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search.","We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge.","We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search.","On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model.","As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks.","Further analysis verifies its effectiveness in test-time scaling.","Codes will be released to facilitate the research in this area."],"url":"http://arxiv.org/abs/2502.18407v1"}
{"created":"2025-02-25 17:57:55","title":"The Gradient of Algebraic Model Counting","abstract":"Algebraic model counting unifies many inference tasks on logic formulas by exploiting semirings. Rather than focusing on inference, we consider learning, especially in statistical-relational and neurosymbolic AI, which combine logical, probabilistic and neural representations. Concretely, we show that the very same semiring perspective of algebraic model counting also applies to learning. This allows us to unify various learning algorithms by generalizing gradients and backpropagation to different semirings. Furthermore, we show how cancellation and ordering properties of a semiring can be exploited for more memory-efficient backpropagation. This allows us to obtain some interesting variations of state-of-the-art gradient-based optimisation methods for probabilistic logical models. We also discuss why algebraic model counting on tractable circuits does not lead to more efficient second-order optimization. Empirically, our algebraic backpropagation exhibits considerable speed-ups as compared to existing approaches.","sentences":["Algebraic model counting unifies many inference tasks on logic formulas by exploiting semirings.","Rather than focusing on inference, we consider learning, especially in statistical-relational and neurosymbolic AI, which combine logical, probabilistic and neural representations.","Concretely, we show that the very same semiring perspective of algebraic model counting also applies to learning.","This allows us to unify various learning algorithms by generalizing gradients and backpropagation to different semirings.","Furthermore, we show how cancellation and ordering properties of a semiring can be exploited for more memory-efficient backpropagation.","This allows us to obtain some interesting variations of state-of-the-art gradient-based optimisation methods for probabilistic logical models.","We also discuss why algebraic model counting on tractable circuits does not lead to more efficient second-order optimization.","Empirically, our algebraic backpropagation exhibits considerable speed-ups as compared to existing approaches."],"url":"http://arxiv.org/abs/2502.18406v1"}
{"created":"2025-02-25 17:56:25","title":"Enhancing DNA Foundation Models to Address Masking Inefficiencies","abstract":"Masked language modelling (MLM) as a pretraining objective has been widely adopted in genomic sequence modelling. While pretrained models can successfully serve as encoders for various downstream tasks, the distribution shift between pretraining and inference detrimentally impacts performance, as the pretraining task is to map [MASK] tokens to predictions, yet the [MASK] is absent during downstream applications. This means the encoder does not prioritize its encodings of non-[MASK] tokens, and expends parameters and compute on work only relevant to the MLM task, despite this being irrelevant at deployment time. In this work, we propose a modified encoder-decoder architecture based on the masked autoencoder framework, designed to address this inefficiency within a BERT-based transformer. We empirically show that the resulting mismatch is particularly detrimental in genomic pipelines where models are often used for feature extraction without fine-tuning. We evaluate our approach on the BIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes. We achieve substantial performance gains in both closed-world and open-world classification tasks when compared against causal models and bidirectional architectures pretrained with MLM tasks.","sentences":["Masked language modelling (MLM) as a pretraining objective has been widely adopted in genomic sequence modelling.","While pretrained models can successfully serve as encoders for various downstream tasks, the distribution shift between pretraining and inference detrimentally impacts performance, as the pretraining task is to map [MASK] tokens to predictions, yet the [MASK] is absent during downstream applications.","This means the encoder does not prioritize its encodings of non-[MASK] tokens, and expends parameters and compute on work only relevant to the MLM task, despite this being irrelevant at deployment time.","In this work, we propose a modified encoder-decoder architecture based on the masked autoencoder framework, designed to address this inefficiency within a BERT-based transformer.","We empirically show that the resulting mismatch is particularly detrimental in genomic pipelines where models are often used for feature extraction without fine-tuning.","We evaluate our approach on the BIOSCAN-5M dataset, comprising over 2 million unique DNA barcodes.","We achieve substantial performance gains in both closed-world and open-world classification tasks when compared against causal models and bidirectional architectures pretrained with MLM tasks."],"url":"http://arxiv.org/abs/2502.18405v1"}
{"created":"2025-02-25 17:52:53","title":"Equidistant-Sample or Wait-and-Sample to Minimize Age Under Sampling Constraint?","abstract":"We study a status update system with a source, a sampler, a transmitter, and a monitor. The source governs a stochastic process that the monitor wants to observe in a timely manner. To achieve this, the sampler samples fresh update packets which the transmitter transmits via an error prone communication channel to the monitor. The transmitter can transmit without any constraint, i.e., it can transmit whenever an update packet is available to the transmitter. However, the sampler is imposed with a sampling rate constraint. The goal of the sampler is to devise an optimal policy that satisfies the resource constraint while minimizing the age of the monitor. We formulate this problem as a constrained Markov decision process (CMDP). We find several structures of an optimal policy. We leverage the optimal structures to find a low complexity optimal policy in an explicit manner, without resorting to complex iterative schemes or techniques that require bounding the age.","sentences":["We study a status update system with a source, a sampler, a transmitter, and a monitor.","The source governs a stochastic process that the monitor wants to observe in a timely manner.","To achieve this, the sampler samples fresh update packets which the transmitter transmits via an error prone communication channel to the monitor.","The transmitter can transmit without any constraint, i.e., it can transmit whenever an update packet is available to the transmitter.","However, the sampler is imposed with a sampling rate constraint.","The goal of the sampler is to devise an optimal policy that satisfies the resource constraint while minimizing the age of the monitor.","We formulate this problem as a constrained Markov decision process (CMDP).","We find several structures of an optimal policy.","We leverage the optimal structures to find a low complexity optimal policy in an explicit manner, without resorting to complex iterative schemes or techniques that require bounding the age."],"url":"http://arxiv.org/abs/2502.18404v1"}
{"created":"2025-02-25 17:52:01","title":"Kitsune: Enabling Dataflow Execution on GPUs","abstract":"State of art DL models are growing in size and complexity, with many modern models also increasing in heterogeneity of behavior. GPUs are still the dominant platform for DL applications, relying on a bulk-synchronous execution model which has many drawbacks and is ill-suited for the graph structure of DL applications. Many industry and academic works attempt to overcome these by employing vertical fusion but this approach still fails to realize three untapped opportunities: (1) the fact that many resources on the GPU are idle while only one operator executes due to temporal multiplexing of the SM; (2) lower energy from more intelligent on-chip data-movement which lends to higher performance in a power-provisioned environment. (3) inability to exploit hidden or reduction dimensions as a source of parallelism to ease pressure on batch size. This paper explores relatively uncharted territory, answering the following key question: Can modest adjustments to the current GPU architecture enable efficient dataflow execution, thereby circumventing the constraints of vertical fusion without necessitating a clean-slate architecture design. We develop Kitsune -- a set of primitives that enable dataflow execution on GPUs and an end-to-end compiler based on PyTorch Dynamo. Across 5 challenge applications, Kitsune can provide 1.3$\\times$-2.3$\\times$ and 1.1$\\times$-2.4$\\times$ performance improvement as well as 41%-98% and 16%-42% off-chip traffic reduction for inference and training, respectively.","sentences":["State of art DL models are growing in size and complexity, with many modern models also increasing in heterogeneity of behavior.","GPUs are still the dominant platform for DL applications, relying on a bulk-synchronous execution model which has many drawbacks and is ill-suited for the graph structure of DL applications.","Many industry and academic works attempt to overcome these by employing vertical fusion but this approach still fails to realize three untapped opportunities: (1) the fact that many resources on the GPU are idle while only one operator executes due to temporal multiplexing of the SM; (2) lower energy from more intelligent on-chip data-movement which lends to higher performance in a power-provisioned environment.","(3) inability to exploit hidden or reduction dimensions as a source of parallelism to ease pressure on batch size.","This paper explores relatively uncharted territory, answering the following key question: Can modest adjustments to the current GPU architecture enable efficient dataflow execution, thereby circumventing the constraints of vertical fusion without necessitating a clean-slate architecture design.","We develop Kitsune -- a set of primitives that enable dataflow execution on GPUs and an end-to-end compiler based on PyTorch Dynamo.","Across 5 challenge applications, Kitsune can provide 1.3$\\times$-2.3$\\times$ and 1.1$\\times$-2.4$\\times$ performance improvement as well as 41%-98% and 16%-42% off-chip traffic reduction for inference and training, respectively."],"url":"http://arxiv.org/abs/2502.18403v1"}
{"created":"2025-02-25 17:47:53","title":"KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation","abstract":"Iterative retrieval-augmented generation (iRAG) models offer an effective approach for multi-hop question answering (QA). However, their retrieval process faces two key challenges: (1) it can be disrupted by irrelevant documents or factually inaccurate chain-of-thoughts; (2) their retrievers are not designed to dynamically adapt to the evolving information needs in multi-step reasoning, making it difficult to identify and retrieve the missing information required at each iterative step. Therefore, we propose KiRAG, which uses a knowledge-driven iterative retriever model to enhance the retrieval process of iRAG. Specifically, KiRAG decomposes documents into knowledge triples and performs iterative retrieval with these triples to enable a factually reliable retrieval process. Moreover, KiRAG integrates reasoning into the retrieval process to dynamically identify and retrieve knowledge that bridges information gaps, effectively adapting to the evolving information needs. Empirical results show that KiRAG significantly outperforms existing iRAG models, with an average improvement of 9.40% in R@3 and 5.14% in F1 on multi-hop QA.","sentences":["Iterative retrieval-augmented generation (iRAG) models offer an effective approach for multi-hop question answering (QA).","However, their retrieval process faces two key challenges: (1) it can be disrupted by irrelevant documents or factually inaccurate chain-of-thoughts; (2) their retrievers are not designed to dynamically adapt to the evolving information needs in multi-step reasoning, making it difficult to identify and retrieve the missing information required at each iterative step.","Therefore, we propose KiRAG, which uses a knowledge-driven iterative retriever model to enhance the retrieval process of iRAG.","Specifically, KiRAG decomposes documents into knowledge triples and performs iterative retrieval with these triples to enable a factually reliable retrieval process.","Moreover, KiRAG integrates reasoning into the retrieval process to dynamically identify and retrieve knowledge that bridges information gaps, effectively adapting to the evolving information needs.","Empirical results show that KiRAG significantly outperforms existing iRAG models, with an average improvement of 9.40% in R@3 and 5.14% in F1 on multi-hop QA."],"url":"http://arxiv.org/abs/2502.18397v1"}
{"created":"2025-02-25 17:45:42","title":"\"Why do we do this?\": Moral Stress and the Affective Experience of Ethics in Practice","abstract":"A plethora of toolkits, checklists, and workshops have been developed to bridge the well-documented gap between AI ethics principles and practice. Yet little is known about effects of such interventions on practitioners. We conducted an ethnographic investigation in a major European city organization that developed and works to integrate an ethics toolkit into city operations. We find that the integration of ethics tools by technical teams destabilises their boundaries, roles, and mandates around responsibilities and decisions. This lead to emotional discomfort and feelings of vulnerability, which neither toolkit designers nor the organization had accounted for. We leverage the concept of moral stress to argue that this affective experience is a core challenge to the successful integration of ethics tools in technical practice. Even in this best case scenario, organisational structures were not able to deal with moral stress that resulted from attempts to implement responsible technology development practices.","sentences":["A plethora of toolkits, checklists, and workshops have been developed to bridge the well-documented gap between AI ethics principles and practice.","Yet little is known about effects of such interventions on practitioners.","We conducted an ethnographic investigation in a major European city organization that developed and works to integrate an ethics toolkit into city operations.","We find that the integration of ethics tools by technical teams destabilises their boundaries, roles, and mandates around responsibilities and decisions.","This lead to emotional discomfort and feelings of vulnerability, which neither toolkit designers nor the organization had accounted for.","We leverage the concept of moral stress to argue that this affective experience is a core challenge to the successful integration of ethics tools in technical practice.","Even in this best case scenario, organisational structures were not able to deal with moral stress that resulted from attempts to implement responsible technology development practices."],"url":"http://arxiv.org/abs/2502.18395v1"}
{"created":"2025-02-25 17:43:43","title":"The FFT Strikes Back: An Efficient Alternative to Self-Attention","abstract":"Conventional self-attention mechanisms incur quadratic complexity, limiting their scalability on long sequences. We introduce FFTNet, an adaptive spectral filtering framework that leverages the Fast Fourier Transform (FFT) to achieve global token mixing in $\\mathcal{O}(n\\log n)$ time. By transforming inputs into the frequency domain, FFTNet exploits the orthogonality and energy preservation guaranteed by Parseval's theorem to capture long-range dependencies efficiently. A learnable spectral filter and modReLU activation dynamically emphasize salient frequency components, providing a rigorous and adaptive alternative to traditional self-attention. Experiments on the Long Range Arena and ImageNet benchmarks validate our theoretical insights and demonstrate superior performance over fixed Fourier and standard attention models.","sentences":["Conventional self-attention mechanisms incur quadratic complexity, limiting their scalability on long sequences.","We introduce FFTNet, an adaptive spectral filtering framework that leverages the Fast Fourier Transform (FFT) to achieve global token mixing in $\\mathcal{O}(n\\log n)$ time.","By transforming inputs into the frequency domain, FFTNet exploits the orthogonality and energy preservation guaranteed by Parseval's theorem to capture long-range dependencies efficiently.","A learnable spectral filter and modReLU activation dynamically emphasize salient frequency components, providing a rigorous and adaptive alternative to traditional self-attention.","Experiments on the Long Range Arena and ImageNet benchmarks validate our theoretical insights and demonstrate superior performance over fixed Fourier and standard attention models."],"url":"http://arxiv.org/abs/2502.18394v1"}
{"created":"2025-02-25 17:35:01","title":"Unbent Collections of Orthogonal Drawings","abstract":"Recently, there has been interest in representing single graphs by multiple drawings; for example, using graph stories, storyplans, or uncrossed collections. In this paper, we apply this idea to orthogonal graph drawing. Due to the orthogonal drawing style, we focus on plane 4-graphs, that is, planar graphs of maximum degree 4 whose embedding is fixed. Our goal is to represent any plane 4-graph $G$ by an unbent collection, that is, a collection of orthogonal drawings of $G$ that adhere to the embedding of $G$ and ensure that each edge of $G$ is drawn without bends in at least one of the drawings. We investigate two objectives. First, we consider minimizing the number of drawings in an unbent collection. We prove that every plane 4-graph can be represented by a collection with at most three drawings, which is tight. We also give sufficient conditions for a graph to admit an unbent collection of size 2. Second, we consider minimizing the total number of bends over all drawings in an unbent collection. We show that this problem is NP-hard and give a 3-approximation algorithm. For the special case of plane triconnected cubic graphs, we show how to compute minimum-bend collections in linear time.","sentences":["Recently, there has been interest in representing single graphs by multiple drawings; for example, using graph stories, storyplans, or uncrossed collections.","In this paper, we apply this idea to orthogonal graph drawing.","Due to the orthogonal drawing style, we focus on plane 4-graphs, that is, planar graphs of maximum degree 4 whose embedding is fixed.","Our goal is to represent any plane 4-graph $G$ by an unbent collection, that is, a collection of orthogonal drawings of $G$ that adhere to the embedding of $G$ and ensure that each edge of $G$ is drawn without bends in at least one of the drawings.","We investigate two objectives.","First, we consider minimizing the number of drawings in an unbent collection.","We prove that every plane 4-graph can be represented by a collection with at most three drawings, which is tight.","We also give sufficient conditions for a graph to admit an unbent collection of size 2.","Second, we consider minimizing the total number of bends over all drawings in an unbent collection.","We show that this problem is NP-hard and give a 3-approximation algorithm.","For the special case of plane triconnected cubic graphs, we show how to compute minimum-bend collections in linear time."],"url":"http://arxiv.org/abs/2502.18390v1"}
{"created":"2025-02-25 17:33:20","title":"Monte Carlo Temperature: a robust sampling strategy for LLM's uncertainty quantification methods","abstract":"Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences. Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation. However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates. The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination. We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration. Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process. These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration.","sentences":["Uncertainty quantification (UQ) in Large Language Models (LLMs) is essential for their safe and reliable deployment, particularly in critical applications where incorrect outputs can have serious consequences.","Current UQ methods typically rely on querying the model multiple times using non-zero temperature sampling to generate diverse outputs for uncertainty estimation.","However, the impact of selecting a given temperature parameter is understudied, and our analysis reveals that temperature plays a fundamental role in the quality of uncertainty estimates.","The conventional approach of identifying optimal temperature values requires expensive hyperparameter optimization (HPO) that must be repeated for each new model-dataset combination.","We propose Monte Carlo Temperature (MCT), a robust sampling strategy that eliminates the need for temperature calibration.","Our analysis reveals that: 1) MCT provides more robust uncertainty estimates across a wide range of temperatures, 2) MCT improves the performance of UQ methods by replacing fixed-temperature strategies that do not rely on HPO, and 3) MCT achieves statistical parity with oracle temperatures, which represent the ideal outcome of a well-tuned but computationally expensive HPO process.","These findings demonstrate that effective UQ can be achieved without the computational burden of temperature parameter calibration."],"url":"http://arxiv.org/abs/2502.18389v1"}
{"created":"2025-02-25 17:30:40","title":"How Far are LLMs from Real Search? A Comprehensive Study on Efficiency, Completeness, and Inherent Capabilities","abstract":"Search plays a fundamental role in problem-solving across various domains, with most real-world decision-making problems being solvable through systematic search. Drawing inspiration from recent discussions on search and learning, we systematically explore the complementary relationship between search and Large Language Models (LLMs) from three perspectives. First, we analyze how learning can enhance search efficiency and propose Search via Learning (SeaL), a framework that leverages LLMs for effective and efficient search. Second, we further extend SeaL to SeaL-C to ensure rigorous completeness during search. Our evaluation across three real-world planning tasks demonstrates that SeaL achieves near-perfect accuracy while reducing search spaces by up to 99.1% compared to traditional approaches. Finally, we explore how far LLMs are from real search by investigating whether they can develop search capabilities independently. Our analysis reveals that while current LLMs struggle with efficient search in complex problems, incorporating systematic search strategies significantly enhances their problem-solving capabilities. These findings not only validate the effectiveness of our approach but also highlight the need for improving LLMs' search abilities for real-world applications.","sentences":["Search plays a fundamental role in problem-solving across various domains, with most real-world decision-making problems being solvable through systematic search.","Drawing inspiration from recent discussions on search and learning, we systematically explore the complementary relationship between search and Large Language Models (LLMs) from three perspectives.","First, we analyze how learning can enhance search efficiency and propose Search via Learning (SeaL), a framework that leverages LLMs for effective and efficient search.","Second, we further extend SeaL to SeaL-C to ensure rigorous completeness during search.","Our evaluation across three real-world planning tasks demonstrates that SeaL achieves near-perfect accuracy while reducing search spaces by up to 99.1% compared to traditional approaches.","Finally, we explore how far LLMs are from real search by investigating whether they can develop search capabilities independently.","Our analysis reveals that while current LLMs struggle with efficient search in complex problems, incorporating systematic search strategies significantly enhances their problem-solving capabilities.","These findings not only validate the effectiveness of our approach but also highlight the need for improving LLMs' search abilities for real-world applications."],"url":"http://arxiv.org/abs/2502.18387v1"}
{"created":"2025-02-25 17:25:16","title":"Property Testing in Bounded Degree Hypergraphs","abstract":"We extend the study of property testing on hypergraphs initiated by Czumaj and Sohler (Theoretical Computer Science, 2005). Provided oracle access to a hypergraph, our goal is to distinguish between the case it has a certain property and the case it is \"far\" from having this property. Here, we assume that hypergraphs are represented by bounded-length incidence lists and we measure distances between them as a fraction of the maximum possible number of hyperedges. This contrasts with previous work where representations were given by adjacency matrices and distances by fractions of all possible vertex tuples. Thus, while the previous model is better for studying dense hypergraphs, ours is more effective for testing those of bounded-degree. In particular, our model can be seen as an extension to hypergraphs of the graph testing framework introduced by Goldreich and Ron (Algorithmica, 2002). In this framework, we analyse the query complexity of three fundamental hypergraph properties: colorability, $k$-partiteness, and independence number. We show that $k$-partiteness within families of $k$-uniform $n$-vertex hypergraphs of bounded treewidth is strongly testable. Our algorithm always accepts when the hypergraph is $k$-partite, and rejects with high probability if it is $\\varepsilon$-far from $k$-partiteness. In addition, we prove optimal lower bounds of $\\Omega(n)$ on the query complexity of testing algorithms for $k$-colorability, $k$-partiteness, and independence number in $k$-uniform $n$-vertex hypergraphs of bounded degree. For each of these properties, as an independently interesting combinatorial question, we consider the problem of explicitly constructing $k$-uniform hypergraphs of bounded degree that differ in $\\Theta(n)$ hyperedges from any hypergraph satisfying the property, but where violations of the latter cannot be detected in any neighborhood of $o(n)$ vertices.","sentences":["We extend the study of property testing on hypergraphs initiated by Czumaj and Sohler (Theoretical Computer Science, 2005).","Provided oracle access to a hypergraph, our goal is to distinguish between the case it has a certain property and the case it is \"far\" from having this property.","Here, we assume that hypergraphs are represented by bounded-length incidence lists and we measure distances between them as a fraction of the maximum possible number of hyperedges.","This contrasts with previous work where representations were given by adjacency matrices and distances by fractions of all possible vertex tuples.","Thus, while the previous model is better for studying dense hypergraphs, ours is more effective for testing those of bounded-degree.","In particular, our model can be seen as an extension to hypergraphs of the graph testing framework introduced by Goldreich and Ron (Algorithmica, 2002).","In this framework, we analyse the query complexity of three fundamental hypergraph properties: colorability, $k$-partiteness, and independence number.","We show that $k$-partiteness within families of $k$-uniform $n$-vertex hypergraphs of bounded treewidth is strongly testable.","Our algorithm always accepts when the hypergraph is $k$-partite, and rejects with high probability if it is $\\varepsilon$-far from $k$-partiteness.","In addition, we prove optimal lower bounds of $\\Omega(n)$ on the query complexity of testing algorithms for $k$-colorability, $k$-partiteness, and independence number in $k$-uniform $n$-vertex hypergraphs of bounded degree.","For each of these properties, as an independently interesting combinatorial question, we consider the problem of explicitly constructing $k$-uniform hypergraphs of bounded degree that differ in $\\Theta(n)$ hyperedges from any hypergraph satisfying the property, but where violations of the latter cannot be detected in any neighborhood of $o(n)$ vertices."],"url":"http://arxiv.org/abs/2502.18382v1"}
{"created":"2025-02-25 17:24:26","title":"Semantic and Goal-oriented Wireless Network Coverage: The Area of Effectiveness","abstract":"Assessing wireless coverage is a fundamental task for public network operators and private deployments, whose goal is to guarantee quality of service across the network while minimizing material waste and energy consumption. These maps are usually built through ray tracing techniques and/or channel measurements that can be consequently translated into network Key Performance Indicators (KPIs), such as capacity or throughput. However, next generation networks (e.g., 6G) typically involve beyond communication resources, towards services that require data transmission, but also processing (local and remote) to perform complex decision making in real time, with the best balance between performance, energy consumption, material waste, and privacy. In this paper, we introduce the novel concept of areas of effectiveness, which goes beyond the legacy notion of coverage, towards one that takes into account capability of the network of offering edge Artificial Intelligence (AI)-related computation. We will show that radio coverage is a poor indicator of real system performance, depending on the application and the computing capabilities of network and devices. This opens new challenges in network planning, but also resource orchestration during operation to achieve the specific goal of communication.","sentences":["Assessing wireless coverage is a fundamental task for public network operators and private deployments, whose goal is to guarantee quality of service across the network while minimizing material waste and energy consumption.","These maps are usually built through ray tracing techniques and/or channel measurements that can be consequently translated into network Key Performance Indicators (KPIs), such as capacity or throughput.","However, next generation networks (e.g., 6G) typically involve beyond communication resources, towards services that require data transmission, but also processing (local and remote) to perform complex decision making in real time, with the best balance between performance, energy consumption, material waste, and privacy.","In this paper, we introduce the novel concept of areas of effectiveness, which goes beyond the legacy notion of coverage, towards one that takes into account capability of the network of offering edge Artificial Intelligence (AI)-related computation.","We will show that radio coverage is a poor indicator of real system performance, depending on the application and the computing capabilities of network and devices.","This opens new challenges in network planning, but also resource orchestration during operation to achieve the specific goal of communication."],"url":"http://arxiv.org/abs/2502.18381v1"}
{"created":"2025-02-25 17:21:44","title":"Mechanistic PDE Networks for Discovery of Governing Equations","abstract":"We present Mechanistic PDE Networks -- a model for discovery of governing partial differential equations from data. Mechanistic PDE Networks represent spatiotemporal data as space-time dependent linear partial differential equations in neural network hidden representations. The represented PDEs are then solved and decoded for specific tasks. The learned PDE representations naturally express the spatiotemporal dynamics in data in neural network hidden space, enabling increased power for dynamical modeling. Solving the PDE representations in a compute and memory-efficient way, however, is a significant challenge. We develop a native, GPU-capable, parallel, sparse, and differentiable multigrid solver specialized for linear partial differential equations that acts as a module in Mechanistic PDE Networks. Leveraging the PDE solver, we propose a discovery architecture that can discover nonlinear PDEs in complex settings while also being robust to noise. We validate PDE discovery on a number of PDEs, including reaction-diffusion and Navier-Stokes equations.","sentences":["We present Mechanistic PDE Networks -- a model for discovery of governing partial differential equations from data.","Mechanistic PDE Networks represent spatiotemporal data as space-time dependent linear partial differential equations in neural network hidden representations.","The represented PDEs are then solved and decoded for specific tasks.","The learned PDE representations naturally express the spatiotemporal dynamics in data in neural network hidden space, enabling increased power for dynamical modeling.","Solving the PDE representations in a compute and memory-efficient way, however, is a significant challenge.","We develop a native, GPU-capable, parallel, sparse, and differentiable multigrid solver specialized for linear partial differential equations that acts as a module in Mechanistic PDE Networks.","Leveraging the PDE solver, we propose a discovery architecture that can discover nonlinear PDEs in complex settings while also being robust to noise.","We validate PDE discovery on a number of PDEs, including reaction-diffusion and Navier-Stokes equations."],"url":"http://arxiv.org/abs/2502.18377v1"}
{"created":"2025-02-25 17:11:14","title":"EgoSim: An Egocentric Multi-view Simulator and Real Dataset for Body-worn Cameras during Motion and Activity","abstract":"Research on egocentric tasks in computer vision has mostly focused on head-mounted cameras, such as fisheye cameras or embedded cameras inside immersive headsets. We argue that the increasing miniaturization of optical sensors will lead to the prolific integration of cameras into many more body-worn devices at various locations. This will bring fresh perspectives to established tasks in computer vision and benefit key areas such as human motion tracking, body pose estimation, or action recognition -- particularly for the lower body, which is typically occluded.   In this paper, we introduce EgoSim, a novel simulator of body-worn cameras that generates realistic egocentric renderings from multiple perspectives across a wearer's body. A key feature of EgoSim is its use of real motion capture data to render motion artifacts, which are especially noticeable with arm- or leg-worn cameras. In addition, we introduce MultiEgoView, a dataset of egocentric footage from six body-worn cameras and ground-truth full-body 3D poses during several activities: 119 hours of data are derived from AMASS motion sequences in four high-fidelity virtual environments, which we augment with 5 hours of real-world motion data from 13 participants using six GoPro cameras and 3D body pose references from an Xsens motion capture suit.   We demonstrate EgoSim's effectiveness by training an end-to-end video-only 3D pose estimation network. Analyzing its domain gap, we show that our dataset and simulator substantially aid training for inference on real-world data.   EgoSim code & MultiEgoView dataset: https://siplab.org/projects/EgoSim","sentences":["Research on egocentric tasks in computer vision has mostly focused on head-mounted cameras, such as fisheye cameras or embedded cameras inside immersive headsets.","We argue that the increasing miniaturization of optical sensors will lead to the prolific integration of cameras into many more body-worn devices at various locations.","This will bring fresh perspectives to established tasks in computer vision and benefit key areas such as human motion tracking, body pose estimation, or action recognition -- particularly for the lower body, which is typically occluded.   ","In this paper, we introduce EgoSim, a novel simulator of body-worn cameras that generates realistic egocentric renderings from multiple perspectives across a wearer's body.","A key feature of EgoSim is its use of real motion capture data to render motion artifacts, which are especially noticeable with arm- or leg-worn cameras.","In addition, we introduce MultiEgoView, a dataset of egocentric footage from six body-worn cameras and ground-truth full-body 3D poses during several activities: 119 hours of data are derived from AMASS motion sequences in four high-fidelity virtual environments, which we augment with 5 hours of real-world motion data from 13 participants using six GoPro cameras and 3D body pose references from an Xsens motion capture suit.   ","We demonstrate EgoSim's effectiveness by training an end-to-end video-only 3D pose estimation network.","Analyzing its domain gap, we show that our dataset and simulator substantially aid training for inference on real-world data.   ","EgoSim code & MultiEgoView dataset: https://siplab.org/projects/EgoSim"],"url":"http://arxiv.org/abs/2502.18373v1"}
{"created":"2025-02-25 17:09:12","title":"MindMem: Multimodal for Predicting Advertisement Memorability Using LLMs and Deep Learning","abstract":"In the competitive landscape of advertising, success hinges on effectively navigating and leveraging complex interactions among consumers, advertisers, and advertisement platforms. These multifaceted interactions compel advertisers to optimize strategies for modeling consumer behavior, enhancing brand recall, and tailoring advertisement content. To address these challenges, we present MindMem, a multimodal predictive model for advertisement memorability. By integrating textual, visual, and auditory data, MindMem achieves state-of-the-art performance, with a Spearman's correlation coefficient of 0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently surpassing existing methods. Furthermore, our analysis identified key factors influencing advertisement memorability, such as video pacing, scene complexity, and emotional resonance. Expanding on this, we introduced MindMem-ReAd (MindMem-Driven Re-generated Advertisement), which employs Large Language Model-based simulations to optimize advertisement content and placement, resulting in up to a 74.12% improvement in advertisement memorability. Our results highlight the transformative potential of Artificial Intelligence in advertising, offering advertisers a robust tool to drive engagement, enhance competitiveness, and maximize impact in a rapidly evolving market.","sentences":["In the competitive landscape of advertising, success hinges on effectively navigating and leveraging complex interactions among consumers, advertisers, and advertisement platforms.","These multifaceted interactions compel advertisers to optimize strategies for modeling consumer behavior, enhancing brand recall, and tailoring advertisement content.","To address these challenges, we present MindMem, a multimodal predictive model for advertisement memorability.","By integrating textual, visual, and auditory data, MindMem achieves state-of-the-art performance, with a Spearman's correlation coefficient of 0.631 on the LAMBDA and 0.731 on the Memento10K dataset, consistently surpassing existing methods.","Furthermore, our analysis identified key factors influencing advertisement memorability, such as video pacing, scene complexity, and emotional resonance.","Expanding on this, we introduced MindMem-ReAd (MindMem-Driven Re-generated Advertisement), which employs Large Language Model-based simulations to optimize advertisement content and placement, resulting in up to a 74.12% improvement in advertisement memorability.","Our results highlight the transformative potential of Artificial Intelligence in advertising, offering advertisers a robust tool to drive engagement, enhance competitiveness, and maximize impact in a rapidly evolving market."],"url":"http://arxiv.org/abs/2502.18371v1"}
{"created":"2025-02-25 17:03:34","title":"Near-Shore Mapping for Detection and Tracking of Vessels","abstract":"For an autonomous surface vessel (ASV) to dock, it must track other vessels close to the docking area. Kayaks present a particular challenge due to their proximity to the dock and relatively small size. Maritime target tracking has typically employed land masking to filter out land and the dock. However, imprecise land masking makes it difficult to track close-to-dock objects. Our approach uses Light Detection And Ranging (LiDAR) data and maps the docking area offline. The precise 3D measurements allow for precise map creation. However, the mapping could result in static, yet potentially moving, objects being mapped. We detect and filter out potentially moving objects from the LiDAR data by utilizing image data. The visual vessel detection and segmentation method is a neural network that is trained on our labeled data. Close-to-shore tracking improves with an accurate map and is demonstrated on a recently gathered real-world dataset. The dataset contains multiple sequences of a kayak and a day cruiser moving close to the dock, in a collision path with an autonomous ferry prototype.","sentences":["For an autonomous surface vessel (ASV) to dock, it must track other vessels close to the docking area.","Kayaks present a particular challenge due to their proximity to the dock and relatively small size.","Maritime target tracking has typically employed land masking to filter out land and the dock.","However, imprecise land masking makes it difficult to track close-to-dock objects.","Our approach uses Light Detection","And Ranging (LiDAR) data and maps the docking area offline.","The precise 3D measurements allow for precise map creation.","However, the mapping could result in static, yet potentially moving, objects being mapped.","We detect and filter out potentially moving objects from the LiDAR data by utilizing image data.","The visual vessel detection and segmentation method is a neural network that is trained on our labeled data.","Close-to-shore tracking improves with an accurate map and is demonstrated on a recently gathered real-world dataset.","The dataset contains multiple sequences of a kayak and a day cruiser moving close to the dock, in a collision path with an autonomous ferry prototype."],"url":"http://arxiv.org/abs/2502.18368v1"}
{"created":"2025-02-25 16:57:04","title":"ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation","abstract":"Multi-layer image generation is a fundamental task that enables users to isolate, select, and edit specific image layers, thereby revolutionizing interactions with generative models. In this paper, we introduce the Anonymous Region Transformer (ART), which facilitates the direct generation of variable multi-layer transparent images based on a global text prompt and an anonymous region layout. Inspired by Schema theory suggests that knowledge is organized in frameworks (schemas) that enable people to interpret and learn from new information by linking it to prior knowledge.}, this anonymous region layout allows the generative model to autonomously determine which set of visual tokens should align with which text tokens, which is in contrast to the previously dominant semantic layout for the image generation task. In addition, the layer-wise region crop mechanism, which only selects the visual tokens belonging to each anonymous region, significantly reduces attention computation costs and enables the efficient generation of images with numerous distinct layers (e.g., 50+). When compared to the full attention approach, our method is over 12 times faster and exhibits fewer layer conflicts. Furthermore, we propose a high-quality multi-layer transparent image autoencoder that supports the direct encoding and decoding of the transparency of variable multi-layer images in a joint manner. By enabling precise control and scalable layer generation, ART establishes a new paradigm for interactive content creation.","sentences":["Multi-layer image generation is a fundamental task that enables users to isolate, select, and edit specific image layers, thereby revolutionizing interactions with generative models.","In this paper, we introduce the Anonymous Region Transformer (ART), which facilitates the direct generation of variable multi-layer transparent images based on a global text prompt and an anonymous region layout.","Inspired by Schema theory suggests that knowledge is organized in frameworks (schemas) that enable people to interpret and learn from new information by linking it to prior knowledge.","}, this anonymous region layout allows the generative model to autonomously determine which set of visual tokens should align with which text tokens, which is in contrast to the previously dominant semantic layout for the image generation task.","In addition, the layer-wise region crop mechanism, which only selects the visual tokens belonging to each anonymous region, significantly reduces attention computation costs and enables the efficient generation of images with numerous distinct layers (e.g., 50+).","When compared to the full attention approach, our method is over 12 times faster and exhibits fewer layer conflicts.","Furthermore, we propose a high-quality multi-layer transparent image autoencoder that supports the direct encoding and decoding of the transparency of variable multi-layer images in a joint manner.","By enabling precise control and scalable layer generation, ART establishes a new paradigm for interactive content creation."],"url":"http://arxiv.org/abs/2502.18364v1"}
{"created":"2025-02-25 16:56:43","title":"Stretchable Capacitive and Resistive Strain Sensors: Accessible Manufacturing Using Direct Ink Writing","abstract":"As robotics advances toward integrating soft structures, anthropomorphic shapes, and complex tasks, soft and highly stretchable mechanotransducers are becoming essential. To reliably measure tactile and proprioceptive data while ensuring shape conformability, stretchability, and adaptability, researchers have explored diverse transduction principles alongside scalable and versatile manufacturing techniques. Nonetheless, many current methods for stretchable sensors are designed to produce a single sensor configuration, thereby limiting design flexibility. Here, we present an accessible, flexible, printing-based fabrication approach for customizable, stretchable sensors. Our method employs a custom-built printhead integrated with a commercial 3D printer to enable direct ink writing (DIW) of conductive ink onto cured silicone substrates. A layer-wise fabrication process, facilitated by stackable trays, allows for the deposition of multiple liquid conductive ink layers within a silicone matrix. To demonstrate the method's capacity for high design flexibility, we fabricate and evaluate both capacitive and resistive strain sensor morphologies. Experimental characterization showed that the capacitive strain sensor possesses high linearity (R^2 = 0.99), high sensitivity near the 1.0 theoretical limit (GF = 0.95), minimal hysteresis (DH = 1.36%), and large stretchability (550%), comparable to state-of-the-art stretchable strain sensors reported in the literature.","sentences":["As robotics advances toward integrating soft structures, anthropomorphic shapes, and complex tasks, soft and highly stretchable mechanotransducers are becoming essential.","To reliably measure tactile and proprioceptive data while ensuring shape conformability, stretchability, and adaptability, researchers have explored diverse transduction principles alongside scalable and versatile manufacturing techniques.","Nonetheless, many current methods for stretchable sensors are designed to produce a single sensor configuration, thereby limiting design flexibility.","Here, we present an accessible, flexible, printing-based fabrication approach for customizable, stretchable sensors.","Our method employs a custom-built printhead integrated with a commercial 3D printer to enable direct ink writing (DIW) of conductive ink onto cured silicone substrates.","A layer-wise fabrication process, facilitated by stackable trays, allows for the deposition of multiple liquid conductive ink layers within a silicone matrix.","To demonstrate the method's capacity for high design flexibility, we fabricate and evaluate both capacitive and resistive strain sensor morphologies.","Experimental characterization showed that the capacitive strain sensor possesses high linearity (R^2 = 0.99), high sensitivity near the 1.0 theoretical limit (GF = 0.95), minimal hysteresis (DH = 1.36%), and large stretchability (550%), comparable to state-of-the-art stretchable strain sensors reported in the literature."],"url":"http://arxiv.org/abs/2502.18363v1"}
{"created":"2025-02-25 16:49:06","title":"Responsible AI Agents","abstract":"Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace. Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks. Instead of a travel itinerary, an AI Agent would book all aspects of your trip. Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets. The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms. These scholars are calling for regulation before AI Agents cause havoc.   This Article addresses the concerns around AI Agents head on. It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents. It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations. That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions. These practices will enable desired economic outcomes and mitigate perceived risks. The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status. In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents.","sentences":["Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace.","Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks.","Instead of a travel itinerary, an AI Agent would book all aspects of your trip.","Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets.","The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms.","These scholars are calling for regulation before AI Agents cause havoc.   ","This Article addresses the concerns around AI Agents head on.","It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents.","It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations.","That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions.","These practices will enable desired economic outcomes and mitigate perceived risks.","The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status.","In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents."],"url":"http://arxiv.org/abs/2502.18359v1"}
{"created":"2025-02-25 16:48:10","title":"Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation","abstract":"AI systems powered by large language models can act as capable assistants for writing and editing. In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s). One question that arises in these scenarios is the extent to which AI should be credited for its contributions. We examined knowledge workers' views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative. Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions. Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations. Our results motivate and inform new approaches for crediting AI contributions to co-created work.","sentences":["AI systems powered by large language models can act as capable assistants for writing and editing.","In these tasks, the AI system acts as a co-creative partner, making novel contributions to an artifact-under-creation alongside its human partner(s).","One question that arises in these scenarios is the extent to which AI should be credited for its contributions.","We examined knowledge workers' views of attribution through a survey study (N=155) and found that they assigned different levels of credit across different contribution types, amounts, and initiative.","Compared to a human partner, we observed a consistent pattern in which AI was assigned less credit for equivalent contributions.","Participants felt that disclosing AI involvement was important and used a variety of criteria to make attribution judgments, including the quality of contributions, personal values, and technology considerations.","Our results motivate and inform new approaches for crediting AI contributions to co-created work."],"url":"http://arxiv.org/abs/2502.18357v1"}
{"created":"2025-02-25 16:45:08","title":"WebGames: Challenging General-Purpose Web-Browsing AI Agents","abstract":"We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents.","sentences":["We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges.","These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment.","Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions.","We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance.","Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive.","The benchmark is publicly available at webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles.","Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents."],"url":"http://arxiv.org/abs/2502.18356v1"}
{"created":"2025-02-25 16:44:10","title":"DBR: Divergence-Based Regularization for Debiasing Natural Language Understanding Models","abstract":"Pre-trained language models (PLMs) have achieved impressive results on various natural language processing tasks. However, recent research has revealed that these models often rely on superficial features and shortcuts instead of developing a genuine understanding of language, especially for natural language understanding (NLU) tasks. Consequently, the models struggle to generalize to out-of-domain data. In this work, we propose Divergence Based Regularization (DBR) to mitigate this shortcut learning behavior. Our method measures the divergence between the output distributions for original examples and examples where shortcut tokens have been masked. This process prevents the model's predictions from being overly influenced by shortcut features or biases. We evaluate our model on three NLU tasks and find that it improves out-of-domain performance with little loss of in-domain accuracy. Our results demonstrate that reducing the reliance on shortcuts and superficial features can enhance the generalization ability of large pre-trained language models.","sentences":["Pre-trained language models (PLMs) have achieved impressive results on various natural language processing tasks.","However, recent research has revealed that these models often rely on superficial features and shortcuts instead of developing a genuine understanding of language, especially for natural language understanding (NLU) tasks.","Consequently, the models struggle to generalize to out-of-domain data.","In this work, we propose Divergence Based Regularization (DBR) to mitigate this shortcut learning behavior.","Our method measures the divergence between the output distributions for original examples and examples where shortcut tokens have been masked.","This process prevents the model's predictions from being overly influenced by shortcut features or biases.","We evaluate our model on three NLU tasks and find that it improves out-of-domain performance with little loss of in-domain accuracy.","Our results demonstrate that reducing the reliance on shortcuts and superficial features can enhance the generalization ability of large pre-trained language models."],"url":"http://arxiv.org/abs/2502.18353v1"}
{"created":"2025-02-25 16:37:25","title":"Graph Inference with Effective Resistance Queries","abstract":"The goal of graph inference is to design algorithms for learning properties of a hidden graph using queries to an oracle that returns information about the graph. Graph reconstruction, verification, and property testing are all types of graph inference.   In this work, we study graph inference using an oracle that returns the effective resistance (ER) between a pair of vertices. Effective resistance is a distance originating from the study of electrical circuits with many applications. However, ER has received little attention from a graph inference perspective. Indeed, although it is known that an $n$-vertex graph can be uniquely reconstructed from all $\\binom{n}{2}$ possible ER queries, little else is known. We address this gap with several new results, including:   1. $O(n)$-query algorithms for testing whether a graph is a tree; deciding whether two graphs are equal assuming one is a subgraph of the other; and testing whether a given vertex (or edge) is a cut vertex (or cut edge).   2. Property testing algorithms, including for testing whether a graph is vertex- or edge-biconnected. We also give a reduction to adapt property testing results from the bounded-degree model to our ER query model. This yields ER-query-based algorithms for testing $k$-connectivity, bipartiteness, planarity, and containment of a fixed subgraph.   3. Graph reconstruction algorithms, including an algorithm for reconstructing a graph from a low-width tree decomposition; a $\\Theta(k^2)$-query, polynomial-time algorithm for recovering the adjacency matrix $A$ of a hidden graph, given $A$ with $k$ of its entries deleted; and a $k$-query, exponential-time algorithm for the same task.   We also compare the power of ER queries and shortest path queries, which are closely related but better studied. Interestingly, we show that the two query models are incomparable in power.","sentences":["The goal of graph inference is to design algorithms for learning properties of a hidden graph using queries to an oracle that returns information about the graph.","Graph reconstruction, verification, and property testing are all types of graph inference.   ","In this work, we study graph inference using an oracle that returns the effective resistance (ER) between a pair of vertices.","Effective resistance is a distance originating from the study of electrical circuits with many applications.","However, ER has received little attention from a graph inference perspective.","Indeed, although it is known that an $n$-vertex graph can be uniquely reconstructed from all $\\binom{n}{2}$ possible ER queries, little else is known.","We address this gap with several new results, including:   1.","$O(n)$-query algorithms for testing whether a graph is a tree; deciding whether two graphs are equal assuming one is a subgraph of the other; and testing whether a given vertex (or edge) is a cut vertex (or cut edge).   ","2.","Property testing algorithms, including for testing whether a graph is vertex- or edge-biconnected.","We also give a reduction to adapt property testing results from the bounded-degree model to our ER query model.","This yields ER-query-based algorithms for testing $k$-connectivity, bipartiteness, planarity, and containment of a fixed subgraph.   ","3.","Graph reconstruction algorithms, including an algorithm for reconstructing a graph from a low-width tree decomposition; a $\\Theta(k^2)$-query, polynomial-time algorithm for recovering the adjacency matrix $A$ of a hidden graph, given $A$ with $k$ of its entries deleted; and a $k$-query, exponential-time algorithm for the same task.   ","We also compare the power of ER queries and shortest path queries, which are closely related but better studied.","Interestingly, we show that the two query models are incomparable in power."],"url":"http://arxiv.org/abs/2502.18350v1"}
{"created":"2025-02-25 16:36:32","title":"Towards softerware: Enabling personalization of interactive data representations for users with disabilities","abstract":"Accessible design for some may still produce barriers for others. This tension, called access friction, creates challenges for both designers and end-users with disabilities. To address this, we present the concept of softerware, a system design approach that provides end users with agency to meaningfully customize and adapt interfaces to their needs. To apply softerware to visualization, we assembled 195 data visualization customization options centered on the barriers we expect users with disabilities will experience. We built a prototype that applies a subset of these options and interviewed practitioners for feedback. Lastly, we conducted a design probe study with blind and low vision accessibility professionals to learn more about their challenges and visions for softerware. We observed access frictions between our participant's designs and they expressed that for softerware's success, current and future systems must be designed with accessible defaults, interoperability, persistence, and respect for a user's perceived effort-to-outcome ratio.","sentences":["Accessible design for some may still produce barriers for others.","This tension, called access friction, creates challenges for both designers and end-users with disabilities.","To address this, we present the concept of softerware, a system design approach that provides end users with agency to meaningfully customize and adapt interfaces to their needs.","To apply softerware to visualization, we assembled 195 data visualization customization options centered on the barriers we expect users with disabilities will experience.","We built a prototype that applies a subset of these options and interviewed practitioners for feedback.","Lastly, we conducted a design probe study with blind and low vision accessibility professionals to learn more about their challenges and visions for softerware.","We observed access frictions between our participant's designs and they expressed that for softerware's success, current and future systems must be designed with accessible defaults, interoperability, persistence, and respect for a user's perceived effort-to-outcome ratio."],"url":"http://arxiv.org/abs/2502.18348v1"}
{"created":"2025-02-25 16:33:50","title":"BRIDO: Bringing Democratic Order to Abstractive Summarization","abstract":"Hallucination refers to the inaccurate, irrelevant, and inconsistent text generated from large language models (LLMs). While the LLMs have shown great promise in a variety of tasks, the issue of hallucination still remains a major challenge for many practical uses. In this paper, we tackle the issue of hallucination in abstract text summarization by mitigating exposure bias. Existing models targeted for exposure bias mitigation, namely BRIO, aim for better summarization quality in the ROUGE score. We propose a model that uses a similar exposure bias mitigation strategy but with a goal that is aligned with less hallucination. We conjecture that among a group of candidate outputs, ones with hallucinations will comprise the minority of the whole group. That is, candidates with less similarity with others will have a higher chance of containing hallucinated content. Our method uses this aspect and utilizes contrastive learning, incentivizing candidates with high inter-candidate ROUGE scores. We performed experiments on the XSum and CNN/DM summarization datasets, and our method showed 6.25% and 3.82% improvement, respectively, on the consistency G-Eval score over BRIO.","sentences":["Hallucination refers to the inaccurate, irrelevant, and inconsistent text generated from large language models (LLMs).","While the LLMs have shown great promise in a variety of tasks, the issue of hallucination still remains a major challenge for many practical uses.","In this paper, we tackle the issue of hallucination in abstract text summarization by mitigating exposure bias.","Existing models targeted for exposure bias mitigation, namely BRIO, aim for better summarization quality in the ROUGE score.","We propose a model that uses a similar exposure bias mitigation strategy but with a goal that is aligned with less hallucination.","We conjecture that among a group of candidate outputs, ones with hallucinations will comprise the minority of the whole group.","That is, candidates with less similarity with others will have a higher chance of containing hallucinated content.","Our method uses this aspect and utilizes contrastive learning, incentivizing candidates with high inter-candidate ROUGE scores.","We performed experiments on the XSum and CNN/DM summarization datasets, and our method showed 6.25% and 3.82% improvement, respectively, on the consistency G-Eval score over BRIO."],"url":"http://arxiv.org/abs/2502.18342v1"}
{"created":"2025-02-25 16:26:25","title":"Structural Alignment Improves Graph Test-Time Adaptation","abstract":"Graph-based learning has achieved remarkable success in domains ranging from recommendation to fraud detection and particle physics by effectively capturing underlying interaction patterns. However, it often struggles to generalize when distribution shifts occur, particularly those involving changes in network connectivity or interaction patterns. Existing approaches designed to mitigate such shifts typically require retraining with full access to source data, rendering them infeasible under strict computational or privacy constraints. To address this limitation, we propose a test-time structural alignment (TSA) algorithm for Graph Test-Time Adaptation (GTTA), a novel method that aligns graph structures during inference without revisiting the source domain. Built upon a theoretically grounded treatment of graph data distribution shifts, TSA integrates three key strategies: an uncertainty-aware neighborhood weighting that accommodates structure shifts, an adaptive balancing of self-node and neighborhood-aggregated representations driven by node representations' signal-to-noise ratio, and a decision boundary refinement that corrects remaining label and feature shifts. Extensive experiments on synthetic and real-world datasets demonstrate that TSA can consistently outperform both non-graph TTA methods and state-of-the-art GTTA baselines.","sentences":["Graph-based learning has achieved remarkable success in domains ranging from recommendation to fraud detection and particle physics by effectively capturing underlying interaction patterns.","However, it often struggles to generalize when distribution shifts occur, particularly those involving changes in network connectivity or interaction patterns.","Existing approaches designed to mitigate such shifts typically require retraining with full access to source data, rendering them infeasible under strict computational or privacy constraints.","To address this limitation, we propose a test-time structural alignment (TSA) algorithm for Graph Test-Time Adaptation (GTTA), a novel method that aligns graph structures during inference without revisiting the source domain.","Built upon a theoretically grounded treatment of graph data distribution shifts, TSA integrates three key strategies: an uncertainty-aware neighborhood weighting that accommodates structure shifts, an adaptive balancing of self-node and neighborhood-aggregated representations driven by node representations' signal-to-noise ratio, and a decision boundary refinement that corrects remaining label and feature shifts.","Extensive experiments on synthetic and real-world datasets demonstrate that TSA can consistently outperform both non-graph TTA methods and state-of-the-art GTTA baselines."],"url":"http://arxiv.org/abs/2502.18334v1"}
{"created":"2025-02-25 16:22:42","title":"From Vision to Sound: Advancing Audio Anomaly Detection with Vision-Based Algorithms","abstract":"Recent advances in Visual Anomaly Detection (VAD) have introduced sophisticated algorithms leveraging embeddings generated by pre-trained feature extractors. Inspired by these developments, we investigate the adaptation of such algorithms to the audio domain to address the problem of Audio Anomaly Detection (AAD). Unlike most existing AAD methods, which primarily classify anomalous samples, our approach introduces fine-grained temporal-frequency localization of anomalies within the spectrogram, significantly improving explainability. This capability enables a more precise understanding of where and when anomalies occur, making the results more actionable for end users. We evaluate our approach on industrial and environmental benchmarks, demonstrating the effectiveness of VAD techniques in detecting anomalies in audio signals. Moreover, they improve explainability by enabling localized anomaly identification, making audio anomaly detection systems more interpretable and practical.","sentences":["Recent advances in Visual Anomaly Detection (VAD) have introduced sophisticated algorithms leveraging embeddings generated by pre-trained feature extractors.","Inspired by these developments, we investigate the adaptation of such algorithms to the audio domain to address the problem of Audio Anomaly Detection (AAD).","Unlike most existing AAD methods, which primarily classify anomalous samples, our approach introduces fine-grained temporal-frequency localization of anomalies within the spectrogram, significantly improving explainability.","This capability enables a more precise understanding of where and when anomalies occur, making the results more actionable for end users.","We evaluate our approach on industrial and environmental benchmarks, demonstrating the effectiveness of VAD techniques in detecting anomalies in audio signals.","Moreover, they improve explainability by enabling localized anomaly identification, making audio anomaly detection systems more interpretable and practical."],"url":"http://arxiv.org/abs/2502.18328v1"}
{"created":"2025-02-25 16:20:10","title":"A Unified Bayesian Perspective for Conventional and Robust Adaptive Filters","abstract":"In this work, we present a new perspective on the origin and interpretation of adaptive filters. By applying Bayesian principles of recursive inference from the state-space model and using a series of simplifications regarding the structure of the solution, we can present, in a unified framework, derivations of many adaptive filters which depend on the probabilistic model of the observational noise. In particular, under a Gaussian model, we obtain solutions well-known in the literature (such as LMS, NLMS, or Kalman filter), while using non-Gaussian noise, we obtain new families of adaptive filter. Notably, under assumption of Laplacian noise, we obtain a family of robust filters of which the signed-error algorithm is a well-known member, while other algorithms, derived effortlessly in the proposed framework, are entirely new. Numerical examples are shown to illustrate the properties and provide a better insight into the performance of the derived adaptive filters.","sentences":["In this work, we present a new perspective on the origin and interpretation of adaptive filters.","By applying Bayesian principles of recursive inference from the state-space model and using a series of simplifications regarding the structure of the solution, we can present, in a unified framework, derivations of many adaptive filters which depend on the probabilistic model of the observational noise.","In particular, under a Gaussian model, we obtain solutions well-known in the literature (such as LMS, NLMS, or Kalman filter), while using non-Gaussian noise, we obtain new families of adaptive filter.","Notably, under assumption of Laplacian noise, we obtain a family of robust filters of which the signed-error algorithm is a well-known member, while other algorithms, derived effortlessly in the proposed framework, are entirely new.","Numerical examples are shown to illustrate the properties and provide a better insight into the performance of the derived adaptive filters."],"url":"http://arxiv.org/abs/2502.18325v1"}
{"created":"2025-02-25 16:18:15","title":"Accelerated Training on Low-Power Edge Devices","abstract":"Training on edge devices poses several challenges as these devices are generally resource-constrained, especially in terms of power. State-of-the-art techniques at the device level reduce the GPU frequency to enforce power constraints, leading to a significant increase in training time. To accelerate training, we propose to jointly adjust the system and application parameters (in our case, the GPU frequency and the batch size of the training task) while adhering to the power constraints on devices. We introduce a novel cross-layer methodology that combines predictions of batch size efficiency and device profiling to achieve the desired optimization. Our evaluation on real hardware shows that our method outperforms the current baselines that depend on state of the art techniques, reducing the training time by $2.4\\times$ with results very close to optimal. Our measurements also indicate a substantial reduction in the overall energy used for the training process. These gains are achieved without reduction in the performance of the trained model.","sentences":["Training on edge devices poses several challenges as these devices are generally resource-constrained, especially in terms of power.","State-of-the-art techniques at the device level reduce the GPU frequency to enforce power constraints, leading to a significant increase in training time.","To accelerate training, we propose to jointly adjust the system and application parameters (in our case, the GPU frequency and the batch size of the training task) while adhering to the power constraints on devices.","We introduce a novel cross-layer methodology that combines predictions of batch size efficiency and device profiling to achieve the desired optimization.","Our evaluation on real hardware shows that our method outperforms the current baselines that depend on state of the art techniques, reducing the training time by $2.4\\times$ with results very close to optimal.","Our measurements also indicate a substantial reduction in the overall energy used for the training process.","These gains are achieved without reduction in the performance of the trained model."],"url":"http://arxiv.org/abs/2502.18323v1"}
{"created":"2025-02-25 16:15:35","title":"Global-Decision-Focused Neural ODEs for Proactive Grid Resilience Management","abstract":"Extreme hazard events such as wildfires and hurricanes increasingly threaten power systems, causing widespread outages and disrupting critical services. Recently, predict-then-optimize approaches have gained traction in grid operations, where system functionality forecasts are first generated and then used as inputs for downstream decision-making. However, this two-stage method often results in a misalignment between prediction and optimization objectives, leading to suboptimal resource allocation. To address this, we propose predict-all-then-optimize-globally (PATOG), a framework that integrates outage prediction with globally optimized interventions. At its core, our global-decision-focused (GDF) neural ODE model captures outage dynamics while optimizing resilience strategies in a decision-aware manner. Unlike conventional methods, our approach ensures spatially and temporally coherent decision-making, improving both predictive accuracy and operational efficiency. Experiments on synthetic and real-world datasets demonstrate significant improvements in outage prediction consistency and grid resilience.","sentences":["Extreme hazard events such as wildfires and hurricanes increasingly threaten power systems, causing widespread outages and disrupting critical services.","Recently, predict-then-optimize approaches have gained traction in grid operations, where system functionality forecasts are first generated and then used as inputs for downstream decision-making.","However, this two-stage method often results in a misalignment between prediction and optimization objectives, leading to suboptimal resource allocation.","To address this, we propose predict-all-then-optimize-globally (PATOG), a framework that integrates outage prediction with globally optimized interventions.","At its core, our global-decision-focused (GDF) neural ODE model captures outage dynamics while optimizing resilience strategies in a decision-aware manner.","Unlike conventional methods, our approach ensures spatially and temporally coherent decision-making, improving both predictive accuracy and operational efficiency.","Experiments on synthetic and real-world datasets demonstrate significant improvements in outage prediction consistency and grid resilience."],"url":"http://arxiv.org/abs/2502.18321v1"}
{"created":"2025-02-25 16:13:49","title":"Self-Supervised Data Generation for Precision Agriculture: Blending Simulated Environments with Real Imagery","abstract":"In precision agriculture, the scarcity of labeled data and significant covariate shifts pose unique challenges for training machine learning models. This scarcity is particularly problematic due to the dynamic nature of the environment and the evolving appearance of agricultural subjects as living things. We propose a novel system for generating realistic synthetic data to address these challenges. Utilizing a vineyard simulator based on the Unity engine, our system employs a cut-and-paste technique with geometrical consistency considerations to produce accurate photo-realistic images and labels from synthetic environments to train detection algorithms. This approach generates diverse data samples across various viewpoints and lighting conditions. We demonstrate considerable performance improvements in training a state-of-the-art detector by applying our method to table grapes cultivation. The combination of techniques can be easily automated, an increasingly important consideration for adoption in agricultural practice.","sentences":["In precision agriculture, the scarcity of labeled data and significant covariate shifts pose unique challenges for training machine learning models.","This scarcity is particularly problematic due to the dynamic nature of the environment and the evolving appearance of agricultural subjects as living things.","We propose a novel system for generating realistic synthetic data to address these challenges.","Utilizing a vineyard simulator based on the Unity engine, our system employs a cut-and-paste technique with geometrical consistency considerations to produce accurate photo-realistic images and labels from synthetic environments to train detection algorithms.","This approach generates diverse data samples across various viewpoints and lighting conditions.","We demonstrate considerable performance improvements in training a state-of-the-art detector by applying our method to table grapes cultivation.","The combination of techniques can be easily automated, an increasingly important consideration for adoption in agricultural practice."],"url":"http://arxiv.org/abs/2502.18320v1"}
{"created":"2025-02-25 16:11:40","title":"Mapping of Subjective Accounts into Interpreted Clusters (MOSAIC): Topic Modelling and LLM applied to Stroboscopic Phenomenology","abstract":"Stroboscopic light stimulation (SLS) on closed eyes typically induces simple visual hallucinations (VHs), characterised by vivid, geometric and colourful patterns. A dataset of 862 sentences, extracted from 422 open subjective reports, was recently compiled as part of the Dreamachine programme (Collective Act, 2022), an immersive multisensory experience that combines SLS and spatial sound in a collective setting. Although open reports extend the range of reportable phenomenology, their analysis presents significant challenges, particularly in systematically identifying patterns. To address this challenge, we implemented a data-driven approach leveraging Large Language Models and Topic Modelling to uncover and interpret latent experiential topics directly from the Dreamachine's text-based reports. Our analysis confirmed the presence of simple VHs typically documented in scientific studies of SLS, while also revealing experiences of altered states of consciousness and complex hallucinations. Building on these findings, our computational approach expands the systematic study of subjective experience by enabling data-driven analyses of open-ended phenomenological reports, capturing experiences not readily identified through standard questionnaires. By revealing rich and multifaceted aspects of experiences, our study broadens our understanding of stroboscopically-induced phenomena while highlighting the potential of Natural Language Processing and Large Language Models in the emerging field of computational (neuro)phenomenology. More generally, this approach provides a practically applicable methodology for uncovering subtle hidden patterns of subjective experience across diverse research domains.","sentences":["Stroboscopic light stimulation (SLS) on closed eyes typically induces simple visual hallucinations (VHs), characterised by vivid, geometric and colourful patterns.","A dataset of 862 sentences, extracted from 422 open subjective reports, was recently compiled as part of the Dreamachine programme (Collective Act, 2022), an immersive multisensory experience that combines SLS and spatial sound in a collective setting.","Although open reports extend the range of reportable phenomenology, their analysis presents significant challenges, particularly in systematically identifying patterns.","To address this challenge, we implemented a data-driven approach leveraging Large Language Models and Topic Modelling to uncover and interpret latent experiential topics directly from the Dreamachine's text-based reports.","Our analysis confirmed the presence of simple VHs typically documented in scientific studies of SLS, while also revealing experiences of altered states of consciousness and complex hallucinations.","Building on these findings, our computational approach expands the systematic study of subjective experience by enabling data-driven analyses of open-ended phenomenological reports, capturing experiences not readily identified through standard questionnaires.","By revealing rich and multifaceted aspects of experiences, our study broadens our understanding of stroboscopically-induced phenomena while highlighting the potential of Natural Language Processing and Large Language Models in the emerging field of computational (neuro)phenomenology. More generally, this approach provides a practically applicable methodology for uncovering subtle hidden patterns of subjective experience across diverse research domains."],"url":"http://arxiv.org/abs/2502.18318v1"}
{"created":"2025-02-25 16:09:38","title":"WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging","abstract":"We introduce WiCkeD, a simple method to increase the complexity of existing multiple-choice benchmarks by randomly replacing a choice with \"None of the above\", a method often used in educational tests. We show that WiCkeD can be automatically applied to any existing benchmark, making it more challenging. We apply WiCkeD to 6 popular benchmarks and use it to evaluate 18 open-weight LLMs. The performance of the models drops 12.1 points on average with respect to the original versions of the datasets. When using chain-of-thought on 3 MMLU datasets, the performance drop for the WiCkeD variant is similar to the one observed when using the LLMs directly, showing that WiCkeD is also challenging for models with enhanced reasoning abilities. WiCkeD also uncovers that some models are more sensitive to the extra reasoning required, providing additional information with respect to the original benchmarks. We relase our code and data at https://github.com/ahmedselhady/wicked-benchmarks.","sentences":["We introduce WiCkeD, a simple method to increase the complexity of existing multiple-choice benchmarks by randomly replacing a choice with \"None of the above\", a method often used in educational tests.","We show that WiCkeD can be automatically applied to any existing benchmark, making it more challenging.","We apply WiCkeD to 6 popular benchmarks and use it to evaluate 18 open-weight LLMs.","The performance of the models drops 12.1 points on average with respect to the original versions of the datasets.","When using chain-of-thought on 3 MMLU datasets, the performance drop for the WiCkeD variant is similar to the one observed when using the LLMs directly, showing that WiCkeD is also challenging for models with enhanced reasoning abilities.","WiCkeD also uncovers that some models are more sensitive to the extra reasoning required, providing additional information with respect to the original benchmarks.","We relase our code and data at https://github.com/ahmedselhady/wicked-benchmarks."],"url":"http://arxiv.org/abs/2502.18316v1"}
{"created":"2025-02-25 16:07:40","title":"GraphRank Pro+: Advancing Talent Analytics Through Knowledge Graphs and Sentiment-Enhanced Skill Profiling","abstract":"The extraction of information from semi-structured text, such as resumes, has long been a challenge due to the diverse formatting styles and subjective content organization. Conventional solutions rely on specialized logic tailored for specific use cases. However, we propose a revolutionary approach leveraging structured Graphs, Natural Language Processing (NLP), and Deep Learning. By abstracting intricate logic into Graph structures, we transform raw data into a comprehensive Knowledge Graph. This innovative framework enables precise information extraction and sophisticated querying. We systematically construct dictionaries assigning skill weights, paving the way for nuanced talent analysis. Our system not only benefits job recruiters and curriculum designers but also empowers job seekers with targeted query-based filtering and ranking capabilities.","sentences":["The extraction of information from semi-structured text, such as resumes, has long been a challenge due to the diverse formatting styles and subjective content organization.","Conventional solutions rely on specialized logic tailored for specific use cases.","However, we propose a revolutionary approach leveraging structured Graphs, Natural Language Processing (NLP), and Deep Learning.","By abstracting intricate logic into Graph structures, we transform raw data into a comprehensive Knowledge Graph.","This innovative framework enables precise information extraction and sophisticated querying.","We systematically construct dictionaries assigning skill weights, paving the way for nuanced talent analysis.","Our system not only benefits job recruiters and curriculum designers but also empowers job seekers with targeted query-based filtering and ranking capabilities."],"url":"http://arxiv.org/abs/2502.18315v1"}
{"created":"2025-02-25 16:03:15","title":"Looking forward: Linguistic theory and methods","abstract":"This chapter examines current developments in linguistic theory and methods, focusing on the increasing integration of computational, cognitive, and evolutionary perspectives. We highlight four major themes shaping contemporary linguistics: (1) the explicit testing of hypotheses about symbolic representation, such as efficiency, locality, and conceptual semantic grounding; (2) the impact of artificial neural networks on theoretical debates and linguistic analysis; (3) the importance of intersubjectivity in linguistic theory; and (4) the growth of evolutionary linguistics. By connecting linguistics with computer science, psychology, neuroscience, and biology, we provide a forward-looking perspective on the changing landscape of linguistic research.","sentences":["This chapter examines current developments in linguistic theory and methods, focusing on the increasing integration of computational, cognitive, and evolutionary perspectives.","We highlight four major themes shaping contemporary linguistics: (1) the explicit testing of hypotheses about symbolic representation, such as efficiency, locality, and conceptual semantic grounding; (2) the impact of artificial neural networks on theoretical debates and linguistic analysis; (3) the importance of intersubjectivity in linguistic theory; and (4) the growth of evolutionary linguistics.","By connecting linguistics with computer science, psychology, neuroscience, and biology, we provide a forward-looking perspective on the changing landscape of linguistic research."],"url":"http://arxiv.org/abs/2502.18313v1"}
{"created":"2025-02-25 15:53:18","title":"GCDance: Genre-Controlled 3D Full Body Dance Generation Driven By Music","abstract":"Generating high-quality full-body dance sequences from music is a challenging task as it requires strict adherence to genre-specific choreography. Moreover, the generated sequences must be both physically realistic and precisely synchronized with the beats and rhythm of the music. To overcome these challenges, we propose GCDance, a classifier-free diffusion framework for generating genre-specific dance motions conditioned on both music and textual prompts. Specifically, our approach extracts music features by combining high-level pre-trained music foundation model features with hand-crafted features for multi-granularity feature fusion. To achieve genre controllability, we leverage CLIP to efficiently embed genre-based textual prompt representations at each time step within our dance generation pipeline. Our GCDance framework can generate diverse dance styles from the same piece of music while ensuring coherence with the rhythm and melody of the music. Extensive experimental results obtained on the FineDance dataset demonstrate that GCDance significantly outperforms the existing state-of-the-art approaches, which also achieve competitive results on the AIST++ dataset. Our ablation and inference time analysis demonstrate that GCDance provides an effective solution for high-quality music-driven dance generation.","sentences":["Generating high-quality full-body dance sequences from music is a challenging task as it requires strict adherence to genre-specific choreography.","Moreover, the generated sequences must be both physically realistic and precisely synchronized with the beats and rhythm of the music.","To overcome these challenges, we propose GCDance, a classifier-free diffusion framework for generating genre-specific dance motions conditioned on both music and textual prompts.","Specifically, our approach extracts music features by combining high-level pre-trained music foundation model features with hand-crafted features for multi-granularity feature fusion.","To achieve genre controllability, we leverage CLIP to efficiently embed genre-based textual prompt representations at each time step within our dance generation pipeline.","Our GCDance framework can generate diverse dance styles from the same piece of music while ensuring coherence with the rhythm and melody of the music.","Extensive experimental results obtained on the FineDance dataset demonstrate that GCDance significantly outperforms the existing state-of-the-art approaches, which also achieve competitive results on the AIST++ dataset.","Our ablation and inference time analysis demonstrate that GCDance provides an effective solution for high-quality music-driven dance generation."],"url":"http://arxiv.org/abs/2502.18309v1"}
{"created":"2025-02-25 15:51:25","title":"RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction","abstract":"In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.   We design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. https://github.com/ElliottYan/RefuteBench-2.0","sentences":["In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses.","However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging.","In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.   ","We design both transient and persistent refutation instructions with different validity periods.","Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans.","Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information.","Interestingly, we also observe that the performance of the initial task decreases as the refutations increase.","Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues.","https://github.com/ElliottYan/RefuteBench-2.0"],"url":"http://arxiv.org/abs/2502.18308v1"}
{"created":"2025-02-25 15:43:16","title":"Experimental Analysis of Efficiency of the Messaging Layer Security for Multiple Delivery Services","abstract":"Messaging Layer security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions. One of the most relevant contributions of MLS is its efficiency, as its communication cost scales logarithmically with the number of members. However, this claim has only been analysed in theoretical models and thus it is unclear how efficient MLS is in real-world scenarios. Furthermore, practical decisions such as the chosen Delivery Service and paradigm can also influence the efficiency and evolution of an MLS group. In this work we analyse MLS from an empirical viewpoint: we provide real-world measurements for metrics such as commit generation and processing times and message sizes under different conditions. In order to obtain these results we have developed a highly configurable environment for empirical evaluations of MLS through the simulation of MLS clients. Among other findings, our results show that computation costs scale linearly in practical scenarios even in the best-case scenario.","sentences":["Messaging Layer security (MLS) and its underlying Continuous Group Key Agreement (CGKA) protocol allows a group of users to share a cryptographic secret in a dynamic manner, such that the secret is modified in member insertions and deletions.","One of the most relevant contributions of MLS is its efficiency, as its communication cost scales logarithmically with the number of members.","However, this claim has only been analysed in theoretical models and thus it is unclear how efficient MLS is in real-world scenarios.","Furthermore, practical decisions such as the chosen Delivery Service and paradigm can also influence the efficiency and evolution of an MLS group.","In this work we analyse MLS from an empirical viewpoint: we provide real-world measurements for metrics such as commit generation and processing times and message sizes under different conditions.","In order to obtain these results we have developed a highly configurable environment for empirical evaluations of MLS through the simulation of MLS clients.","Among other findings, our results show that computation costs scale linearly in practical scenarios even in the best-case scenario."],"url":"http://arxiv.org/abs/2502.18303v1"}
{"created":"2025-02-25 15:42:34","title":"LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation","abstract":"In this paper, we introduce LDGen, a novel method for integrating large language models (LLMs) into existing text-to-image diffusion models while minimizing computational demands. Traditional text encoders, such as CLIP and T5, exhibit limitations in multilingual processing, hindering image generation across diverse languages. We address these challenges by leveraging the advanced capabilities of LLMs. Our approach employs a language representation strategy that applies hierarchical caption optimization and human instruction techniques to derive precise semantic information,. Subsequently, we incorporate a lightweight adapter and a cross-modal refiner to facilitate efficient feature alignment and interaction between LLMs and image features. LDGen reduces training time and enables zero-shot multilingual image generation. Experimental results indicate that our method surpasses baseline models in both prompt adherence and image aesthetic quality, while seamlessly supporting multiple languages. Project page: https://zrealli.github.io/LDGen.","sentences":["In this paper, we introduce LDGen, a novel method for integrating large language models (LLMs) into existing text-to-image diffusion models while minimizing computational demands.","Traditional text encoders, such as CLIP and T5, exhibit limitations in multilingual processing, hindering image generation across diverse languages.","We address these challenges by leveraging the advanced capabilities of LLMs.","Our approach employs a language representation strategy that applies hierarchical caption optimization and human instruction techniques to derive precise semantic information,.","Subsequently, we incorporate a lightweight adapter and a cross-modal refiner to facilitate efficient feature alignment and interaction between LLMs and image features.","LDGen reduces training time and enables zero-shot multilingual image generation.","Experimental results indicate that our method surpasses baseline models in both prompt adherence and image aesthetic quality, while seamlessly supporting multiple languages.","Project page: https://zrealli.github.io/LDGen."],"url":"http://arxiv.org/abs/2502.18302v1"}
{"created":"2025-02-25 15:39:33","title":"Bayesian Computation in Deep Learning","abstract":"This review paper is intended for the 2nd edition of the Handbook of Markov chain Monte Carlo.We provide an introduction to approximate inference techniques as Bayesian computation methods applied to deep learning models. We organize the chapter by presenting popular computational methods for (1) Bayesian neural networks and (2) deep generative models, explaining their unique challenges in posterior inference as well as the solutions.","sentences":["This review paper is intended for the 2nd edition of the Handbook of Markov chain Monte Carlo.","We provide an introduction to approximate inference techniques as Bayesian computation methods applied to deep learning models.","We organize the chapter by presenting popular computational methods for (1) Bayesian neural networks and (2) deep generative models, explaining their unique challenges in posterior inference as well as the solutions."],"url":"http://arxiv.org/abs/2502.18300v1"}
{"created":"2025-02-25 15:34:38","title":"Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach","abstract":"Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries. On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss. One of these technologies is the Internet of Things (IoT). Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems. Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems. In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval. The designed system comprises sensors, a central agent, and irrigation nodes. These agents follow defined rules to maintain soil moisture at a desired level cooperatively. For system simulation, a hybrid agent-based and system dynamics model was designed. In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach. The proposed model, was implemented in AnyLogic computer simulation software. Utilizing the simulation model, irrigation rules were examined. The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed. Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests. Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time.","sentences":["Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries.","On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss.","One of these technologies is the Internet of Things (IoT).","Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems.","Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems.","In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval.","The designed system comprises sensors, a central agent, and irrigation nodes.","These agents follow defined rules to maintain soil moisture at a desired level cooperatively.","For system simulation, a hybrid agent-based and system dynamics model was designed.","In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach.","The proposed model, was implemented in AnyLogic computer simulation software.","Utilizing the simulation model, irrigation rules were examined.","The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed.","Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests.","Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time."],"url":"http://arxiv.org/abs/2502.18298v1"}
{"created":"2025-02-25 15:34:00","title":"DeepCircuitX: A Comprehensive Repository-Level Dataset for RTL Code Understanding, Generation, and PPA Analysis","abstract":"This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis. Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code. This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks. DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels. These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion. Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code. We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations. Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design automation.Our data is available at https://zeju.gitbook.io/lcm-team.","sentences":["This paper introduces DeepCircuitX, a comprehensive repository-level dataset designed to advance RTL (Register Transfer Level) code understanding, generation, and power-performance-area (PPA) analysis.","Unlike existing datasets that are limited to either file-level RTL code or physical layout data, DeepCircuitX provides a holistic, multilevel resource that spans repository, file, module, and block-level RTL code.","This structure enables more nuanced training and evaluation of large language models (LLMs) for RTL-specific tasks.","DeepCircuitX is enriched with Chain of Thought (CoT) annotations, offering detailed descriptions of functionality and structure at multiple levels.","These annotations enhance its utility for a wide range of tasks, including RTL code understanding, generation, and completion.","Additionally, the dataset includes synthesized netlists and PPA metrics, facilitating early-stage design exploration and enabling accurate PPA prediction directly from RTL code.","We demonstrate the dataset's effectiveness on various LLMs finetuned with our dataset and confirm the quality with human evaluations.","Our results highlight DeepCircuitX as a critical resource for advancing RTL-focused machine learning applications in hardware design automation.","Our data is available at https://zeju.gitbook.io/lcm-team."],"url":"http://arxiv.org/abs/2502.18297v1"}
{"created":"2025-02-25 15:33:59","title":"Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective MDPs and its Impact on Randomised Strategies","abstract":"We consider multi-dimensional payoff functions in Markov decision processes, and ask whether a given expected payoff vector can be achieved or not. In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.   We study the structure of the set of expected payoff vectors of all strategies given a multi-dimensional payoff function and its consequences regarding randomisation requirements for strategies. In particular, we prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision. Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies.","sentences":["We consider multi-dimensional payoff functions in Markov decision processes, and ask whether a given expected payoff vector can be achieved or not.","In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.   ","We study the structure of the set of expected payoff vectors of all strategies given a multi-dimensional payoff function and its consequences regarding randomisation requirements for strategies.","In particular, we prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision.","Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies."],"url":"http://arxiv.org/abs/2502.18296v1"}
{"created":"2025-02-25 15:29:51","title":"AMPO: Active Multi-Preference Optimization","abstract":"Multi-preference optimization enriches language-model alignment beyond pairwise preferences by contrasting entire sets of helpful and undesired responses, thereby enabling richer training signals for large language models. During self-play alignment, these models often produce numerous candidate answers per query, rendering it computationally infeasible to include all responses in the training objective. In this work, we propose $\\textit{Active Multi-Preference Optimization}$ (AMPO), a novel approach that combines on-policy generation, a multi-preference group-contrastive loss, and active subset selection. Specifically, we score and embed large candidate pools of responses and then select a small, yet informative, subset that covers reward extremes and distinct semantic clusters for preference optimization. Our contrastive training scheme is capable of identifying not only the best and worst answers but also subtle, underexplored modes that are crucial for robust alignment. Theoretically, we provide guarantees for expected reward maximization using our active selection method, and empirically, AMPO achieves state-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B.","sentences":["Multi-preference optimization enriches language-model alignment beyond pairwise preferences by contrasting entire sets of helpful and undesired responses, thereby enabling richer training signals for large language models.","During self-play alignment, these models often produce numerous candidate answers per query, rendering it computationally infeasible to include all responses in the training objective.","In this work, we propose $\\textit{Active Multi-Preference Optimization}$ (AMPO), a novel approach that combines on-policy generation, a multi-preference group-contrastive loss, and active subset selection.","Specifically, we score and embed large candidate pools of responses and then select a small, yet informative, subset that covers reward extremes and distinct semantic clusters for preference optimization.","Our contrastive training scheme is capable of identifying not only the best and worst answers but also subtle, underexplored modes that are crucial for robust alignment.","Theoretically, we provide guarantees for expected reward maximization using our active selection method, and empirically, AMPO achieves state-of-the-art results on $\\textit{AlpacaEval}$ using Llama 8B."],"url":"http://arxiv.org/abs/2502.18293v1"}
{"created":"2025-02-25 15:29:07","title":"How Vital is the Jurisprudential Relevance: Law Article Intervened Legal Case Retrieval and Matching","abstract":"Legal case retrieval (LCR) aims to automatically scour for comparable legal cases based on a given query, which is crucial for offering relevant precedents to support the judgment in intelligent legal systems. Due to similar goals, it is often associated with a similar case matching (LCM) task. To address them, a daunting challenge is assessing the uniquely defined legal-rational similarity within the judicial domain, which distinctly deviates from the semantic similarities in general text retrieval. Past works either tagged domain-specific factors or incorporated reference laws to capture legal-rational information. However, their heavy reliance on expert or unrealistic assumptions restricts their practical applicability in real-world scenarios. In this paper, we propose an end-to-end model named LCM-LAI to solve the above challenges. Through meticulous theoretical analysis, LCM-LAI employs a dependent multi-task learning framework to capture legal-rational information within legal cases by a law article prediction (LAP) sub-task, without any additional assumptions in inference. Besides, LCM-LAI proposes an article-aware attention mechanism to evaluate the legal-rational similarity between across-case sentences based on law distribution, which is more effective than conventional semantic similarity. Weperform a series of exhaustive experiments including two different tasks involving four real-world datasets. Results demonstrate that LCM-LAI achieves state-of-the-art performance.","sentences":["Legal case retrieval (LCR) aims to automatically scour for comparable legal cases based on a given query, which is crucial for offering relevant precedents to support the judgment in intelligent legal systems.","Due to similar goals, it is often associated with a similar case matching (LCM) task.","To address them, a daunting challenge is assessing the uniquely defined legal-rational similarity within the judicial domain, which distinctly deviates from the semantic similarities in general text retrieval.","Past works either tagged domain-specific factors or incorporated reference laws to capture legal-rational information.","However, their heavy reliance on expert or unrealistic assumptions restricts their practical applicability in real-world scenarios.","In this paper, we propose an end-to-end model named LCM-LAI to solve the above challenges.","Through meticulous theoretical analysis, LCM-LAI employs a dependent multi-task learning framework to capture legal-rational information within legal cases by a law article prediction (LAP) sub-task, without any additional assumptions in inference.","Besides, LCM-LAI proposes an article-aware attention mechanism to evaluate the legal-rational similarity between across-case sentences based on law distribution, which is more effective than conventional semantic similarity.","Weperform a series of exhaustive experiments including two different tasks involving four real-world datasets.","Results demonstrate that LCM-LAI achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2502.18292v1"}
{"created":"2025-02-25 15:28:41","title":"Stealthy Backdoor Attack in Self-Supervised Learning Vision Encoders for Large Vision Language Models","abstract":"Self-supervised learning (SSL) vision encoders learn high-quality image representations and thus have become a vital part of developing vision modality of large vision language models (LVLMs). Due to the high cost of training such encoders, pre-trained encoders are widely shared and deployed into many LVLMs, which are security-critical or bear societal significance. Under this practical scenario, we reveal a new backdoor threat that significant visual hallucinations can be induced into these LVLMs by merely compromising vision encoders. Because of the sharing and reuse of these encoders, many downstream LVLMs may inherit backdoor behaviors from encoders, leading to widespread backdoors. In this work, we propose BadVision, the first method to exploit this vulnerability in SSL vision encoders for LVLMs with novel trigger optimization and backdoor learning techniques. We evaluate BadVision on two types of SSL encoders and LVLMs across eight benchmarks. We show that BadVision effectively drives the LVLMs to attacker-chosen hallucination with over 99% attack success rate, causing a 77.6% relative visual understanding error while maintaining the stealthiness. SoTA backdoor detection methods cannot detect our attack effectively.","sentences":["Self-supervised learning (SSL) vision encoders learn high-quality image representations and thus have become a vital part of developing vision modality of large vision language models (LVLMs).","Due to the high cost of training such encoders, pre-trained encoders are widely shared and deployed into many LVLMs, which are security-critical or bear societal significance.","Under this practical scenario, we reveal a new backdoor threat that significant visual hallucinations can be induced into these LVLMs by merely compromising vision encoders.","Because of the sharing and reuse of these encoders, many downstream LVLMs may inherit backdoor behaviors from encoders, leading to widespread backdoors.","In this work, we propose BadVision, the first method to exploit this vulnerability in SSL vision encoders for LVLMs with novel trigger optimization and backdoor learning techniques.","We evaluate BadVision on two types of SSL encoders and LVLMs across eight benchmarks.","We show that BadVision effectively drives the LVLMs to attacker-chosen hallucination with over 99% attack success rate, causing a 77.6% relative visual understanding error while maintaining the stealthiness.","SoTA backdoor detection methods cannot detect our attack effectively."],"url":"http://arxiv.org/abs/2502.18290v1"}
{"created":"2025-02-25 15:28:41","title":"Neural Network Graph Similarity Computation Based on Graph Fusion","abstract":"Graph similarity learning, crucial for tasks such as graph classification and similarity search, focuses on measuring the similarity between two graph-structured entities. The core challenge in this field is effectively managing the interactions between graphs. Traditional methods often entail separate, redundant computations for each graph pair, leading to unnecessary complexity. This paper revolutionizes the approach by introducing a parallel graph interaction method called graph fusion. By merging the node sequences of graph pairs into a single large graph, our method leverages a global attention mechanism to facilitate interaction computations and to harvest cross-graph insights. We further assess the similarity between graph pairs at two distinct levels-graph-level and node-level-introducing two innovative, yet straightforward, similarity computation algorithms. Extensive testing across five public datasets shows that our model not only outperforms leading baseline models in graph-to-graph classification and regression tasks but also sets a new benchmark for performance and efficiency. The code for this paper is open-source and available at https://github.com/LLiRarry/GFM-code.git","sentences":["Graph similarity learning, crucial for tasks such as graph classification and similarity search, focuses on measuring the similarity between two graph-structured entities.","The core challenge in this field is effectively managing the interactions between graphs.","Traditional methods often entail separate, redundant computations for each graph pair, leading to unnecessary complexity.","This paper revolutionizes the approach by introducing a parallel graph interaction method called graph fusion.","By merging the node sequences of graph pairs into a single large graph, our method leverages a global attention mechanism to facilitate interaction computations and to harvest cross-graph insights.","We further assess the similarity between graph pairs at two distinct levels-graph-level and node-level-introducing two innovative, yet straightforward, similarity computation algorithms.","Extensive testing across five public datasets shows that our model not only outperforms leading baseline models in graph-to-graph classification and regression tasks but also sets a new benchmark for performance and efficiency.","The code for this paper is open-source and available at https://github.com/LLiRarry/GFM-code.git"],"url":"http://arxiv.org/abs/2502.18291v1"}
{"created":"2025-02-25 15:26:39","title":"Yoimiya: A Scalable Framework for Optimal Resource Utilization in ZK-SNARK Systems","abstract":"With the widespread adoption of Zero-Knowledge Proof systems, particularly ZK-SNARK, the efficiency of proof generation, encompassing both the witness generation and proof computation phases, has become a significant concern. While substantial efforts have successfully accelerated proof computation, progress in optimizing witness generation remains limited, which inevitably hampers overall efficiency. In this paper, we propose Yoimiya, a scalable framework with pipeline, to optimize the efficiency in ZK-SNARK systems. First, Yoimiya introduces an automatic circuit partitioning algorithm that divides large circuits of ZK-SNARK into smaller subcircuits, the minimal computing units with smaller memory requirement, allowing parallel processing on multiple units. Second, Yoimiya decouples witness generation from proof computation, and achieves simultaneous executions over units from multiple circuits. Moreover, Yoimiya enables each phase scalable separately by configuring the resource distribution to make the time costs of the two phases aligned, maximizing the resource utilization. Experimental results confirmed that our framework effectively improves the resource utilization and proof generation speed.","sentences":["With the widespread adoption of Zero-Knowledge Proof systems, particularly ZK-SNARK, the efficiency of proof generation, encompassing both the witness generation and proof computation phases, has become a significant concern.","While substantial efforts have successfully accelerated proof computation, progress in optimizing witness generation remains limited, which inevitably hampers overall efficiency.","In this paper, we propose Yoimiya, a scalable framework with pipeline, to optimize the efficiency in ZK-SNARK systems.","First, Yoimiya introduces an automatic circuit partitioning algorithm that divides large circuits of ZK-SNARK into smaller subcircuits, the minimal computing units with smaller memory requirement, allowing parallel processing on multiple units.","Second, Yoimiya decouples witness generation from proof computation, and achieves simultaneous executions over units from multiple circuits.","Moreover, Yoimiya enables each phase scalable separately by configuring the resource distribution to make the time costs of the two phases aligned, maximizing the resource utilization.","Experimental results confirmed that our framework effectively improves the resource utilization and proof generation speed."],"url":"http://arxiv.org/abs/2502.18288v1"}
{"created":"2025-02-25 15:19:21","title":"Uncertainty Modeling in Multimodal Speech Analysis Across the Psychosis Spectrum","abstract":"Capturing subtle speech disruptions across the psychosis spectrum is challenging because of the inherent variability in speech patterns. This variability reflects individual differences and the fluctuating nature of symptoms in both clinical and non-clinical populations. Accounting for uncertainty in speech data is essential for predicting symptom severity and improving diagnostic precision. Speech disruptions characteristic of psychosis appear across the spectrum, including in non-clinical individuals. We develop an uncertainty-aware model integrating acoustic and linguistic features to predict symptom severity and psychosis-related traits. Quantifying uncertainty in specific modalities allows the model to address speech variability, improving prediction accuracy. We analyzed speech data from 114 participants, including 32 individuals with early psychosis and 82 with low or high schizotypy, collected through structured interviews, semi-structured autobiographical tasks, and narrative-driven interactions in German. The model improved prediction accuracy, reducing RMSE and achieving an F1-score of 83% with ECE = 4.5e-2, showing robust performance across different interaction contexts. Uncertainty estimation improved model interpretability by identifying reliability differences in speech markers such as pitch variability, fluency disruptions, and spectral instability. The model dynamically adjusted to task structures, weighting acoustic features more in structured settings and linguistic features in unstructured contexts. This approach strengthens early detection, personalized assessment, and clinical decision-making in psychosis-spectrum research.","sentences":["Capturing subtle speech disruptions across the psychosis spectrum is challenging because of the inherent variability in speech patterns.","This variability reflects individual differences and the fluctuating nature of symptoms in both clinical and non-clinical populations.","Accounting for uncertainty in speech data is essential for predicting symptom severity and improving diagnostic precision.","Speech disruptions characteristic of psychosis appear across the spectrum, including in non-clinical individuals.","We develop an uncertainty-aware model integrating acoustic and linguistic features to predict symptom severity and psychosis-related traits.","Quantifying uncertainty in specific modalities allows the model to address speech variability, improving prediction accuracy.","We analyzed speech data from 114 participants, including 32 individuals with early psychosis and 82 with low or high schizotypy, collected through structured interviews, semi-structured autobiographical tasks, and narrative-driven interactions in German.","The model improved prediction accuracy, reducing RMSE and achieving an F1-score of 83% with ECE = 4.5e-2, showing robust performance across different interaction contexts.","Uncertainty estimation improved model interpretability by identifying reliability differences in speech markers such as pitch variability, fluency disruptions, and spectral instability.","The model dynamically adjusted to task structures, weighting acoustic features more in structured settings and linguistic features in unstructured contexts.","This approach strengthens early detection, personalized assessment, and clinical decision-making in psychosis-spectrum research."],"url":"http://arxiv.org/abs/2502.18285v1"}
{"created":"2025-02-25 15:16:17","title":"Better Aligned with Survey Respondents or Training Data? Unveiling Political Leanings of LLMs on U.S. Supreme Court Cases","abstract":"The increased adoption of Large Language Models (LLMs) and their potential to shape public opinion have sparked interest in assessing these models' political leanings. Building on previous research that compared LLMs and human opinions and observed political bias in system responses, we take a step further to investigate the underlying causes of such biases by empirically examining how the values and biases embedded in training corpora shape model outputs. Specifically, we propose a method to quantitatively evaluate political leanings embedded in the large pretraining corpora. Subsequently we investigate to whom are the LLMs' political leanings more aligned with, their pretrainig corpora or the surveyed human opinions. As a case study, we focus on probing the political leanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics such as abortion and voting rights. Our findings reveal that LLMs strongly reflect the political leanings in their training data, and no strong correlation is observed with their alignment to human opinions as expressed in surveys. These results underscore the importance of responsible curation of training data and the need for robust evaluation metrics to ensure LLMs' alignment with human-centered values.","sentences":["The increased adoption of Large Language Models (LLMs) and their potential to shape public opinion have sparked interest in assessing these models' political leanings.","Building on previous research that compared LLMs and human opinions and observed political bias in system responses, we take a step further to investigate the underlying causes of such biases by empirically examining how the values and biases embedded in training corpora shape model outputs.","Specifically, we propose a method to quantitatively evaluate political leanings embedded in the large pretraining corpora.","Subsequently we investigate to whom are the LLMs' political leanings more aligned with, their pretrainig corpora or the surveyed human opinions.","As a case study, we focus on probing the political leanings of LLMs in 32 U.S. Supreme Court cases, addressing contentious topics such as abortion and voting rights.","Our findings reveal that LLMs strongly reflect the political leanings in their training data, and no strong correlation is observed with their alignment to human opinions as expressed in surveys.","These results underscore the importance of responsible curation of training data and the need for robust evaluation metrics to ensure LLMs' alignment with human-centered values."],"url":"http://arxiv.org/abs/2502.18282v1"}
{"created":"2025-02-25 15:07:40","title":"Self-Adjust Softmax","abstract":"The softmax function is crucial in Transformer attention, which normalizes each row of the attention scores with summation to one, achieving superior performances over other alternative functions. However, the softmax function can face a gradient vanishing issue when some elements of the attention scores approach extreme values, such as probabilities close to one or zero. In this paper, we propose Self-Adjust Softmax (SA-Softmax) to address this issue by modifying $softmax(x)$ to $x \\cdot softmax(x)$ and its normalized variant $\\frac{(x - min(x_{\\min},0))}{max(0,x_{max})-min(x_{min},0)} \\cdot softmax(x)$. We theoretically show that SA-Softmax provides enhanced gradient properties compared to the vanilla softmax function. Moreover, SA-Softmax Attention can be seamlessly integrated into existing Transformer models to their attention mechanisms with minor adjustments. We conducted experiments to evaluate the empirical performance of Transformer models using SA-Softmax compared to the vanilla softmax function. These experiments, involving models with up to 2.7 billion parameters, are conducted across diverse datasets, language tasks, and positional encoding methods.","sentences":["The softmax function is crucial in Transformer attention, which normalizes each row of the attention scores with summation to one, achieving superior performances over other alternative functions.","However, the softmax function can face a gradient vanishing issue when some elements of the attention scores approach extreme values, such as probabilities close to one or zero.","In this paper, we propose Self-Adjust Softmax (SA-Softmax) to address this issue by modifying $softmax(x)$ to $x \\cdot softmax(x)$ and its normalized variant $\\frac{(x - min(x_{\\min},0))}{max(0,x_{max})-min(x_{min},0)}","\\cdot softmax(x)$. We theoretically show that SA-Softmax provides enhanced gradient properties compared to the vanilla softmax function.","Moreover, SA-Softmax Attention can be seamlessly integrated into existing Transformer models to their attention mechanisms with minor adjustments.","We conducted experiments to evaluate the empirical performance of Transformer models using SA-Softmax compared to the vanilla softmax function.","These experiments, involving models with up to 2.7 billion parameters, are conducted across diverse datasets, language tasks, and positional encoding methods."],"url":"http://arxiv.org/abs/2502.18277v1"}
{"created":"2025-02-25 15:05:12","title":"Citrus: Leveraging Expert Cognitive Pathways in a Medical Language Model for Advanced Medical Decision Support","abstract":"Large language models (LLMs), particularly those with reasoning capabilities, have rapidly advanced in recent years, demonstrating significant potential across a wide range of applications. However, their deployment in healthcare, especially in disease reasoning tasks, is hindered by the challenge of acquiring expert-level cognitive data. In this paper, we introduce Citrus, a medical language model that bridges the gap between clinical expertise and AI reasoning by emulating the cognitive processes of medical experts. The model is trained on a large corpus of simulated expert disease reasoning data, synthesized using a novel approach that accurately captures the decision-making pathways of clinicians. This approach enables Citrus to better simulate the complex reasoning processes involved in diagnosing and treating medical conditions.To further address the lack of publicly available datasets for medical reasoning tasks, we release the last-stage training data, including a custom-built medical diagnostic dialogue dataset. This open-source contribution aims to support further research and development in the field. Evaluations using authoritative benchmarks such as MedQA, covering tasks in medical reasoning and language understanding, show that Citrus achieves superior performance compared to other models of similar size. These results highlight Citrus potential to significantly enhance medical decision support systems, providing a more accurate and efficient tool for clinical decision-making.","sentences":["Large language models (LLMs), particularly those with reasoning capabilities, have rapidly advanced in recent years, demonstrating significant potential across a wide range of applications.","However, their deployment in healthcare, especially in disease reasoning tasks, is hindered by the challenge of acquiring expert-level cognitive data.","In this paper, we introduce Citrus, a medical language model that bridges the gap between clinical expertise and AI reasoning by emulating the cognitive processes of medical experts.","The model is trained on a large corpus of simulated expert disease reasoning data, synthesized using a novel approach that accurately captures the decision-making pathways of clinicians.","This approach enables Citrus to better simulate the complex reasoning processes involved in diagnosing and treating medical conditions.","To further address the lack of publicly available datasets for medical reasoning tasks, we release the last-stage training data, including a custom-built medical diagnostic dialogue dataset.","This open-source contribution aims to support further research and development in the field.","Evaluations using authoritative benchmarks such as MedQA, covering tasks in medical reasoning and language understanding, show that Citrus achieves superior performance compared to other models of similar size.","These results highlight Citrus potential to significantly enhance medical decision support systems, providing a more accurate and efficient tool for clinical decision-making."],"url":"http://arxiv.org/abs/2502.18274v1"}
{"created":"2025-02-25 15:04:17","title":"Beyond In-Distribution Success: Scaling Curves of CoT Granularity for Language Model Generalization","abstract":"Generalization to novel compound tasks under distribution shift is important for deploying transformer-based language models (LMs). This work investigates Chain-of-Thought (CoT) reasoning as a means to enhance OOD generalization. Through controlled experiments across several compound tasks, we reveal three key insights: (1) While QA-trained models achieve near-perfect in-distribution accuracy, their OOD performance degrades catastrophically, even with 10000k+ training examples; (2) the granularity of CoT data strongly correlates with generalization performance; finer-grained CoT data leads to better generalization; (3) CoT exhibits remarkable sample efficiency, matching QA performance with much less (even 80%) data.   Theoretically, we demonstrate that compound tasks inherently permit shortcuts in Q-A data that misalign with true reasoning principles, while CoT forces internalization of valid dependency structures, and thus can achieve better generalization. Further, we show that transformer positional embeddings can amplify generalization by emphasizing subtask condition recurrence in long CoT sequences. Our combined theoretical and empirical analysis provides compelling evidence for CoT reasoning as a crucial training paradigm for enabling LM generalization under real-world distributional shifts for compound tasks.","sentences":["Generalization to novel compound tasks under distribution shift is important for deploying transformer-based language models (LMs).","This work investigates Chain-of-Thought (CoT) reasoning as a means to enhance OOD generalization.","Through controlled experiments across several compound tasks, we reveal three key insights: (1) While QA-trained models achieve near-perfect in-distribution accuracy, their OOD performance degrades catastrophically, even with 10000k+ training examples; (2) the granularity of CoT data strongly correlates with generalization performance; finer-grained CoT data leads to better generalization; (3) CoT exhibits remarkable sample efficiency, matching QA performance with much less (even 80%) data.   ","Theoretically, we demonstrate that compound tasks inherently permit shortcuts in Q-A data that misalign with true reasoning principles, while CoT forces internalization of valid dependency structures, and thus can achieve better generalization.","Further, we show that transformer positional embeddings can amplify generalization by emphasizing subtask condition recurrence in long CoT sequences.","Our combined theoretical and empirical analysis provides compelling evidence for CoT reasoning as a crucial training paradigm for enabling LM generalization under real-world distributional shifts for compound tasks."],"url":"http://arxiv.org/abs/2502.18273v1"}
{"created":"2025-02-25 14:53:40","title":"Parsing TTree Formula in Python","abstract":"Uproot can read ROOT files directly in pure Python but cannot (yet) compute expressions in ROOT's TTreeFormula expression language. Despite its popularity, this language has only one implementation and no formal specification. In a package called \"formulate,\" we defined the language's syntax in standard BNF and parse it with Lark, a fast and modern parsing toolkit in Python. With formulate, users can now convert ROOT TTreeFormula expressions into NumExpr and Awkward Array manipulations.   In this contribution, we describe BNF notation and the Look Ahead Left to Right (LALR) parsing algorithm, which scales linearly with expression length. We also present the challenges with interpreting TTreeFormula expressions as a functional language; some function-like forms can't be expressed as true functions. We also describe the design of the abstract syntax tree that facilitates conversion between the three languages. The formulate package has zero package dependencies, so we are adding it as one of Uproot's dependencies so that Uproot will be able to use TTreeFormula expressions, whether they are hand-written or embedded in a ROOT file as TTree aliases.","sentences":["Uproot can read ROOT files directly in pure Python but cannot (yet) compute expressions in ROOT's TTreeFormula expression language.","Despite its popularity, this language has only one implementation and no formal specification.","In a package called \"formulate,\" we defined the language's syntax in standard BNF and parse it with Lark, a fast and modern parsing toolkit in Python.","With formulate, users can now convert ROOT TTreeFormula expressions into NumExpr and Awkward Array manipulations.   ","In this contribution, we describe BNF notation and the Look Ahead Left to Right (LALR) parsing algorithm, which scales linearly with expression length.","We also present the challenges with interpreting TTreeFormula expressions as a functional language; some function-like forms can't be expressed as true functions.","We also describe the design of the abstract syntax tree that facilitates conversion between the three languages.","The formulate package has zero package dependencies, so we are adding it as one of Uproot's dependencies so that Uproot will be able to use TTreeFormula expressions, whether they are hand-written or embedded in a ROOT file as TTree aliases."],"url":"http://arxiv.org/abs/2502.18266v1"}
{"created":"2025-02-25 14:51:22","title":"A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions","abstract":"We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.","sentences":["We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services.","The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments.","We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them.","The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever.","We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012).","Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents.","The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered.","Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation."],"url":"http://arxiv.org/abs/2502.18265v1"}
