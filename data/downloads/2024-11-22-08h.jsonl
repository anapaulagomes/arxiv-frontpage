{"created":"2024-11-21 18:59:55","title":"Insight-V: Exploring Long-Chain Visual Reasoning with Multimodal Large Language Models","abstract":"Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1. Despite various efforts to improve LLM reasoning, high-quality long-chain reasoning data and optimized training pipelines still remain inadequately explored in vision-language tasks. In this paper, we present Insight-V, an early effort to 1) scalably produce long and robust reasoning data for complex multi-modal tasks, and 2) an effective training pipeline to enhance the reasoning capabilities of multi-modal large language models (MLLMs). Specifically, to create long and structured reasoning data without human labor, we design a two-step pipeline with a progressive strategy to generate sufficiently long and diverse reasoning paths and a multi-granularity assessment method to ensure data quality. We observe that directly supervising MLLMs with such long and complex reasoning data will not yield ideal reasoning ability. To tackle this problem, we design a multi-agent system consisting of a reasoning agent dedicated to performing long-chain reasoning and a summary agent trained to judge and summarize reasoning results. We further incorporate an iterative DPO algorithm to enhance the reasoning agent's generation stability and quality. Based on the popular LLaVA-NeXT model and our stronger base MLLM, we demonstrate significant performance gains across challenging multi-modal benchmarks requiring visual reasoning. Benefiting from our multi-agent system, Insight-V can also easily maintain or improve performance on perception-focused multi-modal tasks.","sentences":["Large Language Models (LLMs) demonstrate enhanced capabilities and reliability by reasoning more, evolving from Chain-of-Thought prompting to product-level solutions like OpenAI o1.","Despite various efforts to improve LLM reasoning, high-quality long-chain reasoning data and optimized training pipelines still remain inadequately explored in vision-language tasks.","In this paper, we present Insight-V, an early effort to 1) scalably produce long and robust reasoning data for complex multi-modal tasks, and 2) an effective training pipeline to enhance the reasoning capabilities of multi-modal large language models (MLLMs).","Specifically, to create long and structured reasoning data without human labor, we design a two-step pipeline with a progressive strategy to generate sufficiently long and diverse reasoning paths and a multi-granularity assessment method to ensure data quality.","We observe that directly supervising MLLMs with such long and complex reasoning data will not yield ideal reasoning ability.","To tackle this problem, we design a multi-agent system consisting of a reasoning agent dedicated to performing long-chain reasoning and a summary agent trained to judge and summarize reasoning results.","We further incorporate an iterative DPO algorithm to enhance the reasoning agent's generation stability and quality.","Based on the popular LLaVA-NeXT model and our stronger base MLLM, we demonstrate significant performance gains across challenging multi-modal benchmarks requiring visual reasoning.","Benefiting from our multi-agent system, Insight-V can also easily maintain or improve performance on perception-focused multi-modal tasks."],"url":"http://arxiv.org/abs/2411.14432v1"}
{"created":"2024-11-21 18:59:52","title":"On Optimal Testing of Linearity","abstract":"Linearity testing has been a focal problem in property testing of functions. We combine different known techniques and observations about linearity testing in order to resolve two recent versions of this task.   First, we focus on the online manipulations model introduced by Kalemaj, Raskhodnikova and Varma (ITCS 2022 \\& Theory of Computing 2023). In this model, up to $t$ data entries are adversarially manipulated after each query is answered. Ben-Eliezer, Kelman, Meir, and Raskhodnikova (ITCS 2024) showed an asymptotically optimal linearity tester that is resilient to $t$ manipulations per query, but their approach fails if $t$ is too large. We extend this result, showing an optimal tester for almost any possible value of $t$. First, we simplify their result when $t$ is small, and for larger values of $t$ we instead use sample-based testers, as defined by Goldreich and Ron (ACM Transactions on Computation Theory 2016). A key observation is that sample-based testing is resilient to online manipulations, but still achieves optimal query complexity for linearity when $t$ is large. We complement our result by showing that when $t$ is \\emph{very} large, any reasonable property, and in particular linearity, cannot be tested at all.   Second, we consider linearity over the reals with proximity parameter $\\varepsilon$. Fleming and Yoshida (ITCS 2020) gave a tester using $O(1/\\varepsilon\\ \\cdot log(1/\\varepsilon))$ queries. We simplify their algorithms and modify the analysis accordingly, showing an optimal tester that only uses $O(1/\\varepsilon)$ queries. This modification works for the low-degree testers presented in Arora, Bhattacharyya, Fleming, Kelman, and Yoshida (SODA 2023) as well, resulting in optimal testers for degree-$d$ polynomials, for any constant degree $d$.","sentences":["Linearity testing has been a focal problem in property testing of functions.","We combine different known techniques and observations about linearity testing in order to resolve two recent versions of this task.   ","First, we focus on the online manipulations model introduced by Kalemaj, Raskhodnikova and Varma (ITCS 2022 \\& Theory of Computing 2023).","In this model, up to $t$ data entries are adversarially manipulated after each query is answered.","Ben-Eliezer, Kelman, Meir, and Raskhodnikova (ITCS 2024) showed an asymptotically optimal linearity tester that is resilient to $t$ manipulations per query, but their approach fails if $t$ is too large.","We extend this result, showing an optimal tester for almost any possible value of $t$. First, we simplify their result when $t$ is small, and for larger values of $t$ we instead use sample-based testers, as defined by Goldreich and Ron (ACM Transactions on Computation Theory 2016).","A key observation is that sample-based testing is resilient to online manipulations, but still achieves optimal query complexity for linearity when $t$ is large.","We complement our result by showing that when $t$ is \\emph{very} large, any reasonable property, and in particular linearity, cannot be tested at all.   ","Second, we consider linearity over the reals with proximity parameter $\\varepsilon$. Fleming and Yoshida (ITCS 2020) gave a tester using $O(1/\\varepsilon\\ \\cdot log(1/\\varepsilon))$ queries.","We simplify their algorithms and modify the analysis accordingly, showing an optimal tester that only uses $O(1/\\varepsilon)$ queries.","This modification works for the low-degree testers presented in Arora, Bhattacharyya, Fleming, Kelman, and Yoshida (SODA 2023) as well, resulting in optimal testers for degree-$d$ polynomials, for any constant degree $d$."],"url":"http://arxiv.org/abs/2411.14431v1"}
{"created":"2024-11-21 18:59:51","title":"Stable Flow: Vital Layers for Training-Free Image Editing","abstract":"Diffusion models have revolutionized the field of content synthesis and editing. Recent models have replaced the traditional UNet architecture with the Diffusion Transformer (DiT), and employed flow-matching for improved training and sampling. However, they exhibit limited generation diversity. In this work, we leverage this limitation to perform consistent image edits via selective injection of attention features. The main challenge is that, unlike the UNet-based models, DiT lacks a coarse-to-fine synthesis structure, making it unclear in which layers to perform the injection. Therefore, we propose an automatic method to identify \"vital layers\" within DiT, crucial for image formation, and demonstrate how these layers facilitate a range of controlled stable edits, from non-rigid modifications to object addition, using the same mechanism. Next, to enable real-image editing, we introduce an improved image inversion method for flow models. Finally, we evaluate our approach through qualitative and quantitative comparisons, along with a user study, and demonstrate its effectiveness across multiple applications. The project page is available at https://omriavrahami.com/stable-flow","sentences":["Diffusion models have revolutionized the field of content synthesis and editing.","Recent models have replaced the traditional UNet architecture with the Diffusion Transformer (DiT), and employed flow-matching for improved training and sampling.","However, they exhibit limited generation diversity.","In this work, we leverage this limitation to perform consistent image edits via selective injection of attention features.","The main challenge is that, unlike the UNet-based models, DiT lacks a coarse-to-fine synthesis structure, making it unclear in which layers to perform the injection.","Therefore, we propose an automatic method to identify \"vital layers\" within DiT, crucial for image formation, and demonstrate how these layers facilitate a range of controlled stable edits, from non-rigid modifications to object addition, using the same mechanism.","Next, to enable real-image editing, we introduce an improved image inversion method for flow models.","Finally, we evaluate our approach through qualitative and quantitative comparisons, along with a user study, and demonstrate its effectiveness across multiple applications.","The project page is available at https://omriavrahami.com/stable-flow"],"url":"http://arxiv.org/abs/2411.14430v1"}
{"created":"2024-11-21 18:59:08","title":"Revisiting the Integration of Convolution and Attention for Vision Backbone","abstract":"Convolutions (Convs) and multi-head self-attentions (MHSAs) are typically considered alternatives to each other for building vision backbones. Although some works try to integrate both, they apply the two operators simultaneously at the finest pixel granularity. With Convs responsible for per-pixel feature extraction already, the question is whether we still need to include the heavy MHSAs at such a fine-grained level. In fact, this is the root cause of the scalability issue w.r.t. the input resolution for vision transformers. To address this important problem, we propose in this work to use MSHAs and Convs in parallel \\textbf{at different granularity levels} instead. Specifically, in each layer, we use two different ways to represent an image: a fine-grained regular grid and a coarse-grained set of semantic slots. We apply different operations to these two representations: Convs to the grid for local features, and MHSAs to the slots for global features. A pair of fully differentiable soft clustering and dispatching modules is introduced to bridge the grid and set representations, thus enabling local-global fusion. Through extensive experiments on various vision tasks, we empirically verify the potential of the proposed integration scheme, named \\textit{GLMix}: by offloading the burden of fine-grained features to light-weight Convs, it is sufficient to use MHSAs in a few (e.g., 64) semantic slots to match the performance of recent state-of-the-art backbones, while being more efficient. Our visualization results also demonstrate that the soft clustering module produces a meaningful semantic grouping effect with only IN1k classification supervision, which may induce better interpretability and inspire new weakly-supervised semantic segmentation approaches. Code will be available at \\url{https://github.com/rayleizhu/GLMix}.","sentences":["Convolutions (Convs) and multi-head self-attentions (MHSAs) are typically considered alternatives to each other for building vision backbones.","Although some works try to integrate both, they apply the two operators simultaneously at the finest pixel granularity.","With Convs responsible for per-pixel feature extraction already, the question is whether we still need to include the heavy MHSAs at such a fine-grained level.","In fact, this is the root cause of the scalability issue w.r.t.","the input resolution for vision transformers.","To address this important problem, we propose in this work to use MSHAs and Convs in parallel \\textbf{at different granularity levels} instead.","Specifically, in each layer, we use two different ways to represent an image: a fine-grained regular grid and a coarse-grained set of semantic slots.","We apply different operations to these two representations: Convs to the grid for local features, and MHSAs to the slots for global features.","A pair of fully differentiable soft clustering and dispatching modules is introduced to bridge the grid and set representations, thus enabling local-global fusion.","Through extensive experiments on various vision tasks, we empirically verify the potential of the proposed integration scheme, named \\textit{GLMix}: by offloading the burden of fine-grained features to light-weight Convs, it is sufficient to use MHSAs in a few (e.g., 64) semantic slots to match the performance of recent state-of-the-art backbones, while being more efficient.","Our visualization results also demonstrate that the soft clustering module produces a meaningful semantic grouping effect with only IN1k classification supervision, which may induce better interpretability and inspire new weakly-supervised semantic segmentation approaches.","Code will be available at \\url{https://github.com/rayleizhu/GLMix}."],"url":"http://arxiv.org/abs/2411.14429v1"}
{"created":"2024-11-21 18:58:32","title":"Transformer-based Heuristic for Advanced Air Mobility Planning","abstract":"Safety is extremely important for urban flights of autonomous Unmanned Aerial Vehicles (UAVs). Risk-aware path planning is one of the most effective methods to guarantee the safety of UAVs. This type of planning can be represented as a Constrained Shortest Path (CSP) problem, which seeks to find the shortest route that meets a predefined safety constraint. Solving CSP problems is NP-hard, presenting significant computational challenges. Although traditional methods can accurately solve CSP problems, they tend to be very slow. Previously, we introduced an additional safety dimension to the traditional A* algorithm, known as ASD A*, to effectively handle Constrained Shortest Path (CSP) problems. Then, we developed a custom learning-based heuristic using transformer-based neural networks, which significantly reduced computational load and enhanced the performance of the ASD A* algorithm. In this paper, we expand our dataset to include more risk maps and tasks, improve the proposed model, and increase its performance. We also introduce a new heuristic strategy and a novel neural network, which enhance the overall effectiveness of our approach.","sentences":["Safety is extremely important for urban flights of autonomous Unmanned Aerial Vehicles (UAVs).","Risk-aware path planning is one of the most effective methods to guarantee the safety of UAVs.","This type of planning can be represented as a Constrained Shortest Path (CSP) problem, which seeks to find the shortest route that meets a predefined safety constraint.","Solving CSP problems is NP-hard, presenting significant computational challenges.","Although traditional methods can accurately solve CSP problems, they tend to be very slow.","Previously, we introduced an additional safety dimension to the traditional A* algorithm, known as ASD A*, to effectively handle Constrained Shortest Path (CSP) problems.","Then, we developed a custom learning-based heuristic using transformer-based neural networks, which significantly reduced computational load and enhanced the performance of the ASD A* algorithm.","In this paper, we expand our dataset to include more risk maps and tasks, improve the proposed model, and increase its performance.","We also introduce a new heuristic strategy and a novel neural network, which enhance the overall effectiveness of our approach."],"url":"http://arxiv.org/abs/2411.14427v1"}
{"created":"2024-11-21 18:57:17","title":"Whack-a-Chip: The Futility of Hardware-Centric Export Controls","abstract":"U.S. export controls on semiconductors are widely known to be permeable, with the People's Republic of China (PRC) steadily creating state-of-the-art artificial intelligence (AI) models with exfiltrated chips. This paper presents the first concrete, public evidence of how leading PRC AI labs evade and circumvent U.S. export controls. We examine how Chinese companies, notably Tencent, are not only using chips that are restricted under U.S. export controls but are also finding ways to circumvent these regulations by using software and modeling techniques that maximize less capable hardware. Specifically, we argue that Tencent's ability to power its Hunyuan-Large model with non-export controlled NVIDIA H20s exemplifies broader gains in efficiency in machine learning that have eroded the moat that the United States initially built via its existing export controls. Finally, we examine the implications of this finding for the future of the United States' export control strategy.","sentences":["U.S. export controls on semiconductors are widely known to be permeable, with the People's Republic of China (PRC) steadily creating state-of-the-art artificial intelligence (AI) models with exfiltrated chips.","This paper presents the first concrete, public evidence of how leading PRC AI labs evade and circumvent U.S. export controls.","We examine how Chinese companies, notably Tencent, are not only using chips that are restricted under U.S. export controls but are also finding ways to circumvent these regulations by using software and modeling techniques that maximize less capable hardware.","Specifically, we argue that Tencent's ability to power its Hunyuan-Large model with non-export controlled NVIDIA H20s exemplifies broader gains in efficiency in machine learning that have eroded the moat that the United States initially built via its existing export controls.","Finally, we examine the implications of this finding for the future of the United States' export control strategy."],"url":"http://arxiv.org/abs/2411.14425v1"}
{"created":"2024-11-21 18:56:33","title":"Learning Fair Robustness via Domain Mixup","abstract":"Adversarial training is one of the predominant techniques for training classifiers that are robust to adversarial attacks. Recent work, however has found that adversarial training, which makes the overall classifier robust, it does not necessarily provide equal amount of robustness for all classes. In this paper, we propose the use of mixup for the problem of learning fair robust classifiers, which can provide similar robustness across all classes. Specifically, the idea is to mix inputs from the same classes and perform adversarial training on mixed up inputs. We present a theoretical analysis of this idea for the case of linear classifiers and show that mixup combined with adversarial training can provably reduce the class-wise robustness disparity. This method not only contributes to reducing the disparity in class-wise adversarial risk, but also the class-wise natural risk. Complementing our theoretical analysis, we also provide experimental results on both synthetic data and the real world dataset (CIFAR-10), which shows improvement in class wise disparities for both natural and adversarial risks.","sentences":["Adversarial training is one of the predominant techniques for training classifiers that are robust to adversarial attacks.","Recent work, however has found that adversarial training, which makes the overall classifier robust, it does not necessarily provide equal amount of robustness for all classes.","In this paper, we propose the use of mixup for the problem of learning fair robust classifiers, which can provide similar robustness across all classes.","Specifically, the idea is to mix inputs from the same classes and perform adversarial training on mixed up inputs.","We present a theoretical analysis of this idea for the case of linear classifiers and show that mixup combined with adversarial training can provably reduce the class-wise robustness disparity.","This method not only contributes to reducing the disparity in class-wise adversarial risk, but also the class-wise natural risk.","Complementing our theoretical analysis, we also provide experimental results on both synthetic data and the real world dataset (CIFAR-10), which shows improvement in class wise disparities for both natural and adversarial risks."],"url":"http://arxiv.org/abs/2411.14424v1"}
{"created":"2024-11-21 18:55:23","title":"Unleashing the Potential of Multi-modal Foundation Models and Video Diffusion for 4D Dynamic Physical Scene Simulation","abstract":"Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles. However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials. We introduce a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation. Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation. We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss. This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations.","sentences":["Realistic simulation of dynamic scenes requires accurately capturing diverse material properties and modeling complex object interactions grounded in physical principles.","However, existing methods are constrained to basic material types with limited predictable parameters, making them insufficient to represent the complexity of real-world materials.","We introduce a novel approach that leverages multi-modal foundation models and video diffusion to achieve enhanced 4D dynamic scene simulation.","Our method utilizes multi-modal models to identify material types and initialize material parameters through image queries, while simultaneously inferring 3D Gaussian splats for detailed scene representation.","We further refine these material parameters using video diffusion with a differentiable Material Point Method (MPM) and optical flow guidance rather than render loss or Score Distillation Sampling (SDS) loss.","This integrated framework enables accurate prediction and realistic simulation of dynamic interactions in real-world scenarios, advancing both accuracy and flexibility in physics-based simulations."],"url":"http://arxiv.org/abs/2411.14423v1"}
{"created":"2024-11-21 18:54:43","title":"From RNNs to Foundation Models: An Empirical Study on Commercial Building Energy Consumption","abstract":"Accurate short-term energy consumption forecasting for commercial buildings is crucial for smart grid operations. While smart meters and deep learning models enable forecasting using past data from multiple buildings, data heterogeneity from diverse buildings can reduce model performance. The impact of increasing dataset heterogeneity in time series forecasting, while keeping size and model constant, is understudied. We tackle this issue using the ComStock dataset, which provides synthetic energy consumption data for U.S. commercial buildings. Two curated subsets, identical in size and region but differing in building type diversity, are used to assess the performance of various time series forecasting models, including fine-tuned open-source foundation models (FMs). The results show that dataset heterogeneity and model architecture have a greater impact on post-training forecasting performance than the parameter count. Moreover, despite the higher computational cost, fine-tuned FMs demonstrate competitive performance compared to base models trained from scratch.","sentences":["Accurate short-term energy consumption forecasting for commercial buildings is crucial for smart grid operations.","While smart meters and deep learning models enable forecasting using past data from multiple buildings, data heterogeneity from diverse buildings can reduce model performance.","The impact of increasing dataset heterogeneity in time series forecasting, while keeping size and model constant, is understudied.","We tackle this issue using the ComStock dataset, which provides synthetic energy consumption data for U.S. commercial buildings.","Two curated subsets, identical in size and region but differing in building type diversity, are used to assess the performance of various time series forecasting models, including fine-tuned open-source foundation models (FMs).","The results show that dataset heterogeneity and model architecture have a greater impact on post-training forecasting performance than the parameter count.","Moreover, despite the higher computational cost, fine-tuned FMs demonstrate competitive performance compared to base models trained from scratch."],"url":"http://arxiv.org/abs/2411.14421v1"}
{"created":"2024-11-21 18:53:58","title":"Aggregating Funnels for Faster Fetch&Add and Queues","abstract":"Many concurrent algorithms require processes to perform fetch-and-add operations on a single memory location, which can be a hot spot of contention. We present a novel algorithm called Aggregating Funnels that reduces this contention by spreading the fetch-and-add operations across multiple memory locations. It aggregates fetch-and-add operations into batches so that the batch can be performed by a single hardware fetch-and-add instruction on one location and all operations in the batch can efficiently compute their results by performing a fetch-and-add instruction on a different location. We show experimentally that this approach achieves higher throughput than previous combining techniques, such as Combining Funnels, and is substantially more scalable than applying hardware fetch-and-add instructions on a single memory location. We show that replacing the fetch-and-add instructions in the fastest state-of-the-art concurrent queue by our Aggregating Funnels eliminates a bottleneck and greatly improves the queue's overall throughput.","sentences":["Many concurrent algorithms require processes to perform fetch-and-add operations on a single memory location, which can be a hot spot of contention.","We present a novel algorithm called Aggregating Funnels that reduces this contention by spreading the fetch-and-add operations across multiple memory locations.","It aggregates fetch-and-add operations into batches so that the batch can be performed by a single hardware fetch-and-add instruction on one location and all operations in the batch can efficiently compute their results by performing a fetch-and-add instruction on a different location.","We show experimentally that this approach achieves higher throughput than previous combining techniques, such as Combining Funnels, and is substantially more scalable than applying hardware fetch-and-add instructions on a single memory location.","We show that replacing the fetch-and-add instructions in the fastest state-of-the-art concurrent queue by our Aggregating Funnels eliminates a bottleneck and greatly improves the queue's overall throughput."],"url":"http://arxiv.org/abs/2411.14420v1"}
{"created":"2024-11-21 18:46:23","title":"Multi-Agent Environments for Vehicle Routing Problems","abstract":"Research on Reinforcement Learning (RL) approaches for discrete optimization problems has increased considerably, extending RL to an area classically dominated by Operations Research (OR). Vehicle routing problems are a good example of discrete optimization problems with high practical relevance where RL techniques have had considerable success. Despite these advances, open-source development frameworks remain scarce, hampering both the testing of algorithms and the ability to objectively compare results. This ultimately slows down progress in the field and limits the exchange of ideas between the RL and OR communities.   Here we propose a library composed of multi-agent environments that simulates classic vehicle routing problems. The library, built on PyTorch, provides a flexible modular architecture design that allows easy customization and incorporation of new routing problems. It follows the Agent Environment Cycle (\"AEC\") games model and has an intuitive API, enabling rapid adoption and easy integration into existing reinforcement learning frameworks.   The library allows for a straightforward use of classical OR benchmark instances in order to narrow the gap between the test beds for algorithm benchmarking used by the RL and OR communities. Additionally, we provide benchmark instance sets for each environment, as well as baseline RL models and training code.","sentences":["Research on Reinforcement Learning (RL) approaches for discrete optimization problems has increased considerably, extending RL to an area classically dominated by Operations Research (OR).","Vehicle routing problems are a good example of discrete optimization problems with high practical relevance where RL techniques have had considerable success.","Despite these advances, open-source development frameworks remain scarce, hampering both the testing of algorithms and the ability to objectively compare results.","This ultimately slows down progress in the field and limits the exchange of ideas between the RL and OR communities.   ","Here we propose a library composed of multi-agent environments that simulates classic vehicle routing problems.","The library, built on PyTorch, provides a flexible modular architecture design that allows easy customization and incorporation of new routing problems.","It follows the Agent Environment Cycle (\"AEC\") games model and has an intuitive API, enabling rapid adoption and easy integration into existing reinforcement learning frameworks.   ","The library allows for a straightforward use of classical OR benchmark instances in order to narrow the gap between the test beds for algorithm benchmarking used by the RL and OR communities.","Additionally, we provide benchmark instance sets for each environment, as well as baseline RL models and training code."],"url":"http://arxiv.org/abs/2411.14411v1"}
{"created":"2024-11-21 18:37:33","title":"Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions","abstract":"Currently OpenAI o1 has sparked a surge of interest in the study of large reasoning models (LRM). Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also places greater emphasis on open-ended resolutions. We aim to address the question: \"Can the o1 model effectively generalize to broader domains where clear standards are absent and rewards are challenging to quantify?\" Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and innovative reasoning strategies -- optimized for complex real-world problem-solving tasks.","sentences":["Currently OpenAI o1 has sparked a surge of interest in the study of large reasoning models (LRM).","Building on this momentum, Marco-o1 not only focuses on disciplines with standard answers, such as mathematics, physics, and coding -- which are well-suited for reinforcement learning (RL) -- but also places greater emphasis on open-ended resolutions.","We aim to address the question: \"Can the o1 model effectively generalize to broader domains where clear standards are absent and rewards are challenging to quantify?\"","Marco-o1 is powered by Chain-of-Thought (CoT) fine-tuning, Monte Carlo Tree Search (MCTS), reflection mechanisms, and innovative reasoning strategies -- optimized for complex real-world problem-solving tasks."],"url":"http://arxiv.org/abs/2411.14405v1"}
{"created":"2024-11-21 18:36:19","title":"Resolving Multiple-Dynamic Model Uncertainty in Hypothesis-Driven Belief-MDPs","abstract":"When human operators of cyber-physical systems encounter surprising behavior, they often consider multiple hypotheses that might explain it. In some cases, taking information-gathering actions such as additional measurements or control inputs given to the system can help resolve uncertainty and determine the most accurate hypothesis. The task of optimizing these actions can be formulated as a belief-space Markov decision process that we call a hypothesis-driven belief MDP. Unfortunately, this problem suffers from the curse of history similar to a partially observable Markov decision process (POMDP). To plan in continuous domains, an agent needs to reason over countlessly many possible action-observation histories, each resulting in a different belief over the unknown state. The problem is exacerbated in the hypothesis-driven context because each action-observation pair spawns a different belief for each hypothesis, leading to additional branching. This paper considers the case in which each hypothesis corresponds to a different dynamic model in an underlying POMDP. We present a new belief MDP formulation that: (i) enables reasoning over multiple hypotheses, (ii) balances the goals of determining the (most likely) correct hypothesis and performing well in the underlying POMDP, and (iii) can be solved with sparse tree search.","sentences":["When human operators of cyber-physical systems encounter surprising behavior, they often consider multiple hypotheses that might explain it.","In some cases, taking information-gathering actions such as additional measurements or control inputs given to the system can help resolve uncertainty and determine the most accurate hypothesis.","The task of optimizing these actions can be formulated as a belief-space Markov decision process that we call a hypothesis-driven belief MDP.","Unfortunately, this problem suffers from the curse of history similar to a partially observable Markov decision process (POMDP).","To plan in continuous domains, an agent needs to reason over countlessly many possible action-observation histories, each resulting in a different belief over the unknown state.","The problem is exacerbated in the hypothesis-driven context because each action-observation pair spawns a different belief for each hypothesis, leading to additional branching.","This paper considers the case in which each hypothesis corresponds to a different dynamic model in an underlying POMDP.","We present a new belief MDP formulation that: (i) enables reasoning over multiple hypotheses, (ii) balances the goals of determining the (most likely) correct hypothesis and performing well in the underlying POMDP, and (iii) can be solved with sparse tree search."],"url":"http://arxiv.org/abs/2411.14404v1"}
{"created":"2024-11-21 18:34:33","title":"Landing Trajectory Prediction for UAS Based on Generative Adversarial Network","abstract":"Models for trajectory prediction are an essential component of many advanced air mobility studies. These models help aircraft detect conflict and plan avoidance maneuvers, which is especially important in Unmanned Aircraft systems (UAS) landing management due to the congested airspace near vertiports. In this paper, we propose a landing trajectory prediction model for UAS based on Generative Adversarial Network (GAN). The GAN is a prestigious neural network that has been developed for many years. In previous research, GAN has achieved many state-of-the-art results in many generation tasks. The GAN consists of one neural network generator and a neural network discriminator. Because of the learning capacity of the neural networks, the generator is capable to understand the features of the sample trajectory. The generator takes the previous trajectory as input and outputs some random status of a flight. According to the results of the experiences, the proposed model can output more accurate predictions than the baseline method(GMR) in various datasets. To evaluate the proposed model, we also create a real UAV landing dataset that includes more than 2600 trajectories of drone control manually by real pilots.","sentences":["Models for trajectory prediction are an essential component of many advanced air mobility studies.","These models help aircraft detect conflict and plan avoidance maneuvers, which is especially important in Unmanned Aircraft systems (UAS) landing management due to the congested airspace near vertiports.","In this paper, we propose a landing trajectory prediction model for UAS based on Generative Adversarial Network (GAN).","The GAN is a prestigious neural network that has been developed for many years.","In previous research, GAN has achieved many state-of-the-art results in many generation tasks.","The GAN consists of one neural network generator and a neural network discriminator.","Because of the learning capacity of the neural networks, the generator is capable to understand the features of the sample trajectory.","The generator takes the previous trajectory as input and outputs some random status of a flight.","According to the results of the experiences, the proposed model can output more accurate predictions than the baseline method(GMR) in various datasets.","To evaluate the proposed model, we also create a real UAV landing dataset that includes more than 2600 trajectories of drone control manually by real pilots."],"url":"http://arxiv.org/abs/2411.14403v1"}
{"created":"2024-11-21 18:31:25","title":"Multimodal Autoregressive Pre-training of Large Vision Encoders","abstract":"We introduce a novel method for pre-training of large-scale vision encoders. Building on recent advancements in autoregressive pre-training of vision models, we extend this framework to a multimodal setting, i.e., images and text. In this paper, we present AIMV2, a family of generalist vision encoders characterized by a straightforward pre-training process, scalability, and remarkable performance across a range of downstream tasks. This is achieved by pairing the vision encoder with a multimodal decoder that autoregressively generates raw image patches and text tokens. Our encoders excel not only in multimodal evaluations but also in vision benchmarks such as localization, grounding, and classification. Notably, our AIMV2-3B encoder achieves 89.5% accuracy on ImageNet-1k with a frozen trunk. Furthermore, AIMV2 consistently outperforms state-of-the-art contrastive models (e.g., CLIP, SigLIP) in multimodal image understanding across diverse settings.","sentences":["We introduce a novel method for pre-training of large-scale vision encoders.","Building on recent advancements in autoregressive pre-training of vision models, we extend this framework to a multimodal setting, i.e., images and text.","In this paper, we present AIMV2, a family of generalist vision encoders characterized by a straightforward pre-training process, scalability, and remarkable performance across a range of downstream tasks.","This is achieved by pairing the vision encoder with a multimodal decoder that autoregressively generates raw image patches and text tokens.","Our encoders excel not only in multimodal evaluations but also in vision benchmarks such as localization, grounding, and classification.","Notably, our AIMV2-3B encoder achieves 89.5% accuracy on ImageNet-1k with a frozen trunk.","Furthermore, AIMV2 consistently outperforms state-of-the-art contrastive models (e.g., CLIP, SigLIP) in multimodal image understanding across diverse settings."],"url":"http://arxiv.org/abs/2411.14402v1"}
{"created":"2024-11-21 18:30:11","title":"Beyond Training: Dynamic Token Merging for Zero-Shot Video Understanding","abstract":"Recent advancements in multimodal large language models (MLLMs) have opened new avenues for video understanding. However, achieving high fidelity in zero-shot video tasks remains challenging. Traditional video processing methods rely heavily on fine-tuning to capture nuanced spatial-temporal details, which incurs significant data and computation costs. In contrast, training-free approaches, though efficient, often lack robustness in preserving context-rich features across complex video content. To this end, we propose DYTO, a novel dynamic token merging framework for zero-shot video understanding that adaptively optimizes token efficiency while preserving crucial scene details. DYTO integrates a hierarchical frame selection and a bipartite token merging strategy to dynamically cluster key frames and selectively compress token sequences, striking a balance between computational efficiency with semantic richness. Extensive experiments across multiple benchmarks demonstrate the effectiveness of DYTO, achieving superior performance compared to both fine-tuned and training-free methods and setting a new state-of-the-art for zero-shot video understanding.","sentences":["Recent advancements in multimodal large language models (MLLMs) have opened new avenues for video understanding.","However, achieving high fidelity in zero-shot video tasks remains challenging.","Traditional video processing methods rely heavily on fine-tuning to capture nuanced spatial-temporal details, which incurs significant data and computation costs.","In contrast, training-free approaches, though efficient, often lack robustness in preserving context-rich features across complex video content.","To this end, we propose DYTO, a novel dynamic token merging framework for zero-shot video understanding that adaptively optimizes token efficiency while preserving crucial scene details.","DYTO integrates a hierarchical frame selection and a bipartite token merging strategy to dynamically cluster key frames and selectively compress token sequences, striking a balance between computational efficiency with semantic richness.","Extensive experiments across multiple benchmarks demonstrate the effectiveness of DYTO, achieving superior performance compared to both fine-tuned and training-free methods and setting a new state-of-the-art for zero-shot video understanding."],"url":"http://arxiv.org/abs/2411.14401v1"}
{"created":"2024-11-21 18:29:16","title":"23 DoF Grasping Policies from a Raw Point Cloud","abstract":"Coordinating the motion of robots with high degrees of freedom (DoF) to grasp objects gives rise to many challenges. In this paper, we propose a novel imitation learning approach to learn a policy that directly predicts 23 DoF grasp trajectories from a partial point cloud provided by a single, fixed camera. At the core of the approach is a second-order geometric-based model of behavioral dynamics. This Neural Geometric Fabric (NGF) policy predicts accelerations directly in joint space. We show that our policy is capable of generalizing to novel objects, and combine our policy with a geometric fabric motion planner in a loop to generate stable grasping trajectories. We evaluate our approach on a set of three different objects, compare different policy structures, and run ablation studies to understand the importance of different object encodings for policy learning.","sentences":["Coordinating the motion of robots with high degrees of freedom (DoF) to grasp objects gives rise to many challenges.","In this paper, we propose a novel imitation learning approach to learn a policy that directly predicts 23 DoF grasp trajectories from a partial point cloud provided by a single, fixed camera.","At the core of the approach is a second-order geometric-based model of behavioral dynamics.","This Neural Geometric Fabric (NGF) policy predicts accelerations directly in joint space.","We show that our policy is capable of generalizing to novel objects, and combine our policy with a geometric fabric motion planner in a loop to generate stable grasping trajectories.","We evaluate our approach on a set of three different objects, compare different policy structures, and run ablation studies to understand the importance of different object encodings for policy learning."],"url":"http://arxiv.org/abs/2411.14400v1"}
{"created":"2024-11-21 18:27:25","title":"Lightweight Safety Guardrails Using Fine-tuned BERT Embeddings","abstract":"With the recent proliferation of large language models (LLMs), enterprises have been able to rapidly develop proof-of-concepts and prototypes. As a result, there is a growing need to implement robust guardrails that monitor, quantize and control an LLM's behavior, ensuring that the use is reliable, safe, accurate and also aligned with the users' expectations. Previous approaches for filtering out inappropriate user prompts or system outputs, such as LlamaGuard and OpenAI's MOD API, have achieved significant success by fine-tuning existing LLMs. However, using fine-tuned LLMs as guardrails introduces increased latency and higher maintenance costs, which may not be practical or scalable for cost-efficient deployments. We take a different approach, focusing on fine-tuning a lightweight architecture: Sentence-BERT. This method reduces the model size from LlamaGuard's 7 billion parameters to approximately 67 million, while maintaining comparable performance on the AEGIS safety benchmark.","sentences":["With the recent proliferation of large language models (LLMs), enterprises have been able to rapidly develop proof-of-concepts and prototypes.","As a result, there is a growing need to implement robust guardrails that monitor, quantize and control an LLM's behavior, ensuring that the use is reliable, safe, accurate and also aligned with the users' expectations.","Previous approaches for filtering out inappropriate user prompts or system outputs, such as LlamaGuard and OpenAI's MOD API, have achieved significant success by fine-tuning existing LLMs.","However, using fine-tuned LLMs as guardrails introduces increased latency and higher maintenance costs, which may not be practical or scalable for cost-efficient deployments.","We take a different approach, focusing on fine-tuning a lightweight architecture: Sentence-BERT.","This method reduces the model size from LlamaGuard's 7 billion parameters to approximately 67 million, while maintaining comparable performance on the AEGIS safety benchmark."],"url":"http://arxiv.org/abs/2411.14398v1"}
{"created":"2024-11-21 18:26:05","title":"Securing Legacy Communication Networks via Authenticated Cyclic Redundancy Integrity Check","abstract":"Integrating modern communication technologies into legacy systems, such as Industrial Control Systems and in-vehicle networks, invalidates the assumptions of isolated and trusted operating environments. Security incidents like the 2015 Ukraine power grid attack and the 2021 compromise of a U.S. water treatment facility demonstrate how increased interconnectivity, paired with insufficient security measures, expose these critical systems to cyber threats, posing risks to national and public safety. These attacks were favored by the lack of proper message authentication, highlighting its importance as a primary countermeasure to enhance system security. Solutions proposed in the literature remain largely unadopted in practice due to challenges such as preserving backward compatibility, additional hardware requirements, and limited computational resources on legacy devices. Moreover, many solutions are protocol-specific, necessitating complex and costly multiple implementations in heterogeneous systems.   In this paper, we propose Authenticated Cyclic Redundancy Integrity Check (ACRIC), a novel security mechanism that overcomes these limitations by leveraging a cryptographic computation of the existing Cyclyic Redundancy Check (CRC) field to ensure message integrity protection and authentication. ACRIC preserves backward compatibility without requiring additional hardware and is protocol agnostic. This makes it applicable across various systems, suitable for diverse legacy network protocols including point-to-point and broadcast communications. Experimental results, supported by formal verification and real-world testing, demonstrate that ACRIC offers robust security with minimal transmission overhead (<< 1 ms). This proves ACRIC's practicality, cost-effectiveness, and suitability for real-world adoption.","sentences":["Integrating modern communication technologies into legacy systems, such as Industrial Control Systems and in-vehicle networks, invalidates the assumptions of isolated and trusted operating environments.","Security incidents like the 2015 Ukraine power grid attack and the 2021 compromise of a U.S. water treatment facility demonstrate how increased interconnectivity, paired with insufficient security measures, expose these critical systems to cyber threats, posing risks to national and public safety.","These attacks were favored by the lack of proper message authentication, highlighting its importance as a primary countermeasure to enhance system security.","Solutions proposed in the literature remain largely unadopted in practice due to challenges such as preserving backward compatibility, additional hardware requirements, and limited computational resources on legacy devices.","Moreover, many solutions are protocol-specific, necessitating complex and costly multiple implementations in heterogeneous systems.   ","In this paper, we propose Authenticated Cyclic Redundancy Integrity Check (ACRIC), a novel security mechanism that overcomes these limitations by leveraging a cryptographic computation of the existing Cyclyic Redundancy Check (CRC) field to ensure message integrity protection and authentication.","ACRIC preserves backward compatibility without requiring additional hardware and is protocol agnostic.","This makes it applicable across various systems, suitable for diverse legacy network protocols including point-to-point and broadcast communications.","Experimental results, supported by formal verification and real-world testing, demonstrate that ACRIC offers robust security with minimal transmission overhead (<< 1 ms).","This proves ACRIC's practicality, cost-effectiveness, and suitability for real-world adoption."],"url":"http://arxiv.org/abs/2411.14394v1"}
{"created":"2024-11-21 18:25:19","title":"POS-tagging to highlight the skeletal structure of sentences","abstract":"This study presents the development of a part-of-speech (POS) tagging model to extract the skeletal structure of sentences using transfer learning with the BERT architecture for token classification. The model, fine-tuned on Russian text, demonstrating its effectiveness. The approach offers potential applications in enhancing natural language processing tasks, such as improving machine translation.   Keywords: part of speech tagging, morphological analysis, natural language processing, BERT.","sentences":["This study presents the development of a part-of-speech (POS) tagging model to extract the skeletal structure of sentences using transfer learning with the BERT architecture for token classification.","The model, fine-tuned on Russian text, demonstrating its effectiveness.","The approach offers potential applications in enhancing natural language processing tasks, such as improving machine translation.   ","Keywords: part of speech tagging, morphological analysis, natural language processing, BERT."],"url":"http://arxiv.org/abs/2411.14393v1"}
{"created":"2024-11-21 18:23:28","title":"Hardness Amplification for Dynamic Binary Search Trees","abstract":"We prove direct-sum theorems for Wilber's two lower bounds [Wilber, FOCS'86] on the cost of access sequences in the binary search tree (BST) model. These bounds are central to the question of dynamic optimality [Sleator and Tarjan, JACM'85]: the Alternation bound is the only bound to have yielded online BST algorithms beating $\\log n$ competitive ratio, while the Funnel bound has repeatedly been conjectured to exactly characterize the cost of executing an access sequence using the optimal tree [Wilber, FOCS'86, Kozma'16], and has been explicitly linked to splay trees [Levy and Tarjan, SODA'19]. Previously, the direct-sum theorem for the Alternation bound was known only when approximation was allowed [Chalermsook, Chuzhoy and Saranurak, APPROX'20, ToC'24].   We use these direct-sum theorems to amplify the sequences from [Lecomte and Weinstein, ESA'20] that separate between Wilber's Alternation and Funnel bounds, increasing the Alternation and Funnel bounds while optimally maintaining the separation. As a corollary, we show that Tango trees [Demaine et al., FOCS'04] are optimal among any BST algorithms that charge their costs to the Alternation bound. This is true for any value of the Alternation bound, even values for which Tango trees achieve a competitive ratio of $o(\\log \\log n)$ instead of the default $O(\\log \\log n)$. Previously, the optimality of Tango trees was shown only for a limited range of Alternation bound [Lecomte and Weinstein, ESA'20].","sentences":["We prove direct-sum theorems for Wilber's two lower bounds","[Wilber, FOCS'86] on the cost of access sequences in the binary search tree (BST) model.","These bounds are central to the question of dynamic optimality [Sleator and Tarjan, JACM'85]: the Alternation bound is the only bound to have yielded online BST algorithms beating $\\log n$ competitive ratio, while the Funnel bound has repeatedly been conjectured to exactly characterize the cost of executing an access sequence using the optimal tree","[Wilber, FOCS'86, Kozma'16], and has been explicitly linked to splay trees","[Levy and Tarjan, SODA'19].","Previously, the direct-sum theorem for the Alternation bound was known only when approximation was allowed [Chalermsook, Chuzhoy and Saranurak, APPROX'20, ToC'24].   ","We use these direct-sum theorems to amplify the sequences from [Lecomte and Weinstein, ESA'20] that separate between Wilber's Alternation and Funnel bounds, increasing the Alternation and Funnel bounds while optimally maintaining the separation.","As a corollary, we show that Tango trees","[Demaine et al., FOCS'04] are optimal among any BST algorithms that charge their costs to the Alternation bound.","This is true for any value of the Alternation bound, even values for which Tango trees achieve a competitive ratio of $o(\\log \\log n)$ instead of the default $O(\\log \\log n)$. Previously, the optimality of Tango trees was shown only for a limited range of Alternation","bound","[Lecomte and Weinstein, ESA'20]."],"url":"http://arxiv.org/abs/2411.14387v1"}
{"created":"2024-11-21 18:21:59","title":"Learning Humanoid Locomotion with Perceptive Internal Model","abstract":"In contrast to quadruped robots that can navigate diverse terrains using a \"blind\" policy, humanoid robots require accurate perception for stable locomotion due to their high degrees of freedom and inherently unstable morphology. However, incorporating perceptual signals often introduces additional disturbances to the system, potentially reducing its robustness, generalizability, and efficiency. This paper presents the Perceptive Internal Model (PIM), which relies on onboard, continuously updated elevation maps centered around the robot to perceive its surroundings. We train the policy using ground-truth obstacle heights surrounding the robot in simulation, optimizing it based on the Hybrid Internal Model (HIM), and perform inference with heights sampled from the constructed elevation map. Unlike previous methods that directly encode depth maps or raw point clouds, our approach allows the robot to perceive the terrain beneath its feet clearly and is less affected by camera movement or noise. Furthermore, since depth map rendering is not required in simulation, our method introduces minimal additional computational costs and can train the policy in 3 hours on an RTX 4090 GPU. We verify the effectiveness of our method across various humanoid robots, various indoor and outdoor terrains, stairs, and various sensor configurations. Our method can enable a humanoid robot to continuously climb stairs and has the potential to serve as a foundational algorithm for the development of future humanoid control methods.","sentences":["In contrast to quadruped robots that can navigate diverse terrains using a \"blind\" policy, humanoid robots require accurate perception for stable locomotion due to their high degrees of freedom and inherently unstable morphology.","However, incorporating perceptual signals often introduces additional disturbances to the system, potentially reducing its robustness, generalizability, and efficiency.","This paper presents the Perceptive Internal Model (PIM), which relies on onboard, continuously updated elevation maps centered around the robot to perceive its surroundings.","We train the policy using ground-truth obstacle heights surrounding the robot in simulation, optimizing it based on the Hybrid Internal Model (HIM), and perform inference with heights sampled from the constructed elevation map.","Unlike previous methods that directly encode depth maps or raw point clouds, our approach allows the robot to perceive the terrain beneath its feet clearly and is less affected by camera movement or noise.","Furthermore, since depth map rendering is not required in simulation, our method introduces minimal additional computational costs and can train the policy in 3 hours on an RTX 4090 GPU.","We verify the effectiveness of our method across various humanoid robots, various indoor and outdoor terrains, stairs, and various sensor configurations.","Our method can enable a humanoid robot to continuously climb stairs and has the potential to serve as a foundational algorithm for the development of future humanoid control methods."],"url":"http://arxiv.org/abs/2411.14386v1"}
{"created":"2024-11-21 18:21:24","title":"Baking Gaussian Splatting into Diffusion Denoiser for Fast and Scalable Single-stage Image-to-3D Generation","abstract":"Existing feed-forward image-to-3D methods mainly rely on 2D multi-view diffusion models that cannot guarantee 3D consistency. These methods easily collapse when changing the prompt view direction and mainly handle object-centric prompt images. In this paper, we propose a novel single-stage 3D diffusion model, DiffusionGS, for object and scene generation from a single view. DiffusionGS directly outputs 3D Gaussian point clouds at each timestep to enforce view consistency and allow the model to generate robustly given prompt views of any directions, beyond object-centric inputs. Plus, to improve the capability and generalization ability of DiffusionGS, we scale up 3D training data by developing a scene-object mixed training strategy. Experiments show that our method enjoys better generation quality (2.20 dB higher in PSNR and 23.25 lower in FID) and over 5x faster speed (~6s on an A100 GPU) than SOTA methods. The user study and text-to-3D applications also reveals the practical values of our method. Our Project page at https://caiyuanhao1998.github.io/project/DiffusionGS/ shows the video and interactive generation results.","sentences":["Existing feed-forward image-to-3D methods mainly rely on 2D multi-view diffusion models that cannot guarantee 3D consistency.","These methods easily collapse when changing the prompt view direction and mainly handle object-centric prompt images.","In this paper, we propose a novel single-stage 3D diffusion model, DiffusionGS, for object and scene generation from a single view.","DiffusionGS directly outputs 3D Gaussian point clouds at each timestep to enforce view consistency and allow the model to generate robustly given prompt views of any directions, beyond object-centric inputs.","Plus, to improve the capability and generalization ability of DiffusionGS, we scale up 3D training data by developing a scene-object mixed training strategy.","Experiments show that our method enjoys better generation quality (2.20 dB higher in PSNR and 23.25 lower in FID) and over 5x faster speed (~6s on an A100 GPU) than SOTA methods.","The user study and text-to-3D applications also reveals the practical values of our method.","Our Project page at https://caiyuanhao1998.github.io/project/DiffusionGS/ shows the video and interactive generation results."],"url":"http://arxiv.org/abs/2411.14384v1"}
{"created":"2024-11-21 18:16:20","title":"ETA-IK: Execution-Time-Aware Inverse Kinematics for Dual-Arm Systems","abstract":"This paper presents ETA-IK, a novel Execution-Time-Aware Inverse Kinematics method tailored for dual-arm robotic systems. The primary goal is to optimize motion execution time by leveraging the redundancy of both arms, specifically in tasks where only the relative pose of the robots is constrained, such as dual-arm scanning of unknown objects. Unlike traditional inverse kinematics methods that use surrogate metrics such as joint configuration distance, our method incorporates direct motion execution time and implicit collisions into the optimization process, thereby finding target joints that allow subsequent trajectory generation to get more efficient and collision-free motion. A neural network based execution time approximator is employed to predict time-efficient joint configurations while accounting for potential collisions. Through experimental evaluation on a system composed of a UR5 and a KUKA iiwa robot, we demonstrate significant reductions in execution time. The proposed method outperforms conventional approaches, showing improved motion efficiency without sacrificing positioning accuracy. These results highlight the potential of ETA-IK to improve the performance of dual-arm systems in applications, where efficiency and safety are paramount.","sentences":["This paper presents ETA-IK, a novel Execution-Time-Aware Inverse Kinematics method tailored for dual-arm robotic systems.","The primary goal is to optimize motion execution time by leveraging the redundancy of both arms, specifically in tasks where only the relative pose of the robots is constrained, such as dual-arm scanning of unknown objects.","Unlike traditional inverse kinematics methods that use surrogate metrics such as joint configuration distance, our method incorporates direct motion execution time and implicit collisions into the optimization process, thereby finding target joints that allow subsequent trajectory generation to get more efficient and collision-free motion.","A neural network based execution time approximator is employed to predict time-efficient joint configurations while accounting for potential collisions.","Through experimental evaluation on a system composed of a UR5 and a KUKA iiwa robot, we demonstrate significant reductions in execution time.","The proposed method outperforms conventional approaches, showing improved motion efficiency without sacrificing positioning accuracy.","These results highlight the potential of ETA-IK to improve the performance of dual-arm systems in applications, where efficiency and safety are paramount."],"url":"http://arxiv.org/abs/2411.14381v1"}
{"created":"2024-11-21 18:09:20","title":"Model Checking for Reinforcement Learning in Autonomous Driving: One Can Do More Than You Think!","abstract":"Most reinforcement learning (RL) platforms use high-level programming languages, such as OpenAI Gymnasium using Python. These frameworks provide various API and benchmarks for testing RL algorithms in different domains, such as autonomous driving (AD) and robotics. These platforms often emphasise the design of RL algorithms and the training performance but neglect the correctness of models and reward functions, which can be crucial for the successful application of RL. This paper proposes using formal methods to model AD systems and demonstrates how model checking (MC) can be used in RL for AD. Most studies combining MC and RL focus on safety, such as safety shields. However, this paper shows different facets where MC can strengthen RL. First, an MC-based model pre-analysis can reveal bugs with respect to sensor accuracy and learning step size. This step serves as a preparation of RL, which saves time if bugs exist and deepens users' understanding of the target system. Second, reward automata can benefit the design of reward functions and greatly improve learning performance especially when the learning objectives are multiple. All these findings are supported by experiments.","sentences":["Most reinforcement learning (RL) platforms use high-level programming languages, such as OpenAI Gymnasium using Python.","These frameworks provide various API and benchmarks for testing RL algorithms in different domains, such as autonomous driving (AD) and robotics.","These platforms often emphasise the design of RL algorithms and the training performance but neglect the correctness of models and reward functions, which can be crucial for the successful application of RL.","This paper proposes using formal methods to model AD systems and demonstrates how model checking (MC) can be used in RL for AD.","Most studies combining MC and RL focus on safety, such as safety shields.","However, this paper shows different facets where MC can strengthen RL.","First, an MC-based model pre-analysis can reveal bugs with respect to sensor accuracy and learning step size.","This step serves as a preparation of RL, which saves time if bugs exist and deepens users' understanding of the target system.","Second, reward automata can benefit the design of reward functions and greatly improve learning performance especially when the learning objectives are multiple.","All these findings are supported by experiments."],"url":"http://arxiv.org/abs/2411.14375v1"}
{"created":"2024-11-21 18:09:04","title":"Using Formal Models, Safety Shields and Certified Control to Validate AI-Based Train Systems","abstract":"The certification of autonomous systems is an important concern in science and industry. The KI-LOK project explores new methods for certifying and safely integrating AI components into autonomous trains. We pursued a two-layered approach: (1) ensuring the safety of the steering system by formal analysis using the B method, and (2) improving the reliability of the perception system with a runtime certificate checker. This work links both strategies within a demonstrator that runs simulations on the formal model, controlled by the real AI output and the real certificate checker. The demonstrator is integrated into the validation tool ProB. This enables runtime monitoring, runtime verification, and statistical validation of formal safety properties using a formal B model. Consequently, one can detect and analyse potential vulnerabilities and weaknesses of the AI and the certificate checker. We apply these techniques to a signal detection case study and present our findings.","sentences":["The certification of autonomous systems is an important concern in science and industry.","The KI-LOK project explores new methods for certifying and safely integrating AI components into autonomous trains.","We pursued a two-layered approach: (1) ensuring the safety of the steering system by formal analysis using the B method, and (2) improving the reliability of the perception system with a runtime certificate checker.","This work links both strategies within a demonstrator that runs simulations on the formal model, controlled by the real AI output and the real certificate checker.","The demonstrator is integrated into the validation tool ProB.","This enables runtime monitoring, runtime verification, and statistical validation of formal safety properties using a formal B model.","Consequently, one can detect and analyse potential vulnerabilities and weaknesses of the AI and the certificate checker.","We apply these techniques to a signal detection case study and present our findings."],"url":"http://arxiv.org/abs/2411.14374v1"}
{"created":"2024-11-21 18:08:49","title":"Cross--layer Formal Verification of Robotic Systems","abstract":"Robotic systems are widely used to interact with humans or to perform critical tasks. As a result, it is imperative to provide guarantees about their behavior. Due to the modularity and complexity of robotic systems, their design and verification are often divided into several layers. However, some system properties can only be investigated by considering multiple layers simultaneously. We propose a cross-layer verification method to verify the expected properties of concrete robotic systems. Our method verifies one layer using abstractions of other layers. We propose two approaches: refining the models of the abstract layers and refining the property under verification. A combination of these two approaches seems to be the most promising to ensure model genericity and to avoid the state-space explosion problem.","sentences":["Robotic systems are widely used to interact with humans or to perform critical tasks.","As a result, it is imperative to provide guarantees about their behavior.","Due to the modularity and complexity of robotic systems, their design and verification are often divided into several layers.","However, some system properties can only be investigated by considering multiple layers simultaneously.","We propose a cross-layer verification method to verify the expected properties of concrete robotic systems.","Our method verifies one layer using abstractions of other layers.","We propose two approaches: refining the models of the abstract layers and refining the property under verification.","A combination of these two approaches seems to be the most promising to ensure model genericity and to avoid the state-space explosion problem."],"url":"http://arxiv.org/abs/2411.14373v1"}
{"created":"2024-11-21 18:08:34","title":"A Case Study on Numerical Analysis of a Path Computation Algorithm","abstract":"Lack of numerical precision in control software -- in particular, related to trajectory computation -- can lead to incorrect results with costly or even catastrophic consequences. Various tools have been proposed to analyze the precision of program computations. This paper presents a case study on numerical analysis of an industrial implementation of the fast marching algorithm, a popular path computation algorithm frequently used for trajectory computation. We briefly describe the selected tools, present the applied methodology, highlight some attention points, summarize the results and outline future work directions.","sentences":["Lack of numerical precision in control software -- in particular, related to trajectory computation -- can lead to incorrect results with costly or even catastrophic consequences.","Various tools have been proposed to analyze the precision of program computations.","This paper presents a case study on numerical analysis of an industrial implementation of the fast marching algorithm, a popular path computation algorithm frequently used for trajectory computation.","We briefly describe the selected tools, present the applied methodology, highlight some attention points, summarize the results and outline future work directions."],"url":"http://arxiv.org/abs/2411.14372v1"}
{"created":"2024-11-21 18:08:18","title":"Synthesising Robust Controllers for Robot Collectives with Recurrent Tasks: A Case Study","abstract":"When designing correct-by-construction controllers for autonomous collectives, three key challenges are the task specification, the modelling, and its use at practical scale. In this paper, we focus on a simple yet useful abstraction for high-level controller synthesis for robot collectives with optimisation goals (e.g., maximum cleanliness, minimum energy consumption) and recurrence (e.g., re-establish contamination and charge thresholds) and safety (e.g., avoid full discharge, mutually exclusive room occupation) constraints. Due to technical limitations (related to scalability and using constraints in the synthesis), we simplify our graph-based setting from a stochastic two-player game into a single-player game on a partially observable Markov decision process (POMDP). Robustness against environmental uncertainty is encoded via partial observability. Linear-time correctness properties are verified separately after synthesising the POMDP strategy. We contribute at-scale guidance on POMDP modelling and controller synthesis for tasked robot collectives exemplified by the scenario of battery-driven robots responsible for cleaning public buildings with utilisation constraints.","sentences":["When designing correct-by-construction controllers for autonomous collectives, three key challenges are the task specification, the modelling, and its use at practical scale.","In this paper, we focus on a simple yet useful abstraction for high-level controller synthesis for robot collectives with optimisation goals (e.g., maximum cleanliness, minimum energy consumption) and recurrence (e.g., re-establish contamination and charge thresholds) and safety (e.g., avoid full discharge, mutually exclusive room occupation) constraints.","Due to technical limitations (related to scalability and using constraints in the synthesis), we simplify our graph-based setting from a stochastic two-player game into a single-player game on a partially observable Markov decision process (POMDP).","Robustness against environmental uncertainty is encoded via partial observability.","Linear-time correctness properties are verified separately after synthesising the POMDP strategy.","We contribute at-scale guidance on POMDP modelling and controller synthesis for tasked robot collectives exemplified by the scenario of battery-driven robots responsible for cleaning public buildings with utilisation constraints."],"url":"http://arxiv.org/abs/2411.14371v1"}
{"created":"2024-11-21 18:08:02","title":"Model Checking and Verification of Synchronisation Properties of Cobot Welding","abstract":"This paper describes use of model checking to verify synchronisation properties of an industrial welding system consisting of a cobot arm and an external turntable. The robots must move synchronously, but sometimes get out of synchronisation, giving rise to unsatisfactory weld qualities in problem areas, such as around corners. These mistakes are costly, since time is lost both in the robotic welding and in manual repairs needed to improve the weld. Verification of the synchronisation properties has shown that they are fulfilled as long as assumptions of correctness made about parts outside the scope of the model hold, indicating limitations in the hardware. These results have indicated the source of the problem, and motivated a re-calibration of the real-life system. This has drastically improved the welding results, and is a demonstration of how formal methods can be useful in an industrial setting.","sentences":["This paper describes use of model checking to verify synchronisation properties of an industrial welding system consisting of a cobot arm and an external turntable.","The robots must move synchronously, but sometimes get out of synchronisation, giving rise to unsatisfactory weld qualities in problem areas, such as around corners.","These mistakes are costly, since time is lost both in the robotic welding and in manual repairs needed to improve the weld.","Verification of the synchronisation properties has shown that they are fulfilled as long as assumptions of correctness made about parts outside the scope of the model hold, indicating limitations in the hardware.","These results have indicated the source of the problem, and motivated a re-calibration of the real-life system.","This has drastically improved the welding results, and is a demonstration of how formal methods can be useful in an industrial setting."],"url":"http://arxiv.org/abs/2411.14369v1"}
{"created":"2024-11-21 18:07:46","title":"RV4Chatbot: Are Chatbots Allowed to Dream of Electric Sheep?","abstract":"Chatbots have become integral to various application domains, including those with safety-critical considerations. As a result, there is a pressing need for methods that ensure chatbots consistently adhere to expected, safe behaviours. In this paper, we introduce RV4Chatbot, a Runtime Verification framework designed to monitor deviations in chatbot behaviour. We formalise expected behaviours as interaction protocols between the user and the chatbot. We present the RV4Chatbot design and describe two implementations that instantiate it: RV4Rasa, for monitoring chatbots created with the Rasa framework, and RV4Dialogflow, for monitoring Dialogflow chatbots. Additionally, we detail experiments conducted in a factory automation scenario using both RV4Rasa and RV4Dialogflow.","sentences":["Chatbots have become integral to various application domains, including those with safety-critical considerations.","As a result, there is a pressing need for methods that ensure chatbots consistently adhere to expected, safe behaviours.","In this paper, we introduce RV4Chatbot, a Runtime Verification framework designed to monitor deviations in chatbot behaviour.","We formalise expected behaviours as interaction protocols between the user and the chatbot.","We present the RV4Chatbot design and describe two implementations that instantiate it: RV4Rasa, for monitoring chatbots created with the Rasa framework, and RV4Dialogflow, for monitoring Dialogflow chatbots.","Additionally, we detail experiments conducted in a factory automation scenario using both RV4Rasa and RV4Dialogflow."],"url":"http://arxiv.org/abs/2411.14368v1"}
{"created":"2024-11-21 18:07:31","title":"ROSMonitoring 2.0: Extending ROS Runtime Verification to Services and Ordered Topics","abstract":"Formal verification of robotic applications presents challenges due to their hybrid nature and distributed architecture. This paper introduces ROSMonitoring 2.0, an extension of ROSMonitoring designed to facilitate the monitoring of both topics and services while considering the order in which messages are published and received. The framework has been enhanced to support these novel features for ROS1 -- and partially ROS2 environments -- offering improved real-time support, security, scalability, and interoperability. We discuss the modifications made to accommodate these advancements and present results obtained from a case study involving the runtime monitoring of specific components of a fire-fighting Uncrewed Aerial Vehicle (UAV).","sentences":["Formal verification of robotic applications presents challenges due to their hybrid nature and distributed architecture.","This paper introduces ROSMonitoring 2.0, an extension of ROSMonitoring designed to facilitate the monitoring of both topics and services while considering the order in which messages are published and received.","The framework has been enhanced to support these novel features for ROS1 -- and partially ROS2 environments -- offering improved real-time support, security, scalability, and interoperability.","We discuss the modifications made to accommodate these advancements and present results obtained from a case study involving the runtime monitoring of specific components of a fire-fighting Uncrewed Aerial Vehicle (UAV)."],"url":"http://arxiv.org/abs/2411.14367v1"}
{"created":"2024-11-21 18:00:12","title":"Improved Lower Bounds for all Odd-Query Locally Decodable Codes","abstract":"We prove that for every odd $q\\geq 3$, any $q$-query binary, possibly non-linear locally decodable code ($q$-LDC) $E:\\{\\pm1\\}^k \\rightarrow \\{\\pm1\\}^n$ must satisfy $k \\leq \\tilde{O}(n^{1-2/q})$. For even $q$, this bound was established in a sequence of prior works. For $q=3$, the above bound was achieved in a recent work of Alrabiah, Guruswami, Kothari and Manohar using an argument that crucially exploits known exponential lower bounds for $2$-LDCs. Their strategy hits an inherent bottleneck for $q \\geq 5$.   Our key insight is identifying a general sufficient condition on the hypergraph of local decoding sets called $t$-approximate strong regularity. This condition demands that 1) the number of hyperedges containing any given subset of vertices of size $t$ (i.e., its co-degree) be equal to the same but arbitrary value $d_t$ up to a multiplicative constant slack, and 2) all other co-degrees be upper-bounded relative to $d_t$. This condition significantly generalizes related proposals in prior works that demand absolute upper bounds on all co-degrees.   We give an argument based on spectral bounds on Kikuchi Matrices that lower bounds the blocklength of any LDC whose local decoding sets satisfy $t$-approximate strong regularity for any $t \\leq q$. Crucially, unlike prior works, our argument works despite having no non-trivial absolute upper bound on the co-degrees of any set of vertices. To apply our argument to arbitrary $q$-LDCs, we give a new, greedy, approximate strong regularity decomposition that shows that arbitrary, dense enough hypergraphs can be partitioned (up to a small error) into approximately strongly regular pieces satisfying the required relative bounds on the co-degrees.","sentences":["We prove that for every odd $q\\geq 3$, any $q$-query binary, possibly non-linear locally decodable code ($q$-LDC) $E:\\{\\pm1\\}^k \\rightarrow \\{\\pm1\\}^n$ must satisfy $k \\leq \\tilde{O}(n^{1-2/q})$. For even $q$, this bound was established in a sequence of prior works.","For $q=3$, the above bound was achieved in a recent work of Alrabiah, Guruswami, Kothari and Manohar using an argument that crucially exploits known exponential lower bounds for $2$-LDCs.","Their strategy hits an inherent bottleneck for $q \\geq 5$.   Our key insight is identifying a general sufficient condition on the hypergraph of local decoding sets called $t$-approximate strong regularity.","This condition demands that 1) the number of hyperedges containing any given subset of vertices of size $t$ (i.e., its co-degree) be equal to the same but arbitrary value $d_t$ up to a multiplicative constant slack, and 2) all other co-degrees be upper-bounded relative to $d_t$. This condition significantly generalizes related proposals in prior works that demand absolute upper bounds on all co-degrees.   ","We give an argument based on spectral bounds on Kikuchi Matrices that lower bounds the blocklength of any LDC whose local decoding sets satisfy $t$-approximate strong regularity for any $t \\leq q$.","Crucially, unlike prior works, our argument works despite having no non-trivial absolute upper bound on the co-degrees of any set of vertices.","To apply our argument to arbitrary $q$-LDCs, we give a new, greedy, approximate strong regularity decomposition that shows that arbitrary, dense enough hypergraphs can be partitioned (up to a small error) into approximately strongly regular pieces satisfying the required relative bounds on the co-degrees."],"url":"http://arxiv.org/abs/2411.14361v1"}
{"created":"2024-11-21 17:58:07","title":"InCrowd-VI: A Realistic Visual-Inertial Dataset for Evaluating SLAM in Indoor Pedestrian-Rich Spaces for Human Navigation","abstract":"Simultaneous localization and mapping (SLAM) techniques can be used to navigate the visually impaired, but the development of robust SLAM solutions for crowded spaces is limited by the lack of realistic datasets. To address this, we introduce InCrowd-VI, a novel visual-inertial dataset specifically designed for human navigation in indoor pedestrian-rich environments. Recorded using Meta Aria Project glasses, it captures realistic scenarios without environmental control. InCrowd-VI features 58 sequences totaling a 5 km trajectory length and 1.5 hours of recording time, including RGB, stereo images, and IMU measurements. The dataset captures important challenges such as pedestrian occlusions, varying crowd densities, complex layouts, and lighting changes. Ground-truth trajectories, accurate to approximately 2 cm, are provided in the dataset, originating from the Meta Aria project machine perception SLAM service. In addition, a semi-dense 3D point cloud of scenes is provided for each sequence. The evaluation of state-of-the-art visual odometry (VO) and SLAM algorithms on InCrowd-VI revealed severe performance limitations in these realistic scenarios, demonstrating the need and value of the new dataset to advance SLAM research for visually impaired navigation in complex indoor environments.","sentences":["Simultaneous localization and mapping (SLAM) techniques can be used to navigate the visually impaired, but the development of robust SLAM solutions for crowded spaces is limited by the lack of realistic datasets.","To address this, we introduce InCrowd-VI, a novel visual-inertial dataset specifically designed for human navigation in indoor pedestrian-rich environments.","Recorded using Meta Aria Project glasses, it captures realistic scenarios without environmental control.","InCrowd-VI features 58 sequences totaling a 5 km trajectory length and 1.5 hours of recording time, including RGB, stereo images, and IMU measurements.","The dataset captures important challenges such as pedestrian occlusions, varying crowd densities, complex layouts, and lighting changes.","Ground-truth trajectories, accurate to approximately 2 cm, are provided in the dataset, originating from the Meta Aria project machine perception SLAM service.","In addition, a semi-dense 3D point cloud of scenes is provided for each sequence.","The evaluation of state-of-the-art visual odometry (VO) and SLAM algorithms on InCrowd-VI revealed severe performance limitations in these realistic scenarios, demonstrating the need and value of the new dataset to advance SLAM research for visually impaired navigation in complex indoor environments."],"url":"http://arxiv.org/abs/2411.14358v1"}
{"created":"2024-11-21 17:54:54","title":"Convex Approximation of Probabilistic Reachable Sets from Small Samples Using Self-supervised Neural Networks","abstract":"Probabilistic Reachable Set (PRS) plays a crucial role in many fields of autonomous systems, yet efficiently generating PRS remains a significant challenge. This paper presents a learning approach to generating 2-dimensional PRS for states in a dynamic system. Traditional methods such as Hamilton-Jacobi reachability analysis, Monte Carlo, and Gaussian process classification face significant computational challenges or require detailed dynamics information, limiting their applicability in realistic situations. Existing data-driven methods may lack accuracy. To overcome these limitations, we propose leveraging neural networks, commonly used in imitation learning and computer vision, to imitate expert methods to generate PRS approximations. We trained the neural networks using a multi-label, self-supervised learning approach. We selected the fine-tuned convex approximation method as the expert to create expert PRS. Additionally, we continued sampling from the distribution to obtain a diverse array of sample sets. Given a small sample set, the trained neural networks can replicate the PRS approximation generated by the expert method, while the generation speed is much faster.","sentences":["Probabilistic Reachable Set (PRS) plays a crucial role in many fields of autonomous systems, yet efficiently generating PRS remains a significant challenge.","This paper presents a learning approach to generating 2-dimensional PRS for states in a dynamic system.","Traditional methods such as Hamilton-Jacobi reachability analysis, Monte Carlo, and Gaussian process classification face significant computational challenges or require detailed dynamics information, limiting their applicability in realistic situations.","Existing data-driven methods may lack accuracy.","To overcome these limitations, we propose leveraging neural networks, commonly used in imitation learning and computer vision, to imitate expert methods to generate PRS approximations.","We trained the neural networks using a multi-label, self-supervised learning approach.","We selected the fine-tuned convex approximation method as the expert to create expert PRS.","Additionally, we continued sampling from the distribution to obtain a diverse array of sample sets.","Given a small sample set, the trained neural networks can replicate the PRS approximation generated by the expert method, while the generation speed is much faster."],"url":"http://arxiv.org/abs/2411.14356v1"}
{"created":"2024-11-21 17:53:27","title":"Contrasting local and global modeling with machine learning and satellite data: A case study estimating tree canopy height in African savannas","abstract":"While advances in machine learning with satellite imagery (SatML) are facilitating environmental monitoring at a global scale, developing SatML models that are accurate and useful for local regions remains critical to understanding and acting on an ever-changing planet. As increasing attention and resources are being devoted to training SatML models with global data, it is important to understand when improvements in global models will make it easier to train or fine-tune models that are accurate in specific regions. To explore this question, we contrast local and global training paradigms for SatML through a case study of tree canopy height (TCH) mapping in the Karingani Game Reserve, Mozambique. We find that recent advances in global TCH mapping do not necessarily translate to better local modeling abilities in our study region. Specifically, small models trained only with locally-collected data outperform published global TCH maps, and even outperform globally pretrained models that we fine-tune using local data. Analyzing these results further, we identify specific points of conflict and synergy between local and global modeling paradigms that can inform future research toward aligning local and global performance objectives in geospatial machine learning.","sentences":["While advances in machine learning with satellite imagery (SatML) are facilitating environmental monitoring at a global scale, developing SatML models that are accurate and useful for local regions remains critical to understanding and acting on an ever-changing planet.","As increasing attention and resources are being devoted to training SatML models with global data, it is important to understand when improvements in global models will make it easier to train or fine-tune models that are accurate in specific regions.","To explore this question, we contrast local and global training paradigms for SatML through a case study of tree canopy height (TCH) mapping in the Karingani Game Reserve, Mozambique.","We find that recent advances in global TCH mapping do not necessarily translate to better local modeling abilities in our study region.","Specifically, small models trained only with locally-collected data outperform published global TCH maps, and even outperform globally pretrained models that we fine-tune using local data.","Analyzing these results further, we identify specific points of conflict and synergy between local and global modeling paradigms that can inform future research toward aligning local and global performance objectives in geospatial machine learning."],"url":"http://arxiv.org/abs/2411.14354v1"}
{"created":"2024-11-21 17:43:51","title":"Agnostic Learning of Arbitrary ReLU Activation under Gaussian Marginals","abstract":"We consider the problem of learning an arbitrarily-biased ReLU activation (or neuron) over Gaussian marginals with the squared loss objective. Despite the ReLU neuron being the basic building block of modern neural networks, we still do not understand the basic algorithmic question of whether one arbitrary ReLU neuron is learnable in the non-realizable setting. In particular, all existing polynomial time algorithms only provide approximation guarantees for the better-behaved unbiased setting or restricted bias setting.   Our main result is a polynomial time statistical query (SQ) algorithm that gives the first constant factor approximation for arbitrary bias. It outputs a ReLU activation that achieves a loss of $O(\\mathrm{OPT}) + \\varepsilon$ in time $\\mathrm{poly}(d,1/\\varepsilon)$, where $\\mathrm{OPT}$ is the loss obtained by the optimal ReLU activation. Our algorithm presents an interesting departure from existing algorithms, which are all based on gradient descent and thus fall within the class of correlational statistical query (CSQ) algorithms. We complement our algorithmic result by showing that no polynomial time CSQ algorithm can achieve a constant factor approximation. Together, these results shed light on the intrinsic limitation of gradient descent, while identifying arguably the simplest setting (a single neuron) where there is a separation between SQ and CSQ algorithms.","sentences":["We consider the problem of learning an arbitrarily-biased ReLU activation (or neuron) over Gaussian marginals with the squared loss objective.","Despite the ReLU neuron being the basic building block of modern neural networks, we still do not understand the basic algorithmic question of whether one arbitrary ReLU neuron is learnable in the non-realizable setting.","In particular, all existing polynomial time algorithms only provide approximation guarantees for the better-behaved unbiased setting or restricted bias setting.   ","Our main result is a polynomial time statistical query (SQ) algorithm that gives the first constant factor approximation for arbitrary bias.","It outputs a ReLU activation that achieves a loss of $O(\\mathrm{OPT})","+ \\varepsilon$ in time $\\mathrm{poly}(d,1/\\varepsilon)$, where $\\mathrm{OPT}$ is the loss obtained by the optimal ReLU activation.","Our algorithm presents an interesting departure from existing algorithms, which are all based on gradient descent and thus fall within the class of correlational statistical query (CSQ) algorithms.","We complement our algorithmic result by showing that no polynomial time CSQ algorithm can achieve a constant factor approximation.","Together, these results shed light on the intrinsic limitation of gradient descent, while identifying arguably the simplest setting (a single neuron) where there is a separation between SQ and CSQ algorithms."],"url":"http://arxiv.org/abs/2411.14349v1"}
{"created":"2024-11-21 17:42:20","title":"DINO-X: A Unified Vision Model for Open-World Object Detection and Understanding","abstract":"In this paper, we introduce DINO-X, which is a unified object-centric vision model developed by IDEA Research with the best open-world object detection performance to date. DINO-X employs the same Transformer-based encoder-decoder architecture as Grounding DINO 1.5 to pursue an object-level representation for open-world object understanding. To make long-tailed object detection easy, DINO-X extends its input options to support text prompt, visual prompt, and customized prompt. With such flexible prompt options, we develop a universal object prompt to support prompt-free open-world detection, making it possible to detect anything in an image without requiring users to provide any prompt. To enhance the model's core grounding capability, we have constructed a large-scale dataset with over 100 million high-quality grounding samples, referred to as Grounding-100M, for advancing the model's open-vocabulary detection performance. Pre-training on such a large-scale grounding dataset leads to a foundational object-level representation, which enables DINO-X to integrate multiple perception heads to simultaneously support multiple object perception and understanding tasks, including detection, segmentation, pose estimation, object captioning, object-based QA, etc. Experimental results demonstrate the superior performance of DINO-X. Specifically, the DINO-X Pro model achieves 56.0 AP, 59.8 AP, and 52.4 AP on the COCO, LVIS-minival, and LVIS-val zero-shot object detection benchmarks, respectively. Notably, it scores 63.3 AP and 56.5 AP on the rare classes of LVIS-minival and LVIS-val benchmarks, both improving the previous SOTA performance by 5.8 AP. Such a result underscores its significantly improved capacity for recognizing long-tailed objects.","sentences":["In this paper, we introduce DINO-X, which is a unified object-centric vision model developed by IDEA Research with the best open-world object detection performance to date.","DINO-X employs the same Transformer-based encoder-decoder architecture as Grounding DINO 1.5 to pursue an object-level representation for open-world object understanding.","To make long-tailed object detection easy, DINO-X extends its input options to support text prompt, visual prompt, and customized prompt.","With such flexible prompt options, we develop a universal object prompt to support prompt-free open-world detection, making it possible to detect anything in an image without requiring users to provide any prompt.","To enhance the model's core grounding capability, we have constructed a large-scale dataset with over 100 million high-quality grounding samples, referred to as Grounding-100M, for advancing the model's open-vocabulary detection performance.","Pre-training on such a large-scale grounding dataset leads to a foundational object-level representation, which enables DINO-X to integrate multiple perception heads to simultaneously support multiple object perception and understanding tasks, including detection, segmentation, pose estimation, object captioning, object-based QA, etc.","Experimental results demonstrate the superior performance of DINO-X. Specifically, the DINO-X Pro model achieves 56.0 AP, 59.8 AP, and 52.4 AP on the COCO, LVIS-minival, and LVIS-val zero-shot object detection benchmarks, respectively.","Notably, it scores 63.3 AP and 56.5 AP on the rare classes of LVIS-minival and LVIS-val benchmarks, both improving the previous SOTA performance by 5.8 AP.","Such a result underscores its significantly improved capacity for recognizing long-tailed objects."],"url":"http://arxiv.org/abs/2411.14347v1"}
{"created":"2024-11-21 17:41:27","title":"Layer Pruning with Consensus: A Triple-Win Solution","abstract":"Layer pruning offers a promising alternative to standard structured pruning, effectively reducing computational costs, latency, and memory footprint. While notable layer-pruning approaches aim to detect unimportant layers for removal, they often rely on single criteria that may not fully capture the complex, underlying properties of layers. We propose a novel approach that combines multiple similarity metrics into a single expressive measure of low-importance layers, called the Consensus criterion. Our technique delivers a triple-win solution: low accuracy drop, high-performance improvement, and increased robustness to adversarial attacks. With up to 78.80% FLOPs reduction and performance on par with state-of-the-art methods across different benchmarks, our approach reduces energy consumption and carbon emissions by up to 66.99% and 68.75%, respectively. Additionally, it avoids shortcut learning and improves robustness by up to 4 percentage points under various adversarial attacks. Overall, the Consensus criterion demonstrates its effectiveness in creating robust, efficient, and environmentally friendly pruned models.","sentences":["Layer pruning offers a promising alternative to standard structured pruning, effectively reducing computational costs, latency, and memory footprint.","While notable layer-pruning approaches aim to detect unimportant layers for removal, they often rely on single criteria that may not fully capture the complex, underlying properties of layers.","We propose a novel approach that combines multiple similarity metrics into a single expressive measure of low-importance layers, called the Consensus criterion.","Our technique delivers a triple-win solution: low accuracy drop, high-performance improvement, and increased robustness to adversarial attacks.","With up to 78.80% FLOPs reduction and performance on par with state-of-the-art methods across different benchmarks, our approach reduces energy consumption and carbon emissions by up to 66.99% and 68.75%, respectively.","Additionally, it avoids shortcut learning and improves robustness by up to 4 percentage points under various adversarial attacks.","Overall, the Consensus criterion demonstrates its effectiveness in creating robust, efficient, and environmentally friendly pruned models."],"url":"http://arxiv.org/abs/2411.14345v1"}
{"created":"2024-11-21 17:41:09","title":"Overcomplete Tensor Decomposition via Koszul-Young Flattenings","abstract":"Motivated by connections between algebraic complexity lower bounds and tensor decompositions, we investigate Koszul-Young flattenings, which are the main ingredient in recent lower bounds for matrix multiplication. Based on this tool we give a new algorithm for decomposing an $n_1 \\times n_2 \\times n_3$ tensor as the sum of a minimal number of rank-1 terms, and certifying uniqueness of this decomposition. For $n_1 \\le n_2 \\le n_3$ with $n_1 \\to \\infty$ and $n_3/n_2 = O(1)$, our algorithm is guaranteed to succeed when the tensor rank is bounded by $r \\le (1-\\epsilon)(n_2 + n_3)$ for an arbitrary $\\epsilon > 0$, provided the tensor components are generically chosen. For any fixed $\\epsilon$, the runtime is polynomial in $n_3$. When $n_2 = n_3 = n$, our condition on the rank gives a factor-of-2 improvement over the classical simultaneous diagonalization algorithm, which requires $r \\le n$, and also improves on the recent algorithm of Koiran (2024) which requires $r \\le 4n/3$. It also improves on the PhD thesis of Persu (2018) which solves rank detection for $r \\leq 3n/2$.   We complement our upper bounds by showing limitations, in particular that no flattening of the style we consider can surpass rank $n_2 + n_3$. Furthermore, for $n \\times n \\times n$ tensors, we show that an even more general class of degree-$d$ polynomial flattenings cannot surpass rank $Cn$ for a constant $C = C(d)$. This suggests that for tensor decompositions, the case of generic components may be fundamentally harder than that of random components, where efficient decomposition is possible even in highly overcomplete settings.","sentences":["Motivated by connections between algebraic complexity lower bounds and tensor decompositions, we investigate Koszul-Young flattenings, which are the main ingredient in recent lower bounds for matrix multiplication.","Based on this tool we give a new algorithm for decomposing an $n_1 \\times n_2 \\times n_3$ tensor as the sum of a minimal number of rank-1 terms, and certifying uniqueness of this decomposition.","For $n_1 \\le n_2 \\le n_3$ with $n_1 \\to \\infty$ and $n_3/n_2 = O(1)$, our algorithm is guaranteed to succeed when the tensor rank is bounded by $r \\le (1-\\epsilon)(n_2 + n_3)$ for an arbitrary $\\epsilon > 0$, provided the tensor components are generically chosen.","For any fixed $\\epsilon$, the runtime is polynomial in $n_3$. When $n_2 = n_3 = n$, our condition on the rank gives a factor-of-2 improvement over the classical simultaneous diagonalization algorithm, which requires $r \\le n$, and also improves on the recent algorithm of Koiran (2024) which requires $r \\le 4n/3$. It also improves on the PhD thesis of Persu (2018) which solves rank detection for $r \\leq","3n/2$.   ","We complement our upper bounds by showing limitations, in particular that no flattening of the style we consider can surpass rank $n_2 + n_3$.","Furthermore, for $n \\times n \\times n$ tensors, we show that an even more general class of degree-$d$ polynomial flattenings cannot surpass rank $Cn$ for a constant $C = C(d)$.","This suggests that for tensor decompositions, the case of generic components may be fundamentally harder than that of random components, where efficient decomposition is possible even in highly overcomplete settings."],"url":"http://arxiv.org/abs/2411.14344v1"}
{"created":"2024-11-21 17:41:08","title":"UnifiedCrawl: Aggregated Common Crawl for Affordable Adaptation of LLMs on Low-Resource Languages","abstract":"Large language models (LLMs) under-perform on low-resource languages due to limited training data. We present a method to efficiently collect text data for low-resource languages from the entire Common Crawl corpus. Our approach, UnifiedCrawl, filters and extracts common crawl using minimal compute resources, yielding mono-lingual datasets much larger than previously available sources. We demonstrate that leveraging this data to fine-tuning multilingual LLMs via efficient adapter methods (QLoRA) significantly boosts performance on the low-resource language, while minimizing VRAM usage. Our experiments show large improvements in language modeling perplexity and an increase in few-shot prompting scores. Our work and released source code provide an affordable approach to improve LLMs for low-resource languages using consumer hardware. Our source code is available here at https://github.com/bethelmelesse/unifiedcrawl.","sentences":["Large language models (LLMs) under-perform on low-resource languages due to limited training data.","We present a method to efficiently collect text data for low-resource languages from the entire Common Crawl corpus.","Our approach, UnifiedCrawl, filters and extracts common crawl using minimal compute resources, yielding mono-lingual datasets much larger than previously available sources.","We demonstrate that leveraging this data to fine-tuning multilingual LLMs via efficient adapter methods (QLoRA) significantly boosts performance on the low-resource language, while minimizing VRAM usage.","Our experiments show large improvements in language modeling perplexity and an increase in few-shot prompting scores.","Our work and released source code provide an affordable approach to improve LLMs for low-resource languages using consumer hardware.","Our source code is available here at https://github.com/bethelmelesse/unifiedcrawl."],"url":"http://arxiv.org/abs/2411.14343v1"}
{"created":"2024-11-21 17:24:36","title":"Data Formats in Analytical DBMSs: Performance Trade-offs and Future Directions","abstract":"This paper evaluates the suitability of Apache Arrow, Parquet, and ORC as formats for subsumption in an analytical DBMS. We systematically identify and explore the high-level features that are important to support efficient querying in modern OLAP DBMSs and evaluate the ability of each format to support these features. We find that each format has trade-offs that make it more or less suitable for use as a format in a DBMS and identify opportunities to more holistically co-design a unified in-memory and on-disk data representation. Notably, for certain popular machine learning tasks, none of these formats perform optimally, highlighting significant opportunities for advancing format design. Our hope is that this study can be used as a guide for system developers designing and using these formats, as well as provide the community with directions to pursue for improving these common open formats.","sentences":["This paper evaluates the suitability of Apache Arrow, Parquet, and ORC as formats for subsumption in an analytical DBMS.","We systematically identify and explore the high-level features that are important to support efficient querying in modern OLAP DBMSs and evaluate the ability of each format to support these features.","We find that each format has trade-offs that make it more or less suitable for use as a format in a DBMS and identify opportunities to more holistically co-design a unified in-memory and on-disk data representation.","Notably, for certain popular machine learning tasks, none of these formats perform optimally, highlighting significant opportunities for advancing format design.","Our hope is that this study can be used as a guide for system developers designing and using these formats, as well as provide the community with directions to pursue for improving these common open formats."],"url":"http://arxiv.org/abs/2411.14331v1"}
{"created":"2024-11-21 17:22:44","title":"Datalog with First-Class Facts","abstract":"Datalog is a popular logic programming language for deductive reasoning tasks in a wide array of applications, including business analytics, program analysis, and ontological reasoning. However, Datalog's restriction to flat facts over atomic constants leads to challenges in working with tree-structured data, such as derivation trees or abstract syntax trees. To ameliorate Datalog's restrictions, popular extensions of Datalog support features such as existential quantification in rule heads (Datalog$^\\pm$, Datalog$^\\exists$) or algebraic data types (Souffl\\'e). Unfortunately, these are imperfect solutions for reasoning over structured and recursive data types, with general existentials leading to complex implementations requiring unification, and ADTs unable to trigger rule evaluation and failing to support efficient indexing.   We present DL$^{\\exists!}$, a Datalog with first-class facts, wherein every fact is identified with a Skolem term unique to the fact. We show that this restriction offers an attractive price point for Datalog-based reasoning over tree-shaped data, demonstrating its application to databases, artificial intelligence, and programming languages. We implemented DL$^{\\exists!}$ as a system \\slog{}, which leverages the uniqueness restriction of DL$^{\\exists!}$ to enable a communication-avoiding, massively-parallel implementation built on MPI. We show that Slog outperforms leading systems (Nemo, Vlog, RDFox, and Souffl\\'e) on a variety of benchmarks, with the potential to scale to thousands of threads.","sentences":["Datalog is a popular logic programming language for deductive reasoning tasks in a wide array of applications, including business analytics, program analysis, and ontological reasoning.","However, Datalog's restriction to flat facts over atomic constants leads to challenges in working with tree-structured data, such as derivation trees or abstract syntax trees.","To ameliorate Datalog's restrictions, popular extensions of Datalog support features such as existential quantification in rule heads (Datalog$^\\pm$, Datalog$^\\exists$) or algebraic data types (Souffl\\'e).","Unfortunately, these are imperfect solutions for reasoning over structured and recursive data types, with general existentials leading to complex implementations requiring unification, and ADTs unable to trigger rule evaluation and failing to support efficient indexing.   ","We present DL$^{\\exists!}$, a Datalog with first-class facts, wherein every fact is identified with a Skolem term unique to the fact.","We show that this restriction offers an attractive price point for Datalog-based reasoning over tree-shaped data, demonstrating its application to databases, artificial intelligence, and programming languages.","We implemented DL$^{\\exists!}$ as a system \\slog{}, which leverages the uniqueness restriction of DL$^{\\exists!}$ to enable a communication-avoiding, massively-parallel implementation built on MPI.","We show that Slog outperforms leading systems (Nemo, Vlog, RDFox, and Souffl\\'e) on a variety of benchmarks, with the potential to scale to thousands of threads."],"url":"http://arxiv.org/abs/2411.14330v1"}
{"created":"2024-11-21 17:12:47","title":"SplatR : Experience Goal Visual Rearrangement with 3D Gaussian Splatting and Dense Feature Matching","abstract":"Experience Goal Visual Rearrangement task stands as a foundational challenge within Embodied AI, requiring an agent to construct a robust world model that accurately captures the goal state. The agent uses this world model to restore a shuffled scene to its original configuration, making an accurate representation of the world essential for successfully completing the task. In this work, we present a novel framework that leverages on 3D Gaussian Splatting as a 3D scene representation for experience goal visual rearrangement task. Recent advances in volumetric scene representation like 3D Gaussian Splatting, offer fast rendering of high quality and photo-realistic novel views. Our approach enables the agent to have consistent views of the current and the goal setting of the rearrangement task, which enables the agent to directly compare the goal state and the shuffled state of the world in image space. To compare these views, we propose to use a dense feature matching method with visual features extracted from a foundation model, leveraging its advantages of a more universal feature representation, which facilitates robustness, and generalization. We validate our approach on the AI2-THOR rearrangement challenge benchmark and demonstrate improvements over the current state of the art methods","sentences":["Experience Goal Visual Rearrangement task stands as a foundational challenge within Embodied AI, requiring an agent to construct a robust world model that accurately captures the goal state.","The agent uses this world model to restore a shuffled scene to its original configuration, making an accurate representation of the world essential for successfully completing the task.","In this work, we present a novel framework that leverages on 3D Gaussian Splatting as a 3D scene representation for experience goal visual rearrangement task.","Recent advances in volumetric scene representation like 3D Gaussian Splatting, offer fast rendering of high quality and photo-realistic novel views.","Our approach enables the agent to have consistent views of the current and the goal setting of the rearrangement task, which enables the agent to directly compare the goal state and the shuffled state of the world in image space.","To compare these views, we propose to use a dense feature matching method with visual features extracted from a foundation model, leveraging its advantages of a more universal feature representation, which facilitates robustness, and generalization.","We validate our approach on the AI2-THOR rearrangement challenge benchmark and demonstrate improvements over the current state of the art methods"],"url":"http://arxiv.org/abs/2411.14322v1"}
{"created":"2024-11-21 17:10:36","title":"Continual Learning and Lifting of Koopman Dynamics for Linear Control of Legged Robots","abstract":"The control of legged robots, particularly humanoid and quadruped robots, presents significant challenges due to their high-dimensional and nonlinear dynamics. While linear systems can be effectively controlled using methods like Model Predictive Control (MPC), the control of nonlinear systems remains complex. One promising solution is the Koopman Operator, which approximates nonlinear dynamics with a linear model, enabling the use of proven linear control techniques. However, achieving accurate linearization through data-driven methods is difficult due to issues like approximation error, domain shifts, and the limitations of fixed linear state-space representations. These challenges restrict the scalability of Koopman-based approaches. This paper addresses these challenges by proposing a continual learning algorithm designed to iteratively refine Koopman dynamics for high-dimensional legged robots. The key idea is to progressively expand the dataset and latent space dimension, enabling the learned Koopman dynamics to converge towards accurate approximations of the true system dynamics. Theoretical analysis shows that the linear approximation error of our method converges monotonically. Experimental results demonstrate that our method achieves high control performance on robots like Unitree G1/H1/A1/Go2 and ANYmal D, across various terrains using simple linear MPC controllers. This work is the first to successfully apply linearized Koopman dynamics for locomotion control of high-dimensional legged robots, enabling a scalable model-based control solution.","sentences":["The control of legged robots, particularly humanoid and quadruped robots, presents significant challenges due to their high-dimensional and nonlinear dynamics.","While linear systems can be effectively controlled using methods like Model Predictive Control (MPC), the control of nonlinear systems remains complex.","One promising solution is the Koopman Operator, which approximates nonlinear dynamics with a linear model, enabling the use of proven linear control techniques.","However, achieving accurate linearization through data-driven methods is difficult due to issues like approximation error, domain shifts, and the limitations of fixed linear state-space representations.","These challenges restrict the scalability of Koopman-based approaches.","This paper addresses these challenges by proposing a continual learning algorithm designed to iteratively refine Koopman dynamics for high-dimensional legged robots.","The key idea is to progressively expand the dataset and latent space dimension, enabling the learned Koopman dynamics to converge towards accurate approximations of the true system dynamics.","Theoretical analysis shows that the linear approximation error of our method converges monotonically.","Experimental results demonstrate that our method achieves high control performance on robots like Unitree G1/H1/A1/Go2 and ANYmal D, across various terrains using simple linear MPC controllers.","This work is the first to successfully apply linearized Koopman dynamics for locomotion control of high-dimensional legged robots, enabling a scalable model-based control solution."],"url":"http://arxiv.org/abs/2411.14321v1"}
{"created":"2024-11-21 17:10:02","title":"Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training","abstract":"It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains. In general, previous efforts resort to sampling training data from different domains with static proportions, as well as adjusting data proportions during training. However, few methods have addressed the complexities of domain-adaptive continual pre-training. To fill this gap, we propose Velocitune, a novel framework dynamically assesses learning velocity and adjusts data proportions accordingly, favoring slower-learning domains while shunning faster-learning ones, which is guided by a scaling law to indicate the desired learning goal for each domain with less associated cost. To evaluate the effectiveness of Velocitune, we conduct experiments in a reasoning-focused dataset with CodeLlama, as well as in a corpus specialised for system command generation with Llama3 and Mistral. Velocitune achieves performance gains in both math and code reasoning tasks and command-line generation benchmarks. Further analysis reveals that key factors driving Velocitune's effectiveness include target loss prediction and data ordering.","sentences":["It is well-known that a diverse corpus is critical for training large language models, which are typically constructed from a mixture of various domains.","In general, previous efforts resort to sampling training data from different domains with static proportions, as well as adjusting data proportions during training.","However, few methods have addressed the complexities of domain-adaptive continual pre-training.","To fill this gap, we propose Velocitune, a novel framework dynamically assesses learning velocity and adjusts data proportions accordingly, favoring slower-learning domains while shunning faster-learning ones, which is guided by a scaling law to indicate the desired learning goal for each domain with less associated cost.","To evaluate the effectiveness of Velocitune, we conduct experiments in a reasoning-focused dataset with CodeLlama, as well as in a corpus specialised for system command generation with Llama3 and Mistral.","Velocitune achieves performance gains in both math and code reasoning tasks and command-line generation benchmarks.","Further analysis reveals that key factors driving Velocitune's effectiveness include target loss prediction and data ordering."],"url":"http://arxiv.org/abs/2411.14318v1"}
{"created":"2024-11-21 17:06:53","title":"Switching Graph Matrix Norm Bounds: from i.i.d. to Random Regular Graphs","abstract":"In this work, we give novel spectral norm bounds for graph matrix on inputs being random regular graphs. Graph matrix is a family of random matrices with entries given by polynomial functions of the underlying input. These matrices have been known to be the backbone for the analysis of various average-case algorithms and hardness. Previous investigations of such matrices are largely restricted to the \\Erdos-\\Renyi model, and tight matrix norm bounds on regular graphs are only known for specific examples. We unite these two lines of investigations, and give the first result departing from the \\Erdos-\\Renyi setting in the full generality of graph matrices. We believe our norm bound result would enable a simple transfer of spectral analysis for average-case algorithms and hardness between these two distributions of random graphs.   As an application of our spectral norm bounds, we show that higher-degree Sum-of-Squares lower bounds for the independent set problem on \\Erdos-\\Renyi random graphs can be switched into lower bounds on random $d$-regular graphs. Our result is the first to address the general open question of analyzing higher-degree Sum-of-Squares on random regular graphs.","sentences":["In this work, we give novel spectral norm bounds for graph matrix on inputs being random regular graphs.","Graph matrix is a family of random matrices with entries given by polynomial functions of the underlying input.","These matrices have been known to be the backbone for the analysis of various average-case algorithms and hardness.","Previous investigations of such matrices are largely restricted to the \\Erdos-\\Renyi model, and tight matrix norm bounds on regular graphs are only known for specific examples.","We unite these two lines of investigations, and give the first result departing from the \\Erdos-\\Renyi setting in the full generality of graph matrices.","We believe our norm bound result would enable a simple transfer of spectral analysis for average-case algorithms and hardness between these two distributions of random graphs.   ","As an application of our spectral norm bounds, we show that higher-degree Sum-of-Squares lower bounds for the independent set problem on \\Erdos-\\Renyi random graphs can be switched into lower bounds on random $d$-regular graphs.","Our result is the first to address the general open question of analyzing higher-degree Sum-of-Squares on random regular graphs."],"url":"http://arxiv.org/abs/2411.14314v1"}
{"created":"2024-11-21 16:57:05","title":"Outlier-robust Mean Estimation near the Breakdown Point via Sum-of-Squares","abstract":"We revisit the problem of estimating the mean of a high-dimensional distribution in the presence of an $\\varepsilon$-fraction of adversarial outliers.   When $\\varepsilon$ is at most some sufficiently small constant, previous works can achieve optimal error rate efficiently \\cite{diakonikolas2018robustly, kothari2018robust}. As $\\varepsilon$ approaches the breakdown point $\\frac{1}{2}$, all previous algorithms incur either sub-optimal error rates or exponential running time.   In this paper we give a new analysis of the canonical sum-of-squares program introduced in \\cite{kothari2018robust} and show that this program efficiently achieves optimal error rate for all $\\varepsilon \\in[0,\\frac{1}{2})$. The key ingredient for our results is a new identifiability proof for robust mean estimation that focuses on the overlap between the distributions instead of their statistical distance as in previous works. We capture this proof within the sum-of-squares proof system, thus obtaining efficient algorithms using the sum-of-squares proofs to algorithms paradigm \\cite{raghavendra2018high}.","sentences":["We revisit the problem of estimating the mean of a high-dimensional distribution in the presence of an $\\varepsilon$-fraction of adversarial outliers.   ","When $\\varepsilon$ is at most some sufficiently small constant, previous works can achieve optimal error rate efficiently \\cite{diakonikolas2018robustly, kothari2018robust}.","As $\\varepsilon$ approaches the breakdown point $\\frac{1}{2}$, all previous algorithms incur either sub-optimal error rates or exponential running time.   ","In this paper we give a new analysis of the canonical sum-of-squares program introduced in \\cite{kothari2018robust} and show that this program efficiently achieves optimal error rate for all $\\varepsilon \\in[0,\\frac{1}{2})$. The key ingredient for our results is a new identifiability proof for robust mean estimation that focuses on the overlap between the distributions instead of their statistical distance as in previous works.","We capture this proof within the sum-of-squares proof system, thus obtaining efficient algorithms using the sum-of-squares proofs to algorithms paradigm \\cite{raghavendra2018high}."],"url":"http://arxiv.org/abs/2411.14305v1"}
{"created":"2024-11-21 16:56:33","title":"Automated Generation of Code Debugging Exercises","abstract":"Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.","sentences":["Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses.","In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important.","However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues.","Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means.","This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite.","Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification.","This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications.","We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems.","We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications.","Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging."],"url":"http://arxiv.org/abs/2411.14303v1"}
{"created":"2024-11-21 16:54:04","title":"Sustainability concepts for digital research infrastructures developed through ground-level stakeholder empowerment","abstract":"The UK Research and Innovation Digital Research Infrastructure (DRI) needs to operate sustainably in the future, encompassing its use of energy and resources, and embedded computer hardware carbon emissions. Transition concepts towards less unsustainable operations will inform the future design and operations of DRI. A problem remains that, while the skills and knowledge for solving net zero challenges already exist within the UK's DRI community, the mechanisms for sharing them and enabling behavior change are missing. Without adopting community-driven approaches, individual stakeholders may feel isolated and uncertain about how to play their role in the transition. A research programme was funded to give voice to the ground-level stakeholders of the DRI ecosystem for the co-creation of carbon downshift concepts. This article presents the results of the programme, with the goal to inform a fair and just transition from the ground-level, complementing the top-down interventions of energy efficiency policies and renewable energies integration. A workshop-based innovation method was developed for researching stakeholder recommendations and perspectives on the sustainable transition of the UK's DRI. We find that giving a purposeful voice to the stakeholders for shaping their own future sustainable DRI environment can be achieved by a guided, expert-integrated, interactive and problem-focused workshop series. The chosen workshop design is impactful on creating bottom-up agency for climate action by first defining the high-level problems of unsustainability in energy and fossil-fuel consumption, and then connecting them to the ground-level circumstances of DRI stakeholders. This approach to stakeholder management should initiate a sustainable transition that promises to kick-start impactful changes from within communities, adding to high-level efforts from economics, policy, and governance.","sentences":["The UK Research and Innovation Digital Research Infrastructure (DRI) needs to operate sustainably in the future, encompassing its use of energy and resources, and embedded computer hardware carbon emissions.","Transition concepts towards less unsustainable operations will inform the future design and operations of DRI.","A problem remains that, while the skills and knowledge for solving net zero challenges already exist within the UK's DRI community, the mechanisms for sharing them and enabling behavior change are missing.","Without adopting community-driven approaches, individual stakeholders may feel isolated and uncertain about how to play their role in the transition.","A research programme was funded to give voice to the ground-level stakeholders of the DRI ecosystem for the co-creation of carbon downshift concepts.","This article presents the results of the programme, with the goal to inform a fair and just transition from the ground-level, complementing the top-down interventions of energy efficiency policies and renewable energies integration.","A workshop-based innovation method was developed for researching stakeholder recommendations and perspectives on the sustainable transition of the UK's DRI.","We find that giving a purposeful voice to the stakeholders for shaping their own future sustainable DRI environment can be achieved by a guided, expert-integrated, interactive and problem-focused workshop series.","The chosen workshop design is impactful on creating bottom-up agency for climate action by first defining the high-level problems of unsustainability in energy and fossil-fuel consumption, and then connecting them to the ground-level circumstances of DRI stakeholders.","This approach to stakeholder management should initiate a sustainable transition that promises to kick-start impactful changes from within communities, adding to high-level efforts from economics, policy, and governance."],"url":"http://arxiv.org/abs/2411.14301v1"}
{"created":"2024-11-21 16:50:11","title":"Auto-SPICE: Leveraging LLMs for Dataset Creation via Automated SPICE Netlist Extraction from Analog Circuit Diagrams","abstract":"Auto-SPICE is the first fully automated framework leveraging large language models (LLMs) to generate Simulation Programs with Integrated Circuit Emphasis (SPICE) netlists. It addresses a long-standing challenge in automating netlist generation for analog circuits within circuit design automation. Automating this workflow could accelerate the creation of finetuned LLMs for analog circuit design and verification. We identify key challenges in this automation and evaluate the multi-modal capabilities of state-of-the-art LLMs, particularly GPT-4, to address these issues. We propose a three-step workflow to overcome current limitations: labeling analog circuits, prompt tuning, and netlist verification. This approach aims to create an end-to-end SPICE netlist generator from circuit schematic images, tackling the long-standing hurdle of accurate netlist generation. Our framework demonstrates significant performance improvements, tested on approximately 2,100 schematics of varying complexity. We open-source this solution for community-driven development.","sentences":["Auto-SPICE is the first fully automated framework leveraging large language models (LLMs) to generate Simulation Programs with Integrated Circuit Emphasis (SPICE) netlists.","It addresses a long-standing challenge in automating netlist generation for analog circuits within circuit design automation.","Automating this workflow could accelerate the creation of finetuned LLMs for analog circuit design and verification.","We identify key challenges in this automation and evaluate the multi-modal capabilities of state-of-the-art LLMs, particularly GPT-4, to address these issues.","We propose a three-step workflow to overcome current limitations: labeling analog circuits, prompt tuning, and netlist verification.","This approach aims to create an end-to-end SPICE netlist generator from circuit schematic images, tackling the long-standing hurdle of accurate netlist generation.","Our framework demonstrates significant performance improvements, tested on approximately 2,100 schematics of varying complexity.","We open-source this solution for community-driven development."],"url":"http://arxiv.org/abs/2411.14299v1"}
{"created":"2024-11-21 16:49:31","title":"Decoding the Meaning of Success on Digital Labor Platforms: Worker-Centered Perspectives","abstract":"What does work and career success mean for those who secure their work using digital labor platforms? Traditional research on success predominantly relies on organizationally-centric benchmarks, such as promotions and income. These measures provide limited insights into the evolving nature of work and careers shaped at the intersection of digital labor platform technologies and workers' evolving perspectives. Drawing on data from a longitudinal study of 108 digital labor platform workers on Upwork, we (1) identify seven dimensions of success indicators that reflect workers' definitions of success in platform-mediated work and careers, (2) delineate three dimensions of digital labor platforms mediating workers' experiences of success and (3) examine the shifting perspectives of these workers relative to success. Based on these findings, we discuss the implications of platform-mediated success in workers' labor experiences, marked by platformic management, standardization, precarity and ongoing evolution. Our discussion intertwines CSCW scholarship with career studies, advancing a more nuanced understanding of the evolving perspectives on success in platform-mediated work and careers.","sentences":["What does work and career success mean for those who secure their work using digital labor platforms?","Traditional research on success predominantly relies on organizationally-centric benchmarks, such as promotions and income.","These measures provide limited insights into the evolving nature of work and careers shaped at the intersection of digital labor platform technologies and workers' evolving perspectives.","Drawing on data from a longitudinal study of 108 digital labor platform workers on Upwork, we (1) identify seven dimensions of success indicators that reflect workers' definitions of success in platform-mediated work and careers, (2) delineate three dimensions of digital labor platforms mediating workers' experiences of success and (3) examine the shifting perspectives of these workers relative to success.","Based on these findings, we discuss the implications of platform-mediated success in workers' labor experiences, marked by platformic management, standardization, precarity and ongoing evolution.","Our discussion intertwines CSCW scholarship with career studies, advancing a more nuanced understanding of the evolving perspectives on success in platform-mediated work and careers."],"url":"http://arxiv.org/abs/2411.14298v1"}
{"created":"2024-11-21 16:42:41","title":"Improving Routability Prediction via NAS Using a Smooth One-shot Augmented Predictor","abstract":"Routability optimization in modern EDA tools has benefited greatly from using machine learning (ML) models. Constructing and optimizing the performance of ML models continues to be a challenge. Neural Architecture Search (NAS) serves as a tool to aid in the construction and improvement of these models. Traditional NAS techniques struggle to perform well on routability prediction as a result of two primary factors. First, the separation between the training objective and the search objective adds noise to the NAS process. Secondly, the increased variance of the search objective further complicates performing NAS. We craft a novel NAS technique, coined SOAP-NAS, to address these challenges through novel data augmentation techniques and a novel combination of one-shot and predictor-based NAS. Results show that our technique outperforms existing solutions by 40% closer to the ideal performance measured by ROC-AUC (area under the receiver operating characteristic curve) in DRC hotspot detection. SOAPNet is able to achieve an ROC-AUC of 0.9802 and a query time of only 0.461 ms.","sentences":["Routability optimization in modern EDA tools has benefited greatly from using machine learning (ML) models.","Constructing and optimizing the performance of ML models continues to be a challenge.","Neural Architecture Search (NAS) serves as a tool to aid in the construction and improvement of these models.","Traditional NAS techniques struggle to perform well on routability prediction as a result of two primary factors.","First, the separation between the training objective and the search objective adds noise to the NAS process.","Secondly, the increased variance of the search objective further complicates performing NAS.","We craft a novel NAS technique, coined SOAP-NAS, to address these challenges through novel data augmentation techniques and a novel combination of one-shot and predictor-based NAS.","Results show that our technique outperforms existing solutions by 40% closer to the ideal performance measured by ROC-AUC (area under the receiver operating characteristic curve) in DRC hotspot detection.","SOAPNet is able to achieve an ROC-AUC of 0.9802 and a query time of only 0.461 ms."],"url":"http://arxiv.org/abs/2411.14296v1"}
{"created":"2024-11-21 16:41:55","title":"StereoCrafter-Zero: Zero-Shot Stereo Video Generation with Noisy Restart","abstract":"Generating high-quality stereo videos that mimic human binocular vision requires maintaining consistent depth perception and temporal coherence across frames. While diffusion models have advanced image and video synthesis, generating high-quality stereo videos remains challenging due to the difficulty of maintaining consistent temporal and spatial coherence between left and right views. We introduce \\textit{StereoCrafter-Zero}, a novel framework for zero-shot stereo video generation that leverages video diffusion priors without the need for paired training data. Key innovations include a noisy restart strategy to initialize stereo-aware latents and an iterative refinement process that progressively harmonizes the latent space, addressing issues like temporal flickering and view inconsistencies. Comprehensive evaluations, including quantitative metrics and user studies, demonstrate that \\textit{StereoCrafter-Zero} produces high-quality stereo videos with improved depth consistency and temporal smoothness, even when depth estimations are imperfect. Our framework is robust and adaptable across various diffusion models, setting a new benchmark for zero-shot stereo video generation and enabling more immersive visual experiences. Our code can be found in~\\url{https://github.com/shijianjian/StereoCrafter-Zero}.","sentences":["Generating high-quality stereo videos that mimic human binocular vision requires maintaining consistent depth perception and temporal coherence across frames.","While diffusion models have advanced image and video synthesis, generating high-quality stereo videos remains challenging due to the difficulty of maintaining consistent temporal and spatial coherence between left and right views.","We introduce \\textit{StereoCrafter-Zero}, a novel framework for zero-shot stereo video generation that leverages video diffusion priors without the need for paired training data.","Key innovations include a noisy restart strategy to initialize stereo-aware latents and an iterative refinement process that progressively harmonizes the latent space, addressing issues like temporal flickering and view inconsistencies.","Comprehensive evaluations, including quantitative metrics and user studies, demonstrate that \\textit{StereoCrafter-Zero} produces high-quality stereo videos with improved depth consistency and temporal smoothness, even when depth estimations are imperfect.","Our framework is robust and adaptable across various diffusion models, setting a new benchmark for zero-shot stereo video generation and enabling more immersive visual experiences.","Our code can be found in~\\url{https://github.com/shijianjian/StereoCrafter-Zero}."],"url":"http://arxiv.org/abs/2411.14295v1"}
{"created":"2024-11-21 16:36:38","title":"Soft Manipulation Surface With Reduced Actuator Density For Heterogeneous Object Manipulation","abstract":"Object manipulation in robotics faces challenges due to diverse object shapes, sizes, and fragility. Gripper-based methods offer precision and low degrees of freedom (DOF) but the gripper limits the kind of objects to grasp. On the other hand, surface-based approaches provide flexibility for handling fragile and heterogeneous objects but require numerous actuators, increasing complexity. We propose new manipulation hardware that utilizes equally spaced linear actuators placed vertically and connected by a soft surface. In this setup, object manipulation occurs on the soft surface through coordinated movements of the surrounding actuators. This approach requires fewer actuators to cover a large manipulation area, offering a cost-effective solution with a lower DOF compared to dense actuator arrays. It also effectively handles heterogeneous objects of varying shapes and weights, even when they are significantly smaller than the distance between actuators. This method is particularly suitable for managing highly fragile objects in the food industry.","sentences":["Object manipulation in robotics faces challenges due to diverse object shapes, sizes, and fragility.","Gripper-based methods offer precision and low degrees of freedom (DOF) but the gripper limits the kind of objects to grasp.","On the other hand, surface-based approaches provide flexibility for handling fragile and heterogeneous objects but require numerous actuators, increasing complexity.","We propose new manipulation hardware that utilizes equally spaced linear actuators placed vertically and connected by a soft surface.","In this setup, object manipulation occurs on the soft surface through coordinated movements of the surrounding actuators.","This approach requires fewer actuators to cover a large manipulation area, offering a cost-effective solution with a lower DOF compared to dense actuator arrays.","It also effectively handles heterogeneous objects of varying shapes and weights, even when they are significantly smaller than the distance between actuators.","This method is particularly suitable for managing highly fragile objects in the food industry."],"url":"http://arxiv.org/abs/2411.14290v1"}
{"created":"2024-11-21 16:36:01","title":"On the Sample Complexity of One Hidden Layer Networks with Equivariance, Locality and Weight Sharing","abstract":"Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks. However, it is not clear how each one of these design choices contribute to the generalization error. Through the lens of statistical learning theory, we aim to provide an insight into this question by characterizing the relative impact of each choice on the sample complexity. We obtain lower and upper sample complexity bounds for a class of single hidden layer networks. It is shown that the gain of equivariance is directly manifested in the bound, while getting a similar increase for weight sharing depends on the sharing mechanism. Among our results, we obtain a completely dimension-free bound for equivariant networks for a class of pooling operations. We show that the bound depends merely on the norm of filters, which is tighter than using the spectral norm of the respective matrix. We also characterize the trade-off in sample complexity between the parametrization of filters in spatial and frequency domains, particularly when spatial filters are localized as in vanilla convolutional neural networks.","sentences":["Weight sharing, equivariance, and local filters, as in convolutional neural networks, are believed to contribute to the sample efficiency of neural networks.","However, it is not clear how each one of these design choices contribute to the generalization error.","Through the lens of statistical learning theory, we aim to provide an insight into this question by characterizing the relative impact of each choice on the sample complexity.","We obtain lower and upper sample complexity bounds for a class of single hidden layer networks.","It is shown that the gain of equivariance is directly manifested in the bound, while getting a similar increase for weight sharing depends on the sharing mechanism.","Among our results, we obtain a completely dimension-free bound for equivariant networks for a class of pooling operations.","We show that the bound depends merely on the norm of filters, which is tighter than using the spectral norm of the respective matrix.","We also characterize the trade-off in sample complexity between the parametrization of filters in spatial and frequency domains, particularly when spatial filters are localized as in vanilla convolutional neural networks."],"url":"http://arxiv.org/abs/2411.14288v1"}
{"created":"2024-11-21 16:34:53","title":"Algebras for Deterministic Computation Are Inherently Incomplete","abstract":"Kleene Algebra with Tests (KAT) provides an elegant algebraic framework for describing non-deterministic finite-state computations. Using a small finite set of non-deterministic programming constructs (sequencing, non-deterministic choice, and iteration) it is able to express all non-deterministic finite state control flow over a finite set of primitives. It is natural to ask whether there exists a similar finite set of constructs that can capture all deterministic computation. We show that this is not the case. More precisely, the deterministic fragment of KAT is not generated by any finite set of regular control flow operations. This generalizes earlier results about the expressivity of the traditional control flow operations, i.e., sequential composition, if-then-else and while.","sentences":["Kleene Algebra with Tests (KAT) provides an elegant algebraic framework for describing non-deterministic finite-state computations.","Using a small finite set of non-deterministic programming constructs (sequencing, non-deterministic choice, and iteration) it is able to express all non-deterministic finite state control flow over a finite set of primitives.","It is natural to ask whether there exists a similar finite set of constructs that can capture all deterministic computation.","We show that this is not the case.","More precisely, the deterministic fragment of KAT is not generated by any finite set of regular control flow operations.","This generalizes earlier results about the expressivity of the traditional control flow operations, i.e., sequential composition, if-then-else and while."],"url":"http://arxiv.org/abs/2411.14284v1"}
{"created":"2024-11-21 16:34:52","title":"CAIP: Detecting Router Misconfigurations with Context-Aware Iterative Prompting of LLMs","abstract":"Model checkers and consistency checkers detect critical errors in router configurations, but these tools require significant manual effort to develop and maintain. LLM-based Q&A models have emerged as a promising alternative, allowing users to query partitions of configurations through prompts and receive answers based on learned patterns, thanks to transformer models pre-trained on vast datasets that provide generic configuration context for interpreting router configurations. Yet, current methods of partition-based prompting often do not provide enough network-specific context from the actual configurations to enable accurate inference. We introduce a Context-Aware Iterative Prompting (CAIP) framework that automates network-specific context extraction and optimizes LLM prompts for more precise router misconfiguration detection. CAIP addresses three challenges: (1) efficiently mining relevant context from complex configuration files, (2) accurately distinguishing between pre-defined and user-defined parameter values to prevent irrelevant context from being introduced, and (3) managing prompt context overload with iterative, guided interactions with the model. Our evaluations on synthetic and real-world configurations show that CAIP improves misconfiguration detection accuracy by more than 30% compared to partition-based LLM approaches, model checkers, and consistency checkers, uncovering over 20 previously undetected misconfigurations in real-world configurations.","sentences":["Model checkers and consistency checkers detect critical errors in router configurations, but these tools require significant manual effort to develop and maintain.","LLM-based Q&A models have emerged as a promising alternative, allowing users to query partitions of configurations through prompts and receive answers based on learned patterns, thanks to transformer models pre-trained on vast datasets that provide generic configuration context for interpreting router configurations.","Yet, current methods of partition-based prompting often do not provide enough network-specific context from the actual configurations to enable accurate inference.","We introduce a Context-Aware Iterative Prompting (CAIP) framework that automates network-specific context extraction and optimizes LLM prompts for more precise router misconfiguration detection.","CAIP addresses three challenges: (1) efficiently mining relevant context from complex configuration files, (2) accurately distinguishing between pre-defined and user-defined parameter values to prevent irrelevant context from being introduced, and (3) managing prompt context overload with iterative, guided interactions with the model.","Our evaluations on synthetic and real-world configurations show that CAIP improves misconfiguration detection accuracy by more than 30% compared to partition-based LLM approaches, model checkers, and consistency checkers, uncovering over 20 previously undetected misconfigurations in real-world configurations."],"url":"http://arxiv.org/abs/2411.14283v1"}
{"created":"2024-11-21 16:33:39","title":"Q-CSM: Q-Learning-based Cognitive Service Management in Heterogeneous IoT Networks","abstract":"The dramatic increase in the number of smart services and their diversity poses a significant challenge in Internet of Things (IoT) networks: heterogeneity. This causes significant quality of service (QoS) degradation in IoT networks. In addition, the constraints of IoT devices in terms of computational capability and energy resources add extra complexity to this. However, the current studies remain insufficient to solve this problem due to the lack of cognitive action recommendations. Therefore, we propose a Q-learning-based Cognitive Service Management framework called Q-CSM. In this framework, we first design an IoT Agent Manager to handle the heterogeneity in data formats. After that, we design a Q-learning-based recommendation engine to optimize the devices' lifetime according to the predicted QoS behaviour of the changing IoT network scenarios. We apply the proposed cognitive management to a smart city scenario consisting of three specific services: wind turbines, solar panels, and transportation systems. We note that our proposed cognitive method achieves 38.7% faster response time to the dynamical IoT changes in topology. Furthermore, the proposed framework achieves 19.8% longer lifetime on average for constrained IoT devices thanks to its Q-learning-based cognitive decision capability. In addition, we explore the most successive learning rate value in the Q-learning run through the exploration and exploitation phases.","sentences":["The dramatic increase in the number of smart services and their diversity poses a significant challenge in Internet of Things (IoT) networks: heterogeneity.","This causes significant quality of service (QoS) degradation in IoT networks.","In addition, the constraints of IoT devices in terms of computational capability and energy resources add extra complexity to this.","However, the current studies remain insufficient to solve this problem due to the lack of cognitive action recommendations.","Therefore, we propose a Q-learning-based Cognitive Service Management framework called Q-CSM.","In this framework, we first design an IoT Agent Manager to handle the heterogeneity in data formats.","After that, we design a Q-learning-based recommendation engine to optimize the devices' lifetime according to the predicted QoS behaviour of the changing IoT network scenarios.","We apply the proposed cognitive management to a smart city scenario consisting of three specific services: wind turbines, solar panels, and transportation systems.","We note that our proposed cognitive method achieves 38.7% faster response time to the dynamical IoT changes in topology.","Furthermore, the proposed framework achieves 19.8% longer lifetime on average for constrained IoT devices thanks to its Q-learning-based cognitive decision capability.","In addition, we explore the most successive learning rate value in the Q-learning run through the exploration and exploitation phases."],"url":"http://arxiv.org/abs/2411.14281v1"}
{"created":"2024-11-21 16:33:35","title":"EasyHOI: Unleashing the Power of Large Models for Reconstructing Hand-Object Interactions in the Wild","abstract":"Our work aims to reconstruct hand-object interactions from a single-view image, which is a fundamental but ill-posed task. Unlike methods that reconstruct from videos, multi-view images, or predefined 3D templates, single-view reconstruction faces significant challenges due to inherent ambiguities and occlusions. These challenges are further amplified by the diverse nature of hand poses and the vast variety of object shapes and sizes. Our key insight is that current foundational models for segmentation, inpainting, and 3D reconstruction robustly generalize to in-the-wild images, which could provide strong visual and geometric priors for reconstructing hand-object interactions. Specifically, given a single image, we first design a novel pipeline to estimate the underlying hand pose and object shape using off-the-shelf large models. Furthermore, with the initial reconstruction, we employ a prior-guided optimization scheme, which optimizes hand pose to comply with 3D physical constraints and the 2D input image content. We perform experiments across several datasets and show that our method consistently outperforms baselines and faithfully reconstructs a diverse set of hand-object interactions. Here is the link of our project page: https://lym29.github.io/EasyHOI-page/","sentences":["Our work aims to reconstruct hand-object interactions from a single-view image, which is a fundamental but ill-posed task.","Unlike methods that reconstruct from videos, multi-view images, or predefined 3D templates, single-view reconstruction faces significant challenges due to inherent ambiguities and occlusions.","These challenges are further amplified by the diverse nature of hand poses and the vast variety of object shapes and sizes.","Our key insight is that current foundational models for segmentation, inpainting, and 3D reconstruction robustly generalize to in-the-wild images, which could provide strong visual and geometric priors for reconstructing hand-object interactions.","Specifically, given a single image, we first design a novel pipeline to estimate the underlying hand pose and object shape using off-the-shelf large models.","Furthermore, with the initial reconstruction, we employ a prior-guided optimization scheme, which optimizes hand pose to comply with 3D physical constraints and the 2D input image content.","We perform experiments across several datasets and show that our method consistently outperforms baselines and faithfully reconstructs a diverse set of hand-object interactions.","Here is the link of our project page: https://lym29.github.io/EasyHOI-page/"],"url":"http://arxiv.org/abs/2411.14280v1"}
{"created":"2024-11-21 16:33:30","title":"Looking Beyond Text: Reducing Language bias in Large Vision-Language Models via Multimodal Dual-Attention and Soft-Image Guidance","abstract":"Large vision-language models (LVLMs) have achieved impressive results in various vision-language tasks. However, despite showing promising performance, LVLMs suffer from hallucinations caused by language bias, leading to diminished focus on images and ineffective visual comprehension. We identify two primary reasons for this bias: 1. Different scales of training data between the pretraining stage of LLM and multimodal alignment stage. 2. The learned inference bias due to short-term dependency of text data. Therefore, we propose LACING, a systemic framework designed to address the language bias of LVLMs with muLtimodal duAl-attention meChanIsm (MDA) aNd soft-image Guidance (IFG). Specifically, MDA introduces a parallel dual-attention mechanism that enhances the integration of visual inputs across the model. IFG introduces a learnable soft visual prompt during training and inference to replace visual inputs, designed to compel LVLMs to prioritize text inputs. Then, IFG further proposes a novel decoding strategy using the soft visual prompt to mitigate the model's over-reliance on adjacent text inputs. Comprehensive experiments demonstrate that our method effectively debiases LVLMs from their language bias, enhancing visual comprehension and reducing hallucinations without requiring additional training resources or data. The code and model are available at [lacing-lvlm.github.io](https://lacing-lvlm.github.io).","sentences":["Large vision-language models (LVLMs) have achieved impressive results in various vision-language tasks.","However, despite showing promising performance, LVLMs suffer from hallucinations caused by language bias, leading to diminished focus on images and ineffective visual comprehension.","We identify two primary reasons for this bias: 1. Different scales of training data between the pretraining stage of LLM and multimodal alignment stage.","2.","The learned inference bias due to short-term dependency of text data.","Therefore, we propose LACING, a systemic framework designed to address the language bias of LVLMs with muLtimodal duAl-attention meChanIsm (MDA) aNd soft-image Guidance (IFG).","Specifically, MDA introduces a parallel dual-attention mechanism that enhances the integration of visual inputs across the model.","IFG introduces a learnable soft visual prompt during training and inference to replace visual inputs, designed to compel LVLMs to prioritize text inputs.","Then, IFG further proposes a novel decoding strategy using the soft visual prompt to mitigate the model's over-reliance on adjacent text inputs.","Comprehensive experiments demonstrate that our method effectively debiases LVLMs from their language bias, enhancing visual comprehension and reducing hallucinations without requiring additional training resources or data.","The code and model are available at [lacing-lvlm.github.io](https://lacing-lvlm.github.io)."],"url":"http://arxiv.org/abs/2411.14279v1"}
{"created":"2024-11-21 16:32:02","title":"Adaptive Anomaly Detection for Identifying Attacks in Cyber-Physical Systems: A Systematic Literature Review","abstract":"Modern cyberattacks in cyber-physical systems (CPS) rapidly evolve and cannot be deterred effectively with most current methods which focused on characterizing past threats. Adaptive anomaly detection (AAD) is among the most promising techniques to detect evolving cyberattacks focused on fast data processing and model adaptation. AAD has been researched in the literature extensively; however, to the best of our knowledge, our work is the first systematic literature review (SLR) on the current research within this field. We present a comprehensive SLR, gathering 397 relevant papers and systematically analyzing 65 of them (47 research and 18 survey papers) on AAD in CPS studies from 2013 to 2023 (November). We introduce a novel taxonomy considering attack types, CPS application, learning paradigm, data management, and algorithms. Our analysis indicates, among other findings, that reviewed works focused on a single aspect of adaptation (either data processing or model adaptation) but rarely in both at the same time. We aim to help researchers to advance the state of the art and help practitioners to become familiar with recent progress in this field. We identify the limitations of the state of the art and provide recommendations for future research directions.","sentences":["Modern cyberattacks in cyber-physical systems (CPS) rapidly evolve and cannot be deterred effectively with most current methods which focused on characterizing past threats.","Adaptive anomaly detection (AAD) is among the most promising techniques to detect evolving cyberattacks focused on fast data processing and model adaptation.","AAD has been researched in the literature extensively; however, to the best of our knowledge, our work is the first systematic literature review (SLR) on the current research within this field.","We present a comprehensive SLR, gathering 397 relevant papers and systematically analyzing 65 of them (47 research and 18 survey papers) on AAD in CPS studies from 2013 to 2023 (November).","We introduce a novel taxonomy considering attack types, CPS application, learning paradigm, data management, and algorithms.","Our analysis indicates, among other findings, that reviewed works focused on a single aspect of adaptation (either data processing or model adaptation) but rarely in both at the same time.","We aim to help researchers to advance the state of the art and help practitioners to become familiar with recent progress in this field.","We identify the limitations of the state of the art and provide recommendations for future research directions."],"url":"http://arxiv.org/abs/2411.14278v1"}
{"created":"2024-11-21 16:31:27","title":"Neuro-Symbolic Query Optimization in Knowledge Graphs","abstract":"This chapter delves into the emerging field of neuro-symbolic query optimization for knowledge graphs (KGs), presenting a comprehensive exploration of how neural and symbolic techniques can be integrated to enhance query processing. Traditional query optimizers in knowledge graphs rely heavily on symbolic methods, utilizing dataset summaries, statistics, and cost models to select efficient execution plans. However, these approaches often suffer from misestimations and inaccuracies, particularly when dealing with complex queries or large-scale datasets. Recent advancements have introduced neural models, which capture non-linear aspects of query optimization, offering promising alternatives to purely symbolic methods. In this chapter, we introduce neuro-symbolic query optimizers, a novel approach that combines the strengths of symbolic reasoning with the adaptability of neural computation. We discuss the architecture of these hybrid systems, highlighting the interplay between neural and symbolic components to improve the optimizer's ability to navigate the search space and produce efficient execution plans. Additionally, the chapter reviews existing neural components tailored for optimizing queries over knowledge graphs and examines the limitations and challenges in deploying neuro-symbolic query optimizers in real-world environments.","sentences":["This chapter delves into the emerging field of neuro-symbolic query optimization for knowledge graphs (KGs), presenting a comprehensive exploration of how neural and symbolic techniques can be integrated to enhance query processing.","Traditional query optimizers in knowledge graphs rely heavily on symbolic methods, utilizing dataset summaries, statistics, and cost models to select efficient execution plans.","However, these approaches often suffer from misestimations and inaccuracies, particularly when dealing with complex queries or large-scale datasets.","Recent advancements have introduced neural models, which capture non-linear aspects of query optimization, offering promising alternatives to purely symbolic methods.","In this chapter, we introduce neuro-symbolic query optimizers, a novel approach that combines the strengths of symbolic reasoning with the adaptability of neural computation.","We discuss the architecture of these hybrid systems, highlighting the interplay between neural and symbolic components to improve the optimizer's ability to navigate the search space and produce efficient execution plans.","Additionally, the chapter reviews existing neural components tailored for optimizing queries over knowledge graphs and examines the limitations and challenges in deploying neuro-symbolic query optimizers in real-world environments."],"url":"http://arxiv.org/abs/2411.14277v1"}
{"created":"2024-11-21 16:31:26","title":"A $k^{\\frac{q}{q-2}}$ Lower Bound for Odd Query Locally Decodable Codes from Bipartite Kikuchi Graphs","abstract":"A code $C \\colon \\{0,1\\}^k \\to \\{0,1\\}^n$ is a $q$-query locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \\in \\{0,1\\}^k$ with good confidence by querying a corrupted string $\\tilde{x}$ of the codeword $x = C(b)$ in at most $q$ coordinates. For $2$ queries, the Hadamard code is a $2$-LDC of length $n = 2^k$, and this code is in fact essentially optimal. For $q \\geq 3$, there is a large gap in our understanding: the best constructions achieve $n = \\exp(k^{o(1)})$, while prior to the recent work of [AGKM23], the best lower bounds were $n \\geq \\tilde{\\Omega}(k^{\\frac{q}{q-2}})$ for $q$ even and $n \\geq \\tilde{\\Omega}(k^{\\frac{q+1}{q-1}})$ for $q$ odd.   The recent work of [AGKM23] used spectral methods to prove a lower bound of $n \\geq \\tilde{\\Omega}(k^3)$ for $q = 3$, thus achieving the \"$k^{\\frac{q}{q-2}}$ bound\" for an odd value of $q$. However, their proof does not extend to any odd $q \\geq 5$. In this paper, we prove a $q$-LDC lower bound of $n \\geq \\tilde{\\Omega}(k^{\\frac{q}{q-2}})$ for any odd $q$. Our key technical idea is the use of an imbalanced bipartite Kikuchi graph, which gives a simpler method to analyze spectral refutations of odd arity XOR without using the standard \"Cauchy-Schwarz trick\", a trick that typically produces random matrices with correlated entries and makes the analysis for odd arity XOR significantly more complicated than even arity XOR.","sentences":["A code $C \\colon \\{0,1\\}^k \\to \\{0,1\\}^n$ is a $q$-query locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \\in \\{0,1\\}^k$ with good confidence by querying a corrupted string $\\tilde{x}$ of the codeword $x = C(b)$ in at most $q$ coordinates.","For $2$ queries",", the Hadamard code is a $2$-LDC of length $n = 2^k$, and this code is in fact essentially optimal.","For $q \\geq 3$, there is a large gap in our understanding: the best constructions achieve $n = \\exp(k^{o(1)})$, while prior to the recent work of [AGKM23], the best lower bounds were $n \\geq \\tilde{\\Omega}(k^{\\frac{q}{q-2}})$ for $q$ even and $n \\geq \\tilde{\\Omega}(k^{\\frac{q+1}{q-1}})$ for $q$ odd.   ","The recent work of [AGKM23] used spectral methods to prove a lower bound of $n \\geq \\tilde{\\Omega}(k^3)$ for $q = 3$, thus achieving the \"$k^{\\frac{q}{q-2}}$ bound\" for an odd value of $q$. However, their proof does not extend to any odd $q \\geq 5$. In this paper, we prove a $q$-LDC lower bound of $n \\geq \\tilde{\\Omega}(k^{\\frac{q}{q-2}})$ for any odd $q$. Our key technical idea is the use of an imbalanced bipartite Kikuchi graph, which gives a simpler method to analyze spectral refutations of odd arity XOR without using the standard \"Cauchy-Schwarz trick\", a trick that typically produces random matrices with correlated entries and makes the analysis for odd arity XOR significantly more complicated than even arity XOR."],"url":"http://arxiv.org/abs/2411.14276v1"}
{"created":"2024-11-21 16:31:14","title":"Exploring the Impact of Quizzes Interleaved with Write-Code Tasks in Elementary-Level Visual Programming","abstract":"We explore the role of quizzes in elementary visual programming domains popularly used for K-8 computing education. Prior work has studied various quiz types, such as fill-in-the-gap write-code questions. However, the overall impact of these quizzes is unclear: studies often show utility in the learning phase when enhanced with quizzes, though limited transfer of utility in the post-learning phase. In this paper, we aim to better understand the impact of different quiz types and whether quizzes focusing on diverse skills (e.g., code debugging and task design) would have higher utility. We design a study with Hour of Code: Maze Challenge by code.org as the base curriculum, interleaved with different quiz types. Specifically, we examine two learning groups: (i) HoC-ACE with diverse quizzes including solution tracing, code debugging, code equivalence, and task design; (ii) HoC-Fill with simple quizzes on solution finding. We conducted a large-scale study with 405 students in grades 6--7. Our results highlight that the curriculum enhanced with richer quizzes led to higher utility during the post-learning phase.","sentences":["We explore the role of quizzes in elementary visual programming domains popularly used for K-8 computing education.","Prior work has studied various quiz types, such as fill-in-the-gap write-code questions.","However, the overall impact of these quizzes is unclear: studies often show utility in the learning phase when enhanced with quizzes, though limited transfer of utility in the post-learning phase.","In this paper, we aim to better understand the impact of different quiz types and whether quizzes focusing on diverse skills (e.g., code debugging and task design) would have higher utility.","We design a study with Hour of Code: Maze Challenge by code.org as the base curriculum, interleaved with different quiz types.","Specifically, we examine two learning groups: (i) HoC-ACE with diverse quizzes including solution tracing, code debugging, code equivalence, and task design; (ii) HoC-Fill with simple quizzes on solution finding.","We conducted a large-scale study with 405 students in grades 6--7.","Our results highlight that the curriculum enhanced with richer quizzes led to higher utility during the post-learning phase."],"url":"http://arxiv.org/abs/2411.14275v1"}
{"created":"2024-11-21 16:28:32","title":"Efficient Aspect-Based Summarization of Climate Change Reports with Small Language Models","abstract":"The use of Natural Language Processing (NLP) for helping decision-makers with Climate Change action has recently been highlighted as a use case aligning with a broader drive towards NLP technologies for social good. In this context, Aspect-Based Summarization (ABS) systems that extract and summarize relevant information are particularly useful as they provide stakeholders with a convenient way of finding relevant information in expert-curated reports. In this work, we release a new dataset for ABS of Climate Change reports and we employ different Large Language Models (LLMs) and so-called Small Language Models (SLMs) to tackle this problem in an unsupervised way. Considering the problem at hand, we also show how SLMs are not significantly worse for the problem while leading to reduced carbon footprint; we do so by applying for the first time an existing framework considering both energy efficiency and task performance to the evaluation of zero-shot generative models for ABS. Overall, our results show that modern language models, both big and small, can effectively tackle ABS for Climate Change reports but more research is needed when we frame the problem as a Retrieval Augmented Generation (RAG) problem and our work and dataset will help foster efforts in this direction.","sentences":["The use of Natural Language Processing (NLP) for helping decision-makers with Climate Change action has recently been highlighted as a use case aligning with a broader drive towards NLP technologies for social good.","In this context, Aspect-Based Summarization (ABS) systems that extract and summarize relevant information are particularly useful as they provide stakeholders with a convenient way of finding relevant information in expert-curated reports.","In this work, we release a new dataset for ABS of Climate Change reports and we employ different Large Language Models (LLMs) and so-called Small Language Models (SLMs) to tackle this problem in an unsupervised way.","Considering the problem at hand, we also show how SLMs are not significantly worse for the problem while leading to reduced carbon footprint; we do so by applying for the first time an existing framework considering both energy efficiency and task performance to the evaluation of zero-shot generative models for ABS.","Overall, our results show that modern language models, both big and small, can effectively tackle ABS for Climate Change reports but more research is needed when we frame the problem as a Retrieval Augmented Generation (RAG) problem and our work and dataset will help foster efforts in this direction."],"url":"http://arxiv.org/abs/2411.14272v1"}
{"created":"2024-11-21 16:25:10","title":"Truly Supercritical Trade-offs for Resolution, Cutting Planes, Monotone Circuits, and Weisfeiler-Leman","abstract":"We exhibit supercritical trade-off for monotone circuits, showing that there are functions computable by small circuits for which any circuit must have depth super-linear or even super-polynomial in the number of variables, far exceeding the linear worst-case upper bound. We obtain similar trade-offs in proof complexity, where we establish the first size-depth trade-offs for cutting planes and resolution that are truly supercritical, i.e., in terms of formula size rather than number of variables, and we also show supercritical trade-offs between width and size for treelike resolution. Our results build on a new supercritical width-depth trade-off for resolution, obtained by refining and strengthening the compression scheme for the Cop-Robber game in [Grohe, Lichter, Neuen & Schweitzer 2023]. This yields robust supercritical trade-offs for dimension versus iteration number in the Weisfeiler-Leman algorithm, which also translate into trade-offs between number of variables and quantifier depth in first-order logic. Our other results follow from improved lifting theorems that might be of independent interest.","sentences":["We exhibit supercritical trade-off for monotone circuits, showing that there are functions computable by small circuits for which any circuit must have depth super-linear or even super-polynomial in the number of variables, far exceeding the linear worst-case upper bound.","We obtain similar trade-offs in proof complexity, where we establish the first size-depth trade-offs for cutting planes and resolution that are truly supercritical, i.e., in terms of formula size rather than number of variables, and we also show supercritical trade-offs between width and size for treelike resolution.","Our results build on a new supercritical width-depth trade-off for resolution, obtained by refining and strengthening the compression scheme for the Cop-Robber game in [Grohe, Lichter, Neuen & Schweitzer 2023].","This yields robust supercritical trade-offs for dimension versus iteration number in the Weisfeiler-Leman algorithm, which also translate into trade-offs between number of variables and quantifier depth in first-order logic.","Our other results follow from improved lifting theorems that might be of independent interest."],"url":"http://arxiv.org/abs/2411.14267v1"}
{"created":"2024-11-21 16:20:31","title":"Explainable Multi-Agent Reinforcement Learning for Extended Reality Codec Adaptation","abstract":"Extended Reality (XR) services are set to transform applications over 5th and 6th generation wireless networks, delivering immersive experiences. Concurrently, Artificial Intelligence (AI) advancements have expanded their role in wireless networks, however, trust and transparency in AI remain to be strengthened. Thus, providing explanations for AI-enabled systems can enhance trust. We introduce Value Function Factorization (VFF)-based Explainable (X) Multi-Agent Reinforcement Learning (MARL) algorithms, explaining reward design in XR codec adaptation through reward decomposition. We contribute four enhancements to XMARL algorithms. Firstly, we detail architectural modifications to enable reward decomposition in VFF-based MARL algorithms: Value Decomposition Networks (VDN), Mixture of Q-Values (QMIX), and Q-Transformation (Q-TRAN). Secondly, inspired by multi-task learning, we reduce the overhead of vanilla XMARL algorithms. Thirdly, we propose a new explainability metric, Reward Difference Fluctuation Explanation (RDFX), suitable for problems with adjustable parameters. Lastly, we propose adaptive XMARL, leveraging network gradients and reward decomposition for improved action selection. Simulation results indicate that, in XR codec adaptation, the Packet Delivery Ratio reward is the primary contributor to optimal performance compared to the initial composite reward, which included delay and Data Rate Ratio components. Modifications to VFF-based XMARL algorithms, incorporating multi-headed structures and adaptive loss functions, enable the best-performing algorithm, Multi-Headed Adaptive (MHA)-QMIX, to achieve significant average gains over the Adjust Packet Size baseline up to 10.7%, 41.4%, 33.3%, and 67.9% in XR index, jitter, delay, and Packet Loss Ratio (PLR), respectively.","sentences":["Extended Reality (XR) services are set to transform applications over 5th and 6th generation wireless networks, delivering immersive experiences.","Concurrently, Artificial Intelligence (AI) advancements have expanded their role in wireless networks, however, trust and transparency in AI remain to be strengthened.","Thus, providing explanations for AI-enabled systems can enhance trust.","We introduce Value Function Factorization (VFF)-based Explainable (X) Multi-Agent Reinforcement Learning (MARL) algorithms, explaining reward design in XR codec adaptation through reward decomposition.","We contribute four enhancements to XMARL algorithms.","Firstly, we detail architectural modifications to enable reward decomposition in VFF-based MARL algorithms: Value Decomposition Networks (VDN), Mixture of Q-Values (QMIX), and Q-Transformation (Q-TRAN).","Secondly, inspired by multi-task learning, we reduce the overhead of vanilla XMARL algorithms.","Thirdly, we propose a new explainability metric, Reward Difference Fluctuation Explanation (RDFX), suitable for problems with adjustable parameters.","Lastly, we propose adaptive XMARL, leveraging network gradients and reward decomposition for improved action selection.","Simulation results indicate that, in XR codec adaptation, the Packet Delivery Ratio reward is the primary contributor to optimal performance compared to the initial composite reward, which included delay and Data Rate Ratio components.","Modifications to VFF-based XMARL algorithms, incorporating multi-headed structures and adaptive loss functions, enable the best-performing algorithm, Multi-Headed Adaptive (MHA)-QMIX, to achieve significant average gains over the Adjust Packet Size baseline up to 10.7%, 41.4%, 33.3%, and 67.9% in XR index, jitter, delay, and Packet Loss Ratio (PLR), respectively."],"url":"http://arxiv.org/abs/2411.14264v1"}
{"created":"2024-11-21 16:18:52","title":"Generating Realistic Adversarial Examples for Business Processes using Variational Autoencoders","abstract":"In predictive process monitoring, predictive models are vulnerable to adversarial attacks, where input perturbations can lead to incorrect predictions. Unlike in computer vision, where these perturbations are designed to be imperceptible to the human eye, the generation of adversarial examples in predictive process monitoring poses unique challenges. Minor changes to the activity sequences can create improbable or even impossible scenarios to occur due to underlying constraints such as regulatory rules or process constraints. To address this, we focus on generating realistic adversarial examples tailored to the business process context, in contrast to the imperceptible, pixel-level changes commonly seen in computer vision adversarial attacks. This paper introduces two novel latent space attacks, which generate adversaries by adding noise to the latent space representation of the input data, rather than directly modifying the input attributes. These latent space methods are domain-agnostic and do not rely on process-specific knowledge, as we restrict the generation of adversarial examples to the learned class-specific data distributions by directly perturbing the latent space representation of the business process executions. We evaluate these two latent space methods with six other adversarial attacking methods on eleven real-life event logs and four predictive models. The first three attacking methods directly permute the activities of the historically observed business process executions. The fourth method constrains the adversarial examples to lie within the same data distribution as the original instances, by projecting the adversarial examples to the original data distribution.","sentences":["In predictive process monitoring, predictive models are vulnerable to adversarial attacks, where input perturbations can lead to incorrect predictions.","Unlike in computer vision, where these perturbations are designed to be imperceptible to the human eye, the generation of adversarial examples in predictive process monitoring poses unique challenges.","Minor changes to the activity sequences can create improbable or even impossible scenarios to occur due to underlying constraints such as regulatory rules or process constraints.","To address this, we focus on generating realistic adversarial examples tailored to the business process context, in contrast to the imperceptible, pixel-level changes commonly seen in computer vision adversarial attacks.","This paper introduces two novel latent space attacks, which generate adversaries by adding noise to the latent space representation of the input data, rather than directly modifying the input attributes.","These latent space methods are domain-agnostic and do not rely on process-specific knowledge, as we restrict the generation of adversarial examples to the learned class-specific data distributions by directly perturbing the latent space representation of the business process executions.","We evaluate these two latent space methods with six other adversarial attacking methods on eleven real-life event logs and four predictive models.","The first three attacking methods directly permute the activities of the historically observed business process executions.","The fourth method constrains the adversarial examples to lie within the same data distribution as the original instances, by projecting the adversarial examples to the original data distribution."],"url":"http://arxiv.org/abs/2411.14263v1"}
{"created":"2024-11-21 16:09:05","title":"Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective","abstract":"Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) based applications including automated text generation, question answering, chatbots, and others. However, they face a significant challenge: hallucinations, where models produce plausible-sounding but factually incorrect responses. This undermines trust and limits the applicability of LLMs in different domains. Knowledge Graphs (KGs), on the other hand, provide a structured collection of interconnected facts represented as entities (nodes) and their relationships (edges). In recent research, KGs have been leveraged to provide context that can fill gaps in an LLM understanding of certain topics offering a promising approach to mitigate hallucinations in LLMs, enhancing their reliability and accuracy while benefiting from their wide applicability. Nonetheless, it is still a very active area of research with various unresolved open problems. In this paper, we discuss these open challenges covering state-of-the-art datasets and benchmarks as well as methods for knowledge integration and evaluating hallucinations. In our discussion, we consider the current use of KGs in LLM systems and identify future directions within each of these challenges.","sentences":["Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) based applications including automated text generation, question answering, chatbots, and others.","However, they face a significant challenge: hallucinations, where models produce plausible-sounding but factually incorrect responses.","This undermines trust and limits the applicability of LLMs in different domains.","Knowledge Graphs (KGs), on the other hand, provide a structured collection of interconnected facts represented as entities (nodes) and their relationships (edges).","In recent research, KGs have been leveraged to provide context that can fill gaps in an LLM understanding of certain topics offering a promising approach to mitigate hallucinations in LLMs, enhancing their reliability and accuracy while benefiting from their wide applicability.","Nonetheless, it is still a very active area of research with various unresolved open problems.","In this paper, we discuss these open challenges covering state-of-the-art datasets and benchmarks as well as methods for knowledge integration and evaluating hallucinations.","In our discussion, we consider the current use of KGs in LLM systems and identify future directions within each of these challenges."],"url":"http://arxiv.org/abs/2411.14258v1"}
{"created":"2024-11-21 16:05:58","title":"Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models","abstract":"Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem. Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about. Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie. This suggests that models can have self-knowledge: internal representations about their own capabilities. These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse. We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism. Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token.","sentences":["Hallucinations in large language models are a widespread problem, yet the mechanisms behind whether models will hallucinate are poorly understood, limiting our ability to solve this problem.","Using sparse autoencoders as an interpretability tool, we discover that a key part of these mechanisms is entity recognition, where the model detects if an entity is one it can recall facts about.","Sparse autoencoders uncover meaningful directions in the representation space, these detect whether the model recognizes an entity, e.g. detecting it doesn't know about an athlete or a movie.","This suggests that models can have self-knowledge: internal representations about their own capabilities.","These directions are causally relevant: capable of steering the model to refuse to answer questions about known entities, or to hallucinate attributes of unknown entities when it would otherwise refuse.","We demonstrate that despite the sparse autoencoders being trained on the base model, these directions have a causal effect on the chat model's refusal behavior, suggesting that chat finetuning has repurposed this existing mechanism.","Furthermore, we provide an initial exploration into the mechanistic role of these directions in the model, finding that they disrupt the attention of downstream heads that typically move entity attributes to the final token."],"url":"http://arxiv.org/abs/2411.14257v1"}
{"created":"2024-11-21 16:04:10","title":"Generalizing End-To-End Autonomous Driving In Real-World Environments Using Zero-Shot LLMs","abstract":"Traditional autonomous driving methods adopt a modular design, decomposing tasks into sub-tasks. In contrast, end-to-end autonomous driving directly outputs actions from raw sensor data, avoiding error accumulation. However, training an end-to-end model requires a comprehensive dataset; otherwise, the model exhibits poor generalization capabilities. Recently, large language models (LLMs) have been applied to enhance the generalization capabilities of end-to-end driving models. Most studies explore LLMs in an open-loop manner, where the output actions are compared to those of experts without direct feedback from the real world, while others examine closed-loop results only in simulations. This paper proposes an efficient architecture that integrates multimodal LLMs into end-to-end driving models operating in closed-loop settings in real-world environments. In our architecture, the LLM periodically processes raw sensor data to generate high-level driving instructions, effectively guiding the end-to-end model, even at a slower rate than the raw sensor data. This architecture relaxes the trade-off between the latency and inference quality of the LLM. It also allows us to choose from a wide variety of LLMs to improve high-level driving instructions and minimize fine-tuning costs. Consequently, our architecture reduces data collection requirements because the LLMs do not directly output actions; we only need to train a simple imitation learning model to output actions. In our experiments, the training data for the end-to-end model in a real-world environment consists of only simple obstacle configurations with one traffic cone, while the test environment is more complex and contains multiple obstacles placed in various positions. Experiments show that the proposed architecture enhances the generalization capabilities of the end-to-end model even without fine-tuning the LLM.","sentences":["Traditional autonomous driving methods adopt a modular design, decomposing tasks into sub-tasks.","In contrast, end-to-end autonomous driving directly outputs actions from raw sensor data, avoiding error accumulation.","However, training an end-to-end model requires a comprehensive dataset; otherwise, the model exhibits poor generalization capabilities.","Recently, large language models (LLMs) have been applied to enhance the generalization capabilities of end-to-end driving models.","Most studies explore LLMs in an open-loop manner, where the output actions are compared to those of experts without direct feedback from the real world, while others examine closed-loop results only in simulations.","This paper proposes an efficient architecture that integrates multimodal LLMs into end-to-end driving models operating in closed-loop settings in real-world environments.","In our architecture, the LLM periodically processes raw sensor data to generate high-level driving instructions, effectively guiding the end-to-end model, even at a slower rate than the raw sensor data.","This architecture relaxes the trade-off between the latency and inference quality of the LLM.","It also allows us to choose from a wide variety of LLMs to improve high-level driving instructions and minimize fine-tuning costs.","Consequently, our architecture reduces data collection requirements because the LLMs do not directly output actions; we only need to train a simple imitation learning model to output actions.","In our experiments, the training data for the end-to-end model in a real-world environment consists of only simple obstacle configurations with one traffic cone, while the test environment is more complex and contains multiple obstacles placed in various positions.","Experiments show that the proposed architecture enhances the generalization capabilities of the end-to-end model even without fine-tuning the LLM."],"url":"http://arxiv.org/abs/2411.14256v1"}
{"created":"2024-11-21 16:02:39","title":"BERT-Based Approach for Automating Course Articulation Matrix Construction with Explainable AI","abstract":"Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO) alignment is a crucial task for ensuring curriculum coherence and assessing educational effectiveness. The construction of a Course Articulation Matrix (CAM), which quantifies the relationship between COs and POs/PSOs, typically involves assigning numerical values (0, 1, 2, 3) to represent the degree of alignment. In this study, We experiment with four models from the BERT family: BERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification to assess the alignment between CO and PO/PSO pairs. We first evaluate traditional machine learning classifiers, such as Decision Tree, Random Forest, and XGBoost, and then apply transfer learning to evaluate the performance of the pretrained BERT models. To enhance model interpretability, we apply Explainable AI technique, specifically Local Interpretable Model-agnostic Explanations (LIME), to provide transparency into the decision-making process. Our system achieves accuracy, precision, recall, and F1-score values of 98.66%, 98.67%, 98.66%, and 98.66%, respectively. This work demonstrates the potential of utilizing transfer learning with BERT-based models for the automated generation of CAMs, offering high performance and interpretability in educational outcome assessment.","sentences":["Course Outcome (CO) and Program Outcome (PO)/Program-Specific Outcome (PSO) alignment is a crucial task for ensuring curriculum coherence and assessing educational effectiveness.","The construction of a Course Articulation Matrix (CAM), which quantifies the relationship between COs and POs/PSOs, typically involves assigning numerical values (0, 1, 2, 3) to represent the degree of alignment.","In this study, We experiment with four models from the BERT family: BERT Base, DistilBERT, ALBERT, and RoBERTa, and use multiclass classification to assess the alignment between CO and PO/PSO pairs.","We first evaluate traditional machine learning classifiers, such as Decision Tree, Random Forest, and XGBoost, and then apply transfer learning to evaluate the performance of the pretrained BERT models.","To enhance model interpretability, we apply Explainable AI technique, specifically Local Interpretable Model-agnostic Explanations (LIME), to provide transparency into the decision-making process.","Our system achieves accuracy, precision, recall, and F1-score values of 98.66%, 98.67%, 98.66%, and 98.66%, respectively.","This work demonstrates the potential of utilizing transfer learning with BERT-based models for the automated generation of CAMs, offering high performance and interpretability in educational outcome assessment."],"url":"http://arxiv.org/abs/2411.14254v1"}
{"created":"2024-11-21 15:59:29","title":"Intent-Aware Dialogue Generation and Multi-Task Contrastive Learning for Multi-Turn Intent Classification","abstract":"Generating large-scale, domain-specific, multilingual multi-turn dialogue datasets remains a significant hurdle for training effective Multi-Turn Intent Classification models in chatbot systems. In this paper, we introduce Chain-of-Intent, a novel mechanism that combines Hidden Markov Models with Large Language Models (LLMs) to generate contextually aware, intent-driven conversations through self-play. By extracting domain-specific knowledge from e-commerce chat logs, we estimate conversation turns and intent transitions, which guide the generation of coherent dialogues. Leveraging LLMs to enhance emission probabilities, our approach produces natural and contextually consistent questions and answers. We also propose MINT-CL, a framework for multi-turn intent classification using multi-task contrastive learning, improving classification accuracy without the need for extensive annotated data. Evaluations show that our methods outperform baselines in dialogue quality and intent classification accuracy, especially in multilingual settings, while significantly reducing data generation efforts. Furthermore, we release MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue corpus to support future research in this area.","sentences":["Generating large-scale, domain-specific, multilingual multi-turn dialogue datasets remains a significant hurdle for training effective Multi-Turn Intent Classification models in chatbot systems.","In this paper, we introduce Chain-of-Intent, a novel mechanism that combines Hidden Markov Models with Large Language Models (LLMs) to generate contextually aware, intent-driven conversations through self-play.","By extracting domain-specific knowledge from e-commerce chat logs, we estimate conversation turns and intent transitions, which guide the generation of coherent dialogues.","Leveraging LLMs to enhance emission probabilities, our approach produces natural and contextually consistent questions and answers.","We also propose MINT-CL, a framework for multi-turn intent classification using multi-task contrastive learning, improving classification accuracy without the need for extensive annotated data.","Evaluations show that our methods outperform baselines in dialogue quality and intent classification accuracy, especially in multilingual settings, while significantly reducing data generation efforts.","Furthermore, we release MINT-E, a multilingual, intent-aware multi-turn e-commerce dialogue corpus to support future research in this area."],"url":"http://arxiv.org/abs/2411.14252v1"}
{"created":"2024-11-21 15:57:02","title":"Natural Language Reinforcement Learning","abstract":"Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP). With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models. This paper seeks a new possibility, Natural Language Reinforcement Learning (NLRL), by extending traditional MDP to natural language-based representation space. Specifically, NLRL innovatively redefines RL principles, including task objectives, policy, value function, Bellman equation, and policy iteration, into their language counterparts. With recent advancements in large language models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value improvement by either pure prompting or gradient-based training. Experiments over Maze, Breakthrough, and Tic-Tac-Toe games demonstrate the effectiveness, efficiency, and interpretability of the NLRL framework among diverse use cases. Our code will be released at https://github.com/waterhorse1/Natural-language-RL.","sentences":["Reinforcement Learning (RL) mathematically formulates decision-making with Markov Decision Process (MDP).","With MDPs, researchers have achieved remarkable breakthroughs across various domains, including games, robotics, and language models.","This paper seeks a new possibility, Natural Language Reinforcement Learning (NLRL), by extending traditional MDP to natural language-based representation space.","Specifically, NLRL innovatively redefines RL principles, including task objectives, policy, value function, Bellman equation, and policy iteration, into their language counterparts.","With recent advancements in large language models (LLMs), NLRL can be practically implemented to achieve RL-like policy and value improvement by either pure prompting or gradient-based training.","Experiments over Maze, Breakthrough, and Tic-Tac-Toe games demonstrate the effectiveness, efficiency, and interpretability of the NLRL framework among diverse use cases.","Our code will be released at https://github.com/waterhorse1/Natural-language-RL."],"url":"http://arxiv.org/abs/2411.14251v1"}
{"created":"2024-11-21 15:54:34","title":"Towards a Physics Engine to Simulate Robotic Laser Surgery: Finite Element Modeling of Thermal Laser-Tissue Interactions","abstract":"This paper presents a computational model, based on the Finite Element Method (FEM), that simulates the thermal response of laser-irradiated tissue. This model addresses a gap in the current ecosystem of surgical robot simulators, which generally lack support for lasers and other energy-based end effectors. In the proposed model, the thermal dynamics of the tissue are calculated as the solution to a heat conduction problem with appropriate boundary conditions. The FEM formulation allows the model to capture complex phenomena, such as convection, which is crucial for creating realistic simulations. The accuracy of the model was verified via benchtop laser-tissue interaction experiments using agar tissue phantoms and ex-vivo chicken muscle. The results revealed an average root-mean-square error (RMSE) of less than 2 degrees Celsius across most experimental conditions.","sentences":["This paper presents a computational model, based on the Finite Element Method (FEM), that simulates the thermal response of laser-irradiated tissue.","This model addresses a gap in the current ecosystem of surgical robot simulators, which generally lack support for lasers and other energy-based end effectors.","In the proposed model, the thermal dynamics of the tissue are calculated as the solution to a heat conduction problem with appropriate boundary conditions.","The FEM formulation allows the model to capture complex phenomena, such as convection, which is crucial for creating realistic simulations.","The accuracy of the model was verified via benchtop laser-tissue interaction experiments using agar tissue phantoms and ex-vivo chicken muscle.","The results revealed an average root-mean-square error (RMSE) of less than 2 degrees Celsius across most experimental conditions."],"url":"http://arxiv.org/abs/2411.14249v1"}
{"created":"2024-11-21 15:52:23","title":"Simulation-Aided Policy Tuning for Black-Box Robot Learning","abstract":"How can robots learn and adapt to new tasks and situations with little data? Systematic exploration and simulation are crucial tools for efficient robot learning. We present a novel black-box policy search algorithm focused on data-efficient policy improvements. The algorithm learns directly on the robot and treats simulation as an additional information source to speed up the learning process. At the core of the algorithm, a probabilistic model learns the dependence of the policy parameters and the robot learning objective not only by performing experiments on the robot, but also by leveraging data from a simulator. This substantially reduces interaction time with the robot. Using this model, we can guarantee improvements with high probability for each policy update, thereby facilitating fast, goal-oriented learning. We evaluate our algorithm on simulated fine-tuning tasks and demonstrate the data-efficiency of the proposed dual-information source optimization algorithm. In a real robot learning experiment, we show fast and successful task learning on a robot manipulator with the aid of an imperfect simulator.","sentences":["How can robots learn and adapt to new tasks and situations with little data?","Systematic exploration and simulation are crucial tools for efficient robot learning.","We present a novel black-box policy search algorithm focused on data-efficient policy improvements.","The algorithm learns directly on the robot and treats simulation as an additional information source to speed up the learning process.","At the core of the algorithm, a probabilistic model learns the dependence of the policy parameters and the robot learning objective not only by performing experiments on the robot, but also by leveraging data from a simulator.","This substantially reduces interaction time with the robot.","Using this model, we can guarantee improvements with high probability for each policy update, thereby facilitating fast, goal-oriented learning.","We evaluate our algorithm on simulated fine-tuning tasks and demonstrate the data-efficiency of the proposed dual-information source optimization algorithm.","In a real robot learning experiment, we show fast and successful task learning on a robot manipulator with the aid of an imperfect simulator."],"url":"http://arxiv.org/abs/2411.14246v1"}
{"created":"2024-11-21 15:52:12","title":"Pulsar Consensus","abstract":"In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.","sentences":["In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations.","The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain.","We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols.","We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work.","Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain."],"url":"http://arxiv.org/abs/2411.14245v1"}
{"created":"2024-11-21 15:50:59","title":"AnywhereDoor: Multi-Target Backdoor Attacks on Object Detection","abstract":"As object detection becomes integral to many safety-critical applications, understanding its vulnerabilities is essential. Backdoor attacks, in particular, pose a significant threat by implanting hidden backdoor in a victim model, which adversaries can later exploit to trigger malicious behaviors during inference. However, current backdoor techniques are limited to static scenarios where attackers must define a malicious objective before training, locking the attack into a predetermined action without inference-time adaptability. Given the expressive output space in object detection, including object existence detection, bounding box estimation, and object classification, the feasibility of implanting a backdoor that provides inference-time control with a high degree of freedom remains unexplored. This paper introduces AnywhereDoor, a flexible backdoor attack tailored for object detection. Once implanted, AnywhereDoor enables adversaries to specify different attack types (object vanishing, fabrication, or misclassification) and configurations (untargeted or targeted with specific classes) to dynamically control detection behavior. This flexibility is achieved through three key innovations: (i) objective disentanglement to support a broader range of attack combinations well beyond what existing methods allow; (ii) trigger mosaicking to ensure backdoor activations are robust, even against those object detectors that extract localized regions from the input image for recognition; and (iii) strategic batching to address object-level data imbalances that otherwise hinders a balanced manipulation. Extensive experiments demonstrate that AnywhereDoor provides attackers with a high degree of control, achieving an attack success rate improvement of nearly 80% compared to adaptations of existing methods for such flexible control.","sentences":["As object detection becomes integral to many safety-critical applications, understanding its vulnerabilities is essential.","Backdoor attacks, in particular, pose a significant threat by implanting hidden backdoor in a victim model, which adversaries can later exploit to trigger malicious behaviors during inference.","However, current backdoor techniques are limited to static scenarios where attackers must define a malicious objective before training, locking the attack into a predetermined action without inference-time adaptability.","Given the expressive output space in object detection, including object existence detection, bounding box estimation, and object classification, the feasibility of implanting a backdoor that provides inference-time control with a high degree of freedom remains unexplored.","This paper introduces AnywhereDoor, a flexible backdoor attack tailored for object detection.","Once implanted, AnywhereDoor enables adversaries to specify different attack types (object vanishing, fabrication, or misclassification) and configurations (untargeted or targeted with specific classes) to dynamically control detection behavior.","This flexibility is achieved through three key innovations: (i) objective disentanglement to support a broader range of attack combinations well beyond what existing methods allow; (ii) trigger mosaicking to ensure backdoor activations are robust, even against those object detectors that extract localized regions from the input image for recognition; and (iii) strategic batching to address object-level data imbalances that otherwise hinders a balanced manipulation.","Extensive experiments demonstrate that AnywhereDoor provides attackers with a high degree of control, achieving an attack success rate improvement of nearly 80% compared to adaptations of existing methods for such flexible control."],"url":"http://arxiv.org/abs/2411.14243v1"}
{"created":"2024-11-21 15:50:06","title":"Approximate Constrained Lumping of Chemical Reaction Networks","abstract":"Gaining insights from realistic dynamical models of biochemical systems can be challenging given their large number of state variables. Model reduction techniques can mitigate this by decreasing complexity by mapping the model onto a lower-dimensional state space. Exact constrained lumping identifies reductions as linear combinations of the original state variables in systems of nonlinear ordinary differential equations, preserving specific user-defined output variables without error. However, exact reductions can be too stringent in practice, as model parameters are often uncertain or imprecise -- a particularly relevant problem for biochemical systems. We propose approximate constrained lumping. It allows for a relaxation of exactness within a given tolerance parameter $\\varepsilon$, while still working in polynomial time. We prove that the accuracy, i.e., the difference between the output variables in the original and reduced model, is in the order of $\\varepsilon$. Furthermore, we provide a heuristic algorithm to find the smallest $\\varepsilon$ for a given maximum allowable size of the lumped system. Our method is applied to several models from the literature, resulting in coarser aggregations than exact lumping while still capturing the dynamics of the original system accurately.","sentences":["Gaining insights from realistic dynamical models of biochemical systems can be challenging given their large number of state variables.","Model reduction techniques can mitigate this by decreasing complexity by mapping the model onto a lower-dimensional state space.","Exact constrained lumping identifies reductions as linear combinations of the original state variables in systems of nonlinear ordinary differential equations, preserving specific user-defined output variables without error.","However, exact reductions can be too stringent in practice, as model parameters are often uncertain or imprecise -- a particularly relevant problem for biochemical systems.","We propose approximate constrained lumping.","It allows for a relaxation of exactness within a given tolerance parameter $\\varepsilon$, while still working in polynomial time.","We prove that the accuracy, i.e., the difference between the output variables in the original and reduced model, is in the order of $\\varepsilon$. Furthermore, we provide a heuristic algorithm to find the smallest $\\varepsilon$ for a given maximum allowable size of the lumped system.","Our method is applied to several models from the literature, resulting in coarser aggregations than exact lumping while still capturing the dynamics of the original system accurately."],"url":"http://arxiv.org/abs/2411.14242v1"}
{"created":"2024-11-21 15:42:13","title":"A qualitative analysis of remote patient monitoring: how a paradox mindset can support balancing emotional tensions in the design of healthcare technologies","abstract":"Remote patient monitoring (RPM) is the use of digital technologies to improve patient care at a distance. However, current RPM solutions are often biased toward tech-savvy patients. To foster health equity, researchers have studied how to address the socio-economic and cognitive needs of diverse patient groups, but their emotional needs have remained largely neglected. We perform the first qualitative study to explore the emotional needs of diverse patients around RPM. Specifically, we conduct a thematic analysis of 18 interviews and 4 focus groups at a large US healthcare organization. We identify emotional needs that lead to four emotional tensions within and across stakeholder groups when applying an equity focus to the design and implementation of RPM technologies. The four emotional tensions are making diverse patients feel: (i) heard vs. exploited; (ii) seen vs. deprioritized for efficiency; (iii) empowered vs. anxious; and (iv) cared for vs. detached from care. To manage these emotional tensions across stakeholders, we develop design recommendations informed by a paradox mindset (i.e., \"both-and\" rather than \"and-or\" strategies).","sentences":["Remote patient monitoring (RPM) is the use of digital technologies to improve patient care at a distance.","However, current RPM solutions are often biased toward tech-savvy patients.","To foster health equity, researchers have studied how to address the socio-economic and cognitive needs of diverse patient groups, but their emotional needs have remained largely neglected.","We perform the first qualitative study to explore the emotional needs of diverse patients around RPM.","Specifically, we conduct a thematic analysis of 18 interviews and 4 focus groups at a large US healthcare organization.","We identify emotional needs that lead to four emotional tensions within and across stakeholder groups when applying an equity focus to the design and implementation of RPM technologies.","The four emotional tensions are making diverse patients feel: (i) heard vs. exploited; (ii) seen vs. deprioritized for efficiency; (iii) empowered vs. anxious; and (iv) cared for vs. detached from care.","To manage these emotional tensions across stakeholders, we develop design recommendations informed by a paradox mindset (i.e., \"both-and\" rather than \"and-or\" strategies)."],"url":"http://arxiv.org/abs/2411.14233v1"}
