{"created":"2024-08-19 17:59:04","title":"KAN 2.0: Kolmogorov-Arnold Networks Meet Science","abstract":"A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism. To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science. The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas. The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs). We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes. (2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs. (3) tree converter: convert KANs (or any neural networks) to tree graphs. Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws.","sentences":["A major challenge of AI + Science lies in their inherent incompatibility: today's AI is primarily based on connectionism, while science depends on symbolism.","To bridge the two worlds, we propose a framework to seamlessly synergize Kolmogorov-Arnold Networks (KANs) and science.","The framework highlights KANs' usage for three aspects of scientific discovery: identifying relevant features, revealing modular structures, and discovering symbolic formulas.","The synergy is bidirectional: science to KAN (incorporating scientific knowledge into KANs), and KAN to science (extracting scientific insights from KANs).","We highlight major new functionalities in the pykan package: (1) MultKAN: KANs with multiplication nodes.","(2) kanpiler: a KAN compiler that compiles symbolic formulas into KANs.","(3) tree converter: convert KANs (or any neural networks) to tree graphs.","Based on these tools, we demonstrate KANs' capability to discover various types of physical laws, including conserved quantities, Lagrangians, symmetries, and constitutive laws."],"url":"http://arxiv.org/abs/2408.10205v1"}
{"created":"2024-08-19 17:58:03","title":"Criticality Leveraged Adversarial Training (CLAT) for Boosted Performance via Parameter Efficiency","abstract":"Adversarial training enhances neural network robustness but suffers from a tendency to overfit and increased generalization errors on clean data. This work introduces CLAT, an innovative approach that mitigates adversarial overfitting by introducing parameter efficiency into the adversarial training process, improving both clean accuracy and adversarial robustness. Instead of tuning the entire model, CLAT identifies and fine-tunes robustness-critical layers - those predominantly learning non-robust features - while freezing the remaining model to enhance robustness. It employs dynamic critical layer selection to adapt to changes in layer criticality throughout the fine-tuning process. Empirically, CLAT can be applied on top of existing adversarial training methods, significantly reduces the number of trainable parameters by approximately 95%, and achieves more than a 2% improvement in adversarial robustness compared to baseline methods.","sentences":["Adversarial training enhances neural network robustness but suffers from a tendency to overfit and increased generalization errors on clean data.","This work introduces CLAT, an innovative approach that mitigates adversarial overfitting by introducing parameter efficiency into the adversarial training process, improving both clean accuracy and adversarial robustness.","Instead of tuning the entire model, CLAT identifies and fine-tunes robustness-critical layers - those predominantly learning non-robust features - while freezing the remaining model to enhance robustness.","It employs dynamic critical layer selection to adapt to changes in layer criticality throughout the fine-tuning process.","Empirically, CLAT can be applied on top of existing adversarial training methods, significantly reduces the number of trainable parameters by approximately 95%, and achieves more than a 2% improvement in adversarial robustness compared to baseline methods."],"url":"http://arxiv.org/abs/2408.10204v1"}
{"created":"2024-08-19 17:57:28","title":"SANER: Annotation-free Societal Attribute Neutralizer for Debiasing CLIP","abstract":"Large-scale vision-language models, such as CLIP, are known to contain harmful societal bias regarding protected attributes (e.g., gender and age). In this paper, we aim to address the problems of societal bias in CLIP. Although previous studies have proposed to debias societal bias through adversarial learning or test-time projecting, our comprehensive study of these works identifies two critical limitations: 1) loss of attribute information when it is explicitly disclosed in the input and 2) use of the attribute annotations during debiasing process. To mitigate societal bias in CLIP and overcome these limitations simultaneously, we introduce a simple-yet-effective debiasing method called SANER (societal attribute neutralizer) that eliminates attribute information from CLIP text features only of attribute-neutral descriptions. Experimental results show that SANER, which does not require attribute annotations and preserves original information for attribute-specific descriptions, demonstrates superior debiasing ability than the existing methods.","sentences":["Large-scale vision-language models, such as CLIP, are known to contain harmful societal bias regarding protected attributes (e.g., gender and age).","In this paper, we aim to address the problems of societal bias in CLIP.","Although previous studies have proposed to debias societal bias through adversarial learning or test-time projecting, our comprehensive study of these works identifies two critical limitations: 1) loss of attribute information when it is explicitly disclosed in the input and 2) use of the attribute annotations during debiasing process.","To mitigate societal bias in CLIP and overcome these limitations simultaneously, we introduce a simple-yet-effective debiasing method called SANER (societal attribute neutralizer) that eliminates attribute information from CLIP text features only of attribute-neutral descriptions.","Experimental results show that SANER, which does not require attribute annotations and preserves original information for attribute-specific descriptions, demonstrates superior debiasing ability than the existing methods."],"url":"http://arxiv.org/abs/2408.10202v1"}
{"created":"2024-08-19 17:57:01","title":"SoK: Runtime Integrity","abstract":"This paper provides a systematic exploration of runtime integrity mechanisms, such as Control Flow Integrity (CFI) and Control Flow Attestation (CFA). It examines their differences and relationships while addressing crucial questions about the goals, assumptions, features, and design spaces. It includes examining a potential coexistence of CFI and CFA on the same platform. Through a comprehensive review of existing defenses, this paper positions CFI and CFA within the broader landscape of runtime defenses, critically evaluating their strengths, limitations, and trade-offs. The findings emphasize the importance of further research to bridge the gaps between CFI and CFA, advancing the field of runtime defenses.","sentences":["This paper provides a systematic exploration of runtime integrity mechanisms, such as Control Flow Integrity (CFI) and Control Flow Attestation (CFA).","It examines their differences and relationships while addressing crucial questions about the goals, assumptions, features, and design spaces.","It includes examining a potential coexistence of CFI and CFA on the same platform.","Through a comprehensive review of existing defenses, this paper positions CFI and CFA within the broader landscape of runtime defenses, critically evaluating their strengths, limitations, and trade-offs.","The findings emphasize the importance of further research to bridge the gaps between CFI and CFA, advancing the field of runtime defenses."],"url":"http://arxiv.org/abs/2408.10200v1"}
{"created":"2024-08-19 17:55:17","title":"MeshFormer: High-Quality Mesh Generation with 3D-Guided Reconstruction Model","abstract":"Open-world 3D reconstruction models have recently garnered significant attention. However, without sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to extract high-quality 3D meshes. In this work, we introduce MeshFormer, a sparse-view reconstruction model that explicitly leverages 3D native structure, input guidance, and training supervision. Specifically, instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers with 3D convolutions to leverage an explicit 3D structure and projective bias. In addition to sparse-view RGB input, we require the network to take input and generate corresponding normal maps. The input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and refinement of the geometry's learning. Moreover, by combining Signed Distance Function (SDF) supervision with surface rendering, we directly learn to generate high-quality meshes without the need for complex multi-stage training processes. By incorporating these explicit 3D biases, MeshFormer can be trained efficiently and deliver high-quality textured meshes with fine-grained geometric details. It can also be integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks. Project page: https://meshformer3d.github.io","sentences":["Open-world 3D reconstruction models have recently garnered significant attention.","However, without sufficient 3D inductive bias, existing methods typically entail expensive training costs and struggle to extract high-quality 3D meshes.","In this work, we introduce MeshFormer, a sparse-view reconstruction model that explicitly leverages 3D native structure, input guidance, and training supervision.","Specifically, instead of using a triplane representation, we store features in 3D sparse voxels and combine transformers with 3D convolutions to leverage an explicit 3D structure and projective bias.","In addition to sparse-view RGB input, we require the network to take input and generate corresponding normal maps.","The input normal maps can be predicted by 2D diffusion models, significantly aiding in the guidance and refinement of the geometry's learning.","Moreover, by combining Signed Distance Function (SDF) supervision with surface rendering, we directly learn to generate high-quality meshes without the need for complex multi-stage training processes.","By incorporating these explicit 3D biases, MeshFormer can be trained efficiently and deliver high-quality textured meshes with fine-grained geometric details.","It can also be integrated with 2D diffusion models to enable fast single-image-to-3D and text-to-3D tasks.","Project page: https://meshformer3d.github.io"],"url":"http://arxiv.org/abs/2408.10198v1"}
{"created":"2024-08-19 17:54:29","title":"Demystifying the Communication Characteristics for Distributed Transformer Models","abstract":"Deep learning (DL) models based on the transformer architecture have revolutionized many DL applications such as large language models (LLMs), vision transformers, audio generation, and time series prediction. Much of this progress has been fueled by distributed training, yet distributed communication remains a substantial bottleneck to training progress. This paper examines the communication behavior of transformer models - that is, how different parallelism schemes used in multi-node/multi-GPU DL Training communicate data in the context of transformers. We use GPT-based language models as a case study of the transformer architecture due to their ubiquity. We validate the empirical results obtained from our communication logs using analytical models. At a high level, our analysis reveals a need to optimize small message point-to-point communication further, correlations between sequence length, per-GPU throughput, model size, and optimizations used, and where to potentially guide further optimizations in framework and HPC middleware design and optimization.","sentences":["Deep learning (DL) models based on the transformer architecture have revolutionized many DL applications such as large language models (LLMs), vision transformers, audio generation, and time series prediction.","Much of this progress has been fueled by distributed training, yet distributed communication remains a substantial bottleneck to training progress.","This paper examines the communication behavior of transformer models - that is, how different parallelism schemes used in multi-node/multi-GPU DL Training communicate data in the context of transformers.","We use GPT-based language models as a case study of the transformer architecture due to their ubiquity.","We validate the empirical results obtained from our communication logs using analytical models.","At a high level, our analysis reveals a need to optimize small message point-to-point communication further, correlations between sequence length, per-GPU throughput, model size, and optimizations used, and where to potentially guide further optimizations in framework and HPC middleware design and optimization."],"url":"http://arxiv.org/abs/2408.10197v1"}
{"created":"2024-08-19 17:53:10","title":"SpaRP: Fast 3D Object Reconstruction and Pose Estimation from Sparse Views","abstract":"Open-world 3D generation has recently attracted considerable attention. While many single-image-to-3D methods have yielded visually appealing outcomes, they often lack sufficient controllability and tend to produce hallucinated regions that may not align with users' expectations. In this paper, we explore an important scenario in which the input consists of one or a few unposed 2D images of a single object, with little or no overlap. We propose a novel method, SpaRP, to reconstruct a 3D textured mesh and estimate the relative camera poses for these sparse-view images. SpaRP distills knowledge from 2D diffusion models and finetunes them to implicitly deduce the 3D spatial relationships between the sparse views. The diffusion model is trained to jointly predict surrogate representations for camera poses and multi-view images of the object under known poses, integrating all information from the input sparse views. These predictions are then leveraged to accomplish 3D reconstruction and pose estimation, and the reconstructed 3D model can be used to further refine the camera poses of input views. Through extensive experiments on three datasets, we demonstrate that our method not only significantly outperforms baseline methods in terms of 3D reconstruction quality and pose prediction accuracy but also exhibits strong efficiency. It requires only about 20 seconds to produce a textured mesh and camera poses for the input views. Project page: https://chaoxu.xyz/sparp.","sentences":["Open-world 3D generation has recently attracted considerable attention.","While many single-image-to-3D methods have yielded visually appealing outcomes, they often lack sufficient controllability and tend to produce hallucinated regions that may not align with users' expectations.","In this paper, we explore an important scenario in which the input consists of one or a few unposed 2D images of a single object, with little or no overlap.","We propose a novel method, SpaRP, to reconstruct a 3D textured mesh and estimate the relative camera poses for these sparse-view images.","SpaRP distills knowledge from 2D diffusion models and finetunes them to implicitly deduce the 3D spatial relationships between the sparse views.","The diffusion model is trained to jointly predict surrogate representations for camera poses and multi-view images of the object under known poses, integrating all information from the input sparse views.","These predictions are then leveraged to accomplish 3D reconstruction and pose estimation, and the reconstructed 3D model can be used to further refine the camera poses of input views.","Through extensive experiments on three datasets, we demonstrate that our method not only significantly outperforms baseline methods in terms of 3D reconstruction quality and pose prediction accuracy but also exhibits strong efficiency.","It requires only about 20 seconds to produce a textured mesh and camera poses for the input views.","Project page: https://chaoxu.xyz/sparp."],"url":"http://arxiv.org/abs/2408.10195v1"}
{"created":"2024-08-19 17:52:00","title":"A Biologically Inspired Design Principle for Building Robust Robotic Systems","abstract":"Robustness, the ability of a system to maintain performance under significant and unanticipated environmental changes, is a critical property for robotic systems. While biological systems naturally exhibit robustness, there is no comprehensive understanding of how to achieve similar robustness in robotic systems. In this work, we draw inspirations from biological systems and propose a design principle that advocates active interconnections among system components to enhance robustness to environmental variations. We evaluate this design principle in a challenging long-horizon manipulation task: solving lockboxes. Our extensive simulated and real-world experiments demonstrate that we could enhance robustness against environmental changes by establishing active interconnections among system components without substantial changes in individual components. Our findings suggest that a systematic investigation of design principles in system building is necessary. It also advocates for interdisciplinary collaborations to explore and evaluate additional principles of biological robustness to advance the development of intelligent and adaptable robotic systems.","sentences":["Robustness, the ability of a system to maintain performance under significant and unanticipated environmental changes, is a critical property for robotic systems.","While biological systems naturally exhibit robustness, there is no comprehensive understanding of how to achieve similar robustness in robotic systems.","In this work, we draw inspirations from biological systems and propose a design principle that advocates active interconnections among system components to enhance robustness to environmental variations.","We evaluate this design principle in a challenging long-horizon manipulation task: solving lockboxes.","Our extensive simulated and real-world experiments demonstrate that we could enhance robustness against environmental changes by establishing active interconnections among system components without substantial changes in individual components.","Our findings suggest that a systematic investigation of design principles in system building is necessary.","It also advocates for interdisciplinary collaborations to explore and evaluate additional principles of biological robustness to advance the development of intelligent and adaptable robotic systems."],"url":"http://arxiv.org/abs/2408.10192v1"}
{"created":"2024-08-19 17:51:00","title":"A Graph-based Approach to Human Activity Recognition","abstract":"Advanced wearable sensor devices have enabled the recording of vast amounts of movement data from individuals regarding their physical activities. This data offers valuable insights that enhance our understanding of how physical activities contribute to improved physical health and overall quality of life. Consequently, there is a growing need for efficient methods to extract significant insights from these rapidly expanding real-time datasets. This paper presents a methodology to efficiently extract substantial insights from these expanding datasets, focusing on professional sports but applicable to various human activities. By utilizing data from Inertial Measurement Units (IMU) and Global Navigation Satellite Systems (GNSS) receivers, athletic performance can be analyzed using directed graphs to encode knowledge of complex movements. Our approach is demonstrated on biathlon data and detects specific points of interest and complex movement sequences, facilitating the comparison and analysis of human physical performance.","sentences":["Advanced wearable sensor devices have enabled the recording of vast amounts of movement data from individuals regarding their physical activities.","This data offers valuable insights that enhance our understanding of how physical activities contribute to improved physical health and overall quality of life.","Consequently, there is a growing need for efficient methods to extract significant insights from these rapidly expanding real-time datasets.","This paper presents a methodology to efficiently extract substantial insights from these expanding datasets, focusing on professional sports but applicable to various human activities.","By utilizing data from Inertial Measurement Units (IMU) and Global Navigation Satellite Systems (GNSS) receivers, athletic performance can be analyzed using directed graphs to encode knowledge of complex movements.","Our approach is demonstrated on biathlon data and detects specific points of interest and complex movement sequences, facilitating the comparison and analysis of human physical performance."],"url":"http://arxiv.org/abs/2408.10191v1"}
{"created":"2024-08-19 17:48:11","title":"Transformers to SSMs: Distilling Quadratic Knowledge to Subquadratic Models","abstract":"Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention. Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models. In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs). The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences. We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions. Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens. Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models. MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models.","sentences":["Transformer architectures have become a dominant paradigm for domains like language modeling but suffer in many inference settings due to their quadratic-time self-attention.","Recently proposed subquadratic architectures, such as Mamba, have shown promise, but have been pretrained with substantially less computational resources than the strongest Transformer models.","In this work, we present a method that is able to distill a pretrained Transformer architecture into alternative architectures such as state space models (SSMs).","The key idea to our approach is that we can view both Transformers and SSMs as applying different forms of mixing matrices over the token sequences.","We can thus progressively distill the Transformer architecture by matching different degrees of granularity in the SSM: first matching the mixing matrices themselves, then the hidden units at each block, and finally the end-to-end predictions.","Our method, called MOHAWK, is able to distill a Mamba-2 variant based on the Phi-1.5 architecture (Phi-Mamba) using only 3B tokens and a hybrid version (Hybrid Phi-Mamba) using 5B tokens.","Despite using less than 1% of the training data typically used to train models from scratch, Phi-Mamba boasts substantially stronger performance compared to all past open-source non-Transformer models.","MOHAWK allows models like SSMs to leverage computational resources invested in training Transformer-based architectures, highlighting a new avenue for building such models."],"url":"http://arxiv.org/abs/2408.10189v1"}
{"created":"2024-08-19 17:48:08","title":"LongVILA: Scaling Long-Context Visual Language Models for Long Videos","abstract":"Long-context capability is critical for multi-modal foundation models. We introduce LongVILA, a full-stack solution for long-context vision-language models, including system, model training, and dataset development. On the system side, we introduce the first Multi-Modal Sequence Parallelism (MM-SP) system that enables long-context training and inference, enabling 2M context length training on 256 GPUs. MM-SP is also efficient, being 2.1x - 5.7x faster than Ring-Style Sequence Parallelism and 1.1x - 1.4x faster than Megatron-LM in text-only settings. Moreover, it seamlessly integrates with Hugging Face Transformers. For model training, we propose a five-stage pipeline comprising alignment, pre-training, context extension, and long-short joint supervised fine-tuning. Regarding datasets, we meticulously construct large-scale visual language pre-training datasets and long video instruction-following datasets to support our multi-stage training process. The full-stack solution extends the feasible frame number of VILA by a factor of 128 (from 8 to 1024 frames) and improves long video captioning score from 2.00 to 3.26 (1.6x), achieving 99.5% accuracy in 1400-frames video (274k context length) needle in a haystack. LongVILA-8B also demonstrates a consistent improvement in performance on long videos within the VideoMME benchmark as the video frames increase.","sentences":["Long-context capability is critical for multi-modal foundation models.","We introduce LongVILA, a full-stack solution for long-context vision-language models, including system, model training, and dataset development.","On the system side, we introduce the first Multi-Modal Sequence Parallelism (MM-SP) system that enables long-context training and inference, enabling 2M context length training on 256 GPUs.","MM-SP is also efficient, being 2.1x - 5.7x faster than Ring-Style Sequence Parallelism and 1.1x - 1.4x faster than Megatron-LM in text-only settings.","Moreover, it seamlessly integrates with Hugging Face Transformers.","For model training, we propose a five-stage pipeline comprising alignment, pre-training, context extension, and long-short joint supervised fine-tuning.","Regarding datasets, we meticulously construct large-scale visual language pre-training datasets and long video instruction-following datasets to support our multi-stage training process.","The full-stack solution extends the feasible frame number of VILA by a factor of 128 (from 8 to 1024 frames) and improves long video captioning score from 2.00 to 3.26 (1.6x), achieving 99.5% accuracy in 1400-frames video (274k context length) needle in a haystack.","LongVILA-8B also demonstrates a consistent improvement in performance on long videos within the VideoMME benchmark as the video frames increase."],"url":"http://arxiv.org/abs/2408.10188v1"}
{"created":"2024-08-19 17:47:22","title":"Assessment of Spectral based Solutions for the Detection of Floating Marine Debris","abstract":"Typically, the detection of marine debris relies on in-situ campaigns that are characterized by huge human effort and limited spatial coverage. Following the need of a rapid solution for the detection of floating plastic, methods based on remote sensing data have been proposed recently. Their main limitation is represented by the lack of a general reference for evaluating performance. Recently, the Marine Debris Archive (MARIDA) has been released as a standard dataset to develop and evaluate Machine Learning (ML) algorithms for detection of Marine Plastic Debris. The MARIDA dataset has been created for simplifying the comparison between detection solutions with the aim of stimulating the research in the field of marine environment preservation. In this work, an assessment of spectral based solutions is proposed by evaluating performance on MARIDA dataset. The outcome highlights the need of precise reference for fair evaluation.","sentences":["Typically, the detection of marine debris relies on in-situ campaigns that are characterized by huge human effort and limited spatial coverage.","Following the need of a rapid solution for the detection of floating plastic, methods based on remote sensing data have been proposed recently.","Their main limitation is represented by the lack of a general reference for evaluating performance.","Recently, the Marine Debris Archive (MARIDA) has been released as a standard dataset to develop and evaluate Machine Learning (ML) algorithms for detection of Marine Plastic Debris.","The MARIDA dataset has been created for simplifying the comparison between detection solutions with the aim of stimulating the research in the field of marine environment preservation.","In this work, an assessment of spectral based solutions is proposed by evaluating performance on MARIDA dataset.","The outcome highlights the need of precise reference for fair evaluation."],"url":"http://arxiv.org/abs/2408.10187v1"}
{"created":"2024-08-19 17:40:18","title":"Imbalance-Aware Culvert-Sewer Defect Segmentation Using an Enhanced Feature Pyramid Network","abstract":"Imbalanced datasets are a significant challenge in real-world scenarios. They lead to models that underperform on underrepresented classes, which is a critical issue in infrastructure inspection. This paper introduces the Enhanced Feature Pyramid Network (E-FPN), a deep learning model for the semantic segmentation of culverts and sewer pipes within imbalanced datasets. The E-FPN incorporates architectural innovations like sparsely connected blocks and depth-wise separable convolutions to improve feature extraction and handle object variations. To address dataset imbalance, the model employs strategies like class decomposition and data augmentation. Experimental results on the culvert-sewer defects dataset and a benchmark aerial semantic segmentation drone dataset show that the E-FPN outperforms state-of-the-art methods, achieving an average Intersection over Union (IoU) improvement of 13.8% and 27.2%, respectively. Additionally, class decomposition and data augmentation together boost the model's performance by approximately 6.9% IoU. The proposed E-FPN presents a promising solution for enhancing object segmentation in challenging, multi-class real-world datasets, with potential applications extending beyond culvert-sewer defect detection.","sentences":["Imbalanced datasets are a significant challenge in real-world scenarios.","They lead to models that underperform on underrepresented classes, which is a critical issue in infrastructure inspection.","This paper introduces the Enhanced Feature Pyramid Network (E-FPN), a deep learning model for the semantic segmentation of culverts and sewer pipes within imbalanced datasets.","The E-FPN incorporates architectural innovations like sparsely connected blocks and depth-wise separable convolutions to improve feature extraction and handle object variations.","To address dataset imbalance, the model employs strategies like class decomposition and data augmentation.","Experimental results on the culvert-sewer defects dataset and a benchmark aerial semantic segmentation drone dataset show that the E-FPN outperforms state-of-the-art methods, achieving an average Intersection over Union (IoU) improvement of 13.8% and 27.2%, respectively.","Additionally, class decomposition and data augmentation together boost the model's performance by approximately 6.9% IoU.","The proposed E-FPN presents a promising solution for enhancing object segmentation in challenging, multi-class real-world datasets, with potential applications extending beyond culvert-sewer defect detection."],"url":"http://arxiv.org/abs/2408.10181v1"}
{"created":"2024-08-19 17:36:35","title":"NeuRodin: A Two-stage Framework for High-Fidelity Neural Surface Reconstruction","abstract":"Signed Distance Function (SDF)-based volume rendering has demonstrated significant capabilities in surface reconstruction. Although promising, SDF-based methods often fail to capture detailed geometric structures, resulting in visible defects. By comparing SDF-based volume rendering to density-based volume rendering, we identify two main factors within the SDF-based approach that degrade surface quality: SDF-to-density representation and geometric regularization. These factors introduce challenges that hinder the optimization of the SDF field. To address these issues, we introduce NeuRodin, a novel two-stage neural surface reconstruction framework that not only achieves high-fidelity surface reconstruction but also retains the flexible optimization characteristics of density-based methods. NeuRodin incorporates innovative strategies that facilitate transformation of arbitrary topologies and reduce artifacts associated with density bias. Extensive evaluations on the Tanks and Temples and ScanNet++ datasets demonstrate the superiority of NeuRodin, showing strong reconstruction capabilities for both indoor and outdoor environments using solely posed RGB captures. Project website: https://open3dvlab.github.io/NeuRodin/","sentences":["Signed Distance Function (SDF)-based volume rendering has demonstrated significant capabilities in surface reconstruction.","Although promising, SDF-based methods often fail to capture detailed geometric structures, resulting in visible defects.","By comparing SDF-based volume rendering to density-based volume rendering, we identify two main factors within the SDF-based approach that degrade surface quality: SDF-to-density representation and geometric regularization.","These factors introduce challenges that hinder the optimization of the SDF field.","To address these issues, we introduce NeuRodin, a novel two-stage neural surface reconstruction framework that not only achieves high-fidelity surface reconstruction but also retains the flexible optimization characteristics of density-based methods.","NeuRodin incorporates innovative strategies that facilitate transformation of arbitrary topologies and reduce artifacts associated with density bias.","Extensive evaluations on the Tanks and Temples and ScanNet++ datasets demonstrate the superiority of NeuRodin, showing strong reconstruction capabilities for both indoor and outdoor environments using solely posed RGB captures.","Project website: https://open3dvlab.github.io/NeuRodin/"],"url":"http://arxiv.org/abs/2408.10178v1"}
{"created":"2024-08-19 17:35:07","title":"Perfectly Undetectable Reflection and Scaling False Data Injection Attacks via Affine Transformation on Mobile Robot Trajectory Tracking Control","abstract":"With the increasing integration of cyber-physical systems (CPS) into critical applications, ensuring their resilience against cyberattacks is paramount. A particularly concerning threat is the vulnerability of CPS to deceptive attacks that degrade system performance while remaining undetected. This paper investigates perfectly undetectable false data injection attacks (FDIAs) targeting the trajectory tracking control of a non-holonomic mobile robot. The proposed attack method utilizes affine transformations of intercepted signals, exploiting weaknesses inherent in the partially linear dynamic properties and symmetry of the nonlinear plant. The feasibility and potential impact of these attacks are validated through experiments using a Turtlebot 3 platform, highlighting the urgent need for sophisticated detection mechanisms and resilient control strategies to safeguard CPS against such threats. Furthermore, a novel approach for detection of these attacks called the state monitoring signature function (SMSF) is introduced. An example SMSF, a carefully designed function resilient to FDIA, is shown to be able to detect the presence of a FDIA through signatures based on systems states.","sentences":["With the increasing integration of cyber-physical systems (CPS) into critical applications, ensuring their resilience against cyberattacks is paramount.","A particularly concerning threat is the vulnerability of CPS to deceptive attacks that degrade system performance while remaining undetected.","This paper investigates perfectly undetectable false data injection attacks (FDIAs) targeting the trajectory tracking control of a non-holonomic mobile robot.","The proposed attack method utilizes affine transformations of intercepted signals, exploiting weaknesses inherent in the partially linear dynamic properties and symmetry of the nonlinear plant.","The feasibility and potential impact of these attacks are validated through experiments using a Turtlebot 3 platform, highlighting the urgent need for sophisticated detection mechanisms and resilient control strategies to safeguard CPS against such threats.","Furthermore, a novel approach for detection of these attacks called the state monitoring signature function (SMSF) is introduced.","An example SMSF, a carefully designed function resilient to FDIA, is shown to be able to detect the presence of a FDIA through signatures based on systems states."],"url":"http://arxiv.org/abs/2408.10177v1"}
{"created":"2024-08-19 17:34:19","title":"Fairness Under Cover: Evaluating the Impact of Occlusions on Demographic Bias in Facial Recognition","abstract":"This study investigates the effects of occlusions on the fairness of face recognition systems, particularly focusing on demographic biases. Using the Racial Faces in the Wild (RFW) dataset and synthetically added realistic occlusions, we evaluate their effect on the performance of face recognition models trained on the BUPT-Balanced and BUPT-GlobalFace datasets. We note increases in the dispersion of FMR, FNMR, and accuracy alongside decreases in fairness according to Equilized Odds, Demographic Parity, STD of Accuracy, and Fairness Discrepancy Rate. Additionally, we utilize a pixel attribution method to understand the importance of occlusions in model predictions, proposing a new metric, Face Occlusion Impact Ratio (FOIR), that quantifies the extent to which occlusions affect model performance across different demographic groups. Our results indicate that occlusions exacerbate existing demographic biases, with models placing higher importance on occlusions in an unequal fashion, particularly affecting African individuals more severely.","sentences":["This study investigates the effects of occlusions on the fairness of face recognition systems, particularly focusing on demographic biases.","Using the Racial Faces in the Wild (RFW) dataset and synthetically added realistic occlusions, we evaluate their effect on the performance of face recognition models trained on the BUPT-Balanced and BUPT-GlobalFace datasets.","We note increases in the dispersion of FMR, FNMR, and accuracy alongside decreases in fairness according to Equilized Odds, Demographic Parity, STD of Accuracy, and Fairness Discrepancy Rate.","Additionally, we utilize a pixel attribution method to understand the importance of occlusions in model predictions, proposing a new metric, Face Occlusion Impact Ratio (FOIR), that quantifies the extent to which occlusions affect model performance across different demographic groups.","Our results indicate that occlusions exacerbate existing demographic biases, with models placing higher importance on occlusions in an unequal fashion, particularly affecting African individuals more severely."],"url":"http://arxiv.org/abs/2408.10175v1"}
{"created":"2024-08-19 17:32:15","title":"SMILE: Zero-Shot Sparse Mixture of Low-Rank Experts Construction From Pre-Trained Foundation Models","abstract":"Deep model training on extensive datasets is increasingly becoming cost-prohibitive, prompting the widespread adoption of deep model fusion techniques to leverage knowledge from pre-existing models. From simple weight averaging to more sophisticated methods like AdaMerging, model fusion effectively improves model performance and accelerates the development of new models. However, potential interference between parameters of individual models and the lack of interpretability in the fusion progress remain significant challenges. Existing methods often try to resolve the parameter interference issue by evaluating attributes of parameters, such as their magnitude or sign, or by parameter pruning. In this study, we begin by examining the fine-tuning of linear layers through the lens of subspace analysis and explicitly define parameter interference as an optimization problem to shed light on this subject. Subsequently, we introduce an innovative approach to model fusion called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which allows for the upscaling of source models into an MoE model without extra data or further training. Our approach relies on the observation that fine-tuning mostly keeps the important parts from the pre-training, but it uses less significant or unused areas to adapt to new tasks. Also, the issue of parameter interference, which is intrinsically intractable in the original parameter space, can be managed by expanding the dimensions. We conduct extensive experiments across diverse scenarios, such as image classification and text generalization tasks, using full fine-tuning and LoRA fine-tuning, and we apply our method to large language models (CLIP models, Flan-T5 models, and Mistral-7B models), highlighting the adaptability and scalability of SMILE. Code is available at https://github.com/tanganke/fusion_bench","sentences":["Deep model training on extensive datasets is increasingly becoming cost-prohibitive, prompting the widespread adoption of deep model fusion techniques to leverage knowledge from pre-existing models.","From simple weight averaging to more sophisticated methods like AdaMerging, model fusion effectively improves model performance and accelerates the development of new models.","However, potential interference between parameters of individual models and the lack of interpretability in the fusion progress remain significant challenges.","Existing methods often try to resolve the parameter interference issue by evaluating attributes of parameters, such as their magnitude or sign, or by parameter pruning.","In this study, we begin by examining the fine-tuning of linear layers through the lens of subspace analysis and explicitly define parameter interference as an optimization problem to shed light on this subject.","Subsequently, we introduce an innovative approach to model fusion called zero-shot Sparse MIxture of Low-rank Experts (SMILE) construction, which allows for the upscaling of source models into an MoE model without extra data or further training.","Our approach relies on the observation that fine-tuning mostly keeps the important parts from the pre-training, but it uses less significant or unused areas to adapt to new tasks.","Also, the issue of parameter interference, which is intrinsically intractable in the original parameter space, can be managed by expanding the dimensions.","We conduct extensive experiments across diverse scenarios, such as image classification and text generalization tasks, using full fine-tuning and LoRA fine-tuning, and we apply our method to large language models (CLIP models, Flan-T5 models, and Mistral-7B models), highlighting the adaptability and scalability of SMILE.","Code is available at https://github.com/tanganke/fusion_bench"],"url":"http://arxiv.org/abs/2408.10174v1"}
{"created":"2024-08-19 17:26:59","title":"Eulerian Graph Sparsification by Effective Resistance Decomposition","abstract":"We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\\breve{O}(n\\log^{2} n \\cdot \\varepsilon^{-2})$-edge $\\varepsilon$-approximate Eulerian sparsifier with high probability in $\\breve{O}(m\\log^3 n)$ time (where $\\breve{O}(\\cdot)$ hides $\\text{polyloglog}(n)$ factors). Due to a reduction from [Peng-Song, STOC '22], this yields an $\\breve{O}(m\\log^3 n + n\\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\\Omega(m\\log^8 n + n\\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\\min(n\\log n \\cdot \\varepsilon^{-2} + n\\log^{5/3} n \\cdot \\varepsilon^{-4/3}, n\\log^{3/2} n \\cdot \\varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\\log^2 n \\cdot \\varepsilon^{-2} + n\\log^{8/3} n \\cdot \\varepsilon^{-4/3})$ [Sachdeva-Thudi-Zhao, ICALP '24]. Finally, we show that our techniques extend to yield the first $O(m\\cdot\\text{polylog}(n))$ time algorithm for computing $O(n\\varepsilon^{-1}\\cdot\\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce.   In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce. Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions. Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory.","sentences":["We provide an algorithm that, given an $n$-vertex $m$-edge Eulerian graph with polynomially bounded weights, computes an $\\breve{O}(n\\log^{2} n \\cdot \\varepsilon^{-2})$-edge $\\varepsilon$-approximate Eulerian sparsifier with high probability in $\\breve{O}(m\\log^3 n)$ time (where $\\breve{O}(\\cdot)$ hides $\\text{polyloglog}(n)$ factors).","Due to a reduction from [Peng-Song, STOC '22], this yields an $\\breve{O}(m\\log^3 n + n\\log^6 n)$-time algorithm for solving $n$-vertex $m$-edge Eulerian Laplacian systems with polynomially-bounded weights with high probability, improving upon the previous state-of-the-art runtime of $\\Omega(m\\log^8 n + n\\log^{23} n)$. We also give a polynomial-time algorithm that computes $O(\\min(n\\log n \\cdot \\varepsilon^{-2} + n\\log^{5/3} n \\cdot \\varepsilon^{-4/3}, n\\log^{3/2} n \\cdot \\varepsilon^{-2}))$-edge sparsifiers, improving the best such sparsity bound of $O(n\\log^2 n \\cdot \\varepsilon^{-2} + n\\log^{8/3} n \\cdot \\varepsilon^{-4/3})$","[Sachdeva-Thudi-Zhao, ICALP '24].","Finally, we show that our techniques extend to yield the first $O(m\\cdot\\text{polylog}(n))$ time algorithm for computing $O(n\\varepsilon^{-1}\\cdot\\text{polylog}(n))$-edge graphical spectral sketches, as well as a natural Eulerian generalization we introduce.   ","In contrast to prior Eulerian graph sparsification algorithms which used either short cycle or expander decompositions, our algorithms use a simple efficient effective resistance decomposition scheme we introduce.","Our algorithms apply a natural sampling scheme and electrical routing (to achieve degree balance) to such decompositions.","Our analysis leverages new asymmetric variance bounds specialized to Eulerian Laplacians and tools from discrepancy theory."],"url":"http://arxiv.org/abs/2408.10172v1"}
{"created":"2024-08-19 17:24:44","title":"LCDN: Providing Network Determinism with Low-Cost Switches","abstract":"The demands on networks are increasing on a fast pace. In particular, real-time applications have very strict network requirements. However, building a network capable of hosting real-time applications is a cost-intensive endeavor, especially for experimental systems such as testbeds. Systems that provide guaranteed real-time networking capabilities usually work with expensive software-defined switches. In contrast, real-time networking systems based on cheaper hardware face the limitation of lower link speeds. Therefore, this paper fills this gap and presents Low-Cost Deterministic Networking (LCDN), a system that is designed to work with cheap common off-the-shelf switches and devices. LCDN works at Gigabit speed and enables powerful testbeds that can host real-time applications with hard delay guarantees. This paper also provides the evaluation of the determinism of the used switch as well as a Raspberry Pi used as an end device.","sentences":["The demands on networks are increasing on a fast pace.","In particular, real-time applications have very strict network requirements.","However, building a network capable of hosting real-time applications is a cost-intensive endeavor, especially for experimental systems such as testbeds.","Systems that provide guaranteed real-time networking capabilities usually work with expensive software-defined switches.","In contrast, real-time networking systems based on cheaper hardware face the limitation of lower link speeds.","Therefore, this paper fills this gap and presents Low-Cost Deterministic Networking (LCDN), a system that is designed to work with cheap common off-the-shelf switches and devices.","LCDN works at Gigabit speed and enables powerful testbeds that can host real-time applications with hard delay guarantees.","This paper also provides the evaluation of the determinism of the used switch as well as a Raspberry Pi used as an end device."],"url":"http://arxiv.org/abs/2408.10171v1"}
{"created":"2024-08-19 17:21:35","title":"Don't Get Stuck: A Deadlock Recovery Approach","abstract":"When multiple agents share space, interactions can lead to deadlocks, where no agent can advance towards its goal. This paper addresses this challenge with a deadlock recovery strategy. In particular, the proposed algorithm integrates hybrid-A$^\\star$, STL, and MPPI frameworks. Specifically, hybrid-A$^\\star$ generates a reference path, STL defines a goal (deadlock avoidance) and associated constraints (w.r.t. traffic rules), and MPPI refines the path and speed accordingly. This STL-MPPI framework ensures system compliance to specifications and dynamics while ensuring the safety of the resulting maneuvers, indicating a strong potential for application to complex traffic scenarios (and rules) in practice. Validation studies are conducted in simulations and on scaled cars, respectively, to demonstrate the effectiveness of the proposed algorithm.","sentences":["When multiple agents share space, interactions can lead to deadlocks, where no agent can advance towards its goal.","This paper addresses this challenge with a deadlock recovery strategy.","In particular, the proposed algorithm integrates hybrid-A$^\\star$, STL, and MPPI frameworks.","Specifically, hybrid-A$^\\star$ generates a reference path, STL defines a goal (deadlock avoidance) and associated constraints (w.r.t. traffic rules), and MPPI refines the path and speed accordingly.","This STL-MPPI framework ensures system compliance to specifications and dynamics while ensuring the safety of the resulting maneuvers, indicating a strong potential for application to complex traffic scenarios (and rules) in practice.","Validation studies are conducted in simulations and on scaled cars, respectively, to demonstrate the effectiveness of the proposed algorithm."],"url":"http://arxiv.org/abs/2408.10167v1"}
{"created":"2024-08-19 17:16:59","title":"Towards UAV-USV Collaboration in Harsh Maritime Conditions Including Large Waves","abstract":"This paper introduces a system designed for tight collaboration between Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) in harsh maritime conditions characterized by large waves. This onboard UAV system aims to enhance collaboration with USVs for following and landing tasks under such challenging conditions. The main contribution of our system is the novel mathematical USV model, describing the movement of the USV in 6 degrees of freedom on a wavy water surface, which is used to estimate and predict USV states. The estimator fuses data from multiple global and onboard sensors, ensuring accurate USV state estimation. The predictor computes future USV states using the novel mathematical USV model and the last estimated states. The estimated and predicted USV states are forwarded into a trajectory planner that generates a UAV trajectory for following the USV or landing on its deck, even in harsh environmental conditions. The proposed approach was verified in numerous simulations and deployed to the real world, where the UAV was able to follow the USV and land on its deck repeatedly.","sentences":["This paper introduces a system designed for tight collaboration between Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) in harsh maritime conditions characterized by large waves.","This onboard UAV system aims to enhance collaboration with USVs for following and landing tasks under such challenging conditions.","The main contribution of our system is the novel mathematical USV model, describing the movement of the USV in 6 degrees of freedom on a wavy water surface, which is used to estimate and predict USV states.","The estimator fuses data from multiple global and onboard sensors, ensuring accurate USV state estimation.","The predictor computes future USV states using the novel mathematical USV model and the last estimated states.","The estimated and predicted USV states are forwarded into a trajectory planner that generates a UAV trajectory for following the USV or landing on its deck, even in harsh environmental conditions.","The proposed approach was verified in numerous simulations and deployed to the real world, where the UAV was able to follow the USV and land on its deck repeatedly."],"url":"http://arxiv.org/abs/2408.10163v1"}
{"created":"2024-08-19 17:16:35","title":"Physics-Aware Combinatorial Assembly Planning using Deep Reinforcement Learning","abstract":"Combinatorial assembly uses standardized unit primitives to build objects that satisfy user specifications. Lego is a widely used platform for combinatorial assembly, in which people use unit primitives (ie Lego bricks) to build highly customizable 3D objects. This paper studies sequence planning for physical combinatorial assembly using Lego. Given the shape of the desired object, we want to find a sequence of actions for placing Lego bricks to build the target object. In particular, we aim to ensure the planned assembly sequence is physically executable. However, assembly sequence planning (ASP) for combinatorial assembly is particularly challenging due to its combinatorial nature, ie the vast number of possible combinations and complex constraints. To address the challenges, we employ deep reinforcement learning to learn a construction policy for placing unit primitives sequentially to build the desired object. Specifically, we design an online physics-aware action mask that efficiently filters out invalid actions and guides policy learning. In the end, we demonstrate that the proposed method successfully plans physically valid assembly sequences for constructing different Lego structures. The generated construction plan can be executed in real.","sentences":["Combinatorial assembly uses standardized unit primitives to build objects that satisfy user specifications.","Lego is a widely used platform for combinatorial assembly, in which people use unit primitives (ie Lego bricks) to build highly customizable 3D objects.","This paper studies sequence planning for physical combinatorial assembly using Lego.","Given the shape of the desired object, we want to find a sequence of actions for placing Lego bricks to build the target object.","In particular, we aim to ensure the planned assembly sequence is physically executable.","However, assembly sequence planning (ASP) for combinatorial assembly is particularly challenging due to its combinatorial nature, ie the vast number of possible combinations and complex constraints.","To address the challenges, we employ deep reinforcement learning to learn a construction policy for placing unit primitives sequentially to build the desired object.","Specifically, we design an online physics-aware action mask that efficiently filters out invalid actions and guides policy learning.","In the end, we demonstrate that the proposed method successfully plans physically valid assembly sequences for constructing different Lego structures.","The generated construction plan can be executed in real."],"url":"http://arxiv.org/abs/2408.10162v1"}
{"created":"2024-08-19 17:13:34","title":"NeuFlow v2: High-Efficiency Optical Flow Estimation on Edge Devices","abstract":"Real-time high-accuracy optical flow estimation is crucial for various real-world applications. While recent learning-based optical flow methods have achieved high accuracy, they often come with significant computational costs. In this paper, we propose a highly efficient optical flow method that balances high accuracy with reduced computational demands. Building upon NeuFlow v1, we introduce new components including a much more light-weight backbone and a fast refinement module. Both these modules help in keeping the computational demands light while providing close to state of the art accuracy. Compares to other state of the art methods, our model achieves a 10x-70x speedup while maintaining comparable performance on both synthetic and real-world data. It is capable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin Nano. The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow_v2.","sentences":["Real-time high-accuracy optical flow estimation is crucial for various real-world applications.","While recent learning-based optical flow methods have achieved high accuracy, they often come with significant computational costs.","In this paper, we propose a highly efficient optical flow method that balances high accuracy with reduced computational demands.","Building upon NeuFlow v1, we introduce new components including a much more light-weight backbone and a fast refinement module.","Both these modules help in keeping the computational demands light while providing close to state of the art accuracy.","Compares to other state of the art methods, our model achieves a 10x-70x speedup while maintaining comparable performance on both synthetic and real-world data.","It is capable of running at over 20 FPS on 512x384 resolution images on a Jetson Orin Nano.","The full training and evaluation code is available at https://github.com/neufieldrobotics/NeuFlow_v2."],"url":"http://arxiv.org/abs/2408.10161v1"}
{"created":"2024-08-19 17:09:32","title":"Customizing Language Models with Instance-wise LoRA for Sequential Recommendation","abstract":"Sequential recommendation systems predict a user's next item of interest by analyzing past interactions, aligning recommendations with individual preferences. Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches have applied LLMs to sequential recommendation through language generation paradigms. These methods convert user behavior sequences into prompts for LLM fine-tuning, utilizing Low-Rank Adaptation (LoRA) modules to refine recommendations. However, the uniform application of LoRA across diverse user behaviors sometimes fails to capture individual variability, leading to suboptimal performance and negative transfer between disparate sequences. To address these challenges, we propose Instance-wise LoRA (iLoRA), integrating LoRA with the Mixture of Experts (MoE) framework. iLoRA creates a diverse array of experts, each capturing specific aspects of user preferences, and introduces a sequence representation guided gate function. This gate function processes historical interaction sequences to generate enriched representations, guiding the gating network to output customized expert participation weights. This tailored approach mitigates negative transfer and dynamically adjusts to diverse behavior patterns. Extensive experiments on three benchmark datasets demonstrate the effectiveness of iLoRA, highlighting its superior performance compared to existing methods in capturing user-specific preferences and improving recommendation accuracy.","sentences":["Sequential recommendation systems predict a user's next item of interest by analyzing past interactions, aligning recommendations with individual preferences.","Leveraging the strengths of Large Language Models (LLMs) in knowledge comprehension and reasoning, recent approaches have applied LLMs to sequential recommendation through language generation paradigms.","These methods convert user behavior sequences into prompts for LLM fine-tuning, utilizing Low-Rank Adaptation (LoRA) modules to refine recommendations.","However, the uniform application of LoRA across diverse user behaviors sometimes fails to capture individual variability, leading to suboptimal performance and negative transfer between disparate sequences.","To address these challenges, we propose Instance-wise LoRA (iLoRA), integrating LoRA with the Mixture of Experts (MoE) framework.","iLoRA creates a diverse array of experts, each capturing specific aspects of user preferences, and introduces a sequence representation guided gate function.","This gate function processes historical interaction sequences to generate enriched representations, guiding the gating network to output customized expert participation weights.","This tailored approach mitigates negative transfer and dynamically adjusts to diverse behavior patterns.","Extensive experiments on three benchmark datasets demonstrate the effectiveness of iLoRA, highlighting its superior performance compared to existing methods in capturing user-specific preferences and improving recommendation accuracy."],"url":"http://arxiv.org/abs/2408.10159v1"}
{"created":"2024-08-19 17:04:18","title":"LoopSplat: Loop Closure by Registering 3D Gaussian Splats","abstract":"Simultaneous Localization and Mapping (SLAM) based on 3D Gaussian Splats (3DGS) has recently shown promise towards more accurate, dense 3D scene maps. However, existing 3DGS-based methods fail to address the global consistency of the scene via loop closure and/or global bundle adjustment. To this end, we propose LoopSplat, which takes RGB-D images as input and performs dense mapping with 3DGS submaps and frame-to-model tracking. LoopSplat triggers loop closure online and computes relative loop edge constraints between submaps directly via 3DGS registration, leading to improvements in efficiency and accuracy over traditional global-to-local point cloud registration. It uses a robust pose graph optimization formulation and rigidly aligns the submaps to achieve global consistency. Evaluation on the synthetic Replica and real-world TUM-RGBD, ScanNet, and ScanNet++ datasets demonstrates competitive or superior tracking, mapping, and rendering compared to existing methods for dense RGB-D SLAM. Code is available at \\href{https://loopsplat.github.io/}{loopsplat.github.io}.","sentences":["Simultaneous Localization and Mapping (SLAM) based on 3D Gaussian Splats (3DGS) has recently shown promise towards more accurate, dense 3D scene maps.","However, existing 3DGS-based methods fail to address the global consistency of the scene via loop closure and/or global bundle adjustment.","To this end, we propose LoopSplat, which takes RGB-D images as input and performs dense mapping with 3DGS submaps and frame-to-model tracking.","LoopSplat triggers loop closure online and computes relative loop edge constraints between submaps directly via 3DGS registration, leading to improvements in efficiency and accuracy over traditional global-to-local point cloud registration.","It uses a robust pose graph optimization formulation and rigidly aligns the submaps to achieve global consistency.","Evaluation on the synthetic Replica and real-world TUM-RGBD, ScanNet, and ScanNet++ datasets demonstrates competitive or superior tracking, mapping, and rendering compared to existing methods for dense RGB-D SLAM.","Code is available at \\href{https://loopsplat.github.io/}{loopsplat.github.io}."],"url":"http://arxiv.org/abs/2408.10154v1"}
{"created":"2024-08-19 17:02:16","title":"Structure-preserving Image Translation for Depth Estimation in Colonoscopy Video","abstract":"Monocular depth estimation in colonoscopy video aims to overcome the unusual lighting properties of the colonoscopic environment. One of the major challenges in this area is the domain gap between annotated but unrealistic synthetic data and unannotated but realistic clinical data. Previous attempts to bridge this domain gap directly target the depth estimation task itself. We propose a general pipeline of structure-preserving synthetic-to-real (sim2real) image translation (producing a modified version of the input image) to retain depth geometry through the translation process. This allows us to generate large quantities of realistic-looking synthetic images for supervised depth estimation with improved generalization to the clinical domain. We also propose a dataset of hand-picked sequences from clinical colonoscopies to improve the image translation process. We demonstrate the simultaneous realism of the translated images and preservation of depth maps via the performance of downstream depth estimation on various datasets.","sentences":["Monocular depth estimation in colonoscopy video aims to overcome the unusual lighting properties of the colonoscopic environment.","One of the major challenges in this area is the domain gap between annotated but unrealistic synthetic data and unannotated but realistic clinical data.","Previous attempts to bridge this domain gap directly target the depth estimation task itself.","We propose a general pipeline of structure-preserving synthetic-to-real (sim2real) image translation (producing a modified version of the input image) to retain depth geometry through the translation process.","This allows us to generate large quantities of realistic-looking synthetic images for supervised depth estimation with improved generalization to the clinical domain.","We also propose a dataset of hand-picked sequences from clinical colonoscopies to improve the image translation process.","We demonstrate the simultaneous realism of the translated images and preservation of depth maps via the performance of downstream depth estimation on various datasets."],"url":"http://arxiv.org/abs/2408.10153v1"}
{"created":"2024-08-19 17:02:06","title":"Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models","abstract":"While recent large language models (LLMs) demonstrate remarkable abilities in responding to queries in diverse languages, their ability to handle long multilingual contexts is unexplored. As such, a systematic evaluation of the long-context capabilities of LLMs in multilingual settings is crucial, specifically in the context of information retrieval. To address this gap, we introduce the MultiLingual Needle-in-a-Haystack (MLNeedle) test, designed to assess a model's ability to retrieve relevant information (the needle) from a collection of multilingual distractor texts (the haystack). This test serves as an extension of the multilingual question-answering task, encompassing both monolingual and cross-lingual retrieval. We evaluate four state-of-the-art LLMs on MLNeedle. Our findings reveal that model performance can vary significantly with language and needle position. Specifically, we observe that model performance is the lowest when the needle is (i) in a language outside the English language family and (ii) located in the middle of the input context. Furthermore, although some models claim a context size of $8k$ tokens or greater, none demonstrate satisfactory cross-lingual retrieval performance as the context length increases. Our analysis provides key insights into the long-context behavior of LLMs in multilingual settings to guide future evaluation protocols. To our knowledge, this is the first study to investigate the multilingual long-context behavior of LLMs.","sentences":["While recent large language models (LLMs) demonstrate remarkable abilities in responding to queries in diverse languages, their ability to handle long multilingual contexts is unexplored.","As such, a systematic evaluation of the long-context capabilities of LLMs in multilingual settings is crucial, specifically in the context of information retrieval.","To address this gap, we introduce the MultiLingual Needle-in-a-Haystack (MLNeedle) test, designed to assess a model's ability to retrieve relevant information (the needle) from a collection of multilingual distractor texts (the haystack).","This test serves as an extension of the multilingual question-answering task, encompassing both monolingual and cross-lingual retrieval.","We evaluate four state-of-the-art LLMs on MLNeedle.","Our findings reveal that model performance can vary significantly with language and needle position.","Specifically, we observe that model performance is the lowest when the needle is (i) in a language outside the English language family and (ii) located in the middle of the input context.","Furthermore, although some models claim a context size of $8k$ tokens or greater, none demonstrate satisfactory cross-lingual retrieval performance as the context length increases.","Our analysis provides key insights into the long-context behavior of LLMs in multilingual settings to guide future evaluation protocols.","To our knowledge, this is the first study to investigate the multilingual long-context behavior of LLMs."],"url":"http://arxiv.org/abs/2408.10151v1"}
{"created":"2024-08-19 17:02:06","title":"Source-Seeking Problem with Robot Swarms","abstract":"We present an algorithm to solve the problem of locating the source, or maxima, of a scalar field using a robot swarm. We demonstrate how the robot swarm determines its direction of movement to approach the source using only field intensity measurements taken by each robot. In contrast with the current literature, our algorithm accommodates a generic (non-degenerate) geometry for the swarm's formation. Additionally, we rigorously show the effectiveness of the algorithm even when the dynamics of the robots are complex, such as a unicycle with constant speed. Not requiring a strict geometry for the swarm significantly enhances its resilience. For example, this allows the swarm to change its size and formation in the presence of obstacles or other real-world factors, including the loss or addition of individuals to the swarm on the fly. For clarity, the article begins by presenting the algorithm for robots with free dynamics. In the second part, we demonstrate the algorithm's effectiveness even considering non-holonomic dynamics for the robots, using the vector field guidance paradigm. Finally, we verify and validate our algorithm with various numerical simulations.","sentences":["We present an algorithm to solve the problem of locating the source, or maxima, of a scalar field using a robot swarm.","We demonstrate how the robot swarm determines its direction of movement to approach the source using only field intensity measurements taken by each robot.","In contrast with the current literature, our algorithm accommodates a generic (non-degenerate) geometry for the swarm's formation.","Additionally, we rigorously show the effectiveness of the algorithm even when the dynamics of the robots are complex, such as a unicycle with constant speed.","Not requiring a strict geometry for the swarm significantly enhances its resilience.","For example, this allows the swarm to change its size and formation in the presence of obstacles or other real-world factors, including the loss or addition of individuals to the swarm on the fly.","For clarity, the article begins by presenting the algorithm for robots with free dynamics.","In the second part, we demonstrate the algorithm's effectiveness even considering non-holonomic dynamics for the robots, using the vector field guidance paradigm.","Finally, we verify and validate our algorithm with various numerical simulations."],"url":"http://arxiv.org/abs/2408.10152v1"}
{"created":"2024-08-19 16:49:19","title":"Auctioning Escape Permits for Multiple Correlated Pollutants Using CMRA","abstract":"In the context of increasingly complex environmental challenges, effective pollution control mechanisms are crucial. By extending the state of the art auction mechanisms, we aim to develop an efficient approach for allocating pollution abatement resources in a multi-pollutant setting with pollutants affecting each other's reduction costs. We modify the Combinatorial Multi-Round Ascending Auction for the auction of escape permits of pollutants with co-dependent reduction processes, specifically, greenhouse gas emissions and nutrient runoff in Finnish agriculture. We show the significant advantages of this mechanism in pollution control through experiments on the bid prices and amount of escape permits sold in multiple auction simulations.","sentences":["In the context of increasingly complex environmental challenges, effective pollution control mechanisms are crucial.","By extending the state of the art auction mechanisms, we aim to develop an efficient approach for allocating pollution abatement resources in a multi-pollutant setting with pollutants affecting each other's reduction costs.","We modify the Combinatorial Multi-Round Ascending Auction for the auction of escape permits of pollutants with co-dependent reduction processes, specifically, greenhouse gas emissions and nutrient runoff in Finnish agriculture.","We show the significant advantages of this mechanism in pollution control through experiments on the bid prices and amount of escape permits sold in multiple auction simulations."],"url":"http://arxiv.org/abs/2408.10148v1"}
{"created":"2024-08-19 16:47:46","title":"In-Context Learning with Representations: Contextual Generalization of Trained Transformers","abstract":"In-context learning (ICL) refers to a remarkable capability of pretrained large language models, which can learn a new task given a few examples during inference. However, theoretical understanding of ICL is largely under-explored, particularly whether transformers can be trained to generalize to unseen examples in a prompt, which will require the model to acquire contextual knowledge of the prompt for generalization. This paper investigates the training dynamics of transformers by gradient descent through the lens of non-linear regression tasks. The contextual generalization here can be attained via learning the template function for each task in-context, where all template functions lie in a linear space with $m$ basis functions. We analyze the training dynamics of one-layer multi-head transformers to in-contextly predict unlabeled inputs given partially labeled prompts, where the labels contain Gaussian noise and the number of examples in each prompt are not sufficient to determine the template. Under mild assumptions, we show that the training loss for a one-layer multi-head transformer converges linearly to a global minimum. Moreover, the transformer effectively learns to perform ridge regression over the basis functions. To our knowledge, this study is the first provable demonstration that transformers can learn contextual (i.e., template) information to generalize to both unseen examples and tasks when prompts contain only a small number of query-answer pairs.","sentences":["In-context learning (ICL) refers to a remarkable capability of pretrained large language models, which can learn a new task given a few examples during inference.","However, theoretical understanding of ICL is largely under-explored, particularly whether transformers can be trained to generalize to unseen examples in a prompt, which will require the model to acquire contextual knowledge of the prompt for generalization.","This paper investigates the training dynamics of transformers by gradient descent through the lens of non-linear regression tasks.","The contextual generalization here can be attained via learning the template function for each task in-context, where all template functions lie in a linear space with $m$ basis functions.","We analyze the training dynamics of one-layer multi-head transformers to in-contextly predict unlabeled inputs given partially labeled prompts, where the labels contain Gaussian noise and the number of examples in each prompt are not sufficient to determine the template.","Under mild assumptions, we show that the training loss for a one-layer multi-head transformer converges linearly to a global minimum.","Moreover, the transformer effectively learns to perform ridge regression over the basis functions.","To our knowledge, this study is the first provable demonstration that transformers can learn contextual (i.e., template) information to generalize to both unseen examples and tasks when prompts contain only a small number of query-answer pairs."],"url":"http://arxiv.org/abs/2408.10147v1"}
{"created":"2024-08-19 16:42:58","title":"Multi-Scale Representation Learning for Image Restoration with State-Space Model","abstract":"Image restoration endeavors to reconstruct a high-quality, detail-rich image from a degraded counterpart, which is a pivotal process in photography and various computer vision systems. In real-world scenarios, different types of degradation can cause the loss of image details at various scales and degrade image contrast. Existing methods predominantly rely on CNN and Transformer to capture multi-scale representations. However, these methods are often limited by the high computational complexity of Transformers and the constrained receptive field of CNN, which hinder them from achieving superior performance and efficiency in image restoration. To address these challenges, we propose a novel Multi-Scale State-Space Model-based (MS-Mamba) for efficient image restoration that enhances the capacity for multi-scale representation learning through our proposed global and regional SSM modules. Additionally, an Adaptive Gradient Block (AGB) and a Residual Fourier Block (RFB) are proposed to improve the network's detail extraction capabilities by capturing gradients in various directions and facilitating learning details in the frequency domain. Extensive experiments on nine public benchmarks across four classic image restoration tasks, image deraining, dehazing, denoising, and low-light enhancement, demonstrate that our proposed method achieves new state-of-the-art performance while maintaining low computational complexity. The source code will be publicly available.","sentences":["Image restoration endeavors to reconstruct a high-quality, detail-rich image from a degraded counterpart, which is a pivotal process in photography and various computer vision systems.","In real-world scenarios, different types of degradation can cause the loss of image details at various scales and degrade image contrast.","Existing methods predominantly rely on CNN and Transformer to capture multi-scale representations.","However, these methods are often limited by the high computational complexity of Transformers and the constrained receptive field of CNN, which hinder them from achieving superior performance and efficiency in image restoration.","To address these challenges, we propose a novel Multi-Scale State-Space Model-based (MS-Mamba) for efficient image restoration that enhances the capacity for multi-scale representation learning through our proposed global and regional SSM modules.","Additionally, an Adaptive Gradient Block (AGB) and a Residual Fourier Block (RFB) are proposed to improve the network's detail extraction capabilities by capturing gradients in various directions and facilitating learning details in the frequency domain.","Extensive experiments on nine public benchmarks across four classic image restoration tasks, image deraining, dehazing, denoising, and low-light enhancement, demonstrate that our proposed method achieves new state-of-the-art performance while maintaining low computational complexity.","The source code will be publicly available."],"url":"http://arxiv.org/abs/2408.10145v1"}
{"created":"2024-08-19 16:42:34","title":"Data-Driven Analysis to Understand GPU Hardware Resource Usage of Optimizations","abstract":"With heterogeneous systems, the number of GPUs per chip increases to provide computational capabilities for solving science at a nanoscopic scale. However, low utilization for single GPUs defies the need to invest more money for expensive ccelerators. While related work develops optimizations for improving application performance, none studies how these optimizations impact hardware resource usage or the average GPU utilization. This paper takes a data-driven analysis approach in addressing this gap by (1) characterizing how hardware resource usage affects device utilization, execution time, or both, (2) presenting a multi-objective metric to identify important application-device interactions that can be optimized to improve device utilization and application performance jointly, (3) studying hardware resource usage behaviors of several optimizations for a benchmark application, and finally (4) identifying optimization opportunities for several scientific proxy applications based on their hardware resource usage behaviors. Furthermore, we demonstrate the applicability of our methodology by applying the identified optimizations to a proxy application, which improves the execution time, device utilization and power consumption by up to 29.6%, 5.3% and 26.5% respectively.","sentences":["With heterogeneous systems, the number of GPUs per chip increases to provide computational capabilities for solving science at a nanoscopic scale.","However, low utilization for single GPUs defies the need to invest more money for expensive ccelerators.","While related work develops optimizations for improving application performance, none studies how these optimizations impact hardware resource usage or the average GPU utilization.","This paper takes a data-driven analysis approach in addressing this gap by (1) characterizing how hardware resource usage affects device utilization, execution time, or both, (2) presenting a multi-objective metric to identify important application-device interactions that can be optimized to improve device utilization and application performance jointly, (3) studying hardware resource usage behaviors of several optimizations for a benchmark application, and finally (4) identifying optimization opportunities for several scientific proxy applications based on their hardware resource usage behaviors.","Furthermore, we demonstrate the applicability of our methodology by applying the identified optimizations to a proxy application, which improves the execution time, device utilization and power consumption by up to 29.6%, 5.3% and 26.5% respectively."],"url":"http://arxiv.org/abs/2408.10143v1"}
{"created":"2024-08-19 16:41:07","title":"Instruction Finetuning for Leaderboard Generation from Empirical AI Research","abstract":"This study demonstrates the application of instruction finetuning of pretrained Large Language Models (LLMs) to automate the generation of AI research leaderboards, extracting (Task, Dataset, Metric, Score) quadruples from articles. It aims to streamline the dissemination of advancements in AI research by transitioning from traditional, manual community curation, or otherwise taxonomy-constrained natural language inference (NLI) models, to an automated, generative LLM-based approach. Utilizing the FLAN-T5 model, this research enhances LLMs' adaptability and reliability in information extraction, offering a novel method for structured knowledge representation.","sentences":["This study demonstrates the application of instruction finetuning of pretrained Large Language Models (LLMs) to automate the generation of AI research leaderboards, extracting (Task, Dataset, Metric, Score) quadruples from articles.","It aims to streamline the dissemination of advancements in AI research by transitioning from traditional, manual community curation, or otherwise taxonomy-constrained natural language inference (NLI) models, to an automated, generative LLM-based approach.","Utilizing the FLAN-T5 model, this research enhances LLMs' adaptability and reliability in information extraction, offering a novel method for structured knowledge representation."],"url":"http://arxiv.org/abs/2408.10141v1"}
{"created":"2024-08-19 16:33:17","title":"$R^2$-Mesh: Reinforcement Learning Powered Mesh Reconstruction via Geometry and Appearance Refinement","abstract":"Mesh reconstruction based on Neural Radiance Fields (NeRF) is popular in a variety of applications such as computer graphics, virtual reality, and medical imaging due to its efficiency in handling complex geometric structures and facilitating real-time rendering. However, existing works often fail to capture fine geometric details accurately and struggle with optimizing rendering quality. To address these challenges, we propose a novel algorithm that progressively generates and optimizes meshes from multi-view images. Our approach initiates with the training of a NeRF model to establish an initial Signed Distance Field (SDF) and a view-dependent appearance field. Subsequently, we iteratively refine the SDF through a differentiable mesh extraction method, continuously updating both the vertex positions and their connectivity based on the loss from mesh differentiable rasterization, while also optimizing the appearance representation. To further leverage high-fidelity and detail-rich representations from NeRF, we propose an online-learning strategy based on Upper Confidence Bound (UCB) to enhance viewpoints by adaptively incorporating images rendered by the initial NeRF model into the training dataset. Through extensive experiments, we demonstrate that our method delivers highly competitive and robust performance in both mesh rendering quality and geometric quality.","sentences":["Mesh reconstruction based on Neural Radiance Fields (NeRF) is popular in a variety of applications such as computer graphics, virtual reality, and medical imaging due to its efficiency in handling complex geometric structures and facilitating real-time rendering.","However, existing works often fail to capture fine geometric details accurately and struggle with optimizing rendering quality.","To address these challenges, we propose a novel algorithm that progressively generates and optimizes meshes from multi-view images.","Our approach initiates with the training of a NeRF model to establish an initial Signed Distance Field (SDF) and a view-dependent appearance field.","Subsequently, we iteratively refine the SDF through a differentiable mesh extraction method, continuously updating both the vertex positions and their connectivity based on the loss from mesh differentiable rasterization, while also optimizing the appearance representation.","To further leverage high-fidelity and detail-rich representations from NeRF, we propose an online-learning strategy based on Upper Confidence Bound (UCB) to enhance viewpoints by adaptively incorporating images rendered by the initial NeRF model into the training dataset.","Through extensive experiments, we demonstrate that our method delivers highly competitive and robust performance in both mesh rendering quality and geometric quality."],"url":"http://arxiv.org/abs/2408.10135v1"}
{"created":"2024-08-19 16:28:05","title":"Perceptual Depth Quality Assessment of Stereoscopic Omnidirectional Images","abstract":"Depth perception plays an essential role in the viewer experience for immersive virtual reality (VR) visual environments. However, previous research investigations in the depth quality of 3D/stereoscopic images are rather limited, and in particular, are largely lacking for 3D viewing of 360-degree omnidirectional content. In this work, we make one of the first attempts to develop an objective quality assessment model named depth quality index (DQI) for efficient no-reference (NR) depth quality assessment of stereoscopic omnidirectional images. Motivated by the perceptual characteristics of the human visual system (HVS), the proposed DQI is built upon multi-color-channel, adaptive viewport selection, and interocular discrepancy features. Experimental results demonstrate that the proposed method outperforms state-of-the-art image quality assessment (IQA) and depth quality assessment (DQA) approaches in predicting the perceptual depth quality when tested using both single-viewport and omnidirectional stereoscopic image databases. Furthermore, we demonstrate that combining the proposed depth quality model with existing IQA methods significantly boosts the performance in predicting the overall quality of 3D omnidirectional images.","sentences":["Depth perception plays an essential role in the viewer experience for immersive virtual reality (VR) visual environments.","However, previous research investigations in the depth quality of 3D/stereoscopic images are rather limited, and in particular, are largely lacking for 3D viewing of 360-degree omnidirectional content.","In this work, we make one of the first attempts to develop an objective quality assessment model named depth quality index (DQI) for efficient no-reference (NR) depth quality assessment of stereoscopic omnidirectional images.","Motivated by the perceptual characteristics of the human visual system (HVS), the proposed DQI is built upon multi-color-channel, adaptive viewport selection, and interocular discrepancy features.","Experimental results demonstrate that the proposed method outperforms state-of-the-art image quality assessment (IQA) and depth quality assessment (DQA) approaches in predicting the perceptual depth quality when tested using both single-viewport and omnidirectional stereoscopic image databases.","Furthermore, we demonstrate that combining the proposed depth quality model with existing IQA methods significantly boosts the performance in predicting the overall quality of 3D omnidirectional images."],"url":"http://arxiv.org/abs/2408.10134v1"}
{"created":"2024-08-19 16:17:20","title":"Rhyme-aware Chinese lyric generator based on GPT","abstract":"Neural language representation models such as GPT, pre-trained on large-scale corpora, can effectively capture rich semantic patterns from plain text and be fine-tuned to consistently improve natural language generation performance. However, existing pre-trained language models used to generate lyrics rarely consider rhyme information, which is crucial in lyrics. Using a pre-trained model directly results in poor performance. To enhance the rhyming quality of generated lyrics, we incorporate integrated rhyme information into our model, thereby improving lyric generation performance.","sentences":["Neural language representation models such as GPT, pre-trained on large-scale corpora, can effectively capture rich semantic patterns from plain text and be fine-tuned to consistently improve natural language generation performance.","However, existing pre-trained language models used to generate lyrics rarely consider rhyme information, which is crucial in lyrics.","Using a pre-trained model directly results in poor performance.","To enhance the rhyming quality of generated lyrics, we incorporate integrated rhyme information into our model, thereby improving lyric generation performance."],"url":"http://arxiv.org/abs/2408.10130v1"}
{"created":"2024-08-19 16:15:56","title":"UNINEXT-Cutie: The 1st Solution for LSVOS Challenge RVOS Track","abstract":"Referring video object segmentation (RVOS) relies on natural language expressions to segment target objects in video. In this year, LSVOS Challenge RVOS Track replaced the origin YouTube-RVOS benchmark with MeViS. MeViS focuses on referring the target object in a video through its motion descriptions instead of static attributes, posing a greater challenge to RVOS task. In this work, we integrate strengths of that leading RVOS and VOS models to build up a simple and effective pipeline for RVOS. Firstly, We finetune the state-of-the-art RVOS model to obtain mask sequences that are correlated with language descriptions. Secondly, based on a reliable and high-quality key frames, we leverage VOS model to enhance the quality and temporal consistency of the mask results. Finally, we further improve the performance of the RVOS model using semi-supervised learning. Our solution achieved 62.57 J&F on the MeViS test set and ranked 1st place for 6th LSVOS Challenge RVOS Track.","sentences":["Referring video object segmentation (RVOS) relies on natural language expressions to segment target objects in video.","In this year, LSVOS Challenge RVOS Track replaced the origin YouTube-RVOS benchmark with MeViS. MeViS focuses on referring the target object in a video through its motion descriptions instead of static attributes, posing a greater challenge to RVOS task.","In this work, we integrate strengths of that leading RVOS and VOS models to build up a simple and effective pipeline for RVOS.","Firstly, We finetune the state-of-the-art RVOS model to obtain mask sequences that are correlated with language descriptions.","Secondly, based on a reliable and high-quality key frames, we leverage VOS model to enhance the quality and temporal consistency of the mask results.","Finally, we further improve the performance of the RVOS model using semi-supervised learning.","Our solution achieved 62.57 J&F on the MeViS test set and ranked 1st place for 6th LSVOS Challenge RVOS Track."],"url":"http://arxiv.org/abs/2408.10129v1"}
{"created":"2024-08-19 16:15:09","title":"Advancing Voice Cloning for Nepali: Leveraging Transfer Learning in a Low-Resource Language","abstract":"Voice cloning is a prominent feature in personalized speech interfaces. A neural vocal cloning system can mimic someone's voice using just a few audio samples. Both speaker encoding and speaker adaptation are topics of research in the field of voice cloning. Speaker adaptation relies on fine-tuning a multi-speaker generative model, which involves training a separate model to infer a new speaker embedding used for speaker encoding. Both methods can achieve excellent performance, even with a small number of cloning audios, in terms of the speech's naturalness and similarity to the original speaker. Speaker encoding approaches are more appropriate for low-resource deployment since they require significantly less memory and have a faster cloning time than speaker adaption, which can offer slightly greater naturalness and similarity. The main goal is to create a vocal cloning system that produces audio output with a Nepali accent or that sounds like Nepali. For the further advancement of TTS, the idea of transfer learning was effectively used to address several issues that were encountered in the development of this system, including the poor audio quality and the lack of available data.","sentences":["Voice cloning is a prominent feature in personalized speech interfaces.","A neural vocal cloning system can mimic someone's voice using just a few audio samples.","Both speaker encoding and speaker adaptation are topics of research in the field of voice cloning.","Speaker adaptation relies on fine-tuning a multi-speaker generative model, which involves training a separate model to infer a new speaker embedding used for speaker encoding.","Both methods can achieve excellent performance, even with a small number of cloning audios, in terms of the speech's naturalness and similarity to the original speaker.","Speaker encoding approaches are more appropriate for low-resource deployment since they require significantly less memory and have a faster cloning time than speaker adaption, which can offer slightly greater naturalness and similarity.","The main goal is to create a vocal cloning system that produces audio output with a Nepali accent or that sounds like Nepali.","For the further advancement of TTS, the idea of transfer learning was effectively used to address several issues that were encountered in the development of this system, including the poor audio quality and the lack of available data."],"url":"http://arxiv.org/abs/2408.10128v1"}
{"created":"2024-08-19 16:13:35","title":"Learning Brave Assumption-Based Argumentation Frameworks via ASP","abstract":"Assumption-based Argumentation (ABA) is advocated as a unifying formalism for various forms of non-monotonic reasoning, including logic programming. It allows capturing defeasible knowledge, subject to argumentative debate. While, in much existing work, ABA frameworks are given up-front, in this paper we focus on the problem of automating their learning from background knowledge and positive/negative examples. Unlike prior work, we newly frame the problem in terms of brave reasoning under stable extensions for ABA. We present a novel algorithm based on transformation rules (such as Rote Learning, Folding, Assumption Introduction and Fact Subsumption) and an implementation thereof that makes use of Answer Set Programming. Finally, we compare our technique to state-of-the-art ILP systems that learn defeasible knowledge.","sentences":["Assumption-based Argumentation (ABA) is advocated as a unifying formalism for various forms of non-monotonic reasoning, including logic programming.","It allows capturing defeasible knowledge, subject to argumentative debate.","While, in much existing work, ABA frameworks are given up-front, in this paper we focus on the problem of automating their learning from background knowledge and positive/negative examples.","Unlike prior work, we newly frame the problem in terms of brave reasoning under stable extensions for ABA.","We present a novel algorithm based on transformation rules (such as Rote Learning, Folding, Assumption Introduction and Fact Subsumption) and an implementation thereof that makes use of Answer Set Programming.","Finally, we compare our technique to state-of-the-art ILP systems that learn defeasible knowledge."],"url":"http://arxiv.org/abs/2408.10126v1"}
{"created":"2024-08-19 16:13:14","title":"Video Object Segmentation via SAM 2: The 4th Solution for LSVOS Challenge VOS Track","abstract":"Video Object Segmentation (VOS) task aims to segmenting a particular object instance throughout the entire video sequence given only the object mask of the first frame. Recently, Segment Anything Model 2 (SAM 2) is proposed, which is a foundation model towards solving promptable visual segmentation in images and videos. SAM 2 builds a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date. SAM 2 is a simple transformer architecture with streaming memory for real-time video processing, which trained on the date provides strong performance across a wide range of tasks. In this work, we evaluate the zero-shot performance of SAM 2 on the more challenging VOS datasets MOSE and LVOS. Without fine-tuning on the training set, SAM 2 achieved 75.79 J&F on the test set and ranked 4th place for 6th LSVOS Challenge VOS Track.","sentences":["Video Object Segmentation (VOS) task aims to segmenting a particular object instance throughout the entire video sequence given only the object mask of the first frame.","Recently, Segment Anything Model 2 (SAM 2) is proposed, which is a foundation model towards solving promptable visual segmentation in images and videos.","SAM 2 builds a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date.","SAM 2 is a simple transformer architecture with streaming memory for real-time video processing, which trained on the date provides strong performance across a wide range of tasks.","In this work, we evaluate the zero-shot performance of SAM 2 on the more challenging VOS datasets MOSE and LVOS.","Without fine-tuning on the training set, SAM 2 achieved 75.79 J&F on the test set and ranked 4th place for 6th LSVOS Challenge VOS Track."],"url":"http://arxiv.org/abs/2408.10125v1"}
{"created":"2024-08-19 16:11:59","title":"Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models","abstract":"Molecular property prediction is a crucial foundation for drug discovery. In recent years, pre-trained deep learning models have been widely applied to this task. Some approaches that incorporate prior biological domain knowledge into the pre-training framework have achieved impressive results. However, these methods heavily rely on biochemical experts, and retrieving and summarizing vast amounts of domain knowledge literature is both time-consuming and expensive. Large Language Models (LLMs) have demonstrated remarkable performance in understanding and efficiently providing general knowledge. Nevertheless, they occasionally exhibit hallucinations and lack precision in generating domain-specific knowledge. Conversely, Domain-specific Small Models (DSMs) possess rich domain knowledge and can accurately calculate molecular domain-related metrics. However, due to their limited model size and singular functionality, they lack the breadth of knowledge necessary for comprehensive representation learning. To leverage the advantages of both approaches in molecular property prediction, we propose a novel Molecular Graph representation learning framework that integrates Large language models and Domain-specific small models (MolGraph-LarDo). Technically, we design a two-stage prompt strategy where DSMs are introduced to calibrate the knowledge provided by LLMs, enhancing the accuracy of domain-specific information and thus enabling LLMs to generate more precise textual descriptions for molecular samples. Subsequently, we employ a multi-modal alignment method to coordinate various modalities, including molecular graphs and their corresponding descriptive texts, to guide the pre-training of molecular representations. Extensive experiments demonstrate the effectiveness of the proposed method.","sentences":["Molecular property prediction is a crucial foundation for drug discovery.","In recent years, pre-trained deep learning models have been widely applied to this task.","Some approaches that incorporate prior biological domain knowledge into the pre-training framework have achieved impressive results.","However, these methods heavily rely on biochemical experts, and retrieving and summarizing vast amounts of domain knowledge literature is both time-consuming and expensive.","Large Language Models (LLMs) have demonstrated remarkable performance in understanding and efficiently providing general knowledge.","Nevertheless, they occasionally exhibit hallucinations and lack precision in generating domain-specific knowledge.","Conversely, Domain-specific Small Models (DSMs) possess rich domain knowledge and can accurately calculate molecular domain-related metrics.","However, due to their limited model size and singular functionality, they lack the breadth of knowledge necessary for comprehensive representation learning.","To leverage the advantages of both approaches in molecular property prediction, we propose a novel Molecular Graph representation learning framework that integrates Large language models and Domain-specific small models (MolGraph-LarDo).","Technically, we design a two-stage prompt strategy where DSMs are introduced to calibrate the knowledge provided by LLMs, enhancing the accuracy of domain-specific information and thus enabling LLMs to generate more precise textual descriptions for molecular samples.","Subsequently, we employ a multi-modal alignment method to coordinate various modalities, including molecular graphs and their corresponding descriptive texts, to guide the pre-training of molecular representations.","Extensive experiments demonstrate the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2408.10124v1"}
{"created":"2024-08-19 16:11:47","title":"Learning Precise Affordances from Egocentric Videos for Robotic Manipulation","abstract":"Affordance, defined as the potential actions that an object offers, is crucial for robotic manipulation tasks. A deep understanding of affordance can lead to more intelligent AI systems. For example, such knowledge directs an agent to grasp a knife by the handle for cutting and by the blade when passing it to someone. In this paper, we present a streamlined affordance learning system that encompasses data collection, effective model training, and robot deployment. First, we collect training data from egocentric videos in an automatic manner. Different from previous methods that focus only on the object graspable affordance and represent it as coarse heatmaps, we cover both graspable (e.g., object handles) and functional affordances (e.g., knife blades, hammer heads) and extract data with precise segmentation masks. We then propose an effective model, termed Geometry-guided Affordance Transformer (GKT), to train on the collected data. GKT integrates an innovative Depth Feature Injector (DFI) to incorporate 3D shape and geometric priors, enhancing the model's understanding of affordances. To enable affordance-oriented manipulation, we further introduce Aff-Grasp, a framework that combines GKT with a grasp generation model. For comprehensive evaluation, we create an affordance evaluation dataset with pixel-wise annotations, and design real-world tasks for robot experiments. The results show that GKT surpasses the state-of-the-art by 15.9% in mIoU, and Aff-Grasp achieves high success rates of 95.5% in affordance prediction and 77.1% in successful grasping among 179 trials, including evaluations with seen, unseen objects, and cluttered scenes.","sentences":["Affordance, defined as the potential actions that an object offers, is crucial for robotic manipulation tasks.","A deep understanding of affordance can lead to more intelligent AI systems.","For example, such knowledge directs an agent to grasp a knife by the handle for cutting and by the blade when passing it to someone.","In this paper, we present a streamlined affordance learning system that encompasses data collection, effective model training, and robot deployment.","First, we collect training data from egocentric videos in an automatic manner.","Different from previous methods that focus only on the object graspable affordance and represent it as coarse heatmaps, we cover both graspable (e.g., object handles) and functional affordances (e.g., knife blades, hammer heads) and extract data with precise segmentation masks.","We then propose an effective model, termed Geometry-guided Affordance Transformer (GKT), to train on the collected data.","GKT integrates an innovative Depth Feature Injector (DFI) to incorporate 3D shape and geometric priors, enhancing the model's understanding of affordances.","To enable affordance-oriented manipulation, we further introduce Aff-Grasp, a framework that combines GKT with a grasp generation model.","For comprehensive evaluation, we create an affordance evaluation dataset with pixel-wise annotations, and design real-world tasks for robot experiments.","The results show that GKT surpasses the state-of-the-art by 15.9% in mIoU, and Aff-Grasp achieves high success rates of 95.5% in affordance prediction and 77.1% in successful grasping among 179 trials, including evaluations with seen, unseen objects, and cluttered scenes."],"url":"http://arxiv.org/abs/2408.10123v1"}
{"created":"2024-08-19 16:09:59","title":"Geometry Informed Tokenization of Molecules for Language Model Generation","abstract":"We consider molecule generation in 3D space using language models (LMs), which requires discrete tokenization of 3D molecular geometries. Although tokenization of molecular graphs exists, that for 3D geometries is largely unexplored. Here, we attempt to bridge this gap by proposing the Geo2Seq, which converts molecular geometries into $SE(3)$-invariant 1D discrete sequences. Geo2Seq consists of canonical labeling and invariant spherical representation steps, which together maintain geometric and atomic fidelity in a format conducive to LMs. Our experiments show that, when coupled with Geo2Seq, various LMs excel in molecular geometry generation, especially in controlled generation tasks.","sentences":["We consider molecule generation in 3D space using language models (LMs), which requires discrete tokenization of 3D molecular geometries.","Although tokenization of molecular graphs exists, that for 3D geometries is largely unexplored.","Here, we attempt to bridge this gap by proposing the Geo2Seq, which converts molecular geometries into $SE(3)$-invariant 1D discrete sequences.","Geo2Seq consists of canonical labeling and invariant spherical representation steps, which together maintain geometric and atomic fidelity in a format conducive to LMs.","Our experiments show that, when coupled with Geo2Seq, various LMs excel in molecular geometry generation, especially in controlled generation tasks."],"url":"http://arxiv.org/abs/2408.10120v1"}
{"created":"2024-08-19 16:08:00","title":"Factorized-Dreamer: Training A High-Quality Video Generator with Limited and Low-Quality Data","abstract":"Text-to-video (T2V) generation has gained significant attention due to its wide applications to video generation, editing, enhancement and translation, \\etc. However, high-quality (HQ) video synthesis is extremely challenging because of the diverse and complex motions existed in real world. Most existing works struggle to address this problem by collecting large-scale HQ videos, which are inaccessible to the community. In this work, we show that publicly available limited and low-quality (LQ) data are sufficient to train a HQ video generator without recaptioning or finetuning. We factorize the whole T2V generation process into two steps: generating an image conditioned on a highly descriptive caption, and synthesizing the video conditioned on the generated image and a concise caption of motion details. Specifically, we present \\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several critical designs for T2V generation, including an adapter to combine text and image embeddings, a pixel-aware cross attention module to capture pixel-level image information, a T5 text encoder to better understand motion description, and a PredictNet to supervise optical flows. We further present a noise schedule, which plays a key role in ensuring the quality and stability of video generation. Our model lowers the requirements in detailed captions and HQ videos, and can be directly trained on limited LQ datasets with noisy and brief captions such as WebVid-10M, largely alleviating the cost to collect large-scale HQ video-text pairs. Extensive experiments in a variety of T2V and image-to-video generation tasks demonstrate the effectiveness of our proposed Factorized-Dreamer. Our source codes are available at \\url{https://github.com/yangxy/Factorized-Dreamer/}.","sentences":["Text-to-video (T2V) generation has gained significant attention due to its wide applications to video generation, editing, enhancement and translation, \\etc.","However, high-quality (HQ) video synthesis is extremely challenging because of the diverse and complex motions existed in real world.","Most existing works struggle to address this problem by collecting large-scale HQ videos, which are inaccessible to the community.","In this work, we show that publicly available limited and low-quality (LQ) data are sufficient to train a HQ video generator without recaptioning or finetuning.","We factorize the whole T2V generation process into two steps: generating an image conditioned on a highly descriptive caption, and synthesizing the video conditioned on the generated image and a concise caption of motion details.","Specifically, we present \\emph{Factorized-Dreamer}, a factorized spatiotemporal framework with several critical designs for T2V generation, including an adapter to combine text and image embeddings, a pixel-aware cross attention module to capture pixel-level image information, a T5 text encoder to better understand motion description, and a PredictNet to supervise optical flows.","We further present a noise schedule, which plays a key role in ensuring the quality and stability of video generation.","Our model lowers the requirements in detailed captions and HQ videos, and can be directly trained on limited LQ datasets with noisy and brief captions such as WebVid-10M, largely alleviating the cost to collect large-scale HQ video-text pairs.","Extensive experiments in a variety of T2V and image-to-video generation tasks demonstrate the effectiveness of our proposed Factorized-Dreamer.","Our source codes are available at \\url{https://github.com/yangxy/Factorized-Dreamer/}."],"url":"http://arxiv.org/abs/2408.10119v1"}
{"created":"2024-08-19 16:03:30","title":"Branching Bisimilarity for Processes with Time-outs","abstract":"This paper provides an adaptation of branching bisimilarity to reactive systems with time-outs. Multiple equivalent definitions are procured, along with a modal characterisation and a proof of its congruence property for a standard process algebra with recursion. The last section presents a complete axiomatisation for guarded processes without infinite sequences of unobservable actions.","sentences":["This paper provides an adaptation of branching bisimilarity to reactive systems with time-outs.","Multiple equivalent definitions are procured, along with a modal characterisation and a proof of its congruence property for a standard process algebra with recursion.","The last section presents a complete axiomatisation for guarded processes without infinite sequences of unobservable actions."],"url":"http://arxiv.org/abs/2408.10117v1"}
{"created":"2024-08-19 16:03:03","title":"Vulseye: Detect Smart Contract Vulnerabilities via Stateful Directed Graybox Fuzzing","abstract":"Smart contracts, the cornerstone of decentralized applications, have become increasingly prominent in revolutionizing the digital landscape. However, vulnerabilities in smart contracts pose great risks to user assets and undermine overall trust in decentralized systems. But current smart contract fuzzers fall short of expectations in testing efficiency for two primary reasons. Firstly, smart contracts are stateful programs, and existing approaches, primarily coverage-guided, lack effective feedback from the contract state. Consequently, they struggle to effectively explore the contract state space. Secondly, coverage-guided fuzzers, aiming for comprehensive program coverage, may lead to a wastage of testing resources on benign code areas. This wastage worsens in smart contract testing, as the mix of code and state spaces further complicates comprehensive testing.   To address these challenges, we propose Vulseye, a stateful directed graybox fuzzer for smart contracts guided by vulnerabilities. Different from prior works, Vulseye achieves stateful directed fuzzing by prioritizing testing resources to code areas and contract states that are more prone to vulnerabilities. We introduce Code Targets and State Targets into fuzzing loops as the testing targets of Vulseye. We use static analysis and pattern matching to pinpoint Code Targets, and propose a scalable backward analysis algorithm to specify State Targets. We design a novel fitness metric that leverages feedback from both the contract code space and state space, directing fuzzing toward these targets. With the guidance of code and state targets, Vulseye alleviates the wastage of testing resources on benign code areas and achieves effective stateful fuzzing. In comparison with state-of-the-art fuzzers, Vulseye demonstrated superior effectiveness and efficiency.","sentences":["Smart contracts, the cornerstone of decentralized applications, have become increasingly prominent in revolutionizing the digital landscape.","However, vulnerabilities in smart contracts pose great risks to user assets and undermine overall trust in decentralized systems.","But current smart contract fuzzers fall short of expectations in testing efficiency for two primary reasons.","Firstly, smart contracts are stateful programs, and existing approaches, primarily coverage-guided, lack effective feedback from the contract state.","Consequently, they struggle to effectively explore the contract state space.","Secondly, coverage-guided fuzzers, aiming for comprehensive program coverage, may lead to a wastage of testing resources on benign code areas.","This wastage worsens in smart contract testing, as the mix of code and state spaces further complicates comprehensive testing.   ","To address these challenges, we propose Vulseye, a stateful directed graybox fuzzer for smart contracts guided by vulnerabilities.","Different from prior works, Vulseye achieves stateful directed fuzzing by prioritizing testing resources to code areas and contract states that are more prone to vulnerabilities.","We introduce Code Targets and State Targets into fuzzing loops as the testing targets of Vulseye.","We use static analysis and pattern matching to pinpoint Code Targets, and propose a scalable backward analysis algorithm to specify State Targets.","We design a novel fitness metric that leverages feedback from both the contract code space and state space, directing fuzzing toward these targets.","With the guidance of code and state targets, Vulseye alleviates the wastage of testing resources on benign code areas and achieves effective stateful fuzzing.","In comparison with state-of-the-art fuzzers, Vulseye demonstrated superior effectiveness and efficiency."],"url":"http://arxiv.org/abs/2408.10116v1"}
{"created":"2024-08-19 16:01:48","title":"GLIMMER: Incorporating Graph and Lexical Features in Unsupervised Multi-Document Summarization","abstract":"Pre-trained language models are increasingly being used in multi-document summarization tasks. However, these models need large-scale corpora for pre-training and are domain-dependent. Other non-neural unsupervised summarization approaches mostly rely on key sentence extraction, which can lead to information loss. To address these challenges, we propose a lightweight yet effective unsupervised approach called GLIMMER: a Graph and LexIcal features based unsupervised Multi-docuMEnt summaRization approach. It first constructs a sentence graph from the source documents, then automatically identifies semantic clusters by mining low-level features from raw texts, thereby improving intra-cluster correlation and the fluency of generated sentences. Finally, it summarizes clusters into natural sentences. Experiments conducted on Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach outperforms existing unsupervised approaches. Furthermore, it surpasses state-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS and PRIMERA) under zero-shot settings in terms of ROUGE scores. Additionally, human evaluations indicate that summaries generated by GLIMMER achieve high readability and informativeness scores. Our code is available at https://github.com/Oswald1997/GLIMMER.","sentences":["Pre-trained language models are increasingly being used in multi-document summarization tasks.","However, these models need large-scale corpora for pre-training and are domain-dependent.","Other non-neural unsupervised summarization approaches mostly rely on key sentence extraction, which can lead to information loss.","To address these challenges, we propose a lightweight yet effective unsupervised approach called GLIMMER: a Graph and LexIcal features based unsupervised Multi-docuMEnt summaRization approach.","It first constructs a sentence graph from the source documents, then automatically identifies semantic clusters by mining low-level features from raw texts, thereby improving intra-cluster correlation and the fluency of generated sentences.","Finally, it summarizes clusters into natural sentences.","Experiments conducted on Multi-News, Multi-XScience and DUC-2004 demonstrate that our approach outperforms existing unsupervised approaches.","Furthermore, it surpasses state-of-the-art pre-trained multi-document summarization models (e.g. PEGASUS and PRIMERA) under zero-shot settings in terms of ROUGE scores.","Additionally, human evaluations indicate that summaries generated by GLIMMER achieve high readability and informativeness scores.","Our code is available at https://github.com/Oswald1997/GLIMMER."],"url":"http://arxiv.org/abs/2408.10115v1"}
{"created":"2024-08-19 16:00:02","title":"Enhancing Reinforcement Learning Through Guided Search","abstract":"With the aim of improving performance in Markov Decision Problem in an Off-Policy setting, we suggest taking inspiration from what is done in Offline Reinforcement Learning (RL). In Offline RL, it is a common practice during policy learning to maintain proximity to a reference policy to mitigate uncertainty, reduce potential policy errors, and help improve performance. We find ourselves in a different setting, yet it raises questions about whether a similar concept can be applied to enhance performance ie, whether it is possible to find a guiding policy capable of contributing to performance improvement, and how to incorporate it into our RL agent. Our attention is particularly focused on algorithms based on Monte Carlo Tree Search (MCTS) as a guide.MCTS renowned for its state-of-the-art capabilities across various domains, catches our interest due to its ability to converge to equilibrium in single-player and two-player contexts. By harnessing the power of MCTS as a guide for our RL agent, we observed a significant performance improvement, surpassing the outcomes achieved by utilizing each method in isolation. Our experiments were carried out on the Atari 100k benchmark.","sentences":["With the aim of improving performance in Markov Decision Problem in an Off-Policy setting, we suggest taking inspiration from what is done in Offline Reinforcement Learning (RL).","In Offline RL, it is a common practice during policy learning to maintain proximity to a reference policy to mitigate uncertainty, reduce potential policy errors, and help improve performance.","We find ourselves in a different setting, yet it raises questions about whether a similar concept can be applied to enhance performance ie, whether it is possible to find a guiding policy capable of contributing to performance improvement, and how to incorporate it into our RL agent.","Our attention is particularly focused on algorithms based on Monte Carlo Tree Search (MCTS) as a guide.","MCTS renowned for its state-of-the-art capabilities across various domains, catches our interest due to its ability to converge to equilibrium in single-player and two-player contexts.","By harnessing the power of MCTS as a guide for our RL agent, we observed a significant performance improvement, surpassing the outcomes achieved by utilizing each method in isolation.","Our experiments were carried out on the Atari 100k benchmark."],"url":"http://arxiv.org/abs/2408.10113v1"}
{"created":"2024-08-19 15:59:46","title":"PLUTUS: A Well Pre-trained Large Unified Transformer can Unveil Financial Time Series Regularities","abstract":"Financial time series modeling is crucial for understanding and predicting market behaviors but faces challenges such as non-linearity, non-stationarity, and high noise levels. Traditional models struggle to capture complex patterns due to these issues, compounded by limitations in computational resources and model capacity. Inspired by the success of large language models in NLP, we introduce \\textbf{PLUTUS}, a \\textbf{P}re-trained \\textbf{L}arge \\textbf{U}nified \\textbf{T}ransformer-based model that \\textbf{U}nveils regularities in financial time \\textbf{S}eries. PLUTUS uses an invertible embedding module with contrastive learning and autoencoder techniques to create an approximate one-to-one mapping between raw data and patch embeddings. TimeFormer, an attention based architecture, forms the core of PLUTUS, effectively modeling high-noise time series. We incorporate a novel attention mechanisms to capture features across both variable and temporal dimensions. PLUTUS is pre-trained on an unprecedented dataset of 100 billion observations, designed to thrive in noisy financial environments. To our knowledge, PLUTUS is the first open-source, large-scale, pre-trained financial time series model with over one billion parameters. It achieves state-of-the-art performance in various tasks, demonstrating strong transferability and establishing a robust foundational model for finance. Our research provides technical guidance for pre-training financial time series data, setting a new standard in the field.","sentences":["Financial time series modeling is crucial for understanding and predicting market behaviors but faces challenges such as non-linearity, non-stationarity, and high noise levels.","Traditional models struggle to capture complex patterns due to these issues, compounded by limitations in computational resources and model capacity.","Inspired by the success of large language models in NLP, we introduce \\textbf{PLUTUS}, a \\textbf{P}re-trained \\textbf{L}arge \\textbf{U}nified \\textbf{T}ransformer-based model that \\textbf{U}nveils regularities in financial time \\textbf{S}eries.","PLUTUS uses an invertible embedding module with contrastive learning and autoencoder techniques to create an approximate one-to-one mapping between raw data and patch embeddings.","TimeFormer, an attention based architecture, forms the core of PLUTUS, effectively modeling high-noise time series.","We incorporate a novel attention mechanisms to capture features across both variable and temporal dimensions.","PLUTUS is pre-trained on an unprecedented dataset of 100 billion observations, designed to thrive in noisy financial environments.","To our knowledge, PLUTUS is the first open-source, large-scale, pre-trained financial time series model with over one billion parameters.","It achieves state-of-the-art performance in various tasks, demonstrating strong transferability and establishing a robust foundational model for finance.","Our research provides technical guidance for pre-training financial time series data, setting a new standard in the field."],"url":"http://arxiv.org/abs/2408.10111v1"}
{"created":"2024-08-19 15:55:46","title":"Envisioning Possibilities and Challenges of AI for Personalized Cancer Care","abstract":"The use of Artificial Intelligence (AI) in healthcare, including in caring for cancer survivors, has gained significant interest. However, gaps remain in our understanding of how such AI systems can provide care, especially for ethnic and racial minority groups who continue to face care disparities. Through interviews with six cancer survivors, we identify critical gaps in current healthcare systems such as a lack of personalized care and insufficient cultural and linguistic accommodation. AI, when applied to care, was seen as a way to address these issues by enabling real-time, culturally aligned, and linguistically appropriate interactions. We also uncovered concerns about the implications of AI-driven personalization, such as data privacy, loss of human touch in caregiving, and the risk of echo chambers that limit exposure to diverse information. We conclude by discussing the trade-offs between AI-enhanced personalization and the need for structural changes in healthcare that go beyond technological solutions, leading us to argue that we should begin by asking, ``Why personalization?''","sentences":["The use of Artificial Intelligence (AI) in healthcare, including in caring for cancer survivors, has gained significant interest.","However, gaps remain in our understanding of how such AI systems can provide care, especially for ethnic and racial minority groups who continue to face care disparities.","Through interviews with six cancer survivors, we identify critical gaps in current healthcare systems such as a lack of personalized care and insufficient cultural and linguistic accommodation.","AI, when applied to care, was seen as a way to address these issues by enabling real-time, culturally aligned, and linguistically appropriate interactions.","We also uncovered concerns about the implications of AI-driven personalization, such as data privacy, loss of human touch in caregiving, and the risk of echo chambers that limit exposure to diverse information.","We conclude by discussing the trade-offs between AI-enhanced personalization and the need for structural changes in healthcare that go beyond technological solutions, leading us to argue that we should begin by asking, ``Why personalization?''"],"url":"http://arxiv.org/abs/2408.10108v1"}
{"created":"2024-08-19 15:51:31","title":"Perturb-and-Compare Approach for Detecting Out-of-Distribution Samples in Constrained Access Environments","abstract":"Accessing machine learning models through remote APIs has been gaining prevalence following the recent trend of scaling up model parameters for increased performance. Even though these models exhibit remarkable ability, detecting out-of-distribution (OOD) samples remains a crucial safety concern for end users as these samples may induce unreliable outputs from the model. In this work, we propose an OOD detection framework, MixDiff, that is applicable even when the model's parameters or its activations are not accessible to the end user. To bypass the access restriction, MixDiff applies an identical input-level perturbation to a given target sample and a similar in-distribution (ID) sample, then compares the relative difference in the model outputs of these two samples. MixDiff is model-agnostic and compatible with existing output-based OOD detection methods. We provide theoretical analysis to illustrate MixDiff's effectiveness in discerning OOD samples that induce overconfident outputs from the model and empirically demonstrate that MixDiff consistently enhances the OOD detection performance on various datasets in vision and text domains.","sentences":["Accessing machine learning models through remote APIs has been gaining prevalence following the recent trend of scaling up model parameters for increased performance.","Even though these models exhibit remarkable ability, detecting out-of-distribution (OOD) samples remains a crucial safety concern for end users as these samples may induce unreliable outputs from the model.","In this work, we propose an OOD detection framework, MixDiff, that is applicable even when the model's parameters or its activations are not accessible to the end user.","To bypass the access restriction, MixDiff applies an identical input-level perturbation to a given target sample and a similar in-distribution (ID) sample, then compares the relative difference in the model outputs of these two samples.","MixDiff is model-agnostic and compatible with existing output-based OOD detection methods.","We provide theoretical analysis to illustrate MixDiff's effectiveness in discerning OOD samples that induce overconfident outputs from the model and empirically demonstrate that MixDiff consistently enhances the OOD detection performance on various datasets in vision and text domains."],"url":"http://arxiv.org/abs/2408.10107v1"}
{"created":"2024-08-19 15:38:53","title":"Neural Representation of Shape-Dependent Laplacian Eigenfunctions","abstract":"The eigenfunctions of the Laplace operator are essential in mathematical physics, engineering, and geometry processing. Typically, these are computed by discretizing the domain and performing eigendecomposition, tying the results to a specific mesh. However, this method is unsuitable for continuously-parameterized shapes.   We propose a novel representation for eigenfunctions in continuously-parameterized shape spaces, where eigenfunctions are spatial fields with continuous dependence on shape parameters, defined by minimal Dirichlet energy, unit norm, and mutual orthogonality. We implement this with multilayer perceptrons trained as neural fields, mapping shape parameters and domain positions to eigenfunction values.   A unique challenge is enforcing mutual orthogonality with respect to causality, where the causal ordering varies across the shape space. Our training method therefore requires three interwoven concepts: (1) learning $n$ eigenfunctions concurrently by minimizing Dirichlet energy with unit norm constraints; (2) filtering gradients during backpropagation to enforce causal orthogonality, preventing earlier eigenfunctions from being influenced by later ones; (3) dynamically sorting the causal ordering based on eigenvalues to track eigenvalue curve crossovers.   We demonstrate our method on problems such as shape family analysis, predicting eigenfunctions for incomplete shapes, interactive shape manipulation, and computing higher-dimensional eigenfunctions, on all of which traditional methods fall short.","sentences":["The eigenfunctions of the Laplace operator are essential in mathematical physics, engineering, and geometry processing.","Typically, these are computed by discretizing the domain and performing eigendecomposition, tying the results to a specific mesh.","However, this method is unsuitable for continuously-parameterized shapes.   ","We propose a novel representation for eigenfunctions in continuously-parameterized shape spaces, where eigenfunctions are spatial fields with continuous dependence on shape parameters, defined by minimal Dirichlet energy, unit norm, and mutual orthogonality.","We implement this with multilayer perceptrons trained as neural fields, mapping shape parameters and domain positions to eigenfunction values.   ","A unique challenge is enforcing mutual orthogonality with respect to causality, where the causal ordering varies across the shape space.","Our training method therefore requires three interwoven concepts: (1) learning $n$ eigenfunctions concurrently by minimizing Dirichlet energy with unit norm constraints; (2) filtering gradients during backpropagation to enforce causal orthogonality, preventing earlier eigenfunctions from being influenced by later ones; (3) dynamically sorting the causal ordering based on eigenvalues to track eigenvalue curve crossovers.   ","We demonstrate our method on problems such as shape family analysis, predicting eigenfunctions for incomplete shapes, interactive shape manipulation, and computing higher-dimensional eigenfunctions, on all of which traditional methods fall short."],"url":"http://arxiv.org/abs/2408.10099v1"}
{"created":"2024-08-19 15:33:59","title":"Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision","abstract":"Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted. We propose a two-stage generative framework \"convert-and-speak\" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain. The decoupling design enables the \"speaking\" module to use massive amount of target accent speech and relieves the parallel data required for the \"conversion\" module. Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data. To reduce the complexity and latency of \"speaking\", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost. Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker. Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data. Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.","sentences":["Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted.","We propose a two-stage generative framework \"convert-and-speak\" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain.","The decoupling design enables the \"speaking\" module to use massive amount of target accent speech and relieves the parallel data required for the \"conversion\" module.","Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data.","To reduce the complexity and latency of \"speaking\", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost.","Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker.","Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data.","Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/."],"url":"http://arxiv.org/abs/2408.10096v1"}
{"created":"2024-08-19 15:32:29","title":"Selecting Relay Nodes Based on Evaluation Results to Enhance P2P Broadcasting Efficiency","abstract":"The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms. High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network. To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks. However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency. In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions. According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate.","sentences":["The existence of node failures is inevitable in distributed systems, thus many P2P broadcasting networks adopt highly robust Flooding-based broadcast algorithms.","High redundancy inevitably leads to high network resource consumption, and it may constrain the data transmission rate of the network.","To address excessive network resource consumption, many studies have explored broadcasting mechanisms in structured P2P overlay networks.","However, existing DHT-based algorithms cannot assess the quality of neighbors, which is crucial for broadcast efficiency.","In this paper, we introduce the Neighbor Evaluation mechanism to select relay nodes based on their evaluated contributions.","According to experimental results, the Neighbor Evaluation mechanism has a significant effect on both broadcast latency and coverage rate."],"url":"http://arxiv.org/abs/2408.10092v1"}
{"created":"2024-08-19 15:31:06","title":"Federated Frank-Wolfe Algorithm","abstract":"Federated learning (FL) has gained a lot of attention in recent years for building privacy-preserving collaborative learning systems. However, FL algorithms for constrained machine learning problems are still limited, particularly when the projection step is costly. To this end, we propose a Federated Frank-Wolfe Algorithm (FedFW). FedFW features data privacy, low per-iteration cost, and communication of sparse signals. In the deterministic setting, FedFW achieves an $\\varepsilon$-suboptimal solution within $O(\\varepsilon^{-2})$ iterations for smooth and convex objectives, and $O(\\varepsilon^{-3})$ iterations for smooth but non-convex objectives. Furthermore, we present a stochastic variant of FedFW and show that it finds a solution within $O(\\varepsilon^{-3})$ iterations in the convex setting. We demonstrate the empirical performance of FedFW on several machine learning tasks.","sentences":["Federated learning (FL) has gained a lot of attention in recent years for building privacy-preserving collaborative learning systems.","However, FL algorithms for constrained machine learning problems are still limited, particularly when the projection step is costly.","To this end, we propose a Federated Frank-Wolfe Algorithm (FedFW).","FedFW features data privacy, low per-iteration cost, and communication of sparse signals.","In the deterministic setting, FedFW achieves an $\\varepsilon$-suboptimal solution within $O(\\varepsilon^{-2})$ iterations for smooth and convex objectives, and $O(\\varepsilon^{-3})$ iterations for smooth but non-convex objectives.","Furthermore, we present a stochastic variant of FedFW and show that it finds a solution within $O(\\varepsilon^{-3})$ iterations in the convex setting.","We demonstrate the empirical performance of FedFW on several machine learning tasks."],"url":"http://arxiv.org/abs/2408.10090v1"}
{"created":"2024-08-19 15:29:56","title":"Recent Surge in Public Interest in Transportation: Sentiment Analysis of Baidu Apollo Go Using Weibo Data","abstract":"Urban mobility and transportation systems have been profoundly transformed by the advancement of autonomous vehicle technologies. Baidu Apollo Go, a pioneer robotaxi service from the Chinese tech giant Baidu, has recently been widely deployed in major cities like Beijing and Wuhan, sparking increased conversation and offering a glimpse into the future of urban mobility.   This study investigates public attitudes towards Apollo Go across China using Sentiment Analysis with a hybrid BERT model on 36,096 Weibo posts from January to July 2024. The analysis shows that 89.56\\% of posts related to Apollo Go are clustered in July. From January to July, public sentiment was mostly positive, but negative comments began to rise after it became a hot topic on July 21.   Spatial analysis indicates a strong correlation between provinces with high discussion intensity and those where Apollo Go operates. Initially, Hubei and Guangdong dominated online posting volume, but by July, Guangdong, Beijing, and international regions had overtaken Hubei. Attitudes varied significantly among provinces, with Xinjiang and Qinghai showing optimism and Tibet and Gansu expressing concerns about the impact on traditional taxi services.   Sentiment analysis revealed that positive comments focused on technology applications and personal experiences, while negative comments centered on job displacement and safety concerns. In summary, this study highlights the divergence in public perceptions of autonomous ride-hailing services, providing valuable insights for planners, policymakers, and service providers. The model is published on Hugging Face at https://huggingface.co/wsqstar/bert-finetuned-weibo-luobokuaipao and the repository on GitHub at https://github.com/GIStudio/trb2024.","sentences":["Urban mobility and transportation systems have been profoundly transformed by the advancement of autonomous vehicle technologies.","Baidu Apollo Go, a pioneer robotaxi service from the Chinese tech giant Baidu, has recently been widely deployed in major cities like Beijing and Wuhan, sparking increased conversation and offering a glimpse into the future of urban mobility.   ","This study investigates public attitudes towards Apollo Go across China using Sentiment Analysis with a hybrid BERT model on 36,096 Weibo posts from January to July 2024.","The analysis shows that 89.56\\% of posts related to Apollo Go are clustered in July.","From January to July, public sentiment was mostly positive, but negative comments began to rise after it became a hot topic on July 21.   ","Spatial analysis indicates a strong correlation between provinces with high discussion intensity and those where Apollo Go operates.","Initially, Hubei and Guangdong dominated online posting volume, but by July, Guangdong, Beijing, and international regions had overtaken Hubei.","Attitudes varied significantly among provinces, with Xinjiang and Qinghai showing optimism and Tibet and Gansu expressing concerns about the impact on traditional taxi services.   ","Sentiment analysis revealed that positive comments focused on technology applications and personal experiences, while negative comments centered on job displacement and safety concerns.","In summary, this study highlights the divergence in public perceptions of autonomous ride-hailing services, providing valuable insights for planners, policymakers, and service providers.","The model is published on Hugging Face at https://huggingface.co/wsqstar/bert-finetuned-weibo-luobokuaipao and the repository on GitHub at https://github.com/GIStudio/trb2024."],"url":"http://arxiv.org/abs/2408.10088v1"}
{"created":"2024-08-19 15:27:25","title":"ARMADA: Attribute-Based Multimodal Data Augmentation","abstract":"In Multimodal Language Models (MLMs), the cost of manually annotating high-quality image-text pair data for fine-tuning and alignment is extremely high. While existing multimodal data augmentation frameworks propose ways to augment image-text pairs, they either suffer from semantic inconsistency between texts and images, or generate unrealistic images, causing knowledge gap with real world examples. To address these issues, we propose Attribute-based Multimodal Data Augmentation (ARMADA), a novel multimodal data augmentation method via knowledge-guided manipulation of visual attributes of the mentioned entities. Specifically, we extract entities and their visual attributes from the original text data, then search for alternative values for the visual attributes under the guidance of knowledge bases (KBs) and large language models (LLMs). We then utilize an image-editing model to edit the images with the extracted attributes. ARMADA is a novel multimodal data generation framework that: (i) extracts knowledge-grounded attributes from symbolic KBs for semantically consistent yet distinctive image-text pair generation, (ii) generates visually similar images of disparate categories using neighboring entities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs to modulate auxiliary visual attributes such as backgrounds for more robust representation of original entities. Our empirical results over four downstream tasks demonstrate the efficacy of our framework to produce high-quality data and enhance the model performance. This also highlights the need to leverage external knowledge proxies for enhanced interpretability and real-world grounding.","sentences":["In Multimodal Language Models (MLMs), the cost of manually annotating high-quality image-text pair data for fine-tuning and alignment is extremely high.","While existing multimodal data augmentation frameworks propose ways to augment image-text pairs, they either suffer from semantic inconsistency between texts and images, or generate unrealistic images, causing knowledge gap with real world examples.","To address these issues, we propose Attribute-based Multimodal Data Augmentation (ARMADA), a novel multimodal data augmentation method via knowledge-guided manipulation of visual attributes of the mentioned entities.","Specifically, we extract entities and their visual attributes from the original text data, then search for alternative values for the visual attributes under the guidance of knowledge bases (KBs) and large language models (LLMs).","We then utilize an image-editing model to edit the images with the extracted attributes.","ARMADA is a novel multimodal data generation framework that: (i) extracts knowledge-grounded attributes from symbolic KBs for semantically consistent yet distinctive image-text pair generation, (ii) generates visually similar images of disparate categories using neighboring entities in the KB hierarchy, and (iii) uses the commonsense knowledge of LLMs to modulate auxiliary visual attributes such as backgrounds for more robust representation of original entities.","Our empirical results over four downstream tasks demonstrate the efficacy of our framework to produce high-quality data and enhance the model performance.","This also highlights the need to leverage external knowledge proxies for enhanced interpretability and real-world grounding."],"url":"http://arxiv.org/abs/2408.10086v1"}
{"created":"2024-08-19 15:26:45","title":"MASALA: Model-Agnostic Surrogate Explanations by Locality Adaptation","abstract":"Existing local Explainable AI (XAI) methods, such as LIME, select a region of the input space in the vicinity of a given input instance, for which they approximate the behaviour of a model using a simpler and more interpretable surrogate model. The size of this region is often controlled by a user-defined locality hyperparameter. In this paper, we demonstrate the difficulties associated with defining a suitable locality size to capture impactful model behaviour, as well as the inadequacy of using a single locality size to explain all predictions. We propose a novel method, MASALA, for generating explanations, which automatically determines the appropriate local region of impactful model behaviour for each individual instance being explained. MASALA approximates the local behaviour used by a complex model to make a prediction by fitting a linear surrogate model to a set of points which experience similar model behaviour. These points are found by clustering the input space into regions of linear behavioural trends exhibited by the model. We compare the fidelity and consistency of explanations generated by our method with existing local XAI methods, namely LIME and CHILLI. Experiments on the PHM08 and MIDAS datasets show that our method produces more faithful and consistent explanations than existing methods, without the need to define any sensitive locality hyperparameters.","sentences":["Existing local Explainable AI (XAI) methods, such as LIME, select a region of the input space in the vicinity of a given input instance, for which they approximate the behaviour of a model using a simpler and more interpretable surrogate model.","The size of this region is often controlled by a user-defined locality hyperparameter.","In this paper, we demonstrate the difficulties associated with defining a suitable locality size to capture impactful model behaviour, as well as the inadequacy of using a single locality size to explain all predictions.","We propose a novel method, MASALA, for generating explanations, which automatically determines the appropriate local region of impactful model behaviour for each individual instance being explained.","MASALA approximates the local behaviour used by a complex model to make a prediction by fitting a linear surrogate model to a set of points which experience similar model behaviour.","These points are found by clustering the input space into regions of linear behavioural trends exhibited by the model.","We compare the fidelity and consistency of explanations generated by our method with existing local XAI methods, namely LIME and CHILLI.","Experiments on the PHM08 and MIDAS datasets show that our method produces more faithful and consistent explanations than existing methods, without the need to define any sensitive locality hyperparameters."],"url":"http://arxiv.org/abs/2408.10085v1"}
{"created":"2024-08-19 15:26:25","title":"TANGO: Clustering with Typicality-Aware Nonlocal Mode-Seeking and Graph-Cut Optimization","abstract":"Density-based clustering methods by mode-seeking usually achieve clustering by using local density estimation to mine structural information, such as local dependencies from lower density points to higher neighbors. However, they often rely too heavily on \\emph{local} structures and neglect \\emph{global} characteristics, which can lead to significant errors in peak selection and dependency establishment. Although introducing more hyperparameters that revise dependencies can help mitigate this issue, tuning them is challenging and even impossible on real-world datasets. In this paper, we propose a new algorithm (TANGO) to establish local dependencies by exploiting a global-view \\emph{typicality} of points, which is obtained by mining further the density distributions and initial dependencies. TANGO then obtains sub-clusters with the help of the adjusted dependencies, and characterizes the similarity between sub-clusters by incorporating path-based connectivity. It achieves final clustering by employing graph-cut on sub-clusters, thus avoiding the challenging selection of cluster centers. Moreover, this paper provides theoretical analysis and an efficient method for the calculation of typicality. Experimental results on several synthetic and $16$ real-world datasets demonstrate the effectiveness and superiority of TANGO.","sentences":["Density-based clustering methods by mode-seeking usually achieve clustering by using local density estimation to mine structural information, such as local dependencies from lower density points to higher neighbors.","However, they often rely too heavily on \\emph{local} structures and neglect \\emph{global} characteristics, which can lead to significant errors in peak selection and dependency establishment.","Although introducing more hyperparameters that revise dependencies can help mitigate this issue, tuning them is challenging and even impossible on real-world datasets.","In this paper, we propose a new algorithm (TANGO) to establish local dependencies by exploiting a global-view \\emph{typicality} of points, which is obtained by mining further the density distributions and initial dependencies.","TANGO then obtains sub-clusters with the help of the adjusted dependencies, and characterizes the similarity between sub-clusters by incorporating path-based connectivity.","It achieves final clustering by employing graph-cut on sub-clusters, thus avoiding the challenging selection of cluster centers.","Moreover, this paper provides theoretical analysis and an efficient method for the calculation of typicality.","Experimental results on several synthetic and $16$ real-world datasets demonstrate the effectiveness and superiority of TANGO."],"url":"http://arxiv.org/abs/2408.10084v1"}
{"created":"2024-08-19 15:25:40","title":"Tywaves: A Typed Waveform Viewer for Chisel","abstract":"Chisel (Constructing Hardware In a Scala Embedded Language) is a broadly adopted HDL that brings object-oriented and functional programming, type-safety, and parameterization to hardware design. However, while these language features significantly improve the process of writing code, debugging Chisel designs with open source tools loses many of the advantages of the source language, as type information and data structure hierarchies are lost in the translation, simulator output, and waveform viewer. This work, Tywaves, presents a new type-centered debugging format that brings the same level of abstraction found in contemporary hardware languages to waveform viewers. Contributions to the Chisel library and CIRCT MLIR compiler as well as the Surfer waveform viewer result in a waveform viewer that better supports the Chisel HDL.   Project url: https://github.com/rameloni/tywaves-chisel-demo","sentences":["Chisel (Constructing Hardware In a Scala Embedded Language) is a broadly adopted HDL that brings object-oriented and functional programming, type-safety, and parameterization to hardware design.","However, while these language features significantly improve the process of writing code, debugging Chisel designs with open source tools loses many of the advantages of the source language, as type information and data structure hierarchies are lost in the translation, simulator output, and waveform viewer.","This work, Tywaves, presents a new type-centered debugging format that brings the same level of abstraction found in contemporary hardware languages to waveform viewers.","Contributions to the Chisel library and CIRCT MLIR compiler as well as the Surfer waveform viewer result in a waveform viewer that better supports the Chisel HDL.   ","Project url: https://github.com/rameloni/tywaves-chisel-demo"],"url":"http://arxiv.org/abs/2408.10082v1"}
{"created":"2024-08-19 15:18:30","title":"Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning","abstract":"Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences. However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population. When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups. To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods. Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data. While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling. To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions. Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy. We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences. This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment.","sentences":["Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences.","However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population.","When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups.","To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods.","Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data.","While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling.","To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions.","Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy.","We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences.","This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment."],"url":"http://arxiv.org/abs/2408.10075v1"}
{"created":"2024-08-19 15:17:58","title":"Synthesis of Reward Machines for Multi-Agent Equilibrium Design (Full Version)","abstract":"Mechanism design is a well-established game-theoretic paradigm for designing games to achieve desired outcomes. This paper addresses a closely related but distinct concept, equilibrium design. Unlike mechanism design, the designer's authority in equilibrium design is more constrained; she can only modify the incentive structures in a given game to achieve certain outcomes without the ability to create the game from scratch. We study the problem of equilibrium design using dynamic incentive structures, known as reward machines. We use weighted concurrent game structures for the game model, with goals (for the players and the designer) defined as mean-payoff objectives. We show how reward machines can be used to represent dynamic incentives that allocate rewards in a manner that optimises the designer's goal. We also introduce the main decision problem within our framework, the payoff improvement problem. This problem essentially asks whether there exists a dynamic incentive (represented by some reward machine) that can improve the designer's payoff by more than a given threshold value. We present two variants of the problem: strong and weak. We demonstrate that both can be solved in polynomial time using a Turing machine equipped with an NP oracle. Furthermore, we also establish that these variants are either NP-hard or coNP-hard. Finally, we show how to synthesise the corresponding reward machine if it exists.","sentences":["Mechanism design is a well-established game-theoretic paradigm for designing games to achieve desired outcomes.","This paper addresses a closely related but distinct concept, equilibrium design.","Unlike mechanism design, the designer's authority in equilibrium design is more constrained; she can only modify the incentive structures in a given game to achieve certain outcomes without the ability to create the game from scratch.","We study the problem of equilibrium design using dynamic incentive structures, known as reward machines.","We use weighted concurrent game structures for the game model, with goals (for the players and the designer) defined as mean-payoff objectives.","We show how reward machines can be used to represent dynamic incentives that allocate rewards in a manner that optimises the designer's goal.","We also introduce the main decision problem within our framework, the payoff improvement problem.","This problem essentially asks whether there exists a dynamic incentive (represented by some reward machine) that can improve the designer's payoff by more than a given threshold value.","We present two variants of the problem: strong and weak.","We demonstrate that both can be solved in polynomial time using a Turing machine equipped with an NP oracle.","Furthermore, we also establish that these variants are either NP-hard or coNP-hard.","Finally, we show how to synthesise the corresponding reward machine if it exists."],"url":"http://arxiv.org/abs/2408.10074v1"}
{"created":"2024-08-19 15:16:36","title":"Modelling the Distribution of Human Motion for Sign Language Assessment","abstract":"Sign Language Assessment (SLA) tools are useful to aid in language learning and are underdeveloped. Previous work has focused on isolated signs or comparison against a single reference video to assess Sign Languages (SL). This paper introduces a novel SLA tool designed to evaluate the comprehensibility of SL by modelling the natural distribution of human motion. We train our pipeline on data from native signers and evaluate it using SL learners. We compare our results to ratings from a human raters study and find strong correlation between human ratings and our tool. We visually demonstrate our tools ability to detect anomalous results spatio-temporally, providing actionable feedback to aid in SL learning and assessment.","sentences":["Sign Language Assessment (SLA) tools are useful to aid in language learning and are underdeveloped.","Previous work has focused on isolated signs or comparison against a single reference video to assess Sign Languages (SL).","This paper introduces a novel SLA tool designed to evaluate the comprehensibility of SL by modelling the natural distribution of human motion.","We train our pipeline on data from native signers and evaluate it using SL learners.","We compare our results to ratings from a human raters study and find strong correlation between human ratings and our tool.","We visually demonstrate our tools ability to detect anomalous results spatio-temporally, providing actionable feedback to aid in SL learning and assessment."],"url":"http://arxiv.org/abs/2408.10073v1"}
{"created":"2024-08-19 15:15:20","title":"FFAA: Multimodal Large Language Model based Explainable Open-World Face Forgery Analysis Assistant","abstract":"The rapid advancement of deepfake technologies has sparked widespread public concern, particularly as face forgery poses a serious threat to public information security. However, the unknown and diverse forgery techniques, varied facial features and complex environmental factors pose significant challenges for face forgery analysis. Existing datasets lack descriptions of these aspects, making it difficult for models to distinguish between real and forged faces using only visual information amid various confounding factors. In addition, existing methods do not yield user-friendly and explainable results, complicating the understanding of the model's decision-making process. To address these challenges, we introduce a novel Open-World Face Forgery Analysis VQA (OW-FFA-VQA) task and the corresponding benchmark. To tackle this task, we first establish a dataset featuring a diverse collection of real and forged face images with essential descriptions and reliable forgery reasoning. Base on this dataset, we introduce FFAA: Face Forgery Analysis Assistant, consisting of a fine-tuned Multimodal Large Language Model (MLLM) and Multi-answer Intelligent Decision System (MIDS). By integrating hypothetical prompts with MIDS, the impact of fuzzy classification boundaries is effectively mitigated, enhancing the model's robustness. Extensive experiments demonstrate that our method not only provides user-friendly explainable results but also significantly boosts accuracy and robustness compared to previous methods.","sentences":["The rapid advancement of deepfake technologies has sparked widespread public concern, particularly as face forgery poses a serious threat to public information security.","However, the unknown and diverse forgery techniques, varied facial features and complex environmental factors pose significant challenges for face forgery analysis.","Existing datasets lack descriptions of these aspects, making it difficult for models to distinguish between real and forged faces using only visual information amid various confounding factors.","In addition, existing methods do not yield user-friendly and explainable results, complicating the understanding of the model's decision-making process.","To address these challenges, we introduce a novel Open-World Face Forgery Analysis VQA (OW-FFA-VQA) task and the corresponding benchmark.","To tackle this task, we first establish a dataset featuring a diverse collection of real and forged face images with essential descriptions and reliable forgery reasoning.","Base on this dataset, we introduce FFAA:","Face Forgery Analysis Assistant, consisting of a fine-tuned Multimodal Large Language Model (MLLM) and Multi-answer Intelligent Decision System (MIDS).","By integrating hypothetical prompts with MIDS, the impact of fuzzy classification boundaries is effectively mitigated, enhancing the model's robustness.","Extensive experiments demonstrate that our method not only provides user-friendly explainable results but also significantly boosts accuracy and robustness compared to previous methods."],"url":"http://arxiv.org/abs/2408.10072v1"}
{"created":"2024-08-19 15:11:01","title":"LNQ 2023 challenge: Benchmark of weakly-supervised techniques for mediastinal lymph node quantification","abstract":"Accurate assessment of lymph node size in 3D CT scans is crucial for cancer staging, therapeutic management, and monitoring treatment response. Existing state-of-the-art segmentation frameworks in medical imaging often rely on fully annotated datasets. However, for lymph node segmentation, these datasets are typically small due to the extensive time and expertise required to annotate the numerous lymph nodes in 3D CT scans. Weakly-supervised learning, which leverages incomplete or noisy annotations, has recently gained interest in the medical imaging community as a potential solution. Despite the variety of weakly-supervised techniques proposed, most have been validated only on private datasets or small publicly available datasets. To address this limitation, the Mediastinal Lymph Node Quantification (LNQ) challenge was organized in conjunction with the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023). This challenge aimed to advance weakly-supervised segmentation methods by providing a new, partially annotated dataset and a robust evaluation framework. A total of 16 teams from 5 countries submitted predictions to the validation leaderboard, and 6 teams from 3 countries participated in the evaluation phase. The results highlighted both the potential and the current limitations of weakly-supervised approaches. On one hand, weakly-supervised approaches obtained relatively good performance with a median Dice score of $61.0\\%$. On the other hand, top-ranked teams, with a median Dice score exceeding $70\\%$, boosted their performance by leveraging smaller but fully annotated datasets to combine weak supervision and full supervision. This highlights both the promise of weakly-supervised methods and the ongoing need for high-quality, fully annotated data to achieve higher segmentation performance.","sentences":["Accurate assessment of lymph node size in 3D CT scans is crucial for cancer staging, therapeutic management, and monitoring treatment response.","Existing state-of-the-art segmentation frameworks in medical imaging often rely on fully annotated datasets.","However, for lymph node segmentation, these datasets are typically small due to the extensive time and expertise required to annotate the numerous lymph nodes in 3D CT scans.","Weakly-supervised learning, which leverages incomplete or noisy annotations, has recently gained interest in the medical imaging community as a potential solution.","Despite the variety of weakly-supervised techniques proposed, most have been validated only on private datasets or small publicly available datasets.","To address this limitation, the Mediastinal Lymph Node Quantification (LNQ) challenge was organized in conjunction with the 26th International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI 2023).","This challenge aimed to advance weakly-supervised segmentation methods by providing a new, partially annotated dataset and a robust evaluation framework.","A total of 16 teams from 5 countries submitted predictions to the validation leaderboard, and 6 teams from 3 countries participated in the evaluation phase.","The results highlighted both the potential and the current limitations of weakly-supervised approaches.","On one hand, weakly-supervised approaches obtained relatively good performance with a median Dice score of $61.0\\%$. On the other hand, top-ranked teams, with a median Dice score exceeding $70\\%$, boosted their performance by leveraging smaller but fully annotated datasets to combine weak supervision and full supervision.","This highlights both the promise of weakly-supervised methods and the ongoing need for high-quality, fully annotated data to achieve higher segmentation performance."],"url":"http://arxiv.org/abs/2408.10069v1"}
{"created":"2024-08-19 15:04:20","title":"Near-Optimal Mechanisms for Resource Allocation Without Monetary Transfers","abstract":"We study the problem in which a central planner sequentially allocates a single resource to multiple strategic agents using their utility reports at each round, but without using any monetary transfers. We consider general agent utility distributions and two standard settings: a finite horizon $T$ and an infinite horizon with $\\gamma$ discounts. We provide general tools to characterize the convergence rate between the optimal mechanism for the central planner and the first-best allocation if true agent utilities were available. This heavily depends on the utility distributions, yielding rates anywhere between $1/\\sqrt T$ and $1/T$ for the finite-horizon setting, and rates faster than $\\sqrt{1-\\gamma}$, including exponential rates for the infinite-horizon setting as agents are more patient $\\gamma\\to 1$. On the algorithmic side, we design mechanisms based on the promised-utility framework to achieve these rates and leverage structure on the utility distributions. Intuitively, the more flexibility the central planner has to reward or penalize any agent while incurring little social welfare cost, the faster the convergence rate. In particular, discrete utility distributions typically yield the slower rates $1/\\sqrt T$ and $\\sqrt{1-\\gamma}$, while smooth distributions with density typically yield faster rates $1/T$ (up to logarithmic factors) and $1-\\gamma$.","sentences":["We study the problem in which a central planner sequentially allocates a single resource to multiple strategic agents using their utility reports at each round, but without using any monetary transfers.","We consider general agent utility distributions and two standard settings: a finite horizon $T$ and an infinite horizon with $\\gamma$ discounts.","We provide general tools to characterize the convergence rate between the optimal mechanism for the central planner and the first-best allocation if true agent utilities were available.","This heavily depends on the utility distributions, yielding rates anywhere between $1/\\sqrt T$ and $1/T$ for the finite-horizon setting, and rates faster than $\\sqrt{1-\\gamma}$, including exponential rates for the infinite-horizon setting as agents are more patient $\\gamma\\to 1$. On the algorithmic side, we design mechanisms based on the promised-utility framework to achieve these rates and leverage structure on the utility distributions.","Intuitively, the more flexibility the central planner has to reward or penalize any agent while incurring little social welfare cost, the faster the convergence rate.","In particular, discrete utility distributions typically yield the slower rates $1/\\sqrt T$ and $\\sqrt{1-\\gamma}$, while smooth distributions with density typically yield faster rates $1/T$ (up to logarithmic factors) and $1-\\gamma$."],"url":"http://arxiv.org/abs/2408.10066v1"}
{"created":"2024-08-19 14:58:25","title":"Understanding cyclists' perception of driverless vehicles through eye-tracking and interviews","abstract":"As automated vehicles (AVs) become increasingly popular, the question arises as to how cyclists will interact with such vehicles. This study investigated (1) whether cyclists spontaneously notice if a vehicle is driverless, (2) how well they perform a driver-detection task when explicitly instructed, and (3) how they carry out such tasks. Using a Wizard-of-Oz method, 37 participants cycled a designated route and encountered an AV multiple times in two experimental sessions. In Session 1, participants cycled the route uninstructed, while in Session 2, they were instructed to verbally report whether they detected the presence or absence of a driver. Additionally, we recorded the participants' gaze behaviour with eye-tracking and their responses in post-session interviews. The interviews revealed that 30% of the cyclists spontaneously mentioned the absence of a driver (Session 1), and when instructed (Session 2), they detected the absence and presence of the driver with 93% accuracy. The eye-tracking data showed that cyclists looked more frequently and longer at the vehicle in Session 2 compared to Session 1. Furthermore, participants exhibited intermittent sampling of the vehicle, and they looked in front of the vehicle when it was far away and towards the windshield region when it was closer. The post-session interviews also indicated that participants were curious, felt safe, and reported a need to receive information about the AV's driving state. In conclusion, cyclists can detect the absence of a driver in the AV, and this detection may influence their perceptions of safety. Further research is needed to explore these findings in real-world traffic conditions.","sentences":["As automated vehicles (AVs) become increasingly popular, the question arises as to how cyclists will interact with such vehicles.","This study investigated (1) whether cyclists spontaneously notice if a vehicle is driverless, (2) how well they perform a driver-detection task when explicitly instructed, and (3) how they carry out such tasks.","Using a Wizard-of-Oz method, 37 participants cycled a designated route and encountered an AV multiple times in two experimental sessions.","In Session 1, participants cycled the route uninstructed, while in Session 2, they were instructed to verbally report whether they detected the presence or absence of a driver.","Additionally, we recorded the participants' gaze behaviour with eye-tracking and their responses in post-session interviews.","The interviews revealed that 30% of the cyclists spontaneously mentioned the absence of a driver (Session 1), and when instructed (Session 2), they detected the absence and presence of the driver with 93% accuracy.","The eye-tracking data showed that cyclists looked more frequently and longer at the vehicle in Session 2 compared to Session 1.","Furthermore, participants exhibited intermittent sampling of the vehicle, and they looked in front of the vehicle when it was far away and towards the windshield region when it was closer.","The post-session interviews also indicated that participants were curious, felt safe, and reported a need to receive information about the AV's driving state.","In conclusion, cyclists can detect the absence of a driver in the AV, and this detection may influence their perceptions of safety.","Further research is needed to explore these findings in real-world traffic conditions."],"url":"http://arxiv.org/abs/2408.10064v1"}
{"created":"2024-08-19 14:54:12","title":"Facial Wrinkle Segmentation for Cosmetic Dermatology: Pretraining with Texture Map-Based Weak Supervision","abstract":"Facial wrinkle detection plays a crucial role in cosmetic dermatology. Precise manual segmentation of facial wrinkles is challenging and time-consuming, with inherent subjectivity leading to inconsistent results among graders. To address this issue, we propose two solutions. First, we build and release the first public facial wrinkle dataset, `FFHQ-Wrinkle', an extension of the NVIDIA FFHQ dataset. This dataset includes 1,000 images with human labels and 50,000 images with automatically generated weak labels. This dataset can foster the research community to develop advanced wrinkle detection algorithms. Second, we introduce a training strategy for U-Net-like encoder-decoder models to detect wrinkles across the face automatically. Our method employs a two-stage training strategy: texture map pretraining and finetuning on human-labeled data. Initially, we pretrain models on a large dataset with weak labels (N=50k) or masked texture maps generated through computer vision techniques, without human intervention. Subsequently, we finetune the models using human-labeled data (N=1k), which consists of manually labeled wrinkle masks. During finetuning, the network inputs a combination of RGB and masked texture maps, comprising four channels. We effectively combine labels from multiple annotators to minimize subjectivity in manual labeling. Our strategies demonstrate improved segmentation performance in facial wrinkle segmentation both quantitatively and visually compared to existing pretraining methods.","sentences":["Facial wrinkle detection plays a crucial role in cosmetic dermatology.","Precise manual segmentation of facial wrinkles is challenging and time-consuming, with inherent subjectivity leading to inconsistent results among graders.","To address this issue, we propose two solutions.","First, we build and release the first public facial wrinkle dataset, `FFHQ-Wrinkle', an extension of the NVIDIA FFHQ dataset.","This dataset includes 1,000 images with human labels and 50,000 images with automatically generated weak labels.","This dataset can foster the research community to develop advanced wrinkle detection algorithms.","Second, we introduce a training strategy for U-Net-like encoder-decoder models to detect wrinkles across the face automatically.","Our method employs a two-stage training strategy: texture map pretraining and finetuning on human-labeled data.","Initially, we pretrain models on a large dataset with weak labels (N=50k) or masked texture maps generated through computer vision techniques, without human intervention.","Subsequently, we finetune the models using human-labeled data (N=1k), which consists of manually labeled wrinkle masks.","During finetuning, the network inputs a combination of RGB and masked texture maps, comprising four channels.","We effectively combine labels from multiple annotators to minimize subjectivity in manual labeling.","Our strategies demonstrate improved segmentation performance in facial wrinkle segmentation both quantitatively and visually compared to existing pretraining methods."],"url":"http://arxiv.org/abs/2408.10060v1"}
{"created":"2024-08-19 14:50:48","title":"Efficient Exploration in Deep Reinforcement Learning: A Novel Bayesian Actor-Critic Algorithm","abstract":"Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in particular, have the potential to disrupt and are already changing the way we interact with the world. One of the key indicators of their applicability is their ability to scale and work in real-world scenarios, that is in large-scale problems. This scale can be achieved via a combination of factors, the algorithm's ability to make use of large amounts of data and computational resources and the efficient exploration of the environment for viable solutions (i.e. policies).   In this work, we investigate and motivate some theoretical foundations for deep reinforcement learning. We start with exact dynamic programming and work our way up to stochastic approximations and stochastic approximations for a model-free scenario, which forms the theoretical basis of modern reinforcement learning. We present an overview of this highly varied and rapidly changing field from the perspective of Approximate Dynamic Programming. We then focus our study on the short-comings with respect to exploration of the cornerstone approaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning. On the theory side, our main contribution is the proposal of a novel Bayesian actor-critic algorithm. On the empirical side, we evaluate Bayesian exploration as well as actor-critic algorithms on standard benchmarks as well as state-of-the-art evaluation suites and show the benefits of both of these approaches over current state-of-the-art deep RL methods. We release all the implementations and provide a full python library that is easy to install and hopefully will serve the reinforcement learning community in a meaningful way, and provide a strong foundation for future work.","sentences":["Reinforcement learning (RL) and Deep Reinforcement Learning (DRL), in particular, have the potential to disrupt and are already changing the way we interact with the world.","One of the key indicators of their applicability is their ability to scale and work in real-world scenarios, that is in large-scale problems.","This scale can be achieved via a combination of factors, the algorithm's ability to make use of large amounts of data and computational resources and the efficient exploration of the environment for viable solutions (i.e. policies).   ","In this work, we investigate and motivate some theoretical foundations for deep reinforcement learning.","We start with exact dynamic programming and work our way up to stochastic approximations and stochastic approximations for a model-free scenario, which forms the theoretical basis of modern reinforcement learning.","We present an overview of this highly varied and rapidly changing field from the perspective of Approximate Dynamic Programming.","We then focus our study on the short-comings with respect to exploration of the cornerstone approaches (i.e. DQN, DDQN, A2C) in deep reinforcement learning.","On the theory side, our main contribution is the proposal of a novel Bayesian actor-critic algorithm.","On the empirical side, we evaluate Bayesian exploration as well as actor-critic algorithms on standard benchmarks as well as state-of-the-art evaluation suites and show the benefits of both of these approaches over current state-of-the-art deep RL methods.","We release all the implementations and provide a full python library that is easy to install and hopefully will serve the reinforcement learning community in a meaningful way, and provide a strong foundation for future work."],"url":"http://arxiv.org/abs/2408.10055v1"}
{"created":"2024-08-19 14:48:04","title":"Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory","abstract":"Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications. Computer science researchers, on the other hand, commonly study privacy issues through privacy attacks and defenses on segmented fields. Privacy research is conducted on various sub-fields, including Computer Vision (CV), Natural Language Processing (NLP), and Computer Networks. Within each field, privacy has its own formulation. Though pioneering works on attacks and defenses reveal sensitive privacy issues, they are narrowly trapped and cannot fully cover people's actual privacy concerns. Consequently, the research on general and human-centric privacy research remains rather unexplored. In this paper, we formulate the privacy issue as a reasoning problem rather than simple pattern matching. We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context. Based on such an assumption, we develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations. Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations. Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to personally identifiable information (PII). We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards.","sentences":["Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications.","Computer science researchers, on the other hand, commonly study privacy issues through privacy attacks and defenses on segmented fields.","Privacy research is conducted on various sub-fields, including Computer Vision (CV), Natural Language Processing (NLP), and Computer Networks.","Within each field, privacy has its own formulation.","Though pioneering works on attacks and defenses reveal sensitive privacy issues, they are narrowly trapped and cannot fully cover people's actual privacy concerns.","Consequently, the research on general and human-centric privacy research remains rather unexplored.","In this paper, we formulate the privacy issue as a reasoning problem rather than simple pattern matching.","We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context.","Based on such an assumption, we develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations.","Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations.","Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to personally identifiable information (PII).","We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards."],"url":"http://arxiv.org/abs/2408.10053v1"}
{"created":"2024-08-19 14:38:27","title":"Exploiting Fine-Grained Prototype Distribution for Boosting Unsupervised Class Incremental Learning","abstract":"The dynamic nature of open-world scenarios has attracted more attention to class incremental learning (CIL). However, existing CIL methods typically presume the availability of complete ground-truth labels throughout the training process, an assumption rarely met in practical applications. Consequently, this paper explores a more challenging problem of unsupervised class incremental learning (UCIL). The essence of addressing this problem lies in effectively capturing comprehensive feature representations and discovering unknown novel classes. To achieve this, we first model the knowledge of class distribution by exploiting fine-grained prototypes. Subsequently, a granularity alignment technique is introduced to enhance the unsupervised class discovery. Additionally, we proposed a strategy to minimize overlap between novel and existing classes, thereby preserving historical knowledge and mitigating the phenomenon of catastrophic forgetting. Extensive experiments on the five datasets demonstrate that our approach significantly outperforms current state-of-the-art methods, indicating the effectiveness of the proposed method.","sentences":["The dynamic nature of open-world scenarios has attracted more attention to class incremental learning (CIL).","However, existing CIL methods typically presume the availability of complete ground-truth labels throughout the training process, an assumption rarely met in practical applications.","Consequently, this paper explores a more challenging problem of unsupervised class incremental learning (UCIL).","The essence of addressing this problem lies in effectively capturing comprehensive feature representations and discovering unknown novel classes.","To achieve this, we first model the knowledge of class distribution by exploiting fine-grained prototypes.","Subsequently, a granularity alignment technique is introduced to enhance the unsupervised class discovery.","Additionally, we proposed a strategy to minimize overlap between novel and existing classes, thereby preserving historical knowledge and mitigating the phenomenon of catastrophic forgetting.","Extensive experiments on the five datasets demonstrate that our approach significantly outperforms current state-of-the-art methods, indicating the effectiveness of the proposed method."],"url":"http://arxiv.org/abs/2408.10046v1"}
{"created":"2024-08-19 14:34:36","title":"Stacked Intelligent Metasurfaces for Integrated Sensing and Communications","abstract":"Stacked intelligent metasurfaces (SIM) have recently emerged as a promising technology, which can realize transmit precoding in the wave domain. In this paper, we investigate a SIM-aided integrated sensing and communications system, in which SIM is capable of generating a desired beam pattern for simultaneously communicating with multiple downlink users and detecting a radar target. Specifically, we formulate an optimization problem of maximizing the spectrum efficiency, while satisfying the power constraint of the desired direction. This requires jointly designing the phase shifts of the SIM and the power allocation at the base station. By incorporating the sensing power constraint into the objective functions as a penalty term, we further simplify the optimization problem and solve it by customizing an efficient gradient ascent algorithm. Finally, extensive numerical results demonstrate the effectiveness of the proposed wave-domain precoder for automatically mitigating the inter-user interference and generating a desired beampattern for the sensing task, as multiple separate data streams transmit through the SIM.","sentences":["Stacked intelligent metasurfaces (SIM) have recently emerged as a promising technology, which can realize transmit precoding in the wave domain.","In this paper, we investigate a SIM-aided integrated sensing and communications system, in which SIM is capable of generating a desired beam pattern for simultaneously communicating with multiple downlink users and detecting a radar target.","Specifically, we formulate an optimization problem of maximizing the spectrum efficiency, while satisfying the power constraint of the desired direction.","This requires jointly designing the phase shifts of the SIM and the power allocation at the base station.","By incorporating the sensing power constraint into the objective functions as a penalty term, we further simplify the optimization problem and solve it by customizing an efficient gradient ascent algorithm.","Finally, extensive numerical results demonstrate the effectiveness of the proposed wave-domain precoder for automatically mitigating the inter-user interference and generating a desired beampattern for the sensing task, as multiple separate data streams transmit through the SIM."],"url":"http://arxiv.org/abs/2408.10043v1"}
{"created":"2024-08-19 14:34:17","title":"Implicit Gaussian Splatting with Efficient Multi-Level Tri-Plane Representation","abstract":"Recent advancements in photo-realistic novel view synthesis have been significantly driven by Gaussian Splatting (3DGS). Nevertheless, the explicit nature of 3DGS data entails considerable storage requirements, highlighting a pressing need for more efficient data representations. To address this, we present Implicit Gaussian Splatting (IGS), an innovative hybrid model that integrates explicit point clouds with implicit feature embeddings through a multi-level tri-plane architecture. This architecture features 2D feature grids at various resolutions across different levels, facilitating continuous spatial domain representation and enhancing spatial correlations among Gaussian primitives. Building upon this foundation, we introduce a level-based progressive training scheme, which incorporates explicit spatial regularization. This method capitalizes on spatial correlations to enhance both the rendering quality and the compactness of the IGS representation. Furthermore, we propose a novel compression pipeline tailored for both point clouds and 2D feature grids, considering the entropy variations across different levels. Extensive experimental evaluations demonstrate that our algorithm can deliver high-quality rendering using only a few MBs, effectively balancing storage efficiency and rendering fidelity, and yielding results that are competitive with the state-of-the-art.","sentences":["Recent advancements in photo-realistic novel view synthesis have been significantly driven by Gaussian Splatting (3DGS).","Nevertheless, the explicit nature of 3DGS data entails considerable storage requirements, highlighting a pressing need for more efficient data representations.","To address this, we present Implicit Gaussian Splatting (IGS), an innovative hybrid model that integrates explicit point clouds with implicit feature embeddings through a multi-level tri-plane architecture.","This architecture features 2D feature grids at various resolutions across different levels, facilitating continuous spatial domain representation and enhancing spatial correlations among Gaussian primitives.","Building upon this foundation, we introduce a level-based progressive training scheme, which incorporates explicit spatial regularization.","This method capitalizes on spatial correlations to enhance both the rendering quality and the compactness of the IGS representation.","Furthermore, we propose a novel compression pipeline tailored for both point clouds and 2D feature grids, considering the entropy variations across different levels.","Extensive experimental evaluations demonstrate that our algorithm can deliver high-quality rendering using only a few MBs, effectively balancing storage efficiency and rendering fidelity, and yielding results that are competitive with the state-of-the-art."],"url":"http://arxiv.org/abs/2408.10041v1"}
{"created":"2024-08-19 14:32:21","title":"The Practimum-Optimum Algorithm for Manufacturing Scheduling: A Paradigm Shift Leading to Breakthroughs in Scale and Performance","abstract":"The Practimum-Optimum (P-O) algorithm represents a paradigm shift in developing automatic optimization products for complex real-life business problems such as large-scale manufacturing scheduling. It leverages deep business domain expertise to create a group of virtual human expert (VHE) agents with different \"schools of thought\" on how to create high-quality schedules. By computerizing them into algorithms, P-O generates many valid schedules at far higher speeds than human schedulers are capable of. Initially, these schedules can also be local optimum peaks far away from high-quality schedules. By submitting these schedules to a reinforced machine learning algorithm (RL), P-O learns the weaknesses and strengths of each VHE schedule, and accordingly derives reward and punishment changes in the Demand Set that will modify the relative priorities for time and resource allocation that jobs received in the prior iteration that led to the current state of the schedule. These cause the core logic of the VHE algorithms to explore, in the subsequent iteration, substantially different parts of the schedules universe and potentially find higher-quality schedules. Using the hill climbing analogy, this may be viewed as a big jump, shifting from a given local peak to a faraway promising start point equipped with knowledge embedded in the demand set for future iterations. This is a fundamental difference from most contemporary algorithms, which spend considerable time on local micro-steps restricted to the neighbourhoods of local peaks they visit. This difference enables a breakthrough in scale and performance for fully automatic manufacturing scheduling in complex organizations. The P-O algorithm is at the heart of Plataine Scheduler that, in one click, routinely schedules 30,000-50,000 tasks for real-life complex manufacturing operations.","sentences":["The Practimum-Optimum (P-O) algorithm represents a paradigm shift in developing automatic optimization products for complex real-life business problems such as large-scale manufacturing scheduling.","It leverages deep business domain expertise to create a group of virtual human expert (VHE) agents with different \"schools of thought\" on how to create high-quality schedules.","By computerizing them into algorithms, P-O generates many valid schedules at far higher speeds than human schedulers are capable of.","Initially, these schedules can also be local optimum peaks far away from high-quality schedules.","By submitting these schedules to a reinforced machine learning algorithm (RL), P-O learns the weaknesses and strengths of each VHE schedule, and accordingly derives reward and punishment changes in the Demand Set that will modify the relative priorities for time and resource allocation that jobs received in the prior iteration that led to the current state of the schedule.","These cause the core logic of the VHE algorithms to explore, in the subsequent iteration, substantially different parts of the schedules universe and potentially find higher-quality schedules.","Using the hill climbing analogy, this may be viewed as a big jump, shifting from a given local peak to a faraway promising start point equipped with knowledge embedded in the demand set for future iterations.","This is a fundamental difference from most contemporary algorithms, which spend considerable time on local micro-steps restricted to the neighbourhoods of local peaks they visit.","This difference enables a breakthrough in scale and performance for fully automatic manufacturing scheduling in complex organizations.","The P-O algorithm is at the heart of Plataine Scheduler that, in one click, routinely schedules 30,000-50,000 tasks for real-life complex manufacturing operations."],"url":"http://arxiv.org/abs/2408.10040v1"}
{"created":"2024-08-19 14:31:57","title":"MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis","abstract":"Clinical diagnosis is critical in medical practice, typically requiring a continuous and evolving process that includes primary diagnosis, differential diagnosis, and final diagnosis. However, most existing clinical diagnostic tasks are single-step processes, which does not align with the complex multi-step diagnostic procedures found in real-world clinical settings. In this paper, we propose a multi-step diagnostic task and annotate a clinical diagnostic dataset (MSDiagnosis). This dataset includes primary diagnosis, differential diagnosis, and final diagnosis questions. Additionally, we propose a novel and effective framework. This framework combines forward inference, backward inference, reflection, and refinement, enabling the LLM to self-evaluate and adjust its diagnostic results. To assess the effectiveness of our proposed method, we design and conduct extensive experiments. The experimental results demonstrate the effectiveness of the proposed method. We also provide a comprehensive experimental analysis and suggest future research directions for this task.","sentences":["Clinical diagnosis is critical in medical practice, typically requiring a continuous and evolving process that includes primary diagnosis, differential diagnosis, and final diagnosis.","However, most existing clinical diagnostic tasks are single-step processes, which does not align with the complex multi-step diagnostic procedures found in real-world clinical settings.","In this paper, we propose a multi-step diagnostic task and annotate a clinical diagnostic dataset (MSDiagnosis).","This dataset includes primary diagnosis, differential diagnosis, and final diagnosis questions.","Additionally, we propose a novel and effective framework.","This framework combines forward inference, backward inference, reflection, and refinement, enabling the LLM to self-evaluate and adjust its diagnostic results.","To assess the effectiveness of our proposed method, we design and conduct extensive experiments.","The experimental results demonstrate the effectiveness of the proposed method.","We also provide a comprehensive experimental analysis and suggest future research directions for this task."],"url":"http://arxiv.org/abs/2408.10039v1"}
{"created":"2024-08-19 14:30:29","title":"SHARP: Segmentation of Hands and Arms by Range using Pseudo-Depth for Enhanced Egocentric 3D Hand Pose Estimation and Action Recognition","abstract":"Hand pose represents key information for action recognition in the egocentric perspective, where the user is interacting with objects. We propose to improve egocentric 3D hand pose estimation based on RGB frames only by using pseudo-depth images. Incorporating state-of-the-art single RGB image depth estimation techniques, we generate pseudo-depth representations of the frames and use distance knowledge to segment irrelevant parts of the scene. The resulting depth maps are then used as segmentation masks for the RGB frames. Experimental results on H2O Dataset confirm the high accuracy of the estimated pose with our method in an action recognition task. The 3D hand pose, together with information from object detection, is processed by a transformer-based action recognition network, resulting in an accuracy of 91.73%, outperforming all state-of-the-art methods. Estimations of 3D hand pose result in competitive performance with existing methods with a mean pose error of 28.66 mm. This method opens up new possibilities for employing distance information in egocentric 3D hand pose estimation without relying on depth sensors.","sentences":["Hand pose represents key information for action recognition in the egocentric perspective, where the user is interacting with objects.","We propose to improve egocentric 3D hand pose estimation based on RGB frames only by using pseudo-depth images.","Incorporating state-of-the-art single RGB image depth estimation techniques, we generate pseudo-depth representations of the frames and use distance knowledge to segment irrelevant parts of the scene.","The resulting depth maps are then used as segmentation masks for the RGB frames.","Experimental results on H2O Dataset confirm the high accuracy of the estimated pose with our method in an action recognition task.","The 3D hand pose, together with information from object detection, is processed by a transformer-based action recognition network, resulting in an accuracy of 91.73%, outperforming all state-of-the-art methods.","Estimations of 3D hand pose result in competitive performance with existing methods with a mean pose error of 28.66 mm.","This method opens up new possibilities for employing distance information in egocentric 3D hand pose estimation without relying on depth sensors."],"url":"http://arxiv.org/abs/2408.10037v1"}
{"created":"2024-08-19 14:24:46","title":"Dynamic Label Injection for Imbalanced Industrial Defect Segmentation","abstract":"In this work, we propose a simple yet effective method to tackle the problem of imbalanced multi-class semantic segmentation in deep learning systems. One of the key properties for a good training set is the balancing among the classes. When the input distribution is heavily imbalanced in the number of instances, the learning process could be hindered or difficult to carry on. To this end, we propose a Dynamic Label Injection (DLI) algorithm to impose a uniform distribution in the input batch. Our algorithm computes the current batch defect distribution and re-balances it by transferring defects using a combination of Poisson-based seamless image cloning and cut-paste techniques. A thorough experimental section on the Magnetic Tiles dataset shows better results of DLI compared to other balancing loss approaches also in the challenging weakly-supervised setup. The code is available at https://github.com/covisionlab/dynamic-label-injection.git","sentences":["In this work, we propose a simple yet effective method to tackle the problem of imbalanced multi-class semantic segmentation in deep learning systems.","One of the key properties for a good training set is the balancing among the classes.","When the input distribution is heavily imbalanced in the number of instances, the learning process could be hindered or difficult to carry on.","To this end, we propose a Dynamic Label Injection (DLI) algorithm to impose a uniform distribution in the input batch.","Our algorithm computes the current batch defect distribution and re-balances it by transferring defects using a combination of Poisson-based seamless image cloning and cut-paste techniques.","A thorough experimental section on the Magnetic Tiles dataset shows better results of DLI compared to other balancing loss approaches also in the challenging weakly-supervised setup.","The code is available at https://github.com/covisionlab/dynamic-label-injection.git"],"url":"http://arxiv.org/abs/2408.10031v1"}
{"created":"2024-08-19 14:23:24","title":"The Expressive Power of Uniform Population Protocols with Logarithmic Space","abstract":"Population protocols are a model of computation in which indistinguishable mobile agents interact in pairs to decide a property of their initial configuration. Originally introduced by Angluin et. al. in 2004 with a constant number of states, research nowadays focuses on protocols where the space usage depends on the number of agents. The expressive power of population protocols has so far however only been determined for protocols using $o(\\log n)$ states, which compute only semilinear predicates, and for $\\Omega(n)$ states. This leaves a significant gap, particularly concerning protocols with $\\Theta(\\log n)$ or $\\Theta(\\operatorname{polylog} n)$ states, which are the most common constructions in the literature. In this paper we close the gap and prove that for any $\\varepsilon>0$ and $f\\in\\Omega(\\log n)\\cap\\mathcal{O}(n^{1-\\varepsilon})$, both uniform and non-uniform population protocols with $\\Theta(f(n))$ states can decide exactly $\\mathsf{NSPACE}(f(n) \\log n)$.","sentences":["Population protocols are a model of computation in which indistinguishable mobile agents interact in pairs to decide a property of their initial configuration.","Originally introduced by Angluin et.","al.","in 2004 with a constant number of states, research nowadays focuses on protocols where the space usage depends on the number of agents.","The expressive power of population protocols has so far however only been determined for protocols using $o(\\log n)$ states, which compute only semilinear predicates, and for $\\Omega(n)$ states.","This leaves a significant gap, particularly concerning protocols with $\\Theta(\\log n)$ or $\\Theta(\\operatorname{polylog} n)$ states, which are the most common constructions in the literature.","In this paper we close the gap and prove that for any $\\varepsilon>0$ and $f\\in\\Omega(\\log n)\\cap\\mathcal{O}(n^{1-\\varepsilon})$, both uniform and non-uniform population protocols with $\\Theta(f(n))$ states can decide exactly $\\mathsf{NSPACE}(f(n) \\log n)$."],"url":"http://arxiv.org/abs/2408.10027v1"}
{"created":"2024-08-19 14:22:14","title":"Defense Priorities in the Open-Source AI Debate: A Preliminary Assessment","abstract":"A spirited debate is taking place over the regulation of open foundation models: artificial intelligence models whose underlying architectures and parameters are made public and can be inspected, modified, and run by end users. Proposed limits on releasing open foundation models may have significant defense industrial impacts. If model training is a form of defense production, these impacts deserve further scrutiny. Preliminary evidence suggests that an open foundation model ecosystem could benefit the U.S. Department of Defense's supplier diversity, sustainment, cybersecurity, and innovation priorities. Follow-on analyses should quantify impacts on acquisition cost and supply chain security.","sentences":["A spirited debate is taking place over the regulation of open foundation models: artificial intelligence models whose underlying architectures and parameters are made public and can be inspected, modified, and run by end users.","Proposed limits on releasing open foundation models may have significant defense industrial impacts.","If model training is a form of defense production, these impacts deserve further scrutiny.","Preliminary evidence suggests that an open foundation model ecosystem could benefit the U.S. Department of Defense's supplier diversity, sustainment, cybersecurity, and innovation priorities.","Follow-on analyses should quantify impacts on acquisition cost and supply chain security."],"url":"http://arxiv.org/abs/2408.10026v1"}
{"created":"2024-08-19 14:18:21","title":"Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing","abstract":"In the realm of Federated Learning (FL), particularly within the manufacturing sector, the strategy for selecting client weights for server aggregation is pivotal for model performance. This study investigates the comparative effectiveness of two weight selection strategies: Final Epoch Weight Selection (FEWS) and Optimal Epoch Weight Selection (OEWS). Designed for manufacturing contexts where collaboration typically involves a limited number of partners (two to four clients), our research focuses on federated image classification tasks. We employ various neural network architectures, including EfficientNet, ResNet, and VGG, to assess the impact of these weight selection strategies on model convergence and robustness.   Our research aims to determine whether FEWS or OEWS enhances the global FL model's performance across communication rounds (CRs). Through empirical analysis and rigorous experimentation, we seek to provide valuable insights for optimizing FL implementations in manufacturing, ensuring that collaborative efforts yield the most effective and reliable models with a limited number of participating clients. The findings from this study are expected to refine FL practices significantly in manufacturing, thereby enhancing the efficiency and performance of collaborative machine learning endeavors in this vital sector.","sentences":["In the realm of Federated Learning (FL), particularly within the manufacturing sector, the strategy for selecting client weights for server aggregation is pivotal for model performance.","This study investigates the comparative effectiveness of two weight selection strategies: Final Epoch Weight Selection (FEWS) and Optimal Epoch Weight Selection (OEWS).","Designed for manufacturing contexts where collaboration typically involves a limited number of partners (two to four clients), our research focuses on federated image classification tasks.","We employ various neural network architectures, including EfficientNet, ResNet, and VGG, to assess the impact of these weight selection strategies on model convergence and robustness.   ","Our research aims to determine whether FEWS or OEWS enhances the global FL model's performance across communication rounds (CRs).","Through empirical analysis and rigorous experimentation, we seek to provide valuable insights for optimizing FL implementations in manufacturing, ensuring that collaborative efforts yield the most effective and reliable models with a limited number of participating clients.","The findings from this study are expected to refine FL practices significantly in manufacturing, thereby enhancing the efficiency and performance of collaborative machine learning endeavors in this vital sector."],"url":"http://arxiv.org/abs/2408.10024v1"}
{"created":"2024-08-19 14:13:30","title":"Detecting Adversarial Attacks in Semantic Segmentation via Uncertainty Estimation: A Deep Analysis","abstract":"Deep neural networks have demonstrated remarkable effectiveness across a wide range of tasks such as semantic segmentation. Nevertheless, these networks are vulnerable to adversarial attacks that add imperceptible perturbations to the input image, leading to false predictions. This vulnerability is particularly dangerous in safety-critical applications like automated driving. While adversarial examples and defense strategies are well-researched in the context of image classification, there is comparatively less research focused on semantic segmentation. Recently, we have proposed an uncertainty-based method for detecting adversarial attacks on neural networks for semantic segmentation. We observed that uncertainty, as measured by the entropy of the output distribution, behaves differently on clean versus adversely perturbed images, and we utilize this property to differentiate between the two. In this extended version of our work, we conduct a detailed analysis of uncertainty-based detection of adversarial attacks including a diverse set of adversarial attacks and various state-of-the-art neural networks. Our numerical experiments show the effectiveness of the proposed uncertainty-based detection method, which is lightweight and operates as a post-processing step, i.e., no model modifications or knowledge of the adversarial example generation process are required.","sentences":["Deep neural networks have demonstrated remarkable effectiveness across a wide range of tasks such as semantic segmentation.","Nevertheless, these networks are vulnerable to adversarial attacks that add imperceptible perturbations to the input image, leading to false predictions.","This vulnerability is particularly dangerous in safety-critical applications like automated driving.","While adversarial examples and defense strategies are well-researched in the context of image classification, there is comparatively less research focused on semantic segmentation.","Recently, we have proposed an uncertainty-based method for detecting adversarial attacks on neural networks for semantic segmentation.","We observed that uncertainty, as measured by the entropy of the output distribution, behaves differently on clean versus adversely perturbed images, and we utilize this property to differentiate between the two.","In this extended version of our work, we conduct a detailed analysis of uncertainty-based detection of adversarial attacks including a diverse set of adversarial attacks and various state-of-the-art neural networks.","Our numerical experiments show the effectiveness of the proposed uncertainty-based detection method, which is lightweight and operates as a post-processing step, i.e., no model modifications or knowledge of the adversarial example generation process are required."],"url":"http://arxiv.org/abs/2408.10021v1"}
{"created":"2024-08-19 14:12:20","title":"\"EBK\" : Leveraging Crowd-Sourced Social Media Data to Quantify How Hyperlocal Gang Affiliations Shape Personal Networks and Violence in Chicago's Contemporary Southside","abstract":"Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang \"set\" factions and cross-gang interpersonal networks marking the contemporary landscape. However, standard police datasets lack the depth to analyze gang violence with such granularity. To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board. By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets. Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal. Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation. This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations.","sentences":["Recent ethnographic research reveals that gang dynamics in Chicago's Southside have evolved with decentralized micro-gang \"set\" factions and cross-gang interpersonal networks marking the contemporary landscape.","However, standard police datasets lack the depth to analyze gang violence with such granularity.","To address this, we employed a natural language processing strategy to analyze text from a Chicago gangs message board.","By identifying proper nouns, probabilistically linking them to gang sets, and assuming social connections among names mentioned together, we created a social network dataset of 271 individuals across 11 gang sets.","Using Louvain community detection, we found that these individuals often connect with gang-affiliated peers from various gang sets that are physically proximal.","Hierarchical logistic regression revealed that individuals with ties to homicide victims and central positions in the overall gang network were at increased risk of victimization, regardless of gang affiliation.","This research demonstrates that utilizing crowd-sourced information online can enable the study of otherwise inaccessible topics and populations."],"url":"http://arxiv.org/abs/2408.10018v1"}
{"created":"2024-08-19 14:11:04","title":"Deterministic Policy Gradient Primal-Dual Methods for Continuous-Space Constrained MDPs","abstract":"We study the problem of computing deterministic optimal policies for constrained Markov decision processes (MDPs) with continuous state and action spaces, which are widely encountered in constrained dynamical systems. Designing deterministic policy gradient methods in continuous state and action spaces is particularly challenging due to the lack of enumerable state-action pairs and the adoption of deterministic policies, hindering the application of existing policy gradient methods for constrained MDPs. To this end, we develop a deterministic policy gradient primal-dual method to find an optimal deterministic policy with non-asymptotic convergence. Specifically, we leverage regularization of the Lagrangian of the constrained MDP to propose a deterministic policy gradient primal-dual (D-PGPD) algorithm that updates the deterministic policy via a quadratic-regularized gradient ascent step and the dual variable via a quadratic-regularized gradient descent step. We prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair. We instantiate D-PGPD with function approximation and prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair, up to a function approximation error. Furthermore, we demonstrate the effectiveness of our method in two continuous control problems: robot navigation and fluid control. To the best of our knowledge, this appears to be the first work that proposes a deterministic policy search method for continuous-space constrained MDPs.","sentences":["We study the problem of computing deterministic optimal policies for constrained Markov decision processes (MDPs) with continuous state and action spaces, which are widely encountered in constrained dynamical systems.","Designing deterministic policy gradient methods in continuous state and action spaces is particularly challenging due to the lack of enumerable state-action pairs and the adoption of deterministic policies, hindering the application of existing policy gradient methods for constrained MDPs.","To this end, we develop a deterministic policy gradient primal-dual method to find an optimal deterministic policy with non-asymptotic convergence.","Specifically, we leverage regularization of the Lagrangian of the constrained MDP to propose a deterministic policy gradient primal-dual (D-PGPD) algorithm that updates the deterministic policy via a quadratic-regularized gradient ascent step and the dual variable via a quadratic-regularized gradient descent step.","We prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair.","We instantiate D-PGPD with function approximation and prove that the primal-dual iterates of D-PGPD converge at a sub-linear rate to an optimal regularized primal-dual pair, up to a function approximation error.","Furthermore, we demonstrate the effectiveness of our method in two continuous control problems: robot navigation and fluid control.","To the best of our knowledge, this appears to be the first work that proposes a deterministic policy search method for continuous-space constrained MDPs."],"url":"http://arxiv.org/abs/2408.10015v1"}
{"created":"2024-08-19 14:10:41","title":"Improved Distance (Sensitivity) Oracles with Subquadratic Space","abstract":"A distance oracle (DO) with stretch $(\\alpha, \\beta)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\\widehat{d}(s,t)$ such that $d(s,t) \\le \\widehat{d}(s,t) \\le \\alpha \\cdot d(s,t) + \\beta$. An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs. Introducing a small additive stretch $\\beta > 0$ allows us to make the multiplicative stretch $\\alpha$ arbitrarily small. This sidesteps a known lower bound of $\\alpha \\ge 3$ (for $\\beta = 0$ and subquadratic space) [Thorup & Zwick, JACM 2005]. We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \\in (0, \\ell/2]$, has stretch $(1{+}\\frac{1}{\\ell}, 2W)$, space $\\widetilde{O}(n^{2-\\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\\epsilon, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs. Our second contribution is a framework that turns a $(\\alpha,\\beta)$-stretch DO for unweighted graphs into an $(\\alpha (1{+}\\varepsilon),\\beta)$-stretch $f$-DSO with sensitivity $f = o(\\log(n)/\\log\\log n)$ and retains subquadratic space. This generalizes a result by Bil\\`o, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck [STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\\gamma \\in (0, (\\ell{+}1)/2]$, has stretch $((1{+}\\frac{1}{\\ell}) (1{+}\\varepsilon), 2)$, space $n^{ 2- \\frac{\\gamma}{(\\ell+1)(f+1)} + o(1)}/\\varepsilon^{f+2}$, and query time $\\widetilde{O}(n^{\\gamma} /{\\varepsilon}^2)$.","sentences":["A distance oracle (DO) with stretch $(\\alpha, \\beta)$ for a graph $G$ is a data structure that, when queried with vertices $s$ and $t$, returns a value $\\widehat{d}(s,t)$ such that $d(s,t) \\le \\widehat{d}(s,t) \\le \\alpha \\cdot d(s,t)","+","\\beta$.","An $f$-edge fault-tolerant distance sensitivity oracle ($f$-DSO) additionally receives a set $F$ of up to $f$ edges and estimates the $s$-$t$-distance in $G{-}F$. Our first contribution is a new distance oracle with subquadratic space for undirected graphs.","Introducing a small additive stretch $\\beta > 0$ allows us to make the multiplicative stretch $\\alpha$ arbitrarily small.","This sidesteps a known lower bound of $\\alpha \\ge 3$ (for $\\beta = 0$ and subquadratic space)","[Thorup & Zwick, JACM 2005].","We present a DO for graphs with edge weights in $[0,W]$ that, for any positive integer $t$ and any $c \\in (0, \\ell/2]$, has stretch $(1{+}\\frac{1}{\\ell}, 2W)$, space $\\widetilde{O}(n^{2-\\frac{c}{t}})$, and query time $O(n^c)$. These are the first subquadratic-space DOs with $(1+\\epsilon, O(1))$-stretch generalizing Agarwal and Godfrey's results for sparse graphs [SODA 2013] to general undirected graphs.","Our second contribution is a framework that turns a $(\\alpha,\\beta)$-stretch DO for unweighted graphs into an $(\\alpha (1{+}\\varepsilon),\\beta)$-stretch $f$-DSO with sensitivity $f = o(\\log(n)/\\log\\log n)$ and retains subquadratic space.","This generalizes a result by Bil\\`o, Chechik, Choudhary, Cohen, Friedrich, Krogmann, and Schirneck","[STOC 2023, TheoretiCS 2024] for the special case of stretch $(3,0)$ and $f = O(1)$. By combining the framework with our new distance oracle, we obtain an $f$-DSO that, for any $\\gamma \\in (0, (\\ell{+}1)/2]$, has stretch $((1{+}\\frac{1}{\\ell})","(1{+}\\varepsilon), 2)$, space $n^{","2- \\frac{\\gamma}{(\\ell+1)(f+1)}","+ o(1)}/\\varepsilon^{f+2}$, and query time $\\widetilde{O}(n^{\\gamma} /{\\varepsilon}^2)$."],"url":"http://arxiv.org/abs/2408.10014v1"}
{"created":"2024-08-19 14:09:48","title":"TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading","abstract":"The growth rate of the GPU memory capacity has not been able to keep up with that of the size of large language models (LLMs), hindering the model training process. In particular, activations -- the intermediate tensors produced during forward propagation and reused in backward propagation -- dominate the GPU memory use. To address this challenge, we propose TBA to efficiently offload activations to high-capacity NVMe SSDs. This approach reduces GPU memory usage without impacting performance by adaptively overlapping data transfers with computation. TBA is compatible with popular deep learning frameworks like PyTorch, Megatron, and DeepSpeed, and it employs techniques such as tensor deduplication, forwarding, and adaptive offloading to further enhance efficiency. We conduct extensive experiments on GPT, BERT, and T5. Results demonstrate that TBA effectively reduces 47% of the activation peak memory usage. At the same time, TBA perfectly overlaps the I/O with the computation and incurs negligible performance overhead. We introduce the recompute-offload-keep (ROK) curve to compare the TBA offloading with other two tensor placement strategies, keeping activations in memory and layerwise full recomputation. We find that TBA achieves better memory savings than layerwise full recomputation while retaining the performance of keeping the activations in memory.","sentences":["The growth rate of the GPU memory capacity has not been able to keep up with that of the size of large language models (LLMs), hindering the model training process.","In particular, activations -- the intermediate tensors produced during forward propagation and reused in backward propagation -- dominate the GPU memory use.","To address this challenge, we propose TBA to efficiently offload activations to high-capacity NVMe SSDs.","This approach reduces GPU memory usage without impacting performance by adaptively overlapping data transfers with computation.","TBA is compatible with popular deep learning frameworks like PyTorch, Megatron, and DeepSpeed, and it employs techniques such as tensor deduplication, forwarding, and adaptive offloading to further enhance efficiency.","We conduct extensive experiments on GPT, BERT, and T5.","Results demonstrate that TBA effectively reduces 47% of the activation peak memory usage.","At the same time, TBA perfectly overlaps the I/O with the computation and incurs negligible performance overhead.","We introduce the recompute-offload-keep (ROK) curve to compare the TBA offloading with other two tensor placement strategies, keeping activations in memory and layerwise full recomputation.","We find that TBA achieves better memory savings than layerwise full recomputation while retaining the performance of keeping the activations in memory."],"url":"http://arxiv.org/abs/2408.10013v1"}
{"created":"2024-08-19 14:05:58","title":"CLIPCleaner: Cleaning Noisy Labels with CLIP","abstract":"Learning with Noisy labels (LNL) poses a significant challenge for the Machine Learning community. Some of the most widely used approaches that select as clean samples for which the model itself (the in-training model) has high confidence, e.g., `small loss', can suffer from the so called `self-confirmation' bias. This bias arises because the in-training model, is at least partially trained on the noisy labels. Furthermore, in the classification case, an additional challenge arises because some of the label noise is between classes that are visually very similar (`hard noise'). This paper addresses these challenges by proposing a method (\\textit{CLIPCleaner}) that leverages CLIP, a powerful Vision-Language (VL) model for constructing a zero-shot classifier for efficient, offline, clean sample selection. This has the advantage that the sample selection is decoupled from the in-training model and that the sample selection is aware of the semantic and visual similarities between the classes due to the way that CLIP is trained. We provide theoretical justifications and empirical evidence to demonstrate the advantages of CLIP for LNL compared to conventional pre-trained models. Compared to current methods that combine iterative sample selection with various techniques, \\textit{CLIPCleaner} offers a simple, single-step approach that achieves competitive or superior performance on benchmark datasets. To the best of our knowledge, this is the first time a VL model has been used for sample selection to address the problem of Learning with Noisy Labels (LNL), highlighting their potential in the domain.","sentences":["Learning with Noisy labels (LNL) poses a significant challenge for the Machine Learning community.","Some of the most widely used approaches that select as clean samples for which the model itself (the in-training model) has high confidence, e.g., `small loss', can suffer from the so called `self-confirmation' bias.","This bias arises because the in-training model, is at least partially trained on the noisy labels.","Furthermore, in the classification case, an additional challenge arises because some of the label noise is between classes that are visually very similar (`hard noise').","This paper addresses these challenges by proposing a method (\\textit{CLIPCleaner}) that leverages CLIP, a powerful Vision-Language (VL) model for constructing a zero-shot classifier for efficient, offline, clean sample selection.","This has the advantage that the sample selection is decoupled from the in-training model and that the sample selection is aware of the semantic and visual similarities between the classes due to the way that CLIP is trained.","We provide theoretical justifications and empirical evidence to demonstrate the advantages of CLIP for LNL compared to conventional pre-trained models.","Compared to current methods that combine iterative sample selection with various techniques, \\textit{CLIPCleaner} offers a simple, single-step approach that achieves competitive or superior performance on benchmark datasets.","To the best of our knowledge, this is the first time a VL model has been used for sample selection to address the problem of Learning with Noisy Labels (LNL), highlighting their potential in the domain."],"url":"http://arxiv.org/abs/2408.10012v1"}
{"created":"2024-08-19 14:05:28","title":"PinnDE: Physics-Informed Neural Networks for Solving Differential Equations","abstract":"In recent years the study of deep learning for solving differential equations has grown substantially. The use of physics-informed neural networks (PINNs) and deep operator networks (DeepONets) have emerged as two of the most useful approaches in approximating differential equation solutions using machine learning. Here, we propose PinnDE, an open-source python library for solving differential equations with both PINNs and DeepONets. We give a brief review of both PINNs and DeepONets, introduce PinnDE along with the structure and usage of the package, and present worked examples to show PinnDE's effectiveness in approximating solutions with both PINNs and DeepONets.","sentences":["In recent years the study of deep learning for solving differential equations has grown substantially.","The use of physics-informed neural networks (PINNs) and deep operator networks (DeepONets) have emerged as two of the most useful approaches in approximating differential equation solutions using machine learning.","Here, we propose PinnDE, an open-source python library for solving differential equations with both PINNs and DeepONets.","We give a brief review of both PINNs and DeepONets, introduce PinnDE along with the structure and usage of the package, and present worked examples to show PinnDE's effectiveness in approximating solutions with both PINNs and DeepONets."],"url":"http://arxiv.org/abs/2408.10011v1"}
{"created":"2024-08-19 13:59:53","title":"P3P: Pseudo-3D Pre-training for Scaling 3D Masked Autoencoders","abstract":"3D pre-training is crucial to 3D perception tasks. However, limited by the difficulties in collecting clean 3D data, 3D pre-training consistently faced data scaling challenges. Inspired by semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data, in this work, we propose a novel self-supervised pre-training framework utilizing the real 3D data and the pseudo-3D data lifted from images by a large depth estimation model. Another challenge lies in the efficiency. Previous methods such as Point-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens, requiring quadratic time complexity. To efficiently pre-train on such a large amount of data, we propose a linear-time-complexity token embedding strategy and a training-efficient 2D reconstruction target. Our method achieves state-of-the-art performance in 3D classification and few-shot learning while maintaining high pre-training and downstream fine-tuning efficiency.","sentences":["3D pre-training is crucial to 3D perception tasks.","However, limited by the difficulties in collecting clean 3D data, 3D pre-training consistently faced data scaling challenges.","Inspired by semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data, in this work, we propose a novel self-supervised pre-training framework utilizing the real 3D data and the pseudo-3D data lifted from images by a large depth estimation model.","Another challenge lies in the efficiency.","Previous methods such as Point-BERT and Point-MAE, employ k nearest neighbors to embed 3D tokens, requiring quadratic time complexity.","To efficiently pre-train on such a large amount of data, we propose a linear-time-complexity token embedding strategy and a training-efficient 2D reconstruction target.","Our method achieves state-of-the-art performance in 3D classification and few-shot learning while maintaining high pre-training and downstream fine-tuning efficiency."],"url":"http://arxiv.org/abs/2408.10007v1"}
{"created":"2024-08-19 13:59:26","title":"Unlocking the Power of LSTM for Long Term Time Series Forecasting","abstract":"Traditional recurrent neural network architectures, such as long short-term memory neural networks (LSTM), have historically held a prominent role in time series forecasting (TSF) tasks. While the recently introduced sLSTM for Natural Language Processing (NLP) introduces exponential gating and memory mixing that are beneficial for long term sequential learning, its potential short memory issue is a barrier to applying sLSTM directly in TSF. To address this, we propose a simple yet efficient algorithm named P-sLSTM, which is built upon sLSTM by incorporating patching and channel independence. These modifications substantially enhance sLSTM's performance in TSF, achieving state-of-the-art results. Furthermore, we provide theoretical justifications for our design, and conduct extensive comparative and analytical experiments to fully validate the efficiency and superior performance of our model.","sentences":["Traditional recurrent neural network architectures, such as long short-term memory neural networks (LSTM), have historically held a prominent role in time series forecasting (TSF) tasks.","While the recently introduced sLSTM for Natural Language Processing (NLP) introduces exponential gating and memory mixing that are beneficial for long term sequential learning, its potential short memory issue is a barrier to applying sLSTM directly in TSF.","To address this, we propose a simple yet efficient algorithm named P-sLSTM, which is built upon sLSTM by incorporating patching and channel independence.","These modifications substantially enhance sLSTM's performance in TSF, achieving state-of-the-art results.","Furthermore, we provide theoretical justifications for our design, and conduct extensive comparative and analytical experiments to fully validate the efficiency and superior performance of our model."],"url":"http://arxiv.org/abs/2408.10006v1"}
{"created":"2024-08-19 13:59:12","title":"Optimal Few-GHW Linear Codes and Their Subcode Support Weight Distributions","abstract":"Few-weight codes have been constructed and studied for many years, since their fascinating relations to finite geometries, strongly regular graphs and Boolean functions. Simplex codes are one-weight Griesmer $[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-linear codes and they meet all Griesmer bounds of the generalized Hamming weights of linear codes. All the subcodes with dimension $r$ of a $[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-simplex code have the same subcode support weight $\\frac{q^{k-r}(q^r-1)}{q-1}$ for $1\\leq r\\leq k$. In this paper, we construct linear codes meeting the Griesmer bound of the $r$-generalized Hamming weight, such codes do not meet the Griesmer bound of the $j$-generalized Hamming weight for $1\\leq j<r$. Moreover these codes have only few subcode support weights. The weight distribution and the subcode support weight distributions of these distance-optimal codes are determined. Linear codes constructed in this paper are natural generalizations of distance-optimal few-weight codes.","sentences":["Few-weight codes have been constructed and studied for many years, since their fascinating relations to finite geometries, strongly regular graphs and Boolean functions.","Simplex codes are one-weight Griesmer $","[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-linear codes and they meet all Griesmer bounds of the generalized Hamming weights of linear codes.","All the subcodes with dimension $r$ of a $[\\frac{q^k-1}{q-1},k ,q^{k-1}]_q$-simplex code have the same subcode support weight $\\frac{q^{k-r}(q^r-1)}{q-1}$ for $1\\leq r\\leq k$.","In this paper, we construct linear codes meeting the Griesmer bound of the $r$-generalized Hamming weight, such codes do not meet the Griesmer bound of the $j$-generalized Hamming weight for $1\\leq j<r$.","Moreover these codes have only few subcode support weights.","The weight distribution and the subcode support weight distributions of these distance-optimal codes are determined.","Linear codes constructed in this paper are natural generalizations of distance-optimal few-weight codes."],"url":"http://arxiv.org/abs/2408.10005v1"}
