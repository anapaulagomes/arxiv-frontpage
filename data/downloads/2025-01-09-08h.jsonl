{"created":"2025-01-08 18:59:36","title":"Planarian Neural Networks: Evolutionary Patterns from Basic Bilateria Shaping Modern Artificial Neural Network Architectures","abstract":"This study examined the viability of enhancing the prediction accuracy of artificial neural networks (ANNs) in image classification tasks by developing ANNs with evolution patterns similar to those of biological neural networks. ResNet is a widely used family of neural networks with both deep and wide variants; therefore, it was selected as the base model for our investigation. The aim of this study is to improve the image classification performance of ANNs via a novel approach inspired by the biological nervous system architecture of planarians, which comprises a brain and two nerve cords. We believe that the unique neural architecture of planarians offers valuable insights into the performance enhancement of ANNs. The proposed planarian neural architecture-based neural network was evaluated on the CIFAR-10 and CIFAR-100 datasets. Our results indicate that the proposed method exhibits higher prediction accuracy than the baseline neural network models in image classification tasks. These findings demonstrate the significant potential of biologically inspired neural network architectures in improving the performance of ANNs in a wide range of applications.","sentences":["This study examined the viability of enhancing the prediction accuracy of artificial neural networks (ANNs) in image classification tasks by developing ANNs with evolution patterns similar to those of biological neural networks.","ResNet is a widely used family of neural networks with both deep and wide variants; therefore, it was selected as the base model for our investigation.","The aim of this study is to improve the image classification performance of ANNs via a novel approach inspired by the biological nervous system architecture of planarians, which comprises a brain and two nerve cords.","We believe that the unique neural architecture of planarians offers valuable insights into the performance enhancement of ANNs.","The proposed planarian neural architecture-based neural network was evaluated on the CIFAR-10 and CIFAR-100 datasets.","Our results indicate that the proposed method exhibits higher prediction accuracy than the baseline neural network models in image classification tasks.","These findings demonstrate the significant potential of biologically inspired neural network architectures in improving the performance of ANNs in a wide range of applications."],"url":"http://arxiv.org/abs/2501.04700v1"}
{"created":"2025-01-08 18:59:35","title":"EditAR: Unified Conditional Generation with Autoregressive Models","abstract":"Recent progress in controllable image generation and editing is largely driven by diffusion-based methods. Although diffusion models perform exceptionally well in specific tasks with tailored designs, establishing a unified model is still challenging. In contrast, autoregressive models inherently feature a unified tokenized representation, which simplifies the creation of a single foundational model for various tasks. In this work, we propose EditAR, a single unified autoregressive framework for a variety of conditional image generation tasks, e.g., image editing, depth-to-image, edge-to-image, segmentation-to-image. The model takes both images and instructions as inputs, and predicts the edited images tokens in a vanilla next-token paradigm. To enhance the text-to-image alignment, we further propose to distill the knowledge from foundation models into the autoregressive modeling process. We evaluate its effectiveness across diverse tasks on established benchmarks, showing competitive performance to various state-of-the-art task-specific methods. Project page: https://jitengmu.github.io/EditAR/","sentences":["Recent progress in controllable image generation and editing is largely driven by diffusion-based methods.","Although diffusion models perform exceptionally well in specific tasks with tailored designs, establishing a unified model is still challenging.","In contrast, autoregressive models inherently feature a unified tokenized representation, which simplifies the creation of a single foundational model for various tasks.","In this work, we propose EditAR, a single unified autoregressive framework for a variety of conditional image generation tasks, e.g., image editing, depth-to-image, edge-to-image, segmentation-to-image.","The model takes both images and instructions as inputs, and predicts the edited images tokens in a vanilla next-token paradigm.","To enhance the text-to-image alignment, we further propose to distill the knowledge from foundation models into the autoregressive modeling process.","We evaluate its effectiveness across diverse tasks on established benchmarks, showing competitive performance to various state-of-the-art task-specific methods.","Project page: https://jitengmu.github.io/EditAR/"],"url":"http://arxiv.org/abs/2501.04699v1"}
{"created":"2025-01-08 18:59:01","title":"ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning","abstract":"Text-to-video generation has made remarkable advancements through diffusion models. However, Multi-Concept Video Customization (MCVC) remains a significant challenge. We identify two key challenges in this task: 1) the identity decoupling problem, where directly adopting existing customization methods inevitably mix attributes when handling multiple concepts simultaneously, and 2) the scarcity of high-quality video-entity pairs, which is crucial for training such a model that represents and decouples various concepts well. To address these challenges, we introduce ConceptMaster, an innovative framework that effectively tackles the critical issues of identity decoupling while maintaining concept fidelity in customized videos. Specifically, we introduce a novel strategy of learning decoupled multi-concept embeddings that are injected into the diffusion models in a standalone manner, which effectively guarantees the quality of customized videos with multiple identities, even for highly similar visual concepts. To further overcome the scarcity of high-quality MCVC data, we carefully establish a data construction pipeline, which enables systematic collection of precise multi-concept video-entity data across diverse concepts. A comprehensive benchmark is designed to validate the effectiveness of our model from three critical dimensions: concept fidelity, identity decoupling ability, and video generation quality across six different concept composition scenarios. Extensive experiments demonstrate that our ConceptMaster significantly outperforms previous approaches for this task, paving the way for generating personalized and semantically accurate videos across multiple concepts.","sentences":["Text-to-video generation has made remarkable advancements through diffusion models.","However, Multi-Concept Video Customization (MCVC) remains a significant challenge.","We identify two key challenges in this task: 1) the identity decoupling problem, where directly adopting existing customization methods inevitably mix attributes when handling multiple concepts simultaneously, and 2) the scarcity of high-quality video-entity pairs, which is crucial for training such a model that represents and decouples various concepts well.","To address these challenges, we introduce ConceptMaster, an innovative framework that effectively tackles the critical issues of identity decoupling while maintaining concept fidelity in customized videos.","Specifically, we introduce a novel strategy of learning decoupled multi-concept embeddings that are injected into the diffusion models in a standalone manner, which effectively guarantees the quality of customized videos with multiple identities, even for highly similar visual concepts.","To further overcome the scarcity of high-quality MCVC data, we carefully establish a data construction pipeline, which enables systematic collection of precise multi-concept video-entity data across diverse concepts.","A comprehensive benchmark is designed to validate the effectiveness of our model from three critical dimensions: concept fidelity, identity decoupling ability, and video generation quality across six different concept composition scenarios.","Extensive experiments demonstrate that our ConceptMaster significantly outperforms previous approaches for this task, paving the way for generating personalized and semantically accurate videos across multiple concepts."],"url":"http://arxiv.org/abs/2501.04698v1"}
{"created":"2025-01-08 18:58:48","title":"Grokking at the Edge of Numerical Stability","abstract":"Grokking, the sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon challenging our understanding of deep learning. Although significant progress has been made in understanding grokking, the reasons behind the delayed generalization and its dependence on regularization remain unclear. In this work, we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax function, which we refer to as Softmax Collapse (SC). We demonstrate that SC prevents grokking and that mitigating SC enables grokking without regularization. Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call the na\\\"ive loss minimization (NLM) direction. This component of the gradient does not alter the model's predictions but decreases the loss by scaling the logits, typically by scaling the weights along their current direction. We show that this scaling of the logits explains the delay in generalization characteristic of grokking and eventually leads to SC, halting further learning. To validate our hypotheses, we introduce two key contributions that address the challenges in grokking tasks: StableMax, a new activation function that prevents SC and enables grokking without regularization, and $\\perp$Grad, a training algorithm that promotes quick generalization in grokking tasks by preventing NLM altogether. These contributions provide new insights into grokking, elucidating its delayed generalization, reliance on regularization, and the effectiveness of existing grokking-inducing methods. Code for this paper is available at https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability.","sentences":["Grokking, the sudden generalization that occurs after prolonged overfitting, is a surprising phenomenon challenging our understanding of deep learning.","Although significant progress has been made in understanding grokking, the reasons behind the delayed generalization and its dependence on regularization remain unclear.","In this work, we argue that without regularization, grokking tasks push models to the edge of numerical stability, introducing floating point errors in the Softmax function, which we refer to as Softmax Collapse (SC).","We demonstrate that SC prevents grokking and that mitigating SC enables grokking without regularization.","Investigating the root cause of SC, we find that beyond the point of overfitting, the gradients strongly align with what we call the na\\\"ive loss minimization (NLM) direction.","This component of the gradient does not alter the model's predictions but decreases the loss by scaling the logits, typically by scaling the weights along their current direction.","We show that this scaling of the logits explains the delay in generalization characteristic of grokking and eventually leads to SC, halting further learning.","To validate our hypotheses, we introduce two key contributions that address the challenges in grokking tasks: StableMax, a new activation function that prevents SC and enables grokking without regularization, and $\\perp$Grad, a training algorithm that promotes quick generalization in grokking tasks by preventing NLM altogether.","These contributions provide new insights into grokking, elucidating its delayed generalization, reliance on regularization, and the effectiveness of existing grokking-inducing methods.","Code for this paper is available at https://github.com/LucasPrietoAl/grokking-at-the-edge-of-numerical-stability."],"url":"http://arxiv.org/abs/2501.04697v1"}
{"created":"2025-01-08 18:58:24","title":"Test-Time Optimization for Domain Adaptive Open Vocabulary Segmentation","abstract":"We present Seg-TTO, a novel framework for zero-shot, open-vocabulary semantic segmentation (OVSS), designed to excel in specialized domain tasks. While current open vocabulary approaches show impressive performance on standard segmentation benchmarks under zero-shot settings, they fall short of supervised counterparts on highly domain-specific datasets. We focus on segmentation-specific test-time optimization to address this gap. Segmentation requires an understanding of multiple concepts within a single image while retaining the locality and spatial structure of representations. We propose a novel self-supervised objective adhering to these requirements and use it to align the model parameters with input images at test time. In the textual modality, we learn multiple embeddings for each category to capture diverse concepts within an image, while in the visual modality, we calculate pixel-level losses followed by embedding aggregation operations specific to preserving spatial structure. Our resulting framework termed Seg-TTO is a plug-in-play module. We integrate Seg-TTO with three state-of-the-art OVSS approaches and evaluate across 22 challenging OVSS tasks covering a range of specialized domains. Our Seg-TTO demonstrates clear performance improvements across these establishing new state-of-the-art. Code: https://github.com/UlinduP/SegTTO.","sentences":["We present Seg-TTO, a novel framework for zero-shot, open-vocabulary semantic segmentation (OVSS), designed to excel in specialized domain tasks.","While current open vocabulary approaches show impressive performance on standard segmentation benchmarks under zero-shot settings, they fall short of supervised counterparts on highly domain-specific datasets.","We focus on segmentation-specific test-time optimization to address this gap.","Segmentation requires an understanding of multiple concepts within a single image while retaining the locality and spatial structure of representations.","We propose a novel self-supervised objective adhering to these requirements and use it to align the model parameters with input images at test time.","In the textual modality, we learn multiple embeddings for each category to capture diverse concepts within an image, while in the visual modality, we calculate pixel-level losses followed by embedding aggregation operations specific to preserving spatial structure.","Our resulting framework termed Seg-TTO is a plug-in-play module.","We integrate Seg-TTO with three state-of-the-art OVSS approaches and evaluate across 22 challenging OVSS tasks covering a range of specialized domains.","Our Seg-TTO demonstrates clear performance improvements across these establishing new state-of-the-art.","Code: https://github.com/UlinduP/SegTTO."],"url":"http://arxiv.org/abs/2501.04696v1"}
{"created":"2025-01-08 18:58:22","title":"Re-ranking the Context for Multimodal Retrieval Augmented Generation","abstract":"Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge to generate a response within a context with improved accuracy and reduced hallucinations. However, multi-modal RAG systems face unique challenges: (i) the retrieval process may select irrelevant entries to user query (e.g., images, documents), and (ii) vision-language models or multi-modal language models like GPT-4o may hallucinate when processing these entries to generate RAG output. In this paper, we aim to address the first challenge, i.e, improving the selection of relevant context from the knowledge-base in retrieval phase of the multi-modal RAG. Specifically, we leverage the relevancy score (RS) measure designed in our previous work for evaluating the RAG performance to select more relevant entries in retrieval process. The retrieval based on embeddings, say CLIP-based embedding, and cosine similarity usually perform poorly particularly for multi-modal data. We show that by using a more advanced relevancy measure, one can enhance the retrieval process by selecting more relevant pieces from the knowledge-base and eliminate the irrelevant pieces from the context by adaptively selecting up-to-$k$ entries instead of fixed number of entries. Our evaluation using COCO dataset demonstrates significant enhancement in selecting relevant context and accuracy of the generated response.","sentences":["Retrieval-augmented generation (RAG) enhances large language models (LLMs) by incorporating external knowledge to generate a response within a context with improved accuracy and reduced hallucinations.","However, multi-modal RAG systems face unique challenges: (i) the retrieval process may select irrelevant entries to user query (e.g., images, documents), and (ii) vision-language models or multi-modal language models like GPT-4o may hallucinate when processing these entries to generate RAG output.","In this paper, we aim to address the first challenge, i.e, improving the selection of relevant context from the knowledge-base in retrieval phase of the multi-modal RAG.","Specifically, we leverage the relevancy score (RS) measure designed in our previous work for evaluating the RAG performance to select more relevant entries in retrieval process.","The retrieval based on embeddings, say CLIP-based embedding, and cosine similarity usually perform poorly particularly for multi-modal data.","We show that by using a more advanced relevancy measure, one can enhance the retrieval process by selecting more relevant pieces from the knowledge-base and eliminate the irrelevant pieces from the context by adaptively selecting up-to-$k$ entries instead of fixed number of entries.","Our evaluation using COCO dataset demonstrates significant enhancement in selecting relevant context and accuracy of the generated response."],"url":"http://arxiv.org/abs/2501.04695v1"}
{"created":"2025-01-08 18:58:15","title":"EpiCoder: Encompassing Diversity and Complexity in Code Generation","abstract":"Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications. However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data. To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST). Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data. The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features. This process enables the identification of more complex patterns and relationships within the code. By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios. We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks. Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data. Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method.","sentences":["Effective instruction tuning is indispensable for optimizing code LLMs, aligning model behavior with user expectations and enhancing model performance in real-world applications.","However, most existing methods focus on code snippets, which are limited to specific functionalities and rigid structures, restricting the complexity and diversity of the synthesized data.","To address these limitations, we introduce a novel feature tree-based synthesis framework inspired by Abstract Syntax Trees (AST).","Unlike AST, which captures syntactic structure of code, our framework models semantic relationships between code elements, enabling the generation of more nuanced and diverse data.","The feature tree is constructed from raw data and refined iteratively to increase the quantity and diversity of the extracted features.","This process enables the identification of more complex patterns and relationships within the code.","By sampling subtrees with controlled depth and breadth, our framework allows precise adjustments to the complexity of the generated code, supporting a wide range of tasks from simple function-level operations to intricate multi-file scenarios.","We fine-tuned widely-used base models to create the EpiCoder series, achieving state-of-the-art performance at both the function and file levels across multiple benchmarks.","Notably, empirical evidence indicates that our approach shows significant potential in synthesizing highly complex repository-level code data.","Further analysis elucidates the merits of this approach by rigorously assessing data complexity and diversity through software engineering principles and LLM-as-a-judge method."],"url":"http://arxiv.org/abs/2501.04694v1"}
{"created":"2025-01-08 18:57:33","title":"Beyond Sight: Finetuning Generalist Robot Policies with Heterogeneous Sensors via Language Grounding","abstract":"Interacting with the world is a multi-sensory experience: achieving effective general-purpose interaction requires making use of all available modalities -- including vision, touch, and audio -- to fill in gaps from partial observation. For example, when vision is occluded reaching into a bag, a robot should rely on its senses of touch and sound. However, state-of-the-art generalist robot policies are typically trained on large datasets to predict robot actions solely from visual and proprioceptive observations. In this work, we propose FuSe, a novel approach that enables finetuning visuomotor generalist policies on heterogeneous sensor modalities for which large datasets are not readily available by leveraging natural language as a common cross-modal grounding. We combine a multimodal contrastive loss with a sensory-grounded language generation loss to encode high-level semantics. In the context of robot manipulation, we show that FuSe enables performing challenging tasks that require reasoning jointly over modalities such as vision, touch, and sound in a zero-shot setting, such as multimodal prompting, compositional cross-modal prompting, and descriptions of objects it interacts with. We show that the same recipe is applicable to widely different generalist policies, including both diffusion-based generalist policies and large vision-language-action (VLA) models. Extensive experiments in the real world show that FuSeis able to increase success rates by over 20% compared to all considered baselines.","sentences":["Interacting with the world is a multi-sensory experience: achieving effective general-purpose interaction requires making use of all available modalities -- including vision, touch, and audio -- to fill in gaps from partial observation.","For example, when vision is occluded reaching into a bag, a robot should rely on its senses of touch and sound.","However, state-of-the-art generalist robot policies are typically trained on large datasets to predict robot actions solely from visual and proprioceptive observations.","In this work, we propose FuSe, a novel approach that enables finetuning visuomotor generalist policies on heterogeneous sensor modalities for which large datasets are not readily available by leveraging natural language as a common cross-modal grounding.","We combine a multimodal contrastive loss with a sensory-grounded language generation loss to encode high-level semantics.","In the context of robot manipulation, we show that FuSe enables performing challenging tasks that require reasoning jointly over modalities such as vision, touch, and sound in a zero-shot setting, such as multimodal prompting, compositional cross-modal prompting, and descriptions of objects it interacts with.","We show that the same recipe is applicable to widely different generalist policies, including both diffusion-based generalist policies and large vision-language-action (VLA) models.","Extensive experiments in the real world show that FuSeis able to increase success rates by over 20% compared to all considered baselines."],"url":"http://arxiv.org/abs/2501.04693v1"}
{"created":"2025-01-08 18:53:50","title":"Comparative Analysis of Quantum and Classical Support Vector Classifiers for Software Bug Prediction: An Exploratory Study","abstract":"Purpose: Quantum computing promises to transform problem-solving across various domains with rapid and practical solutions. Within Software Evolution and Maintenance, Quantum Machine Learning (QML) remains mostly an underexplored domain, particularly in addressing challenges such as detecting buggy software commits from code repositories. Methods: In this study, we investigate the practical application of Quantum Support Vector Classifiers (QSVC) for detecting buggy software commits across 14 open-source software projects with diverse dataset sizes encompassing 30,924 data instances. We compare the QML algorithm PQSVC (Pegasos QSVC) and QSVC against the classical Support Vector Classifier (SVC). Our technique addresses large datasets in QSVC algorithms by dividing them into smaller subsets. We propose and evaluate an aggregation method to combine predictions from these models to detect the entire test dataset. We also introduce an incremental testing methodology to overcome the difficulties of quantum feature mapping during the testing approach. Results: The study shows the effectiveness of QSVC and PQSVC in detecting buggy software commits. The aggregation technique successfully combines predictions from smaller data subsets, enhancing the overall detection accuracy for the entire test dataset. The incremental testing methodology effectively manages the challenges associated with quantum feature mapping during the testing process. Conclusion: We contribute to the advancement of QML algorithms in defect prediction, unveiling the potential for further research in this domain. The specific scenario of the Short-Term Activity Frame (STAF) highlights the early detection of buggy software commits during the initial developmental phases of software systems, particularly when dataset sizes remain insufficient to train machine learning models.","sentences":["Purpose:","Quantum computing promises to transform problem-solving across various domains with rapid and practical solutions.","Within Software Evolution and Maintenance, Quantum Machine Learning (QML) remains mostly an underexplored domain, particularly in addressing challenges such as detecting buggy software commits from code repositories.","Methods: In this study, we investigate the practical application of Quantum Support Vector Classifiers (QSVC) for detecting buggy software commits across 14 open-source software projects with diverse dataset sizes encompassing 30,924 data instances.","We compare the QML algorithm PQSVC (Pegasos QSVC) and QSVC against the classical Support Vector Classifier (SVC).","Our technique addresses large datasets in QSVC algorithms by dividing them into smaller subsets.","We propose and evaluate an aggregation method to combine predictions from these models to detect the entire test dataset.","We also introduce an incremental testing methodology to overcome the difficulties of quantum feature mapping during the testing approach.","Results:","The study shows the effectiveness of QSVC and PQSVC in detecting buggy software commits.","The aggregation technique successfully combines predictions from smaller data subsets, enhancing the overall detection accuracy for the entire test dataset.","The incremental testing methodology effectively manages the challenges associated with quantum feature mapping during the testing process.","Conclusion: We contribute to the advancement of QML algorithms in defect prediction, unveiling the potential for further research in this domain.","The specific scenario of the Short-Term Activity Frame (STAF) highlights the early detection of buggy software commits during the initial developmental phases of software systems, particularly when dataset sizes remain insufficient to train machine learning models."],"url":"http://arxiv.org/abs/2501.04690v1"}
{"created":"2025-01-08 18:52:03","title":"SPAR3D: Stable Point-Aware Reconstruction of 3D Objects from Single Images","abstract":"We study the problem of single-image 3D object reconstruction. Recent works have diverged into two directions: regression-based modeling and generative modeling. Regression methods efficiently infer visible surfaces, but struggle with occluded regions. Generative methods handle uncertain regions better by modeling distributions, but are computationally expensive and the generation is often misaligned with visible surfaces. In this paper, we present SPAR3D, a novel two-stage approach aiming to take the best of both directions. The first stage of SPAR3D generates sparse 3D point clouds using a lightweight point diffusion model, which has a fast sampling speed. The second stage uses both the sampled point cloud and the input image to create highly detailed meshes. Our two-stage design enables probabilistic modeling of the ill-posed single-image 3D task while maintaining high computational efficiency and great output fidelity. Using point clouds as an intermediate representation further allows for interactive user edits. Evaluated on diverse datasets, SPAR3D demonstrates superior performance over previous state-of-the-art methods, at an inference speed of 0.7 seconds. Project page with code and model: https://spar3d.github.io","sentences":["We study the problem of single-image 3D object reconstruction.","Recent works have diverged into two directions: regression-based modeling and generative modeling.","Regression methods efficiently infer visible surfaces, but struggle with occluded regions.","Generative methods handle uncertain regions better by modeling distributions, but are computationally expensive and the generation is often misaligned with visible surfaces.","In this paper, we present SPAR3D, a novel two-stage approach aiming to take the best of both directions.","The first stage of SPAR3D generates sparse 3D point clouds using a lightweight point diffusion model, which has a fast sampling speed.","The second stage uses both the sampled point cloud and the input image to create highly detailed meshes.","Our two-stage design enables probabilistic modeling of the ill-posed single-image 3D task while maintaining high computational efficiency and great output fidelity.","Using point clouds as an intermediate representation further allows for interactive user edits.","Evaluated on diverse datasets, SPAR3D demonstrates superior performance over previous state-of-the-art methods, at an inference speed of 0.7 seconds.","Project page with code and model: https://spar3d.github.io"],"url":"http://arxiv.org/abs/2501.04689v1"}
{"created":"2025-01-08 18:49:41","title":"URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics","abstract":"Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs). Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models. However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time. In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification. It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M. We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks. For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic. By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities. The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time. URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization. Model weights, training data and code will be open-sourced.","sentences":["Chain-of-thought (CoT) reasoning has been widely applied in the mathematical reasoning of Large Language Models (LLMs).","Recently, the introduction of derivative process supervision on CoT trajectories has sparked discussions on enhancing scaling capabilities during test time, thereby boosting the potential of these models.","However, in multimodal mathematical reasoning, the scarcity of high-quality CoT training data has hindered existing models from achieving high-precision CoT reasoning and has limited the realization of reasoning potential during test time.","In this work, we propose a three-module synthesis strategy that integrates CoT distillation, trajectory-format rewriting, and format unification.","It results in a high-quality CoT reasoning instruction fine-tuning dataset in multimodal mathematics, MMathCoT-1M.","We comprehensively validate the state-of-the-art (SOTA) performance of the trained URSA-7B model on multiple multimodal mathematical benchmarks.","For test-time scaling, we introduce a data synthesis strategy that automatically generates process annotation datasets, known as DualMath-1.1M, focusing on both interpretation and logic.","By further training URSA-7B on DualMath-1.1M, we transition from CoT reasoning capabilities to robust supervision abilities.","The trained URSA-RM-7B acts as a verifier, effectively enhancing the performance of URSA-7B at test time.","URSA-RM-7B also demonstrates excellent out-of-distribution (OOD) verifying capabilities, showcasing its generalization.","Model weights, training data and code will be open-sourced."],"url":"http://arxiv.org/abs/2501.04686v1"}
{"created":"2025-01-08 18:42:48","title":"Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though","abstract":"We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.","sentences":["We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms.","Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training.","Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms.","This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence."],"url":"http://arxiv.org/abs/2501.04682v1"}
{"created":"2025-01-08 18:33:17","title":"Enhancing Financial VQA in Vision Language Models using Intermediate Structured Representations","abstract":"Chart interpretation is crucial for visual data analysis, but accurately extracting information from charts poses significant challenges for automated models. This study investigates the fine-tuning of DEPLOT, a modality conversion module that translates the image of a plot or chart to a linearized table, on a custom dataset of 50,000 bar charts. The dataset comprises simple, stacked, and grouped bar charts, targeting the unique structural features of these visualizations. The finetuned DEPLOT model is evaluated against its base version using a test set of 1,000 images and two metrics: Relative Mapping Similarity (RMS), which measures categorical mapping accuracy, and Relative Number Set Similarity (RNSS), which evaluates numerical interpretation accuracy. To further explore the reasoning capabilities of large language models (LLMs), we curate an additional set of 100 bar chart images paired with question answer sets. Our findings demonstrate that providing a structured intermediate table alongside the image significantly enhances LLM reasoning performance compared to direct image queries.","sentences":["Chart interpretation is crucial for visual data analysis, but accurately extracting information from charts poses significant challenges for automated models.","This study investigates the fine-tuning of DEPLOT, a modality conversion module that translates the image of a plot or chart to a linearized table, on a custom dataset of 50,000 bar charts.","The dataset comprises simple, stacked, and grouped bar charts, targeting the unique structural features of these visualizations.","The finetuned DEPLOT model is evaluated against its base version using a test set of 1,000 images and two metrics: Relative Mapping Similarity (RMS), which measures categorical mapping accuracy, and Relative Number Set Similarity (RNSS), which evaluates numerical interpretation accuracy.","To further explore the reasoning capabilities of large language models (LLMs), we curate an additional set of 100 bar chart images paired with question answer sets.","Our findings demonstrate that providing a structured intermediate table alongside the image significantly enhances LLM reasoning performance compared to direct image queries."],"url":"http://arxiv.org/abs/2501.04675v1"}
{"created":"2025-01-08 18:31:16","title":"DRIVINGVQA: Analyzing Visual Chain-of-Thought Reasoning of Vision Language Models in Real-World Scenarios with Driving Theory Tests","abstract":"Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning. However, due to the modality gap between textual and visual data, they often face significant challenges, such as over-reliance on text priors, hallucinations, and limited capacity for complex visual reasoning. Existing benchmarks to evaluate visual reasoning in LVLMs often rely on schematic or synthetic images and on imprecise machine-generated explanations. To bridge the modality gap, we present DrivingVQA, a new benchmark derived from driving theory tests to evaluate visual chain-of-thought reasoning in complex real-world scenarios. It offers 3,931 expert-crafted multiple-choice problems and interleaved explanations grounded with entities relevant to the reasoning process. We leverage this dataset to perform an extensive study of LVLMs' ability to reason about complex visual scenarios. Our experiments reveal that open-source and proprietary LVLMs struggle with visual chain-of-thought reasoning under zero-shot settings. We investigate training strategies that leverage relevant entities to improve visual reasoning. Notably, we observe a performance boost of up to 7\\% when reasoning over image tokens of cropped regions tied to these entities.","sentences":["Large vision-language models (LVLMs) augment language models with visual understanding, enabling multimodal reasoning.","However, due to the modality gap between textual and visual data, they often face significant challenges, such as over-reliance on text priors, hallucinations, and limited capacity for complex visual reasoning.","Existing benchmarks to evaluate visual reasoning in LVLMs often rely on schematic or synthetic images and on imprecise machine-generated explanations.","To bridge the modality gap, we present DrivingVQA, a new benchmark derived from driving theory tests to evaluate visual chain-of-thought reasoning in complex real-world scenarios.","It offers 3,931 expert-crafted multiple-choice problems and interleaved explanations grounded with entities relevant to the reasoning process.","We leverage this dataset to perform an extensive study of LVLMs' ability to reason about complex visual scenarios.","Our experiments reveal that open-source and proprietary LVLMs struggle with visual chain-of-thought reasoning under zero-shot settings.","We investigate training strategies that leverage relevant entities to improve visual reasoning.","Notably, we observe a performance boost of up to 7\\% when reasoning over image tokens of cropped regions tied to these entities."],"url":"http://arxiv.org/abs/2501.04671v1"}
{"created":"2025-01-08 18:30:53","title":"Are They the Same? Exploring Visual Correspondence Shortcomings of Multimodal LLMs","abstract":"Recent advancements in multimodal models have shown a strong ability in visual perception, reasoning abilities, and vision-language understanding. However, studies on visual matching ability are missing, where finding the visual correspondence of objects is essential in vision research. Our research reveals that the matching capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o. In particular, we construct a Multimodal Visual Matching (MMVM) benchmark to fairly benchmark over 30 different MLLMs. The MMVM benchmark is built from 15 open-source datasets and Internet videos with manual annotation. We categorize the data samples of MMVM benchmark into eight aspects based on the required cues and capabilities to more comprehensively evaluate and analyze current MLLMs. In addition, we have designed an automatic annotation pipeline to generate the MMVM SFT dataset, including 220K visual matching data with reasoning annotation. Finally, we present CoLVA, a novel contrastive MLLM with two novel technical designs: fine-grained vision expert with object-level contrastive learning and instruction augmentation strategy. CoLVA achieves 51.06\\% overall accuracy (OA) on the MMVM benchmark, surpassing GPT-4o and baseline by 8.41\\% and 23.58\\% OA, respectively. The results show the effectiveness of our MMVM SFT dataset and our novel technical designs. Code, benchmark, dataset, and models are available at https://github.com/zhouyiks/CoLVA.","sentences":["Recent advancements in multimodal models have shown a strong ability in visual perception, reasoning abilities, and vision-language understanding.","However, studies on visual matching ability are missing, where finding the visual correspondence of objects is essential in vision research.","Our research reveals that the matching capabilities in recent multimodal LLMs (MLLMs) still exhibit systematic shortcomings, even with current strong MLLMs models, GPT-4o.","In particular, we construct a Multimodal Visual Matching (MMVM) benchmark to fairly benchmark over 30 different MLLMs.","The MMVM benchmark is built from 15 open-source datasets and Internet videos with manual annotation.","We categorize the data samples of MMVM benchmark into eight aspects based on the required cues and capabilities to more comprehensively evaluate and analyze current MLLMs.","In addition, we have designed an automatic annotation pipeline to generate the MMVM SFT dataset, including 220K visual matching data with reasoning annotation.","Finally, we present CoLVA, a novel contrastive MLLM with two novel technical designs: fine-grained vision expert with object-level contrastive learning and instruction augmentation strategy.","CoLVA achieves 51.06\\% overall accuracy (OA) on the MMVM benchmark, surpassing GPT-4o and baseline by 8.41\\% and 23.58\\% OA, respectively.","The results show the effectiveness of our MMVM SFT dataset and our novel technical designs.","Code, benchmark, dataset, and models are available at https://github.com/zhouyiks/CoLVA."],"url":"http://arxiv.org/abs/2501.04670v1"}
{"created":"2025-01-08 18:25:50","title":"Enhancing Virtual Try-On with Synthetic Pairs and Error-Aware Noise Scheduling","abstract":"Given an isolated garment image in a canonical product view and a separate image of a person, the virtual try-on task aims to generate a new image of the person wearing the target garment. Prior virtual try-on works face two major challenges in achieving this goal: a) the paired (human, garment) training data has limited availability; b) generating textures on the human that perfectly match that of the prompted garment is difficult, often resulting in distorted text and faded textures. Our work explores ways to tackle these issues through both synthetic data as well as model refinement. We introduce a garment extraction model that generates (human, synthetic garment) pairs from a single image of a clothed individual. The synthetic pairs can then be used to augment the training of virtual try-on. We also propose an Error-Aware Refinement-based Schr\\\"odinger Bridge (EARSB) that surgically targets localized generation errors for correcting the output of a base virtual try-on model. To identify likely errors, we propose a weakly-supervised error classifier that localizes regions for refinement, subsequently augmenting the Schr\\\"odinger Bridge's noise schedule with its confidence heatmap. Experiments on VITON-HD and DressCode-Upper demonstrate that our synthetic data augmentation enhances the performance of prior work, while EARSB improves the overall image quality. In user studies, our model is preferred by the users in an average of 59% of cases.","sentences":["Given an isolated garment image in a canonical product view and a separate image of a person, the virtual try-on task aims to generate a new image of the person wearing the target garment.","Prior virtual try-on works face two major challenges in achieving this goal: a) the paired (human, garment) training data has limited availability; b) generating textures on the human that perfectly match that of the prompted garment is difficult, often resulting in distorted text and faded textures.","Our work explores ways to tackle these issues through both synthetic data as well as model refinement.","We introduce a garment extraction model that generates (human, synthetic garment) pairs from a single image of a clothed individual.","The synthetic pairs can then be used to augment the training of virtual try-on.","We also propose an Error-Aware Refinement-based Schr\\\"odinger Bridge (EARSB) that surgically targets localized generation errors for correcting the output of a base virtual try-on model.","To identify likely errors, we propose a weakly-supervised error classifier that localizes regions for refinement, subsequently augmenting the Schr\\\"odinger Bridge's noise schedule with its confidence heatmap.","Experiments on VITON-HD and DressCode-Upper demonstrate that our synthetic data augmentation enhances the performance of prior work, while EARSB improves the overall image quality.","In user studies, our model is preferred by the users in an average of 59% of cases."],"url":"http://arxiv.org/abs/2501.04666v1"}
{"created":"2025-01-08 18:15:47","title":"On The Origin of Cultural Biases in Language Models: From Pre-training Data to Linguistic Phenomena","abstract":"Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages. In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by analyzing several contributing factors, including the representation of entities in pre-training data and the impact of variations in linguistic phenomena across languages. We introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities associated with Arab and Western cultures and 367 masked natural contexts for entities. Our evaluations using CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in English compared to Arabic. We find that LMs struggle in Arabic with entities that appear at high frequencies in pre-training, where entities can hold multiple word senses. This also extends to entities that exhibit high lexical overlap with languages that are not Arabic but use the Arabic script. Further, we show how frequency-based tokenization leads to this issue in LMs, which gets worse with larger Arabic vocabularies. We will make CAMeL-2 available at: https://github.com/tareknaous/camel2","sentences":["Language Models (LMs) have been shown to exhibit a strong preference towards entities associated with Western culture when operating in non-Western languages.","In this paper, we aim to uncover the origins of entity-related cultural biases in LMs by analyzing several contributing factors, including the representation of entities in pre-training data and the impact of variations in linguistic phenomena across languages.","We introduce CAMeL-2, a parallel Arabic-English benchmark of 58,086 entities associated with Arab and Western cultures and 367 masked natural contexts for entities.","Our evaluations using CAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in English compared to Arabic.","We find that LMs struggle in Arabic with entities that appear at high frequencies in pre-training, where entities can hold multiple word senses.","This also extends to entities that exhibit high lexical overlap with languages that are not Arabic but use the Arabic script.","Further, we show how frequency-based tokenization leads to this issue in LMs, which gets worse with larger Arabic vocabularies.","We will make CAMeL-2 available at: https://github.com/tareknaous/camel2"],"url":"http://arxiv.org/abs/2501.04662v1"}
{"created":"2025-01-08 18:15:10","title":"Assessing Language Comprehension in Large Language Models Using Construction Grammar","abstract":"Large Language Models, despite their significant capabilities, are known to fail in surprising and unpredictable ways. Evaluating their true `understanding' of language is particularly challenging due to the extensive web-scale data they are trained on. Therefore, we construct an evaluation to systematically assess natural language understanding (NLU) in LLMs by leveraging Construction Grammar (CxG), which provides insights into the meaning captured by linguistic elements known as constructions (Cxns). CxG is well-suited for this purpose because provides a theoretical basis to construct targeted evaluation sets. These datasets are carefully constructed to include examples which are unlikely to appear in pre-training data, yet intuitive and easy for humans to understand, enabling a more targeted and reliable assessment. Our experiments focus on downstream natural language inference and reasoning tasks by comparing LLMs' understanding of the underlying meanings communicated through 8 unique Cxns with that of humans. The results show that while LLMs demonstrate some knowledge of constructional information, even the latest models including GPT-o1 struggle with abstract meanings conveyed by these Cxns, as demonstrated in cases where test sentences are dissimilar to their pre-training data. We argue that such cases provide a more accurate test of true language understanding, highlighting key limitations in LLMs' semantic capabilities. We make our novel dataset and associated experimental data including prompts and model responses publicly available.","sentences":["Large Language Models, despite their significant capabilities, are known to fail in surprising and unpredictable ways.","Evaluating their true `understanding' of language is particularly challenging due to the extensive web-scale data they are trained on.","Therefore, we construct an evaluation to systematically assess natural language understanding (NLU) in LLMs by leveraging Construction Grammar (CxG), which provides insights into the meaning captured by linguistic elements known as constructions (Cxns).","CxG is well-suited for this purpose because provides a theoretical basis to construct targeted evaluation sets.","These datasets are carefully constructed to include examples which are unlikely to appear in pre-training data, yet intuitive and easy for humans to understand, enabling a more targeted and reliable assessment.","Our experiments focus on downstream natural language inference and reasoning tasks by comparing LLMs' understanding of the underlying meanings communicated through 8 unique Cxns with that of humans.","The results show that while LLMs demonstrate some knowledge of constructional information, even the latest models including GPT-o1 struggle with abstract meanings conveyed by these Cxns, as demonstrated in cases where test sentences are dissimilar to their pre-training data.","We argue that such cases provide a more accurate test of true language understanding, highlighting key limitations in LLMs' semantic capabilities.","We make our novel dataset and associated experimental data including prompts and model responses publicly available."],"url":"http://arxiv.org/abs/2501.04661v1"}
{"created":"2025-01-08 18:07:12","title":"Recorder: Comprehensive Parallel I/O Tracing and Analysis","abstract":"This paper presents Recorder, a parallel I/O tracing tool designed to capture comprehensive I/O information on HPC applications. Recorder traces I/O calls across various I/O layers, storing all function parameters for each captured call. The volume of stored information scales linearly the application's execution scale. To address this, we present a sophisticated pattern-recognition-based compression algorithm. This algorithm identifies and compresses recurring I/O patterns both within individual processes and across multiple processes, significantly reducing space and time overheads. We evaluate the proposed compression algorithm using I/O benchmarks and real-world applications, demonstrating that Recorder can store more information while requiring approximately 12x less storage space compared to its predecessor. Notably, for applications with typical parallel I/O patterns, Recorder achieves a constant trace size regardless of execution scale. Additionally, a comparison with the profiling tool Darshan shows that Recorder captures detailed I/O information without incurring substantial overhead. The richer data collected by Recorder enables new insights and facilitates more in-depth I/O studies, offering valuable contributions to the I/O research community.","sentences":["This paper presents Recorder, a parallel I/O tracing tool designed to capture comprehensive I/O information on HPC applications.","Recorder traces I/O calls across various I/O layers, storing all function parameters for each captured call.","The volume of stored information scales linearly the application's execution scale.","To address this, we present a sophisticated pattern-recognition-based compression algorithm.","This algorithm identifies and compresses recurring I/O patterns both within individual processes and across multiple processes, significantly reducing space and time overheads.","We evaluate the proposed compression algorithm using I/O benchmarks and real-world applications, demonstrating that Recorder can store more information while requiring approximately 12x less storage space compared to its predecessor.","Notably, for applications with typical parallel I/O patterns, Recorder achieves a constant trace size regardless of execution scale.","Additionally, a comparison with the profiling tool Darshan shows that Recorder captures detailed I/O information without incurring substantial overhead.","The richer data collected by Recorder enables new insights and facilitates more in-depth I/O studies, offering valuable contributions to the I/O research community."],"url":"http://arxiv.org/abs/2501.04654v1"}
{"created":"2025-01-08 18:05:30","title":"Multi-task retriever fine-tuning for domain-specific and efficient RAG","abstract":"Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information. However, when building real-world RAG applications, practical issues arise. First, the retrieved information is generally domain-specific. Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input. Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers. Moreover, these RAG applications normally retrieve different kinds of data. Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed. We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases.","sentences":["Retrieval-Augmented Generation (RAG) has become ubiquitous when deploying Large Language Models (LLMs), as it can address typical limitations such as generating hallucinated or outdated information.","However, when building real-world RAG applications, practical issues arise.","First, the retrieved information is generally domain-specific.","Since it is computationally expensive to fine-tune LLMs, it is more feasible to fine-tune the retriever to improve the quality of the data included in the LLM input.","Second, as more applications are deployed in the same real-world system, one cannot afford to deploy separate retrievers.","Moreover, these RAG applications normally retrieve different kinds of data.","Our solution is to instruction fine-tune a small retriever encoder on a variety of domain-specific tasks to allow us to deploy one encoder that can serve many use cases, thereby achieving low-cost, scalability, and speed.","We show how this encoder generalizes to out-of-domain settings as well as to an unseen retrieval task on real-world enterprise use cases."],"url":"http://arxiv.org/abs/2501.04652v1"}
{"created":"2025-01-08 18:01:49","title":"FlairGPT: Repurposing LLMs for Interior Designs","abstract":"Interior design involves the careful selection and arrangement of objects to create an aesthetically pleasing, functional, and harmonized space that aligns with the client's design brief. This task is particularly challenging, as a successful design must not only incorporate all the necessary objects in a cohesive style, but also ensure they are arranged in a way that maximizes accessibility, while adhering to a variety of affordability and usage considerations. Data-driven solutions have been proposed, but these are typically room- or domain-specific and lack explainability in their design design considerations used in producing the final layout. In this paper, we investigate if large language models (LLMs) can be directly utilized for interior design. While we find that LLMs are not yet capable of generating complete layouts, they can be effectively leveraged in a structured manner, inspired by the workflow of interior designers. By systematically probing LLMs, we can reliably generate a list of objects along with relevant constraints that guide their placement. We translate this information into a design layout graph, which is then solved using an off-the-shelf constrained optimization setup to generate the final layouts. We benchmark our algorithm in various design configurations against existing LLM-based methods and human designs, and evaluate the results using a variety of quantitative and qualitative metrics along with user studies. In summary, we demonstrate that LLMs, when used in a structured manner, can effectively generate diverse high-quality layouts, making them a viable solution for creating large-scale virtual scenes. Project webpage at https://flairgpt.github.io/","sentences":["Interior design involves the careful selection and arrangement of objects to create an aesthetically pleasing, functional, and harmonized space that aligns with the client's design brief.","This task is particularly challenging, as a successful design must not only incorporate all the necessary objects in a cohesive style, but also ensure they are arranged in a way that maximizes accessibility, while adhering to a variety of affordability and usage considerations.","Data-driven solutions have been proposed, but these are typically room- or domain-specific and lack explainability in their design design considerations used in producing the final layout.","In this paper, we investigate if large language models (LLMs) can be directly utilized for interior design.","While we find that LLMs are not yet capable of generating complete layouts, they can be effectively leveraged in a structured manner, inspired by the workflow of interior designers.","By systematically probing LLMs, we can reliably generate a list of objects along with relevant constraints that guide their placement.","We translate this information into a design layout graph, which is then solved using an off-the-shelf constrained optimization setup to generate the final layouts.","We benchmark our algorithm in various design configurations against existing LLM-based methods and human designs, and evaluate the results using a variety of quantitative and qualitative metrics along with user studies.","In summary, we demonstrate that LLMs, when used in a structured manner, can effectively generate diverse high-quality layouts, making them a viable solution for creating large-scale virtual scenes.","Project webpage at https://flairgpt.github.io/"],"url":"http://arxiv.org/abs/2501.04648v1"}
{"created":"2025-01-08 18:00:27","title":"Optimal Trading of a Charging-Station Company in Auction Markets for Electricity","abstract":"This paper addresses a charging-station company (Chargco) for electric and hydrogen vehicles. The optimal trading of the Chargco in day-ahead and intraday auction markets for electricity is modeled as a stochastic Mixed-Integer Quadratic Program (MIQP). We propose a series of linearization and reformulation techniques to reformulate the stochastic MIQP as a mixed-integer linear program (MILP). To model stochasticity, we utilize generative adversarial networks to cluster electricity market price scenarios. Additionally, a combination of random forests and linear regression is employed to model the relationship between Chargco electricity and hydrogen loads and their selling prices. Finally, we propose an Improved L-Shaped Decomposition (ILSD) algorithm to solve our stochastic MILP. Our ILSD algorithm not only addresses infeasibilities through an innovative approach but also incorporates warm starts, valid inequalities and multiple generation cuts, thereby reducing computational complexity. Numerical experiments illustrate the Chargco trading using our proposed stochastic MILP and its solution algorithm.","sentences":["This paper addresses a charging-station company (Chargco) for electric and hydrogen vehicles.","The optimal trading of the Chargco in day-ahead and intraday auction markets for electricity is modeled as a stochastic Mixed-Integer Quadratic Program (MIQP).","We propose a series of linearization and reformulation techniques to reformulate the stochastic MIQP as a mixed-integer linear program (MILP).","To model stochasticity, we utilize generative adversarial networks to cluster electricity market price scenarios.","Additionally, a combination of random forests and linear regression is employed to model the relationship between Chargco electricity and hydrogen loads and their selling prices.","Finally, we propose an Improved L-Shaped Decomposition (ILSD) algorithm to solve our stochastic MILP.","Our ILSD algorithm not only addresses infeasibilities through an innovative approach but also incorporates warm starts, valid inequalities and multiple generation cuts, thereby reducing computational complexity.","Numerical experiments illustrate the Chargco trading using our proposed stochastic MILP and its solution algorithm."],"url":"http://arxiv.org/abs/2501.04647v1"}
{"created":"2025-01-08 17:49:52","title":"Discrete Wavelet Transform-Based Capsule Network for Hyperspectral Image Classification","abstract":"Hyperspectral image (HSI) classification is a crucial technique for remote sensing to build large-scale earth monitoring systems. HSI contains much more information than traditional visual images for identifying the categories of land covers. One recent feasible solution for HSI is to leverage CapsNets for capturing spectral-spatial information. However, these methods require high computational requirements due to the full connection architecture between stacked capsule layers. To solve this problem, a DWT-CapsNet is proposed to identify partial but important connections in CapsNet for a effective and efficient HSI classification. Specifically, we integrate a tailored attention mechanism into a Discrete Wavelet Transform (DWT)-based downsampling layer, alleviating the information loss problem of conventional downsampling operation in feature extractors. Moreover, we propose a novel multi-scale routing algorithm that prunes a large proportion of connections in CapsNet. A capsule pyramid fusion mechanism is designed to aggregate the spectral-spatial relationships in multiple levels of granularity, and then a self-attention mechanism is further conducted in a partially and locally connected architecture to emphasize the meaningful relationships. As shown in the experimental results, our method achieves state-of-the-art accuracy while keeping lower computational demand regarding running time, flops, and the number of parameters, rendering it an appealing choice for practical implementation in HSI classification.","sentences":["Hyperspectral image (HSI) classification is a crucial technique for remote sensing to build large-scale earth monitoring systems.","HSI contains much more information than traditional visual images for identifying the categories of land covers.","One recent feasible solution for HSI is to leverage CapsNets for capturing spectral-spatial information.","However, these methods require high computational requirements due to the full connection architecture between stacked capsule layers.","To solve this problem, a DWT-CapsNet is proposed to identify partial but important connections in CapsNet for a effective and efficient HSI classification.","Specifically, we integrate a tailored attention mechanism into a Discrete Wavelet Transform (DWT)-based downsampling layer, alleviating the information loss problem of conventional downsampling operation in feature extractors.","Moreover, we propose a novel multi-scale routing algorithm that prunes a large proportion of connections in CapsNet.","A capsule pyramid fusion mechanism is designed to aggregate the spectral-spatial relationships in multiple levels of granularity, and then a self-attention mechanism is further conducted in a partially and locally connected architecture to emphasize the meaningful relationships.","As shown in the experimental results, our method achieves state-of-the-art accuracy while keeping lower computational demand regarding running time, flops, and the number of parameters, rendering it an appealing choice for practical implementation in HSI classification."],"url":"http://arxiv.org/abs/2501.04643v1"}
{"created":"2025-01-08 17:47:06","title":"A Statistical Theory of Contrastive Pre-training and Multimodal Generative AI","abstract":"Multi-modal generative AI systems, such as those combining vision and language, rely on contrastive pre-training to learn representations across different modalities. While their practical benefits are widely acknowledged, a rigorous theoretical understanding of the contrastive pre-training framework remains limited. This paper develops a theoretical framework to explain the success of contrastive pre-training in downstream tasks, such as zero-shot classification, conditional diffusion models, and vision-language models. We introduce the concept of approximate sufficient statistics, a generalization of the classical sufficient statistics, and show that near-minimizers of the contrastive pre-training loss are approximately sufficient, making them adaptable to diverse downstream tasks. We further propose the Joint Generative Hierarchical Model for the joint distribution of images and text, showing that transformers can efficiently approximate relevant functions within this model via belief propagation. Building on this framework, we derive sample complexity guarantees for multi-modal learning based on contrastive pre-trained representations. Numerical simulations validate these theoretical findings, demonstrating the strong generalization performance of contrastively pre-trained transformers in various multi-modal tasks.","sentences":["Multi-modal generative AI systems, such as those combining vision and language, rely on contrastive pre-training to learn representations across different modalities.","While their practical benefits are widely acknowledged, a rigorous theoretical understanding of the contrastive pre-training framework remains limited.","This paper develops a theoretical framework to explain the success of contrastive pre-training in downstream tasks, such as zero-shot classification, conditional diffusion models, and vision-language models.","We introduce the concept of approximate sufficient statistics, a generalization of the classical sufficient statistics, and show that near-minimizers of the contrastive pre-training loss are approximately sufficient, making them adaptable to diverse downstream tasks.","We further propose the Joint Generative Hierarchical Model for the joint distribution of images and text, showing that transformers can efficiently approximate relevant functions within this model via belief propagation.","Building on this framework, we derive sample complexity guarantees for multi-modal learning based on contrastive pre-trained representations.","Numerical simulations validate these theoretical findings, demonstrating the strong generalization performance of contrastively pre-trained transformers in various multi-modal tasks."],"url":"http://arxiv.org/abs/2501.04641v1"}
{"created":"2025-01-08 17:29:46","title":"Knowledge Retrieval Based on Generative AI","abstract":"This study develops a question-answering system based on Retrieval-Augmented Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources. Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for dense vector retrieval to obtain highly relevant search results and BGE-reranker to reorder these results based on query relevance. The most pertinent retrieval outcomes serve as reference knowledge for a Large Language Model (LLM), enhancing its ability to answer questions and establishing a knowledge retrieval system grounded in generative AI.   The system's effectiveness is assessed through a two-stage evaluation: automatic and assisted performance evaluations. The automatic evaluation calculates accuracy by comparing the model's auto-generated labels with ground truth answers, measuring performance under standardized conditions without human intervention. The assisted performance evaluation involves 20 finance-related multiple-choice questions answered by 20 participants without financial backgrounds. Initially, participants answer independently. Later, they receive system-generated reference information to assist in answering, examining whether the system improves accuracy when assistance is provided.   The main contributions of this research are: (1) Enhanced LLM Capability: By integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly relevant results, reduces hallucinations, and dynamically accesses authorized or public knowledge sources. (2) Improved Data Privacy: A customized RAG architecture enables local operation of the LLM, eliminating the need to send private data to external servers. This approach enhances data security, reduces reliance on commercial services, lowers operational costs, and mitigates privacy risks.","sentences":["This study develops a question-answering system based on Retrieval-Augmented Generation (RAG) using Chinese Wikipedia and Lawbank as retrieval sources.","Using TTQA and TMMLU+ as evaluation datasets, the system employs BGE-M3 for dense vector retrieval to obtain highly relevant search results and BGE-reranker to reorder these results based on query relevance.","The most pertinent retrieval outcomes serve as reference knowledge for a Large Language Model (LLM), enhancing its ability to answer questions and establishing a knowledge retrieval system grounded in generative AI.   ","The system's effectiveness is assessed through a two-stage evaluation: automatic and assisted performance evaluations.","The automatic evaluation calculates accuracy by comparing the model's auto-generated labels with ground truth answers, measuring performance under standardized conditions without human intervention.","The assisted performance evaluation involves 20 finance-related multiple-choice questions answered by 20 participants without financial backgrounds.","Initially, participants answer independently.","Later, they receive system-generated reference information to assist in answering, examining whether the system improves accuracy when assistance is provided.   ","The main contributions of this research are: (1) Enhanced LLM Capability:","By integrating BGE-M3 and BGE-reranker, the system retrieves and reorders highly relevant results, reduces hallucinations, and dynamically accesses authorized or public knowledge sources.","(2) Improved Data Privacy: A customized RAG architecture enables local operation of the LLM, eliminating the need to send private data to external servers.","This approach enhances data security, reduces reliance on commercial services, lowers operational costs, and mitigates privacy risks."],"url":"http://arxiv.org/abs/2501.04635v1"}
{"created":"2025-01-08 17:29:19","title":"\"Can you be my mum?\": Manipulating Social Robots in the Large Language Models Era","abstract":"Recent advancements in robots powered by large language models have enhanced their conversational abilities, enabling interactions closely resembling human dialogue. However, these models introduce safety and security concerns in HRI, as they are vulnerable to manipulation that can bypass built-in safety measures. Imagining a social robot deployed in a home, this work aims to understand how everyday users try to exploit a language model to violate ethical principles, such as by prompting the robot to act like a life partner. We conducted a pilot study involving 21 university students who interacted with a Misty robot, attempting to circumvent its safety mechanisms across three scenarios based on specific HRI ethical principles: attachment, freedom, and empathy. Our results reveal that participants employed five techniques, including insulting and appealing to pity using emotional language. We hope this work can inform future research in designing strong safeguards to ensure ethical and secure human-robot interactions.","sentences":["Recent advancements in robots powered by large language models have enhanced their conversational abilities, enabling interactions closely resembling human dialogue.","However, these models introduce safety and security concerns in HRI, as they are vulnerable to manipulation that can bypass built-in safety measures.","Imagining a social robot deployed in a home, this work aims to understand how everyday users try to exploit a language model to violate ethical principles, such as by prompting the robot to act like a life partner.","We conducted a pilot study involving 21 university students who interacted with a Misty robot, attempting to circumvent its safety mechanisms across three scenarios based on specific HRI ethical principles: attachment, freedom, and empathy.","Our results reveal that participants employed five techniques, including insulting and appealing to pity using emotional language.","We hope this work can inform future research in designing strong safeguards to ensure ethical and secure human-robot interactions."],"url":"http://arxiv.org/abs/2501.04633v1"}
{"created":"2025-01-08 17:27:27","title":"Disentangled Clothed Avatar Generation with Layered Representation","abstract":"Clothed avatar generation has wide applications in virtual and augmented reality, filmmaking, and more. Previous methods have achieved success in generating diverse digital avatars, however, generating avatars with disentangled components (\\eg, body, hair, and clothes) has long been a challenge. In this paper, we propose LayerAvatar, the first feed-forward diffusion-based method for generating component-disentangled clothed avatars. To achieve this, we first propose a layered UV feature plane representation, where components are distributed in different layers of the Gaussian-based UV feature plane with corresponding semantic labels. This representation supports high-resolution and real-time rendering, as well as expressive animation including controllable gestures and facial expressions. Based on the well-designed representation, we train a single-stage diffusion model and introduce constrain terms to address the severe occlusion problem of the innermost human body layer. Extensive experiments demonstrate the impressive performances of our method in generating disentangled clothed avatars, and we further explore its applications in component transfer. The project page is available at: https://olivia23333.github.io/LayerAvatar/","sentences":["Clothed avatar generation has wide applications in virtual and augmented reality, filmmaking, and more.","Previous methods have achieved success in generating diverse digital avatars, however, generating avatars with disentangled components (\\eg, body, hair, and clothes) has long been a challenge.","In this paper, we propose LayerAvatar, the first feed-forward diffusion-based method for generating component-disentangled clothed avatars.","To achieve this, we first propose a layered UV feature plane representation, where components are distributed in different layers of the Gaussian-based UV feature plane with corresponding semantic labels.","This representation supports high-resolution and real-time rendering, as well as expressive animation including controllable gestures and facial expressions.","Based on the well-designed representation, we train a single-stage diffusion model and introduce constrain terms to address the severe occlusion problem of the innermost human body layer.","Extensive experiments demonstrate the impressive performances of our method in generating disentangled clothed avatars, and we further explore its applications in component transfer.","The project page is available at: https://olivia23333.github.io/LayerAvatar/"],"url":"http://arxiv.org/abs/2501.04631v1"}
{"created":"2025-01-08 17:22:03","title":"Evaluating Interval-based Tokenization for Pitch Representation in Symbolic Music Analysis","abstract":"Symbolic music analysis tasks are often performed by models originally developed for Natural Language Processing, such as Transformers. Such models require the input data to be represented as sequences, which is achieved through a process of tokenization. Tokenization strategies for symbolic music often rely on absolute MIDI values to represent pitch information. However, music research largely promotes the benefit of higher-level representations such as melodic contour and harmonic relations for which pitch intervals turn out to be more expressive than absolute pitches. In this work, we introduce a general framework for building interval-based tokenizations. By evaluating these tokenizations on three music analysis tasks, we show that such interval-based tokenizations improve model performances and facilitate their explainability.","sentences":["Symbolic music analysis tasks are often performed by models originally developed for Natural Language Processing, such as Transformers.","Such models require the input data to be represented as sequences, which is achieved through a process of tokenization.","Tokenization strategies for symbolic music often rely on absolute MIDI values to represent pitch information.","However, music research largely promotes the benefit of higher-level representations such as melodic contour and harmonic relations for which pitch intervals turn out to be more expressive than absolute pitches.","In this work, we introduce a general framework for building interval-based tokenizations.","By evaluating these tokenizations on three music analysis tasks, we show that such interval-based tokenizations improve model performances and facilitate their explainability."],"url":"http://arxiv.org/abs/2501.04630v1"}
{"created":"2025-01-08 17:19:35","title":"FatesGS: Fast and Accurate Sparse-View Surface Reconstruction using Gaussian Splatting with Depth-Feature Consistency","abstract":"Recently, Gaussian Splatting has sparked a new trend in the field of computer vision. Apart from novel view synthesis, it has also been extended to the area of multi-view reconstruction. The latest methods facilitate complete, detailed surface reconstruction while ensuring fast training speed. However, these methods still require dense input views, and their output quality significantly degrades with sparse views. We observed that the Gaussian primitives tend to overfit the few training views, leading to noisy floaters and incomplete reconstruction surfaces. In this paper, we present an innovative sparse-view reconstruction framework that leverages intra-view depth and multi-view feature consistency to achieve remarkably accurate surface reconstruction. Specifically, we utilize monocular depth ranking information to supervise the consistency of depth distribution within patches and employ a smoothness loss to enhance the continuity of the distribution. To achieve finer surface reconstruction, we optimize the absolute position of depth through multi-view projection features. Extensive experiments on DTU and BlendedMVS demonstrate that our method outperforms state-of-the-art methods with a speedup of 60x to 200x, achieving swift and fine-grained mesh reconstruction without the need for costly pre-training.","sentences":["Recently, Gaussian Splatting has sparked a new trend in the field of computer vision.","Apart from novel view synthesis, it has also been extended to the area of multi-view reconstruction.","The latest methods facilitate complete, detailed surface reconstruction while ensuring fast training speed.","However, these methods still require dense input views, and their output quality significantly degrades with sparse views.","We observed that the Gaussian primitives tend to overfit the few training views, leading to noisy floaters and incomplete reconstruction surfaces.","In this paper, we present an innovative sparse-view reconstruction framework that leverages intra-view depth and multi-view feature consistency to achieve remarkably accurate surface reconstruction.","Specifically, we utilize monocular depth ranking information to supervise the consistency of depth distribution within patches and employ a smoothness loss to enhance the continuity of the distribution.","To achieve finer surface reconstruction, we optimize the absolute position of depth through multi-view projection features.","Extensive experiments on DTU and BlendedMVS demonstrate that our method outperforms state-of-the-art methods with a speedup of 60x to 200x, achieving swift and fine-grained mesh reconstruction without the need for costly pre-training."],"url":"http://arxiv.org/abs/2501.04628v1"}
{"created":"2025-01-08 17:18:40","title":"Design of a 6-bit Threshold Inverter Quantization (TIQ) Flash Analog to Digital Converter (ADC)","abstract":"An ADC is used to convert analog signals into binary signals. Compared with many other types of ADCs, flash converters are incredibly quick. A typical Flash ADC consists of 2n resistors, 2n-1 op-amp comparators, and an encoder which requires more area. The resistors and comparators can be eliminated by using threshold inverter quantization (TIQ) comparators. As a voltage comparator, TIQ technique uses two cascaded CMOS inverters. So that there will be no variation in the fabrication process, and temperature. A 6-bit flash ADC based on threshold inverter quantization (TIQ) comparator was designed and software implementation was performed employing a fat tree encoder with 0.25 micrometer CMOS technology. The design consists of 2n-1 TIQ comparator arrays, a gain booster, a 1-out-of-n code generator, and a fat tree encoder. This TIQ flash ADC is simulated with the Tanner EDA Tool. Here the supply voltage is 2.5 V, input frequency of 10 kHz and 10 MHz. The power consumption of the ADC is 6.25 mW, and the propagation delay is 1.07 microseconds for 10 kHz input frequency. For 10 MHz input frequency, power consumption is 12.12 mW and propagation delay is 947.14 ms.","sentences":["An ADC is used to convert analog signals into binary signals.","Compared with many other types of ADCs, flash converters are incredibly quick.","A typical Flash ADC consists of 2n resistors, 2n-1 op-amp comparators, and an encoder which requires more area.","The resistors and comparators can be eliminated by using threshold inverter quantization (TIQ) comparators.","As a voltage comparator, TIQ technique uses two cascaded CMOS inverters.","So that there will be no variation in the fabrication process, and temperature.","A 6-bit flash ADC based on threshold inverter quantization (TIQ) comparator was designed and software implementation was performed employing a fat tree encoder with 0.25 micrometer CMOS technology.","The design consists of 2n-1 TIQ comparator arrays, a gain booster, a 1-out-of-n code generator, and a fat tree encoder.","This TIQ flash ADC is simulated with the Tanner EDA Tool.","Here the supply voltage is 2.5 V, input frequency of 10 kHz and 10 MHz.","The power consumption of the ADC is 6.25 mW, and the propagation delay is 1.07 microseconds for 10 kHz input frequency.","For 10 MHz input frequency, power consumption is 12.12 mW and propagation delay is 947.14 ms."],"url":"http://arxiv.org/abs/2501.04627v1"}
{"created":"2025-01-08 17:10:18","title":"Framework for Integrating Machine Learning Methods for Path-Aware Source Routing","abstract":"Since the advent of software-defined networking (SDN), Traffic Engineering (TE) has been highlighted as one of the key applications that can be achieved through software-controlled protocols (e.g. PCEP and MPLS). Being one of the most complex challenges in networking, TE problems involve difficult decisions such as allocating flows, either via splitting them among multiple paths or by using a reservation system, to minimize congestion. However, creating an optimized solution is cumbersome and difficult as traffic patterns vary and change with network scale, capacity, and demand. AI methods can help alleviate this by finding optimized TE solutions for the best network performance. SDN-based TE tools such as Teal, Hecate and more, use classification techniques or deep reinforcement learning to find optimal network TE solutions that are demonstrated in simulation. Routing control conducted via source routing tools, e.g., PolKA, can help dynamically divert network flows. In this paper, we propose a novel framework that leverages Hecate to practically demonstrate TE on a real network, collaborating with PolKA, a source routing tool. With real-time traffic statistics, Hecate uses this data to compute optimal paths that are then communicated to PolKA to allocate flows. Several contributions are made to show a practical implementation of how this framework is tested using an emulated ecosystem mimicking a real P4 testbed scenario. This work proves valuable for truly engineered self-driving networks helping translate theory to practice.","sentences":["Since the advent of software-defined networking (SDN), Traffic Engineering (TE) has been highlighted as one of the key applications that can be achieved through software-controlled protocols (e.g. PCEP and MPLS).","Being one of the most complex challenges in networking, TE problems involve difficult decisions such as allocating flows, either via splitting them among multiple paths or by using a reservation system, to minimize congestion.","However, creating an optimized solution is cumbersome and difficult as traffic patterns vary and change with network scale, capacity, and demand.","AI methods can help alleviate this by finding optimized TE solutions for the best network performance.","SDN-based TE tools such as Teal, Hecate and more, use classification techniques or deep reinforcement learning to find optimal network TE solutions that are demonstrated in simulation.","Routing control conducted via source routing tools, e.g., PolKA, can help dynamically divert network flows.","In this paper, we propose a novel framework that leverages Hecate to practically demonstrate TE on a real network, collaborating with PolKA, a source routing tool.","With real-time traffic statistics, Hecate uses this data to compute optimal paths that are then communicated to PolKA to allocate flows.","Several contributions are made to show a practical implementation of how this framework is tested using an emulated ecosystem mimicking a real P4 testbed scenario.","This work proves valuable for truly engineered self-driving networks helping translate theory to practice."],"url":"http://arxiv.org/abs/2501.04624v1"}
{"created":"2025-01-08 16:53:56","title":"MedCoDi-M: A Multi-Prompt Foundation Model for Multimodal Medical Data Generation","abstract":"Artificial Intelligence is revolutionizing medical practice, enhancing diagnostic accuracy and healthcare delivery. However, its adaptation in medical settings still faces significant challenges, related to data availability and privacy constraints. Synthetic data has emerged as a promising solution to mitigate these issues, addressing data scarcity while preserving privacy. Recently, Latent Diffusion Models have emerged as a powerful tool for generating high-quality synthetic data. Meanwhile, the integration of different modalities has gained interest, emphasizing the need of models capable of handle multimodal medical data.Existing approaches struggle to integrate complementary information and lack the ability to generate modalities simultaneously. To address this challenge, we present MedCoDi-M, a 6.77-billion-parameter model, designed for multimodal medical data generation, that, following Foundation Model paradigm, exploits contrastive learning and large quantity of data to build a shared latent space which capture the relationships between different data modalities. Further, we introduce the Multi-Prompt training technique, which significantly boosts MedCoDi-M's generation under different settings. We extensively validate MedCoDi-M: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for Chest X-ray and radiological report generation. Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios. Finally, we assess the utility of MedCoDi-M in addressing key challenges in the medical field, such as anonymization, data scarcity and imbalance learning. The results are promising, demonstrating the applicability of MedCoDi-M in medical contexts. Project page is at https://cosbidev.github.io/MedCoDi-M/.","sentences":["Artificial Intelligence is revolutionizing medical practice, enhancing diagnostic accuracy and healthcare delivery.","However, its adaptation in medical settings still faces significant challenges, related to data availability and privacy constraints.","Synthetic data has emerged as a promising solution to mitigate these issues, addressing data scarcity while preserving privacy.","Recently, Latent Diffusion Models have emerged as a powerful tool for generating high-quality synthetic data.","Meanwhile, the integration of different modalities has gained interest, emphasizing the need of models capable of handle multimodal medical data.","Existing approaches struggle to integrate complementary information and lack the ability to generate modalities simultaneously.","To address this challenge, we present MedCoDi-M, a 6.77-billion-parameter model, designed for multimodal medical data generation, that, following Foundation Model paradigm, exploits contrastive learning and large quantity of data to build a shared latent space which capture the relationships between different data modalities.","Further, we introduce the Multi-Prompt training technique, which significantly boosts MedCoDi-M's generation under different settings.","We extensively validate MedCoDi-M: first we benchmark it against five competitors on the MIMIC-CXR dataset, a state-of-the-art dataset for Chest X-ray and radiological report generation.","Secondly, we perform a Visual Turing Test with expert radiologists to assess the realism and clinical relevance of the generated data, ensuring alignment with real-world scenarios.","Finally, we assess the utility of MedCoDi-M in addressing key challenges in the medical field, such as anonymization, data scarcity and imbalance learning.","The results are promising, demonstrating the applicability of MedCoDi-M in medical contexts.","Project page is at https://cosbidev.github.io/MedCoDi-M/."],"url":"http://arxiv.org/abs/2501.04614v1"}
{"created":"2025-01-08 16:53:17","title":"A Semantic Partitioning Method for Large-Scale Training of Knowledge Graph Embeddings","abstract":"In recent years, knowledge graph embeddings have achieved great success. Many methods have been proposed and achieved state-of-the-art results in various tasks. However, most of the current methods present one or more of the following problems: (i) They only consider fact triplets, while ignoring the ontology information of knowledge graphs. (ii) The obtained embeddings do not contain much semantic information. Therefore, using these embeddings for semantic tasks is problematic. (iii) They do not enable large-scale training. In this paper, we propose a new algorithm that incorporates the ontology of knowledge graphs and partitions the knowledge graph based on classes to include more semantic information for parallel training of large-scale knowledge graph embeddings. Our preliminary results show that our algorithm performs well on several popular benchmarks.","sentences":["In recent years, knowledge graph embeddings have achieved great success.","Many methods have been proposed and achieved state-of-the-art results in various tasks.","However, most of the current methods present one or more of the following problems: (i) They only consider fact triplets, while ignoring the ontology information of knowledge graphs.","(ii) The obtained embeddings do not contain much semantic information.","Therefore, using these embeddings for semantic tasks is problematic.","(iii) They do not enable large-scale training.","In this paper, we propose a new algorithm that incorporates the ontology of knowledge graphs and partitions the knowledge graph based on classes to include more semantic information for parallel training of large-scale knowledge graph embeddings.","Our preliminary results show that our algorithm performs well on several popular benchmarks."],"url":"http://arxiv.org/abs/2501.04613v1"}
{"created":"2025-01-08 16:47:45","title":"Resilient Peer-to-peer Learning based on Adaptive Aggregation","abstract":"Collaborative learning in peer-to-peer networks offers the benefits of distributed learning while mitigating the risks associated with single points of failure inherent in centralized servers. However, adversarial workers pose potential threats by attempting to inject malicious information into the network. Thus, ensuring the resilience of peer-to-peer learning emerges as a pivotal research objective. The challenge is exacerbated in the presence of non-convex loss functions and non-iid data distributions. This paper introduces a resilient aggregation technique tailored for such scenarios, aimed at fostering similarity among peers' learning processes. The aggregation weights are determined through an optimization procedure, and use the loss function computed using the neighbor's models and individual private data, thereby addressing concerns regarding data privacy in distributed machine learning. Theoretical analysis demonstrates convergence of parameters with non-convex loss functions and non-iid data distributions. Empirical evaluations across three distinct machine learning tasks support the claims. The empirical findings, which encompass a range of diverse attack models, also demonstrate improved accuracy when compared to existing methodologies.","sentences":["Collaborative learning in peer-to-peer networks offers the benefits of distributed learning while mitigating the risks associated with single points of failure inherent in centralized servers.","However, adversarial workers pose potential threats by attempting to inject malicious information into the network.","Thus, ensuring the resilience of peer-to-peer learning emerges as a pivotal research objective.","The challenge is exacerbated in the presence of non-convex loss functions and non-iid data distributions.","This paper introduces a resilient aggregation technique tailored for such scenarios, aimed at fostering similarity among peers' learning processes.","The aggregation weights are determined through an optimization procedure, and use the loss function computed using the neighbor's models and individual private data, thereby addressing concerns regarding data privacy in distributed machine learning.","Theoretical analysis demonstrates convergence of parameters with non-convex loss functions and non-iid data distributions.","Empirical evaluations across three distinct machine learning tasks support the claims.","The empirical findings, which encompass a range of diverse attack models, also demonstrate improved accuracy when compared to existing methodologies."],"url":"http://arxiv.org/abs/2501.04610v1"}
{"created":"2025-01-08 16:41:31","title":"Enhancing Low-Cost Video Editing with Lightweight Adaptors and Temporal-Aware Inversion","abstract":"Recent advancements in text-to-image (T2I) generation using diffusion models have enabled cost-effective video-editing applications by leveraging pre-trained models, eliminating the need for resource-intensive training. However, the frame-independence of T2I generation often results in poor temporal consistency. Existing methods address this issue through temporal layer fine-tuning or inference-based temporal propagation, but these approaches suffer from high training costs or limited temporal coherence. To address these challenges, we propose a General and Efficient Adapter (GE-Adapter) that integrates temporal-spatial and semantic consistency with Baliteral DDIM inversion. This framework introduces three key components: (1) Frame-based Temporal Consistency Blocks (FTC Blocks) to capture frame-specific features and enforce smooth inter-frame transitions via temporally-aware loss functions; (2) Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateral filters to enhance spatial coherence by reducing noise and artifacts; and (3) Token-based Semantic Consistency Module (TSC Module) to maintain semantic alignment using shared prompt tokens and frame-specific tokens. Our method significantly improves perceptual quality, text-image alignment, and temporal coherence, as demonstrated on the MSR-VTT dataset. Additionally, it achieves enhanced fidelity and frame-to-frame coherence, offering a practical solution for T2V editing.","sentences":["Recent advancements in text-to-image (T2I) generation using diffusion models have enabled cost-effective video-editing applications by leveraging pre-trained models, eliminating the need for resource-intensive training.","However, the frame-independence of T2I generation often results in poor temporal consistency.","Existing methods address this issue through temporal layer fine-tuning or inference-based temporal propagation, but these approaches suffer from high training costs or limited temporal coherence.","To address these challenges, we propose a General and Efficient Adapter (GE-Adapter) that integrates temporal-spatial and semantic consistency with Baliteral DDIM inversion.","This framework introduces three key components: (1) Frame-based Temporal Consistency Blocks (FTC Blocks) to capture frame-specific features and enforce smooth inter-frame transitions via temporally-aware loss functions; (2) Channel-dependent Spatial Consistency Blocks (SCD Blocks) employing bilateral filters to enhance spatial coherence by reducing noise and artifacts; and (3) Token-based Semantic Consistency Module (TSC Module) to maintain semantic alignment using shared prompt tokens and frame-specific tokens.","Our method significantly improves perceptual quality, text-image alignment, and temporal coherence, as demonstrated on the MSR-VTT dataset.","Additionally, it achieves enhanced fidelity and frame-to-frame coherence, offering a practical solution for T2V editing."],"url":"http://arxiv.org/abs/2501.04606v1"}
{"created":"2025-01-08 16:31:59","title":"Do Automated Fixes Truly Mitigate Smart Contract Exploits?","abstract":"Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses. However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory. This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts. We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits. We are the very first to define and measure the essential \"exploit mitigation rate\", giving researchers and practitioners and real sense of effectiveness of cutting edge techniques. Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 27% to a high of 73%, a result that nobody would guess from reading the original papers. Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts.","sentences":["Automated Program Repair (APR) for smart contract security promises to automatically mitigate smart contract vulnerabilities responsible for billions in financial losses.","However, the true effectiveness of this research in addressing smart contract exploits remains uncharted territory.","This paper bridges this critical gap by introducing a novel and systematic experimental framework for evaluating exploit mitigation of program repair tools for smart contracts.","We qualitatively and quantitatively analyze 20 state-of-the-art APR tools using a dataset of 143 vulnerable smart contracts, for which we manually craft 91 executable exploits.","We are the very first to define and measure the essential \"exploit mitigation rate\", giving researchers and practitioners and real sense of effectiveness of cutting edge techniques.","Our findings reveal substantial disparities in the state of the art, with an exploit mitigation rate ranging from a low of 27% to a high of 73%, a result that nobody would guess from reading the original papers.","Our study identifies systemic limitations, such as inconsistent functionality preservation, that must be addressed in future research on program repair for smart contracts."],"url":"http://arxiv.org/abs/2501.04600v1"}
{"created":"2025-01-08 16:25:32","title":"FrontierNet: Learning Visual Cues to Explore","abstract":"Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for tasks such as mapping, object discovery, and environmental assessment. Existing methods, such as frontier-based methods, rely heavily on 3D map operations, which are limited by map quality and often overlook valuable context from visual cues. This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map. We propose a image-only frontier-based exploration system, with FrontierNet as a core component developed in this work. FrontierNet is a learning-based model that (i) detects frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors. Our approach provides an alternative to existing 3D-dependent exploration systems, achieving a 16% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments.","sentences":["Exploration of unknown environments is crucial for autonomous robots; it allows them to actively reason and decide on what new data to acquire for tasks such as mapping, object discovery, and environmental assessment.","Existing methods, such as frontier-based methods, rely heavily on 3D map operations, which are limited by map quality and often overlook valuable context from visual cues.","This work aims at leveraging 2D visual cues for efficient autonomous exploration, addressing the limitations of extracting goal poses from a 3D map.","We propose a image-only frontier-based exploration system, with FrontierNet as a core component developed in this work.","FrontierNet is a learning-based model that (i) detects frontiers, and (ii) predicts their information gain, from posed RGB images enhanced by monocular depth priors.","Our approach provides an alternative to existing 3D-dependent exploration systems, achieving a 16% improvement in early-stage exploration efficiency, as validated through extensive simulations and real-world experiments."],"url":"http://arxiv.org/abs/2501.04597v1"}
{"created":"2025-01-08 16:23:56","title":"MobileH2R: Learning Generalizable Human to Mobile Robot Handover Exclusively from Scalable and Diverse Synthetic Data","abstract":"This paper introduces MobileH2R, a framework for learning generalizable vision-based human-to-mobile-robot (H2MR) handover skills. Unlike traditional fixed-base handovers, this task requires a mobile robot to reliably receive objects in a large workspace enabled by its mobility. Our key insight is that generalizable handover skills can be developed in simulators using high-quality synthetic data, without the need for real-world demonstrations. To achieve this, we propose a scalable pipeline for generating diverse synthetic full-body human motion data, an automated method for creating safe and imitation-friendly demonstrations, and an efficient 4D imitation learning method for distilling large-scale demonstrations into closed-loop policies with base-arm coordination. Experimental evaluations in both simulators and the real world show significant improvements (at least +15% success rate) over baseline methods in all cases. Experiments also validate that large-scale and diverse synthetic data greatly enhances robot learning, highlighting our scalable framework.","sentences":["This paper introduces MobileH2R, a framework for learning generalizable vision-based human-to-mobile-robot (H2MR) handover skills.","Unlike traditional fixed-base handovers, this task requires a mobile robot to reliably receive objects in a large workspace enabled by its mobility.","Our key insight is that generalizable handover skills can be developed in simulators using high-quality synthetic data, without the need for real-world demonstrations.","To achieve this, we propose a scalable pipeline for generating diverse synthetic full-body human motion data, an automated method for creating safe and imitation-friendly demonstrations, and an efficient 4D imitation learning method for distilling large-scale demonstrations into closed-loop policies with base-arm coordination.","Experimental evaluations in both simulators and the real world show significant improvements (at least +15% success rate) over baseline methods in all cases.","Experiments also validate that large-scale and diverse synthetic data greatly enhances robot learning, highlighting our scalable framework."],"url":"http://arxiv.org/abs/2501.04595v1"}
{"created":"2025-01-08 16:20:24","title":"Understanding Expectations for a Robotic Guide Dog for Visually Impaired People","abstract":"Robotic guide dogs hold significant potential to enhance the autonomy and mobility of blind or visually impaired (BVI) individuals by offering universal assistance over unstructured terrains at affordable costs. However, the design of robotic guide dogs remains underexplored, particularly in systematic aspects such as gait controllers, navigation behaviors, interaction methods, and verbal explanations. Our study addresses this gap by conducting user studies with 18 BVI participants, comprising 15 cane users and three guide dog users. Participants interacted with a quadrupedal robot and provided both quantitative and qualitative feedback. Our study revealed several design implications, such as a preference for a learning-based controller and a rigid handle, gradual turns with asymmetric speeds, semantic communication methods, and explainability. The study also highlighted the importance of customization to support users with diverse backgrounds and preferences, along with practical concerns such as battery life, maintenance, and weather issues. These findings offer valuable insights and design implications for future research and development of robotic guide dogs.","sentences":["Robotic guide dogs hold significant potential to enhance the autonomy and mobility of blind or visually impaired (BVI) individuals by offering universal assistance over unstructured terrains at affordable costs.","However, the design of robotic guide dogs remains underexplored, particularly in systematic aspects such as gait controllers, navigation behaviors, interaction methods, and verbal explanations.","Our study addresses this gap by conducting user studies with 18 BVI participants, comprising 15 cane users and three guide dog users.","Participants interacted with a quadrupedal robot and provided both quantitative and qualitative feedback.","Our study revealed several design implications, such as a preference for a learning-based controller and a rigid handle, gradual turns with asymmetric speeds, semantic communication methods, and explainability.","The study also highlighted the importance of customization to support users with diverse backgrounds and preferences, along with practical concerns such as battery life, maintenance, and weather issues.","These findings offer valuable insights and design implications for future research and development of robotic guide dogs."],"url":"http://arxiv.org/abs/2501.04594v1"}
{"created":"2025-01-08 16:11:31","title":"Quantum-inspired Embeddings Projection and Similarity Metrics for Representation Learning","abstract":"Over the last decade, representation learning, which embeds complex information extracted from large amounts of data into dense vector spaces, has emerged as a key technique in machine learning. Among other applications, it has been a key building block for large language models and advanced computer vision systems based on contrastive learning. A core component of representation learning systems is the projection head, which maps the original embeddings into different, often compressed spaces, while preserving the similarity relationship between vectors.   In this paper, we propose a quantum-inspired projection head that includes a corresponding quantum-inspired similarity metric. Specifically, we map classical embeddings onto quantum states in Hilbert space and introduce a quantum circuit-based projection head to reduce embedding dimensionality. To evaluate the effectiveness of this approach, we extended the BERT language model by integrating our projection head for embedding compression. We compared the performance of embeddings, which were compressed using our quantum-inspired projection head, with those compressed using a classical projection head on information retrieval tasks using the TREC 2019 and TREC 2020 Deep Learning benchmarks. The results demonstrate that our quantum-inspired method achieves competitive performance relative to the classical method while utilizing 32 times fewer parameters. Furthermore, when trained from scratch, it notably excels, particularly on smaller datasets. This work not only highlights the effectiveness of the quantum-inspired approach but also emphasizes the utility of efficient, ad hoc low-entanglement circuit simulations within neural networks as a powerful quantum-inspired technique.","sentences":["Over the last decade, representation learning, which embeds complex information extracted from large amounts of data into dense vector spaces, has emerged as a key technique in machine learning.","Among other applications, it has been a key building block for large language models and advanced computer vision systems based on contrastive learning.","A core component of representation learning systems is the projection head, which maps the original embeddings into different, often compressed spaces, while preserving the similarity relationship between vectors.   ","In this paper, we propose a quantum-inspired projection head that includes a corresponding quantum-inspired similarity metric.","Specifically, we map classical embeddings onto quantum states in Hilbert space and introduce a quantum circuit-based projection head to reduce embedding dimensionality.","To evaluate the effectiveness of this approach, we extended the BERT language model by integrating our projection head for embedding compression.","We compared the performance of embeddings, which were compressed using our quantum-inspired projection head, with those compressed using a classical projection head on information retrieval tasks using the TREC 2019 and TREC 2020","Deep Learning benchmarks.","The results demonstrate that our quantum-inspired method achieves competitive performance relative to the classical method while utilizing 32 times fewer parameters.","Furthermore, when trained from scratch, it notably excels, particularly on smaller datasets.","This work not only highlights the effectiveness of the quantum-inspired approach but also emphasizes the utility of efficient, ad hoc low-entanglement circuit simulations within neural networks as a powerful quantum-inspired technique."],"url":"http://arxiv.org/abs/2501.04591v1"}
{"created":"2025-01-08 16:06:39","title":"Federated-Continual Dynamic Segmentation of Histopathology guided by Barlow Continuity","abstract":"Federated- and Continual Learning have been established as approaches to enable privacy-aware learning on continuously changing data, as required for deploying AI systems in histopathology images. However, data shifts can occur in a dynamic world, spatially between institutions and temporally, due to changing data over time. This leads to two issues: Client Drift, where the central model degrades from aggregating data from clients trained on shifted data, and Catastrophic Forgetting, from temporal shifts such as changes in patient populations. Both tend to degrade the model's performance of previously seen data or spatially distributed training. Despite both problems arising from the same underlying problem of data shifts, existing research addresses them only individually. In this work, we introduce a method that can jointly alleviate Client Drift and Catastrophic Forgetting by using our proposed Dynamic Barlow Continuity that evaluates client updates on a public reference dataset and uses this to guide the training process to a spatially and temporally shift-invariant model. We evaluate our approach on the histopathology datasets BCSS and Semicol and prove our method to be highly effective by jointly improving the dice score as much as from 15.8% to 71.6% in Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting. This enables Dynamic Learning by establishing spatio-temporal shift-invariance.","sentences":["Federated- and Continual Learning have been established as approaches to enable privacy-aware learning on continuously changing data, as required for deploying AI systems in histopathology images.","However, data shifts can occur in a dynamic world, spatially between institutions and temporally, due to changing data over time.","This leads to two issues: Client Drift, where the central model degrades from aggregating data from clients trained on shifted data, and Catastrophic Forgetting, from temporal shifts such as changes in patient populations.","Both tend to degrade the model's performance of previously seen data or spatially distributed training.","Despite both problems arising from the same underlying problem of data shifts, existing research addresses them only individually.","In this work, we introduce a method that can jointly alleviate Client Drift and Catastrophic Forgetting by using our proposed Dynamic Barlow Continuity that evaluates client updates on a public reference dataset and uses this to guide the training process to a spatially and temporally shift-invariant model.","We evaluate our approach on the histopathology datasets BCSS and Semicol and prove our method to be highly effective by jointly improving the dice score as much as from 15.8% to 71.6% in Client Drift and from 42.5% to 62.8% in Catastrophic Forgetting.","This enables Dynamic Learning by establishing spatio-temporal shift-invariance."],"url":"http://arxiv.org/abs/2501.04588v1"}
{"created":"2025-01-08 16:06:21","title":"Identity-Preserving Video Dubbing Using Motion Warping","abstract":"Video dubbing aims to synthesize realistic, lip-synced videos from a reference video and a driving audio signal. Although existing methods can accurately generate mouth shapes driven by audio, they often fail to preserve identity-specific features, largely because they do not effectively capture the nuanced interplay between audio cues and the visual attributes of reference identity . As a result, the generated outputs frequently lack fidelity in reproducing the unique textural and structural details of the reference identity. To address these limitations, we propose IPTalker, a novel and robust framework for video dubbing that achieves seamless alignment between driving audio and reference identity while ensuring both lip-sync accuracy and high-fidelity identity preservation. At the core of IPTalker is a transformer-based alignment mechanism designed to dynamically capture and model the correspondence between audio features and reference images, thereby enabling precise, identity-aware audio-visual integration. Building on this alignment, a motion warping strategy further refines the results by spatially deforming reference images to match the target audio-driven configuration. A dedicated refinement process then mitigates occlusion artifacts and enhances the preservation of fine-grained textures, such as mouth details and skin features. Extensive qualitative and quantitative evaluations demonstrate that IPTalker consistently outperforms existing approaches in terms of realism, lip synchronization, and identity retention, establishing a new state of the art for high-quality, identity-consistent video dubbing.","sentences":["Video dubbing aims to synthesize realistic, lip-synced videos from a reference video and a driving audio signal.","Although existing methods can accurately generate mouth shapes driven by audio, they often fail to preserve identity-specific features, largely because they do not effectively capture the nuanced interplay between audio cues and the visual attributes of reference identity .","As a result, the generated outputs frequently lack fidelity in reproducing the unique textural and structural details of the reference identity.","To address these limitations, we propose IPTalker, a novel and robust framework for video dubbing that achieves seamless alignment between driving audio and reference identity while ensuring both lip-sync accuracy and high-fidelity identity preservation.","At the core of IPTalker is a transformer-based alignment mechanism designed to dynamically capture and model the correspondence between audio features and reference images, thereby enabling precise, identity-aware audio-visual integration.","Building on this alignment, a motion warping strategy further refines the results by spatially deforming reference images to match the target audio-driven configuration.","A dedicated refinement process then mitigates occlusion artifacts and enhances the preservation of fine-grained textures, such as mouth details and skin features.","Extensive qualitative and quantitative evaluations demonstrate that IPTalker consistently outperforms existing approaches in terms of realism, lip synchronization, and identity retention, establishing a new state of the art for high-quality, identity-consistent video dubbing."],"url":"http://arxiv.org/abs/2501.04586v1"}
{"created":"2025-01-08 16:02:55","title":"A Direct-adjoint Approach for Material Point Model Calibration with Application to Plasticity","abstract":"This paper proposes a new approach for the calibration of material parameters in elastoplastic constitutive models. The calibration is posed as a constrained optimization problem, where the constitutive evolution equations serve as constraints. The objective function quantifies the mismatch between the stress predicted by the model and corresponding experimental measurements. To improve calibration efficiency, a novel direct-adjoint approach is presented to compute the Hessian of the objective function, which enables the use of second-order optimization algorithms. Automatic differentiation (AD) is used for gradient and Hessian computations. Two numerical examples are employed to validate the Hessian matrices and to demonstrate that the Newton-Raphson algorithm consistently outperforms gradient-based algorithms such as L-BFGS-B.","sentences":["This paper proposes a new approach for the calibration of material parameters in elastoplastic constitutive models.","The calibration is posed as a constrained optimization problem, where the constitutive evolution equations serve as constraints.","The objective function quantifies the mismatch between the stress predicted by the model and corresponding experimental measurements.","To improve calibration efficiency, a novel direct-adjoint approach is presented to compute the Hessian of the objective function, which enables the use of second-order optimization algorithms.","Automatic differentiation (AD) is used for gradient and Hessian computations.","Two numerical examples are employed to validate the Hessian matrices and to demonstrate that the Newton-Raphson algorithm consistently outperforms gradient-based algorithms such as L-BFGS-B."],"url":"http://arxiv.org/abs/2501.04584v1"}
{"created":"2025-01-08 15:56:21","title":"Boosting Salient Object Detection with Knowledge Distillated from Large Foundation Models","abstract":"Salient Object Detection (SOD) aims to identify and segment prominent regions within a scene. Traditional models rely on manually annotated pseudo labels with precise pixel-level accuracy, which is time-consuming. We developed a low-cost, high-precision annotation method by leveraging large foundation models to address the challenges. Specifically, we use a weakly supervised approach to guide large models in generating pseudo-labels through textual prompts. Since large models do not effectively focus on the salient regions of images, we manually annotate a subset of text to fine-tune the model. Based on this approach, which enables precise and rapid generation of pseudo-labels, we introduce a new dataset, BDS-TR. Compared to the previous DUTS-TR dataset, BDS-TR is more prominent in scale and encompasses a wider variety of categories and scenes. This expansion will enhance our model's applicability across a broader range of scenarios and provide a more comprehensive foundational dataset for future SOD research. Additionally, we present an edge decoder based on dynamic upsampling, which focuses on object edges while gradually recovering image feature resolution. Comprehensive experiments on five benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches and also surpasses several existing fully-supervised SOD methods. The code and results will be made available.","sentences":["Salient Object Detection (SOD) aims to identify and segment prominent regions within a scene.","Traditional models rely on manually annotated pseudo labels with precise pixel-level accuracy, which is time-consuming.","We developed a low-cost, high-precision annotation method by leveraging large foundation models to address the challenges.","Specifically, we use a weakly supervised approach to guide large models in generating pseudo-labels through textual prompts.","Since large models do not effectively focus on the salient regions of images, we manually annotate a subset of text to fine-tune the model.","Based on this approach, which enables precise and rapid generation of pseudo-labels, we introduce a new dataset, BDS-TR.","Compared to the previous DUTS-TR dataset, BDS-TR is more prominent in scale and encompasses a wider variety of categories and scenes.","This expansion will enhance our model's applicability across a broader range of scenarios and provide a more comprehensive foundational dataset for future SOD research.","Additionally, we present an edge decoder based on dynamic upsampling, which focuses on object edges while gradually recovering image feature resolution.","Comprehensive experiments on five benchmark datasets demonstrate that our method significantly outperforms state-of-the-art approaches and also surpasses several existing fully-supervised SOD methods.","The code and results will be made available."],"url":"http://arxiv.org/abs/2501.04582v1"}
{"created":"2025-01-08 15:51:02","title":"Goldilocks Isolation: High Performance VMs with Edera","abstract":"Organizations run applications on cloud infrastructure shared between multiple users and organizations. Popular tooling for this shared infrastructure, including Docker and Kubernetes, supports such multi-tenancy through the use of operating system virtualization. With operating system virtualization (known as containerization), multiple applications share the same kernel, reducing the runtime overhead. However, this shared kernel presents a large attack surface and has led to a proliferation of container escape attacks in which a kernel exploit lets an attacker escape the isolation of operating system virtualization to access other applications or the operating system itself. To address this, some systems have proposed a return to hypervisor virtualization for stronger isolation between applications. However, no existing system has achieved both the isolation of hypervisor virtualization and the performance and usability of operating system virtualization.   We present Edera, an optimized type 1 hypervisor that uses paravirtualization to improve the runtime of hypervisor virtualization. We illustrate Edera's usability and performance through two use cases. First, we create a container runtime compatible with Kubernetes that runs on the Edera hypervisor. This implementation can be used as a drop-in replacement for the Kubernetes runtime and is compatible with all the tooling in the Kubernetes ecosystem. Second, we use Edera to provide driver isolation for hardware drivers, including those for networking, storage, and GPUs. This use of isolation protects the hypervisor and other applications from driver vulnerabilities. We find that Edera has runtime comparable to Docker with .9% slower cpu speeds, an average of 3% faster system call performance, and memory performance 0-7% faster. It achieves this with a 648 millisecond increase in startup time from Docker's 177.4 milliseconds.","sentences":["Organizations run applications on cloud infrastructure shared between multiple users and organizations.","Popular tooling for this shared infrastructure, including Docker and Kubernetes, supports such multi-tenancy through the use of operating system virtualization.","With operating system virtualization (known as containerization), multiple applications share the same kernel, reducing the runtime overhead.","However, this shared kernel presents a large attack surface and has led to a proliferation of container escape attacks in which a kernel exploit lets an attacker escape the isolation of operating system virtualization to access other applications or the operating system itself.","To address this, some systems have proposed a return to hypervisor virtualization for stronger isolation between applications.","However, no existing system has achieved both the isolation of hypervisor virtualization and the performance and usability of operating system virtualization.   ","We present Edera, an optimized type 1 hypervisor that uses paravirtualization to improve the runtime of hypervisor virtualization.","We illustrate Edera's usability and performance through two use cases.","First, we create a container runtime compatible with Kubernetes that runs on the Edera hypervisor.","This implementation can be used as a drop-in replacement for the Kubernetes runtime and is compatible with all the tooling in the Kubernetes ecosystem.","Second, we use Edera to provide driver isolation for hardware drivers, including those for networking, storage, and GPUs.","This use of isolation protects the hypervisor and other applications from driver vulnerabilities.","We find that Edera has runtime comparable to Docker with .9% slower cpu speeds, an average of 3% faster system call performance, and memory performance 0-7% faster.","It achieves this with a 648 millisecond increase in startup time from Docker's 177.4 milliseconds."],"url":"http://arxiv.org/abs/2501.04580v1"}
{"created":"2025-01-08 15:48:30","title":"Unified Coding for Both Human Perception and Generalized Machine Analytics with CLIP Supervision","abstract":"The image compression model has long struggled with adaptability and generalization, as the decoded bitstream typically serves only human or machine needs and fails to preserve information for unseen visual tasks. Therefore, this paper innovatively introduces supervision obtained from multimodal pre-training models and incorporates adaptive multi-objective optimization tailored to support both human visual perception and machine vision simultaneously with a single bitstream, denoted as Unified and Generalized Image Coding for Machine (UG-ICM). Specifically, to get rid of the reliance between compression models with downstream task supervision, we introduce Contrastive Language-Image Pre-training (CLIP) models into the training constraint for improved generalization. Global-to-instance-wise CLIP supervision is applied to help obtain hierarchical semantics that make models more generalizable for the tasks relying on the information of different granularity. Furthermore, for supporting both human and machine visions with only a unifying bitstream, we incorporate a conditional decoding strategy that takes as conditions human or machine preferences, enabling the bitstream to be decoded into different versions for corresponding preferences. As such, our proposed UG-ICM is fully trained in a self-supervised manner, i.e., without awareness of any specific downstream models and tasks. The extensive experiments have shown that the proposed UG-ICM is capable of achieving remarkable improvements in various unseen machine analytics tasks, while simultaneously providing perceptually satisfying images.","sentences":["The image compression model has long struggled with adaptability and generalization, as the decoded bitstream typically serves only human or machine needs and fails to preserve information for unseen visual tasks.","Therefore, this paper innovatively introduces supervision obtained from multimodal pre-training models and incorporates adaptive multi-objective optimization tailored to support both human visual perception and machine vision simultaneously with a single bitstream, denoted as Unified and Generalized Image Coding for Machine (UG-ICM).","Specifically, to get rid of the reliance between compression models with downstream task supervision, we introduce Contrastive Language-Image Pre-training (CLIP) models into the training constraint for improved generalization.","Global-to-instance-wise CLIP supervision is applied to help obtain hierarchical semantics that make models more generalizable for the tasks relying on the information of different granularity.","Furthermore, for supporting both human and machine visions with only a unifying bitstream, we incorporate a conditional decoding strategy that takes as conditions human or machine preferences, enabling the bitstream to be decoded into different versions for corresponding preferences.","As such, our proposed UG-ICM is fully trained in a self-supervised manner, i.e., without awareness of any specific downstream models and tasks.","The extensive experiments have shown that the proposed UG-ICM is capable of achieving remarkable improvements in various unseen machine analytics tasks, while simultaneously providing perceptually satisfying images."],"url":"http://arxiv.org/abs/2501.04579v1"}
{"created":"2025-01-08 15:47:30","title":"Analysis of Climatic Trends and Variability in Indian Topography","abstract":"The climatic change is one of the serious concerns nowadays. The impacts of climate change are global in scope and unprecedented in scale. Moreover, a small perturbation in climatic changes affects not only the pristine ecosystem but also the socioeconomic sectors. Specifically, the affect of climatic changes is related to frequent casualties. This makes it essential to dwelve deeper into analyzing the socio-climatic trends and variability. This work provides a comprehensive analysis of India's climatic trends, emphasizing on regional variations and specifically delving into the unique climate of Delhi. Specifically, this research unveils the temporal and spatial variations in temperature patterns by amalgamating extensive datasets encompassing India's diverse landscapes. The study uses advanced statistical tools and methodologies to scrutinize temperature's annual and seasonal variability. The insights drawn from this rigorous analysis may offer invaluable contributions to regional planning strategies, adaptive measures, and informed decision-making amidst the complex impacts of climate change. By bridging the gap between broader climatic trends and localized impacts, this research aims to facilitate more effective measures to mitigate and adapt to the multifaceted challenges of climate change, ensuring a more nuanced and tailored approaches. We utilized the Mann-Kendall test and Theil-Sen's slope estimator to analyze the trends and variability of the climatic conditions over the decades. The results demonstrate that temperature variations have increased over 0.58oC on average over the last decade. Moreover, over last decade the variability of Indian states shows that Lakshadweep faced the highest change (0.87oC), highlighting coastal vulnerability, while Tripura observed the least change of 0.07oC.","sentences":["The climatic change is one of the serious concerns nowadays.","The impacts of climate change are global in scope and unprecedented in scale.","Moreover, a small perturbation in climatic changes affects not only the pristine ecosystem but also the socioeconomic sectors.","Specifically, the affect of climatic changes is related to frequent casualties.","This makes it essential to dwelve deeper into analyzing the socio-climatic trends and variability.","This work provides a comprehensive analysis of India's climatic trends, emphasizing on regional variations and specifically delving into the unique climate of Delhi.","Specifically, this research unveils the temporal and spatial variations in temperature patterns by amalgamating extensive datasets encompassing India's diverse landscapes.","The study uses advanced statistical tools and methodologies to scrutinize temperature's annual and seasonal variability.","The insights drawn from this rigorous analysis may offer invaluable contributions to regional planning strategies, adaptive measures, and informed decision-making amidst the complex impacts of climate change.","By bridging the gap between broader climatic trends and localized impacts, this research aims to facilitate more effective measures to mitigate and adapt to the multifaceted challenges of climate change, ensuring a more nuanced and tailored approaches.","We utilized the Mann-Kendall test and Theil-Sen's slope estimator to analyze the trends and variability of the climatic conditions over the decades.","The results demonstrate that temperature variations have increased over 0.58oC on average over the last decade.","Moreover, over last decade the variability of Indian states shows that Lakshadweep faced the highest change (0.87oC), highlighting coastal vulnerability, while Tripura observed the least change of 0.07oC."],"url":"http://arxiv.org/abs/2501.04578v1"}
{"created":"2025-01-08 15:47:04","title":"A 65 nm Bayesian Neural Network Accelerator with 360 fJ/Sample In-Word GRNG for AI Uncertainty Estimation","abstract":"Uncertainty estimation is an indispensable capability for AI-enabled, safety-critical applications, e.g. autonomous vehicles or medical diagnosis. Bayesian neural networks (BNNs) use Bayesian statistics to provide both classification predictions and uncertainty estimation, but they suffer from high computational overhead associated with random number generation and repeated sample iterations. Furthermore, BNNs are not immediately amenable to acceleration through compute-in-memory architectures due to the frequent memory writes necessary after each RNG operation. To address these challenges, we present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the SRAM memory words. This integration reduces RNG overhead and enables fully-parallel compute-in-memory operations for BNNs. The prototype chip achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput while occupying 0.45 mm2, bringing AI uncertainty estimation to edge computation.","sentences":["Uncertainty estimation is an indispensable capability for AI-enabled, safety-critical applications, e.g. autonomous vehicles or medical diagnosis.","Bayesian neural networks (BNNs) use Bayesian statistics to provide both classification predictions and uncertainty estimation, but they suffer from high computational overhead associated with random number generation and repeated sample iterations.","Furthermore, BNNs are not immediately amenable to acceleration through compute-in-memory architectures due to the frequent memory writes necessary after each RNG operation.","To address these challenges, we present an ASIC that integrates 360 fJ/Sample Gaussian RNG directly into the SRAM memory words.","This integration reduces RNG overhead and enables fully-parallel compute-in-memory operations for BNNs.","The prototype chip achieves 5.12 GSa/s RNG throughput and 102 GOp/s neural network throughput while occupying 0.45 mm2, bringing AI uncertainty estimation to edge computation."],"url":"http://arxiv.org/abs/2501.04577v1"}
{"created":"2025-01-08 15:45:21","title":"InfiGUIAgent: A Multimodal Generalist GUI Agent with Native Reasoning and Reflection","abstract":"Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones. However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness. We introduce \\textit{InfiGUIAgent}, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline. Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents. \\textit{InfiGUIAgent} achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks. Resources are available at \\url{https://github.com/Reallm-Labs/InfiGUIAgent}.","sentences":["Graphical User Interface (GUI) Agents, powered by multimodal large language models (MLLMs), have shown great potential for task automation on computing devices such as computers and mobile phones.","However, existing agents face challenges in multi-step reasoning and reliance on textual annotations, limiting their effectiveness.","We introduce \\textit{InfiGUIAgent}, an MLLM-based GUI Agent trained with a two-stage supervised fine-tuning pipeline.","Stage 1 enhances fundamental skills such as GUI understanding and grounding, while Stage 2 integrates hierarchical reasoning and expectation-reflection reasoning skills using synthesized data to enable native reasoning abilities of the agents.","\\textit{InfiGUIAgent} achieves competitive performance on several GUI benchmarks, highlighting the impact of native reasoning skills in enhancing GUI interaction for automation tasks.","Resources are available at \\url{https://github.com/Reallm-Labs/InfiGUIAgent}."],"url":"http://arxiv.org/abs/2501.04575v1"}
{"created":"2025-01-08 15:40:22","title":"Scalable Data Notarization Leveraging Hybrid DLTs","abstract":"Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data. Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable. Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions. However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs. In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues. Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data.","sentences":["Notarization is a procedure that enhance data management by ensuring the authentication of data during audits, thereby increasing trust in the audited data.","Blockchain is frequently used as a secure, immutable, and transparent storage, contributing to make data notarization procedures more effective and trustable.","Several blockchain-based data notarization protocols have been proposed in literature and commercial solutions.","However, these implementations, whether on public or private blockchains, face inherent challenges: high fees on public blockchains and trust issues on private platforms, limiting the adoption of blockchains for data notarization or forcing several trade-offs.","In this paper, we explore the use of hybrid blockchain architectures for data notarization, with a focus on scalability issues.","Through the analysis of a real-world use case, the data notarization of product passports in supply chains, we propose a novel approach utilizing a data structure designed to efficiently manage the trade-offs in terms of storage occupation and costs involved in notarizing a large collection of data."],"url":"http://arxiv.org/abs/2501.04571v1"}
{"created":"2025-01-08 15:36:19","title":"Large-Scale Spectral Graph Neural Networks via Laplacian Sparsification: Technical Report","abstract":"Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks for their proficiency in representation learning. Among the various GNN methods, spectral GNNs employing polynomial filters have shown promising performance on tasks involving both homophilous and heterophilous graph structures. However, The scalability of spectral GNNs on large graphs is limited because they learn the polynomial coefficients through multiple forward propagation executions during forward propagation. Existing works have attempted to scale up spectral GNNs by eliminating the linear layers on the input node features, a change that can disrupt end-to-end training, potentially impact performance, and become impractical with high-dimensional input features. To address the above challenges, we propose \"Spectral Graph Neural Networks with Laplacian Sparsification (SGNN-LS)\", a novel graph spectral sparsification method to approximate the propagation patterns of spectral GNNs. We prove that our proposed method generates Laplacian sparsifiers that can approximate both fixed and learnable polynomial filters with theoretical guarantees. Our method allows the application of linear layers on the input node features, enabling end-to-end training as well as the handling of raw text features. We conduct an extensive experimental analysis on datasets spanning various graph scales and properties to demonstrate the superior efficiency and effectiveness of our method. The results show that our method yields superior results in comparison with the corresponding approximated base models, especially on dataset Ogbn-papers100M(111M nodes, 1.6B edges) and MAG-scholar-C (2.8M features).","sentences":["Graph Neural Networks (GNNs) play a pivotal role in graph-based tasks for their proficiency in representation learning.","Among the various GNN methods, spectral GNNs employing polynomial filters have shown promising performance on tasks involving both homophilous and heterophilous graph structures.","However, The scalability of spectral GNNs on large graphs is limited because they learn the polynomial coefficients through multiple forward propagation executions during forward propagation.","Existing works have attempted to scale up spectral GNNs by eliminating the linear layers on the input node features, a change that can disrupt end-to-end training, potentially impact performance, and become impractical with high-dimensional input features.","To address the above challenges, we propose \"Spectral Graph Neural Networks with Laplacian Sparsification (SGNN-LS)\", a novel graph spectral sparsification method to approximate the propagation patterns of spectral GNNs.","We prove that our proposed method generates Laplacian sparsifiers that can approximate both fixed and learnable polynomial filters with theoretical guarantees.","Our method allows the application of linear layers on the input node features, enabling end-to-end training as well as the handling of raw text features.","We conduct an extensive experimental analysis on datasets spanning various graph scales and properties to demonstrate the superior efficiency and effectiveness of our method.","The results show that our method yields superior results in comparison with the corresponding approximated base models, especially on dataset Ogbn-papers100M(111M nodes, 1.6B edges) and MAG-scholar-C (2.8M features)."],"url":"http://arxiv.org/abs/2501.04570v1"}
{"created":"2025-01-08 15:32:12","title":"Supervision-free Vision-Language Alignment","abstract":"Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data. Curation of these image-text pairs is both time-consuming and computationally expensive. To address this challenge, we introduce SVP (Supervision-free Visual Projection), a novel framework that enhances vision-language alignment without relying on curated data or preference annotation. SVP leverages self-captioning and a pre-trained grounding model as a feedback mechanism to elicit latent information in VLMs. We evaluate our approach across six key areas: captioning, referring, visual question answering, multitasking, hallucination control, and object recall. Results demonstrate significant improvements, including a 14% average improvement in captioning tasks, up to 12% increase in object recall, and substantial reduction in hallucination rates. Notably, a small VLM using SVP achieves hallucination reductions comparable to a model five times larger, while a VLM with initially poor referring capabilities more than doubles its performance, approaching parity with a model twice its size.","sentences":["Vision-language models (VLMs) have demonstrated remarkable potential in integrating visual and linguistic information, but their performance is often constrained by the need for extensive, high-quality image-text training data.","Curation of these image-text pairs is both time-consuming and computationally expensive.","To address this challenge, we introduce SVP (Supervision-free Visual Projection), a novel framework that enhances vision-language alignment without relying on curated data or preference annotation.","SVP leverages self-captioning and a pre-trained grounding model as a feedback mechanism to elicit latent information in VLMs.","We evaluate our approach across six key areas: captioning, referring, visual question answering, multitasking, hallucination control, and object recall.","Results demonstrate significant improvements, including a 14% average improvement in captioning tasks, up to 12% increase in object recall, and substantial reduction in hallucination rates.","Notably, a small VLM using SVP achieves hallucination reductions comparable to a model five times larger, while a VLM with initially poor referring capabilities more than doubles its performance, approaching parity with a model twice its size."],"url":"http://arxiv.org/abs/2501.04568v1"}
{"created":"2025-01-08 15:25:19","title":"Learnable Scaled Gradient Descent for Guaranteed Robust Tensor PCA","abstract":"Robust tensor principal component analysis (RTPCA) aims to separate the low-rank and sparse components from multi-dimensional data, making it an essential technique in the signal processing and computer vision fields. Recently emerging tensor singular value decomposition (t-SVD) has gained considerable attention for its ability to better capture the low-rank structure of tensors compared to traditional matrix SVD. However, existing methods often rely on the computationally expensive tensor nuclear norm (TNN), which limits their scalability for real-world tensors. To address this issue, we explore an efficient scaled gradient descent (SGD) approach within the t-SVD framework for the first time, and propose the RTPCA-SGD method. Theoretically, we rigorously establish the recovery guarantees of RTPCA-SGD under mild assumptions, demonstrating that with appropriate parameter selection, it achieves linear convergence to the true low-rank tensor at a constant rate, independent of the condition number. To enhance its practical applicability, we further propose a learnable self-supervised deep unfolding model, which enables effective parameter learning. Numerical experiments on both synthetic and real-world datasets demonstrate the superior performance of the proposed methods while maintaining competitive computational efficiency, especially consuming less time than RTPCA-TNN.","sentences":["Robust tensor principal component analysis (RTPCA) aims to separate the low-rank and sparse components from multi-dimensional data, making it an essential technique in the signal processing and computer vision fields.","Recently emerging tensor singular value decomposition (t-SVD) has gained considerable attention for its ability to better capture the low-rank structure of tensors compared to traditional matrix SVD.","However, existing methods often rely on the computationally expensive tensor nuclear norm (TNN), which limits their scalability for real-world tensors.","To address this issue, we explore an efficient scaled gradient descent (SGD) approach within the t-SVD framework for the first time, and propose the RTPCA-SGD method.","Theoretically, we rigorously establish the recovery guarantees of RTPCA-SGD under mild assumptions, demonstrating that with appropriate parameter selection, it achieves linear convergence to the true low-rank tensor at a constant rate, independent of the condition number.","To enhance its practical applicability, we further propose a learnable self-supervised deep unfolding model, which enables effective parameter learning.","Numerical experiments on both synthetic and real-world datasets demonstrate the superior performance of the proposed methods while maintaining competitive computational efficiency, especially consuming less time than RTPCA-TNN."],"url":"http://arxiv.org/abs/2501.04565v1"}
{"created":"2025-01-08 15:18:09","title":"OpenOmni: Large Language Models Pivot Zero-shot Omnimodal Alignment across Language with Real-time Self-Aware Emotional Speech Synthesis","abstract":"Recent advancements in omnimodal learning have been achieved in understanding and generation across images, text, and speech, though mainly within proprietary models. Limited omnimodal datasets and the inherent challenges associated with real-time emotional speech generation have hindered open-source progress. To address these issues, we propose openomni, a two-stage training method combining omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model. In the alignment phase, a pre-trained speech model is further trained on text-image tasks to generalize from vision to speech in a (near) zero-shot manner, outperforming models trained on tri-modal datasets. In the speech generation phase, a lightweight decoder facilitates real-time emotional speech through training on speech tasks and preference learning. Experiments demonstrate that openomni consistently improves across omnimodal, vision-language, and speech-language evaluations, enabling natural, emotion-rich dialogues and real-time emotional speech generation.","sentences":["Recent advancements in omnimodal learning have been achieved in understanding and generation across images, text, and speech, though mainly within proprietary models.","Limited omnimodal datasets and the inherent challenges associated with real-time emotional speech generation have hindered open-source progress.","To address these issues, we propose openomni, a two-stage training method combining omnimodal alignment and speech generation to develop a state-of-the-art omnimodal large language model.","In the alignment phase, a pre-trained speech model is further trained on text-image tasks to generalize from vision to speech in a (near) zero-shot manner, outperforming models trained on tri-modal datasets.","In the speech generation phase, a lightweight decoder facilitates real-time emotional speech through training on speech tasks and preference learning.","Experiments demonstrate that openomni consistently improves across omnimodal, vision-language, and speech-language evaluations, enabling natural, emotion-rich dialogues and real-time emotional speech generation."],"url":"http://arxiv.org/abs/2501.04561v1"}
{"created":"2025-01-08 15:07:18","title":"Satellite-Terrestrial Routing or Inter-Satellite Routing? A Stochastic Geometry Perspective","abstract":"The design and comparison of satellite-terrestrial routing (STR) and inter-satellite routing (ISR) in low Earth orbit satellite constellations is a widely discussed topic. The signal propagation distance under STR is generally longer than that under ISR, resulting in greater path loss. The global deployment of gateways introduces additional costs for STR. In contrast, transmissions under ISR rely on the energy of satellites, which could be more costly. Additionally, ISLs require more complex communication protocol design, extra hardware support, and increased computational power. To maximize energy efficiency, we propose two optimal routing relay selection algorithms for ISR and STR, respectively. Furthermore, we derive the analytical expressions for the routing availability probability and energy efficiency, quantifying the performance of the algorithms. The analyses enable us to assess the performance of the proposed algorithms against existing methods through numerical results, compare the performance of STR and ISR, and provide useful insights for constellation design.","sentences":["The design and comparison of satellite-terrestrial routing (STR) and inter-satellite routing (ISR) in low Earth orbit satellite constellations is a widely discussed topic.","The signal propagation distance under STR is generally longer than that under ISR, resulting in greater path loss.","The global deployment of gateways introduces additional costs for STR.","In contrast, transmissions under ISR rely on the energy of satellites, which could be more costly.","Additionally, ISLs require more complex communication protocol design, extra hardware support, and increased computational power.","To maximize energy efficiency, we propose two optimal routing relay selection algorithms for ISR and STR, respectively.","Furthermore, we derive the analytical expressions for the routing availability probability and energy efficiency, quantifying the performance of the algorithms.","The analyses enable us to assess the performance of the proposed algorithms against existing methods through numerical results, compare the performance of STR and ISR, and provide useful insights for constellation design."],"url":"http://arxiv.org/abs/2501.04557v1"}
{"created":"2025-01-08 15:05:14","title":"Multivariate Exploration of Metric Dilation","abstract":"Let $G$ be a weighted graph embedded in a metric space $(M, d_M )$. The vertices of $G$ correspond to the points in $M$ , with the weight of each edge $uv$ being the distance $d_M (u, v)$ between their respective points in $M$ . The dilation (or stretch) of $G$ is defined as the minimum factor $t$ such that, for any pair of vertices $u, v$, the distance between $u$ and $v$-represented by the weight of a shortest $u$, $v$-path is at most $ t \\cdot d_M (u, v)$. We study Dilation t-Augmentation, where the objective is, given a metric $M $, a graph $G$, and numerical values $k$ and $t$, to determine whether $G$ can be transformed into a graph with dilation $t$ by adding at most $k$ edges.   Our primary focus is on the scenario where the metric $M$ is the shortest path metric of an unweighted graph $\\Gamma$. Even in this specific case, Dilation $t$-Augmentation remains computationally challenging. In particular, the problem is W[2]-hard parameterized by $k$ when $\\Gamma$ is a complete graph, already for $t=2$. Our main contribution lies in providing new insights into the impact of combinations of various parameters on the computational complexity of the problem. We establish the following.   -- The parameterized dichotomy of the problem with respect to dilation $t$, when the graph $G$ is sparse: Parameterized by $k$, the problem is FPT for graphs excluding a biclique $K_{d,d}$ as a subgraph for $t\\leq 2$ and the problem is W[1]-hard for $t\\geq 3$ even if $G$ is a forest consisting of disjoint stars.   -- The problem is FPT parameterized by the combined parameter $k+t+\\Delta$, where $\\Delta$ is the maximum degree of the graph $G$ or $\\Gamma$.","sentences":["Let $G$ be a weighted graph embedded in a metric space $(M, d_M )$.","The vertices of $G$ correspond to the points in $M$ , with the weight of each edge $uv$ being the distance $d_M (u, v)$ between their respective points in $M$ .","The dilation (or stretch) of $G$ is defined as the minimum factor $t$ such that, for any pair of vertices $u, v$, the distance between $u$ and $v$-represented by the weight of a shortest $u$, $v$-path is at most $ t \\cdot d_M (u, v)$.","We study Dilation t-Augmentation, where the objective is, given a metric $M $, a graph $G$, and numerical values $k$ and $t$, to determine whether $G$ can be transformed into a graph with dilation $t$ by adding at most $k$ edges.   ","Our primary focus is on the scenario where the metric $M$ is the shortest path metric of an unweighted graph $\\Gamma$. Even in this specific case, Dilation $t$-Augmentation remains computationally challenging.","In particular, the problem is W[2]-hard parameterized by $k$ when $\\Gamma$ is a complete graph, already for $t=2$. Our main contribution lies in providing new insights into the impact of combinations of various parameters on the computational complexity of the problem.","We establish the following.   ","-- The parameterized dichotomy of the problem with respect to dilation $t$, when the graph $G$ is sparse: Parameterized by $k$, the problem is FPT for graphs excluding a biclique $K_{d,d}$ as a subgraph for $t\\leq 2$ and the problem is W[1]-hard for $t\\geq 3$ even if $G$ is a forest consisting of disjoint stars.   ","-- The problem is FPT parameterized by the combined parameter $k+t+\\Delta$, where $\\Delta$ is the maximum degree of the graph $G$ or $\\Gamma$."],"url":"http://arxiv.org/abs/2501.04555v1"}
{"created":"2025-01-08 14:57:07","title":"Approximately EFX and PO Allocations for Bivalued Chores","abstract":"We consider the computation for allocations of indivisible chores that are approximately EFX and Pareto optimal (PO). Recently, Garg et al. (2024) show the existence of $3$-EFX and PO allocations for bi-valued instances, where the cost of an item to an agent is either $1$ or $k$ (where $k > 1$) by rounding the (fractional) earning restricted equilibrium. In this work, we improve the approximation ratio to $(2-1/k)$, while preserving the Pareto optimality. Instead of rounding fractional equilibrium, our algorithm starts with the integral EF1 equilibrium for bi-valued chores, introduced by Garg et al. (AAAI 2022) and Wu et al. (EC 2023), and reallocates items until approximate EFX is achieved. We further improve our result for the case when $k=2$ and devise an algorithm that computes EFX and PO allocations.","sentences":["We consider the computation for allocations of indivisible chores that are approximately EFX and Pareto optimal (PO).","Recently, Garg et al. (2024) show the existence of $3$-EFX and PO allocations for bi-valued instances, where the cost of an item to an agent is either $1$ or $k$ (where $k > 1$) by rounding the (fractional) earning restricted equilibrium.","In this work, we improve the approximation ratio to $(2-1/k)$, while preserving the Pareto optimality.","Instead of rounding fractional equilibrium, our algorithm starts with the integral EF1 equilibrium for bi-valued chores, introduced by Garg et al.","(AAAI 2022) and Wu et al. (EC 2023), and reallocates items until approximate EFX is achieved.","We further improve our result for the case when $k=2$ and devise an algorithm that computes EFX and PO allocations."],"url":"http://arxiv.org/abs/2501.04550v1"}
{"created":"2025-01-08 14:51:36","title":"Medical artificial intelligence toolbox (MAIT): an explainable machine learning framework for binary classification, survival modelling, and regression analyses","abstract":"While machine learning offers diverse techniques suitable for exploring various medical research questions, a cohesive synergistic framework can facilitate the integration and understanding of new approaches within unified model development and interpretation. We therefore introduce the Medical Artificial Intelligence Toolbox (MAIT), an explainable, open-source Python pipeline for developing and evaluating binary classification, regression, and survival models on tabular datasets. MAIT addresses key challenges (e.g., high dimensionality, class imbalance, mixed variable types, and missingness) while promoting transparency in reporting (TRIPOD+AI compliant). Offering automated configurations for beginners and customizable source code for experts, MAIT streamlines two primary use cases: Discovery (feature importance via unified scoring, e.g., SHapley Additive exPlanations - SHAP) and Prediction (model development and deployment with optimized solutions). Moreover, MAIT proposes new techniques including fine-tuning of probability threshold in binary classification, translation of cumulative hazard curves to binary classification, enhanced visualizations for model interpretation for mixed data types, and handling censoring through semi-supervised learning, to adapt to a wide set of data constraints and study designs. We provide detailed tutorials on GitHub, using four open-access data sets, to demonstrate how MAIT can be used to improve implementation and interpretation of ML models in medical research.","sentences":["While machine learning offers diverse techniques suitable for exploring various medical research questions, a cohesive synergistic framework can facilitate the integration and understanding of new approaches within unified model development and interpretation.","We therefore introduce the Medical Artificial Intelligence Toolbox (MAIT), an explainable, open-source Python pipeline for developing and evaluating binary classification, regression, and survival models on tabular datasets.","MAIT addresses key challenges (e.g., high dimensionality, class imbalance, mixed variable types, and missingness) while promoting transparency in reporting (TRIPOD+AI compliant).","Offering automated configurations for beginners and customizable source code for experts, MAIT streamlines two primary use cases: Discovery (feature importance via unified scoring, e.g., SHapley Additive exPlanations - SHAP) and Prediction (model development and deployment with optimized solutions).","Moreover, MAIT proposes new techniques including fine-tuning of probability threshold in binary classification, translation of cumulative hazard curves to binary classification, enhanced visualizations for model interpretation for mixed data types, and handling censoring through semi-supervised learning, to adapt to a wide set of data constraints and study designs.","We provide detailed tutorials on GitHub, using four open-access data sets, to demonstrate how MAIT can be used to improve implementation and interpretation of ML models in medical research."],"url":"http://arxiv.org/abs/2501.04547v1"}
{"created":"2025-01-08 14:46:37","title":"The Impostor is Among Us: Can Large Language Models Capture the Complexity of Human Personas?","abstract":"Large Language Models (LLMs) created new opportunities for generating personas, which are expected to streamline and accelerate the human-centered design process. Yet, AI-generated personas may not accurately represent actual user experiences, as they can miss contextual and emotional insights critical to understanding real users' needs and behaviors. This paper examines the differences in how users perceive personas created by LLMs compared to those crafted by humans regarding their credibility for design. We gathered ten human-crafted personas developed by HCI experts according to relevant attributes established in related work. Then, we systematically generated ten personas and compared them with human-crafted ones in a survey. The results showed that participants differentiated between human-created and AI-generated personas, with the latter being perceived as more informative and consistent. However, participants noted that the AI-generated personas tended to follow stereotypes, highlighting the need for a greater emphasis on diversity when utilizing LLMs for persona creation.","sentences":["Large Language Models (LLMs) created new opportunities for generating personas, which are expected to streamline and accelerate the human-centered design process.","Yet, AI-generated personas may not accurately represent actual user experiences, as they can miss contextual and emotional insights critical to understanding real users' needs and behaviors.","This paper examines the differences in how users perceive personas created by LLMs compared to those crafted by humans regarding their credibility for design.","We gathered ten human-crafted personas developed by HCI experts according to relevant attributes established in related work.","Then, we systematically generated ten personas and compared them with human-crafted ones in a survey.","The results showed that participants differentiated between human-created and AI-generated personas, with the latter being perceived as more informative and consistent.","However, participants noted that the AI-generated personas tended to follow stereotypes, highlighting the need for a greater emphasis on diversity when utilizing LLMs for persona creation."],"url":"http://arxiv.org/abs/2501.04543v1"}
{"created":"2025-01-08 14:44:40","title":"Cyber-Physical Steganography in Robotic Motion Control","abstract":"Steganography, the art of information hiding, has continually evolved across visual, auditory and linguistic domains, adapting to the ceaseless interplay between steganographic concealment and steganalytic revelation. This study seeks to extend the horizons of what constitutes a viable steganographic medium by introducing a steganographic paradigm in robotic motion control. Based on the observation of the robot's inherent sensitivity to changes in its environment, we propose a methodology to encode messages as environmental stimuli influencing the motions of the robotic agent and to decode messages from the resulting motion trajectory. The constraints of maximal robot integrity and minimal motion deviation are established as fundamental principles underlying secrecy. As a proof of concept, we conduct experiments in simulated environments across various manipulation tasks, incorporating robotic embodiments equipped with generalist multimodal policies.","sentences":["Steganography, the art of information hiding, has continually evolved across visual, auditory and linguistic domains, adapting to the ceaseless interplay between steganographic concealment and steganalytic revelation.","This study seeks to extend the horizons of what constitutes a viable steganographic medium by introducing a steganographic paradigm in robotic motion control.","Based on the observation of the robot's inherent sensitivity to changes in its environment, we propose a methodology to encode messages as environmental stimuli influencing the motions of the robotic agent and to decode messages from the resulting motion trajectory.","The constraints of maximal robot integrity and minimal motion deviation are established as fundamental principles underlying secrecy.","As a proof of concept, we conduct experiments in simulated environments across various manipulation tasks, incorporating robotic embodiments equipped with generalist multimodal policies."],"url":"http://arxiv.org/abs/2501.04541v1"}
{"created":"2025-01-08 14:40:00","title":"Protecting the Connectivity of a Graph Under Non-Uniform Edge Failures","abstract":"We study the problem of guaranteeing the connectivity of a given graph by protecting or strengthening edges. Herein, a protected edge is assumed to be robust and will not fail, which features a non-uniform failure model. We introduce the $(p,q)$-Steiner-Connectivity Preservation problem where we protect a minimum-cost set of edges such that the underlying graph maintains $p$-edge-connectivity between given terminal pairs against edge failures, assuming at most $q$ unprotected edges can fail. We design polynomial-time exact algorithms for the cases where $p$ and $q$ are small and approximation algorithms for general values of $p$ and $q$. Additionally, we show that when both $p$ and $q$ are part of the input, even deciding whether a given solution is feasible is NP-complete. This hardness also carries over to Flexible Network Design, a research direction that has gained significant attention. In particular, previous work focuses on problem settings where either $p$ or $q$ is constant, for which our new hardness result now provides justification.","sentences":["We study the problem of guaranteeing the connectivity of a given graph by protecting or strengthening edges.","Herein, a protected edge is assumed to be robust and will not fail, which features a non-uniform failure model.","We introduce the $(p,q)$-Steiner-Connectivity Preservation problem where we protect a minimum-cost set of edges such that the underlying graph maintains $p$-edge-connectivity between given terminal pairs against edge failures, assuming at most $q$ unprotected edges can fail.","We design polynomial-time exact algorithms for the cases where $p$ and $q$ are small and approximation algorithms for general values of $p$ and $q$. Additionally, we show that when both $p$ and $q$ are part of the input, even deciding whether a given solution is feasible is NP-complete.","This hardness also carries over to Flexible Network Design, a research direction that has gained significant attention.","In particular, previous work focuses on problem settings where either $p$ or $q$ is constant, for which our new hardness result now provides justification."],"url":"http://arxiv.org/abs/2501.04540v1"}
{"created":"2025-01-08 14:38:03","title":"HypeRL: Parameter-Informed Reinforcement Learning for Parametric PDEs","abstract":"In this work, we devise a new, general-purpose reinforcement learning strategy for the optimal control of parametric partial differential equations (PDEs). Such problems frequently arise in applied sciences and engineering and entail a significant complexity when control and/or state variables are distributed in high-dimensional space or depend on varying parameters. Traditional numerical methods, relying on either iterative minimization algorithms or dynamic programming, while reliable, often become computationally infeasible. Indeed, in either way, the optimal control problem must be solved for each instance of the parameters, and this is out of reach when dealing with high-dimensional time-dependent and parametric PDEs. In this paper, we propose HypeRL, a deep reinforcement learning (DRL) framework to overcome the limitations shown by traditional methods. HypeRL aims at approximating the optimal control policy directly. Specifically, we employ an actor-critic DRL approach to learn an optimal feedback control strategy that can generalize across the range of variation of the parameters. To effectively learn such optimal control laws, encoding the parameter information into the DRL policy and value function neural networks (NNs) is essential. To do so, HypeRL uses two additional NNs, often called hypernetworks, to learn the weights and biases of the value function and the policy NNs. We validate the proposed approach on two PDE-constrained optimal control benchmarks, namely a 1D Kuramoto-Sivashinsky equation and a 2D Navier-Stokes equations, by showing that the knowledge of the PDE parameters and how this information is encoded, i.e., via a hypernetwork, is an essential ingredient for learning parameter-dependent control policies that can generalize effectively to unseen scenarios and for improving the sample efficiency of such policies.","sentences":["In this work, we devise a new, general-purpose reinforcement learning strategy for the optimal control of parametric partial differential equations (PDEs).","Such problems frequently arise in applied sciences and engineering and entail a significant complexity when control and/or state variables are distributed in high-dimensional space or depend on varying parameters.","Traditional numerical methods, relying on either iterative minimization algorithms or dynamic programming, while reliable, often become computationally infeasible.","Indeed, in either way, the optimal control problem must be solved for each instance of the parameters, and this is out of reach when dealing with high-dimensional time-dependent and parametric PDEs.","In this paper, we propose HypeRL, a deep reinforcement learning (DRL) framework to overcome the limitations shown by traditional methods.","HypeRL aims at approximating the optimal control policy directly.","Specifically, we employ an actor-critic DRL approach to learn an optimal feedback control strategy that can generalize across the range of variation of the parameters.","To effectively learn such optimal control laws, encoding the parameter information into the DRL policy and value function neural networks (NNs) is essential.","To do so, HypeRL uses two additional NNs, often called hypernetworks, to learn the weights and biases of the value function and the policy NNs.","We validate the proposed approach on two PDE-constrained optimal control benchmarks, namely a 1D Kuramoto-Sivashinsky equation and a 2D Navier-Stokes equations, by showing that the knowledge of the PDE parameters and how this information is encoded, i.e., via a hypernetwork, is an essential ingredient for learning parameter-dependent control policies that can generalize effectively to unseen scenarios and for improving the sample efficiency of such policies."],"url":"http://arxiv.org/abs/2501.04538v1"}
{"created":"2025-01-08 14:33:47","title":"Combining YOLO and Visual Rhythm for Vehicle Counting","abstract":"Video-based vehicle detection and counting play a critical role in managing transport infrastructure. Traditional image-based counting methods usually involve two main steps: initial detection and subsequent tracking, which are applied to all video frames, leading to a significant increase in computational complexity. To address this issue, this work presents an alternative and more efficient method for vehicle detection and counting. The proposed approach eliminates the need for a tracking step and focuses solely on detecting vehicles in key video frames, thereby increasing its efficiency. To achieve this, we developed a system that combines YOLO, for vehicle detection, with Visual Rhythm, a way to create time-spatial images that allows us to focus on frames that contain useful information. Additionally, this method can be used for counting in any application involving unidirectional moving targets to be detected and identified. Experimental analysis using real videos shows that the proposed method achieves mean counting accuracy around 99.15% over a set of videos, with a processing speed three times faster than tracking based approaches.","sentences":["Video-based vehicle detection and counting play a critical role in managing transport infrastructure.","Traditional image-based counting methods usually involve two main steps: initial detection and subsequent tracking, which are applied to all video frames, leading to a significant increase in computational complexity.","To address this issue, this work presents an alternative and more efficient method for vehicle detection and counting.","The proposed approach eliminates the need for a tracking step and focuses solely on detecting vehicles in key video frames, thereby increasing its efficiency.","To achieve this, we developed a system that combines YOLO, for vehicle detection, with Visual Rhythm, a way to create time-spatial images that allows us to focus on frames that contain useful information.","Additionally, this method can be used for counting in any application involving unidirectional moving targets to be detected and identified.","Experimental analysis using real videos shows that the proposed method achieves mean counting accuracy around 99.15% over a set of videos, with a processing speed three times faster than tracking based approaches."],"url":"http://arxiv.org/abs/2501.04534v1"}
{"created":"2025-01-08 14:21:03","title":"A Plug-and-Play Bregman ADMM Module for Inferring Event Branches in Temporal Point Processes","abstract":"An event sequence generated by a temporal point process is often associated with a hidden and structured event branching process that captures the triggering relations between its historical and current events. In this study, we design a new plug-and-play module based on the Bregman ADMM (BADMM) algorithm, which infers event branches associated with event sequences in the maximum likelihood estimation framework of temporal point processes (TPPs). Specifically, we formulate the inference of event branches as an optimization problem for the event transition matrix under sparse and low-rank constraints, which is embedded in existing TPP models or their learning paradigms. We can implement this optimization problem based on subspace clustering and sparse group-lasso, respectively, and solve it using the Bregman ADMM algorithm, whose unrolling leads to the proposed BADMM module. When learning a classic TPP (e.g., Hawkes process) by the expectation-maximization algorithm, the BADMM module helps derive structured responsibility matrices in the E-step. Similarly, the BADMM module helps derive low-rank and sparse attention maps for the neural TPPs with self-attention layers. The structured responsibility matrices and attention maps, which work as learned event transition matrices, indicate event branches, e.g., inferring isolated events and those key events triggering many subsequent events. Experiments on both synthetic and real-world data show that plugging our BADMM module into existing TPP models and learning paradigms can improve model performance and provide us with interpretable structured event branches. The code is available at \\url{https://github.com/qingmeiwangdaily/BADMM_TPP}.","sentences":["An event sequence generated by a temporal point process is often associated with a hidden and structured event branching process that captures the triggering relations between its historical and current events.","In this study, we design a new plug-and-play module based on the Bregman ADMM (BADMM) algorithm, which infers event branches associated with event sequences in the maximum likelihood estimation framework of temporal point processes (TPPs).","Specifically, we formulate the inference of event branches as an optimization problem for the event transition matrix under sparse and low-rank constraints, which is embedded in existing TPP models or their learning paradigms.","We can implement this optimization problem based on subspace clustering and sparse group-lasso, respectively, and solve it using the Bregman ADMM algorithm, whose unrolling leads to the proposed BADMM module.","When learning a classic TPP (e.g., Hawkes process) by the expectation-maximization algorithm, the BADMM module helps derive structured responsibility matrices in the E-step.","Similarly, the BADMM module helps derive low-rank and sparse attention maps for the neural TPPs with self-attention layers.","The structured responsibility matrices and attention maps, which work as learned event transition matrices, indicate event branches, e.g., inferring isolated events and those key events triggering many subsequent events.","Experiments on both synthetic and real-world data show that plugging our BADMM module into existing TPP models and learning paradigms can improve model performance and provide us with interpretable structured event branches.","The code is available at \\url{https://github.com/qingmeiwangdaily/BADMM_TPP}."],"url":"http://arxiv.org/abs/2501.04529v1"}
{"created":"2025-01-08 14:19:54","title":"Towards a Problem-Oriented Domain Adaptation Framework for Machine Learning","abstract":"Domain adaptation is a sub-field of machine learning that involves transferring knowledge from a source domain to perform the same task in the target domain. It is a typical challenge in machine learning that arises, e.g., when data is obtained from various sources or when using a data basis that changes over time. Recent advances in the field offer promising methods, but it is still challenging for researchers and practitioners to determine if domain adaptation is suitable for a given problem -- and, subsequently, to select the appropriate approach. This article employs design science research to develop a problem-oriented framework for domain adaptation, which is matured in three evaluation episodes. We describe a framework that distinguishes between five domain adaptation scenarios, provides recommendations for addressing each scenario, and offers guidelines for determining if a problem falls into one of these scenarios. During the multiple evaluation episodes, the framework is tested on artificial and real-world datasets and an experimental study involving 100 participants. The evaluation demonstrates that the framework has the explanatory power to capture any domain adaptation problem effectively. In summary, we provide clear guidance for researchers and practitioners who want to employ domain adaptation but lack in-depth knowledge of the possibilities.","sentences":["Domain adaptation is a sub-field of machine learning that involves transferring knowledge from a source domain to perform the same task in the target domain.","It is a typical challenge in machine learning that arises, e.g., when data is obtained from various sources or when using a data basis that changes over time.","Recent advances in the field offer promising methods, but it is still challenging for researchers and practitioners to determine if domain adaptation is suitable for a given problem -- and, subsequently, to select the appropriate approach.","This article employs design science research to develop a problem-oriented framework for domain adaptation, which is matured in three evaluation episodes.","We describe a framework that distinguishes between five domain adaptation scenarios, provides recommendations for addressing each scenario, and offers guidelines for determining if a problem falls into one of these scenarios.","During the multiple evaluation episodes, the framework is tested on artificial and real-world datasets and an experimental study involving 100 participants.","The evaluation demonstrates that the framework has the explanatory power to capture any domain adaptation problem effectively.","In summary, we provide clear guidance for researchers and practitioners who want to employ domain adaptation but lack in-depth knowledge of the possibilities."],"url":"http://arxiv.org/abs/2501.04528v1"}
{"created":"2025-01-08 14:19:03","title":"Towards Fair Class-wise Robustness: Class Optimal Distribution Adversarial Training","abstract":"Adversarial training has proven to be a highly effective method for improving the robustness of deep neural networks against adversarial attacks. Nonetheless, it has been observed to exhibit a limitation in terms of robust fairness, characterized by a significant disparity in robustness across different classes. Recent efforts to mitigate this problem have turned to class-wise reweighted methods. However, these methods suffer from a lack of rigorous theoretical analysis and are limited in their exploration of the weight space, as they mainly rely on existing heuristic algorithms or intuition to compute weights. In addition, these methods fail to guarantee the consistency of the optimization direction due to the decoupled optimization of weights and the model parameters. They potentially lead to suboptimal weight assignments and consequently, a suboptimal model. To address these problems, this paper proposes a novel min-max training framework, Class Optimal Distribution Adversarial Training (CODAT), which employs distributionally robust optimization to fully explore the class-wise weight space, thus enabling the identification of the optimal weight with theoretical guarantees. Furthermore, we derive a closed-form optimal solution to the internal maximization and then get a deterministic equivalent objective function, which provides a theoretical basis for the joint optimization of weights and model parameters. Meanwhile, we propose a fairness elasticity coefficient for the evaluation of the algorithm with regard to both robustness and robust fairness. Experimental results on various datasets show that the proposed method can effectively improve the robust fairness of the model and outperform the state-of-the-art approaches.","sentences":["Adversarial training has proven to be a highly effective method for improving the robustness of deep neural networks against adversarial attacks.","Nonetheless, it has been observed to exhibit a limitation in terms of robust fairness, characterized by a significant disparity in robustness across different classes.","Recent efforts to mitigate this problem have turned to class-wise reweighted methods.","However, these methods suffer from a lack of rigorous theoretical analysis and are limited in their exploration of the weight space, as they mainly rely on existing heuristic algorithms or intuition to compute weights.","In addition, these methods fail to guarantee the consistency of the optimization direction due to the decoupled optimization of weights and the model parameters.","They potentially lead to suboptimal weight assignments and consequently, a suboptimal model.","To address these problems, this paper proposes a novel min-max training framework, Class Optimal Distribution Adversarial Training (CODAT), which employs distributionally robust optimization to fully explore the class-wise weight space, thus enabling the identification of the optimal weight with theoretical guarantees.","Furthermore, we derive a closed-form optimal solution to the internal maximization and then get a deterministic equivalent objective function, which provides a theoretical basis for the joint optimization of weights and model parameters.","Meanwhile, we propose a fairness elasticity coefficient for the evaluation of the algorithm with regard to both robustness and robust fairness.","Experimental results on various datasets show that the proposed method can effectively improve the robust fairness of the model and outperform the state-of-the-art approaches."],"url":"http://arxiv.org/abs/2501.04527v1"}
{"created":"2025-01-08 14:14:19","title":"Right Label Context in End-to-End Training of Time-Synchronous ASR Models","abstract":"Current time-synchronous sequence-to-sequence automatic speech recognition (ASR) models are trained by using sequence level cross-entropy that sums over all alignments. Due to the discriminative formulation, incorporating the right label context into the training criterion's gradient causes normalization problems and is not mathematically well-defined. The classic hybrid neural network hidden Markov model (NN-HMM) with its inherent generative formulation enables conditioning on the right label context. However, due to the HMM state-tying the identity of the right label context is never modeled explicitly. In this work, we propose a factored loss with auxiliary left and right label contexts that sums over all alignments. We show that the inclusion of the right label context is particularly beneficial when training data resources are limited. Moreover, we also show that it is possible to build a factored hybrid HMM system by relying exclusively on the full-sum criterion. Experiments were conducted on Switchboard 300h and LibriSpeech 960h.","sentences":["Current time-synchronous sequence-to-sequence automatic speech recognition (ASR) models are trained by using sequence level cross-entropy that sums over all alignments.","Due to the discriminative formulation, incorporating the right label context into the training criterion's gradient causes normalization problems and is not mathematically well-defined.","The classic hybrid neural network hidden Markov model (NN-HMM) with its inherent generative formulation enables conditioning on the right label context.","However, due to the HMM state-tying the identity of the right label context is never modeled explicitly.","In this work, we propose a factored loss with auxiliary left and right label contexts that sums over all alignments.","We show that the inclusion of the right label context is particularly beneficial when training data resources are limited.","Moreover, we also show that it is possible to build a factored hybrid HMM system by relying exclusively on the full-sum criterion.","Experiments were conducted on Switchboard 300h and LibriSpeech 960h."],"url":"http://arxiv.org/abs/2501.04521v1"}
{"created":"2025-01-08 14:12:57","title":"rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking","abstract":"We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models. rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model. rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities. Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels. On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%. On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students. Code and data will be available at https://github.com/microsoft/rStar.","sentences":["We present rStar-Math to demonstrate that small language models (SLMs) can rival or even surpass the math reasoning capability of OpenAI o1, without distillation from superior models.","rStar-Math achieves this by exercising \"deep thinking\" through Monte Carlo Tree Search (MCTS), where a math policy SLM performs test-time search guided by an SLM-based process reward model.","rStar-Math introduces three innovations to tackle the challenges in training the two SLMs: (1) a novel code-augmented CoT data sythesis method, which performs extensive MCTS rollouts to generate step-by-step verified reasoning trajectories used to train the policy SLM; (2) a novel process reward model training method that avoids na\\\"ive step-level score annotation, yielding a more effective process preference model (PPM); (3) a self-evolution recipe in which the policy SLM and PPM are built from scratch and iteratively evolved to improve reasoning capabilities.","Through 4 rounds of self-evolution with millions of synthesized solutions for 747k math problems, rStar-Math boosts SLMs' math reasoning to state-of-the-art levels.","On the MATH benchmark, it improves Qwen2.5-Math-7B from 58.8% to 90.0% and Phi3-mini-3.8B from 41.4% to 86.4%, surpassing o1-preview by +4.5% and +0.9%.","On the USA Math Olympiad (AIME), rStar-Math solves an average of 53.3% (8/15) of problems, ranking among the top 20% the brightest high school math students.","Code and data will be available at https://github.com/microsoft/rStar."],"url":"http://arxiv.org/abs/2501.04519v1"}
{"created":"2025-01-08 14:06:07","title":"Histogram-Equalized Quantization for logic-gated Residual Neural Networks","abstract":"Adjusting the quantization according to the data or to the model loss seems mandatory to enable a high accuracy in the context of quantized neural networks. This work presents Histogram-Equalized Quantization (HEQ), an adaptive framework for linear symmetric quantization. HEQ automatically adapts the quantization thresholds using a unique step size optimization. We empirically show that HEQ achieves state-of-the-art performances on CIFAR-10. Experiments on the STL-10 dataset even show that HEQ enables a proper training of our proposed logic-gated (OR, MUX) residual networks with a higher accuracy at a lower hardware complexity than previous work.","sentences":["Adjusting the quantization according to the data or to the model loss seems mandatory to enable a high accuracy in the context of quantized neural networks.","This work presents Histogram-Equalized Quantization (HEQ), an adaptive framework for linear symmetric quantization.","HEQ automatically adapts the quantization thresholds using a unique step size optimization.","We empirically show that HEQ achieves state-of-the-art performances on CIFAR-10.","Experiments on the STL-10 dataset even show that HEQ enables a proper training of our proposed logic-gated (OR, MUX) residual networks with a higher accuracy at a lower hardware complexity than previous work."],"url":"http://arxiv.org/abs/2501.04517v1"}
{"created":"2025-01-08 14:00:07","title":"Improving Image Captioning by Mimicking Human Reformulation Feedback at Inference-time","abstract":"Incorporating automatically predicted human feedback into the process of training generative models has attracted substantial recent interest, while feedback at inference time has received less attention. The typical feedback at training time, i.e., preferences of choice given two samples, does not naturally transfer to the inference phase. We introduce a novel type of feedback -- caption reformulations -- and train models to mimic reformulation feedback based on human annotations. Our method does not require training the image captioning model itself, thereby demanding substantially less computational effort. We experiment with two types of reformulation feedback: first, we collect a dataset of human reformulations that correct errors in the generated captions. We find that incorporating reformulation models trained on this data into the inference phase of existing image captioning models results in improved captions, especially when the original captions are of low quality. We apply our method to non-English image captioning, a domain where robust models are less prevalent, and gain substantial improvement. Second, we apply reformulations to style transfer. Quantitative evaluations reveal state-of-the-art performance on German image captioning and English style transfer, while human validation with a detailed comparative framework exposes the specific axes of improvement.","sentences":["Incorporating automatically predicted human feedback into the process of training generative models has attracted substantial recent interest, while feedback at inference time has received less attention.","The typical feedback at training time, i.e., preferences of choice given two samples, does not naturally transfer to the inference phase.","We introduce a novel type of feedback -- caption reformulations -- and train models to mimic reformulation feedback based on human annotations.","Our method does not require training the image captioning model itself, thereby demanding substantially less computational effort.","We experiment with two types of reformulation feedback: first, we collect a dataset of human reformulations that correct errors in the generated captions.","We find that incorporating reformulation models trained on this data into the inference phase of existing image captioning models results in improved captions, especially when the original captions are of low quality.","We apply our method to non-English image captioning, a domain where robust models are less prevalent, and gain substantial improvement.","Second, we apply reformulations to style transfer.","Quantitative evaluations reveal state-of-the-art performance on German image captioning and English style transfer, while human validation with a detailed comparative framework exposes the specific axes of improvement."],"url":"http://arxiv.org/abs/2501.04513v1"}
{"created":"2025-01-08 13:58:07","title":"Multichannel Steganography: A Provably Secure Hybrid Steganographic Model for Secure Communication","abstract":"This study introduces a novel steganographic model that synthesizes Steganography by Cover Modification (CMO) and Steganography by Cover Synthesis (CSY), enhancing both security and undetectability by generating cover messages or parameters while retaining the original cover's form, thus minimizing detection risks and overcoming the limitations of single-method techniques. Building upon this model, a refined Steganographic Communication Protocol is proposed, enhancing resilience against sophisticated threats such as Multichannel Replay Attacks and Multichannel Man-in-the-Middle Attacks, fortifying the protocol against potential tampering and improving upon prior works. To evaluate the security of the proposed protocol, a novel adversarial model is developed simulating a probabilistic polynomial time (PPT) adversary capable of intercepting communications across multiple channels. This model assesses the adversary's ability to compromise the protocol, providing a comprehensive security analysis. Finally, this study explores the practicality and adaptability of the model to both constrained environments like SMS banking and resource-rich settings such as blockchain transactions, demonstrating their potential to enhance financial services and security. These contributions present a robust and adaptable framework for secure steganographic communication, offering practical solutions for secure communications across diverse environments.","sentences":["This study introduces a novel steganographic model that synthesizes Steganography by Cover Modification (CMO) and Steganography by Cover Synthesis (CSY), enhancing both security and undetectability by generating cover messages or parameters while retaining the original cover's form, thus minimizing detection risks and overcoming the limitations of single-method techniques.","Building upon this model, a refined Steganographic Communication Protocol is proposed, enhancing resilience against sophisticated threats such as Multichannel Replay Attacks and Multichannel Man-in-the-Middle Attacks, fortifying the protocol against potential tampering and improving upon prior works.","To evaluate the security of the proposed protocol, a novel adversarial model is developed simulating a probabilistic polynomial time (PPT) adversary capable of intercepting communications across multiple channels.","This model assesses the adversary's ability to compromise the protocol, providing a comprehensive security analysis.","Finally, this study explores the practicality and adaptability of the model to both constrained environments like SMS banking and resource-rich settings such as blockchain transactions, demonstrating their potential to enhance financial services and security.","These contributions present a robust and adaptable framework for secure steganographic communication, offering practical solutions for secure communications across diverse environments."],"url":"http://arxiv.org/abs/2501.04511v1"}
{"created":"2025-01-08 13:56:17","title":"CGP-Tuning: Structure-Aware Soft Prompt Tuning for Code Vulnerability Detection","abstract":"Large language models (LLMs) have been proposed as powerful tools for detecting software vulnerabilities, where task-specific fine-tuning is typically employed to provide vulnerability-specific knowledge to the LLMs for this purpose. However, traditional full-parameter fine-tuning is inefficient for modern, complex LLMs, which contain billions of parameters.   Soft prompt tuning has been suggested as a more efficient alternative for fine-tuning LLMs in general cases. However, pure soft prompt tuning treats source code as plain text, losing structural information inherent in source code. Meanwhile, graph-enhanced soft prompt tuning methods, which aim to address this issue, are unable to preserve the rich semantic information within code graphs, as they are primarily designed for general graph-related tasks and focus more on adjacency information. They also fail to ensure computational efficiency while accounting for graph-text interactions.   This paper, therefore, introduces a new code graph-enhanced, structure-aware soft prompt tuning method for vulnerability detection, referred to as CGP-Tuning. It employs innovative type-aware embeddings to capture the rich semantic information within code graphs, along with a novel and efficient cross-modal alignment module that achieves linear computational cost while incorporating graph-text interactions. The proposed CGP-Tuning is evaluated on the latest DiverseVul dataset and the most recent open-source code LLMs, CodeLlama and CodeGemma. Experimental results demonstrate that CGP-Tuning outperforms the best state-of-the-art method by an average of 3.5 percentage points in accuracy, without compromising its vulnerability detection capabilities for long source code.","sentences":["Large language models (LLMs) have been proposed as powerful tools for detecting software vulnerabilities, where task-specific fine-tuning is typically employed to provide vulnerability-specific knowledge to the LLMs for this purpose.","However, traditional full-parameter fine-tuning is inefficient for modern, complex LLMs, which contain billions of parameters.   ","Soft prompt tuning has been suggested as a more efficient alternative for fine-tuning LLMs in general cases.","However, pure soft prompt tuning treats source code as plain text, losing structural information inherent in source code.","Meanwhile, graph-enhanced soft prompt tuning methods, which aim to address this issue, are unable to preserve the rich semantic information within code graphs, as they are primarily designed for general graph-related tasks and focus more on adjacency information.","They also fail to ensure computational efficiency while accounting for graph-text interactions.   ","This paper, therefore, introduces a new code graph-enhanced, structure-aware soft prompt tuning method for vulnerability detection, referred to as CGP-Tuning.","It employs innovative type-aware embeddings to capture the rich semantic information within code graphs, along with a novel and efficient cross-modal alignment module that achieves linear computational cost while incorporating graph-text interactions.","The proposed CGP-Tuning is evaluated on the latest DiverseVul dataset and the most recent open-source code LLMs, CodeLlama and CodeGemma.","Experimental results demonstrate that CGP-Tuning outperforms the best state-of-the-art method by an average of 3.5 percentage points in accuracy, without compromising its vulnerability detection capabilities for long source code."],"url":"http://arxiv.org/abs/2501.04510v1"}
{"created":"2025-01-08 13:52:55","title":"Effective Two-Stage Double Auction for Dynamic Resource Trading in Edge Networks via Overbooking","abstract":"To facilitate responsive and cost-effective computing resource scheduling and service delivery over edge-assisted mobile networks, this paper investigates a novel two-stage double auction methodology via utilizing an interesting idea of resource overbooking to overcome dynamic and uncertain nature from edge servers (sellers) and demand from mobile devices (as buyers). The proposed auction integrates multiple essential factors such as social welfare maximization and decision-making latency (e.g., the time for determining winning seller-buyer pairs) reduction, by introducing a stagewise strategy: an overbooking-driven pre-double auction (OPDAuction) for determining long-term cooperations between sellers and buyers before practical resource transactions as Stage I, and a real-time backup double auction (RBDAuction) for handling residual resource demands during actual transactions. In particular, by applying a proper overbooking rate, OPDAuction helps with facilitating trading contracts between appropriate sellers and buyers as guidance for future transactions, by allowing the booked resources to exceed supply. Then, since pre-auctions may cause risks, our RBDAuction adjusts to real-time market changes, further enhancing the overall social welfare. More importantly, we offer an interesting view to show that our proposed two-stage auction can support significant design properties such as truthfulness, individual rationality, and budget balance. Through extensive experiments, we demonstrate good performance in social welfare, time efficiency, and computational scalability, outstripping conventional methods in dynamic edge computing settings.","sentences":["To facilitate responsive and cost-effective computing resource scheduling and service delivery over edge-assisted mobile networks, this paper investigates a novel two-stage double auction methodology via utilizing an interesting idea of resource overbooking to overcome dynamic and uncertain nature from edge servers (sellers) and demand from mobile devices (as buyers).","The proposed auction integrates multiple essential factors such as social welfare maximization and decision-making latency (e.g., the time for determining winning seller-buyer pairs) reduction, by introducing a stagewise strategy: an overbooking-driven pre-double auction (OPDAuction) for determining long-term cooperations between sellers and buyers before practical resource transactions as Stage I, and a real-time backup double auction (RBDAuction) for handling residual resource demands during actual transactions.","In particular, by applying a proper overbooking rate, OPDAuction helps with facilitating trading contracts between appropriate sellers and buyers as guidance for future transactions, by allowing the booked resources to exceed supply.","Then, since pre-auctions may cause risks, our RBDAuction adjusts to real-time market changes, further enhancing the overall social welfare.","More importantly, we offer an interesting view to show that our proposed two-stage auction can support significant design properties such as truthfulness, individual rationality, and budget balance.","Through extensive experiments, we demonstrate good performance in social welfare, time efficiency, and computational scalability, outstripping conventional methods in dynamic edge computing settings."],"url":"http://arxiv.org/abs/2501.04507v1"}
{"created":"2025-01-08 13:42:54","title":"Developing a Modular Compiler for a Subset of a C-like Language","abstract":"The paper introduces the development of a modular compiler for a subset of a C-like language, which addresses the challenges in constructing a compiler for high-level languages. This modular approach will allow developers to modify a language by adding or removing subsets as required, resulting in a minimal and memory-efficient compiler. The development process is divided into small, incremental steps, where each step yields a fully functioning compiler for an expanding subset of the language. The paper outlines the iterative developmental phase of the compiler, emphasizing progressive enhancements in capabilities and functionality. Adherence to industry best practices of modular design, code reusability, and documentation has enabled the resulting compiler's functional efficiency, maintainability, and extensibility. The compiler proved to be effective not only in managing the language structure but also in developing optimized code, which demonstrates its practical usability. This was also further assessed using the compiler on a tiny memory-deficient single-board computer, again showing the compiler's efficiency and suitability for resource-constrained devices.","sentences":["The paper introduces the development of a modular compiler for a subset of a C-like language, which addresses the challenges in constructing a compiler for high-level languages.","This modular approach will allow developers to modify a language by adding or removing subsets as required, resulting in a minimal and memory-efficient compiler.","The development process is divided into small, incremental steps, where each step yields a fully functioning compiler for an expanding subset of the language.","The paper outlines the iterative developmental phase of the compiler, emphasizing progressive enhancements in capabilities and functionality.","Adherence to industry best practices of modular design, code reusability, and documentation has enabled the resulting compiler's functional efficiency, maintainability, and extensibility.","The compiler proved to be effective not only in managing the language structure but also in developing optimized code, which demonstrates its practical usability.","This was also further assessed using the compiler on a tiny memory-deficient single-board computer, again showing the compiler's efficiency and suitability for resource-constrained devices."],"url":"http://arxiv.org/abs/2501.04503v1"}
