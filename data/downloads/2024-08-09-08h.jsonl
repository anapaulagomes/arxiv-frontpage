{"created":"2024-08-08 17:59:58","title":"LiDAR-Event Stereo Fusion with Hallucinations","abstract":"Event stereo matching is an emerging technique to estimate depth from neuromorphic cameras; however, events are unlikely to trigger in the absence of motion or the presence of large, untextured regions, making the correspondence problem extremely challenging. Purposely, we propose integrating a stereo event camera with a fixed-frequency active sensor -- e.g., a LiDAR -- collecting sparse depth measurements, overcoming the aforementioned limitations. Such depth hints are used by hallucinating -- i.e., inserting fictitious events -- the stacks or raw input streams, compensating for the lack of information in the absence of brightness changes. Our techniques are general, can be adapted to any structured representation to stack events and outperform state-of-the-art fusion methods applied to event-based stereo.","sentences":["Event stereo matching is an emerging technique to estimate depth from neuromorphic cameras; however, events are unlikely to trigger in the absence of motion or the presence of large, untextured regions, making the correspondence problem extremely challenging.","Purposely, we propose integrating a stereo event camera with a fixed-frequency active sensor -- e.g., a LiDAR -- collecting sparse depth measurements, overcoming the aforementioned limitations.","Such depth hints are used by hallucinating -- i.e., inserting fictitious events -- the stacks or raw input streams, compensating for the lack of information in the absence of brightness changes.","Our techniques are general, can be adapted to any structured representation to stack events and outperform state-of-the-art fusion methods applied to event-based stereo."],"url":"http://arxiv.org/abs/2408.04633v1"}
{"created":"2024-08-08 17:59:46","title":"Arctic-TILT. Business Document Understanding at Sub-Billion Scale","abstract":"The vast portion of workloads employing LLMs involves answering questions grounded on PDF or scan content. We introduce the Arctic-TILT achieving accuracy on par with models 1000$\\times$ its size on these use cases. It can be fine-tuned and deployed on a single 24GB GPU, lowering operational costs while processing Visually Rich Documents with up to 400k tokens. The model establishes state-of-the-art results on seven diverse Document Understanding benchmarks, as well as provides reliable confidence scores and quick inference, which are essential for processing files in large-scale or time-sensitive enterprise environments.","sentences":["The vast portion of workloads employing LLMs involves answering questions grounded on PDF or scan content.","We introduce the Arctic-TILT achieving accuracy on par with models 1000$\\times$ its size on these use cases.","It can be fine-tuned and deployed on a single 24GB GPU, lowering operational costs while processing Visually Rich Documents with up to 400k tokens.","The model establishes state-of-the-art results on seven diverse Document Understanding benchmarks, as well as provides reliable confidence scores and quick inference, which are essential for processing files in large-scale or time-sensitive enterprise environments."],"url":"http://arxiv.org/abs/2408.04632v1"}
{"created":"2024-08-08 17:59:38","title":"Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics","abstract":"We present Puppet-Master, an interactive video generative model that can serve as a motion prior for part-level dynamics. At test time, given a single image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can synthesize a video depicting realistic part-level motion faithful to the given drag interactions. This is achieved by fine-tuning a large-scale pre-trained video diffusion model, for which we propose a new conditioning architecture to inject the dragging control effectively. More importantly, we introduce the all-to-first attention mechanism, a drop-in replacement for the widely adopted spatial attention modules, which significantly improves generation quality by addressing the appearance and background issues in existing models. Unlike other motion-conditioned video generators that are trained on in-the-wild videos and mostly move an entire object, Puppet-Master is learned from Objaverse-Animation-HQ, a new dataset of curated part-level motion clips. We propose a strategy to automatically filter out sub-optimal animations and augment the synthetic renderings with meaningful motion trajectories. Puppet-Master generalizes well to real images across various categories and outperforms existing methods in a zero-shot manner on a real-world benchmark. See our project page for more results: vgg-puppetmaster.github.io.","sentences":["We present Puppet-Master, an interactive video generative model that can serve as a motion prior for part-level dynamics.","At test time, given a single image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can synthesize a video depicting realistic part-level motion faithful to the given drag interactions.","This is achieved by fine-tuning a large-scale pre-trained video diffusion model, for which we propose a new conditioning architecture to inject the dragging control effectively.","More importantly, we introduce the all-to-first attention mechanism, a drop-in replacement for the widely adopted spatial attention modules, which significantly improves generation quality by addressing the appearance and background issues in existing models.","Unlike other motion-conditioned video generators that are trained on in-the-wild videos and mostly move an entire object, Puppet-Master is learned from Objaverse-Animation-HQ, a new dataset of curated part-level motion clips.","We propose a strategy to automatically filter out sub-optimal animations and augment the synthetic renderings with meaningful motion trajectories.","Puppet-Master generalizes well to real images across various categories and outperforms existing methods in a zero-shot manner on a real-world benchmark.","See our project page for more results: vgg-puppetmaster.github.io."],"url":"http://arxiv.org/abs/2408.04631v1"}
{"created":"2024-08-08 17:58:06","title":"LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP","abstract":"Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor intensive process that requires expert knowledge. At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription -- this issue poses a bottleneck for researchers seeking to apply NLP toolkits to study ancient logographic languages: most of the relevant data are images of writing.   This paper investigates whether direct processing of visual representations of language offers a potential solution. We introduce LogogramNLP, the first benchmark enabling NLP analysis of ancient logographic languages, featuring both transcribed and visual datasets for four writing systems along with annotations for tasks like classification, translation, and parsing. Our experiments compare systems that employ recent visual and text encoding strategies as backbones. The results demonstrate that visual representations outperform textual representations for some investigated tasks, suggesting that visual processing pipelines may unlock a large amount of cultural heritage data of logographic languages for NLP-based analyses.","sentences":["Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens.","However, creating an analogous representation for ancient logographic writing systems is an extremely labor intensive process that requires expert knowledge.","At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription -- this issue poses a bottleneck for researchers seeking to apply NLP toolkits to study ancient logographic languages: most of the relevant data are images of writing.   ","This paper investigates whether direct processing of visual representations of language offers a potential solution.","We introduce LogogramNLP, the first benchmark enabling NLP analysis of ancient logographic languages, featuring both transcribed and visual datasets for four writing systems along with annotations for tasks like classification, translation, and parsing.","Our experiments compare systems that employ recent visual and text encoding strategies as backbones.","The results demonstrate that visual representations outperform textual representations for some investigated tasks, suggesting that visual processing pipelines may unlock a large amount of cultural heritage data of logographic languages for NLP-based analyses."],"url":"http://arxiv.org/abs/2408.04628v1"}
{"created":"2024-08-08 17:50:16","title":"Regularized Unconstrained Weakly Submodular Maximization","abstract":"Submodular optimization finds applications in machine learning and data mining. In this paper, we study the problem of maximizing functions of the form $h = f-c$, where $f$ is a monotone, non-negative, weakly submodular set function and $c$ is a modular function. We design a deterministic approximation algorithm that runs with ${{O}}(\\frac{n}{\\epsilon}\\log \\frac{n}{\\gamma \\epsilon})$ oracle calls to function $h$, and outputs a set ${S}$ such that $h({S}) \\geq \\gamma(1-\\epsilon)f(OPT)-c(OPT)-\\frac{c(OPT)}{\\gamma(1-\\epsilon)}\\log\\frac{f(OPT)}{c(OPT)}$, where $\\gamma$ is the submodularity ratio of $f$. Existing algorithms for this problem either admit a worse approximation ratio or have quadratic runtime. We also present an approximation ratio of our algorithm for this problem with an approximate oracle of $f$. We validate our theoretical results through extensive empirical evaluations on real-world applications, including vertex cover and influence diffusion problems for submodular utility function $f$, and Bayesian A-Optimal design for weakly submodular $f$. Our experimental results demonstrate that our algorithms efficiently achieve high-quality solutions.","sentences":["Submodular optimization finds applications in machine learning and data mining.","In this paper, we study the problem of maximizing functions of the form $h = f-c$, where $f$ is a monotone, non-negative, weakly submodular set function and $c$ is a modular function.","We design a deterministic approximation algorithm that runs with ${{O}}(\\frac{n}{\\epsilon}\\log \\frac{n}{\\gamma \\epsilon})$ oracle calls to function $h$, and outputs a set ${S}$ such that $h({S}) \\geq \\gamma(1-\\epsilon)f(OPT)-c(OPT)-\\frac{c(OPT)}{\\gamma(1-\\epsilon)}\\log\\frac{f(OPT)}{c(OPT)}$, where $\\gamma$ is the submodularity ratio of $f$. Existing algorithms for this problem either admit a worse approximation ratio or have quadratic runtime.","We also present an approximation ratio of our algorithm for this problem with an approximate oracle of $f$. We validate our theoretical results through extensive empirical evaluations on real-world applications, including vertex cover and influence diffusion problems for submodular utility function $f$, and Bayesian A-Optimal design for weakly submodular $f$. Our experimental results demonstrate that our algorithms efficiently achieve high-quality solutions."],"url":"http://arxiv.org/abs/2408.04620v1"}
{"created":"2024-08-08 17:49:07","title":"Transformer Explainer: Interactive Learning of Text-Generative Models","abstract":"Transformers have revolutionized machine learning, yet their inner workings remain opaque to many. We present Transformer Explainer, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model. Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures. It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens. Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques. Our open-sourced tool is available at https://poloclub.github.io/transformer-explainer/. A video demo is available at https://youtu.be/ECR4oAwocjs.","sentences":["Transformers have revolutionized machine learning, yet their inner workings remain opaque to many.","We present Transformer Explainer, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model.","Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures.","It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens.","Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques.","Our open-sourced tool is available at https://poloclub.github.io/transformer-explainer/. A video demo is available at https://youtu.be/ECR4oAwocjs."],"url":"http://arxiv.org/abs/2408.04619v1"}
{"created":"2024-08-08 17:43:53","title":"SSD Set System, Graph Decomposition and Hamiltonian Cycle","abstract":"In this paper, we first study what we call Superset-Subset-Disjoint (SSD) set system. Based on properties of SSD set system, we derive the following (I) to (IV):   (I) For a nonnegative integer $k$ and a graph $G=(V,E)$ with $|V|\\ge2$, let $X_1,X_2,\\dots,X_q\\subsetneq V$ denote all maximal proper subsets of $V$ that induce $k$-edge-connected subgraphs. Then at least one of (a) and (b) holds: (a) $\\{X_1,X_2,\\dots,X_q\\}$ is a partition of $V$; and (b) $V\\setminus X_1, V\\setminus X_2,\\dots,V\\setminus X_q$ are pairwise disjoint.   (II) For a strongly-connected (i.e., $k=1$) digraph $G$, we show that whether $V$ is in (a) and/or (b) can be decided in $O(n+m)$ time and that we can generate all such $X_1,X_2,\\dots,X_q$ in $O(n+m+|X_1|+|X_2|+\\dots+|X_q|)$ time, where $n=|V|$ and $m=|E|$.   (III) For a digraph $G$, we can enumerate in linear delay all vertex subsets of $V$ that induce strongly-connected subgraphs.   (IV) A digraph is Hamiltonian if there is a spanning subgraph that is strongly-connected and in the case (a).","sentences":["In this paper, we first study what we call Superset-Subset-Disjoint (SSD) set system.","Based on properties of SSD set system, we derive the following (I) to (IV):   (I) For a nonnegative integer $k$ and a graph $G=(V,E)$ with $|V|\\ge2$, let $X_1,X_2,\\dots,X_q\\subsetneq V$ denote all maximal proper subsets of $V$ that induce $k$-edge-connected subgraphs.","Then at least one of (a) and (b) holds: (a) $\\{X_1,X_2,\\dots,X_q\\}$ is a partition of $V$; and (b) $V\\setminus X_1, V\\setminus X_2,\\dots,V\\setminus X_q$ are pairwise disjoint.   ","(II)","For a strongly-connected (i.e., $k=1$) digraph $G$, we show that whether $V$ is in (a) and/or (b) can be decided in $O(n+m)$ time and that we can generate all such $X_1,X_2,\\dots,X_q$ in $O(n+m+|X_1|+|X_2|+\\dots+|X_q|)$ time, where $n=|V|$ and $m=|E|$.   (III)","For a digraph $G$, we can enumerate in linear delay all vertex subsets of $V$ that induce strongly-connected subgraphs.   ","(IV) A digraph is Hamiltonian if there is a spanning subgraph that is strongly-connected and in the case (a)."],"url":"http://arxiv.org/abs/2408.04615v1"}
{"created":"2024-08-08 17:42:32","title":"Better Alignment with Instruction Back-and-Forth Translation","abstract":"We propose a new method, instruction back-and-forth translation, to construct high-quality synthetic data grounded in world knowledge for aligning large language models (LLMs). Given documents from a web corpus, we generate and curate synthetic instructions using the backtranslation approach proposed by Li et al.(2023a), and rewrite the responses to improve their quality further based on the initial documents. Fine-tuning with the resulting (backtranslated instruction, rewritten response) pairs yields higher win rates on AlpacaEval than using other common instruction datasets such as Humpback, ShareGPT, Open Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the responses with an LLM outperforms direct distillation, and the two generated text distributions exhibit significant distinction in embedding space. Further analysis shows that our backtranslated instructions are of higher quality than other sources of synthetic instructions, while our responses are more diverse and complex than those obtained from distillation. Overall we find that instruction back-and-forth translation combines the best of both worlds -- making use of the information diversity and quantity found on the web, while ensuring the quality of the responses which is necessary for effective alignment.","sentences":["We propose a new method, instruction back-and-forth translation, to construct high-quality synthetic data grounded in world knowledge for aligning large language models (LLMs).","Given documents from a web corpus, we generate and curate synthetic instructions using the backtranslation approach proposed by Li et al.(2023a), and rewrite the responses to improve their quality further based on the initial documents.","Fine-tuning with the resulting (backtranslated instruction, rewritten response) pairs yields higher win rates on AlpacaEval than using other common instruction datasets such as Humpback, ShareGPT, Open Orca, Alpaca-GPT4 and Self-instruct.","We also demonstrate that rewriting the responses with an LLM outperforms direct distillation, and the two generated text distributions exhibit significant distinction in embedding space.","Further analysis shows that our backtranslated instructions are of higher quality than other sources of synthetic instructions, while our responses are more diverse and complex than those obtained from distillation.","Overall we find that instruction back-and-forth translation combines the best of both worlds -- making use of the information diversity and quantity found on the web, while ensuring the quality of the responses which is necessary for effective alignment."],"url":"http://arxiv.org/abs/2408.04614v1"}
{"created":"2024-08-08 17:40:01","title":"Core-Sparse Monge Matrix Multiplication: Improved Algorithm and Applications","abstract":"The task of min-plus matrix multiplication often arises in the context of distances in graphs and is known to be fine-grained equivalent to the All-Pairs Shortest Path problem. The non-crossing property of shortest paths in planar graphs gives rise to Monge matrices; the min-plus product of $n\\times n$ Monge matrices can be computed in $O(n^2)$ time. Grid graphs arising in sequence alignment problems, such as longest common subsequence or longest increasing subsequence, are even more structured. Tiskin [SODA'10] modeled their behavior using simple unit-Monge matrices and showed that the min-plus product of such matrices can be computed in $O(n\\log n)$ time. Russo [SPIRE'11] showed that the min-plus product of arbitrary Monge matrices can be computed in time $O((n+\\delta)\\log^3 n)$ parameterized by the core size $\\delta$, which is $O(n)$ for unit-Monge matrices.   In this work, we provide a linear bound on the core size of the product matrix in terms of the core sizes of the input matrices and show how to solve the core-sparse Monge matrix multiplication problem in $O((n+\\delta)\\log n)$ time, matching the result of Tiskin for simple unit-Monge matrices. Our algorithm also allows $O(\\log \\delta)$-time witness recovery for any given entry of the output matrix. As an application of this functionality, we show that an array of size $n$ can be preprocessed in $O(n\\log^3 n)$ time so that the longest increasing subsequence of any sub-array can be reconstructed in $O(l)$ time, where $l$ is the length of the reported subsequence; in comparison, Karthik C. S. and Rahul [arXiv'24] recently achieved $O(l+n^{1/2}\\log^3 n)$-time reporting after $O(n^{3/2}\\log^3 n)$-time preprocessing. Our faster core-sparse Monge matrix multiplication also enabled reducing two logarithmic factors in the running times of the recent algorithms for edit distance with integer weights [Gorbachev & Kociumaka, arXiv'24].","sentences":["The task of min-plus matrix multiplication often arises in the context of distances in graphs and is known to be fine-grained equivalent to the All-Pairs Shortest Path problem.","The non-crossing property of shortest paths in planar graphs gives rise to Monge matrices; the min-plus product of $n\\times n$ Monge matrices can be computed in $O(n^2)$ time.","Grid graphs arising in sequence alignment problems, such as longest common subsequence or longest increasing subsequence, are even more structured.","Tiskin","[SODA'10] modeled their behavior using simple unit-Monge matrices and showed that the min-plus product of such matrices can be computed in $O(n\\log n)$ time.","Russo [SPIRE'11] showed that the min-plus product of arbitrary Monge matrices can be computed in time $O((n+\\delta)\\log^3 n)$ parameterized by the core size $\\delta$, which is $O(n)$ for unit-Monge matrices.   ","In this work, we provide a linear bound on the core size of the product matrix in terms of the core sizes of the input matrices and show how to solve the core-sparse Monge matrix multiplication problem in $O((n+\\delta)\\log n)$ time, matching the result of Tiskin for simple unit-Monge matrices.","Our algorithm also allows $O(\\log \\delta)$-time witness recovery for any given entry of the output matrix.","As an application of this functionality, we show that an array of size $n$ can be preprocessed in $O(n\\log^3 n)$ time so that the longest increasing subsequence of any sub-array can be reconstructed in $O(l)$ time, where $l$ is the length of the reported subsequence; in comparison, Karthik C. S. and Rahul","[arXiv'24] recently achieved $O(l+n^{1/2}\\log^3 n)$-time reporting after $O(n^{3/2}\\log^3 n)$-time preprocessing.","Our faster core-sparse Monge matrix multiplication also enabled reducing two logarithmic factors in the running times of the recent algorithms for edit distance with integer weights","[Gorbachev & Kociumaka, arXiv'24]."],"url":"http://arxiv.org/abs/2408.04613v1"}
{"created":"2024-08-08 17:28:24","title":"Criticizing Ethics According to Artificial Intelligence","abstract":"This article presents a critique of ethics in the context of artificial intelligence (AI). It argues for the need to question established patterns of thought and traditional authorities, including core concepts such as autonomy, morality, and ethics. These concepts are increasingly inadequate to deal with the complexities introduced by emerging AI and autonomous agents. This critique has several key components: clarifying conceptual ambiguities, honestly addressing epistemic issues, and thoroughly exploring fundamental normative problems. The ultimate goal is to reevaluate and possibly redefine some traditional ethical concepts to better address the challenges posed by AI.","sentences":["This article presents a critique of ethics in the context of artificial intelligence (AI).","It argues for the need to question established patterns of thought and traditional authorities, including core concepts such as autonomy, morality, and ethics.","These concepts are increasingly inadequate to deal with the complexities introduced by emerging AI and autonomous agents.","This critique has several key components: clarifying conceptual ambiguities, honestly addressing epistemic issues, and thoroughly exploring fundamental normative problems.","The ultimate goal is to reevaluate and possibly redefine some traditional ethical concepts to better address the challenges posed by AI."],"url":"http://arxiv.org/abs/2408.04609v1"}
{"created":"2024-08-08 17:26:56","title":"Enhanced Prototypical Part Network (EPPNet) For Explainable Image Classification Via Prototypes","abstract":"Explainable Artificial Intelligence (xAI) has the potential to enhance the transparency and trust of AI-based systems. Although accurate predictions can be made using Deep Neural Networks (DNNs), the process used to arrive at such predictions is usually hard to explain. In terms of perceptibly human-friendly representations, such as word phrases in text or super-pixels in images, prototype-based explanations can justify a model's decision. In this work, we introduce a DNN architecture for image classification, the Enhanced Prototypical Part Network (EPPNet), which achieves strong performance while discovering relevant prototypes that can be used to explain the classification results. This is achieved by introducing a novel cluster loss that helps to discover more relevant human-understandable prototypes. We also introduce a faithfulness score to evaluate the explainability of the results based on the discovered prototypes. Our score not only accounts for the relevance of the learned prototypes but also the performance of a model. Our evaluations on the CUB-200-2011 dataset show that the EPPNet outperforms state-of-the-art xAI-based methods, in terms of both classification accuracy and explainability","sentences":["Explainable Artificial Intelligence (xAI) has the potential to enhance the transparency and trust of AI-based systems.","Although accurate predictions can be made using Deep Neural Networks (DNNs), the process used to arrive at such predictions is usually hard to explain.","In terms of perceptibly human-friendly representations, such as word phrases in text or super-pixels in images, prototype-based explanations can justify a model's decision.","In this work, we introduce a DNN architecture for image classification, the Enhanced Prototypical Part Network (EPPNet), which achieves strong performance while discovering relevant prototypes that can be used to explain the classification results.","This is achieved by introducing a novel cluster loss that helps to discover more relevant human-understandable prototypes.","We also introduce a faithfulness score to evaluate the explainability of the results based on the discovered prototypes.","Our score not only accounts for the relevance of the learned prototypes but also the performance of a model.","Our evaluations on the CUB-200-2011 dataset show that the EPPNet outperforms state-of-the-art xAI-based methods, in terms of both classification accuracy and explainability"],"url":"http://arxiv.org/abs/2408.04606v1"}
{"created":"2024-08-08 17:24:54","title":"Fall Detection for Industrial Setups Using YOLOv8 Variants","abstract":"This paper presents the development of an industrial fall detection system utilizing YOLOv8 variants, enhanced by our proposed augmentation pipeline to increase dataset variance and improve detection accuracy. Among the models evaluated, the YOLOv8m model, consisting of 25.9 million parameters and 79.1 GFLOPs, demonstrated a respectable balance between computational efficiency and detection performance, achieving a mean Average Precision (mAP) of 0.971 at 50% Intersection over Union (IoU) across both \"Fall Detected\" and \"Human in Motion\" categories. Although the YOLOv8l and YOLOv8x models presented higher precision and recall, particularly in fall detection, their higher computational demands and model size make them less suitable for resource-constrained environments.","sentences":["This paper presents the development of an industrial fall detection system utilizing YOLOv8 variants, enhanced by our proposed augmentation pipeline to increase dataset variance and improve detection accuracy.","Among the models evaluated, the YOLOv8m model, consisting of 25.9 million parameters and 79.1 GFLOPs, demonstrated a respectable balance between computational efficiency and detection performance, achieving a mean Average Precision (mAP) of 0.971 at 50% Intersection over Union (IoU) across both \"Fall Detected\" and \"Human in Motion\" categories.","Although the YOLOv8l and YOLOv8x models presented higher precision and recall, particularly in fall detection, their higher computational demands and model size make them less suitable for resource-constrained environments."],"url":"http://arxiv.org/abs/2408.04605v1"}
{"created":"2024-08-08 17:24:03","title":"Towards High-resolution 3D Anomaly Detection via Group-Level Feature Contrastive Learning","abstract":"High-resolution point clouds~(HRPCD) anomaly detection~(AD) plays a critical role in precision machining and high-end equipment manufacturing. Despite considerable 3D-AD methods that have been proposed recently, they still cannot meet the requirements of the HRPCD-AD task. There are several challenges: i) It is difficult to directly capture HRPCD information due to large amounts of points at the sample level; ii) The advanced transformer-based methods usually obtain anisotropic features, leading to degradation of the representation; iii) The proportion of abnormal areas is very small, which makes it difficult to characterize. To address these challenges, we propose a novel group-level feature-based network, called Group3AD, which has a significantly efficient representation ability. First, we design an Intercluster Uniformity Network~(IUN) to present the mapping of different groups in the feature space as several clusters, and obtain a more uniform distribution between clusters representing different parts of the point clouds in the feature space. Then, an Intracluster Alignment Network~(IAN) is designed to encourage groups within the cluster to be distributed tightly in the feature space. In addition, we propose an Adaptive Group-Center Selection~(AGCS) based on geometric information to improve the pixel density of potential anomalous regions during inference. The experimental results verify the effectiveness of our proposed Group3AD, which surpasses Reg3D-AD by the margin of 5\\% in terms of object-level AUROC on Real3D-AD. We provide the code and supplementary information on our website: https://github.com/M-3LAB/Group3AD.","sentences":["High-resolution point clouds~(HRPCD) anomaly detection~(AD) plays a critical role in precision machining and high-end equipment manufacturing.","Despite considerable 3D-AD methods that have been proposed recently, they still cannot meet the requirements of the HRPCD-AD task.","There are several challenges: i) It is difficult to directly capture HRPCD information due to large amounts of points at the sample level; ii) The advanced transformer-based methods usually obtain anisotropic features, leading to degradation of the representation; iii)","The proportion of abnormal areas is very small, which makes it difficult to characterize.","To address these challenges, we propose a novel group-level feature-based network, called Group3AD, which has a significantly efficient representation ability.","First, we design an Intercluster Uniformity Network~(IUN) to present the mapping of different groups in the feature space as several clusters, and obtain a more uniform distribution between clusters representing different parts of the point clouds in the feature space.","Then, an Intracluster Alignment Network~(IAN) is designed to encourage groups within the cluster to be distributed tightly in the feature space.","In addition, we propose an Adaptive Group-Center Selection~(AGCS) based on geometric information to improve the pixel density of potential anomalous regions during inference.","The experimental results verify the effectiveness of our proposed Group3AD, which surpasses Reg3D-AD by the margin of 5\\% in terms of object-level AUROC on Real3D-AD.","We provide the code and supplementary information on our website: https://github.com/M-3LAB/Group3AD."],"url":"http://arxiv.org/abs/2408.04604v1"}
{"created":"2024-08-08 17:20:08","title":"Improving Network Interpretability via Explanation Consistency Evaluation","abstract":"While deep neural networks have achieved remarkable performance, they tend to lack transparency in prediction. The pursuit of greater interpretability in neural networks often results in a degradation of their original performance. Some works strive to improve both interpretability and performance, but they primarily depend on meticulously imposed conditions. In this paper, we propose a simple yet effective framework that acquires more explainable activation heatmaps and simultaneously increase the model performance, without the need for any extra supervision. Specifically, our concise framework introduces a new metric, i.e., explanation consistency, to reweight the training samples adaptively in model learning. The explanation consistency metric is utilized to measure the similarity between the model's visual explanations of the original samples and those of semantic-preserved adversarial samples, whose background regions are perturbed by using image adversarial attack techniques. Our framework then promotes the model learning by paying closer attention to those training samples with a high difference in explanations (i.e., low explanation consistency), for which the current model cannot provide robust interpretations. Comprehensive experimental results on various benchmarks demonstrate the superiority of our framework in multiple aspects, including higher recognition accuracy, greater data debiasing capability, stronger network robustness, and more precise localization ability on both regular networks and interpretable networks. We also provide extensive ablation studies and qualitative analyses to unveil the detailed contribution of each component.","sentences":["While deep neural networks have achieved remarkable performance, they tend to lack transparency in prediction.","The pursuit of greater interpretability in neural networks often results in a degradation of their original performance.","Some works strive to improve both interpretability and performance, but they primarily depend on meticulously imposed conditions.","In this paper, we propose a simple yet effective framework that acquires more explainable activation heatmaps and simultaneously increase the model performance, without the need for any extra supervision.","Specifically, our concise framework introduces a new metric, i.e., explanation consistency, to reweight the training samples adaptively in model learning.","The explanation consistency metric is utilized to measure the similarity between the model's visual explanations of the original samples and those of semantic-preserved adversarial samples, whose background regions are perturbed by using image adversarial attack techniques.","Our framework then promotes the model learning by paying closer attention to those training samples with a high difference in explanations (i.e., low explanation consistency), for which the current model cannot provide robust interpretations.","Comprehensive experimental results on various benchmarks demonstrate the superiority of our framework in multiple aspects, including higher recognition accuracy, greater data debiasing capability, stronger network robustness, and more precise localization ability on both regular networks and interpretable networks.","We also provide extensive ablation studies and qualitative analyses to unveil the detailed contribution of each component."],"url":"http://arxiv.org/abs/2408.04600v1"}
{"created":"2024-08-08 17:19:02","title":"Quantum Key Storage for Efficient Key Management","abstract":"In the ongoing discourse surrounding integrating QKD networks as a service for critical infrastructures, key storage design often receives insufficient attention. Nonetheless, it bears crucial significance as it profoundly impacts the efficiency of QKD network services, thereby shaping its suitability for diverse applications. In this article, we analyze the effectiveness of key storage designs developed through practical testbeds and propose a novel key storage design to increase the effectiveness of key creation and supply. All key storage designs underwent analysis using network simulation tools, and the findings demonstrate that the novel key storage design surpasses existing approaches in terms of performance.","sentences":["In the ongoing discourse surrounding integrating QKD networks as a service for critical infrastructures, key storage design often receives insufficient attention.","Nonetheless, it bears crucial significance as it profoundly impacts the efficiency of QKD network services, thereby shaping its suitability for diverse applications.","In this article, we analyze the effectiveness of key storage designs developed through practical testbeds and propose a novel key storage design to increase the effectiveness of key creation and supply.","All key storage designs underwent analysis using network simulation tools, and the findings demonstrate that the novel key storage design surpasses existing approaches in terms of performance."],"url":"http://arxiv.org/abs/2408.04598v1"}
{"created":"2024-08-08 17:14:12","title":"Code-switching in text and speech reveals information-theoretic audience design","abstract":"In this work, we use language modeling to investigate the factors that influence code-switching. Code-switching occurs when a speaker alternates between one language variety (the primary language) and another (the secondary language), and is widely observed in multilingual contexts. Recent work has shown that code-switching is often correlated with areas of high information load in the primary language, but it is unclear whether high primary language load only makes the secondary language relatively easier to produce at code-switching points (speaker-driven code-switching), or whether code-switching is additionally used by speakers to signal the need for greater attention on the part of listeners (audience-driven code-switching). In this paper, we use bilingual Chinese-English online forum posts and transcripts of spontaneous Chinese-English speech to replicate prior findings that high primary language (Chinese) information load is correlated with switches to the secondary language (English). We then demonstrate that the information load of the English productions is even higher than that of meaning equivalent Chinese alternatives, and these are therefore not easier to produce, providing evidence of audience-driven influences in code-switching at the level of the communication channel, not just at the sociolinguistic level, in both writing and speech.","sentences":["In this work, we use language modeling to investigate the factors that influence code-switching.","Code-switching occurs when a speaker alternates between one language variety (the primary language) and another (the secondary language), and is widely observed in multilingual contexts.","Recent work has shown that code-switching is often correlated with areas of high information load in the primary language, but it is unclear whether high primary language load only makes the secondary language relatively easier to produce at code-switching points (speaker-driven code-switching), or whether code-switching is additionally used by speakers to signal the need for greater attention on the part of listeners (audience-driven code-switching).","In this paper, we use bilingual Chinese-English online forum posts and transcripts of spontaneous Chinese-English speech to replicate prior findings that high primary language (Chinese) information load is correlated with switches to the secondary language (English).","We then demonstrate that the information load of the English productions is even higher than that of meaning equivalent Chinese alternatives, and these are therefore not easier to produce, providing evidence of audience-driven influences in code-switching at the level of the communication channel, not just at the sociolinguistic level, in both writing and speech."],"url":"http://arxiv.org/abs/2408.04596v1"}
{"created":"2024-08-08 17:10:16","title":"Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models","abstract":"High-performance Multimodal Large Language Models (MLLMs) rely heavily on data quality. This study introduces a novel dataset named Img-Diff, designed to enhance fine-grained image recognition in MLLMs by leveraging insights from contrastive learning and image difference captioning. By analyzing object differences between similar images, we challenge models to identify both matching and distinct components. We utilize the Stable-Diffusion-XL model and advanced image editing techniques to create pairs of similar images that highlight object replacements. Our methodology includes a Difference Area Generator for object differences identifying, followed by a Difference Captions Generator for detailed difference descriptions. The result is a relatively small but high-quality dataset of \"object replacement\" samples. We use the the proposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B, yielding comprehensive improvements of performance scores over SOTA models that trained with larger-scale datasets, in numerous image difference and Visual Question Answering tasks. For instance, our trained models notably surpass the SOTA models GPT-4V and Gemini on the MMVP benchmark. Besides, we investigate alternative methods for generating image difference data through \"object removal\" and conduct thorough evaluation to confirm the dataset's diversity, quality, and robustness, presenting several insights on synthesis of such contrastive dataset. To encourage further research and advance the field of multimodal data synthesis and enhancement of MLLMs' fundamental capabilities for image understanding, we release our codes and dataset at https://github.com/modelscope/data-juicer/tree/ImgDiff.","sentences":["High-performance Multimodal Large Language Models (MLLMs) rely heavily on data quality.","This study introduces a novel dataset named Img-Diff, designed to enhance fine-grained image recognition in MLLMs by leveraging insights from contrastive learning and image difference captioning.","By analyzing object differences between similar images, we challenge models to identify both matching and distinct components.","We utilize the Stable-Diffusion-XL model and advanced image editing techniques to create pairs of similar images that highlight object replacements.","Our methodology includes a Difference Area Generator for object differences identifying, followed by a Difference Captions Generator for detailed difference descriptions.","The result is a relatively small but high-quality dataset of \"object replacement\" samples.","We use the the proposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B, yielding comprehensive improvements of performance scores over SOTA models that trained with larger-scale datasets, in numerous image difference and Visual Question Answering tasks.","For instance, our trained models notably surpass the SOTA models GPT-4V and Gemini on the MMVP benchmark.","Besides, we investigate alternative methods for generating image difference data through \"object removal\" and conduct thorough evaluation to confirm the dataset's diversity, quality, and robustness, presenting several insights on synthesis of such contrastive dataset.","To encourage further research and advance the field of multimodal data synthesis and enhancement of MLLMs' fundamental capabilities for image understanding, we release our codes and dataset at https://github.com/modelscope/data-juicer/tree/ImgDiff."],"url":"http://arxiv.org/abs/2408.04594v1"}
{"created":"2024-08-08 17:08:57","title":"SAM 2 in Robotic Surgery: An Empirical Evaluation for Robustness and Generalization in Surgical Video Segmentation","abstract":"The recent Segment Anything Model (SAM) 2 has demonstrated remarkable foundational competence in semantic segmentation, with its memory mechanism and mask decoder further addressing challenges in video tracking and object occlusion, thereby achieving superior results in interactive segmentation for both images and videos. Building upon our previous empirical studies, we further explore the zero-shot segmentation performance of SAM 2 in robot-assisted surgery based on prompts, alongside its robustness against real-world corruption. For static images, we employ two forms of prompts: 1-point and bounding box, while for video sequences, the 1-point prompt is applied to the initial frame. Through extensive experimentation on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 2, when utilizing bounding box prompts, outperforms state-of-the-art (SOTA) methods in comparative evaluations. The results with point prompts also exhibit a substantial enhancement over SAM's capabilities, nearing or even surpassing existing unprompted SOTA methodologies. Besides, SAM 2 demonstrates improved inference speed and less performance degradation against various image corruption. Although slightly unsatisfactory results remain in specific edges or regions, SAM 2's robust adaptability to 1-point prompts underscores its potential for downstream surgical tasks with limited prompt requirements.","sentences":["The recent Segment Anything Model (SAM) 2 has demonstrated remarkable foundational competence in semantic segmentation, with its memory mechanism and mask decoder further addressing challenges in video tracking and object occlusion, thereby achieving superior results in interactive segmentation for both images and videos.","Building upon our previous empirical studies, we further explore the zero-shot segmentation performance of SAM 2 in robot-assisted surgery based on prompts, alongside its robustness against real-world corruption.","For static images, we employ two forms of prompts: 1-point and bounding box, while for video sequences, the 1-point prompt is applied to the initial frame.","Through extensive experimentation on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 2, when utilizing bounding box prompts, outperforms state-of-the-art (SOTA) methods in comparative evaluations.","The results with point prompts also exhibit a substantial enhancement over SAM's capabilities, nearing or even surpassing existing unprompted SOTA methodologies.","Besides, SAM 2 demonstrates improved inference speed and less performance degradation against various image corruption.","Although slightly unsatisfactory results remain in specific edges or regions, SAM 2's robust adaptability to 1-point prompts underscores its potential for downstream surgical tasks with limited prompt requirements."],"url":"http://arxiv.org/abs/2408.04593v1"}
{"created":"2024-08-08 17:04:06","title":"HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts","abstract":"Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones. In this paper, we challenge a remaining assumption in this task: that all images share the same domain. Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set. Our proposed `HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations. Our intuition is that the clusterings based on domain information and semantic information should be independent. We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach. Finally, we construct a benchmark from corrupted fine-grained datasets as well as a large-scale evaluation on DomainNet with real-world domain shifts, reimplementing a number of GCD baselines in this setting. We demonstrate that HiLo outperforms SoTA category discovery models by a large margin on all evaluations.","sentences":["Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones.","In this paper, we challenge a remaining assumption in this task: that all images share the same domain.","Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set.","Our proposed `HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations.","Our intuition is that the clusterings based on domain information and semantic information should be independent.","We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach.","Finally, we construct a benchmark from corrupted fine-grained datasets as well as a large-scale evaluation on DomainNet with real-world domain shifts, reimplementing a number of GCD baselines in this setting.","We demonstrate that HiLo outperforms SoTA category discovery models by a large margin on all evaluations."],"url":"http://arxiv.org/abs/2408.04591v1"}
{"created":"2024-08-08 17:01:26","title":"Learn To Learn More Precisely","abstract":"Meta-learning has been extensively applied in the domains of few-shot learning and fast adaptation, achieving remarkable performance. While Meta-learning methods like Model-Agnostic Meta-Learning (MAML) and its variants provide a good set of initial parameters for the model, the model still tends to learn shortcut features, which leads to poor generalization. In this paper, we propose the formal conception of \"learn to learn more precisely\", which aims to make the model learn precise target knowledge from data and reduce the effect of noisy knowledge, such as background and noise. To achieve this target, we proposed a simple and effective meta-learning framework named Meta Self-Distillation(MSD) to maximize the consistency of learned knowledge, enhancing the models' ability to learn precise target knowledge. In the inner loop, MSD uses different augmented views of the same support data to update the model respectively. Then in the outer loop, MSD utilizes the same query data to optimize the consistency of learned knowledge, enhancing the model's ability to learn more precisely. Our experiment demonstrates that MSD exhibits remarkable performance in few-shot classification tasks in both standard and augmented scenarios, effectively boosting the accuracy and consistency of knowledge learned by the model.","sentences":["Meta-learning has been extensively applied in the domains of few-shot learning and fast adaptation, achieving remarkable performance.","While Meta-learning methods like Model-Agnostic Meta-Learning (MAML) and its variants provide a good set of initial parameters for the model, the model still tends to learn shortcut features, which leads to poor generalization.","In this paper, we propose the formal conception of \"learn to learn more precisely\", which aims to make the model learn precise target knowledge from data and reduce the effect of noisy knowledge, such as background and noise.","To achieve this target, we proposed a simple and effective meta-learning framework named Meta Self-Distillation(MSD) to maximize the consistency of learned knowledge, enhancing the models' ability to learn precise target knowledge.","In the inner loop, MSD uses different augmented views of the same support data to update the model respectively.","Then in the outer loop, MSD utilizes the same query data to optimize the consistency of learned knowledge, enhancing the model's ability to learn more precisely.","Our experiment demonstrates that MSD exhibits remarkable performance in few-shot classification tasks in both standard and augmented scenarios, effectively boosting the accuracy and consistency of knowledge learned by the model."],"url":"http://arxiv.org/abs/2408.04590v1"}
{"created":"2024-08-08 16:56:07","title":"FORGE: Force-Guided Exploration for Robust Contact-Rich Manipulation under Uncertainty","abstract":"We present FORGE, a method that enables sim-to-real transfer of contact-rich manipulation policies in the presence of significant pose uncertainty. FORGE combines a force threshold mechanism with a dynamics randomization scheme during policy learning in simulation, to enable the robust transfer of the learned policies to the real robot. At deployment, FORGE policies, conditioned on a maximum allowable force, adaptively perform contact-rich tasks while respecting the specified force threshold, regardless of the controller gains. Additionally, FORGE autonomously predicts a termination action once the task has succeeded. We demonstrate that FORGE can be used to learn a variety of robust contact-rich policies, enabling multi-stage assembly of a planetary gear system, which requires success across three assembly tasks: nut-threading, insertion, and gear meshing. Project website can be accessed at https://noseworm.github.io/forge/.","sentences":["We present FORGE, a method that enables sim-to-real transfer of contact-rich manipulation policies in the presence of significant pose uncertainty.","FORGE combines a force threshold mechanism with a dynamics randomization scheme during policy learning in simulation, to enable the robust transfer of the learned policies to the real robot.","At deployment, FORGE policies, conditioned on a maximum allowable force, adaptively perform contact-rich tasks while respecting the specified force threshold, regardless of the controller gains.","Additionally, FORGE autonomously predicts a termination action once the task has succeeded.","We demonstrate that FORGE can be used to learn a variety of robust contact-rich policies, enabling multi-stage assembly of a planetary gear system, which requires success across three assembly tasks: nut-threading, insertion, and gear meshing.","Project website can be accessed at https://noseworm.github.io/forge/."],"url":"http://arxiv.org/abs/2408.04587v1"}
{"created":"2024-08-08 16:56:03","title":"Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond","abstract":"Capturing and rendering novel views of complex real-world scenes is a long-standing problem in computer graphics and vision, with applications in augmented and virtual reality, immersive experiences and 3D photography. The advent of deep learning has enabled revolutionary advances in this area, classically known as image-based rendering. However, previous approaches require intractably dense view sampling or provide little or no guidance for how users should sample views of a scene to reliably render high-quality novel views. Local light field fusion proposes an algorithm for practical view synthesis from an irregular grid of sampled views that first expands each sampled view into a local light field via a multiplane image scene representation, then renders novel views by blending adjacent local light fields. Crucially, we extend traditional plenoptic sampling theory to derive a bound that specifies precisely how densely users should sample views of a given scene when using our algorithm. We achieve the perceptual quality of Nyquist rate view sampling while using up to 4000x fewer views. Subsequent developments have led to new scene representations for deep learning with view synthesis, notably neural radiance fields, but the problem of sparse view synthesis from a small number of images has only grown in importance. We reprise some of the recent results on sparse and even single image view synthesis, while posing the question of whether prescriptive sampling guidelines are feasible for the new generation of image-based rendering algorithms.","sentences":["Capturing and rendering novel views of complex real-world scenes is a long-standing problem in computer graphics and vision, with applications in augmented and virtual reality, immersive experiences and 3D photography.","The advent of deep learning has enabled revolutionary advances in this area, classically known as image-based rendering.","However, previous approaches require intractably dense view sampling or provide little or no guidance for how users should sample views of a scene to reliably render high-quality novel views.","Local light field fusion proposes an algorithm for practical view synthesis from an irregular grid of sampled views that first expands each sampled view into a local light field via a multiplane image scene representation, then renders novel views by blending adjacent local light fields.","Crucially, we extend traditional plenoptic sampling theory to derive a bound that specifies precisely how densely users should sample views of a given scene when using our algorithm.","We achieve the perceptual quality of Nyquist rate view sampling while using up to 4000x fewer views.","Subsequent developments have led to new scene representations for deep learning with view synthesis, notably neural radiance fields, but the problem of sparse view synthesis from a small number of images has only grown in importance.","We reprise some of the recent results on sparse and even single image view synthesis, while posing the question of whether prescriptive sampling guidelines are feasible for the new generation of image-based rendering algorithms."],"url":"http://arxiv.org/abs/2408.04586v1"}
{"created":"2024-08-08 16:54:40","title":"Towards Resilient and Efficient LLMs: A Comparative Study of Efficiency, Performance, and Adversarial Robustness","abstract":"With the increasing demand for practical applications of Large Language Models (LLMs), many attention-efficient models have been developed to balance performance and computational cost. However, the adversarial robustness of these models remains under-explored. In this work, we design a framework to investigate the trade-off between efficiency, performance, and adversarial robustness of LLMs by comparing three prominent models with varying levels of complexity and efficiency -- Transformer++, Gated Linear Attention (GLA) Transformer, and MatMul-Free LM -- utilizing the GLUE and AdvGLUE datasets. The AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to challenge model robustness. Our results show that while the GLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate higher efficiency and either superior or comparative robustness on AdvGLUE tasks compared to Transformer++ across different attack levels. These findings highlight the potential of simplified architectures to achieve a compelling balance between efficiency, performance, and adversarial robustness, offering valuable insights for applications where resource constraints and resilience to adversarial attacks are critical.","sentences":["With the increasing demand for practical applications of Large Language Models (LLMs), many attention-efficient models have been developed to balance performance and computational cost.","However, the adversarial robustness of these models remains under-explored.","In this work, we design a framework to investigate the trade-off between efficiency, performance, and adversarial robustness of LLMs by comparing three prominent models with varying levels of complexity and efficiency -- Transformer++, Gated Linear Attention (GLA) Transformer, and MatMul-Free LM -- utilizing the GLUE and AdvGLUE datasets.","The AdvGLUE dataset extends the GLUE dataset with adversarial samples designed to challenge model robustness.","Our results show that while the GLA Transformer and MatMul-Free LM achieve slightly lower accuracy on GLUE tasks, they demonstrate higher efficiency and either superior or comparative robustness on AdvGLUE tasks compared to Transformer++ across different attack levels.","These findings highlight the potential of simplified architectures to achieve a compelling balance between efficiency, performance, and adversarial robustness, offering valuable insights for applications where resource constraints and resilience to adversarial attacks are critical."],"url":"http://arxiv.org/abs/2408.04585v1"}
{"created":"2024-08-08 16:48:33","title":"Unveiling the Power of Sparse Neural Networks for Feature Selection","abstract":"Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient feature selection. Leveraging the dynamic sparse training (DST) algorithms within SNNs has demonstrated promising feature selection capabilities while drastically reducing computational overheads. Despite these advancements, several critical aspects remain insufficiently explored for feature selection. Questions persist regarding the choice of the DST algorithm for network training, the choice of metric for ranking features/neurons, and the comparative performance of these methods across diverse datasets when compared to dense networks. This paper addresses these gaps by presenting a comprehensive systematic analysis of feature selection with sparse neural networks. Moreover, we introduce a novel metric considering sparse neural network characteristics, which is designed to quantify feature importance within the context of SNNs. Our findings show that feature selection with SNNs trained with DST algorithms can achieve, on average, more than $50\\%$ memory and $55\\%$ FLOPs reduction compared to the dense networks, while outperforming them in terms of the quality of the selected features. Our code and the supplementary material are available on GitHub (\\url{https://github.com/zahraatashgahi/Neuron-Attribution}).","sentences":["Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient feature selection.","Leveraging the dynamic sparse training (DST) algorithms within SNNs has demonstrated promising feature selection capabilities while drastically reducing computational overheads.","Despite these advancements, several critical aspects remain insufficiently explored for feature selection.","Questions persist regarding the choice of the DST algorithm for network training, the choice of metric for ranking features/neurons, and the comparative performance of these methods across diverse datasets when compared to dense networks.","This paper addresses these gaps by presenting a comprehensive systematic analysis of feature selection with sparse neural networks.","Moreover, we introduce a novel metric considering sparse neural network characteristics, which is designed to quantify feature importance within the context of SNNs.","Our findings show that feature selection with SNNs trained with DST algorithms can achieve, on average, more than $50\\%$ memory and $55\\%$ FLOPs reduction compared to the dense networks, while outperforming them in terms of the quality of the selected features.","Our code and the supplementary material are available on GitHub (\\url{https://github.com/zahraatashgahi/Neuron-Attribution})."],"url":"http://arxiv.org/abs/2408.04583v1"}
{"created":"2024-08-08 16:42:45","title":"Quantum Key Distribution Networks -- Key Management: A Survey","abstract":"Secure communication makes the widespread use of telecommunication networks and services possible. With the constant progress of computing and mathematics, new cryptographic methods are being diligently developed. Quantum Key Distribution (QKD) is a promising technology that provides an Information-Theoretically Secure (ITS) solution to the secret-key agreement problem between two remote parties. QKD networks based on trusted repeaters are built to provide service to a larger number of parties at arbitrary distances. They function as an add-on technology to traditional networks, generating, managing, distributing, and supplying ITS cryptographic keys. Since key resources are limited, integrating QKD network services into critical infrastructures necessitates effective key management. As a result, this paper provides a comprehensive review of QKD network key management approaches. They are analyzed to facilitate the identification of potential strategies and accelerate the future development of QKD networks.","sentences":["Secure communication makes the widespread use of telecommunication networks and services possible.","With the constant progress of computing and mathematics, new cryptographic methods are being diligently developed.","Quantum Key Distribution (QKD) is a promising technology that provides an Information-Theoretically Secure (ITS) solution to the secret-key agreement problem between two remote parties.","QKD networks based on trusted repeaters are built to provide service to a larger number of parties at arbitrary distances.","They function as an add-on technology to traditional networks, generating, managing, distributing, and supplying ITS cryptographic keys.","Since key resources are limited, integrating QKD network services into critical infrastructures necessitates effective key management.","As a result, this paper provides a comprehensive review of QKD network key management approaches.","They are analyzed to facilitate the identification of potential strategies and accelerate the future development of QKD networks."],"url":"http://arxiv.org/abs/2408.04580v1"}
{"created":"2024-08-08 16:40:15","title":"SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream Tasks: Camouflage, Shadow, Medical Image Segmentation, and More","abstract":"The advent of large models, also known as foundation models, has significantly transformed the AI research landscape, with models like Segment Anything (SAM) achieving notable success in diverse image segmentation scenarios. Despite its advancements, SAM encountered limitations in handling some complex low-level segmentation tasks like camouflaged object and medical imaging. In response, in 2023, we introduced SAM-Adapter, which demonstrated improved performance on these challenging tasks. Now, with the release of Segment Anything 2 (SAM2), a successor with enhanced architecture and a larger training corpus, we reassess these challenges. This paper introduces SAM2-Adapter, the first adapter designed to overcome the persistent limitations observed in SAM2 and achieve new state-of-the-art (SOTA) results in specific downstream tasks including medical image segmentation, camouflaged (concealed) object detection, and shadow detection. SAM2-Adapter builds on the SAM-Adapter's strengths, offering enhanced generalizability and composability for diverse applications. We present extensive experimental results demonstrating SAM2-Adapter's effectiveness. We show the potential and encourage the research community to leverage the SAM2 model with our SAM2-Adapter for achieving superior segmentation outcomes. Code, pre-trained models, and data processing protocols are available at http://tianrun-chen.github.io/SAM-Adaptor/","sentences":["The advent of large models, also known as foundation models, has significantly transformed the AI research landscape, with models like Segment Anything (SAM) achieving notable success in diverse image segmentation scenarios.","Despite its advancements, SAM encountered limitations in handling some complex low-level segmentation tasks like camouflaged object and medical imaging.","In response, in 2023, we introduced SAM-Adapter, which demonstrated improved performance on these challenging tasks.","Now, with the release of Segment Anything 2 (SAM2), a successor with enhanced architecture and a larger training corpus, we reassess these challenges.","This paper introduces SAM2-Adapter, the first adapter designed to overcome the persistent limitations observed in SAM2 and achieve new state-of-the-art (SOTA) results in specific downstream tasks including medical image segmentation, camouflaged (concealed) object detection, and shadow detection.","SAM2-Adapter builds on the SAM-Adapter's strengths, offering enhanced generalizability and composability for diverse applications.","We present extensive experimental results demonstrating SAM2-Adapter's effectiveness.","We show the potential and encourage the research community to leverage the SAM2 model with our SAM2-Adapter for achieving superior segmentation outcomes.","Code, pre-trained models, and data processing protocols are available at http://tianrun-chen.github.io/SAM-Adaptor/"],"url":"http://arxiv.org/abs/2408.04579v1"}
{"created":"2024-08-08 16:36:24","title":"SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals","abstract":"Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner. By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.","sentences":["Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks.","This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner.","By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning.","SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks.","Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques."],"url":"http://arxiv.org/abs/2408.04575v1"}
{"created":"2024-08-08 16:36:14","title":"Integrating Annotations into the Design Process for Sonifications and Physicalizations","abstract":"Annotations are a critical component of visualizations, helping viewers interpret the visual representation and highlighting critical data insights. Despite their significant role, we lack an understanding of how annotations can be incorporated into other data representations, such as physicalizations and sonifications. Given the emergent nature of these representations, sonifications, and physicalizations lack formalized conventions (e.g., design space, vocabulary) that can introduce challenges for audiences to interpret the intended data encoding. To address this challenge, this work focuses on how annotations can be more tightly integrated into the design process of creating sonifications and physicalizations. In an exploratory study with 13 designers, we explore how visualization annotation techniques can be adapted to sonic and physical modalities. Our work highlights how annotations for sonification and physicalizations are inseparable from their data encodings.","sentences":["Annotations are a critical component of visualizations, helping viewers interpret the visual representation and highlighting critical data insights.","Despite their significant role, we lack an understanding of how annotations can be incorporated into other data representations, such as physicalizations and sonifications.","Given the emergent nature of these representations, sonifications, and physicalizations lack formalized conventions (e.g., design space, vocabulary) that can introduce challenges for audiences to interpret the intended data encoding.","To address this challenge, this work focuses on how annotations can be more tightly integrated into the design process of creating sonifications and physicalizations.","In an exploratory study with 13 designers, we explore how visualization annotation techniques can be adapted to sonic and physical modalities.","Our work highlights how annotations for sonification and physicalizations are inseparable from their data encodings."],"url":"http://arxiv.org/abs/2408.04574v1"}
{"created":"2024-08-08 16:29:09","title":"Mathematical Programming For Adaptive Experiments","abstract":"Adaptive experimentation can significantly improve statistical power, but standard algorithms overlook important practical issues including batched and delayed feedback, personalization, non-stationarity, multiple objectives, and constraints. To address these issues, the current algorithm design paradigm crafts tailored methods for each problem instance. Since it is infeasible to devise novel algorithms for every real-world instance, practitioners often have to resort to suboptimal approximations that do not address all of their challenges. Moving away from developing bespoke algorithms for each setting, we present a mathematical programming view of adaptive experimentation that can flexibly incorporate a wide range of objectives, constraints, and statistical procedures. By formulating a dynamic program in the batched limit, our modeling framework enables the use of scalable optimization methods (e.g., SGD and auto-differentiation) to solve for treatment allocations. We evaluate our framework on benchmarks modeled after practical challenges such as non-stationarity, personalization, multi-objectives, and constraints. Unlike bespoke algorithms such as modified variants of Thomson sampling, our mathematical programming approach provides remarkably robust performance across instances.","sentences":["Adaptive experimentation can significantly improve statistical power, but standard algorithms overlook important practical issues including batched and delayed feedback, personalization, non-stationarity, multiple objectives, and constraints.","To address these issues, the current algorithm design paradigm crafts tailored methods for each problem instance.","Since it is infeasible to devise novel algorithms for every real-world instance, practitioners often have to resort to suboptimal approximations that do not address all of their challenges.","Moving away from developing bespoke algorithms for each setting, we present a mathematical programming view of adaptive experimentation that can flexibly incorporate a wide range of objectives, constraints, and statistical procedures.","By formulating a dynamic program in the batched limit, our modeling framework enables the use of scalable optimization methods (e.g., SGD and auto-differentiation) to solve for treatment allocations.","We evaluate our framework on benchmarks modeled after practical challenges such as non-stationarity, personalization, multi-objectives, and constraints.","Unlike bespoke algorithms such as modified variants of Thomson sampling, our mathematical programming approach provides remarkably robust performance across instances."],"url":"http://arxiv.org/abs/2408.04570v1"}
{"created":"2024-08-08 16:28:56","title":"Activation thresholds and expressiveness of polynomial neural networks","abstract":"Polynomial neural networks have been implemented in a range of applications and present an advantageous framework for theoretical machine learning. A polynomial neural network of fixed architecture and activation degree gives an algebraic map from the network's weights to a set of polynomials. The image of this map is the space of functions representable by the network. Its Zariski closure is an affine variety known as a neurovariety. The dimension of a polynomial neural network's neurovariety provides a measure of its expressivity. In this work, we introduce the notion of the activation threshold of a network architecture which expresses when the dimension of a neurovariety achieves its theoretical maximum. In addition, we prove expressiveness results for polynomial neural networks with equi-width~architectures.","sentences":["Polynomial neural networks have been implemented in a range of applications and present an advantageous framework for theoretical machine learning.","A polynomial neural network of fixed architecture and activation degree gives an algebraic map from the network's weights to a set of polynomials.","The image of this map is the space of functions representable by the network.","Its Zariski closure is an affine variety known as a neurovariety.","The dimension of a polynomial neural network's neurovariety provides a measure of its expressivity.","In this work, we introduce the notion of the activation threshold of a network architecture which expresses when the dimension of a neurovariety achieves its theoretical maximum.","In addition, we prove expressiveness results for polynomial neural networks with equi-width~architectures."],"url":"http://arxiv.org/abs/2408.04569v1"}
{"created":"2024-08-08 16:28:22","title":"Learning Fine-Grained Grounded Citations for Attributed Large Language Models","abstract":"Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations. Attributed LLMs, which augment generated text with in-line citations, have shown potential in mitigating hallucinations and improving verifiability. However, current approaches suffer from suboptimal citation quality due to their reliance on in-context learning. Furthermore, the practice of citing only coarse document identifiers makes it challenging for users to perform fine-grained verification. In this work, we introduce FRONT, a training framework designed to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model outputs in fine-grained supporting quotes, these quotes guide the generation of grounded and consistent responses, not only improving citation quality but also facilitating fine-grained verification. Experiments on the ALCE benchmark demonstrate the efficacy of FRONT in generating superior grounded responses and highly supportive citations. With LLaMA-2-7B, the framework significantly outperforms all the baselines, achieving an average of 14.21% improvement in citation quality across all datasets, even surpassing ChatGPT.","sentences":["Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations.","Attributed LLMs, which augment generated text with in-line citations, have shown potential in mitigating hallucinations and improving verifiability.","However, current approaches suffer from suboptimal citation quality due to their reliance on in-context learning.","Furthermore, the practice of citing only coarse document identifiers makes it challenging for users to perform fine-grained verification.","In this work, we introduce FRONT, a training framework designed to teach LLMs to generate Fine-Grained Grounded Citations.","By grounding model outputs in fine-grained supporting quotes, these quotes guide the generation of grounded and consistent responses, not only improving citation quality but also facilitating fine-grained verification.","Experiments on the ALCE benchmark demonstrate the efficacy of FRONT in generating superior grounded responses and highly supportive citations.","With LLaMA-2-7B, the framework significantly outperforms all the baselines, achieving an average of 14.21% improvement in citation quality across all datasets, even surpassing ChatGPT."],"url":"http://arxiv.org/abs/2408.04568v1"}
{"created":"2024-08-08 16:27:37","title":"Sketch2Scene: Automatic Generation of Interactive 3D Game Scenes from User's Casual Sketches","abstract":"3D Content Generation is at the heart of many computer graphics applications, including video gaming, film-making, virtual and augmented reality, etc. This paper proposes a novel deep-learning based approach for automatically generating interactive and playable 3D game scenes, all from the user's casual prompts such as a hand-drawn sketch. Sketch-based input offers a natural, and convenient way to convey the user's design intention in the content creation process. To circumvent the data-deficient challenge in learning (i.e. the lack of large training data of 3D scenes), our method leverages a pre-trained 2D denoising diffusion model to generate a 2D image of the scene as the conceptual guidance. In this process, we adopt the isometric projection mode to factor out unknown camera poses while obtaining the scene layout. From the generated isometric image, we use a pre-trained image understanding method to segment the image into meaningful parts, such as off-ground objects, trees, and buildings, and extract the 2D scene layout. These segments and layouts are subsequently fed into a procedural content generation (PCG) engine, such as a 3D video game engine like Unity or Unreal, to create the 3D scene. The resulting 3D scene can be seamlessly integrated into a game development environment and is readily playable. Extensive tests demonstrate that our method can efficiently generate high-quality and interactive 3D game scenes with layouts that closely follow the user's intention.","sentences":["3D Content Generation is at the heart of many computer graphics applications, including video gaming, film-making, virtual and augmented reality, etc.","This paper proposes a novel deep-learning based approach for automatically generating interactive and playable 3D game scenes, all from the user's casual prompts such as a hand-drawn sketch.","Sketch-based input offers a natural, and convenient way to convey the user's design intention in the content creation process.","To circumvent the data-deficient challenge in learning (i.e. the lack of large training data of 3D scenes), our method leverages a pre-trained 2D denoising diffusion model to generate a 2D image of the scene as the conceptual guidance.","In this process, we adopt the isometric projection mode to factor out unknown camera poses while obtaining the scene layout.","From the generated isometric image, we use a pre-trained image understanding method to segment the image into meaningful parts, such as off-ground objects, trees, and buildings, and extract the 2D scene layout.","These segments and layouts are subsequently fed into a procedural content generation (PCG) engine, such as a 3D video game engine like Unity or Unreal, to create the 3D scene.","The resulting 3D scene can be seamlessly integrated into a game development environment and is readily playable.","Extensive tests demonstrate that our method can efficiently generate high-quality and interactive 3D game scenes with layouts that closely follow the user's intention."],"url":"http://arxiv.org/abs/2408.04567v1"}
{"created":"2024-08-08 16:18:39","title":"Conversational Prompt Engineering","abstract":"Prompts are how humans communicate with LLMs. Informative prompts are essential for guiding LLMs to produce the desired output. However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use. We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks. CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the prompt. The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction. Then, the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs. The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples. A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts. The results suggest that the zero-shot prompt obtained is comparable to its - much longer - few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large text volumes.","sentences":["Prompts are how humans communicate with LLMs.","Informative prompts are essential for guiding LLMs to produce the desired output.","However, prompt engineering is often tedious and time-consuming, requiring significant expertise, limiting its widespread use.","We propose Conversational Prompt Engineering (CPE), a user-friendly tool that helps users create personalized prompts for their specific tasks.","CPE uses a chat model to briefly interact with users, helping them articulate their output preferences and integrating these into the prompt.","The process includes two main stages: first, the model uses user-provided unlabeled data to generate data-driven questions and utilize user responses to shape the initial instruction.","Then, the model shares the outputs generated by the instruction and uses user feedback to further refine the instruction and the outputs.","The final result is a few-shot prompt, where the outputs approved by the user serve as few-shot examples.","A user study on summarization tasks demonstrates the value of CPE in creating personalized, high-performing prompts.","The results suggest that the zero-shot prompt obtained is comparable to its - much longer - few-shot counterpart, indicating significant savings in scenarios involving repetitive tasks with large text volumes."],"url":"http://arxiv.org/abs/2408.04560v1"}
{"created":"2024-08-08 16:13:26","title":"Bias-Aware Low-Rank Adaptation: Mitigating Catastrophic Inheritance of Large Language Models","abstract":"Large language models (LLMs) have exhibited remarkable proficiency across a diverse array of natural language processing (NLP) tasks. However, adapting LLMs to downstream applications typically necessitates computationally intensive and memory-demanding fine-tuning procedures. To mitigate these burdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a promising approach to tailor LLMs with minimal computational overhead. While PEFT methods offer substantial advantages, they do not fully address the pervasive issue of bias propagation from pre-training data. In this work, we introduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method designed to counteract bias inheritance. BA-LoRA incorporates three distinct regularization terms: (1) consistency regularizer, (2) diversity regularizer, and (3) singular vector decomposition regularizer. These regularizers collectively aim to improve the generative models' consistency, diversity, and generalization capabilities during the fine-tuning process. Through extensive experiments on a variety of natural language understanding (NLU) and natural language generation (NLG) tasks, employing prominent LLMs such as LLaMA, Mistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of LoRA and its state-of-the-art variants. Moreover, our method effectively mitigates the deleterious effects of pre-training bias, leading to more reliable and robust model outputs. The code is available at https://github.com/cyp-jlu-ai/BA-LoRA.","sentences":["Large language models (LLMs) have exhibited remarkable proficiency across a diverse array of natural language processing (NLP) tasks.","However, adapting LLMs to downstream applications typically necessitates computationally intensive and memory-demanding fine-tuning procedures.","To mitigate these burdens, parameter-efficient fine-tuning (PEFT) techniques have emerged as a promising approach to tailor LLMs with minimal computational overhead.","While PEFT methods offer substantial advantages, they do not fully address the pervasive issue of bias propagation from pre-training data.","In this work, we introduce Bias-Aware Low-Rank Adaptation (BA-LoRA), a novel PEFT method designed to counteract bias inheritance.","BA-LoRA incorporates three distinct regularization terms: (1) consistency regularizer, (2) diversity regularizer, and (3) singular vector decomposition regularizer.","These regularizers collectively aim to improve the generative models' consistency, diversity, and generalization capabilities during the fine-tuning process.","Through extensive experiments on a variety of natural language understanding (NLU) and natural language generation (NLG) tasks, employing prominent LLMs such as LLaMA, Mistral, and Gemma, we demonstrate that BA-LoRA surpasses the performance of LoRA and its state-of-the-art variants.","Moreover, our method effectively mitigates the deleterious effects of pre-training bias, leading to more reliable and robust model outputs.","The code is available at https://github.com/cyp-jlu-ai/BA-LoRA."],"url":"http://arxiv.org/abs/2408.04556v1"}
{"created":"2024-08-08 16:12:06","title":"Meta-mechanisms for Combinatorial Auctions over Social Networks","abstract":"Recently there has been a large amount of research designing mechanisms for auction scenarios where the bidders are connected in a social network. Different from the existing studies in this field that focus on specific auction scenarios e.g. single-unit auction and multi-unit auction, this paper considers the following question: is it possible to design a scheme that, given a classical auction scenario and a mechanism $\\tilde{\\mathcal{M}}$ suited for it, produces a mechanism in the network setting that preserves the key properties of $\\tilde{\\mathcal{M}}$? To answer this question, we design meta-mechanisms that provide a uniform way of transforming mechanisms from classical models to mechanisms over networks and prove that the desirable properties are preserved by our meta-mechanisms. Our meta-mechanisms provide solutions to combinatorial auction scenarios in the network setting: (1) combinatorial auction with single-minded buyers and (2) combinatorial auction with general monotone valuation. To the best of our knowledge, this is the first work that designs combinatorial auctions over a social network.","sentences":["Recently there has been a large amount of research designing mechanisms for auction scenarios where the bidders are connected in a social network.","Different from the existing studies in this field that focus on specific auction scenarios e.g. single-unit auction and multi-unit auction, this paper considers the following question: is it possible to design a scheme that, given a classical auction scenario and a mechanism $\\tilde{\\mathcal{M}}$ suited for it, produces a mechanism in the network setting that preserves the key properties of $\\tilde{\\mathcal{M}}$?","To answer this question, we design meta-mechanisms that provide a uniform way of transforming mechanisms from classical models to mechanisms over networks and prove that the desirable properties are preserved by our meta-mechanisms.","Our meta-mechanisms provide solutions to combinatorial auction scenarios in the network setting: (1) combinatorial auction with single-minded buyers and (2) combinatorial auction with general monotone valuation.","To the best of our knowledge, this is the first work that designs combinatorial auctions over a social network."],"url":"http://arxiv.org/abs/2408.04555v1"}
{"created":"2024-08-08 16:09:40","title":"Moly\u00e9: A Corpus-based Approach to Language Contact in Colonial France","abstract":"Whether or not several Creole languages which developed during the early modern period can be considered genetic descendants of European languages has been the subject of intense debate. This is in large part due to the absence of evidence of intermediate forms. This work introduces a new open corpus, the Moly\\'e corpus, which combines stereotypical representations of three kinds of language variation in Europe with early attestations of French-based Creole languages across a period of 400 years. It is intended to facilitate future research on the continuity between contact situations in Europe and Creolophone (former) colonies.","sentences":["Whether or not several Creole languages which developed during the early modern period can be considered genetic descendants of European languages has been the subject of intense debate.","This is in large part due to the absence of evidence of intermediate forms.","This work introduces a new open corpus, the Moly\\'e corpus, which combines stereotypical representations of three kinds of language variation in Europe with early attestations of French-based Creole languages across a period of 400 years.","It is intended to facilitate future research on the continuity between contact situations in Europe and Creolophone (former) colonies."],"url":"http://arxiv.org/abs/2408.04554v1"}
{"created":"2024-08-08 15:57:15","title":"Learning Fair Cooperation in Mixed-Motive Games with Indirect Reciprocity","abstract":"Altruistic cooperation is costly yet socially desirable. As a result, agents struggle to learn cooperative policies through independent reinforcement learning (RL). Indirect reciprocity, where agents consider their interaction partner's reputation, has been shown to stabilise cooperation in homogeneous, idealised populations. However, more realistic settings are comprised of heterogeneous agents with different characteristics and group-based social identities. We study cooperation when agents are stratified into two such groups, and allow reputation updates and actions to depend on group information. We consider two modelling approaches: evolutionary game theory, where we comprehensively search for social norms (i.e., rules to assign reputations) leading to cooperation and fairness; and RL, where we consider how the stochastic dynamics of policy learning affects the analytically identified equilibria. We observe that a defecting majority leads the minority group to defect, but not the inverse. Moreover, changing the norms that judge in and out-group interactions can steer a system towards either fair or unfair cooperation. This is made clearer when moving beyond equilibrium analysis to independent RL agents, where convergence to fair cooperation occurs with a narrower set of norms. Our results highlight that, in heterogeneous populations with reputations, carefully defining interaction norms is fundamental to tackle both dilemmas of cooperation and of fairness.","sentences":["Altruistic cooperation is costly yet socially desirable.","As a result, agents struggle to learn cooperative policies through independent reinforcement learning (RL).","Indirect reciprocity, where agents consider their interaction partner's reputation, has been shown to stabilise cooperation in homogeneous, idealised populations.","However, more realistic settings are comprised of heterogeneous agents with different characteristics and group-based social identities.","We study cooperation when agents are stratified into two such groups, and allow reputation updates and actions to depend on group information.","We consider two modelling approaches: evolutionary game theory, where we comprehensively search for social norms (i.e., rules to assign reputations) leading to cooperation and fairness; and RL, where we consider how the stochastic dynamics of policy learning affects the analytically identified equilibria.","We observe that a defecting majority leads the minority group to defect, but not the inverse.","Moreover, changing the norms that judge in and out-group interactions can steer a system towards either fair or unfair cooperation.","This is made clearer when moving beyond equilibrium analysis to independent RL agents, where convergence to fair cooperation occurs with a narrower set of norms.","Our results highlight that, in heterogeneous populations with reputations, carefully defining interaction norms is fundamental to tackle both dilemmas of cooperation and of fairness."],"url":"http://arxiv.org/abs/2408.04549v1"}
{"created":"2024-08-08 15:55:35","title":"Emotional Cues Extraction and Fusion for Multi-modal Emotion Prediction and Recognition in Conversation","abstract":"Emotion Prediction in Conversation (EPC) aims to forecast the emotions of forthcoming utterances by utilizing preceding dialogues. Previous EPC approaches relied on simple context modeling for emotion extraction, overlooking fine-grained emotion cues at the word level. Additionally, prior works failed to account for the intrinsic differences between modalities, resulting in redundant information. To overcome these limitations, we propose an emotional cues extraction and fusion network, which consists of two stages: a modality-specific learning stage that utilizes word-level labels and prosody learning to construct emotion embedding spaces for each modality, and a two-step fusion stage for integrating multi-modal features. Moreover, the emotion features extracted by our model are also applicable to the Emotion Recognition in Conversation (ERC) task. Experimental results validate the efficacy of the proposed method, demonstrating superior performance on both IEMOCAP and MELD datasets.","sentences":["Emotion Prediction in Conversation (EPC) aims to forecast the emotions of forthcoming utterances by utilizing preceding dialogues.","Previous EPC approaches relied on simple context modeling for emotion extraction, overlooking fine-grained emotion cues at the word level.","Additionally, prior works failed to account for the intrinsic differences between modalities, resulting in redundant information.","To overcome these limitations, we propose an emotional cues extraction and fusion network, which consists of two stages: a modality-specific learning stage that utilizes word-level labels and prosody learning to construct emotion embedding spaces for each modality, and a two-step fusion stage for integrating multi-modal features.","Moreover, the emotion features extracted by our model are also applicable to the Emotion Recognition in Conversation (ERC) task.","Experimental results validate the efficacy of the proposed method, demonstrating superior performance on both IEMOCAP and MELD datasets."],"url":"http://arxiv.org/abs/2408.04547v1"}
{"created":"2024-08-08 15:52:55","title":"Balancing Efficiency with Equality: Auction Design with Group Fairness Concerns","abstract":"The issue of fairness in AI arises from discriminatory practices in applications like job recommendations and risk assessments, emphasising the need for algorithms that do not discriminate based on group characteristics. This concern is also pertinent to auctions, commonly used for resource allocation, which necessitate fairness considerations. Our study examines auctions with groups distinguished by specific attributes, seeking to (1) define a fairness notion that ensures equitable treatment for all, (2) identify mechanisms that adhere to this fairness while preserving incentive compatibility, and (3) explore the balance between fairness and seller's revenue. We introduce two fairness notions-group fairness and individual fairness-and propose two corresponding auction mechanisms: the Group Probability Mechanism, which meets group fairness and incentive criteria, and the Group Score Mechanism, which also encompasses individual fairness. Through experiments, we validate these mechanisms' effectiveness in promoting fairness and examine their implications for seller revenue.","sentences":["The issue of fairness in AI arises from discriminatory practices in applications like job recommendations and risk assessments, emphasising the need for algorithms that do not discriminate based on group characteristics.","This concern is also pertinent to auctions, commonly used for resource allocation, which necessitate fairness considerations.","Our study examines auctions with groups distinguished by specific attributes, seeking to (1) define a fairness notion that ensures equitable treatment for all, (2) identify mechanisms that adhere to this fairness while preserving incentive compatibility, and (3) explore the balance between fairness and seller's revenue.","We introduce two fairness notions-group fairness and individual fairness-and propose two corresponding auction mechanisms: the Group Probability Mechanism, which meets group fairness and incentive criteria, and the Group Score Mechanism, which also encompasses individual fairness.","Through experiments, we validate these mechanisms' effectiveness in promoting fairness and examine their implications for seller revenue."],"url":"http://arxiv.org/abs/2408.04545v1"}
{"created":"2024-08-08 15:49:01","title":"MemeMind at ArAIEval Shared Task: Spotting Persuasive Spans in Arabic Text with Persuasion Techniques Identification","abstract":"This paper focuses on detecting propagandistic spans and persuasion techniques in Arabic text from tweets and news paragraphs. Each entry in the dataset contains a text sample and corresponding labels that indicate the start and end positions of propaganda techniques within the text. Tokens falling within a labeled span were assigned \"B\" (Begin) or \"I\" (Inside), \"O\", corresponding to the specific propaganda technique. Using attention masks, we created uniform lengths for each span and assigned BIO tags to each token based on the provided labels. Then, we used AraBERT-base pre-trained model for Arabic text tokenization and embeddings with a token classification layer to identify propaganda techniques. Our training process involves a two-phase fine-tuning approach. First, we train only the classification layer for a few epochs, followed by full model fine-tuning, updating all parameters. This methodology allows the model to adapt to the specific characteristics of the propaganda detection task while leveraging the knowledge captured by the pre-trained AraBERT model. Our approach achieved an F1 score of 0.2774, securing the 3rd position in the leaderboard of Task 1.","sentences":["This paper focuses on detecting propagandistic spans and persuasion techniques in Arabic text from tweets and news paragraphs.","Each entry in the dataset contains a text sample and corresponding labels that indicate the start and end positions of propaganda techniques within the text.","Tokens falling within a labeled span were assigned \"B\" (Begin) or \"I\" (Inside), \"O\", corresponding to the specific propaganda technique.","Using attention masks, we created uniform lengths for each span and assigned BIO tags to each token based on the provided labels.","Then, we used AraBERT-base pre-trained model for Arabic text tokenization and embeddings with a token classification layer to identify propaganda techniques.","Our training process involves a two-phase fine-tuning approach.","First, we train only the classification layer for a few epochs, followed by full model fine-tuning, updating all parameters.","This methodology allows the model to adapt to the specific characteristics of the propaganda detection task while leveraging the knowledge captured by the pre-trained AraBERT model.","Our approach achieved an F1 score of 0.2774, securing the 3rd position in the leaderboard of Task 1."],"url":"http://arxiv.org/abs/2408.04540v1"}
{"created":"2024-08-08 15:46:11","title":"ParetoTracker: Understanding Population Dynamics in Multi-objective Evolutionary Algorithms through Visual Analytics","abstract":"Multi-objective evolutionary algorithms (MOEAs) have emerged as powerful tools for solving complex optimization problems characterized by multiple, often conflicting, objectives. While advancements have been made in computational efficiency as well as diversity and convergence of solutions, a critical challenge persists: the internal evolutionary mechanisms are opaque to human users. Drawing upon the successes of explainable AI in explaining complex algorithms and models, we argue that the need to understand the underlying evolutionary operators and population dynamics within MOEAs aligns well with a visual analytics paradigm. This paper introduces ParetoTracker, a visual analytics framework designed to support the comprehension and inspection of population dynamics in the evolutionary processes of MOEAs. Informed by preliminary literature review and expert interviews, the framework establishes a multi-level analysis scheme, which caters to user engagement and exploration ranging from examining overall trends in performance metrics to conducting fine-grained inspections of evolutionary operations. In contrast to conventional practices that require manual plotting of solutions for each generation, ParetoTracker facilitates the examination of temporal trends and dynamics across consecutive generations in an integrated visual interface. The effectiveness of the framework is demonstrated through case studies and expert interviews focused on widely adopted benchmark optimization problems.","sentences":["Multi-objective evolutionary algorithms (MOEAs) have emerged as powerful tools for solving complex optimization problems characterized by multiple, often conflicting, objectives.","While advancements have been made in computational efficiency as well as diversity and convergence of solutions, a critical challenge persists: the internal evolutionary mechanisms are opaque to human users.","Drawing upon the successes of explainable AI in explaining complex algorithms and models, we argue that the need to understand the underlying evolutionary operators and population dynamics within MOEAs aligns well with a visual analytics paradigm.","This paper introduces ParetoTracker, a visual analytics framework designed to support the comprehension and inspection of population dynamics in the evolutionary processes of MOEAs.","Informed by preliminary literature review and expert interviews, the framework establishes a multi-level analysis scheme, which caters to user engagement and exploration ranging from examining overall trends in performance metrics to conducting fine-grained inspections of evolutionary operations.","In contrast to conventional practices that require manual plotting of solutions for each generation, ParetoTracker facilitates the examination of temporal trends and dynamics across consecutive generations in an integrated visual interface.","The effectiveness of the framework is demonstrated through case studies and expert interviews focused on widely adopted benchmark optimization problems."],"url":"http://arxiv.org/abs/2408.04539v1"}
{"created":"2024-08-08 15:44:37","title":"Movelet Trees","abstract":"We combine Nishimoto and Tabei's move structure with a wavelet tree to show how, if $T [1..n]$ is over a constant-sized alphabet and its Burrows-Wheeler Transform (BWT) consists of $r$ runs, then we can store $T$ in $O \\left( r \\log \\frac{n}{r} \\right)$ bits such that when given a pattern $P [1..m]$, we can find the BWT interval for $P$ in $O (m)$ time.","sentences":["We combine Nishimoto and Tabei's move structure with a wavelet tree to show how, if $T [1..n]$ is over a constant-sized alphabet and its Burrows-Wheeler Transform (BWT) consists of $r$ runs, then we can store $T$ in $O \\left( r \\log \\frac{n}{r} \\right)$ bits such that when given a pattern $P [1..m]$, we can find the BWT interval for $P$ in $O (m)$ time."],"url":"http://arxiv.org/abs/2408.04537v1"}
{"created":"2024-08-08 15:33:02","title":"How Transformers Utilize Multi-Head Attention in In-Context Learning? A Case Study on Sparse Linear Regression","abstract":"Despite the remarkable success of transformer-based models in various real-world tasks, their underlying mechanisms remain poorly understood. Recent studies have suggested that transformers can implement gradient descent as an in-context learner for linear regression problems and have developed various theoretical analyses accordingly. However, these works mostly focus on the expressive power of transformers by designing specific parameter constructions, lacking a comprehensive understanding of their inherent working mechanisms post-training. In this study, we consider a sparse linear regression problem and investigate how a trained multi-head transformer performs in-context learning. We experimentally discover that the utilization of multi-heads exhibits different patterns across layers: multiple heads are utilized and essential in the first layer, while usually only a single head is sufficient for subsequent layers. We provide a theoretical explanation for this observation: the first layer preprocesses the context data, and the following layers execute simple optimization steps based on the preprocessed context. Moreover, we demonstrate that such a preprocess-then-optimize algorithm can significantly outperform naive gradient descent and ridge regression algorithms. Further experimental results support our explanations. Our findings offer insights into the benefits of multi-head attention and contribute to understanding the more intricate mechanisms hidden within trained transformers.","sentences":["Despite the remarkable success of transformer-based models in various real-world tasks, their underlying mechanisms remain poorly understood.","Recent studies have suggested that transformers can implement gradient descent as an in-context learner for linear regression problems and have developed various theoretical analyses accordingly.","However, these works mostly focus on the expressive power of transformers by designing specific parameter constructions, lacking a comprehensive understanding of their inherent working mechanisms post-training.","In this study, we consider a sparse linear regression problem and investigate how a trained multi-head transformer performs in-context learning.","We experimentally discover that the utilization of multi-heads exhibits different patterns across layers: multiple heads are utilized and essential in the first layer, while usually only a single head is sufficient for subsequent layers.","We provide a theoretical explanation for this observation: the first layer preprocesses the context data, and the following layers execute simple optimization steps based on the preprocessed context.","Moreover, we demonstrate that such a preprocess-then-optimize algorithm can significantly outperform naive gradient descent and ridge regression algorithms.","Further experimental results support our explanations.","Our findings offer insights into the benefits of multi-head attention and contribute to understanding the more intricate mechanisms hidden within trained transformers."],"url":"http://arxiv.org/abs/2408.04532v1"}
{"created":"2024-08-08 15:32:12","title":"AExGym: Benchmarks and Environments for Adaptive Experimentation","abstract":"Innovations across science and industry are evaluated using randomized trials (a.k.a. A/B tests). While simple and robust, such static designs are inefficient or infeasible for testing many hypotheses. Adaptive designs can greatly improve statistical power in theory, but they have seen limited adoption due to their fragility in practice. We present a benchmark for adaptive experimentation based on real-world datasets, highlighting prominent practical challenges to operationalizing adaptivity: non-stationarity, batched/delayed feedback, multiple outcomes and objectives, and external validity. Our benchmark aims to spur methodological development that puts practical performance (e.g., robustness) as a central concern, rather than mathematical guarantees on contrived instances. We release an open source library, AExGym, which is designed with modularity and extensibility in mind to allow experimentation practitioners to develop custom environments and algorithms.","sentences":["Innovations across science and industry are evaluated using randomized trials (a.k.a. A/B tests).","While simple and robust, such static designs are inefficient or infeasible for testing many hypotheses.","Adaptive designs can greatly improve statistical power in theory, but they have seen limited adoption due to their fragility in practice.","We present a benchmark for adaptive experimentation based on real-world datasets, highlighting prominent practical challenges to operationalizing adaptivity: non-stationarity, batched/delayed feedback, multiple outcomes and objectives, and external validity.","Our benchmark aims to spur methodological development that puts practical performance (e.g., robustness) as a central concern, rather than mathematical guarantees on contrived instances.","We release an open source library, AExGym, which is designed with modularity and extensibility in mind to allow experimentation practitioners to develop custom environments and algorithms."],"url":"http://arxiv.org/abs/2408.04531v1"}
{"created":"2024-08-08 15:27:22","title":"Reasoning about Study Regulations in Answer Set Programming","abstract":"We are interested in automating reasoning with and about study regulations, catering to various stakeholders, ranging from administrators, over faculty, to students at different stages. Our work builds on an extensive analysis of various study programs at the University of Potsdam. The conceptualization of the underlying principles provides us with a formal account of study regulations. In particular, the formalization reveals the properties of admissible study plans. With these at end, we propose an encoding of study regulations in Answer Set Programming that produces corresponding study plans. Finally, we show how this approach can be extended to a generic user interface for exploring study plans.","sentences":["We are interested in automating reasoning with and about study regulations, catering to various stakeholders, ranging from administrators, over faculty, to students at different stages.","Our work builds on an extensive analysis of various study programs at the University of Potsdam.","The conceptualization of the underlying principles provides us with a formal account of study regulations.","In particular, the formalization reveals the properties of admissible study plans.","With these at end, we propose an encoding of study regulations in Answer Set Programming that produces corresponding study plans.","Finally, we show how this approach can be extended to a generic user interface for exploring study plans."],"url":"http://arxiv.org/abs/2408.04528v1"}
{"created":"2024-08-08 15:24:19","title":"Field Testing and Detection of Camera Interference for Autonomous Driving","abstract":"In recent advancements in connected and autonomous vehicles (CAVs), automotive ethernet has emerged as a critical technology for in-vehicle networks (IVNs), superseding traditional protocols like the CAN due to its superior bandwidth and data transmission capabilities. This study explores the detection of camera interference attacks (CIA) within an automotive ethernet-driven environment using a novel GRU-based IDS. Leveraging a sliding-window data preprocessing technique, our IDS effectively analyzes packet length sequences to differentiate between normal and anomalous data transmissions. Experimental evaluations conducted on a commercial car equipped with H.264 encoding and fragmentation unit-A (FU-A) demonstrated high detection accuracy, achieving an AUC of 0.9982 and a true positive rate of 0.99 with a window size of 255.","sentences":["In recent advancements in connected and autonomous vehicles (CAVs), automotive ethernet has emerged as a critical technology for in-vehicle networks (IVNs), superseding traditional protocols like the CAN due to its superior bandwidth and data transmission capabilities.","This study explores the detection of camera interference attacks (CIA) within an automotive ethernet-driven environment using a novel GRU-based IDS.","Leveraging a sliding-window data preprocessing technique, our IDS effectively analyzes packet length sequences to differentiate between normal and anomalous data transmissions.","Experimental evaluations conducted on a commercial car equipped with H.264 encoding and fragmentation unit-A (FU-A) demonstrated high detection accuracy, achieving an AUC of 0.9982 and a true positive rate of 0.99 with a window size of 255."],"url":"http://arxiv.org/abs/2408.04524v1"}
{"created":"2024-08-08 15:24:07","title":"Depth Any Canopy: Leveraging Depth Foundation Models for Canopy Height Estimation","abstract":"Estimating global tree canopy height is crucial for forest conservation and climate change applications. However, capturing high-resolution ground truth canopy height using LiDAR is expensive and not available globally. An efficient alternative is to train a canopy height estimator to operate on single-view remotely sensed imagery. The primary obstacle to this approach is that these methods require significant training data to generalize well globally and across uncommon edge cases. Recent monocular depth estimation foundation models have show strong zero-shot performance even for complex scenes. In this paper we leverage the representations learned by these models to transfer to the remote sensing domain for measuring canopy height. Our findings suggest that our proposed Depth Any Canopy, the result of fine-tuning the Depth Anything v2 model for canopy height estimation, provides a performant and efficient solution, surpassing the current state-of-the-art with superior or comparable performance using only a fraction of the computational resources and parameters. Furthermore, our approach requires less than \\$1.30 in compute and results in an estimated carbon footprint of 0.14 kgCO2. Code, experimental results, and model checkpoints are openly available at https://github.com/DarthReca/depth-any-canopy.","sentences":["Estimating global tree canopy height is crucial for forest conservation and climate change applications.","However, capturing high-resolution ground truth canopy height using LiDAR is expensive and not available globally.","An efficient alternative is to train a canopy height estimator to operate on single-view remotely sensed imagery.","The primary obstacle to this approach is that these methods require significant training data to generalize well globally and across uncommon edge cases.","Recent monocular depth estimation foundation models have show strong zero-shot performance even for complex scenes.","In this paper we leverage the representations learned by these models to transfer to the remote sensing domain for measuring canopy height.","Our findings suggest that our proposed Depth Any Canopy, the result of fine-tuning the Depth Anything v2 model for canopy height estimation, provides a performant and efficient solution, surpassing the current state-of-the-art with superior or comparable performance using only a fraction of the computational resources and parameters.","Furthermore, our approach requires less than \\$1.30 in compute and results in an estimated carbon footprint of 0.14 kgCO2.","Code, experimental results, and model checkpoints are openly available at https://github.com/DarthReca/depth-any-canopy."],"url":"http://arxiv.org/abs/2408.04523v1"}
{"created":"2024-08-08 15:24:03","title":"Compromesso! Italian Many-Shot Jailbreaks Undermine the Safety of Large Language Models","abstract":"As diverse linguistic communities and users adopt large language models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to make LLMs safe, they can still be made to behave unsafely with jailbreaking, a technique in which models are prompted to act outside their operational guidelines. Research on LLM safety and jailbreaking, however, has so far mostly focused on English, limiting our understanding of LLM safety in other languages. We contribute towards closing this gap by investigating the effectiveness of many-shot jailbreaking, where models are prompted with unsafe demonstrations to induce unsafe behaviour, in Italian. To enable our analysis, we create a new dataset of unsafe Italian question-answer pairs. With this dataset, we identify clear safety vulnerabilities in four families of open-weight LLMs. We find that the models exhibit unsafe behaviors even when prompted with few unsafe demonstrations, and -- more alarmingly -- that this tendency rapidly escalates with more demonstrations.","sentences":["As diverse linguistic communities and users adopt large language models (LLMs), assessing their safety across languages becomes critical.","Despite ongoing efforts to make LLMs safe, they can still be made to behave unsafely with jailbreaking, a technique in which models are prompted to act outside their operational guidelines.","Research on LLM safety and jailbreaking, however, has so far mostly focused on English, limiting our understanding of LLM safety in other languages.","We contribute towards closing this gap by investigating the effectiveness of many-shot jailbreaking, where models are prompted with unsafe demonstrations to induce unsafe behaviour, in Italian.","To enable our analysis, we create a new dataset of unsafe Italian question-answer pairs.","With this dataset, we identify clear safety vulnerabilities in four families of open-weight LLMs.","We find that the models exhibit unsafe behaviors even when prompted with few unsafe demonstrations, and -- more alarmingly -- that this tendency rapidly escalates with more demonstrations."],"url":"http://arxiv.org/abs/2408.04522v1"}
{"created":"2024-08-08 15:21:07","title":"Advancing Molecular Machine (Learned) Representations with Stereoelectronics-Infused Molecular Graphs","abstract":"Molecular representation is a foundational element in our understanding of the physical world. Its importance ranges from the fundamentals of chemical reactions to the design of new therapies and materials. Previous molecular machine learning models have employed strings, fingerprints, global features, and simple molecular graphs that are inherently information-sparse representations. However, as the complexity of prediction tasks increases, the molecular representation needs to encode higher fidelity information. This work introduces a novel approach to infusing quantum-chemical-rich information into molecular graphs via stereoelectronic effects. We show that the explicit addition of stereoelectronic interactions significantly improves the performance of molecular machine learning models. Furthermore, stereoelectronics-infused representations can be learned and deployed with a tailored double graph neural network workflow, enabling its application to any downstream molecular machine learning task. Finally, we show that the learned representations allow for facile stereoelectronic evaluation of previously intractable systems, such as entire proteins, opening new avenues of molecular design.","sentences":["Molecular representation is a foundational element in our understanding of the physical world.","Its importance ranges from the fundamentals of chemical reactions to the design of new therapies and materials.","Previous molecular machine learning models have employed strings, fingerprints, global features, and simple molecular graphs that are inherently information-sparse representations.","However, as the complexity of prediction tasks increases, the molecular representation needs to encode higher fidelity information.","This work introduces a novel approach to infusing quantum-chemical-rich information into molecular graphs via stereoelectronic effects.","We show that the explicit addition of stereoelectronic interactions significantly improves the performance of molecular machine learning models.","Furthermore, stereoelectronics-infused representations can be learned and deployed with a tailored double graph neural network workflow, enabling its application to any downstream molecular machine learning task.","Finally, we show that the learned representations allow for facile stereoelectronic evaluation of previously intractable systems, such as entire proteins, opening new avenues of molecular design."],"url":"http://arxiv.org/abs/2408.04520v1"}
{"created":"2024-08-08 15:16:37","title":"Approximating $\u03b4$-Covering","abstract":"$\\delta$-Covering, for some covering range $\\delta>0$, is a continuous facility location problem on undirected graphs where all edges have unit length. The facilities may be positioned on the vertices as well as on the interior of the edges. The goal is to position as few facilities as possible such that every point on every edge has distance at most $\\delta$ to one of these facilities. For large $\\delta$, the problem is similar to dominating set, which is hard to approximate, while for small $\\delta$, say close to $1$, the problem is similar to vertex cover. In fact, as shown by Hartmann et al. [Math. Program. 22], $\\delta$-Covering for all unit-fractions $\\delta$ is polynomial time solvable, while for all other values of $\\delta$ the problem is NP-hard.   We study the approximability of $\\delta$-Covering for every covering range $\\delta>0$. For $\\delta \\geq 3/2$, the problem is log-APX-hard, and allows an $\\mathcal O(\\log n)$ approximation. For every $\\delta < 3/2$, there is a constant factor approximation of a minimum $\\delta$-cover (and the problem is APX-hard when $\\delta$ is not a unit-fraction). We further study the dependency of the approximation ratio on the covering range $\\delta < 3/2$. By providing several polynomial time approximation algorithms and lower bounds under the Unique Games Conjecture, we narrow the possible approximation ratio, especially for $\\delta$ close to the polynomial time solvable cases.","sentences":["$\\delta$-Covering, for some covering range $\\delta>0$, is a continuous facility location problem on undirected graphs where all edges have unit length.","The facilities may be positioned on the vertices as well as on the interior of the edges.","The goal is to position as few facilities as possible such that every point on every edge has distance at most $\\delta$ to one of these facilities.","For large $\\delta$, the problem is similar to dominating set, which is hard to approximate, while for small $\\delta$, say close to $1$, the problem is similar to vertex cover.","In fact, as shown by Hartmann et al.","[Math. Program.","22], $\\delta$-Covering for all unit-fractions $\\delta$ is polynomial time solvable, while for all other values of $\\delta$ the problem is NP-hard.   ","We study the approximability of $\\delta$-Covering for every covering range $\\delta>0$. For $\\delta \\geq 3/2$, the problem is log-APX-hard, and allows an $\\mathcal O(\\log n)$ approximation.","For every $\\delta < 3/2$, there is a constant factor approximation of a minimum $\\delta$-cover (and the problem is APX-hard when $\\delta$ is not a unit-fraction).","We further study the dependency of the approximation ratio on the covering range $\\delta <","3/2$. By providing several polynomial time approximation algorithms and lower bounds under the Unique Games Conjecture, we narrow the possible approximation ratio, especially for $\\delta$ close to the polynomial time solvable cases."],"url":"http://arxiv.org/abs/2408.04517v1"}
{"created":"2024-08-08 15:15:48","title":"Saliency Detection in Educational Videos: Analyzing the Performance of Current Models, Identifying Limitations and Advancement Directions","abstract":"Identifying the regions of a learning resource that a learner pays attention to is crucial for assessing the material's impact and improving its design and related support systems. Saliency detection in videos addresses the automatic recognition of attention-drawing regions in single frames. In educational settings, the recognition of pertinent regions in a video's visual stream can enhance content accessibility and information retrieval tasks such as video segmentation, navigation, and summarization. Such advancements can pave the way for the development of advanced AI-assisted technologies that support learning with greater efficacy. However, this task becomes particularly challenging for educational videos due to the combination of unique characteristics such as text, voice, illustrations, animations, and more. To the best of our knowledge, there is currently no study that evaluates saliency detection approaches in educational videos. In this paper, we address this gap by evaluating four state-of-the-art saliency detection approaches for educational videos. We reproduce the original studies and explore the replication capabilities for general-purpose (non-educational) datasets. Then, we investigate the generalization capabilities of the models and evaluate their performance on educational videos. We conduct a comprehensive analysis to identify common failure scenarios and possible areas of improvement. Our experimental results show that educational videos remain a challenging context for generic video saliency detection models.","sentences":["Identifying the regions of a learning resource that a learner pays attention to is crucial for assessing the material's impact and improving its design and related support systems.","Saliency detection in videos addresses the automatic recognition of attention-drawing regions in single frames.","In educational settings, the recognition of pertinent regions in a video's visual stream can enhance content accessibility and information retrieval tasks such as video segmentation, navigation, and summarization.","Such advancements can pave the way for the development of advanced AI-assisted technologies that support learning with greater efficacy.","However, this task becomes particularly challenging for educational videos due to the combination of unique characteristics such as text, voice, illustrations, animations, and more.","To the best of our knowledge, there is currently no study that evaluates saliency detection approaches in educational videos.","In this paper, we address this gap by evaluating four state-of-the-art saliency detection approaches for educational videos.","We reproduce the original studies and explore the replication capabilities for general-purpose (non-educational) datasets.","Then, we investigate the generalization capabilities of the models and evaluate their performance on educational videos.","We conduct a comprehensive analysis to identify common failure scenarios and possible areas of improvement.","Our experimental results show that educational videos remain a challenging context for generic video saliency detection models."],"url":"http://arxiv.org/abs/2408.04515v1"}
{"created":"2024-08-08 15:15:28","title":"Emergence in Multi-Agent Systems: A Safety Perspective","abstract":"Emergent effects can arise in multi-agent systems (MAS) where execution is decentralized and reliant on local information. These effects may range from minor deviations in behavior to catastrophic system failures. To formally define these effects, we identify misalignments between the global inherent specification (the true specification) and its local approximation (such as the configuration of different reward components or observations). Using established safety terminology, we develop a framework to understand these emergent effects. To showcase the resulting implications, we use two broadly configurable exemplary gridworld scenarios, where insufficient specification leads to unintended behavior deviations when derived independently. Recognizing that a global adaptation might not always be feasible, we propose adjusting the underlying parameterizations to mitigate these issues, thereby improving the system's alignment and reducing the risk of emergent failures.","sentences":["Emergent effects can arise in multi-agent systems (MAS) where execution is decentralized and reliant on local information.","These effects may range from minor deviations in behavior to catastrophic system failures.","To formally define these effects, we identify misalignments between the global inherent specification (the true specification) and its local approximation (such as the configuration of different reward components or observations).","Using established safety terminology, we develop a framework to understand these emergent effects.","To showcase the resulting implications, we use two broadly configurable exemplary gridworld scenarios, where insufficient specification leads to unintended behavior deviations when derived independently.","Recognizing that a global adaptation might not always be feasible, we propose adjusting the underlying parameterizations to mitigate these issues, thereby improving the system's alignment and reducing the risk of emergent failures."],"url":"http://arxiv.org/abs/2408.04514v1"}
{"created":"2024-08-08 15:04:23","title":"Who ruins the game?: unveiling cheating players in the \"Battlefield\" game","abstract":"The \"Battlefield\" online game is well-known for its large-scale multiplayer capabilities and unique gaming features, including various vehicle controls. However, these features make the game a major target for cheating, significantly detracting from the gaming experience. This study analyzes user behavior in cheating play in the popular online game, the \"Battlefield\", using statistical methods. We aim to provide comprehensive insights into cheating players through an extensive analysis of over 44,000 reported cheating incidents collected via the \"Game-tools API\". Our methodology includes detailed statistical analyses such as calculating basic statistics of key variables, correlation analysis, and visualizations using histograms, box plots, and scatter plots. Our findings emphasize the importance of adaptive, data-driven approaches to prevent cheating plays in online games.","sentences":["The \"Battlefield\" online game is well-known for its large-scale multiplayer capabilities and unique gaming features, including various vehicle controls.","However, these features make the game a major target for cheating, significantly detracting from the gaming experience.","This study analyzes user behavior in cheating play in the popular online game, the \"Battlefield\", using statistical methods.","We aim to provide comprehensive insights into cheating players through an extensive analysis of over 44,000 reported cheating incidents collected via the \"Game-tools API\".","Our methodology includes detailed statistical analyses such as calculating basic statistics of key variables, correlation analysis, and visualizations using histograms, box plots, and scatter plots.","Our findings emphasize the importance of adaptive, data-driven approaches to prevent cheating plays in online games."],"url":"http://arxiv.org/abs/2408.04506v1"}
{"created":"2024-08-08 15:03:45","title":"Feedback Design with VQ-VAE for Robust Precoding in Multi-User FDD Systems","abstract":"In this letter, we propose a vector quantized-variational autoencoder (VQ-VAE)-based feedback scheme for robust precoder design in multi-user frequency division duplex (FDD) systems. We demonstrate how the VQ-VAE can be tailored to specific propagation environments, focusing on systems with low pilot overhead, which is crucial in massive multiple-input multiple-output (MIMO). Extensive simulations with real-world measurement data show that our proposed feedback scheme outperforms state-of-the-art autoencoder (AE)-based compression schemes and conventional Discrete Fourier transform (DFT) codebook-based schemes. These improvements enable the deployment of systems with fewer feedback bits or pilots.","sentences":["In this letter, we propose a vector quantized-variational autoencoder (VQ-VAE)-based feedback scheme for robust precoder design in multi-user frequency division duplex (FDD) systems.","We demonstrate how the VQ-VAE can be tailored to specific propagation environments, focusing on systems with low pilot overhead, which is crucial in massive multiple-input multiple-output (MIMO).","Extensive simulations with real-world measurement data show that our proposed feedback scheme outperforms state-of-the-art autoencoder (AE)-based compression schemes and conventional Discrete Fourier transform (DFT) codebook-based schemes.","These improvements enable the deployment of systems with fewer feedback bits or pilots."],"url":"http://arxiv.org/abs/2408.04505v1"}
{"created":"2024-08-08 14:55:13","title":"\"I Am Human, Just Like You\": What Intersectional, Neurodivergent Lived Experiences Bring to Accessibility Research","abstract":"The increasing prevalence of neurodivergence has led society to give greater recognition to the importance of neurodiversity. Yet societal perceptions of neurodivergence continue to be predominantly negative. Drawing on Critical Disability Studies, accessibility researchers have demonstrated how neuronormative assumptions dominate HCI. Despite their guidance, neurodivergent and disabled individuals are still marginalized in technology research. In particular, intersectional identities remain largely absent from HCI neurodivergence research. In this paper, I share my perspective as an outsider of the academic research community: I use critical autoethnography to analyze my experiences of coming to understand, accept, and value my neurodivergence within systems of power, privilege, and oppression. Using Data Feminism as an accessible and practical guide to intersectionality, I derive three tenets for reconceptualizing neurodivergence to be more inclusive of intersectional experiences: (1) neurodivergence is a functional difference, not a deficit; (2) neurodivergent disability is a moment of friction, not a static label; and (3) neurodivergence accessibility is a collaborative practice, not a one-sided solution. Then, I discuss the tenets in the context of existing HCI research, applying the same intersectional lens. Finally, I offer three suggestions for how accessibility research can apply these tenets in future work, to bridge the gap between accessibility theory and practice in HCI neurodivergence research","sentences":["The increasing prevalence of neurodivergence has led society to give greater recognition to the importance of neurodiversity.","Yet societal perceptions of neurodivergence continue to be predominantly negative.","Drawing on Critical Disability Studies, accessibility researchers have demonstrated how neuronormative assumptions dominate HCI.","Despite their guidance, neurodivergent and disabled individuals are still marginalized in technology research.","In particular, intersectional identities remain largely absent from HCI neurodivergence research.","In this paper, I share my perspective as an outsider of the academic research community: I use critical autoethnography to analyze my experiences of coming to understand, accept, and value my neurodivergence within systems of power, privilege, and oppression.","Using Data Feminism as an accessible and practical guide to intersectionality, I derive three tenets for reconceptualizing neurodivergence to be more inclusive of intersectional experiences: (1) neurodivergence is a functional difference, not a deficit; (2) neurodivergent disability is a moment of friction, not a static label; and (3) neurodivergence accessibility is a collaborative practice, not a one-sided solution.","Then, I discuss the tenets in the context of existing HCI research, applying the same intersectional lens.","Finally, I offer three suggestions for how accessibility research can apply these tenets in future work, to bridge the gap between accessibility theory and practice in HCI neurodivergence research"],"url":"http://arxiv.org/abs/2408.04500v1"}
{"created":"2024-08-08 14:50:48","title":"Knowledge-Aided Semantic Communication Leveraging Probabilistic Graphical Modeling","abstract":"In this paper, we propose a semantic communication approach based on probabilistic graphical model (PGM). The proposed approach involves constructing a PGM from a training dataset, which is then shared as common knowledge between the transmitter and receiver. We evaluate the importance of various semantic features and present a PGM-based compression algorithm designed to eliminate predictable portions of semantic information. Furthermore, we introduce a technique to reconstruct the discarded semantic information at the receiver end, generating approximate results based on the PGM. Simulation results indicate a significant improvement in transmission efficiency over existing methods, while maintaining the quality of the transmitted images.","sentences":["In this paper, we propose a semantic communication approach based on probabilistic graphical model (PGM).","The proposed approach involves constructing a PGM from a training dataset, which is then shared as common knowledge between the transmitter and receiver.","We evaluate the importance of various semantic features and present a PGM-based compression algorithm designed to eliminate predictable portions of semantic information.","Furthermore, we introduce a technique to reconstruct the discarded semantic information at the receiver end, generating approximate results based on the PGM.","Simulation results indicate a significant improvement in transmission efficiency over existing methods, while maintaining the quality of the transmitted images."],"url":"http://arxiv.org/abs/2408.04499v1"}
{"created":"2024-08-08 14:46:01","title":"Model-Based Transfer Learning for Contextual Reinforcement Learning","abstract":"Deep reinforcement learning is a powerful approach to complex decision making. However, one issue that limits its practical application is its brittleness, sometimes failing to train in the presence of small changes in the environment. This work is motivated by the empirical observation that directly applying an already trained model to a related task often works remarkably well, also called zero-shot transfer. We take this practical trick one step further to consider how to systematically select good tasks to train, maximizing overall performance across a range of tasks. Given the high cost of training, it is critical to choose a small set of training tasks. The key idea behind our approach is to explicitly model the performance loss (generalization gap) incurred by transferring a trained model. We hence introduce Model-Based Transfer Learning (MBTL) for solving contextual RL problems. In this work, we model the performance loss as a simple linear function of task context similarity. Furthermore, we leverage Bayesian optimization techniques to efficiently model and estimate the unknown training performance of the task space. We theoretically show that the method exhibits regret that is sublinear in the number of training tasks and discuss conditions to further tighten regret bounds. We experimentally validate our methods using urban traffic and standard control benchmarks. Despite the conceptual simplicity, the experimental results suggest that MBTL can achieve greater performance than strong baselines, including exhaustive training on all tasks, multi-task training, and random selection of training tasks. This work lays the foundations for investigating explicit modeling of generalization, thereby enabling principled yet effective methods for contextual RL.","sentences":["Deep reinforcement learning is a powerful approach to complex decision making.","However, one issue that limits its practical application is its brittleness, sometimes failing to train in the presence of small changes in the environment.","This work is motivated by the empirical observation that directly applying an already trained model to a related task often works remarkably well, also called zero-shot transfer.","We take this practical trick one step further to consider how to systematically select good tasks to train, maximizing overall performance across a range of tasks.","Given the high cost of training, it is critical to choose a small set of training tasks.","The key idea behind our approach is to explicitly model the performance loss (generalization gap) incurred by transferring a trained model.","We hence introduce Model-Based Transfer Learning (MBTL) for solving contextual RL problems.","In this work, we model the performance loss as a simple linear function of task context similarity.","Furthermore, we leverage Bayesian optimization techniques to efficiently model and estimate the unknown training performance of the task space.","We theoretically show that the method exhibits regret that is sublinear in the number of training tasks and discuss conditions to further tighten regret bounds.","We experimentally validate our methods using urban traffic and standard control benchmarks.","Despite the conceptual simplicity, the experimental results suggest that MBTL can achieve greater performance than strong baselines, including exhaustive training on all tasks, multi-task training, and random selection of training tasks.","This work lays the foundations for investigating explicit modeling of generalization, thereby enabling principled yet effective methods for contextual RL."],"url":"http://arxiv.org/abs/2408.04498v1"}
{"created":"2024-08-08 14:41:32","title":"Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs","abstract":"Liver cirrhosis, a leading cause of global mortality, requires precise segmentation of ROIs for effective disease monitoring and treatment planning. Existing segmentation models often fail to capture complex feature interactions and generalize across diverse datasets. To address these limitations, we propose a novel synergistic theory that leverages complementary latent spaces for enhanced feature interaction modeling. Our proposed architecture, nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes and features auto-configured training. This approach captures both fine-grained and coarse features, enabling effective modeling of intricate feature interactions. We empirically validated nnSynergyNet3D on a private dataset of 628 high-resolution T1 abdominal MRI scans from 339 patients. Our model outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot testing on healthy liver CT scans from the public LiTS dataset demonstrated superior cross-modal generalization capabilities. These results highlight the potential of synergistic latent space models to improve segmentation accuracy and robustness, thereby enhancing clinical workflows by ensuring consistency across CT and MRI modalities.","sentences":["Liver cirrhosis, a leading cause of global mortality, requires precise segmentation of ROIs for effective disease monitoring and treatment planning.","Existing segmentation models often fail to capture complex feature interactions and generalize across diverse datasets.","To address these limitations, we propose a novel synergistic theory that leverages complementary latent spaces for enhanced feature interaction modeling.","Our proposed architecture, nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes and features auto-configured training.","This approach captures both fine-grained and coarse features, enabling effective modeling of intricate feature interactions.","We empirically validated nnSynergyNet3D on a private dataset of 628 high-resolution T1 abdominal MRI scans from 339 patients.","Our model outperformed the baseline nnUNet3D by approximately 2%.","Additionally, zero-shot testing on healthy liver CT scans from the public LiTS dataset demonstrated superior cross-modal generalization capabilities.","These results highlight the potential of synergistic latent space models to improve segmentation accuracy and robustness, thereby enhancing clinical workflows by ensuring consistency across CT and MRI modalities."],"url":"http://arxiv.org/abs/2408.04491v1"}
{"created":"2024-08-08 14:39:51","title":"Symmetric Encryption Scheme Based on Quasigroup Using Chained Mode of Operation","abstract":"In this paper, we propose a novel construction for a symmetric encryption scheme, referred as SEBQ which is based on the structure of quasigroup. We utilize concepts of chaining like mode of operation and present a block cipher with in-built properties. We prove that SEBQ shows resistance against chosen plaintext attack (CPA) and by applying unbalanced Feistel transformation [19], it achieves security against chosen ciphertext attacks (CCA). Subsequently, we conduct an assessment of the randomness of the proposed scheme by running the NIST test suite and we analyze the impact of the initial vector, secret key and plaintext on ciphertext through an avalanche effect analysis. We also compare the results with existing schemes based on quasigroups [11,46]. Moreover, we analyze the computational complexity in terms of number of operations needed for encryption and decryption process.","sentences":["In this paper, we propose a novel construction for a symmetric encryption scheme, referred as SEBQ which is based on the structure of quasigroup.","We utilize concepts of chaining like mode of operation and present a block cipher with in-built properties.","We prove that SEBQ shows resistance against chosen plaintext attack (CPA) and by applying unbalanced Feistel transformation [19], it achieves security against chosen ciphertext attacks (CCA).","Subsequently, we conduct an assessment of the randomness of the proposed scheme by running the NIST test suite and we analyze the impact of the initial vector, secret key and plaintext on ciphertext through an avalanche effect analysis.","We also compare the results with existing schemes based on quasigroups [11,46].","Moreover, we analyze the computational complexity in terms of number of operations needed for encryption and decryption process."],"url":"http://arxiv.org/abs/2408.04490v1"}
{"created":"2024-08-08 14:25:30","title":"The Complexity of Learning Temporal Properties","abstract":"We consider the problem of learning temporal logic formulas from examples of system behavior. Learning temporal properties has crystallized as an effective mean to explain complex temporal behaviors. Several efficient algorithms have been designed for learning temporal formulas. However, the theoretical understanding of the complexity of the learning decision problems remains largely unexplored. To address this, we study the complexity of the passive learning problems of three prominent temporal logics, Linear Temporal Logic (LTL), Computation Tree Logic (CTL) and Alternating-time Temporal Logic (ATL) and several of their fragments. We show that learning formulas using an unbounded amount of occurrences of binary operators is NP-complete for all of these logics. On the other hand, when investigating the complexity of learning formulas with bounded amount of occurrences of binary operators, we exhibit discrepancies between the complexity of learning LTL, CTL and ATL formulas (with a varying number of agents).","sentences":["We consider the problem of learning temporal logic formulas from examples of system behavior.","Learning temporal properties has crystallized as an effective mean to explain complex temporal behaviors.","Several efficient algorithms have been designed for learning temporal formulas.","However, the theoretical understanding of the complexity of the learning decision problems remains largely unexplored.","To address this, we study the complexity of the passive learning problems of three prominent temporal logics, Linear Temporal Logic (LTL), Computation Tree Logic (CTL) and Alternating-time Temporal Logic (ATL) and several of their fragments.","We show that learning formulas using an unbounded amount of occurrences of binary operators is NP-complete for all of these logics.","On the other hand, when investigating the complexity of learning formulas with bounded amount of occurrences of binary operators, we exhibit discrepancies between the complexity of learning LTL, CTL and ATL formulas (with a varying number of agents)."],"url":"http://arxiv.org/abs/2408.04486v1"}
{"created":"2024-08-08 14:23:23","title":"A Learning-Based Model Predictive Contouring Control for Vehicle Evasive Manoeuvres","abstract":"This paper presents a novel Learning-based Model Predictive Contouring Control (L-MPCC) algorithm for evasive manoeuvres at the limit of handling. The algorithm uses the Student-t Process (STP) to minimise model mismatches and uncertainties online. The proposed STP captures the mismatches between the prediction model and the measured lateral tyre forces and yaw rate. The mismatches correspond to the posterior means provided to the prediction model to improve its accuracy. Simultaneously, the posterior covariances are propagated to the vehicle lateral velocity and yaw rate along the prediction horizon. The STP posterior covariance directly depends on the variance of observed data, so its variance is more significant when the online measurements differ from the recorded ones in the training set and smaller in the opposite case. Thus, these covariances can be utilised in the L-MPCC's cost function to minimise the vehicle state uncertainties. In a high-fidelity simulation environment, we demonstrate that the proposed L-MPCC can successfully avoid obstacles, keeping the vehicle stable while driving a double lane change manoeuvre at a higher velocity than an MPCC without STP. Furthermore, the proposed controller yields a significantly lower peak sideslip angle, improving the vehicle's manoeuvrability compared to an L-MPCC with a Gaussian Process.","sentences":["This paper presents a novel Learning-based Model Predictive Contouring Control (L-MPCC) algorithm for evasive manoeuvres at the limit of handling.","The algorithm uses the Student-t Process (STP) to minimise model mismatches and uncertainties online.","The proposed STP captures the mismatches between the prediction model and the measured lateral tyre forces and yaw rate.","The mismatches correspond to the posterior means provided to the prediction model to improve its accuracy.","Simultaneously, the posterior covariances are propagated to the vehicle lateral velocity and yaw rate along the prediction horizon.","The STP posterior covariance directly depends on the variance of observed data, so its variance is more significant when the online measurements differ from the recorded ones in the training set and smaller in the opposite case.","Thus, these covariances can be utilised in the L-MPCC's cost function to minimise the vehicle state uncertainties.","In a high-fidelity simulation environment, we demonstrate that the proposed L-MPCC can successfully avoid obstacles, keeping the vehicle stable while driving a double lane change manoeuvre at a higher velocity than an MPCC without STP.","Furthermore, the proposed controller yields a significantly lower peak sideslip angle, improving the vehicle's manoeuvrability compared to an L-MPCC with a Gaussian Process."],"url":"http://arxiv.org/abs/2408.04485v1"}
{"created":"2024-08-08 14:19:11","title":"SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios","abstract":"Most of the sophisticated AI models utilize huge amounts of annotated data and heavy training to achieve high-end performance. However, there are certain challenges that hinder the deployment of AI models \"in-the-wild\" scenarios, i.e., inefficient use of unlabeled data, lack of incorporation of human expertise, and lack of interpretation of the results. To mitigate these challenges, we propose a novel Explainable Active Learning (XAL) model, XAL-based semantic segmentation model \"SegXAL\", that can (i) effectively utilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm, and (iii) augment the model decisions in an interpretable way. In particular, we investigate the application of the SegXAL model for semantic segmentation in driving scene scenarios. The SegXAL model proposes the image regions that require labeling assistance from Oracle by dint of explainable AI (XAI) and uncertainty measures in a weakly-supervised manner. Specifically, we propose a novel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty (EBU) module to get an Explainable Error Mask, which enables the machine teachers/human experts to provide intuitive reasoning behind the results and to solicit feedback to the AI system via an active learning strategy. Such a mechanism bridges the semantic gap between man and machine through collaborative intelligence, where humans and AI actively enhance each other's complementary strengths. A novel high-confidence sample selection technique based on the DICE similarity coefficient is also presented within the SegXAL framework. Extensive quantitative and qualitative analyses are carried out in the benchmarking Cityscape dataset. Results show the outperformance of our proposed SegXAL against other state-of-the-art models.","sentences":["Most of the sophisticated AI models utilize huge amounts of annotated data and heavy training to achieve high-end performance.","However, there are certain challenges that hinder the deployment of AI models \"in-the-wild\" scenarios, i.e., inefficient use of unlabeled data, lack of incorporation of human expertise, and lack of interpretation of the results.","To mitigate these challenges, we propose a novel Explainable Active Learning (XAL) model, XAL-based semantic segmentation model \"SegXAL\", that can (i) effectively utilize the unlabeled data, (ii) facilitate the \"Human-in-the-loop\" paradigm, and (iii) augment the model decisions in an interpretable way.","In particular, we investigate the application of the SegXAL model for semantic segmentation in driving scene scenarios.","The SegXAL model proposes the image regions that require labeling assistance from Oracle by dint of explainable AI (XAI) and uncertainty measures in a weakly-supervised manner.","Specifically, we propose a novel Proximity-aware Explainable-AI (PAE) module and Entropy-based Uncertainty (EBU) module to get an Explainable Error Mask, which enables the machine teachers/human experts to provide intuitive reasoning behind the results and to solicit feedback to the AI system via an active learning strategy.","Such a mechanism bridges the semantic gap between man and machine through collaborative intelligence, where humans and AI actively enhance each other's complementary strengths.","A novel high-confidence sample selection technique based on the DICE similarity coefficient is also presented within the SegXAL framework.","Extensive quantitative and qualitative analyses are carried out in the benchmarking Cityscape dataset.","Results show the outperformance of our proposed SegXAL against other state-of-the-art models."],"url":"http://arxiv.org/abs/2408.04482v1"}
{"created":"2024-08-08 14:08:39","title":"NFDI4Health workflow and service for synthetic data generation, assessment and risk management","abstract":"Individual health data is crucial for scientific advancements, particularly in developing Artificial Intelligence (AI); however, sharing real patient information is often restricted due to privacy concerns. A promising solution to this challenge is synthetic data generation. This technique creates entirely new datasets that mimic the statistical properties of real data, while preserving confidential patient information. In this paper, we present the workflow and different services developed in the context of Germany's National Data Infrastructure project NFDI4Health. First, two state-of-the-art AI tools (namely, VAMBN and MultiNODEs) for generating synthetic health data are outlined. Further, we introduce SYNDAT (a public web-based tool) which allows users to visualize and assess the quality and risk of synthetic data provided by desired generative models. Additionally, the utility of the proposed methods and the web-based tool is showcased using data from Alzheimer's Disease Neuroimaging Initiative (ADNI) and the Center for Cancer Registry Data of the Robert Koch Institute (RKI).","sentences":["Individual health data is crucial for scientific advancements, particularly in developing Artificial Intelligence (AI); however, sharing real patient information is often restricted due to privacy concerns.","A promising solution to this challenge is synthetic data generation.","This technique creates entirely new datasets that mimic the statistical properties of real data, while preserving confidential patient information.","In this paper, we present the workflow and different services developed in the context of Germany's National Data Infrastructure project NFDI4Health.","First, two state-of-the-art AI tools (namely, VAMBN and MultiNODEs) for generating synthetic health data are outlined.","Further, we introduce SYNDAT (a public web-based tool) which allows users to visualize and assess the quality and risk of synthetic data provided by desired generative models.","Additionally, the utility of the proposed methods and the web-based tool is showcased using data from Alzheimer's Disease Neuroimaging Initiative (ADNI) and the Center for Cancer Registry Data of the Robert Koch Institute (RKI)."],"url":"http://arxiv.org/abs/2408.04478v1"}
{"created":"2024-08-08 14:08:15","title":"What You Need is What You Get: Theory of Mind for an LLM-Based Code Understanding Assistant","abstract":"A growing number of tools have used Large Language Models (LLMs) to support developers' code understanding. However, developers still face several barriers to using such tools, including challenges in describing their intent in natural language, interpreting the tool outcome, and refining an effective prompt to obtain useful information. In this study, we designed an LLM-based conversational assistant that provides a personalized interaction based on inferred user mental state (e.g., background knowledge and experience). We evaluate the approach in a within-subject study with fourteen novices to capture their perceptions and preferences. Our results provide insights for researchers and tool builders who want to create or improve LLM-based conversational assistants to support novices in code understanding.","sentences":["A growing number of tools have used Large Language Models (LLMs) to support developers' code understanding.","However, developers still face several barriers to using such tools, including challenges in describing their intent in natural language, interpreting the tool outcome, and refining an effective prompt to obtain useful information.","In this study, we designed an LLM-based conversational assistant that provides a personalized interaction based on inferred user mental state (e.g., background knowledge and experience).","We evaluate the approach in a within-subject study with fourteen novices to capture their perceptions and preferences.","Our results provide insights for researchers and tool builders who want to create or improve LLM-based conversational assistants to support novices in code understanding."],"url":"http://arxiv.org/abs/2408.04477v1"}
{"created":"2024-08-08 14:02:45","title":"Can LLMs Beat Humans in Debating? A Dynamic Multi-agent Framework for Competitive Debate","abstract":"Competitive debate is a comprehensive and complex computational argumentation task. Large Language Models (LLMs) encounter hallucinations and lack competitiveness in this task. To address these challenges, we introduce Agent for Debate (Agent4Debate), a dynamic, multi-agent framework based on LLMs designed to enhance their capabilities in competitive debate. Drawing inspiration from human behavior in debate preparation and execution, Agent4Debate employs a collaborative architecture where four specialized agents (Searcher, Analyzer, Writer, and Reviewer) dynamically interact and cooperate. These agents work throughout the debate process, covering multiple stages from initial research and argument formulation to rebuttal and summary. To comprehensively evaluate framework performance, we construct the Chinese Debate Arena, comprising 66 carefully selected Chinese debate motions. We recruite ten experienced human debaters and collect records of 200 debates involving Agent4Debate, baseline models, and humans. The evaluation employs the Debatrix automatic scoring system and professional human reviewers based on the established Debatrix-Elo and Human-Elo ranking. Experimental results indicate that the state-of-the-art Agent4Debate exhibits capabilities comparable to those of humans. Furthermore, ablation studies demonstrate the effectiveness of each component in the agent structure.","sentences":["Competitive debate is a comprehensive and complex computational argumentation task.","Large Language Models (LLMs) encounter hallucinations and lack competitiveness in this task.","To address these challenges, we introduce Agent for Debate (Agent4Debate), a dynamic, multi-agent framework based on LLMs designed to enhance their capabilities in competitive debate.","Drawing inspiration from human behavior in debate preparation and execution, Agent4Debate employs a collaborative architecture where four specialized agents (Searcher, Analyzer, Writer, and Reviewer) dynamically interact and cooperate.","These agents work throughout the debate process, covering multiple stages from initial research and argument formulation to rebuttal and summary.","To comprehensively evaluate framework performance, we construct the Chinese Debate Arena, comprising 66 carefully selected Chinese debate motions.","We recruite ten experienced human debaters and collect records of 200 debates involving Agent4Debate, baseline models, and humans.","The evaluation employs the Debatrix automatic scoring system and professional human reviewers based on the established Debatrix-Elo and Human-Elo ranking.","Experimental results indicate that the state-of-the-art Agent4Debate exhibits capabilities comparable to those of humans.","Furthermore, ablation studies demonstrate the effectiveness of each component in the agent structure."],"url":"http://arxiv.org/abs/2408.04472v1"}
{"created":"2024-08-08 14:01:12","title":"What could go wrong? Discovering and describing failure modes in computer vision","abstract":"Deep learning models are effective, yet brittle. Even carefully trained, their behavior tends to be hard to predict when confronted with out-of-distribution samples. In this work, our goal is to propose a simple yet effective solution to predict and describe via natural language potential failure modes of computer vision models. Given a pretrained model and a set of samples, our aim is to find sentences that accurately describe the visual conditions in which the model underperforms. In order to study this important topic and foster future research on it, we formalize the problem of Language-Based Error Explainability (LBEE) and propose a set of metrics to evaluate and compare different methods for this task. We propose solutions that operate in a joint vision-and-language embedding space, and can characterize through language descriptions model failures caused, e.g., by objects unseen during training or adverse visual conditions. We experiment with different tasks, such as classification under the presence of dataset bias and semantic segmentation in unseen environments, and show that the proposed methodology isolates nontrivial sentences associated with specific error causes. We hope our work will help practitioners better understand the behavior of models, increasing their overall safety and interpretability.","sentences":["Deep learning models are effective, yet brittle.","Even carefully trained, their behavior tends to be hard to predict when confronted with out-of-distribution samples.","In this work, our goal is to propose a simple yet effective solution to predict and describe via natural language potential failure modes of computer vision models.","Given a pretrained model and a set of samples, our aim is to find sentences that accurately describe the visual conditions in which the model underperforms.","In order to study this important topic and foster future research on it, we formalize the problem of Language-Based Error Explainability (LBEE) and propose a set of metrics to evaluate and compare different methods for this task.","We propose solutions that operate in a joint vision-and-language embedding space, and can characterize through language descriptions model failures caused, e.g., by objects unseen during training or adverse visual conditions.","We experiment with different tasks, such as classification under the presence of dataset bias and semantic segmentation in unseen environments, and show that the proposed methodology isolates nontrivial sentences associated with specific error causes.","We hope our work will help practitioners better understand the behavior of models, increasing their overall safety and interpretability."],"url":"http://arxiv.org/abs/2408.04471v1"}
{"created":"2024-08-08 13:49:26","title":"One-Shot Method for Computing Generalized Winding Numbers","abstract":"The generalized winding number is an essential part of the geometry processing toolkit, allowing to quantify how much a given point is inside a surface, often represented by a mesh or a point cloud, even when the surface is open, noisy, or non-manifold. Parameterized surfaces, which often contain intentional and unintentional gaps and imprecisions, would also benefit from a generalized winding number. Standard methods to compute it, however, rely on a surface integral, challenging to compute without surface discretization, leading to loss of precision characteristic of parametric surfaces.   We propose an alternative method to compute a generalized winding number, based only on the surface boundary and the intersections of a single ray with the surface. For parametric surfaces, we show that all the necessary operations can be done via a Sum-of-Squares (SOS) formulation, thus computing generalized winding numbers without surface discretization with machine precision. We show that by discretizing only the boundary of the surface, this becomes an efficient method.   We demonstrate an application of our method to the problem of computing a generalized winding number of a surface represented by a curve network, where each curve loop is surfaced via Laplace equation. We use the Boundary Element Method to express the solution as a parametric surface, allowing us to apply our method without meshing the surfaces. As a bonus, we also demonstrate that for meshes with many triangles and a simple boundary, our method is faster than the hierarchical evaluation of the generalized winding number while still being precise.   We validate our algorithms theoretically, numerically, and by demonstrating a gallery of results \\new{on a variety of parametric surfaces and meshes}, as well uses in a variety of applications, including voxelizations and boolean operations.","sentences":["The generalized winding number is an essential part of the geometry processing toolkit, allowing to quantify how much a given point is inside a surface, often represented by a mesh or a point cloud, even when the surface is open, noisy, or non-manifold.","Parameterized surfaces, which often contain intentional and unintentional gaps and imprecisions, would also benefit from a generalized winding number.","Standard methods to compute it, however, rely on a surface integral, challenging to compute without surface discretization, leading to loss of precision characteristic of parametric surfaces.   ","We propose an alternative method to compute a generalized winding number, based only on the surface boundary and the intersections of a single ray with the surface.","For parametric surfaces, we show that all the necessary operations can be done via a Sum-of-Squares (SOS) formulation, thus computing generalized winding numbers without surface discretization with machine precision.","We show that by discretizing only the boundary of the surface, this becomes an efficient method.   ","We demonstrate an application of our method to the problem of computing a generalized winding number of a surface represented by a curve network, where each curve loop is surfaced via Laplace equation.","We use the Boundary Element Method to express the solution as a parametric surface, allowing us to apply our method without meshing the surfaces.","As a bonus, we also demonstrate that for meshes with many triangles and a simple boundary, our method is faster than the hierarchical evaluation of the generalized winding number while still being precise.   ","We validate our algorithms theoretically, numerically, and by demonstrating a gallery of results \\new{on a variety of parametric surfaces and meshes}, as well uses in a variety of applications, including voxelizations and boolean operations."],"url":"http://arxiv.org/abs/2408.04466v1"}
{"created":"2024-08-08 13:45:23","title":"Crowd Intelligence for Early Misinformation Prediction on Social Media","abstract":"Misinformation spreads rapidly on social media, causing serious damage by influencing public opinion, promoting dangerous behavior, or eroding trust in reliable sources. It spreads too fast for traditional fact-checking, stressing the need for predictive methods. We introduce CROWDSHIELD, a crowd intelligence-based method for early misinformation prediction. We hypothesize that the crowd's reactions to misinformation reveal its accuracy. Furthermore, we hinge upon exaggerated assertions/claims and replies with particular positions/stances on the source post within a conversation thread. We employ Q-learning to capture the two dimensions -- stances and claims. We utilize deep Q-learning due to its proficiency in navigating complex decision spaces and effectively learning network properties. Additionally, we use a transformer-based encoder to develop a comprehensive understanding of both content and context. This multifaceted approach helps ensure the model pays attention to user interaction and stays anchored in the communication's content. We propose MIST, a manually annotated misinformation detection Twitter corpus comprising nearly 200 conversation threads with more than 14K replies. In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an improvement of ~4% macro-F1 score. We conduct an ablation study and error analysis to validate our proposed model's performance. The source code and dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git.","sentences":["Misinformation spreads rapidly on social media, causing serious damage by influencing public opinion, promoting dangerous behavior, or eroding trust in reliable sources.","It spreads too fast for traditional fact-checking, stressing the need for predictive methods.","We introduce CROWDSHIELD, a crowd intelligence-based method for early misinformation prediction.","We hypothesize that the crowd's reactions to misinformation reveal its accuracy.","Furthermore, we hinge upon exaggerated assertions/claims and replies with particular positions/stances on the source post within a conversation thread.","We employ Q-learning to capture the two dimensions -- stances and claims.","We utilize deep Q-learning due to its proficiency in navigating complex decision spaces and effectively learning network properties.","Additionally, we use a transformer-based encoder to develop a comprehensive understanding of both content and context.","This multifaceted approach helps ensure the model pays attention to user interaction and stays anchored in the communication's content.","We propose MIST, a manually annotated misinformation detection Twitter corpus comprising nearly 200 conversation threads with more than 14K replies.","In experiments, CROWDSHIELD outperformed ten baseline systems, achieving an improvement of ~4% macro-F1 score.","We conduct an ablation study and error analysis to validate our proposed model's performance.","The source code and dataset are available at https://github.com/LCS2-IIITD/CrowdShield.git."],"url":"http://arxiv.org/abs/2408.04463v1"}
{"created":"2024-08-08 13:42:18","title":"Random Walk Diffusion for Efficient Large-Scale Graph Generation","abstract":"Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs. While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs. In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation. Our method encompasses two components in an iterative process of random walk sampling and graph pruning. We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs.","sentences":["Graph generation addresses the problem of generating new graphs that have a data distribution similar to real-world graphs.","While previous diffusion-based graph generation methods have shown promising results, they often struggle to scale to large graphs.","In this work, we propose ARROW-Diff (AutoRegressive RandOm Walk Diffusion), a novel random walk-based diffusion approach for efficient large-scale graph generation.","Our method encompasses two components in an iterative process of random walk sampling and graph pruning.","We demonstrate that ARROW-Diff can scale to large graphs efficiently, surpassing other baseline methods in terms of both generation time and multiple graph statistics, reflecting the high quality of the generated graphs."],"url":"http://arxiv.org/abs/2408.04461v1"}
{"created":"2024-08-08 13:39:09","title":"An experimental comparative study of backpropagation and alternatives for training binary neural networks for image classification","abstract":"Current artificial neural networks are trained with parameters encoded as floating point numbers that occupy lots of memory space at inference time. Due to the increase in the size of deep learning models, it is becoming very difficult to consider training and using artificial neural networks on edge devices. Binary neural networks promise to reduce the size of deep neural network models, as well as to increase inference speed while decreasing energy consumption. Thus, they may allow the deployment of more powerful models on edge devices. However, binary neural networks are still proven to be difficult to train using the backpropagation-based gradient descent scheme. This paper extends the work of \\cite{crulis2023alternatives}, which proposed adapting to binary neural networks two promising alternatives to backpropagation originally designed for continuous neural networks, and experimented with them on simple image classification datasets. This paper proposes new experiments on the ImageNette dataset, compares three different model architectures for image classification, and adds two additional alternatives to backpropagation.","sentences":["Current artificial neural networks are trained with parameters encoded as floating point numbers that occupy lots of memory space at inference time.","Due to the increase in the size of deep learning models, it is becoming very difficult to consider training and using artificial neural networks on edge devices.","Binary neural networks promise to reduce the size of deep neural network models, as well as to increase inference speed while decreasing energy consumption.","Thus, they may allow the deployment of more powerful models on edge devices.","However, binary neural networks are still proven to be difficult to train using the backpropagation-based gradient descent scheme.","This paper extends the work of \\cite{crulis2023alternatives}, which proposed adapting to binary neural networks two promising alternatives to backpropagation originally designed for continuous neural networks, and experimented with them on simple image classification datasets.","This paper proposes new experiments on the ImageNette dataset, compares three different model architectures for image classification, and adds two additional alternatives to backpropagation."],"url":"http://arxiv.org/abs/2408.04460v1"}
{"created":"2024-08-08 13:29:06","title":"Modelling Probabilistic FPC in Guarded Type Theory","abstract":"Constructive type theory combines logic and programming in one language. This is useful both for reasoning about programs written in type theory, as well as for reasoning about other programming languages inside type theory. It is well-known that it is challenging to extend these applications to languages with recursion and computational effects such as probabilistic choice, because these features are not easily represented in constructive type theory. We show how to define and reason about a programming language with probabilistic choice and recursive types, in guarded type theory. We use higher inductive types to represent finite distributions and guarded recursion to model recursion. We define both operational and denotational semantics, as well as a relation between the two. The relation can be used to prove adequacy, but we also show how to use it to reason about programs up to contextual equivalence. To the best of our knowledge, this is the first model of a programming language with probabilistic choice and recursive types in a constructive type theory.","sentences":["Constructive type theory combines logic and programming in one language.","This is useful both for reasoning about programs written in type theory, as well as for reasoning about other programming languages inside type theory.","It is well-known that it is challenging to extend these applications to languages with recursion and computational effects such as probabilistic choice, because these features are not easily represented in constructive type theory.","We show how to define and reason about a programming language with probabilistic choice and recursive types, in guarded type theory.","We use higher inductive types to represent finite distributions and guarded recursion to model recursion.","We define both operational and denotational semantics, as well as a relation between the two.","The relation can be used to prove adequacy, but we also show how to use it to reason about programs up to contextual equivalence.","To the best of our knowledge, this is the first model of a programming language with probabilistic choice and recursive types in a constructive type theory."],"url":"http://arxiv.org/abs/2408.04455v1"}
{"created":"2024-08-08 13:19:37","title":"RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents","abstract":"The integration of large language models (LLMs) into robotics significantly enhances the capabilities of embodied agents in understanding and executing complex natural language instructions. However, the unmitigated deployment of LLM-based embodied systems in real-world environments may pose potential physical risks, such as property damage and personal injury. Existing security benchmarks for LLMs overlook risk awareness for LLM-based embodied agents. To address this gap, we propose RiskAwareBench, an automated framework designed to assess physical risks awareness in LLM-based embodied agents. RiskAwareBench consists of four modules: safety tips generation, risky scene generation, plan generation, and evaluation, enabling comprehensive risk assessment with minimal manual intervention. Utilizing this framework, we compile the PhysicalRisk dataset, encompassing diverse scenarios with associated safety tips, observations, and instructions. Extensive experiments reveal that most LLMs exhibit insufficient physical risk awareness, and baseline risk mitigation strategies yield limited enhancement, which emphasizes the urgency and cruciality of improving risk awareness in LLM-based embodied agents in the future.","sentences":["The integration of large language models (LLMs) into robotics significantly enhances the capabilities of embodied agents in understanding and executing complex natural language instructions.","However, the unmitigated deployment of LLM-based embodied systems in real-world environments may pose potential physical risks, such as property damage and personal injury.","Existing security benchmarks for LLMs overlook risk awareness for LLM-based embodied agents.","To address this gap, we propose RiskAwareBench, an automated framework designed to assess physical risks awareness in LLM-based embodied agents.","RiskAwareBench consists of four modules: safety tips generation, risky scene generation, plan generation, and evaluation, enabling comprehensive risk assessment with minimal manual intervention.","Utilizing this framework, we compile the PhysicalRisk dataset, encompassing diverse scenarios with associated safety tips, observations, and instructions.","Extensive experiments reveal that most LLMs exhibit insufficient physical risk awareness, and baseline risk mitigation strategies yield limited enhancement, which emphasizes the urgency and cruciality of improving risk awareness in LLM-based embodied agents in the future."],"url":"http://arxiv.org/abs/2408.04449v1"}
{"created":"2024-08-08 13:18:53","title":"Reinforcement Learning from Human Feedback for Lane Changing of Autonomous Vehicles in Mixed Traffic","abstract":"The burgeoning field of autonomous driving necessitates the seamless integration of autonomous vehicles (AVs) with human-driven vehicles, calling for more predictable AV behavior and enhanced interaction with human drivers. Human-like driving, particularly during lane-changing maneuvers on highways, is a critical area of research due to its significant impact on safety and traffic flow. Traditional rule-based decision-making approaches often fail to encapsulate the nuanced boundaries of human behavior in diverse driving scenarios, while crafting reward functions for learning-based methods introduces its own set of complexities. This study investigates the application of Reinforcement Learning from Human Feedback (RLHF) to emulate human-like lane-changing decisions in AVs. An initial RL policy is pre-trained to ensure safe lane changes. Subsequently, this policy is employed to gather data, which is then annotated by humans to train a reward model that discerns lane changes aligning with human preferences. This human-informed reward model supersedes the original, guiding the refinement of the policy to reflect human-like preferences. The effectiveness of RLHF in producing human-like lane changes is demonstrated through the development and evaluation of conservative and aggressive lane-changing models within obstacle-rich environments and mixed autonomy traffic scenarios. The experimental outcomes underscore the potential of RLHF to diversify lane-changing behaviors in AVs, suggesting its viability for enhancing the integration of AVs into the fabric of human-driven traffic.","sentences":["The burgeoning field of autonomous driving necessitates the seamless integration of autonomous vehicles (AVs) with human-driven vehicles, calling for more predictable AV behavior and enhanced interaction with human drivers.","Human-like driving, particularly during lane-changing maneuvers on highways, is a critical area of research due to its significant impact on safety and traffic flow.","Traditional rule-based decision-making approaches often fail to encapsulate the nuanced boundaries of human behavior in diverse driving scenarios, while crafting reward functions for learning-based methods introduces its own set of complexities.","This study investigates the application of Reinforcement Learning from Human Feedback (RLHF) to emulate human-like lane-changing decisions in AVs.","An initial RL policy is pre-trained to ensure safe lane changes.","Subsequently, this policy is employed to gather data, which is then annotated by humans to train a reward model that discerns lane changes aligning with human preferences.","This human-informed reward model supersedes the original, guiding the refinement of the policy to reflect human-like preferences.","The effectiveness of RLHF in producing human-like lane changes is demonstrated through the development and evaluation of conservative and aggressive lane-changing models within obstacle-rich environments and mixed autonomy traffic scenarios.","The experimental outcomes underscore the potential of RLHF to diversify lane-changing behaviors in AVs, suggesting its viability for enhancing the integration of AVs into the fabric of human-driven traffic."],"url":"http://arxiv.org/abs/2408.04447v1"}
{"created":"2024-08-08 13:17:59","title":"On some randomized algorithms and their evaluation","abstract":"The paper considers implementations of some randomized algorithms in connection with obtaining a random $n^2 \\times n^2$ Sudoku matrix with programming language C++. For this purpose we describes the set $\\Pi_n$ of all $(2n) \\times n$ matrices, consisting of elements of the set $\\mathbb{Z}_n =\\{ 1,2,\\ldots ,n\\}$, such that every row is a permutation. We emphasize the relationship between these matrices and the $n^2 \\times n^2$ Sudoku matrices. An algorithm to obtain random $\\Pi_n$ matrices is presented in this paper. Several auxiliary algorithms that are related to the underlying problem have been described. We evaluated all algorithms according to two criteria - probability evaluation, and time for generation of random objects and checking of belonging to a specific set. This evaluations are interesting from both theoretical and practical point of view because they are particularly useful in the analysis of computer programs.","sentences":["The paper considers implementations of some randomized algorithms in connection with obtaining a random $n^2 \\times n^2$ Sudoku matrix with programming language C++.","For this purpose we describes the set $\\Pi_n$ of all $(2n)","\\times n$ matrices, consisting of elements of the set $\\mathbb{Z}_n =\\{ 1,2,\\ldots ,n\\}$, such that every row is a permutation.","We emphasize the relationship between these matrices and the $n^2 \\times n^2$ Sudoku matrices.","An algorithm to obtain random $\\Pi_n$ matrices is presented in this paper.","Several auxiliary algorithms that are related to the underlying problem have been described.","We evaluated all algorithms according to two criteria - probability evaluation, and time for generation of random objects and checking of belonging to a specific set.","This evaluations are interesting from both theoretical and practical point of view because they are particularly useful in the analysis of computer programs."],"url":"http://arxiv.org/abs/2408.04445v1"}
{"created":"2024-08-08 13:14:39","title":"Pairing Clustered Inverted Indexes with kNN Graphs for Fast Approximate Retrieval over Learned Sparse Representations","abstract":"Learned sparse representations form an effective and interpretable class of embeddings for text retrieval. While exact top-k retrieval over such embeddings faces efficiency challenges, a recent algorithm called Seismic has enabled remarkably fast, highly-accurate approximate retrieval. Seismic statically prunes inverted lists, organizes each list into geometrically-cohesive blocks, and augments each block with a summary vector. At query time, each inverted list associated with a query term is traversed one block at a time in an arbitrary order, with the inner product between the query and summaries determining if a block must be evaluated. When a block is deemed promising, its documents are fully evaluated with a forward index. Seismic is one to two orders of magnitude faster than state-of-the-art inverted index-based solutions and significantly outperforms the winning graph-based submissions to the BigANN 2023 Challenge. In this work, we speed up Seismic further by introducing two innovations to its query processing subroutine. First, we traverse blocks in order of importance, rather than arbitrarily. Second, we take the list of documents retrieved by Seismic and expand it to include the neighbors of each document using an offline k-regular nearest neighbor graph; the expanded list is then ranked to produce the final top-k set. Experiments on two public datasets show that our extension, named SeismicWave, can reach almost-exact accuracy levels and is up to 2.2x faster than Seismic.","sentences":["Learned sparse representations form an effective and interpretable class of embeddings for text retrieval.","While exact top-k retrieval over such embeddings faces efficiency challenges, a recent algorithm called Seismic has enabled remarkably fast, highly-accurate approximate retrieval.","Seismic statically prunes inverted lists, organizes each list into geometrically-cohesive blocks, and augments each block with a summary vector.","At query time, each inverted list associated with a query term is traversed one block at a time in an arbitrary order, with the inner product between the query and summaries determining if a block must be evaluated.","When a block is deemed promising, its documents are fully evaluated with a forward index.","Seismic is one to two orders of magnitude faster than state-of-the-art inverted index-based solutions and significantly outperforms the winning graph-based submissions to the BigANN 2023 Challenge.","In this work, we speed up Seismic further by introducing two innovations to its query processing subroutine.","First, we traverse blocks in order of importance, rather than arbitrarily.","Second, we take the list of documents retrieved by Seismic and expand it to include the neighbors of each document using an offline k-regular nearest neighbor graph; the expanded list is then ranked to produce the final top-k set.","Experiments on two public datasets show that our extension, named SeismicWave, can reach almost-exact accuracy levels and is up to 2.2x faster than Seismic."],"url":"http://arxiv.org/abs/2408.04443v1"}
{"created":"2024-08-08 13:14:19","title":"FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data","abstract":"The emergence of federated learning (FL) presents a promising approach to leverage decentralized data while preserving privacy. Furthermore, the combination of FL and anomaly detection is particularly compelling because it allows for detecting rare and critical anomalies (usually also rare in locally gathered data) in sensitive data from multiple sources, such as cybersecurity and healthcare. However, benchmarking the performance of anomaly detection methods in FL environments remains an underexplored area. This paper introduces FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection algorithms within the context of FL. We systematically analyze and compare the performance of recent deep learning anomaly detection models under federated settings, which were typically assessed solely in centralized settings. FedAD-Bench encompasses diverse datasets and metrics to provide a holistic evaluation. Through extensive experiments, we identify key challenges such as model aggregation inefficiencies and metric unreliability. We present insights into FL's regularization effects, revealing scenarios in which it outperforms centralized approaches due to its inherent ability to mitigate overfitting. Our work aims to establish a standardized benchmark to guide future research and development in federated anomaly detection, promoting reproducibility and fair comparison across studies.","sentences":["The emergence of federated learning (FL) presents a promising approach to leverage decentralized data while preserving privacy.","Furthermore, the combination of FL and anomaly detection is particularly compelling because it allows for detecting rare and critical anomalies (usually also rare in locally gathered data) in sensitive data from multiple sources, such as cybersecurity and healthcare.","However, benchmarking the performance of anomaly detection methods in FL environments remains an underexplored area.","This paper introduces FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection algorithms within the context of FL.","We systematically analyze and compare the performance of recent deep learning anomaly detection models under federated settings, which were typically assessed solely in centralized settings.","FedAD-Bench encompasses diverse datasets and metrics to provide a holistic evaluation.","Through extensive experiments, we identify key challenges such as model aggregation inefficiencies and metric unreliability.","We present insights into FL's regularization effects, revealing scenarios in which it outperforms centralized approaches due to its inherent ability to mitigate overfitting.","Our work aims to establish a standardized benchmark to guide future research and development in federated anomaly detection, promoting reproducibility and fair comparison across studies."],"url":"http://arxiv.org/abs/2408.04442v1"}
{"created":"2024-08-08 13:10:03","title":"Deep Learning for identifying systolic complexes in SCG traces: a cross-dataset analysis","abstract":"The seismocardiographic signal is a promising alternative to the traditional ECG in the analysis of the cardiac activity. In particular, the systolic complex is known to be the most informative part of the seismocardiogram, thus requiring further analysis. State-of-art solutions to detect the systolic complex are based on Deep Learning models, which have been proven effective in pioneering studies. However, these solutions have only been tested in a controlled scenario considering only clean signals acquired from users maintained still in supine position. On top of that, all these studies consider data coming from a single dataset, ignoring the benefits and challenges related to a cross-dataset scenario. In this work, a cross-dataset experimental analysis was performed considering also data from a real-world scenario. Our findings prove the effectiveness of a deep learning solution, while showing the importance of a personalization step to contrast the domain shift, namely a change in data distribution between training and testing data. Finally, we demonstrate the benefits of a multi-channels approach, leveraging the information extracted from both accelerometers and gyroscopes data.","sentences":["The seismocardiographic signal is a promising alternative to the traditional ECG in the analysis of the cardiac activity.","In particular, the systolic complex is known to be the most informative part of the seismocardiogram, thus requiring further analysis.","State-of-art solutions to detect the systolic complex are based on Deep Learning models, which have been proven effective in pioneering studies.","However, these solutions have only been tested in a controlled scenario considering only clean signals acquired from users maintained still in supine position.","On top of that, all these studies consider data coming from a single dataset, ignoring the benefits and challenges related to a cross-dataset scenario.","In this work, a cross-dataset experimental analysis was performed considering also data from a real-world scenario.","Our findings prove the effectiveness of a deep learning solution, while showing the importance of a personalization step to contrast the domain shift, namely a change in data distribution between training and testing data.","Finally, we demonstrate the benefits of a multi-channels approach, leveraging the information extracted from both accelerometers and gyroscopes data."],"url":"http://arxiv.org/abs/2408.04439v1"}
{"created":"2024-08-08 12:57:14","title":"Large Language Models for cross-language code clone detection","abstract":"With the involvement of multiple programming languages in modern software development, cross-lingual code clone detection has gained traction with the software engineering community. Numerous studies have explored this topic, proposing various promising approaches. Inspired by the significant advances in machine learning in recent years, particularly Large Language Models (LLMs), which have demonstrated their ability to tackle various tasks, this paper revisits cross-lingual code clone detection.   We investigate the capabilities of four (04) LLMs and eight (08) prompts for the identification of cross-lingual code clones. Additionally, we evaluate a pre-trained embedding model to assess the effectiveness of the generated representations for classifying clone and non-clone pairs. Both studies (based on LLMs and Embedding models) are evaluated using two widely used cross-lingual datasets, XLCoST and CodeNet. Our results show that LLMs can achieve high F1 scores, up to 0.98, for straightforward programming examples (e.g., from XLCoST). However, they not only perform less well on programs associated with complex programming challenges but also do not necessarily understand the meaning of code clones in a cross-lingual setting. We show that embedding models used to represent code fragments from different programming languages in the same representation space enable the training of a basic classifier that outperforms all LLMs by ~2 and ~24 percentage points on the XLCoST and CodeNet datasets, respectively. This finding suggests that, despite the apparent capabilities of LLMs, embeddings provided by embedding models offer suitable representations to achieve state-of-the-art performance in cross-lingual code clone detection.","sentences":["With the involvement of multiple programming languages in modern software development, cross-lingual code clone detection has gained traction with the software engineering community.","Numerous studies have explored this topic, proposing various promising approaches.","Inspired by the significant advances in machine learning in recent years, particularly Large Language Models (LLMs), which have demonstrated their ability to tackle various tasks, this paper revisits cross-lingual code clone detection.   ","We investigate the capabilities of four (04) LLMs and eight (08) prompts for the identification of cross-lingual code clones.","Additionally, we evaluate a pre-trained embedding model to assess the effectiveness of the generated representations for classifying clone and non-clone pairs.","Both studies (based on LLMs and Embedding models) are evaluated using two widely used cross-lingual datasets, XLCoST and CodeNet.","Our results show that LLMs can achieve high F1 scores, up to 0.98, for straightforward programming examples (e.g., from XLCoST).","However, they not only perform less well on programs associated with complex programming challenges but also do not necessarily understand the meaning of code clones in a cross-lingual setting.","We show that embedding models used to represent code fragments from different programming languages in the same representation space enable the training of a basic classifier that outperforms all LLMs by ~2 and ~24 percentage points on the XLCoST and CodeNet datasets, respectively.","This finding suggests that, despite the apparent capabilities of LLMs, embeddings provided by embedding models offer suitable representations to achieve state-of-the-art performance in cross-lingual code clone detection."],"url":"http://arxiv.org/abs/2408.04430v1"}
