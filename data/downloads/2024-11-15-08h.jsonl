{"created":"2024-11-14 18:59:57","title":"MagicQuill: An Intelligent Interactive Image Editing System","abstract":"Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques. In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas. Our system features a streamlined yet functionally robust interface, allowing for the articulation of editing operations (e.g., inserting elements, erasing objects, altering color) with minimal input. These interactions are monitored by a multimodal large language model (MLLM) to anticipate editing intentions in real time, bypassing the need for explicit prompt entry. Finally, we apply a powerful diffusion prior, enhanced by a carefully learned two-branch plug-in module, to process editing requests with precise control. Experimental results demonstrate the effectiveness of MagicQuill in achieving high-quality image edits. Please visit https://magic-quill.github.io to try out our system.","sentences":["Image editing involves a variety of complex tasks and requires efficient and precise manipulation techniques.","In this paper, we present MagicQuill, an integrated image editing system that enables swift actualization of creative ideas.","Our system features a streamlined yet functionally robust interface, allowing for the articulation of editing operations (e.g., inserting elements, erasing objects, altering color) with minimal input.","These interactions are monitored by a multimodal large language model (MLLM) to anticipate editing intentions in real time, bypassing the need for explicit prompt entry.","Finally, we apply a powerful diffusion prior, enhanced by a carefully learned two-branch plug-in module, to process editing requests with precise control.","Experimental results demonstrate the effectiveness of MagicQuill in achieving high-quality image edits.","Please visit https://magic-quill.github.io to try out our system."],"url":"http://arxiv.org/abs/2411.09703v1"}
{"created":"2024-11-14 18:59:40","title":"On the Surprising Effectiveness of Attention Transfer for Vision Transformers","abstract":"Conventional wisdom suggests that pre-training Vision Transformers (ViT) improves downstream performance by learning useful representations. Is this actually true? We investigate this question and find that the features and representations learned during pre-training are not essential. Surprisingly, using only the attention patterns from pre-training (i.e., guiding how information flows between tokens) is sufficient for models to learn high quality features from scratch and achieve comparable downstream performance. We show this by introducing a simple method called attention transfer, where only the attention patterns from a pre-trained teacher ViT are transferred to a student, either by copying or distilling the attention maps. Since attention transfer lets the student learn its own features, ensembling it with a fine-tuned teacher also further improves accuracy on ImageNet. We systematically study various aspects of our findings on the sufficiency of attention maps, including distribution shift settings where they underperform fine-tuning. We hope our exploration provides a better understanding of what pre-training accomplishes and leads to a useful alternative to the standard practice of fine-tuning","sentences":["Conventional wisdom suggests that pre-training Vision Transformers (ViT) improves downstream performance by learning useful representations.","Is this actually true?","We investigate this question and find that the features and representations learned during pre-training are not essential.","Surprisingly, using only the attention patterns from pre-training (i.e., guiding how information flows between tokens) is sufficient for models to learn high quality features from scratch and achieve comparable downstream performance.","We show this by introducing a simple method called attention transfer, where only the attention patterns from a pre-trained teacher ViT are transferred to a student, either by copying or distilling the attention maps.","Since attention transfer lets the student learn its own features, ensembling it with a fine-tuned teacher also further improves accuracy on ImageNet.","We systematically study various aspects of our findings on the sufficiency of attention maps, including distribution shift settings where they underperform fine-tuning.","We hope our exploration provides a better understanding of what pre-training accomplishes and leads to a useful alternative to the standard practice of fine-tuning"],"url":"http://arxiv.org/abs/2411.09702v1"}
{"created":"2024-11-14 18:58:23","title":"A Bayesian Optimization Approach to Machine Translation Reranking","abstract":"Reranking a list of candidates from a machine translation system with an external scoring model and returning the highest-scoring candidate remains a simple and effective method for improving the overall output quality. Translation scoring models continue to grow in size, with the best models being comparable to generation models. Thus, reranking can add substantial computational cost to the translation pipeline. In this work, we pose reranking as a Bayesian optimization (BayesOpt) problem. By strategically selecting candidates to score based on a balance of exploration and exploitation, we show that it is possible to find top-scoring candidates when scoring only a fraction of the candidate list. For instance, our method achieves the same CometKiwi score using only 70 scoring evaluations compared a baseline system using 180. We present a multi-fidelity setting for BayesOpt, where the candidates are first scored with a cheaper but noisier proxy scoring model, which further improves the cost-performance tradeoff when using smaller but well-trained distilled proxy scorers.","sentences":["Reranking a list of candidates from a machine translation system with an external scoring model and returning the highest-scoring candidate remains a simple and effective method for improving the overall output quality.","Translation scoring models continue to grow in size, with the best models being comparable to generation models.","Thus, reranking can add substantial computational cost to the translation pipeline.","In this work, we pose reranking as a Bayesian optimization (BayesOpt) problem.","By strategically selecting candidates to score based on a balance of exploration and exploitation, we show that it is possible to find top-scoring candidates when scoring only a fraction of the candidate list.","For instance, our method achieves the same CometKiwi score using only 70 scoring evaluations compared a baseline system using 180.","We present a multi-fidelity setting for BayesOpt, where the candidates are first scored with a cheaper but noisier proxy scoring model, which further improves the cost-performance tradeoff when using smaller but well-trained distilled proxy scorers."],"url":"http://arxiv.org/abs/2411.09694v1"}
{"created":"2024-11-14 18:58:02","title":"CropCraft: Inverse Procedural Modeling for 3D Reconstruction of Crop Plants","abstract":"The ability to automatically build 3D digital twins of plants from images has countless applications in agriculture, environmental science, robotics, and other fields. However, current 3D reconstruction methods fail to recover complete shapes of plants due to heavy occlusion and complex geometries. In this work, we present a novel method for 3D reconstruction of agricultural crops based on optimizing a parametric model of plant morphology via inverse procedural modeling. Our method first estimates depth maps by fitting a neural radiance field and then employs Bayesian optimization to estimate plant morphological parameters that result in consistent depth renderings. The resulting 3D model is complete and biologically plausible. We validate our method on a dataset of real images of agricultural fields, and demonstrate that the reconstructions can be used for a variety of monitoring and simulation applications.","sentences":["The ability to automatically build 3D digital twins of plants from images has countless applications in agriculture, environmental science, robotics, and other fields.","However, current 3D reconstruction methods fail to recover complete shapes of plants due to heavy occlusion and complex geometries.","In this work, we present a novel method for 3D reconstruction of agricultural crops based on optimizing a parametric model of plant morphology via inverse procedural modeling.","Our method first estimates depth maps by fitting a neural radiance field and then employs Bayesian optimization to estimate plant morphological parameters that result in consistent depth renderings.","The resulting 3D model is complete and biologically plausible.","We validate our method on a dataset of real images of agricultural fields, and demonstrate that the reconstructions can be used for a variety of monitoring and simulation applications."],"url":"http://arxiv.org/abs/2411.09693v1"}
{"created":"2024-11-14 18:57:07","title":"Advancing Fine-Grained Visual Understanding with Multi-Scale Alignment in Multi-Modal Models","abstract":"Multi-modal large language models (MLLMs) have achieved remarkable success in fine-grained visual understanding across a range of tasks. However, they often encounter significant challenges due to inadequate alignment for fine-grained knowledge, which restricts their ability to accurately capture local details and attain a comprehensive global perception. While recent advancements have focused on aligning object expressions with grounding information, they typically lack explicit integration of object images, which contain affluent information beyond mere texts or coordinates. To bridge this gap, we introduce a novel fine-grained visual knowledge alignment method that effectively aligns and integrates multi-scale knowledge of objects, including texts, coordinates, and images. This innovative method is underpinned by our multi-scale fine-grained enhancement data synthesis pipeline, which provides over 300K essential training data to enhance alignment and improve overall performance. Furthermore, we present TinyGroundingGPT, a series of compact models optimized for high-level alignments. With a scale of approximately 3B parameters, TinyGroundingGPT achieves outstanding results in grounding tasks while delivering performance comparable to larger MLLMs in complex visual scenarios.","sentences":["Multi-modal large language models (MLLMs) have achieved remarkable success in fine-grained visual understanding across a range of tasks.","However, they often encounter significant challenges due to inadequate alignment for fine-grained knowledge, which restricts their ability to accurately capture local details and attain a comprehensive global perception.","While recent advancements have focused on aligning object expressions with grounding information, they typically lack explicit integration of object images, which contain affluent information beyond mere texts or coordinates.","To bridge this gap, we introduce a novel fine-grained visual knowledge alignment method that effectively aligns and integrates multi-scale knowledge of objects, including texts, coordinates, and images.","This innovative method is underpinned by our multi-scale fine-grained enhancement data synthesis pipeline, which provides over 300K essential training data to enhance alignment and improve overall performance.","Furthermore, we present TinyGroundingGPT, a series of compact models optimized for high-level alignments.","With a scale of approximately 3B parameters, TinyGroundingGPT achieves outstanding results in grounding tasks while delivering performance comparable to larger MLLMs in complex visual scenarios."],"url":"http://arxiv.org/abs/2411.09691v1"}
{"created":"2024-11-14 18:55:26","title":"LLM Hallucination Reasoning with Zero-shot Knowledge Test","abstract":"LLM hallucination, where LLMs occasionally generate unfaithful text, poses significant challenges for their practical applications. Most existing detection methods rely on external knowledge, LLM fine-tuning, or hallucination-labeled datasets, and they do not distinguish between different types of hallucinations, which are crucial for improving detection performance. We introduce a new task, Hallucination Reasoning, which classifies LLM-generated text into one of three categories: aligned, misaligned, and fabricated. Our novel zero-shot method assesses whether LLM has enough knowledge about a given prompt and text. Our experiments conducted on new datasets demonstrate the effectiveness of our method in hallucination reasoning and underscore its importance for enhancing detection performance.","sentences":["LLM hallucination, where LLMs occasionally generate unfaithful text, poses significant challenges for their practical applications.","Most existing detection methods rely on external knowledge, LLM fine-tuning, or hallucination-labeled datasets, and they do not distinguish between different types of hallucinations, which are crucial for improving detection performance.","We introduce a new task, Hallucination Reasoning, which classifies LLM-generated text into one of three categories: aligned, misaligned, and fabricated.","Our novel zero-shot method assesses whether LLM has enough knowledge about a given prompt and text.","Our experiments conducted on new datasets demonstrate the effectiveness of our method in hallucination reasoning and underscore its importance for enhancing detection performance."],"url":"http://arxiv.org/abs/2411.09689v1"}
{"created":"2024-11-14 18:54:19","title":"Squeezed Attention: Accelerating Long Context Length LLM Inference","abstract":"Emerging Large Language Model (LLM) applications require long input prompts to perform complex downstream tasks like document analysis and code generation. For these long context length applications, the length of the input prompt poses a significant challenge in terms of inference efficiency since the inference costs increase linearly with sequence length. However, for many of these applications, much of the context in the prompt is fixed across different user inputs, thereby providing the opportunity to perform offline optimizations to process user inputs quickly, as they are received. In this work, we propose Squeezed Attention as a mechanism to accelerate LLM applications where a large portion of the input prompt is fixed. We first leverage K-means clustering offline to group the keys for the fixed context based on semantic similarity and represent each cluster with a single centroid value. During inference, we compare query tokens from the user input with the centroids to predict which of the keys from the fixed context are semantically relevant and need to be loaded during inference. We then compute exact attention using only these important keys from the fixed context, thereby reducing bandwidth and computational costs. We also extend our method to use a hierarchical centroid lookup to identify important keys, which can reduce the complexity of attention from linear to logarithmic with respect to the context length. We implement optimized Triton kernels for centroid comparison and sparse FlashAttention with important keys, achieving more than 4x speedups during both the prefill and generation phases for long-context inference. Furthermore, we have extensively evaluated our method on various long-context benchmarks including LongBench, where it achieves a 3x reduction in KV cache budget without accuracy loss and up to an 8x reduction with <0.5 point accuracy gap for various models.","sentences":["Emerging Large Language Model (LLM) applications require long input prompts to perform complex downstream tasks like document analysis and code generation.","For these long context length applications, the length of the input prompt poses a significant challenge in terms of inference efficiency since the inference costs increase linearly with sequence length.","However, for many of these applications, much of the context in the prompt is fixed across different user inputs, thereby providing the opportunity to perform offline optimizations to process user inputs quickly, as they are received.","In this work, we propose Squeezed Attention as a mechanism to accelerate LLM applications where a large portion of the input prompt is fixed.","We first leverage K-means clustering offline to group the keys for the fixed context based on semantic similarity and represent each cluster with a single centroid value.","During inference, we compare query tokens from the user input with the centroids to predict which of the keys from the fixed context are semantically relevant and need to be loaded during inference.","We then compute exact attention using only these important keys from the fixed context, thereby reducing bandwidth and computational costs.","We also extend our method to use a hierarchical centroid lookup to identify important keys, which can reduce the complexity of attention from linear to logarithmic with respect to the context length.","We implement optimized Triton kernels for centroid comparison and sparse FlashAttention with important keys, achieving more than 4x speedups during both the prefill and generation phases for long-context inference.","Furthermore, we have extensively evaluated our method on various long-context benchmarks including LongBench, where it achieves a 3x reduction in KV cache budget without accuracy loss and up to an 8x reduction with <0.5 point accuracy gap for various models."],"url":"http://arxiv.org/abs/2411.09688v1"}
{"created":"2024-11-14 18:52:05","title":"Towards a Classification of Open-Source ML Models and Datasets for Software Engineering","abstract":"Background: Open-Source Pre-Trained Models (PTMs) and datasets provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs. Aims: We apply an SE-oriented classification to PTMs and datasets on a popular open-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs over time. Method: We conducted a repository mining study. We started with a systematically gathered database of PTMs and datasets from the HF API. Our selection was refined by analyzing model and dataset cards and metadata, such as tags, and confirming SE relevance using Gemini 1.5 Pro. All analyses are replicable, with a publicly accessible replication package. Results: The most common SE task among PTMs and datasets is code generation, with a primary focus on software development and limited attention to software management. Popular PTMs and datasets mainly target software development. Among ML tasks, text generation is the most common in SE PTMs and datasets. There has been a marked increase in PTMs for SE since 2023 Q2. Conclusions: This study underscores the need for broader task coverage to enhance the integration of ML within SE practices.","sentences":["Background: Open-Source Pre-Trained Models (PTMs) and datasets provide extensive resources for various Machine Learning (ML) tasks, yet these resources lack a classification tailored to Software Engineering (SE) needs.","Aims:","We apply an SE-oriented classification to PTMs and datasets on a popular open-source ML repository, Hugging Face (HF), and analyze the evolution of PTMs over time.","Method: We conducted a repository mining study.","We started with a systematically gathered database of PTMs and datasets from the HF API.","Our selection was refined by analyzing model and dataset cards and metadata, such as tags, and confirming SE relevance using Gemini 1.5 Pro.","All analyses are replicable, with a publicly accessible replication package.","Results:","The most common SE task among PTMs and datasets is code generation, with a primary focus on software development and limited attention to software management.","Popular PTMs and datasets mainly target software development.","Among ML tasks, text generation is the most common in SE PTMs and datasets.","There has been a marked increase in PTMs for SE since 2023 Q2.","Conclusions: This study underscores the need for broader task coverage to enhance the integration of ML within SE practices."],"url":"http://arxiv.org/abs/2411.09683v1"}
{"created":"2024-11-14 18:44:31","title":"NeuralDEM - Real-time Simulation of Industrial Particulate Flows","abstract":"Advancements in computing power have made it possible to numerically simulate large-scale fluid-mechanical and/or particulate systems, many of which are integral to core industrial processes. Among the different numerical methods available, the discrete element method (DEM) provides one of the most accurate representations of a wide range of physical systems involving granular and discontinuous materials. Consequently, DEM has become a widely accepted approach for tackling engineering problems connected to granular flows and powder mechanics. Additionally, DEM can be integrated with grid-based computational fluid dynamics (CFD) methods, enabling the simulation of chemical processes taking place, e.g., in fluidized beds. However, DEM is computationally intensive because of the intrinsic multiscale nature of particulate systems, restricting simulation duration or number of particles. Towards this end, NeuralDEM presents an end-to-end approach to replace slow numerical DEM routines with fast, adaptable deep learning surrogates. NeuralDEM is capable of picturing long-term transport processes across different regimes using macroscopic observables without any reference to microscopic model parameters. First, NeuralDEM treats the Lagrangian discretization of DEM as an underlying continuous field, while simultaneously modeling macroscopic behavior directly as additional auxiliary fields. Second, NeuralDEM introduces multi-branch neural operators scalable to real-time modeling of industrially-sized scenarios - from slow and pseudo-steady to fast and transient. Such scenarios have previously posed insurmountable challenges for deep learning models. Notably, NeuralDEM faithfully models coupled CFD-DEM fluidized bed reactors of 160k CFD cells and 500k DEM particles for trajectories of 28s. NeuralDEM will open many new doors to advanced engineering and much faster process cycles.","sentences":["Advancements in computing power have made it possible to numerically simulate large-scale fluid-mechanical and/or particulate systems, many of which are integral to core industrial processes.","Among the different numerical methods available, the discrete element method (DEM) provides one of the most accurate representations of a wide range of physical systems involving granular and discontinuous materials.","Consequently, DEM has become a widely accepted approach for tackling engineering problems connected to granular flows and powder mechanics.","Additionally, DEM can be integrated with grid-based computational fluid dynamics (CFD) methods, enabling the simulation of chemical processes taking place, e.g., in fluidized beds.","However, DEM is computationally intensive because of the intrinsic multiscale nature of particulate systems, restricting simulation duration or number of particles.","Towards this end, NeuralDEM presents an end-to-end approach to replace slow numerical DEM routines with fast, adaptable deep learning surrogates.","NeuralDEM is capable of picturing long-term transport processes across different regimes using macroscopic observables without any reference to microscopic model parameters.","First, NeuralDEM treats the Lagrangian discretization of DEM as an underlying continuous field, while simultaneously modeling macroscopic behavior directly as additional auxiliary fields.","Second, NeuralDEM introduces multi-branch neural operators scalable to real-time modeling of industrially-sized scenarios - from slow and pseudo-steady to fast and transient.","Such scenarios have previously posed insurmountable challenges for deep learning models.","Notably, NeuralDEM faithfully models coupled CFD-DEM fluidized bed reactors of 160k CFD cells and 500k DEM particles for trajectories of 28s.","NeuralDEM will open many new doors to advanced engineering and much faster process cycles."],"url":"http://arxiv.org/abs/2411.09678v1"}
{"created":"2024-11-14 18:41:56","title":"Citation Sentiment Reflects Multiscale Sociocultural Norms","abstract":"Modern science is formally structured around scholarly publication, where scientific knowledge is canonized through citation. Precisely how citations are given and accrued can provide information about the value of discovery, the history of scientific ideas, the structure of fields, and the space or scope of inquiry. Yet parsing this information has been challenging because citations are not simply present or absent; rather, they differ in purpose, function, and sentiment. In this paper, we investigate how critical and favorable sentiments are distributed across citations, and demonstrate that citation sentiment tracks sociocultural norms across scales of collaboration, discipline, and country. At the smallest scale of individuals, we find that researchers cite scholars they have collaborated with more favorably (and less critically) than scholars they have not collaborated with. Outside collaborative relationships, higher h-index scholars cite lower h-index scholars more critically. At the mesoscale of disciplines, we find that wetlab disciplines tend to be less critical than drylab disciplines, and disciplines that engage in more synthesis through publishing more review articles tend to be less critical. At the largest scale of countries, we find that greater individualism (and lesser acceptance of the unequal distribution of power) is associated with more critical sentiment. Collectively, our results demonstrate how sociocultural factors can explain variations in sentiment in scientific communication. As such, our study contributes to the broader understanding of how human factors influence the practice of science, and underscore the importance of considering the larger sociocultural contexts in which science progresses.","sentences":["Modern science is formally structured around scholarly publication, where scientific knowledge is canonized through citation.","Precisely how citations are given and accrued can provide information about the value of discovery, the history of scientific ideas, the structure of fields, and the space or scope of inquiry.","Yet parsing this information has been challenging because citations are not simply present or absent; rather, they differ in purpose, function, and sentiment.","In this paper, we investigate how critical and favorable sentiments are distributed across citations, and demonstrate that citation sentiment tracks sociocultural norms across scales of collaboration, discipline, and country.","At the smallest scale of individuals, we find that researchers cite scholars they have collaborated with more favorably (and less critically) than scholars they have not collaborated with.","Outside collaborative relationships, higher h-index scholars cite lower h-index scholars more critically.","At the mesoscale of disciplines, we find that wetlab disciplines tend to be less critical than drylab disciplines, and disciplines that engage in more synthesis through publishing more review articles tend to be less critical.","At the largest scale of countries, we find that greater individualism (and lesser acceptance of the unequal distribution of power) is associated with more critical sentiment.","Collectively, our results demonstrate how sociocultural factors can explain variations in sentiment in scientific communication.","As such, our study contributes to the broader understanding of how human factors influence the practice of science, and underscore the importance of considering the larger sociocultural contexts in which science progresses."],"url":"http://arxiv.org/abs/2411.09675v1"}
{"created":"2024-11-14 18:36:50","title":"Evaluating 5G Networks for U-Space Applications: Insights from Dense Urban Measurement Campaign","abstract":"This paper examines the communication performance of unmanned aerial vehicles (UAVs) in dense urban environments, specifically in Benidorm, Spain. Through a comprehensive measurement campaign, we assessed key performance indicators (KPIs) relating to received signal strength and quality as well as rate across various locations, altitudes, operators, technologies, and frequencies, using different measurement equipment. The results highlight significant challenges, primarily due to the lack of planning for aerial coverage and interference, revealing that current cellular networks may fall short in supporting U-space communication needs. The paper calls for network upgrades to ensure reliable UAV operations in urban airspace, contributing to the integration of UAVS in urban logistics and mobility.","sentences":["This paper examines the communication performance of unmanned aerial vehicles (UAVs) in dense urban environments, specifically in Benidorm, Spain.","Through a comprehensive measurement campaign, we assessed key performance indicators (KPIs) relating to received signal strength and quality as well as rate across various locations, altitudes, operators, technologies, and frequencies, using different measurement equipment.","The results highlight significant challenges, primarily due to the lack of planning for aerial coverage and interference, revealing that current cellular networks may fall short in supporting U-space communication needs.","The paper calls for network upgrades to ensure reliable UAV operations in urban airspace, contributing to the integration of UAVS in urban logistics and mobility."],"url":"http://arxiv.org/abs/2411.09666v1"}
{"created":"2024-11-14 18:31:39","title":"Adaptive Decoding via Latent Preference Optimization","abstract":"During language model decoding, it is known that using higher temperature sampling gives more creative responses, while lower temperatures are more factually accurate. However, such models are commonly applied to general instruction following, which involves both creative and fact seeking tasks, using a single fixed temperature across all examples and tokens. In this work, we introduce Adaptive Decoding, a layer added to the model to select the sampling temperature dynamically at inference time, at either the token or example level, in order to optimize performance. To learn its parameters we introduce Latent Preference Optimization (LPO) a general approach to train discrete latent variables such as choices of temperature. Our method outperforms all fixed decoding temperatures across a range of tasks that require different temperatures, including UltraFeedback, Creative Story Writing, and GSM8K.","sentences":["During language model decoding, it is known that using higher temperature sampling gives more creative responses, while lower temperatures are more factually accurate.","However, such models are commonly applied to general instruction following, which involves both creative and fact seeking tasks, using a single fixed temperature across all examples and tokens.","In this work, we introduce Adaptive Decoding, a layer added to the model to select the sampling temperature dynamically at inference time, at either the token or example level, in order to optimize performance.","To learn its parameters we introduce Latent Preference Optimization (LPO) a general approach to train discrete latent variables such as choices of temperature.","Our method outperforms all fixed decoding temperatures across a range of tasks that require different temperatures, including UltraFeedback, Creative Story Writing, and GSM8K."],"url":"http://arxiv.org/abs/2411.09661v1"}
{"created":"2024-11-14 18:31:16","title":"Capacity and Power Consumption of Multi-Layer 6G Networks Using the Upper Mid-Band","abstract":"This paper presents a new system model to evaluate the capacity and power consumption of multi-layer 6G networks utilising the upper mid-band (FR3). The model captures heteroge- neous 4G, 5G, and 6G deployments, analyzing their performance under different deployment strategies. Our results show that strategic 6G deployments, non-co-located with existing 5G sites, significantly enhance throughput, with median and peak user rates of 300 Mbps and exceeding 1 Gbps, respectively. We also emphasize the importance of priority-based cell reselection and beam configuration to fully leverage 6G capabilities. While 6G implementation increases power consumption by 33%, non-co- located deployments strike a balance between performance and power consumption.","sentences":["This paper presents a new system model to evaluate the capacity and power consumption of multi-layer 6G networks utilising the upper mid-band (FR3).","The model captures heteroge- neous 4G, 5G, and 6G deployments, analyzing their performance under different deployment strategies.","Our results show that strategic 6G deployments, non-co-located with existing 5G sites, significantly enhance throughput, with median and peak user rates of 300 Mbps and exceeding 1 Gbps, respectively.","We also emphasize the importance of priority-based cell reselection and beam configuration to fully leverage 6G capabilities.","While 6G implementation increases power consumption by 33%, non-co- located deployments strike a balance between performance and power consumption."],"url":"http://arxiv.org/abs/2411.09660v1"}
{"created":"2024-11-14 18:29:31","title":"Motion Before Action: Diffusing Object Motion as Manipulation Condition","abstract":"Inferring object motion representations from observations enhances the performance of robotic manipulation tasks. This paper introduces a new paradigm for robot imitation learning that generates action sequences by reasoning about object motion from visual observations. We propose MBA (Motion Before Action), a novel module that employs two cascaded diffusion processes for object motion generation and robot action generation under object motion guidance. MBA first predicts the future pose sequence of the object based on observations, then uses this sequence as a condition to guide robot action generation. Designed as a plug-and-play component, MBA can be flexibly integrated into existing robotic manipulation policies with diffusion action heads. Extensive experiments in both simulated and real-world environments demonstrate that our approach substantially improves the performance of existing policies across a wide range of manipulation tasks.","sentences":["Inferring object motion representations from observations enhances the performance of robotic manipulation tasks.","This paper introduces a new paradigm for robot imitation learning that generates action sequences by reasoning about object motion from visual observations.","We propose MBA (Motion Before Action), a novel module that employs two cascaded diffusion processes for object motion generation and robot action generation under object motion guidance.","MBA first predicts the future pose sequence of the object based on observations, then uses this sequence as a condition to guide robot action generation.","Designed as a plug-and-play component, MBA can be flexibly integrated into existing robotic manipulation policies with diffusion action heads.","Extensive experiments in both simulated and real-world environments demonstrate that our approach substantially improves the performance of existing policies across a wide range of manipulation tasks."],"url":"http://arxiv.org/abs/2411.09658v1"}
{"created":"2024-11-14 18:17:30","title":"Med-Bot: An AI-Powered Assistant to Provide Accurate and Reliable Medical Information","abstract":"This paper introduces Med-Bot, an AI-powered chatbot designed to provide users with accurate and reliable medical information. Utilizing advanced libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq, Med-Bot is built to handle the complexities of natural language understanding in a healthcare context. The integration of llamaassisted data processing and AutoGPT-Q provides enhanced performance in processing and responding to queries based on PDFs of medical literature, ensuring that users receive precise and trustworthy information. This research details the methodologies employed in developing Med-Bot and evaluates its effectiveness in disseminating healthcare information.","sentences":["This paper introduces Med-Bot, an AI-powered chatbot designed to provide users with accurate and reliable medical information.","Utilizing advanced libraries and frameworks such as PyTorch, Chromadb, Langchain and Autogptq, Med-Bot is built to handle the complexities of natural language understanding in a healthcare context.","The integration of llamaassisted data processing and AutoGPT-Q provides enhanced performance in processing and responding to queries based on PDFs of medical literature, ensuring that users receive precise and trustworthy information.","This research details the methodologies employed in developing Med-Bot and evaluates its effectiveness in disseminating healthcare information."],"url":"http://arxiv.org/abs/2411.09648v1"}
{"created":"2024-11-14 18:14:32","title":"How do Machine Learning Models Change?","abstract":"The proliferation of Machine Learning (ML) models and their open-source implementations has transformed Artificial Intelligence research and applications. Platforms like Hugging Face (HF) enable the development, sharing, and deployment of these models, fostering an evolving ecosystem. While previous studies have examined aspects of models hosted on platforms like HF, a comprehensive longitudinal study of how these models change remains underexplored. This study addresses this gap by utilizing both repository mining and longitudinal analysis methods to examine over 200,000 commits and 1,200 releases from over 50,000 models on HF. We replicate and extend an ML change taxonomy for classifying commits and utilize Bayesian networks to uncover patterns in commit and release activities over time. Our findings indicate that commit activities align with established data science methodologies, such as CRISP-DM, emphasizing iterative refinement and continuous improvement. Additionally, release patterns tend to consolidate significant updates, particularly in documentation, distinguishing between granular changes and milestone-based releases. Furthermore, projects with higher popularity prioritize infrastructure enhancements early in their lifecycle, and those with intensive collaboration practices exhibit improved documentation standards. These and other insights enhance the understanding of model changes on community platforms and provide valuable guidance for best practices in model maintenance.","sentences":["The proliferation of Machine Learning (ML) models and their open-source implementations has transformed Artificial Intelligence research and applications.","Platforms like Hugging Face (HF) enable the development, sharing, and deployment of these models, fostering an evolving ecosystem.","While previous studies have examined aspects of models hosted on platforms like HF, a comprehensive longitudinal study of how these models change remains underexplored.","This study addresses this gap by utilizing both repository mining and longitudinal analysis methods to examine over 200,000 commits and 1,200 releases from over 50,000 models on HF.","We replicate and extend an ML change taxonomy for classifying commits and utilize Bayesian networks to uncover patterns in commit and release activities over time.","Our findings indicate that commit activities align with established data science methodologies, such as CRISP-DM, emphasizing iterative refinement and continuous improvement.","Additionally, release patterns tend to consolidate significant updates, particularly in documentation, distinguishing between granular changes and milestone-based releases.","Furthermore, projects with higher popularity prioritize infrastructure enhancements early in their lifecycle, and those with intensive collaboration practices exhibit improved documentation standards.","These and other insights enhance the understanding of model changes on community platforms and provide valuable guidance for best practices in model maintenance."],"url":"http://arxiv.org/abs/2411.09645v1"}
{"created":"2024-11-14 18:10:10","title":"Modular Fault Diagnosis Framework for Complex Autonomous Driving Systems","abstract":"Fault diagnosis is crucial for complex autonomous mobile systems, especially for modern-day autonomous driving (AD). Different actors, numerous use cases, and complex heterogeneous components motivate a fault diagnosis of the system and overall system integrity. AD systems are composed of many heterogeneous components, each with different functionality and possibly using a different algorithm (e.g., rule-based vs. AI components). In addition, these components are subject to the vehicle's driving state and are highly dependent. This paper, therefore, faces this problem by presenting the concept of a modular fault diagnosis framework for AD systems. The concept suggests modular state monitoring and diagnosis elements, together with a state- and dependency-aware aggregation method. Our proposed classification scheme allows for the categorization of the fault diagnosis modules. The concept is implemented on AD shuttle buses and evaluated to demonstrate its capabilities.","sentences":["Fault diagnosis is crucial for complex autonomous mobile systems, especially for modern-day autonomous driving (AD).","Different actors, numerous use cases, and complex heterogeneous components motivate a fault diagnosis of the system and overall system integrity.","AD systems are composed of many heterogeneous components, each with different functionality and possibly using a different algorithm (e.g., rule-based vs. AI components).","In addition, these components are subject to the vehicle's driving state and are highly dependent.","This paper, therefore, faces this problem by presenting the concept of a modular fault diagnosis framework for AD systems.","The concept suggests modular state monitoring and diagnosis elements, together with a state- and dependency-aware aggregation method.","Our proposed classification scheme allows for the categorization of the fault diagnosis modules.","The concept is implemented on AD shuttle buses and evaluated to demonstrate its capabilities."],"url":"http://arxiv.org/abs/2411.09643v1"}
{"created":"2024-11-14 18:06:55","title":"On the Limits of Language Generation: Trade-Offs Between Hallucination and Mode Collapse","abstract":"Specifying all desirable properties of a language model is challenging, but certain requirements seem essential. Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness. Otherwise, outputting invalid strings constitutes \"hallucination,\" and failing to capture the full range leads to \"mode collapse.\" We ask if a language model can meet both requirements.   We investigate this within a statistical language generation setting building on Gold and Angluin. Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages. The goal is to generate unseen strings from K. We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K.   Kleinberg and Mullainathan [KM24] asked if consistency and breadth in language generation are possible. We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages. This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages. Our finding highlights that generation with breadth fundamentally differs from generation without breadth.   As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth.   Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones. This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse.","sentences":["Specifying all desirable properties of a language model is challenging, but certain requirements seem essential.","Given samples from an unknown language, the trained model should produce valid strings not seen in training and be expressive enough to capture the language's full richness.","Otherwise, outputting invalid strings constitutes \"hallucination,\" and failing to capture the full range leads to \"mode collapse.\"","We ask if a language model can meet both requirements.   ","We investigate this within a statistical language generation setting building on Gold and Angluin.","Here, the model receives random samples from a distribution over an unknown language K, which belongs to a possibly infinite collection of languages.","The goal is to generate unseen strings from K.","We say the model generates from K with consistency and breadth if, as training size increases, its output converges to all unseen strings in K.   Kleinberg and Mullainathan","[KM24] asked if consistency and breadth in language generation are possible.","We answer this negatively: for a large class of language models, including next-token prediction models, this is impossible for most collections of candidate languages.","This contrasts with [KM24]'s result, showing consistent generation without breadth is possible for any countable collection of languages.","Our finding highlights that generation with breadth fundamentally differs from generation without breadth.   ","As a byproduct, we establish near-tight bounds on the number of samples needed for generation with or without breadth.   ","Finally, our results offer hope: consistent generation with breadth is achievable for any countable collection of languages when negative examples (strings outside K) are available alongside positive ones.","This suggests that post-training feedback, which encodes negative examples, can be crucial in reducing hallucinations while limiting mode collapse."],"url":"http://arxiv.org/abs/2411.09642v1"}
{"created":"2024-11-14 18:03:44","title":"MCCE: Missingness-aware Causal Concept Explainer","abstract":"Causal concept effect estimation is gaining increasing interest in the field of interpretable machine learning. This general approach explains the behaviors of machine learning models by estimating the causal effect of human-understandable concepts, which represent high-level knowledge more comprehensibly than raw inputs like tokens. However, existing causal concept effect explanation methods assume complete observation of all concepts involved within the dataset, which can fail in practice due to incomplete annotations or missing concept data. We theoretically demonstrate that unobserved concepts can bias the estimation of the causal effects of observed concepts. To address this limitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE), a novel framework specifically designed to estimate causal concept effects when not all concepts are observable. Our framework learns to account for residual bias resulting from missing concepts and utilizes a linear predictor to model the relationships between these concepts and the outputs of black-box machine learning models. It can offer explanations on both local and global levels. We conduct validations using a real-world dataset, demonstrating that MCCE achieves promising performance compared to state-of-the-art explanation methods in causal concept effect estimation.","sentences":["Causal concept effect estimation is gaining increasing interest in the field of interpretable machine learning.","This general approach explains the behaviors of machine learning models by estimating the causal effect of human-understandable concepts, which represent high-level knowledge more comprehensibly than raw inputs like tokens.","However, existing causal concept effect explanation methods assume complete observation of all concepts involved within the dataset, which can fail in practice due to incomplete annotations or missing concept data.","We theoretically demonstrate that unobserved concepts can bias the estimation of the causal effects of observed concepts.","To address this limitation, we introduce the Missingness-aware Causal Concept Explainer (MCCE), a novel framework specifically designed to estimate causal concept effects when not all concepts are observable.","Our framework learns to account for residual bias resulting from missing concepts and utilizes a linear predictor to model the relationships between these concepts and the outputs of black-box machine learning models.","It can offer explanations on both local and global levels.","We conduct validations using a real-world dataset, demonstrating that MCCE achieves promising performance compared to state-of-the-art explanation methods in causal concept effect estimation."],"url":"http://arxiv.org/abs/2411.09639v1"}
{"created":"2024-11-14 17:54:43","title":"One-Shot Manipulation Strategy Learning by Making Contact Analogies","abstract":"We present a novel approach, MAGIC (manipulation analogies for generalizable intelligent contacts), for one-shot learning of manipulation strategies with fast and extensive generalization to novel objects. By leveraging a reference action trajectory, MAGIC effectively identifies similar contact points and sequences of actions on novel objects to replicate a demonstrated strategy, such as using different hooks to retrieve distant objects of different shapes and sizes. Our method is based on a two-stage contact-point matching process that combines global shape matching using pretrained neural features with local curvature analysis to ensure precise and physically plausible contact points. We experiment with three tasks including scooping, hanging, and hooking objects. MAGIC demonstrates superior performance over existing methods, achieving significant improvements in runtime speed and generalization to different object categories. Website: https://magic-2024.github.io/ .","sentences":["We present a novel approach, MAGIC (manipulation analogies for generalizable intelligent contacts), for one-shot learning of manipulation strategies with fast and extensive generalization to novel objects.","By leveraging a reference action trajectory, MAGIC effectively identifies similar contact points and sequences of actions on novel objects to replicate a demonstrated strategy, such as using different hooks to retrieve distant objects of different shapes and sizes.","Our method is based on a two-stage contact-point matching process that combines global shape matching using pretrained neural features with local curvature analysis to ensure precise and physically plausible contact points.","We experiment with three tasks including scooping, hanging, and hooking objects.","MAGIC demonstrates superior performance over existing methods, achieving significant improvements in runtime speed and generalization to different object categories.","Website: https://magic-2024.github.io/ ."],"url":"http://arxiv.org/abs/2411.09627v1"}
{"created":"2024-11-14 17:49:27","title":"Local deployment of large-scale music AI models on commodity hardware","abstract":"We present the MIDInfinite, a web application capable of generating symbolic music using a large-scale generative AI model locally on commodity hardware. Creating this demo involved porting the Anticipatory Music Transformer, a large language model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine Learning Compilation (MLC) framework. Once the model is ported, MLC facilitates inference on a variety of runtimes including C++, mobile, and the browser. We envision that MLC has the potential to bridge the gap between the landscape of increasingly capable music AI models and technology more familiar to music software developers. As a proof of concept, we build a web application that allows users to generate endless streams of multi-instrumental MIDI in the browser, either from scratch or conditioned on a prompt. On commodity hardware (an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster than real-time playback for 72.9% of generations, and increases to 86.3% with 2 seconds of upfront buffering.","sentences":["We present the MIDInfinite, a web application capable of generating symbolic music using a large-scale generative AI model locally on commodity hardware.","Creating this demo involved porting the Anticipatory Music Transformer, a large language model (LLM) pre-trained on the Lakh MIDI dataset, to the Machine Learning Compilation (MLC) framework.","Once the model is ported, MLC facilitates inference on a variety of runtimes including C++, mobile, and the browser.","We envision that MLC has the potential to bridge the gap between the landscape of increasingly capable music AI models and technology more familiar to music software developers.","As a proof of concept, we build a web application that allows users to generate endless streams of multi-instrumental MIDI in the browser, either from scratch or conditioned on a prompt.","On commodity hardware (an M3 Macbook Pro), our demo can generate 51 notes per second, which is faster than real-time playback for 72.9% of generations, and increases to 86.3% with 2 seconds of upfront buffering."],"url":"http://arxiv.org/abs/2411.09625v1"}
{"created":"2024-11-14 17:47:54","title":"Vision-based Manipulation of Transparent Plastic Bags in Industrial Setups","abstract":"This paper addresses the challenges of vision-based manipulation for autonomous cutting and unpacking of transparent plastic bags in industrial setups, aligning with the Industry 4.0 paradigm. Industry 4.0, driven by data, connectivity, analytics, and robotics, promises enhanced accessibility and sustainability throughout the value chain. The integration of autonomous systems, including collaborative robots (cobots), into industrial processes is pivotal for efficiency and safety. The proposed solution employs advanced Machine Learning algorithms, particularly Convolutional Neural Networks (CNNs), to identify transparent plastic bags under varying lighting and background conditions. Tracking algorithms and depth sensing technologies are utilized for 3D spatial awareness during pick and placement. The system addresses challenges in grasping and manipulation, considering optimal points, compliance control with vacuum gripping technology, and real-time automation for safe interaction in dynamic environments. The system's successful testing and validation in the lab with the FRANKA robot arm, showcases its potential for widespread industrial applications, while demonstrating effectiveness in automating the unpacking and cutting of transparent plastic bags for an 8-stack bulk-loader based on specific requirements and rigorous testing.","sentences":["This paper addresses the challenges of vision-based manipulation for autonomous cutting and unpacking of transparent plastic bags in industrial setups, aligning with the Industry 4.0 paradigm.","Industry 4.0, driven by data, connectivity, analytics, and robotics, promises enhanced accessibility and sustainability throughout the value chain.","The integration of autonomous systems, including collaborative robots (cobots), into industrial processes is pivotal for efficiency and safety.","The proposed solution employs advanced Machine Learning algorithms, particularly Convolutional Neural Networks (CNNs), to identify transparent plastic bags under varying lighting and background conditions.","Tracking algorithms and depth sensing technologies are utilized for 3D spatial awareness during pick and placement.","The system addresses challenges in grasping and manipulation, considering optimal points, compliance control with vacuum gripping technology, and real-time automation for safe interaction in dynamic environments.","The system's successful testing and validation in the lab with the FRANKA robot arm, showcases its potential for widespread industrial applications, while demonstrating effectiveness in automating the unpacking and cutting of transparent plastic bags for an 8-stack bulk-loader based on specific requirements and rigorous testing."],"url":"http://arxiv.org/abs/2411.09623v1"}
{"created":"2024-11-14 17:39:23","title":"Hardness Amplification via Group Theory","abstract":"We employ techniques from group theory to show that, in many cases, counting problems on graphs are almost as hard to solve in a small number of instances as they are in all instances. Specifically, we show the following results.   1. Goldreich (2020) asks if, for every constant $\\delta < 1 / 2$, there is an $\\tilde{O} \\left( n^2 \\right)$-time randomized reduction from computing the number of $k$-cliques modulo $2$ with a success probability of greater than $2 / 3$ to computing the number of $k$-cliques modulo $2$ with an error probability of at most $\\delta$.   In this work, we show that for almost all choices of the $\\delta 2^{n \\choose 2}$ corrupt answers within the average-case solver, we have a reduction taking $\\tilde{O} \\left( n^2 \\right)$-time and tolerating an error probability of $\\delta$ in the average-case solver for any constant $\\delta < 1 / 2$. By \"almost all\", we mean that if we choose, with equal probability, any subset $S \\subset \\{0,1\\}^{n \\choose 2}$ with $|S| = \\delta2^{n \\choose 2}$, then with a probability of $1-2^{-\\Omega \\left( n^2 \\right)}$, we can use an average-case solver corrupt on $S$ to obtain a probabilistic algorithm.   2. Inspired by the work of Goldreich and Rothblum in FOCS 2018 to take the weighted versions of the graph counting problems, we prove that if the RETH is true, then for a prime $p = \\Theta \\left( 2^n \\right)$, the problem of counting the number of unique Hamiltonian cycles modulo $p$ on $n$-vertex directed multigraphs and the problem of counting the number of unique half-cliques modulo $p$ on $n$-vertex undirected multigraphs, both require exponential time to compute correctly on even a $1 / 2^{n/\\log n}$-fraction of instances. Meanwhile, simply printing $0$ on all inputs is correct on at least a $\\Omega \\left( 1 / 2^n \\right)$-fraction of instances.","sentences":["We employ techniques from group theory to show that, in many cases, counting problems on graphs are almost as hard to solve in a small number of instances as they are in all instances.","Specifically, we show the following results.   ","1.","Goldreich (2020) asks if, for every constant $\\delta < 1 / 2$, there is an $\\tilde{O} \\left( n^2 \\right)$-time randomized reduction from computing the number of $k$-cliques modulo $2$ with a success probability of greater than $2 / 3$ to computing the number of $k$-cliques modulo $2$ with an error probability of at most $\\delta$.   ","In this work, we show that for almost all choices of the $\\delta 2^{n \\choose 2}$ corrupt answers within the average-case solver, we have a reduction taking $\\tilde{O} \\left( n^2 \\right)$-time and tolerating an error probability of $\\delta$ in the average-case solver for any constant $\\delta < 1 / 2$. By \"almost all\", we mean that if we choose, with equal probability, any subset $S \\subset \\{0,1\\}^{n \\choose 2}$ with $|S| = \\delta2^{n \\choose 2}$, then with a probability of $1-2^{-\\Omega \\left( n^2 \\right)}$, we can use an average-case solver corrupt on $S$ to obtain a probabilistic algorithm.   ","2. Inspired by the work of Goldreich and Rothblum in FOCS 2018 to take the weighted versions of the graph counting problems, we prove that if the RETH is true, then for a prime $p = \\Theta \\left( 2^n \\right)$, the problem of counting the number of unique Hamiltonian cycles modulo $p$ on $n$-vertex directed multigraphs and the problem of counting the number of unique half-cliques modulo $p$ on $n$-vertex undirected multigraphs, both require exponential time to compute correctly on even a $1 / 2^{n/\\log n}$-fraction of instances.","Meanwhile, simply printing $0$ on all inputs is correct on at least a $\\Omega \\left( 1 / 2^n \\right)$-fraction of instances."],"url":"http://arxiv.org/abs/2411.09619v1"}
{"created":"2024-11-14 17:33:36","title":"PTR: Precision-Driven Tool Recommendation for Large Language Models","abstract":"By augmenting Large Language Models (LLMs) with external tools, their capacity to solve complex problems has been significantly enhanced. However, despite ongoing advancements in the parsing capabilities of LLMs, incorporating all available tools simultaneously in the prompt remains impractical due to the vast number of external tools. Consequently, it is essential to provide LLMs with a precise set of tools tailored to the specific task, considering both quantity and quality. Current tool retrieval methods primarily focus on refining the ranking list of tools and directly packaging a fixed number of top-ranked tools as the tool set. However, these approaches often fail to equip LLMs with the optimal set of tools prior to execution, since the optimal number of tools for different tasks could be different, resulting in inefficiencies such as redundant or unsuitable tools, which impede immediate access to the most relevant tools. This paper addresses the challenge of recommending precise toolsets for LLMs. We introduce the problem of tool recommendation, define its scope, and propose a novel Precision-driven Tool Recommendation (PTR) approach. PTR captures an initial, concise set of tools by leveraging historical tool bundle usage and dynamically adjusts the tool set by performing tool matching, culminating in a multi-view-based tool addition. Additionally, we present a new dataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness of tool recommendation for LLMs. We further validate our design choices through comprehensive experiments, demonstrating promising accuracy across two open benchmarks and our RecTools dataset.","sentences":["By augmenting Large Language Models (LLMs) with external tools, their capacity to solve complex problems has been significantly enhanced.","However, despite ongoing advancements in the parsing capabilities of LLMs, incorporating all available tools simultaneously in the prompt remains impractical due to the vast number of external tools.","Consequently, it is essential to provide LLMs with a precise set of tools tailored to the specific task, considering both quantity and quality.","Current tool retrieval methods primarily focus on refining the ranking list of tools and directly packaging a fixed number of top-ranked tools as the tool set.","However, these approaches often fail to equip LLMs with the optimal set of tools prior to execution, since the optimal number of tools for different tasks could be different, resulting in inefficiencies such as redundant or unsuitable tools, which impede immediate access to the most relevant tools.","This paper addresses the challenge of recommending precise toolsets for LLMs.","We introduce the problem of tool recommendation, define its scope, and propose a novel Precision-driven Tool Recommendation (PTR) approach.","PTR captures an initial, concise set of tools by leveraging historical tool bundle usage and dynamically adjusts the tool set by performing tool matching, culminating in a multi-view-based tool addition.","Additionally, we present a new dataset, RecTools, and a metric, TRACC, designed to evaluate the effectiveness of tool recommendation for LLMs.","We further validate our design choices through comprehensive experiments, demonstrating promising accuracy across two open benchmarks and our RecTools dataset."],"url":"http://arxiv.org/abs/2411.09613v1"}
{"created":"2024-11-14 17:32:03","title":"The Moral Foundations Weibo Corpus","abstract":"Moral sentiments expressed in natural language significantly influence both online and offline environments, shaping behavioral styles and interaction patterns, including social media selfpresentation, cyberbullying, adherence to social norms, and ethical decision-making. To effectively measure moral sentiments in natural language processing texts, it is crucial to utilize large, annotated datasets that provide nuanced understanding for accurate analysis and modeltraining. However, existing corpora, while valuable, often face linguistic limitations. To address this gap in the Chinese language domain,we introduce the Moral Foundation Weibo Corpus. This corpus consists of 25,671 Chinese comments on Weibo, encompassing six diverse topic areas. Each comment is manually annotated by at least three systematically trained annotators based on ten moral categories derived from a grounded theory of morality. To assess annotator reliability, we present the kappa testresults, a gold standard for measuring consistency. Additionally, we apply several the latest large language models to supplement the manual annotations, conducting analytical experiments to compare their performance and report baseline results for moral sentiment classification.","sentences":["Moral sentiments expressed in natural language significantly influence both online and offline environments, shaping behavioral styles and interaction patterns, including social media selfpresentation, cyberbullying, adherence to social norms, and ethical decision-making.","To effectively measure moral sentiments in natural language processing texts, it is crucial to utilize large, annotated datasets that provide nuanced understanding for accurate analysis and modeltraining.","However, existing corpora, while valuable, often face linguistic limitations.","To address this gap in the Chinese language domain,we introduce the Moral Foundation Weibo Corpus.","This corpus consists of 25,671 Chinese comments on Weibo, encompassing six diverse topic areas.","Each comment is manually annotated by at least three systematically trained annotators based on ten moral categories derived from a grounded theory of morality.","To assess annotator reliability, we present the kappa testresults, a gold standard for measuring consistency.","Additionally, we apply several the latest large language models to supplement the manual annotations, conducting analytical experiments to compare their performance and report baseline results for moral sentiment classification."],"url":"http://arxiv.org/abs/2411.09612v1"}
{"created":"2024-11-14 17:25:43","title":"Initial Nugget Evaluation Results for the TREC 2024 RAG Track with the AutoNuggetizer Framework","abstract":"This report provides an initial look at partial results from the TREC 2024 Retrieval-Augmented Generation (RAG) Track. We have identified RAG evaluation as a barrier to continued progress in information access (and more broadly, natural language processing and artificial intelligence), and it is our hope that we can contribute to tackling the many challenges in this space. The central hypothesis we explore in this work is that the nugget evaluation methodology, originally developed for the TREC Question Answering Track in 2003, provides a solid foundation for evaluating RAG systems. As such, our efforts have focused on \"refactoring\" this methodology, specifically applying large language models to both automatically create nuggets and to automatically assign nuggets to system answers. We call this the AutoNuggetizer framework. Within the TREC setup, we are able to calibrate our fully automatic process against a manual process whereby nuggets are created by human assessors semi-manually and then assigned manually to system answers. Based on initial results across 21 topics from 45 runs, we observe a strong correlation between scores derived from a fully automatic nugget evaluation and a (mostly) manual nugget evaluation by human assessors. This suggests that our fully automatic evaluation process can be used to guide future iterations of RAG systems.","sentences":["This report provides an initial look at partial results from the TREC 2024 Retrieval-Augmented Generation (RAG) Track.","We have identified RAG evaluation as a barrier to continued progress in information access (and more broadly, natural language processing and artificial intelligence), and it is our hope that we can contribute to tackling the many challenges in this space.","The central hypothesis we explore in this work is that the nugget evaluation methodology, originally developed for the TREC Question Answering Track in 2003, provides a solid foundation for evaluating RAG systems.","As such, our efforts have focused on \"refactoring\" this methodology, specifically applying large language models to both automatically create nuggets and to automatically assign nuggets to system answers.","We call this the AutoNuggetizer framework.","Within the TREC setup, we are able to calibrate our fully automatic process against a manual process whereby nuggets are created by human assessors semi-manually and then assigned manually to system answers.","Based on initial results across 21 topics from 45 runs, we observe a strong correlation between scores derived from a fully automatic nugget evaluation and a (mostly) manual nugget evaluation by human assessors.","This suggests that our fully automatic evaluation process can be used to guide future iterations of RAG systems."],"url":"http://arxiv.org/abs/2411.09607v1"}
{"created":"2024-11-14 17:22:16","title":"Local-Global Attention: An Adaptive Mechanism for Multi-Scale Feature Integration","abstract":"In recent years, attention mechanisms have significantly enhanced the performance of object detection by focusing on key feature information. However, prevalent methods still encounter difficulties in effectively balancing local and global features. This imbalance hampers their ability to capture both fine-grained details and broader contextual information-two critical elements for achieving accurate object detection.To address these challenges, we propose a novel attention mechanism, termed Local-Global Attention, which is designed to better integrate both local and global contextual features. Specifically, our approach combines multi-scale convolutions with positional encoding, enabling the model to focus on local details while concurrently considering the broader global context. Additionally, we introduce a learnable parameters, which allow the model to dynamically adjust the relative importance of local and global attention, depending on the specific requirements of the task, thereby optimizing feature representations across multiple scales.We have thoroughly evaluated the Local-Global Attention mechanism on several widely used object detection and classification datasets. Our experimental results demonstrate that this approach significantly enhances the detection of objects at various scales, with particularly strong performance on multi-class and small object detection tasks. In comparison to existing attention mechanisms, Local-Global Attention consistently outperforms them across several key metrics, all while maintaining computational efficiency.","sentences":["In recent years, attention mechanisms have significantly enhanced the performance of object detection by focusing on key feature information.","However, prevalent methods still encounter difficulties in effectively balancing local and global features.","This imbalance hampers their ability to capture both fine-grained details and broader contextual information-two critical elements for achieving accurate object detection.","To address these challenges, we propose a novel attention mechanism, termed Local-Global Attention, which is designed to better integrate both local and global contextual features.","Specifically, our approach combines multi-scale convolutions with positional encoding, enabling the model to focus on local details while concurrently considering the broader global context.","Additionally, we introduce a learnable parameters, which allow the model to dynamically adjust the relative importance of local and global attention, depending on the specific requirements of the task, thereby optimizing feature representations across multiple scales.","We have thoroughly evaluated the Local-Global Attention mechanism on several widely used object detection and classification datasets.","Our experimental results demonstrate that this approach significantly enhances the detection of objects at various scales, with particularly strong performance on multi-class and small object detection tasks.","In comparison to existing attention mechanisms, Local-Global Attention consistently outperforms them across several key metrics, all while maintaining computational efficiency."],"url":"http://arxiv.org/abs/2411.09604v1"}
{"created":"2024-11-14 17:22:11","title":"Smart Automation in Luxury Leather Shoe Polishing: A Human Centric Robotic Approach","abstract":"The polishing of luxury leather shoes is a delicate, labor intensive process traditionally performed by skilled craftsmen. Footwear companies aim to automate parts of this process to enhance quality, productivity, and operator well-being, but the unique nature of luxury shoe production presents challenges. This paper introduces a solution involving a collaborative robotic cell to assist in shoe polishing. A collaborative robotic manipulator, equipped with a specialized tool and governed by force control, executes the polishing tasks. Key factors such as trajectory design, applied force, polishing speed, and polish amount were analyzed. Polishing trajectories are designed using CAM software and transferred to the robot control system. Human operators design the process, supervise the robot, and perform final finishing, ensuring their expertise is integral to achieving quality. Extensive testing on various shoe models showed significant improvements in quality and reliability, leading to successful implementation on an industrial production line.","sentences":["The polishing of luxury leather shoes is a delicate, labor intensive process traditionally performed by skilled craftsmen.","Footwear companies aim to automate parts of this process to enhance quality, productivity, and operator well-being, but the unique nature of luxury shoe production presents challenges.","This paper introduces a solution involving a collaborative robotic cell to assist in shoe polishing.","A collaborative robotic manipulator, equipped with a specialized tool and governed by force control, executes the polishing tasks.","Key factors such as trajectory design, applied force, polishing speed, and polish amount were analyzed.","Polishing trajectories are designed using CAM software and transferred to the robot control system.","Human operators design the process, supervise the robot, and perform final finishing, ensuring their expertise is integral to achieving quality.","Extensive testing on various shoe models showed significant improvements in quality and reliability, leading to successful implementation on an industrial production line."],"url":"http://arxiv.org/abs/2411.09603v1"}
{"created":"2024-11-14 17:21:02","title":"Accelerating Knowledge Graph and Ontology Engineering with Large Language Models","abstract":"Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance.","sentences":["Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation.","We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance."],"url":"http://arxiv.org/abs/2411.09601v1"}
{"created":"2024-11-14 17:18:24","title":"Latency Optimization in LEO Satellite Communications with Hybrid Beam Pattern and Interference Control","abstract":"The rapid advancement of low Earth orbit (LEO) satellite communication systems has significantly enhanced global connectivity, offering high-capacity, low-latency services crucial for next-generation applications. However, the dense configuration of LEO constellations poses challenges in resource allocation optimization and interference management, complicating coexistence with other communication systems. To address these limitations, this paper proposes a novel framework for optimizing the beam scheduling and resource allocation in multi-beam LEO systems. To satisfy the uneven terrestrial traffic demand, a hybrid beam pattern is employed to enhance the downlink quality of service and minimize the transmission latency from LEO satellites to ground user terminals. Additionally, a dynamic co-channel interference (CCI) control mechanism is developed to mitigate inter-beam interference within the LEO constellation and limit cross-system interference affecting protected users from other networks. The problem of user-beam-frequency allocation with power optimization is formulated as a mixed-integer dynamic programming model and solved using a low-complexity neural network-based graph generation algorithm. Simulation results show that the proposed approach outperforms the baseline methods of full frequency reuse and single-channel transmission, and highlights the potential for further performance improvement with multi-user transmissions.","sentences":["The rapid advancement of low Earth orbit (LEO) satellite communication systems has significantly enhanced global connectivity, offering high-capacity, low-latency services crucial for next-generation applications.","However, the dense configuration of LEO constellations poses challenges in resource allocation optimization and interference management, complicating coexistence with other communication systems.","To address these limitations, this paper proposes a novel framework for optimizing the beam scheduling and resource allocation in multi-beam LEO systems.","To satisfy the uneven terrestrial traffic demand, a hybrid beam pattern is employed to enhance the downlink quality of service and minimize the transmission latency from LEO satellites to ground user terminals.","Additionally, a dynamic co-channel interference (CCI) control mechanism is developed to mitigate inter-beam interference within the LEO constellation and limit cross-system interference affecting protected users from other networks.","The problem of user-beam-frequency allocation with power optimization is formulated as a mixed-integer dynamic programming model and solved using a low-complexity neural network-based graph generation algorithm.","Simulation results show that the proposed approach outperforms the baseline methods of full frequency reuse and single-channel transmission, and highlights the potential for further performance improvement with multi-user transmissions."],"url":"http://arxiv.org/abs/2411.09600v1"}
{"created":"2024-11-14 17:15:08","title":"Rare-Case Hard Functions Against Various Adversaries","abstract":"We say that a function is rare-case hard against a given class of algorithms (the adversary) if all algorithms in the class can compute the function only on an $o(1)$-fraction of instances of size $n$ for large enough $n$. Starting from any NP-complete language, for each $k > 0$, we construct a function that cannot be computed correctly on even a $1/n^k$-fraction of instances for polynomial-sized circuit families if NP $\\not \\subset$ P/POLY and by polynomial-time algorithms if NP $\\not \\subset$ BPP - functions that are rare-case hard against polynomial-time algorithms and polynomial-sized circuits. The constructed function is a number-theoretic polynomial evaluated over specific finite fields. For NP-complete languages that admit parsimonious reductions from all of NP (for example, SAT), the constructed functions are hard to compute on even a $1/n^k$-fraction of instances by polynomial-time algorithms and polynomial-sized circuit families simply if $P^{\\#P} \\not \\subset$ BPP and $P^{\\#P} \\not \\subset$ P/POLY, respectively. We also show that if the Randomized Exponential Time Hypothesis (RETH) is true, none of these constructed functions can be computed on even a $1/n^k$-fraction of instances in subexponential time. These functions are very hard, almost always.   While one may not be able to efficiently compute the values of these constructed functions themselves, in polynomial time, one can verify that the evaluation of a function, $s = f(x)$, is correct simply by asking a prover to compute $f(y)$ on targeted queries.","sentences":["We say that a function is rare-case hard against a given class of algorithms (the adversary) if all algorithms in the class can compute the function only on an $o(1)$-fraction of instances of size $n$ for large enough $n$. Starting from any NP-complete language, for each $k > 0$, we construct a function that cannot be computed correctly on even a $1/n^k$-fraction of instances for polynomial-sized circuit families if NP $\\not \\subset$ P/POLY and by polynomial-time algorithms if NP $\\not \\subset$ BPP - functions that are rare-case hard against polynomial-time algorithms and polynomial-sized circuits.","The constructed function is a number-theoretic polynomial evaluated over specific finite fields.","For NP-complete languages that admit parsimonious reductions from all of NP (for example, SAT), the constructed functions are hard to compute on even a $1/n^k$-fraction of instances by polynomial-time algorithms and polynomial-sized circuit families simply if $P^{\\#P} \\not \\subset$ BPP and $P^{\\#P} \\not \\subset$ P/POLY, respectively.","We also show that if the Randomized Exponential Time Hypothesis (RETH) is true, none of these constructed functions can be computed on even a $1/n^k$-fraction of instances in subexponential time.","These functions are very hard, almost always.   ","While one may not be able to efficiently compute the values of these constructed functions themselves, in polynomial time, one can verify that the evaluation of a function, $s = f(x)$, is correct simply by asking a prover to compute $f(y)$ on targeted queries."],"url":"http://arxiv.org/abs/2411.09597v1"}
{"created":"2024-11-14 17:08:23","title":"LLaMA-Mesh: Unifying 3D Mesh Generation with Language Models","abstract":"This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model. This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling conversational 3D generation and mesh understanding. A primary challenge is effectively tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly. To address this, we introduce LLaMA-Mesh, a novel approach that represents the vertex coordinates and face definitions of 3D meshes as plain text, allowing direct integration with LLMs without expanding the vocabulary. We construct a supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate 3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs as required, and (3) understand and interpret 3D meshes. Our work is the first to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge for 3D mesh generation in a text-based format, effectively unifying the 3D and text modalities. LLaMA-Mesh achieves mesh generation quality on par with models trained from scratch while maintaining strong text generation performance.","sentences":["This work explores expanding the capabilities of large language models (LLMs) pretrained on text to generate 3D meshes within a unified model.","This offers key advantages of (1) leveraging spatial knowledge already embedded in LLMs, derived from textual sources like 3D tutorials, and (2) enabling conversational 3D generation and mesh understanding.","A primary challenge is effectively tokenizing 3D mesh data into discrete tokens that LLMs can process seamlessly.","To address this, we introduce LLaMA-Mesh, a novel approach that represents the vertex coordinates and face definitions of 3D meshes as plain text, allowing direct integration with LLMs without expanding the vocabulary.","We construct a supervised fine-tuning (SFT) dataset enabling pretrained LLMs to (1) generate 3D meshes from text prompts, (2) produce interleaved text and 3D mesh outputs as required, and (3) understand and interpret 3D meshes.","Our work is the first to demonstrate that LLMs can be fine-tuned to acquire complex spatial knowledge for 3D mesh generation in a text-based format, effectively unifying the 3D and text modalities.","LLaMA-Mesh achieves mesh generation quality on par with models trained from scratch while maintaining strong text generation performance."],"url":"http://arxiv.org/abs/2411.09595v1"}
{"created":"2024-11-14 17:02:41","title":"Expert Study on Interpretable Machine Learning Models with Missing Data","abstract":"Inherently interpretable machine learning (IML) models provide valuable insights for clinical decision-making but face challenges when features have missing values. Classical solutions like imputation or excluding incomplete records are often unsuitable in applications where values are missing at test time. In this work, we conducted a survey with 71 clinicians from 29 trauma centers across France, including 20 complete responses to study the interaction between medical professionals and IML applied to data with missing values. This provided valuable insights into how missing data is interpreted in clinical machine learning. We used the prediction of hemorrhagic shock as a concrete example to gauge the willingness and readiness of the participants to adopt IML models from three classes of methods. Our findings show that, while clinicians value interpretability and are familiar with common IML methods, classical imputation techniques often misalign with their intuition, and that models that natively handle missing values are preferred. These results emphasize the need to integrate clinical intuition into future IML models for better human-computer interaction.","sentences":["Inherently interpretable machine learning (IML) models provide valuable insights for clinical decision-making but face challenges when features have missing values.","Classical solutions like imputation or excluding incomplete records are often unsuitable in applications where values are missing at test time.","In this work, we conducted a survey with 71 clinicians from 29 trauma centers across France, including 20 complete responses to study the interaction between medical professionals and IML applied to data with missing values.","This provided valuable insights into how missing data is interpreted in clinical machine learning.","We used the prediction of hemorrhagic shock as a concrete example to gauge the willingness and readiness of the participants to adopt IML models from three classes of methods.","Our findings show that, while clinicians value interpretability and are familiar with common IML methods, classical imputation techniques often misalign with their intuition, and that models that natively handle missing values are preferred.","These results emphasize the need to integrate clinical intuition into future IML models for better human-computer interaction."],"url":"http://arxiv.org/abs/2411.09591v1"}
{"created":"2024-11-14 17:01:24","title":"Adopting RAG for LLM-Aided Future Vehicle Design","abstract":"In this paper, we explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to enhance automated design and software development in the automotive industry. We present two case studies: a standardization compliance chatbot and a design copilot, both utilizing RAG to provide accurate, context-aware responses. We evaluate four LLMs-GPT-4o, LLAMA3, Mistral, and Mixtral- comparing their answering accuracy and execution time. Our results demonstrate that while GPT-4 offers superior performance, LLAMA3 and Mistral also show promising capabilities for local deployment, addressing data privacy concerns in automotive applications. This study highlights the potential of RAG-augmented LLMs in improving design workflows and compliance in automotive engineering.","sentences":["In this paper, we explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) to enhance automated design and software development in the automotive industry.","We present two case studies: a standardization compliance chatbot and a design copilot, both utilizing RAG to provide accurate, context-aware responses.","We evaluate four LLMs-GPT-4o, LLAMA3, Mistral, and Mixtral- comparing their answering accuracy and execution time.","Our results demonstrate that while GPT-4 offers superior performance, LLAMA3 and Mistral also show promising capabilities for local deployment, addressing data privacy concerns in automotive applications.","This study highlights the potential of RAG-augmented LLMs in improving design workflows and compliance in automotive engineering."],"url":"http://arxiv.org/abs/2411.09590v1"}
{"created":"2024-11-14 16:58:19","title":"Spider: Any-to-Many Multimodal LLM","abstract":"Multimodal LLMs (MLLMs) have emerged as an extension of Large Language Models (LLMs), enabling the integration of various modalities. However, Any-to-Any MLLMs are limited to generating pairwise modalities 'Text + X' within a single response, such as Text + {Image or Audio or Video}. To address this limitation, we introduce Spider, a novel efficient Any-to-Many Modalities Generation (AMMG) framework, which can generate an arbitrary combination of modalities 'Text + Xs', such as Text + {Image and Audio and Video}. To achieve efficient AMMG, our Spider integrates three core components: a Base Model for basic X-to-X (i.e., Any-to-Any) modality processing, a novel Efficient Decoders-Controller for controlling multimodal Decoders to generate Xs (many-modal) contents, and an Any-to-Many Instruction Template designed for producing Xs signal prompts. To train Spider, we constructed a novel Text-formatted Many-Modal (TMM) dataset, which facilitates the learning of the X-to-Xs (i.e., Any-to-Many) capability necessary for AMMG. Ultimately, the well-trained Spider generates a pseudo X-to-Xs dataset, the first-ever X-to-Xs many-modal dataset, enhancing the potential for AMMG task in future research. Overall, this work not only pushes the boundary of multimodal interaction but also provides rich data support for advancing the field.","sentences":["Multimodal LLMs (MLLMs) have emerged as an extension of Large Language Models (LLMs), enabling the integration of various modalities.","However, Any-to-Any MLLMs are limited to generating pairwise modalities 'Text + X' within a single response, such as Text + {Image or Audio or Video}.","To address this limitation, we introduce Spider, a novel efficient Any-to-Many Modalities Generation (AMMG) framework, which can generate an arbitrary combination of modalities 'Text + Xs', such as Text + {Image and Audio and Video}.","To achieve efficient AMMG, our Spider integrates three core components: a Base Model for basic X-to-X (i.e., Any-to-Any) modality processing, a novel Efficient Decoders-Controller for controlling multimodal Decoders to generate Xs (many-modal) contents, and an Any-to-Many Instruction Template designed for producing Xs signal prompts.","To train Spider, we constructed a novel Text-formatted Many-Modal (TMM) dataset, which facilitates the learning of the X-to-Xs (i.e., Any-to-Many) capability necessary for AMMG.","Ultimately, the well-trained Spider generates a pseudo X-to-Xs dataset, the first-ever X-to-Xs many-modal dataset, enhancing the potential for AMMG task in future research.","Overall, this work not only pushes the boundary of multimodal interaction but also provides rich data support for advancing the field."],"url":"http://arxiv.org/abs/2411.09439v1"}
{"created":"2024-11-14 16:57:46","title":"BabyLM Challenge: Exploring the Effect of Variation Sets on Language Model Training Efficiency","abstract":"While current large language models have achieved a remarkable success, their data efficiency remains a challenge to overcome. Recently it has been suggested that child-directed speech (CDS) can improve training data efficiency of modern language models based on Transformer neural networks. However, it is not yet understood which specific properties of CDS are effective for training these models. In the context of the BabyLM Challenge, we focus on Variation Sets (VSs), sets of consecutive utterances expressing a similar intent with slightly different words and structures, which are ubiquitous in CDS. To assess the impact of VSs on training data efficiency, we augment CDS data with different proportions of artificial VSs and use these datasets to train an auto-regressive model, GPT-2. We find that the best proportion of VSs depends on the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of VSs, but EWOK scores do not. Additionally, the results vary depending on multiple factors such as the number of epochs and the order of utterance presentation. Taken together, these findings suggest that VSs can have a beneficial influence on language models, while leaving room for further investigation.","sentences":["While current large language models have achieved a remarkable success, their data efficiency remains a challenge to overcome.","Recently it has been suggested that child-directed speech (CDS) can improve training data efficiency of modern language models based on Transformer neural networks.","However, it is not yet understood which specific properties of CDS are effective for training these models.","In the context of the BabyLM Challenge, we focus on Variation Sets (VSs), sets of consecutive utterances expressing a similar intent with slightly different words and structures, which are ubiquitous in CDS.","To assess the impact of VSs on training data efficiency, we augment CDS data with different proportions of artificial VSs and use these datasets to train an auto-regressive model, GPT-2.","We find that the best proportion of VSs depends on the evaluation benchmark: BLiMP and GLUE scores benefit from the presence of VSs, but EWOK scores do not.","Additionally, the results vary depending on multiple factors such as the number of epochs and the order of utterance presentation.","Taken together, these findings suggest that VSs can have a beneficial influence on language models, while leaving room for further investigation."],"url":"http://arxiv.org/abs/2411.09587v1"}
{"created":"2024-11-14 16:54:06","title":"Backdoor Mitigation by Distance-Driven Detoxification","abstract":"Backdoor attacks undermine the integrity of machine learning models by allowing attackers to manipulate predictions using poisoned training data. Such attacks lead to targeted misclassification when specific triggers are present, while the model behaves normally under other conditions. This paper considers a post-training backdoor defense task, aiming to detoxify the backdoors in pre-trained models. We begin by analyzing the underlying issues of vanilla fine-tuning and observe that it is often trapped in regions with low loss for both clean and poisoned samples. Motivated by such observations, we propose Distance-Driven Detoxification (D3), an innovative approach that reformulates backdoor defense as a constrained optimization problem. Specifically, D3 promotes the model's departure from the vicinity of its initial weights, effectively reducing the influence of backdoors. Extensive experiments on state-of-the-art (SOTA) backdoor attacks across various model architectures and datasets demonstrate that D3 not only matches but often surpasses the performance of existing SOTA post-training defense techniques.","sentences":["Backdoor attacks undermine the integrity of machine learning models by allowing attackers to manipulate predictions using poisoned training data.","Such attacks lead to targeted misclassification when specific triggers are present, while the model behaves normally under other conditions.","This paper considers a post-training backdoor defense task, aiming to detoxify the backdoors in pre-trained models.","We begin by analyzing the underlying issues of vanilla fine-tuning and observe that it is often trapped in regions with low loss for both clean and poisoned samples.","Motivated by such observations, we propose Distance-Driven Detoxification (D3), an innovative approach that reformulates backdoor defense as a constrained optimization problem.","Specifically, D3 promotes the model's departure from the vicinity of its initial weights, effectively reducing the influence of backdoors.","Extensive experiments on state-of-the-art (SOTA) backdoor attacks across various model architectures and datasets demonstrate that D3 not only matches but often surpasses the performance of existing SOTA post-training defense techniques."],"url":"http://arxiv.org/abs/2411.09585v1"}
{"created":"2024-11-14 16:42:19","title":"Software Performance Engineering for Foundation Model-Powered Software (FMware)","abstract":"The rise of Foundation Models (FMs) like Large Language Models (LLMs) is revolutionizing software development. Despite the impressive prototypes, transforming FMware into production-ready products demands complex engineering across various domains. A critical but overlooked aspect is performance engineering, which aims at ensuring FMware meets performance goals such as throughput and latency to avoid user dissatisfaction and financial loss. Often, performance considerations are an afterthought, leading to costly optimization efforts post-deployment. FMware's high computational resource demands highlight the need for efficient hardware use. Continuous performance engineering is essential to prevent degradation. This paper highlights the significance of Software Performance Engineering (SPE) in FMware, identifying four key challenges: cognitive architecture design, communication protocols, tuning and optimization, and deployment. These challenges are based on literature surveys and experiences from developing an in-house FMware system. We discuss problems, current practices, and innovative paths for the software engineering community.","sentences":["The rise of Foundation Models (FMs) like Large Language Models (LLMs) is revolutionizing software development.","Despite the impressive prototypes, transforming FMware into production-ready products demands complex engineering across various domains.","A critical but overlooked aspect is performance engineering, which aims at ensuring FMware meets performance goals such as throughput and latency to avoid user dissatisfaction and financial loss.","Often, performance considerations are an afterthought, leading to costly optimization efforts post-deployment.","FMware's high computational resource demands highlight the need for efficient hardware use.","Continuous performance engineering is essential to prevent degradation.","This paper highlights the significance of Software Performance Engineering (SPE) in FMware, identifying four key challenges: cognitive architecture design, communication protocols, tuning and optimization, and deployment.","These challenges are based on literature surveys and experiences from developing an in-house FMware system.","We discuss problems, current practices, and innovative paths for the software engineering community."],"url":"http://arxiv.org/abs/2411.09580v1"}
{"created":"2024-11-14 16:35:17","title":"SimTube: Generating Simulated Video Comments through Multimodal AI and User Personas","abstract":"Audience feedback is crucial for refining video content, yet it typically comes after publication, limiting creators' ability to make timely adjustments. To bridge this gap, we introduce SimTube, a generative AI system designed to simulate audience feedback in the form of video comments before a video's release. SimTube features a computational pipeline that integrates multimodal data from the video-such as visuals, audio, and metadata-with user personas derived from a broad and diverse corpus of audience demographics, generating varied and contextually relevant feedback. Furthermore, the system's UI allows creators to explore and customize the simulated comments. Through a comprehensive evaluation-comprising quantitative analysis, crowd-sourced assessments, and qualitative user studies-we show that SimTube's generated comments are not only relevant, believable, and diverse but often more detailed and informative than actual audience comments, highlighting its potential to help creators refine their content before release.","sentences":["Audience feedback is crucial for refining video content, yet it typically comes after publication, limiting creators' ability to make timely adjustments.","To bridge this gap, we introduce SimTube, a generative AI system designed to simulate audience feedback in the form of video comments before a video's release.","SimTube features a computational pipeline that integrates multimodal data from the video-such as visuals, audio, and metadata-with user personas derived from a broad and diverse corpus of audience demographics, generating varied and contextually relevant feedback.","Furthermore, the system's UI allows creators to explore and customize the simulated comments.","Through a comprehensive evaluation-comprising quantitative analysis, crowd-sourced assessments, and qualitative user studies-we show that SimTube's generated comments are not only relevant, believable, and diverse but often more detailed and informative than actual audience comments, highlighting its potential to help creators refine their content before release."],"url":"http://arxiv.org/abs/2411.09577v1"}
{"created":"2024-11-14 16:35:15","title":"Automating Reformulation of Essence Specifications via Graph Rewriting","abstract":"Formulating an effective constraint model of a parameterised problem class is crucial to the efficiency with which instances of the class can subsequently be solved. It is difficult to know beforehand which of a set of candidate models will perform best in practice. This paper presents a system that employs graph rewriting to reformulate an input model for improved performance automatically. By situating our work in the Essence abstract constraint specification language, we can use the structure in its high level variable types to trigger rewrites directly. We implement our system via rewrite rules expressed in the Graph Programs 2 language, applied to the abstract syntax tree of an input specification. We show how to automatically translate the solution of the reformulated problem into a solution of the original problem for verification and presentation. We demonstrate the efficacy of our system with a detailed case study.","sentences":["Formulating an effective constraint model of a parameterised problem class is crucial to the efficiency with which instances of the class can subsequently be solved.","It is difficult to know beforehand which of a set of candidate models will perform best in practice.","This paper presents a system that employs graph rewriting to reformulate an input model for improved performance automatically.","By situating our work in the Essence abstract constraint specification language, we can use the structure in its high level variable types to trigger rewrites directly.","We implement our system via rewrite rules expressed in the Graph Programs 2 language, applied to the abstract syntax tree of an input specification.","We show how to automatically translate the solution of the reformulated problem into a solution of the original problem for verification and presentation.","We demonstrate the efficacy of our system with a detailed case study."],"url":"http://arxiv.org/abs/2411.09576v1"}
{"created":"2024-11-14 16:29:45","title":"Dynamic Reconstruction of Hand-Object Interaction with Distributed Force-aware Contact Representation","abstract":"We present ViTaM-D, a novel visual-tactile framework for dynamic hand-object interaction reconstruction, integrating distributed tactile sensing for more accurate contact modeling. While existing methods focus primarily on visual inputs, they struggle with capturing detailed contact interactions such as object deformation. Our approach leverages distributed tactile sensors to address this limitation by introducing DF-Field. This distributed force-aware contact representation models both kinetic and potential energy in hand-object interaction. ViTaM-D first reconstructs hand-object interactions using a visual-only network, VDT-Net, and then refines contact details through a force-aware optimization (FO) process, enhancing object deformation modeling. To benchmark our approach, we introduce the HOT dataset, which features 600 sequences of hand-object interactions, including deformable objects, built in a high-precision simulation environment. Extensive experiments on both the DexYCB and HOT datasets demonstrate significant improvements in accuracy over previous state-of-the-art methods such as gSDF and HOTrack. Our results highlight the superior performance of ViTaM-D in both rigid and deformable object reconstruction, as well as the effectiveness of DF-Field in refining hand poses. This work offers a comprehensive solution to dynamic hand-object interaction reconstruction by seamlessly integrating visual and tactile data. Codes, models, and datasets will be available.","sentences":["We present ViTaM-D, a novel visual-tactile framework for dynamic hand-object interaction reconstruction, integrating distributed tactile sensing for more accurate contact modeling.","While existing methods focus primarily on visual inputs, they struggle with capturing detailed contact interactions such as object deformation.","Our approach leverages distributed tactile sensors to address this limitation by introducing DF-Field.","This distributed force-aware contact representation models both kinetic and potential energy in hand-object interaction.","ViTaM-D first reconstructs hand-object interactions using a visual-only network, VDT-Net, and then refines contact details through a force-aware optimization (FO) process, enhancing object deformation modeling.","To benchmark our approach, we introduce the HOT dataset, which features 600 sequences of hand-object interactions, including deformable objects, built in a high-precision simulation environment.","Extensive experiments on both the DexYCB and HOT datasets demonstrate significant improvements in accuracy over previous state-of-the-art methods such as gSDF and HOTrack.","Our results highlight the superior performance of ViTaM-D in both rigid and deformable object reconstruction, as well as the effectiveness of DF-Field in refining hand poses.","This work offers a comprehensive solution to dynamic hand-object interaction reconstruction by seamlessly integrating visual and tactile data.","Codes, models, and datasets will be available."],"url":"http://arxiv.org/abs/2411.09572v1"}
{"created":"2024-11-14 16:21:47","title":"VPBSD:Vessel-Pattern-Based Semi-Supervised Distillation for Efficient 3D Microscopic Cerebrovascular Segmentation","abstract":"3D microscopic cerebrovascular images are characterized by their high resolution, presenting significant annotation challenges, large data volumes, and intricate variations in detail. Together, these factors make achieving high-quality, efficient whole-brain segmentation particularly demanding. In this paper, we propose a novel Vessel-Pattern-Based Semi-Supervised Distillation pipeline (VpbSD) to address the challenges of 3D microscopic cerebrovascular segmentation. This pipeline initially constructs a vessel-pattern codebook that captures diverse vascular structures from unlabeled data during the teacher model's pretraining phase. In the knowledge distillation stage, the codebook facilitates the transfer of rich knowledge from a heterogeneous teacher model to a student model, while the semi-supervised approach further enhances the student model's exposure to diverse learning samples. Experimental results on real-world data, including comparisons with state-of-the-art methods and ablation studies, demonstrate that our pipeline and its individual components effectively address the challenges inherent in microscopic cerebrovascular segmentation.","sentences":["3D microscopic cerebrovascular images are characterized by their high resolution, presenting significant annotation challenges, large data volumes, and intricate variations in detail.","Together, these factors make achieving high-quality, efficient whole-brain segmentation particularly demanding.","In this paper, we propose a novel Vessel-Pattern-Based Semi-Supervised Distillation pipeline (VpbSD) to address the challenges of 3D microscopic cerebrovascular segmentation.","This pipeline initially constructs a vessel-pattern codebook that captures diverse vascular structures from unlabeled data during the teacher model's pretraining phase.","In the knowledge distillation stage, the codebook facilitates the transfer of rich knowledge from a heterogeneous teacher model to a student model, while the semi-supervised approach further enhances the student model's exposure to diverse learning samples.","Experimental results on real-world data, including comparisons with state-of-the-art methods and ablation studies, demonstrate that our pipeline and its individual components effectively address the challenges inherent in microscopic cerebrovascular segmentation."],"url":"http://arxiv.org/abs/2411.09567v1"}
{"created":"2024-11-14 16:16:16","title":"Vlimb: A Wire-Driven Wearable Robot for Bodily Extension, Balancing Powerfulness and Reachability","abstract":"Numerous wearable robots have been developed to meet the demands of physical assistance and entertainment. These wearable robots range from body-enhancing types that assist human arms and legs to body-extending types that have extra arms. This study focuses specifically on wearable robots of the latter category, aimed at bodily extension. However, they have not yet achieved the level of powerfulness and reachability equivalent to that of human limbs, limiting their application to entertainment and manipulation tasks involving lightweight objects. Therefore, in this study, we develop an body-extending wearable robot, Vlimb, which has enough powerfulness to lift a human and can perform manipulation. Leveraging the advantages of tendon-driven mechanisms, Vlimb incorporates a wire routing mechanism capable of accommodating both delicate manipulations and robust lifting tasks. Moreover, by introducing a passive ring structure to overcome the limited reachability inherent in tendon-driven mechanisms, Vlimb achieves both the powerfulness and reachability comparable to that of humans. This paper outlines the design methodology of Vlimb, conducts preliminary manipulation and lifting tasks, and verifies its effectiveness.","sentences":["Numerous wearable robots have been developed to meet the demands of physical assistance and entertainment.","These wearable robots range from body-enhancing types that assist human arms and legs to body-extending types that have extra arms.","This study focuses specifically on wearable robots of the latter category, aimed at bodily extension.","However, they have not yet achieved the level of powerfulness and reachability equivalent to that of human limbs, limiting their application to entertainment and manipulation tasks involving lightweight objects.","Therefore, in this study, we develop an body-extending wearable robot, Vlimb, which has enough powerfulness to lift a human and can perform manipulation.","Leveraging the advantages of tendon-driven mechanisms, Vlimb incorporates a wire routing mechanism capable of accommodating both delicate manipulations and robust lifting tasks.","Moreover, by introducing a passive ring structure to overcome the limited reachability inherent in tendon-driven mechanisms, Vlimb achieves both the powerfulness and reachability comparable to that of humans.","This paper outlines the design methodology of Vlimb, conducts preliminary manipulation and lifting tasks, and verifies its effectiveness."],"url":"http://arxiv.org/abs/2411.09565v1"}
{"created":"2024-11-14 16:10:15","title":"Adaptive Deviation Learning for Visual Anomaly Detection with Data Contamination","abstract":"Visual anomaly detection targets to detect images that notably differ from normal pattern, and it has found extensive application in identifying defective parts within the manufacturing industry. These anomaly detection paradigms predominantly focus on training detection models using only clean, unlabeled normal samples, assuming an absence of contamination; a condition often unmet in real-world scenarios. The performance of these methods significantly depends on the quality of the data and usually decreases when exposed to noise. We introduce a systematic adaptive method that employs deviation learning to compute anomaly scores end-to-end while addressing data contamination by assigning relative importance to the weights of individual instances. In this approach, the anomaly scores for normal instances are designed to approximate scalar scores obtained from the known prior distribution. Meanwhile, anomaly scores for anomaly examples are adjusted to exhibit statistically significant deviations from these reference scores. Our approach incorporates a constrained optimization problem within the deviation learning framework to update instance weights, resolving this problem for each mini-batch. Comprehensive experiments on the MVTec and VisA benchmark datasets indicate that our proposed method surpasses competing techniques and exhibits both stability and robustness in the presence of data contamination.","sentences":["Visual anomaly detection targets to detect images that notably differ from normal pattern, and it has found extensive application in identifying defective parts within the manufacturing industry.","These anomaly detection paradigms predominantly focus on training detection models using only clean, unlabeled normal samples, assuming an absence of contamination; a condition often unmet in real-world scenarios.","The performance of these methods significantly depends on the quality of the data and usually decreases when exposed to noise.","We introduce a systematic adaptive method that employs deviation learning to compute anomaly scores end-to-end while addressing data contamination by assigning relative importance to the weights of individual instances.","In this approach, the anomaly scores for normal instances are designed to approximate scalar scores obtained from the known prior distribution.","Meanwhile, anomaly scores for anomaly examples are adjusted to exhibit statistically significant deviations from these reference scores.","Our approach incorporates a constrained optimization problem within the deviation learning framework to update instance weights, resolving this problem for each mini-batch.","Comprehensive experiments on the MVTec and VisA benchmark datasets indicate that our proposed method surpasses competing techniques and exhibits both stability and robustness in the presence of data contamination."],"url":"http://arxiv.org/abs/2411.09558v1"}
{"created":"2024-11-14 16:07:04","title":"Image Processing for Motion Magnification","abstract":"Motion Magnification (MM) is a collection of relative recent techniques within the realm of Image Processing. The main motivation of introducing these techniques in to support the human visual system to capture relevant displacements of an object of interest; these motions can be in object color and in object location. In fact, the goal is to opportunely process a video sequence to obtain as output a new video in which motions are magnified and visible to the viewer. We propose a numerical technique using the Phase-Based Motion Magnification which analyses the video sequence in the Fourier Domain and rely on the Fourier Shifting Property. We describe the mathematical foundation of this method and the corresponding implementation in a numerical algorithm. We present preliminary experiments, focusing on some basic test made up using synthetic images.","sentences":["Motion Magnification (MM) is a collection of relative recent techniques within the realm of Image Processing.","The main motivation of introducing these techniques in to support the human visual system to capture relevant displacements of an object of interest; these motions can be in object color and in object location.","In fact, the goal is to opportunely process a video sequence to obtain as output a new video in which motions are magnified and visible to the viewer.","We propose a numerical technique using the Phase-Based Motion Magnification which analyses the video sequence in the Fourier Domain and rely on the Fourier Shifting Property.","We describe the mathematical foundation of this method and the corresponding implementation in a numerical algorithm.","We present preliminary experiments, focusing on some basic test made up using synthetic images."],"url":"http://arxiv.org/abs/2411.09555v1"}
{"created":"2024-11-14 16:06:30","title":"OOD-SEG: Out-Of-Distribution detection for image SEGmentation with sparse multi-class positive-only annotations","abstract":"Despite significant advancements, segmentation based on deep neural networks in medical and surgical imaging faces several challenges, two of which we aim to address in this work. First, acquiring complete pixel-level segmentation labels for medical images is time-consuming and requires domain expertise. Second, typical segmentation pipelines cannot detect out-of-distribution (OOD) pixels, leaving them prone to spurious outputs during deployment. In this work, we propose a novel segmentation approach exploiting OOD detection that learns only from sparsely annotated pixels from multiple positive-only classes. %but \\emph{no background class} annotation. These multi-class positive annotations naturally fall within the in-distribution (ID) set. Unlabelled pixels may contain positive classes but also negative ones, including what is typically referred to as \\emph{background} in standard segmentation formulations. Here, we forgo the need for background annotation and consider these together with any other unseen classes as part of the OOD set. Our framework can integrate, at a pixel-level, any OOD detection approaches designed for classification tasks. To address the lack of existing OOD datasets and established evaluation metric for medical image segmentation, we propose a cross-validation strategy that treats held-out labelled classes as OOD. Extensive experiments on both multi-class hyperspectral and RGB surgical imaging datasets demonstrate the robustness and generalisation capability of our proposed framework.","sentences":["Despite significant advancements, segmentation based on deep neural networks in medical and surgical imaging faces several challenges, two of which we aim to address in this work.","First, acquiring complete pixel-level segmentation labels for medical images is time-consuming and requires domain expertise.","Second, typical segmentation pipelines cannot detect out-of-distribution (OOD) pixels, leaving them prone to spurious outputs during deployment.","In this work, we propose a novel segmentation approach exploiting OOD detection that learns only from sparsely annotated pixels from multiple positive-only classes.","%but \\emph{no background class} annotation.","These multi-class positive annotations naturally fall within the in-distribution (ID) set.","Unlabelled pixels may contain positive classes but also negative ones, including what is typically referred to as \\emph{background} in standard segmentation formulations.","Here, we forgo the need for background annotation and consider these together with any other unseen classes as part of the OOD set.","Our framework can integrate, at a pixel-level, any OOD detection approaches designed for classification tasks.","To address the lack of existing OOD datasets and established evaluation metric for medical image segmentation, we propose a cross-validation strategy that treats held-out labelled classes as OOD.","Extensive experiments on both multi-class hyperspectral and RGB surgical imaging datasets demonstrate the robustness and generalisation capability of our proposed framework."],"url":"http://arxiv.org/abs/2411.09553v1"}
{"created":"2024-11-14 16:06:13","title":"Faster Differentially Private Top-$k$ Selection: A Joint Exponential Mechanism with Pruning","abstract":"We study the differentially private top-$k$ selection problem, aiming to identify a sequence of $k$ items with approximately the highest scores from $d$ items. Recent work by Gillenwater et al. (ICML '22) employs a direct sampling approach from the vast collection of $d^{\\,\\Theta(k)}$ possible length-$k$ sequences, showing superior empirical accuracy compared to previous pure or approximate differentially private methods. Their algorithm has a time and space complexity of $\\tilde{O}(dk)$.   In this paper, we present an improved algorithm with time and space complexity $O(d + k^2 / \\epsilon \\cdot \\ln d)$, where $\\epsilon$ denotes the privacy parameter. Experimental results show that our algorithm runs orders of magnitude faster than their approach, while achieving similar empirical accuracy.","sentences":["We study the differentially private top-$k$ selection problem, aiming to identify a sequence of $k$ items with approximately the highest scores from $d$ items.","Recent work by Gillenwater et al.","(ICML '22) employs a direct sampling approach from the vast collection of $d^{\\,\\Theta(k)}$ possible length-$k$ sequences, showing superior empirical accuracy compared to previous pure or approximate differentially private methods.","Their algorithm has a time and space complexity of $\\tilde{O}(dk)$.   In this paper, we present an improved algorithm with time and space complexity $O(d + k^2 / \\epsilon \\cdot \\ln d)$, where $\\epsilon$ denotes the privacy parameter.","Experimental results show that our algorithm runs orders of magnitude faster than their approach, while achieving similar empirical accuracy."],"url":"http://arxiv.org/abs/2411.09552v1"}
{"created":"2024-11-14 16:06:10","title":"MFTIQ: Multi-Flow Tracker with Independent Matching Quality Estimation","abstract":"In this work, we present MFTIQ, a novel dense long-term tracking model that advances the Multi-Flow Tracker (MFT) framework to address challenges in point-level visual tracking in video sequences. MFTIQ builds upon the flow-chaining concepts of MFT, integrating an Independent Quality (IQ) module that separates correspondence quality estimation from optical flow computations. This decoupling significantly enhances the accuracy and flexibility of the tracking process, allowing MFTIQ to maintain reliable trajectory predictions even in scenarios of prolonged occlusions and complex dynamics. Designed to be \"plug-and-play\", MFTIQ can be employed with any off-the-shelf optical flow method without the need for fine-tuning or architectural modifications. Experimental validations on the TAP-Vid Davis dataset show that MFTIQ with RoMa optical flow not only surpasses MFT but also performs comparably to state-of-the-art trackers while having substantially faster processing speed. Code and models available at https://github.com/serycjon/MFTIQ .","sentences":["In this work, we present MFTIQ, a novel dense long-term tracking model that advances the Multi-Flow Tracker (MFT) framework to address challenges in point-level visual tracking in video sequences.","MFTIQ builds upon the flow-chaining concepts of MFT, integrating an Independent Quality (IQ) module that separates correspondence quality estimation from optical flow computations.","This decoupling significantly enhances the accuracy and flexibility of the tracking process, allowing MFTIQ to maintain reliable trajectory predictions even in scenarios of prolonged occlusions and complex dynamics.","Designed to be \"plug-and-play\", MFTIQ can be employed with any off-the-shelf optical flow method without the need for fine-tuning or architectural modifications.","Experimental validations on the TAP-Vid Davis dataset show that MFTIQ with RoMa optical flow not only surpasses MFT but also performs comparably to state-of-the-art trackers while having substantially faster processing speed.","Code and models available at https://github.com/serycjon/MFTIQ ."],"url":"http://arxiv.org/abs/2411.09551v1"}
{"created":"2024-11-14 16:01:33","title":"Piecing It All Together: Verifying Multi-Hop Multimodal Claims","abstract":"Existing claim verification datasets often do not require systems to perform complex reasoning or effectively interpret multimodal evidence. To address this, we introduce a new task: multi-hop multimodal claim verification. This task challenges models to reason over multiple pieces of evidence from diverse sources, including text, images, and tables, and determine whether the combined multimodal evidence supports or refutes a given claim. To study this task, we construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired with multimodal evidence, generated and refined using large language models, with additional input from human feedback. We show that MMCV is challenging even for the latest state-of-the-art multimodal large language models, especially as the number of reasoning hops increases. Additionally, we establish a human performance benchmark on a subset of MMCV. We hope this dataset and its evaluation task will encourage future research in multimodal multi-hop claim verification.","sentences":["Existing claim verification datasets often do not require systems to perform complex reasoning or effectively interpret multimodal evidence.","To address this, we introduce a new task: multi-hop multimodal claim verification.","This task challenges models to reason over multiple pieces of evidence from diverse sources, including text, images, and tables, and determine whether the combined multimodal evidence supports or refutes a given claim.","To study this task, we construct MMCV, a large-scale dataset comprising 16k multi-hop claims paired with multimodal evidence, generated and refined using large language models, with additional input from human feedback.","We show that MMCV is challenging even for the latest state-of-the-art multimodal large language models, especially as the number of reasoning hops increases.","Additionally, we establish a human performance benchmark on a subset of MMCV.","We hope this dataset and its evaluation task will encourage future research in multimodal multi-hop claim verification."],"url":"http://arxiv.org/abs/2411.09547v1"}
{"created":"2024-11-14 16:01:05","title":"Architectural Exploration of Application-Specific Resonant SRAM Compute-in-Memory (rCiM)","abstract":"While general-purpose computing follows Von Neumann's architecture, the data movement between memory and processor elements dictates the processor's performance. The evolving compute-in-memory (CiM) paradigm tackles this issue by facilitating simultaneous processing and storage within static random-access memory (SRAM) elements. Numerous design decisions taken at different levels of hierarchy affect the figure of merits (FoMs) of SRAM, such as power, performance, area, and yield. The absence of a rapid assessment mechanism for the impact of changes at different hierarchy levels on global FoMs poses a challenge to accurately evaluating innovative SRAM designs. This paper presents an automation tool designed to optimize the energy and latency of SRAM designs incorporating diverse implementation strategies for executing logic operations within the SRAM. The tool structure allows easy comparison across different array topologies and various design strategies to result in energy-efficient implementations. Our study involves a comprehensive comparison of over 6900+ distinct design implementation strategies for EPFL combinational benchmark circuits on the energy-recycling resonant compute-in-memory (rCiM) architecture designed using TSMC 28 nm technology. When provided with a combinational circuit, the tool aims to generate an energy-efficient implementation strategy tailored to the specified input memory and latency constraints. The tool reduces 80.9% of energy consumption on average across all benchmarks while using the six-topology implementation compared to baseline implementation of single-macro topology by considering the parallel processing capability of rCiM cache size ranging from 4KB to 192KB.","sentences":["While general-purpose computing follows Von Neumann's architecture, the data movement between memory and processor elements dictates the processor's performance.","The evolving compute-in-memory (CiM) paradigm tackles this issue by facilitating simultaneous processing and storage within static random-access memory (SRAM) elements.","Numerous design decisions taken at different levels of hierarchy affect the figure of merits (FoMs) of SRAM, such as power, performance, area, and yield.","The absence of a rapid assessment mechanism for the impact of changes at different hierarchy levels on global FoMs poses a challenge to accurately evaluating innovative SRAM designs.","This paper presents an automation tool designed to optimize the energy and latency of SRAM designs incorporating diverse implementation strategies for executing logic operations within the SRAM.","The tool structure allows easy comparison across different array topologies and various design strategies to result in energy-efficient implementations.","Our study involves a comprehensive comparison of over 6900+ distinct design implementation strategies for EPFL combinational benchmark circuits on the energy-recycling resonant compute-in-memory (rCiM) architecture designed using TSMC 28 nm technology.","When provided with a combinational circuit, the tool aims to generate an energy-efficient implementation strategy tailored to the specified input memory and latency constraints.","The tool reduces 80.9% of energy consumption on average across all benchmarks while using the six-topology implementation compared to baseline implementation of single-macro topology by considering the parallel processing capability of rCiM cache size ranging from 4KB to 192KB."],"url":"http://arxiv.org/abs/2411.09546v1"}
{"created":"2024-11-14 15:58:46","title":"OpenGeMM: A High-Utilization GeMM Accelerator Generator with Lightweight RISC-V Control and Tight Memory Coupling","abstract":"Deep neural networks (DNNs) face significant challenges when deployed on resource-constrained extreme edge devices due to their computational and data-intensive nature. While standalone accelerators tailored for specific application scenarios suffer from inflexible control and limited programmability, generic hardware acceleration platforms coupled with RISC-V CPUs can enable high reusability and flexibility, yet typically at the expense of system level efficiency and low utilization. To fill this gap, we propose OpenGeMM, an open-source acceleration platform, jointly demonstrating high efficiency and utilization, as well as ease of configurability and programmability. OpenGeMM encompasses a parameterized Chisel-coded GeMM accelerator, a lightweight RISC-V processor, and a tightly coupled multi-banked scratchpad memory. The GeMM core utilization and system efficiency are boosted through three mechanisms: configuration pre-loading, input pre-fetching with output buffering, and programmable strided memory access. Experimental results show that OpenGeMM can consistently achieve hardware utilization ranging from 81.89% to 99.34% across diverse CNN and Transformer workloads. Compared to the SotA open-source Gemmini accelerator, OpenGeMM demonstrates a 3.58x to 16.40x speedup on normalized throughput across a wide variety ofGeMM workloads, while achieving 4.68 TOPS/W system efficiency.","sentences":["Deep neural networks (DNNs) face significant challenges when deployed on resource-constrained extreme edge devices due to their computational and data-intensive nature.","While standalone accelerators tailored for specific application scenarios suffer from inflexible control and limited programmability, generic hardware acceleration platforms coupled with RISC-V CPUs can enable high reusability and flexibility, yet typically at the expense of system level efficiency and low utilization.","To fill this gap, we propose OpenGeMM, an open-source acceleration platform, jointly demonstrating high efficiency and utilization, as well as ease of configurability and programmability.","OpenGeMM encompasses a parameterized Chisel-coded GeMM accelerator, a lightweight RISC-V processor, and a tightly coupled multi-banked scratchpad memory.","The GeMM core utilization and system efficiency are boosted through three mechanisms: configuration pre-loading, input pre-fetching with output buffering, and programmable strided memory access.","Experimental results show that OpenGeMM can consistently achieve hardware utilization ranging from 81.89% to 99.34% across diverse CNN and Transformer workloads.","Compared to the SotA open-source Gemmini accelerator, OpenGeMM demonstrates a 3.58x to 16.40x speedup on normalized throughput across a wide variety ofGeMM workloads, while achieving 4.68 TOPS/W system efficiency."],"url":"http://arxiv.org/abs/2411.09543v1"}
{"created":"2024-11-14 15:56:11","title":"Prompting the Unseen: Detecting Hidden Backdoors in Black-Box Models","abstract":"Visual prompting (VP) is a new technique that adapts well-trained frozen models for source domain tasks to target domain tasks. This study examines VP's benefits for black-box model-level backdoor detection. The visual prompt in VP maps class subspaces between source and target domains. We identify a misalignment, termed class subspace inconsistency, between clean and poisoned datasets. Based on this, we introduce \\textsc{BProm}, a black-box model-level detection method to identify backdoors in suspicious models, if any. \\textsc{BProm} leverages the low classification accuracy of prompted models when backdoors are present. Extensive experiments confirm \\textsc{BProm}'s effectiveness.","sentences":["Visual prompting (VP) is a new technique that adapts well-trained frozen models for source domain tasks to target domain tasks.","This study examines VP's benefits for black-box model-level backdoor detection.","The visual prompt in VP maps class subspaces between source and target domains.","We identify a misalignment, termed class subspace inconsistency, between clean and poisoned datasets.","Based on this, we introduce \\textsc{BProm}, a black-box model-level detection method to identify backdoors in suspicious models, if any.","\\textsc{BProm} leverages the low classification accuracy of prompted models when backdoors are present.","Extensive experiments confirm \\textsc{BProm}'s effectiveness."],"url":"http://arxiv.org/abs/2411.09540v1"}
{"created":"2024-11-14 15:55:37","title":"A Practical Guide to Fine-tuning Language Models with Limited Data","abstract":"Employing pre-trained Large Language Models (LLMs) has become the de facto standard in Natural Language Processing (NLP) despite their extensive data requirements. Motivated by the recent surge in research focused on training LLMs with limited data, particularly in low-resource domains and languages, this paper surveys recent transfer learning approaches to optimize model performance in downstream tasks where data is scarce. We first address initial and continued pre-training strategies to better leverage prior knowledge in unseen domains and languages. We then examine how to maximize the utility of limited data during fine-tuning and few-shot learning. The final section takes a task-specific perspective, reviewing models and methods suited for different levels of data scarcity. Our goal is to provide practitioners with practical guidelines for overcoming the challenges posed by constrained data while also highlighting promising directions for future research.","sentences":["Employing pre-trained Large Language Models (LLMs) has become the de facto standard in Natural Language Processing (NLP) despite their extensive data requirements.","Motivated by the recent surge in research focused on training LLMs with limited data, particularly in low-resource domains and languages, this paper surveys recent transfer learning approaches to optimize model performance in downstream tasks where data is scarce.","We first address initial and continued pre-training strategies to better leverage prior knowledge in unseen domains and languages.","We then examine how to maximize the utility of limited data during fine-tuning and few-shot learning.","The final section takes a task-specific perspective, reviewing models and methods suited for different levels of data scarcity.","Our goal is to provide practitioners with practical guidelines for overcoming the challenges posed by constrained data while also highlighting promising directions for future research."],"url":"http://arxiv.org/abs/2411.09539v1"}
{"created":"2024-11-14 15:55:21","title":"Marker-free Human Gait Analysis using a Smart Edge Sensor System","abstract":"The human gait is a complex interplay between the neuronal and the muscular systems, reflecting an individual's neurological and physiological condition. This makes gait analysis a valuable tool for biomechanics and medical experts. Traditional observational gait analysis is cost-effective but lacks reliability and accuracy, while instrumented gait analysis, particularly using marker-based optical systems, provides accurate data but is expensive and time-consuming. In this paper, we introduce a novel markerless approach for gait analysis using a multi-camera setup with smart edge sensors to estimate 3D body poses without fiducial markers. We propose a Siamese embedding network with triplet loss calculation to identify individuals by their gait pattern. This network effectively maps gait sequences to an embedding space that enables clustering sequences from the same individual or activity closely together while separating those of different ones. Our results demonstrate the potential of the proposed system for efficient automated gait analysis in diverse real-world environments, facilitating a wide range of applications.","sentences":["The human gait is a complex interplay between the neuronal and the muscular systems, reflecting an individual's neurological and physiological condition.","This makes gait analysis a valuable tool for biomechanics and medical experts.","Traditional observational gait analysis is cost-effective but lacks reliability and accuracy, while instrumented gait analysis, particularly using marker-based optical systems, provides accurate data but is expensive and time-consuming.","In this paper, we introduce a novel markerless approach for gait analysis using a multi-camera setup with smart edge sensors to estimate 3D body poses without fiducial markers.","We propose a Siamese embedding network with triplet loss calculation to identify individuals by their gait pattern.","This network effectively maps gait sequences to an embedding space that enables clustering sequences from the same individual or activity closely together while separating those of different ones.","Our results demonstrate the potential of the proposed system for efficient automated gait analysis in diverse real-world environments, facilitating a wide range of applications."],"url":"http://arxiv.org/abs/2411.09538v1"}
{"created":"2024-11-14 15:47:52","title":"Efficient top-down updates in AVL trees","abstract":"Since AVL trees were invented in 1962, two major open questions about rebalancing operations, which found positive answers in other balanced binary search trees, were left open: can these operations be performed top-down (with a fixed look-ahead), and can they use an amortised constant number of write operations per update? We propose an algorithm that answers both questions positively.","sentences":["Since AVL trees were invented in 1962, two major open questions about rebalancing operations, which found positive answers in other balanced binary search trees, were left open: can these operations be performed top-down (with a fixed look-ahead), and can they use an amortised constant number of write operations per update?","We propose an algorithm that answers both questions positively."],"url":"http://arxiv.org/abs/2411.09531v1"}
{"created":"2024-11-14 15:40:16","title":"FlowNav: Learning Efficient Navigation Policies via Conditional Flow Matching","abstract":"Effective robot navigation in dynamic environments is a challenging task that depends on generating precise control actions at high frequencies. Recent advancements have framed navigation as a goal-conditioned control problem. Current state-of-the-art methods for goal-based navigation, such as diffusion policies, either generate sub-goal images or robot control actions to guide robots. However, despite their high accuracy, these methods incur substantial computational costs, which limits their practicality for real-time applications. Recently, Conditional Flow Matching(CFM) has emerged as a more efficient and robust generalization of diffusion. In this work we explore the use of CFM to learn action policies that help the robot navigate its environment. Our results demonstrate that CFM is able to generate highly accurate robot actions. CFM not only matches the accuracy of diffusion policies but also significantly improves runtime performance. This makes it particularly advantageous for real-time robot navigation, where swift, reliable action generation is vital for collision avoidance and smooth operation. By leveraging CFM, we provide a pathway to more scalable, responsive robot navigation systems capable of handling the demands of dynamic and unpredictable environments.","sentences":["Effective robot navigation in dynamic environments is a challenging task that depends on generating precise control actions at high frequencies.","Recent advancements have framed navigation as a goal-conditioned control problem.","Current state-of-the-art methods for goal-based navigation, such as diffusion policies, either generate sub-goal images or robot control actions to guide robots.","However, despite their high accuracy, these methods incur substantial computational costs, which limits their practicality for real-time applications.","Recently, Conditional Flow Matching(CFM) has emerged as a more efficient and robust generalization of diffusion.","In this work we explore the use of CFM to learn action policies that help the robot navigate its environment.","Our results demonstrate that CFM is able to generate highly accurate robot actions.","CFM not only matches the accuracy of diffusion policies but also significantly improves runtime performance.","This makes it particularly advantageous for real-time robot navigation, where swift, reliable action generation is vital for collision avoidance and smooth operation.","By leveraging CFM, we provide a pathway to more scalable, responsive robot navigation systems capable of handling the demands of dynamic and unpredictable environments."],"url":"http://arxiv.org/abs/2411.09524v1"}
{"created":"2024-11-14 15:40:04","title":"Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents","abstract":"With the continuous development of large language models (LLMs), transformer-based models have made groundbreaking advances in numerous natural language processing (NLP) tasks, leading to the emergence of a series of agents that use LLMs as their control hub. While LLMs have achieved success in various tasks, they face numerous security and privacy threats, which become even more severe in the agent scenarios. To enhance the reliability of LLM-based applications, a range of research has emerged to assess and mitigate these risks from different perspectives.   To help researchers gain a comprehensive understanding of various risks, this survey collects and analyzes the different threats faced by these agents. To address the challenges posed by previous taxonomies in handling cross-module and cross-stage threats, we propose a novel taxonomy framework based on the sources and impacts. Additionally, we identify six key features of LLM-based agents, based on which we summarize the current research progress and analyze their limitations. Subsequently, we select four representative agents as case studies to analyze the risks they may face in practical use. Finally, based on the aforementioned analyses, we propose future research directions from the perspectives of data, methodology, and policy, respectively.","sentences":["With the continuous development of large language models (LLMs), transformer-based models have made groundbreaking advances in numerous natural language processing (NLP) tasks, leading to the emergence of a series of agents that use LLMs as their control hub.","While LLMs have achieved success in various tasks, they face numerous security and privacy threats, which become even more severe in the agent scenarios.","To enhance the reliability of LLM-based applications, a range of research has emerged to assess and mitigate these risks from different perspectives.   ","To help researchers gain a comprehensive understanding of various risks, this survey collects and analyzes the different threats faced by these agents.","To address the challenges posed by previous taxonomies in handling cross-module and cross-stage threats, we propose a novel taxonomy framework based on the sources and impacts.","Additionally, we identify six key features of LLM-based agents, based on which we summarize the current research progress and analyze their limitations.","Subsequently, we select four representative agents as case studies to analyze the risks they may face in practical use.","Finally, based on the aforementioned analyses, we propose future research directions from the perspectives of data, methodology, and policy, respectively."],"url":"http://arxiv.org/abs/2411.09523v1"}
{"created":"2024-11-14 15:28:40","title":"Randomized Truthful Auctions with Learning Agents","abstract":"We study a setting where agents use no-regret learning algorithms to participate in repeated auctions. \\citet{kolumbus2022auctions} showed, rather surprisingly, that when bidders participate in second-price auctions using no-regret bidding algorithms, no matter how large the number of interactions $T$ is, the runner-up bidder may not converge to bidding truthfully. Our first result shows that this holds for \\emph{general deterministic} truthful auctions. We also show that the ratio of the learning rates of the bidders can \\emph{qualitatively} affect the convergence of the bidders. Next, we consider the problem of revenue maximization in this environment. In the setting with fully rational bidders, \\citet{myerson1981optimal} showed that revenue can be maximized by using a second-price auction with reserves.We show that, in stark contrast, in our setting with learning bidders, \\emph{randomized} auctions can have strictly better revenue guarantees than second-price auctions with reserves, when $T$ is large enough. Finally, we study revenue maximization in the non-asymptotic regime. We define a notion of {\\em auctioneer regret} comparing the revenue generated to the revenue of a second price auction with truthful bids. When the auctioneer has to use the same auction throughout the interaction, we show an (almost) tight regret bound of $\\smash{\\widetilde \\Theta(T^{3/4})}.$ If the auctioneer can change auctions during the interaction, but in a way that is oblivious to the bids, we show an (almost) tight bound of $\\smash{\\widetilde \\Theta(\\sqrt{T})}.$","sentences":["We study a setting where agents use no-regret learning algorithms to participate in repeated auctions.","\\citet{kolumbus2022auctions} showed, rather surprisingly, that when bidders participate in second-price auctions using no-regret bidding algorithms, no matter how large the number of interactions $T$ is, the runner-up bidder may not converge to bidding truthfully.","Our first result shows that this holds for \\emph{general deterministic} truthful auctions.","We also show that the ratio of the learning rates of the bidders can \\emph{qualitatively} affect the convergence of the bidders.","Next, we consider the problem of revenue maximization in this environment.","In the setting with fully rational bidders, \\citet{myerson1981optimal} showed that revenue can be maximized by using a second-price auction with reserves.","We show that, in stark contrast, in our setting with learning bidders, \\emph{randomized} auctions can have strictly better revenue guarantees than second-price auctions with reserves, when $T$ is large enough.","Finally, we study revenue maximization in the non-asymptotic regime.","We define a notion of {\\em auctioneer regret} comparing the revenue generated to the revenue of a second price auction with truthful bids.","When the auctioneer has to use the same auction throughout the interaction, we show an (almost) tight regret bound of $\\smash{\\widetilde \\Theta(T^{3/4})}.$","If the auctioneer can change auctions during the interaction, but in a way that is oblivious to the bids, we show an (almost) tight bound of $\\smash{\\widetilde \\Theta(\\sqrt{T})}.$"],"url":"http://arxiv.org/abs/2411.09517v1"}
{"created":"2024-11-14 15:19:01","title":"Communication Compression for Tensor Parallel LLM Inference","abstract":"Large Language Models (LLMs) have pushed the frontier of artificial intelligence but are comprised of hundreds of billions of parameters and operations. For faster inference latency, LLMs are deployed on multiple hardware accelerators through various Model Parallelism strategies. Our paper looks into the details on one such strategy - Tensor Parallel - and proposes to reduce latency by compressing inter-accelerator communication. We leverage fine grained quantization techniques to compress selected activations by 3.5 - 4.5x. Our proposed method leads up to 2x reduction of time-to-first-token (TTFT) with negligible model performance degradation.","sentences":["Large Language Models (LLMs) have pushed the frontier of artificial intelligence but are comprised of hundreds of billions of parameters and operations.","For faster inference latency, LLMs are deployed on multiple hardware accelerators through various Model Parallelism strategies.","Our paper looks into the details on one such strategy - Tensor Parallel - and proposes to reduce latency by compressing inter-accelerator communication.","We leverage fine grained quantization techniques to compress selected activations by 3.5 - 4.5x.","Our proposed method leads up to 2x reduction of time-to-first-token (TTFT) with negligible model performance degradation."],"url":"http://arxiv.org/abs/2411.09510v1"}
{"created":"2024-11-14 15:17:50","title":"Toward a Cohesive AI and Simulation Software Ecosystem for Scientific Innovation","abstract":"In this paper, we discuss the need for an integrated software stack that unites artificial intelligence (AI) and modeling and simulation (ModSim) tools to advance scientific discovery. The authors advocate for a unified AI/ModSim software ecosystem that ensures compatibility across a wide range of software on diverse high-performance computing systems, promoting ease of deployment, version management, and binary distribution. Key challenges highlighted include balancing the distinct needs of AI and ModSim, especially in terms of software build practices, dependency management, and compatibility. The document underscores the importance of continuous integration, community-driven stewardship, and collaboration with the Department of Energy (DOE) to develop a portable and cohesive scientific software ecosystem. Recommendations focus on supporting standardized environments through initiatives like the Extreme-scale Scientific Software Stack (E4S) and Spack to foster interdisciplinary innovation and facilitate new scientific advancements.","sentences":["In this paper, we discuss the need for an integrated software stack that unites artificial intelligence (AI) and modeling and simulation (ModSim) tools to advance scientific discovery.","The authors advocate for a unified AI/ModSim software ecosystem that ensures compatibility across a wide range of software on diverse high-performance computing systems, promoting ease of deployment, version management, and binary distribution.","Key challenges highlighted include balancing the distinct needs of AI and ModSim, especially in terms of software build practices, dependency management, and compatibility.","The document underscores the importance of continuous integration, community-driven stewardship, and collaboration with the Department of Energy (DOE) to develop a portable and cohesive scientific software ecosystem.","Recommendations focus on supporting standardized environments through initiatives like the Extreme-scale Scientific Software Stack (E4S) and Spack to foster interdisciplinary innovation and facilitate new scientific advancements."],"url":"http://arxiv.org/abs/2411.09507v1"}
{"created":"2024-11-14 15:13:13","title":"Golden Noise for Diffusion Models: A Learning Framework","abstract":"Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise. While people observe that some noises are ``golden noises'' that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those golden noises. To learn golden noises for diffusion sampling, we mainly make three contributions in this paper. First, we identify a new concept termed the \\textit{noise prompt}, which aims at turning a random Gaussian noise into a golden noise by adding a small desirable perturbation derived from the text prompt. Following the concept, we first formulate the \\textit{noise prompt learning} framework that systematically learns ``prompted'' golden noise associated with a text prompt for diffusion models. Second, we design a noise prompt data collection pipeline and collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains 100k pairs of random noises and golden noises with the associated text prompts. With the prepared NPD as the training dataset, we trained a small \\textit{noise prompt network}~(NPNet) that can directly learn to transform a random noise into a golden noise. The learned golden noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt. Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT. Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a golden noise instead of a random noise without accessing the original pipeline.","sentences":["Text-to-image diffusion model is a popular paradigm that synthesizes personalized images by providing a text prompt and a random Gaussian noise.","While people observe that some noises are ``golden noises'' that can achieve better text-image alignment and higher human preference than others, we still lack a machine learning framework to obtain those golden noises.","To learn golden noises for diffusion sampling, we mainly make three contributions in this paper.","First, we identify a new concept termed the \\textit{noise prompt}, which aims at turning a random Gaussian noise into a golden noise by adding a small desirable perturbation derived from the text prompt.","Following the concept, we first formulate the \\textit{noise prompt learning} framework that systematically learns ``prompted'' golden noise associated with a text prompt for diffusion models.","Second, we design a noise prompt data collection pipeline and collect a large-scale \\textit{noise prompt dataset}~(NPD) that contains 100k pairs of random noises and golden noises with the associated text prompts.","With the prepared NPD as the training dataset, we trained a small \\textit{noise prompt network}~(NPNet) that can directly learn to transform a random noise into a golden noise.","The learned golden noise perturbation can be considered as a kind of prompt for noise, as it is rich in semantic information and tailored to the given text prompt.","Third, our extensive experiments demonstrate the impressive effectiveness and generalization of NPNet on improving the quality of synthesized images across various diffusion models, including SDXL, DreamShaper-xl-v2-turbo, and Hunyuan-DiT.","Moreover, NPNet is a small and efficient controller that acts as a plug-and-play module with very limited additional inference and computational costs, as it just provides a golden noise instead of a random noise without accessing the original pipeline."],"url":"http://arxiv.org/abs/2411.09502v1"}
