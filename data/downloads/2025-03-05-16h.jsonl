{"created":"2025-03-04 18:59:56","title":"ARINAR: Bi-Level Autoregressive Feature-by-Feature Generative Models","abstract":"Existing autoregressive (AR) image generative models use a token-by-token generation schema. That is, they predict a per-token probability distribution and sample the next token from that distribution. The main challenge is how to model the complex distribution of high-dimensional tokens. Previous methods either are too simplistic to fit the distribution or result in slow generation speed. Instead of fitting the distribution of the whole tokens, we explore using a AR model to generate each token in a feature-by-feature way, i.e., taking the generated features as input and generating the next feature. Based on that, we propose ARINAR (AR-in-AR), a bi-level AR model. The outer AR layer take previous tokens as input, predicts a condition vector z for the next token. The inner layer, conditional on z, generates features of the next token autoregressively. In this way, the inner layer only needs to model the distribution of a single feature, for example, using a simple Gaussian Mixture Model. On the ImageNet 256x256 image generation task, ARINAR-B with 213M parameters achieves an FID of 2.75, which is comparable to the state-of-the-art MAR-B model (FID=2.31), while five times faster than the latter.","sentences":["Existing autoregressive (AR) image generative models use a token-by-token generation schema.","That is, they predict a per-token probability distribution and sample the next token from that distribution.","The main challenge is how to model the complex distribution of high-dimensional tokens.","Previous methods either are too simplistic to fit the distribution or result in slow generation speed.","Instead of fitting the distribution of the whole tokens, we explore using a AR model to generate each token in a feature-by-feature way, i.e., taking the generated features as input and generating the next feature.","Based on that, we propose ARINAR (AR-in-AR), a bi-level AR model.","The outer AR layer take previous tokens as input, predicts a condition vector z for the next token.","The inner layer, conditional on z, generates features of the next token autoregressively.","In this way, the inner layer only needs to model the distribution of a single feature, for example, using a simple Gaussian Mixture Model.","On the ImageNet 256x256 image generation task, ARINAR-B with 213M parameters achieves an FID of 2.75, which is comparable to the state-of-the-art MAR-B model (FID=2.31), while five times faster than the latter."],"url":"http://arxiv.org/abs/2503.02883v1"}
{"created":"2025-03-04 18:58:42","title":"Bringing Comparative Cognition To Computers","abstract":"Researchers are increasingly subjecting artificial intelligence systems to psychological testing. But to rigorously compare their cognitive capacities with humans and other animals, we must avoid both over- and under-stating our similarities and differences. By embracing a comparative approach, we can integrate AI cognition research into the broader cognitive sciences.","sentences":["Researchers are increasingly subjecting artificial intelligence systems to psychological testing.","But to rigorously compare their cognitive capacities with humans and other animals, we must avoid both over- and under-stating our similarities and differences.","By embracing a comparative approach, we can integrate AI cognition research into the broader cognitive sciences."],"url":"http://arxiv.org/abs/2503.02882v1"}
{"created":"2025-03-04 18:58:21","title":"Reactive Diffusion Policy: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation","abstract":"Humans can accomplish complex contact-rich tasks using vision and touch, with highly reactive capabilities such as quick adjustments to environmental changes and adaptive control of contact forces; however, this remains challenging for robots. Existing visual imitation learning (IL) approaches rely on action chunking to model complex behaviors, which lacks the ability to respond instantly to real-time tactile feedback during the chunk execution. Furthermore, most teleoperation systems struggle to provide fine-grained tactile / force feedback, which limits the range of tasks that can be performed. To address these challenges, we introduce TactAR, a low-cost teleoperation system that provides real-time tactile feedback through Augmented Reality (AR), along with Reactive Diffusion Policy (RDP), a novel slow-fast visual-tactile imitation learning algorithm for learning contact-rich manipulation skills. RDP employs a two-level hierarchy: (1) a slow latent diffusion policy for predicting high-level action chunks in latent space at low frequency, (2) a fast asymmetric tokenizer for closed-loop tactile feedback control at high frequency. This design enables both complex trajectory modeling and quick reactive behavior within a unified framework. Through extensive evaluation across three challenging contact-rich tasks, RDP significantly improves performance compared to state-of-the-art visual IL baselines through rapid response to tactile / force feedback. Furthermore, experiments show that RDP is applicable across different tactile / force sensors. Code and videos are available on https://reactive-diffusion-policy.github.io/.","sentences":["Humans can accomplish complex contact-rich tasks using vision and touch, with highly reactive capabilities such as quick adjustments to environmental changes and adaptive control of contact forces; however, this remains challenging for robots.","Existing visual imitation learning (IL) approaches rely on action chunking to model complex behaviors, which lacks the ability to respond instantly to real-time tactile feedback during the chunk execution.","Furthermore, most teleoperation systems struggle to provide fine-grained tactile / force feedback, which limits the range of tasks that can be performed.","To address these challenges, we introduce TactAR, a low-cost teleoperation system that provides real-time tactile feedback through Augmented Reality (AR), along with Reactive Diffusion Policy (RDP), a novel slow-fast visual-tactile imitation learning algorithm for learning contact-rich manipulation skills.","RDP employs a two-level hierarchy: (1) a slow latent diffusion policy for predicting high-level action chunks in latent space at low frequency, (2) a fast asymmetric tokenizer for closed-loop tactile feedback control at high frequency.","This design enables both complex trajectory modeling and quick reactive behavior within a unified framework.","Through extensive evaluation across three challenging contact-rich tasks, RDP significantly improves performance compared to state-of-the-art visual IL baselines through rapid response to tactile / force feedback.","Furthermore, experiments show that RDP is applicable across different tactile / force sensors.","Code and videos are available on https://reactive-diffusion-policy.github.io/."],"url":"http://arxiv.org/abs/2503.02881v1"}
{"created":"2025-03-04 18:58:13","title":"Wikipedia in the Era of LLMs: Evolution and Risks","abstract":"In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks. We begin by analyzing page views and article content to study Wikipedia's recent changes and assess the impact of LLMs. Subsequently, we evaluate how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG). Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 1%-2% in certain categories. If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well. Moreover, the effectiveness of RAG might decrease if the knowledge base becomes polluted by LLM-generated content. While LLMs have not yet fully changed Wikipedia's language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks.","sentences":["In this paper, we present a thorough analysis of the impact of Large Language Models (LLMs) on Wikipedia, examining the evolution of Wikipedia through existing data and using simulations to explore potential risks.","We begin by analyzing page views and article content to study Wikipedia's recent changes and assess the impact of LLMs.","Subsequently, we evaluate how LLMs affect various Natural Language Processing (NLP) tasks related to Wikipedia, including machine translation and retrieval-augmented generation (RAG).","Our findings and simulation results reveal that Wikipedia articles have been influenced by LLMs, with an impact of approximately 1%-2% in certain categories.","If the machine translation benchmark based on Wikipedia is influenced by LLMs, the scores of the models may become inflated, and the comparative results among models might shift as well.","Moreover, the effectiveness of RAG might decrease if the knowledge base becomes polluted by LLM-generated content.","While LLMs have not yet fully changed Wikipedia's language and knowledge structures, we believe that our empirical findings signal the need for careful consideration of potential future risks."],"url":"http://arxiv.org/abs/2503.02879v1"}
{"created":"2025-03-04 18:58:11","title":"Language Models can Self-Improve at State-Value Estimation for Better Search","abstract":"Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks. To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages state-transition dynamics to train a value model capable of effectively guiding language model-controlled search. We find that moderately sized (8 billion parameters) open-weight value models improved with self-taught lookahead can match the performance of using a frontier LLM such as gpt-4o as the value model. Furthermore, we find that self-taught lookahead improves performance by 20% while reducing costs 37x compared to previous LLM-based tree search, without relying on ground truth rewards.","sentences":["Collecting ground truth task completion rewards or human demonstrations for multi-step reasoning tasks is often cost-prohibitive and time-consuming, especially in interactive domains like web tasks.","To address this bottleneck, we present self-taught lookahead, a self-supervised method that leverages state-transition dynamics to train a value model capable of effectively guiding language model-controlled search.","We find that moderately sized (8 billion parameters) open-weight value models improved with self-taught lookahead can match the performance of using a frontier LLM such as gpt-4o as the value model.","Furthermore, we find that self-taught lookahead improves performance by 20% while reducing costs 37x compared to previous LLM-based tree search, without relying on ground truth rewards."],"url":"http://arxiv.org/abs/2503.02878v1"}
{"created":"2025-03-04 18:58:00","title":"Weak-to-Strong Generalization Even in Random Feature Networks, Provably","abstract":"Weak-to-Strong Generalization (Burns et al., 2024) is the phenomenon whereby a strong student, say GPT-4, learns a task from a weak teacher, say GPT-2, and ends up significantly outperforming the teacher. We show that this phenomenon does not require a strong learner like GPT-4. We consider student and teacher that are random feature models, described by two-layer networks with a random and fixed bottom layer and a trained top layer. A \"weak\" teacher, with a small number of units (i.e. random features), is trained on the population, and a \"strong\" student, with a much larger number of units (i.e. random features), is trained only on labels generated by the weak teacher. We demonstrate, prove, and understand how the student can outperform the teacher, even though trained only on data labeled by the teacher. We also explain how such weak-to-strong generalization is enabled by early stopping. Importantly, we also show the quantitative limits of weak-to-strong generalization in this model.","sentences":["Weak-to-Strong Generalization (Burns et al., 2024) is the phenomenon whereby a strong student, say GPT-4, learns a task from a weak teacher, say GPT-2, and ends up significantly outperforming the teacher.","We show that this phenomenon does not require a strong learner like GPT-4.","We consider student and teacher that are random feature models, described by two-layer networks with a random and fixed bottom layer and a trained top layer.","A \"weak\" teacher, with a small number of units (i.e. random features), is trained on the population, and a \"strong\" student, with a much larger number of units (i.e. random features), is trained only on labels generated by the weak teacher.","We demonstrate, prove, and understand how the student can outperform the teacher, even though trained only on data labeled by the teacher.","We also explain how such weak-to-strong generalization is enabled by early stopping.","Importantly, we also show the quantitative limits of weak-to-strong generalization in this model."],"url":"http://arxiv.org/abs/2503.02877v1"}
{"created":"2025-03-04 18:56:03","title":"The First Few Tokens Are All You Need: An Efficient and Effective Unsupervised Prefix Fine-Tuning Method for Reasoning Models","abstract":"Improving the reasoning capabilities of large language models (LLMs) typically requires supervised fine-tuning with labeled data or computationally expensive sampling. We introduce Unsupervised Prefix Fine-Tuning (UPFT), which leverages the observation of Prefix Self-Consistency -- the shared initial reasoning steps across diverse solution trajectories -- to enhance LLM reasoning efficiency. By training exclusively on the initial prefix substrings (as few as 8 tokens), UPFT removes the need for labeled data or exhaustive sampling. Experiments on reasoning benchmarks show that UPFT matches the performance of supervised methods such as Rejection Sampling Fine-Tuning, while reducing training time by 75% and sampling cost by 99%. Further analysis reveals that errors tend to appear in later stages of the reasoning process and that prefix-based training preserves the model's structural knowledge. This work demonstrates how minimal unsupervised fine-tuning can unlock substantial reasoning gains in LLMs, offering a scalable and resource-efficient alternative to conventional approaches.","sentences":["Improving the reasoning capabilities of large language models (LLMs) typically requires supervised fine-tuning with labeled data or computationally expensive sampling.","We introduce Unsupervised Prefix Fine-Tuning (UPFT), which leverages the observation of Prefix Self-Consistency -- the shared initial reasoning steps across diverse solution trajectories -- to enhance LLM reasoning efficiency.","By training exclusively on the initial prefix substrings (as few as 8 tokens), UPFT removes the need for labeled data or exhaustive sampling.","Experiments on reasoning benchmarks show that UPFT matches the performance of supervised methods such as Rejection Sampling Fine-Tuning, while reducing training time by 75% and sampling cost by 99%.","Further analysis reveals that errors tend to appear in later stages of the reasoning process and that prefix-based training preserves the model's structural knowledge.","This work demonstrates how minimal unsupervised fine-tuning can unlock substantial reasoning gains in LLMs, offering a scalable and resource-efficient alternative to conventional approaches."],"url":"http://arxiv.org/abs/2503.02875v1"}
{"created":"2025-03-04 18:55:19","title":"Prompting Generative AI with Interaction-Augmented Instructions","abstract":"The emergence of generative AI (GenAI) models, including large language models and text-to-image models, has significantly advanced the synergy between humans and AI with not only their outstanding capability but more importantly, the intuitive communication method with text prompts. Though intuitive, text-based instructions suffer from natural languages' ambiguous and redundant nature. To address the issue, researchers have explored augmenting text-based instructions with interactions that facilitate precise and effective human intent expression, such as direct manipulation. However, the design strategy of interaction-augmented instructions lacks systematic investigation, hindering our understanding and application. To provide a panorama of interaction-augmented instructions, we propose a framework to analyze related tools from why, when, who, what, and how interactions are applied to augment text-based instructions. Notably, we identify four purposes for applying interactions, including restricting, expanding, organizing, and refining text instructions. The design paradigms for each purpose are also summarized to benefit future researchers and practitioners.","sentences":["The emergence of generative AI (GenAI) models, including large language models and text-to-image models, has significantly advanced the synergy between humans and AI with not only their outstanding capability but more importantly, the intuitive communication method with text prompts.","Though intuitive, text-based instructions suffer from natural languages' ambiguous and redundant nature.","To address the issue, researchers have explored augmenting text-based instructions with interactions that facilitate precise and effective human intent expression, such as direct manipulation.","However, the design strategy of interaction-augmented instructions lacks systematic investigation, hindering our understanding and application.","To provide a panorama of interaction-augmented instructions, we propose a framework to analyze related tools from why, when, who, what, and how interactions are applied to augment text-based instructions.","Notably, we identify four purposes for applying interactions, including restricting, expanding, organizing, and refining text instructions.","The design paradigms for each purpose are also summarized to benefit future researchers and practitioners."],"url":"http://arxiv.org/abs/2503.02874v1"}
{"created":"2025-03-04 18:43:57","title":"FairSense-AI: Responsible AI Meets Sustainability","abstract":"In this paper, we introduce FairSense-AI: a multimodal framework designed to detect and mitigate bias in both text and images. By leveraging Large Language Models (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle forms of prejudice or stereotyping that can appear in content, providing users with bias scores, explanatory highlights, and automated recommendations for fairness enhancements. In addition, FairSense-AI integrates an AI risk assessment component that aligns with frameworks like the MIT AI Risk Repository and NIST AI Risk Management Framework, enabling structured identification of ethical and safety concerns. The platform is optimized for energy efficiency via techniques such as model pruning and mixed-precision computation, thereby reducing its environmental footprint. Through a series of case studies and applications, we demonstrate how FairSense-AI promotes responsible AI use by addressing both the social dimension of fairness and the pressing need for sustainability in large-scale AI deployments. https://vectorinstitute.github.io/FairSense-AI, https://pypi.org/project/fair-sense-ai/","sentences":["In this paper, we introduce FairSense-AI: a multimodal framework designed to detect and mitigate bias in both text and images.","By leveraging Large Language Models (LLMs) and Vision-Language Models (VLMs), FairSense-AI uncovers subtle forms of prejudice or stereotyping that can appear in content, providing users with bias scores, explanatory highlights, and automated recommendations for fairness enhancements.","In addition, FairSense-AI integrates an AI risk assessment component that aligns with frameworks like the MIT AI Risk Repository and NIST AI Risk Management Framework, enabling structured identification of ethical and safety concerns.","The platform is optimized for energy efficiency via techniques such as model pruning and mixed-precision computation, thereby reducing its environmental footprint.","Through a series of case studies and applications, we demonstrate how FairSense-AI promotes responsible AI use by addressing both the social dimension of fairness and the pressing need for sustainability in large-scale AI deployments.","https://vectorinstitute.github.io/FairSense-AI, https://pypi.org/project/fair-sense-ai/"],"url":"http://arxiv.org/abs/2503.02865v1"}
{"created":"2025-03-04 18:40:49","title":"Calibrating LLM Confidence with Semantic Steering: A Multi-Prompt Aggregation Framework","abstract":"Large Language Models (LLMs) often exhibit misaligned confidence scores, usually overestimating the reliability of their predictions. While verbalized confidence in Large Language Models (LLMs) has gained attention, prior work remains divided on whether confidence scores can be systematically steered through prompting. Recent studies even argue that such prompt-induced confidence shifts are negligible, suggesting LLMs' confidence calibration is rigid to linguistic interventions. Contrary to these claims, we first rigorously confirm the existence of directional confidence shifts by probing three models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks, demonstrating that explicit instructions can inflate or deflate confidence scores in a regulated manner. Based on this observation, we propose a novel framework containing three components: confidence steering, steered confidence aggregation and steered answers selection, named SteeringConf. Our method, SteeringConf, leverages a confidence manipulation mechanism to steer the confidence scores of LLMs in several desired directions, followed by a summarization module that aggregates the steered confidence scores to produce a final prediction. We evaluate our method on 7 benchmarks and it consistently outperforms the baselines in terms of calibration metrics in task of confidence calibration and failure detection.","sentences":["Large Language Models (LLMs) often exhibit misaligned confidence scores, usually overestimating the reliability of their predictions.","While verbalized confidence in Large Language Models (LLMs) has gained attention, prior work remains divided on whether confidence scores can be systematically steered through prompting.","Recent studies even argue that such prompt-induced confidence shifts are negligible, suggesting LLMs' confidence calibration is rigid to linguistic interventions.","Contrary to these claims, we first rigorously confirm the existence of directional confidence shifts by probing three models (including GPT3.5, LLAMA3-70b, GPT4) across 7 benchmarks, demonstrating that explicit instructions can inflate or deflate confidence scores in a regulated manner.","Based on this observation, we propose a novel framework containing three components: confidence steering, steered confidence aggregation and steered answers selection, named SteeringConf.","Our method, SteeringConf, leverages a confidence manipulation mechanism to steer the confidence scores of LLMs in several desired directions, followed by a summarization module that aggregates the steered confidence scores to produce a final prediction.","We evaluate our method on 7 benchmarks and it consistently outperforms the baselines in terms of calibration metrics in task of confidence calibration and failure detection."],"url":"http://arxiv.org/abs/2503.02863v1"}
{"created":"2025-03-04 18:40:38","title":"Privacy and Accuracy-Aware AI/ML Model Deduplication","abstract":"With the growing adoption of privacy-preserving machine learning algorithms, such as Differentially Private Stochastic Gradient Descent (DP-SGD), training or fine-tuning models on private datasets has become increasingly prevalent. This shift has led to the need for models offering varying privacy guarantees and utility levels to satisfy diverse user requirements. However, managing numerous versions of large models introduces significant operational challenges, including increased inference latency, higher resource consumption, and elevated costs. Model deduplication is a technique widely used by many model serving and database systems to support high-performance and low-cost inference queries and model diagnosis queries. However, none of the existing model deduplication works has considered privacy, leading to unbounded aggregation of privacy costs for certain deduplicated models and inefficiencies when applied to deduplicate DP-trained models. We formalize the problems of deduplicating DP-trained models for the first time and propose a novel privacy- and accuracy-aware deduplication mechanism to address the problems. We developed a greedy strategy to select and assign base models to target models to minimize storage and privacy costs. When deduplicating a target model, we dynamically schedule accuracy validations and apply the Sparse Vector Technique to reduce the privacy costs associated with private validation data. Compared to baselines that do not provide privacy guarantees, our approach improved the compression ratio by up to $35\\times$ for individual models (including large language models and vision transformers). We also observed up to $43\\times$ inference speedup due to the reduction of I/O operations.","sentences":["With the growing adoption of privacy-preserving machine learning algorithms, such as Differentially Private Stochastic Gradient Descent (DP-SGD), training or fine-tuning models on private datasets has become increasingly prevalent.","This shift has led to the need for models offering varying privacy guarantees and utility levels to satisfy diverse user requirements.","However, managing numerous versions of large models introduces significant operational challenges, including increased inference latency, higher resource consumption, and elevated costs.","Model deduplication is a technique widely used by many model serving and database systems to support high-performance and low-cost inference queries and model diagnosis queries.","However, none of the existing model deduplication works has considered privacy, leading to unbounded aggregation of privacy costs for certain deduplicated models and inefficiencies when applied to deduplicate DP-trained models.","We formalize the problems of deduplicating DP-trained models for the first time and propose a novel privacy- and accuracy-aware deduplication mechanism to address the problems.","We developed a greedy strategy to select and assign base models to target models to minimize storage and privacy costs.","When deduplicating a target model, we dynamically schedule accuracy validations and apply the Sparse Vector Technique to reduce the privacy costs associated with private validation data.","Compared to baselines that do not provide privacy guarantees, our approach improved the compression ratio by up to $35\\times$ for individual models (including large language models and vision transformers).","We also observed up to $43\\times$ inference speedup due to the reduction of I/O operations."],"url":"http://arxiv.org/abs/2503.02862v1"}
{"created":"2025-03-04 18:39:28","title":"Evaluation of Architectural Synthesis Using Generative AI","abstract":"Recent advancements in multimodal Generative AI have the potential to democratize specialized architectural tasks, such as interpreting technical drawings and creating 3D CAD models, which traditionally require expert knowledge. This paper presents a comparative evaluation of two systems: GPT-4o and Claude 3.5, in the task of architectural 3D synthesis. We conduct a case study on two buildings from Palladio's Four Books of Architecture (1965): Villa Rotonda and Palazzo Porto. High-level architectural models and drawings of these buildings were prepared, inspired by Palladio's original texts and drawings. Through sequential text and image prompting, we assess the systems' abilities in (1) interpreting 2D and 3D representations of buildings from drawings, (2) encoding the buildings into a CAD software script, and (3) self-improving based on outputs. While both systems successfully generate individual parts, they struggle to accurately assemble these parts into the desired spatial relationships, with Claude 3.5 demonstrating better performance, particularly in self-correcting its output. This study contributes to ongoing research on benchmarking the strengths and weaknesses of off-the-shelf AI systems in performing intelligent human tasks that require discipline-specific knowledge. The findings highlight the potential of language-enabled AI systems to act as collaborative technical assistants in the architectural design process.","sentences":["Recent advancements in multimodal Generative AI have the potential to democratize specialized architectural tasks, such as interpreting technical drawings and creating 3D CAD models, which traditionally require expert knowledge.","This paper presents a comparative evaluation of two systems: GPT-4o and Claude 3.5, in the task of architectural 3D synthesis.","We conduct a case study on two buildings from Palladio's Four Books of Architecture (1965): Villa Rotonda and Palazzo Porto.","High-level architectural models and drawings of these buildings were prepared, inspired by Palladio's original texts and drawings.","Through sequential text and image prompting, we assess the systems' abilities in (1) interpreting 2D and 3D representations of buildings from drawings, (2) encoding the buildings into a CAD software script, and (3) self-improving based on outputs.","While both systems successfully generate individual parts, they struggle to accurately assemble these parts into the desired spatial relationships, with Claude 3.5 demonstrating better performance, particularly in self-correcting its output.","This study contributes to ongoing research on benchmarking the strengths and weaknesses of off-the-shelf AI systems in performing intelligent human tasks that require discipline-specific knowledge.","The findings highlight the potential of language-enabled AI systems to act as collaborative technical assistants in the architectural design process."],"url":"http://arxiv.org/abs/2503.02861v1"}
{"created":"2025-03-04 18:33:22","title":"Deepfake-Eval-2024: A Multi-Modal In-the-Wild Benchmark of Deepfakes Circulated in 2024","abstract":"In the age of increasingly realistic generative AI, robust deepfake detection is essential for mitigating fraud and disinformation. While many deepfake detectors report high accuracy on academic datasets, we show that these academic benchmarks are out of date and not representative of recent deepfakes. We introduce Deepfake-Eval-2024, a new deepfake detection benchmark consisting of in-the-wild deepfakes collected from social media and deepfake detection platform users in 2024. Deepfake-Eval-2024 consists of 44 hours of videos, 56.5 hours of audio, and 1,975 images, encompassing the latest manipulation technologies. The benchmark contains diverse media content from 88 different websites in 52 different languages. We find that the performance of open-source state-of-the-art deepfake detection models drops precipitously when evaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for audio, and 45% for image models compared to previous benchmarks. We also evaluate commercial deepfake detection models and models finetuned on Deepfake-Eval-2024, and find that they have superior performance to off-the-shelf open-source models, but they do not yet reach the accuracy of human deepfake forensic analysts. The dataset is available at https://github.com/nuriachandra/Deepfake-Eval-2024.","sentences":["In the age of increasingly realistic generative AI, robust deepfake detection is essential for mitigating fraud and disinformation.","While many deepfake detectors report high accuracy on academic datasets, we show that these academic benchmarks are out of date and not representative of recent deepfakes.","We introduce Deepfake-Eval-2024, a new deepfake detection benchmark consisting of in-the-wild deepfakes collected from social media and deepfake detection platform users in 2024.","Deepfake-Eval-2024 consists of 44 hours of videos, 56.5 hours of audio, and 1,975 images, encompassing the latest manipulation technologies.","The benchmark contains diverse media content from 88 different websites in 52 different languages.","We find that the performance of open-source state-of-the-art deepfake detection models drops precipitously when evaluated on Deepfake-Eval-2024, with AUC decreasing by 50% for video, 48% for audio, and 45% for image models compared to previous benchmarks.","We also evaluate commercial deepfake detection models and models finetuned on Deepfake-Eval-2024, and find that they have superior performance to off-the-shelf open-source models, but they do not yet reach the accuracy of human deepfake forensic analysts.","The dataset is available at https://github.com/nuriachandra/Deepfake-Eval-2024."],"url":"http://arxiv.org/abs/2503.02857v1"}
{"created":"2025-03-04 18:31:02","title":"(How) Do Language Models Track State?","abstract":"Transformer language models (LMs) exhibit behaviors -- from storytelling to code generation -- that appear to require tracking the unobserved state of an evolving world. How do they do so? We study state tracking in LMs trained or fine-tuned to compose permutations (i.e., to compute the order of a set of objects after a sequence of swaps). Despite the simple algebraic structure of this problem, many other tasks (e.g., simulation of finite automata and evaluation of boolean expressions) can be reduced to permutation composition, making it a natural model for state tracking in general. We show that LMs consistently learn one of two state tracking mechanisms for this task. The first closely resembles the \"associative scan\" construction used in recent theoretical work by Liu et al. (2023) and Merrill et al. (2024). The second uses an easy-to-compute feature (permutation parity) to partially prune the space of outputs, then refines this with an associative scan. The two mechanisms exhibit markedly different robustness properties, and we show how to steer LMs toward one or the other with intermediate training tasks that encourage or suppress the heuristics. Our results demonstrate that transformer LMs, whether pretrained or fine-tuned, can learn to implement efficient and interpretable state tracking mechanisms, and the emergence of these mechanisms can be predicted and controlled.","sentences":["Transformer language models (LMs) exhibit behaviors -- from storytelling to code generation -- that appear to require tracking the unobserved state of an evolving world.","How do they do so?","We study state tracking in LMs trained or fine-tuned to compose permutations (i.e., to compute the order of a set of objects after a sequence of swaps).","Despite the simple algebraic structure of this problem, many other tasks (e.g., simulation of finite automata and evaluation of boolean expressions) can be reduced to permutation composition, making it a natural model for state tracking in general.","We show that LMs consistently learn one of two state tracking mechanisms for this task.","The first closely resembles the \"associative scan\" construction used in recent theoretical work by Liu et al.","(2023) and Merrill et al. (2024).","The second uses an easy-to-compute feature (permutation parity) to partially prune the space of outputs, then refines this with an associative scan.","The two mechanisms exhibit markedly different robustness properties, and we show how to steer LMs toward one or the other with intermediate training tasks that encourage or suppress the heuristics.","Our results demonstrate that transformer LMs, whether pretrained or fine-tuned, can learn to implement efficient and interpretable state tracking mechanisms, and the emergence of these mechanisms can be predicted and controlled."],"url":"http://arxiv.org/abs/2503.02854v1"}
{"created":"2025-03-04 18:29:57","title":"CADDI: An in-Class Activity Detection Dataset using IMU data from low-cost sensors","abstract":"The monitoring and prediction of in-class student activities is of paramount importance for the comprehension of engagement and the enhancement of pedagogical efficacy. The accurate detection of these activities enables educators to modify their lessons in real time, thereby reducing negative emotional states and enhancing the overall learning experience. To this end, the use of non-intrusive devices, such as inertial measurement units (IMUs) embedded in smartwatches, represents a viable solution. The development of reliable predictive systems has been limited by the lack of large, labeled datasets in education. To bridge this gap, we present a novel dataset for in-class activity detection using affordable IMU sensors. The dataset comprises 19 diverse activities, both instantaneous and continuous, performed by 12 participants in typical classroom scenarios. It includes accelerometer, gyroscope, rotation vector data, and synchronized stereo images, offering a comprehensive resource for developing multimodal algorithms using sensor and visual data. This dataset represents a key step toward scalable solutions for activity recognition in educational settings.","sentences":["The monitoring and prediction of in-class student activities is of paramount importance for the comprehension of engagement and the enhancement of pedagogical efficacy.","The accurate detection of these activities enables educators to modify their lessons in real time, thereby reducing negative emotional states and enhancing the overall learning experience.","To this end, the use of non-intrusive devices, such as inertial measurement units (IMUs) embedded in smartwatches, represents a viable solution.","The development of reliable predictive systems has been limited by the lack of large, labeled datasets in education.","To bridge this gap, we present a novel dataset for in-class activity detection using affordable IMU sensors.","The dataset comprises 19 diverse activities, both instantaneous and continuous, performed by 12 participants in typical classroom scenarios.","It includes accelerometer, gyroscope, rotation vector data, and synchronized stereo images, offering a comprehensive resource for developing multimodal algorithms using sensor and visual data.","This dataset represents a key step toward scalable solutions for activity recognition in educational settings."],"url":"http://arxiv.org/abs/2503.02853v1"}
{"created":"2025-03-04 18:27:00","title":"Shakespearean Sparks: The Dance of Hallucination and Creativity in LLMs' Decoding Layers","abstract":"Large language models (LLMs) are known to hallucinate, a phenomenon often linked to creativity. While previous research has primarily explored this connection through theoretical or qualitative lenses, our work takes a quantitative approach to systematically examine the relationship between hallucination and creativity in LLMs. Given the complex nature of creativity, we propose a narrow definition tailored to LLMs and introduce an evaluation framework, HCL, which quantifies Hallucination and Creativity across different Layers of LLMs during decoding. Our empirical analysis reveals a tradeoff between hallucination and creativity that is consistent across layer depth, model type, and model size. Notably, across different model architectures, we identify a specific layer at each model size that optimally balances this tradeoff. Additionally, the optimal layer tends to appear in the early layers of larger models, and the confidence of the model is also significantly higher at this layer. These findings provide a quantitative perspective that offers new insights into the interplay between LLM creativity and hallucination. The code and data for our experiments are available at https://github.com/ZicongHe2002/HCL-Spark.","sentences":["Large language models (LLMs) are known to hallucinate, a phenomenon often linked to creativity.","While previous research has primarily explored this connection through theoretical or qualitative lenses, our work takes a quantitative approach to systematically examine the relationship between hallucination and creativity in LLMs.","Given the complex nature of creativity, we propose a narrow definition tailored to LLMs and introduce an evaluation framework, HCL, which quantifies Hallucination and Creativity across different Layers of LLMs during decoding.","Our empirical analysis reveals a tradeoff between hallucination and creativity that is consistent across layer depth, model type, and model size.","Notably, across different model architectures, we identify a specific layer at each model size that optimally balances this tradeoff.","Additionally, the optimal layer tends to appear in the early layers of larger models, and the confidence of the model is also significantly higher at this layer.","These findings provide a quantitative perspective that offers new insights into the interplay between LLM creativity and hallucination.","The code and data for our experiments are available at https://github.com/ZicongHe2002/HCL-Spark."],"url":"http://arxiv.org/abs/2503.02851v1"}
{"created":"2025-03-04 18:24:33","title":"Multimodal Deep Learning for Subtype Classification in Breast Cancer Using Histopathological Images and Gene Expression Data","abstract":"Molecular subtyping of breast cancer is crucial for personalized treatment and prognosis. Traditional classification approaches rely on either histopathological images or gene expression profiling, limiting their predictive power. In this study, we propose a deep multimodal learning framework that integrates histopathological images and gene expression data to classify breast cancer into BRCA.Luminal and BRCA.Basal / Her2 subtypes. Our approach employs a ResNet-50 model for image feature extraction and fully connected layers for gene expression processing, with a cross-attention fusion mechanism to enhance modality interaction. We conduct extensive experiments using five-fold cross-validation, demonstrating that our multimodal integration outperforms unimodal approaches in terms of classification accuracy, precision-recall AUC, and F1-score. Our findings highlight the potential of deep learning for robust and interpretable breast cancer subtype classification, paving the way for improved clinical decision-making.","sentences":["Molecular subtyping of breast cancer is crucial for personalized treatment and prognosis.","Traditional classification approaches rely on either histopathological images or gene expression profiling, limiting their predictive power.","In this study, we propose a deep multimodal learning framework that integrates histopathological images and gene expression data to classify breast cancer into BRCA.Luminal and BRCA.Basal / Her2 subtypes.","Our approach employs a ResNet-50 model for image feature extraction and fully connected layers for gene expression processing, with a cross-attention fusion mechanism to enhance modality interaction.","We conduct extensive experiments using five-fold cross-validation, demonstrating that our multimodal integration outperforms unimodal approaches in terms of classification accuracy, precision-recall AUC, and F1-score.","Our findings highlight the potential of deep learning for robust and interpretable breast cancer subtype classification, paving the way for improved clinical decision-making."],"url":"http://arxiv.org/abs/2503.02849v1"}
{"created":"2025-03-04 18:20:24","title":"Mask-DPO: Generalizable Fine-grained Factuality Alignment of LLMs","abstract":"Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains. Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preference learning inevitably introduced noises during training. Therefore, this paper proposes a fine-grained factuality alignment method based on Direct Preference Optimization (DPO), called Mask-DPO. Incorporating sentence-level factuality as mask signals, Mask-DPO only learns from factually correct sentences in the preferred samples and prevents the penalty on factual contents in the not preferred samples, which resolves the ambiguity in the preference learning. Extensive experimental results demonstrate that Mask-DPO can significantly improve the factuality of LLMs responses to questions from both in-domain and out-of-domain datasets, although these questions and their corresponding topics are unseen during training. Only trained on the ANAH train set, the score of Llama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%, even surpassing the score of Llama3.1-70B-Instruct (53.44%), while its FactScore on the out-of-domain Biography dataset is also improved from 30.29% to 39.39%. We further study the generalization property of Mask-DPO using different training sample scaling strategies and find that scaling the number of topics in the dataset is more effective than the number of questions. We provide a hypothesis of what factual alignment is doing with LLMs, on the implication of this phenomenon, and conduct proof-of-concept experiments to verify it. We hope the method and the findings pave the way for future research on scaling factuality alignment.","sentences":["Large language models (LLMs) exhibit hallucinations (i.e., unfaithful or nonsensical information) when serving as AI assistants in various domains.","Since hallucinations always come with truthful content in the LLM responses, previous factuality alignment methods that conduct response-level preference learning inevitably introduced noises during training.","Therefore, this paper proposes a fine-grained factuality alignment method based on Direct Preference Optimization (DPO), called Mask-DPO.","Incorporating sentence-level factuality as mask signals, Mask-DPO only learns from factually correct sentences in the preferred samples and prevents the penalty on factual contents in the not preferred samples, which resolves the ambiguity in the preference learning.","Extensive experimental results demonstrate that Mask-DPO can significantly improve the factuality of LLMs responses to questions from both in-domain and out-of-domain datasets, although these questions and their corresponding topics are unseen during training.","Only trained on the ANAH train set, the score of Llama3.1-8B-Instruct on the ANAH test set is improved from 49.19% to 77.53%, even surpassing the score of Llama3.1-70B-Instruct (53.44%), while its FactScore on the out-of-domain Biography dataset is also improved from 30.29% to 39.39%.","We further study the generalization property of Mask-DPO using different training sample scaling strategies and find that scaling the number of topics in the dataset is more effective than the number of questions.","We provide a hypothesis of what factual alignment is doing with LLMs, on the implication of this phenomenon, and conduct proof-of-concept experiments to verify it.","We hope the method and the findings pave the way for future research on scaling factuality alignment."],"url":"http://arxiv.org/abs/2503.02846v1"}
{"created":"2025-03-04 18:15:57","title":"Beyond Cosine Decay: On the effectiveness of Infinite Learning Rate Schedule for Continual Pre-training","abstract":"The ever-growing availability of unlabeled data presents both opportunities and challenges for training artificial intelligence systems. While self-supervised learning (SSL) has emerged as a powerful paradigm for extracting meaningful representations from vast amounts of unlabeled data, existing methods still struggle to adapt to the non-stationary, non-IID nature of real-world data streams without forgetting previously learned knowledge. Recent works have adopted a repeated cosine annealing schedule for large-scale continual pre-training; however, these schedules (1) inherently cause forgetting during the re-warming phase and (2) have not been systematically compared to existing continual SSL methods. In this work, we systematically compare the widely used cosine schedule with the recently proposed infinite learning rate schedule and empirically find the latter to be a more effective alternative. Our extensive empirical evaluation across diverse image and language datasets demonstrates that the infinite learning rate schedule consistently enhances continual pre-training performance compared to a repeated cosine decay without being restricted to a fixed iteration budget. For instance, in a small-scale MAE pre-training setup, it outperforms several strong baselines from the literature. We then scale up our experiments to larger MAE pre-training and autoregressive language model pre-training. Our results show that the infinite learning rate schedule remains effective at scale, surpassing repeated cosine decay for both MAE pre-training and zero-shot LM benchmarks.","sentences":["The ever-growing availability of unlabeled data presents both opportunities and challenges for training artificial intelligence systems.","While self-supervised learning (SSL) has emerged as a powerful paradigm for extracting meaningful representations from vast amounts of unlabeled data, existing methods still struggle to adapt to the non-stationary, non-IID nature of real-world data streams without forgetting previously learned knowledge.","Recent works have adopted a repeated cosine annealing schedule for large-scale continual pre-training; however, these schedules (1) inherently cause forgetting during the re-warming phase and (2) have not been systematically compared to existing continual SSL methods.","In this work, we systematically compare the widely used cosine schedule with the recently proposed infinite learning rate schedule and empirically find the latter to be a more effective alternative.","Our extensive empirical evaluation across diverse image and language datasets demonstrates that the infinite learning rate schedule consistently enhances continual pre-training performance compared to a repeated cosine decay without being restricted to a fixed iteration budget.","For instance, in a small-scale MAE pre-training setup, it outperforms several strong baselines from the literature.","We then scale up our experiments to larger MAE pre-training and autoregressive language model pre-training.","Our results show that the infinite learning rate schedule remains effective at scale, surpassing repeated cosine decay for both MAE pre-training and zero-shot LM benchmarks."],"url":"http://arxiv.org/abs/2503.02844v1"}
{"created":"2025-03-04 18:13:39","title":"Flipping Matchings is Hard","abstract":"Given a point set $\\mathcal{P}$ and a plane perfect matching $\\mathcal{M}$ on $\\mathcal{P}$, a flip is an operation that replaces two edges of $\\mathcal{M}$ such that another plane perfect matching on $\\mathcal{P}$ is obtained. Given two plane perfect matchings on $\\mathcal{P}$, we show that it is NP-hard to minimize the number of flips that are needed to transform one matching into the other.","sentences":["Given a point set $\\mathcal{P}$ and a plane perfect matching $\\mathcal{M}$ on $\\mathcal{P}$, a flip is an operation that replaces two edges of $\\mathcal{M}$ such that another plane perfect matching on $\\mathcal{P}$ is obtained.","Given two plane perfect matchings on $\\mathcal{P}$, we show that it is NP-hard to minimize the number of flips that are needed to transform one matching into the other."],"url":"http://arxiv.org/abs/2503.02842v1"}
{"created":"2025-03-04 18:12:58","title":"Boltzmann Attention Sampling for Image Analysis with Small Objects","abstract":"Detecting and segmenting small objects, such as lung nodules and tumor lesions, remains a critical challenge in image analysis. These objects often occupy less than 0.1% of an image, making traditional transformer architectures inefficient and prone to performance degradation due to redundant attention computations on irrelevant regions. Existing sparse attention mechanisms rely on rigid hierarchical structures, which are poorly suited for detecting small, variable, and uncertain object locations. In this paper, we propose BoltzFormer, a novel transformer-based architecture designed to address these challenges through dynamic sparse attention. BoltzFormer identifies and focuses attention on relevant areas by modeling uncertainty using a Boltzmann distribution with an annealing schedule. Initially, a higher temperature allows broader area sampling in early layers, when object location uncertainty is greatest. As the temperature decreases in later layers, attention becomes more focused, enhancing efficiency and accuracy. BoltzFormer seamlessly integrates into existing transformer architectures via a modular Boltzmann attention sampling mechanism. Comprehensive evaluations on benchmark datasets demonstrate that BoltzFormer significantly improves segmentation performance for small objects while reducing attention computation by an order of magnitude compared to previous state-of-the-art methods.","sentences":["Detecting and segmenting small objects, such as lung nodules and tumor lesions, remains a critical challenge in image analysis.","These objects often occupy less than 0.1% of an image, making traditional transformer architectures inefficient and prone to performance degradation due to redundant attention computations on irrelevant regions.","Existing sparse attention mechanisms rely on rigid hierarchical structures, which are poorly suited for detecting small, variable, and uncertain object locations.","In this paper, we propose BoltzFormer, a novel transformer-based architecture designed to address these challenges through dynamic sparse attention.","BoltzFormer identifies and focuses attention on relevant areas by modeling uncertainty using a Boltzmann distribution with an annealing schedule.","Initially, a higher temperature allows broader area sampling in early layers, when object location uncertainty is greatest.","As the temperature decreases in later layers, attention becomes more focused, enhancing efficiency and accuracy.","BoltzFormer seamlessly integrates into existing transformer architectures via a modular Boltzmann attention sampling mechanism.","Comprehensive evaluations on benchmark datasets demonstrate that BoltzFormer significantly improves segmentation performance for small objects while reducing attention computation by an order of magnitude compared to previous state-of-the-art methods."],"url":"http://arxiv.org/abs/2503.02841v1"}
{"created":"2025-03-04 17:59:17","title":"SeqFusion: Sequential Fusion of Pre-Trained Models for Zero-Shot Time-Series Forecasting","abstract":"Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data. Current zero-shot approaches primarily rely on pre-trained generalized models, with their performance often depending on the variety and relevance of the pre-training data, which can raise privacy concerns. Instead of collecting diverse pre-training data, we introduce SeqFusion in this work, a novel framework that collects and fuses diverse pre-trained models (PTMs) sequentially for zero-shot forecasting. Based on the specific temporal characteristics of the target time series, SeqFusion selects the most suitable PTMs from a batch of pre-collected PTMs, performs sequential predictions, and fuses all the predictions while using minimal data to protect privacy. Each of these PTMs specializes in different temporal patterns and forecasting tasks, allowing SeqFusion to select by measuring distances in a shared representation space of the target time series with each PTM. Experiments demonstrate that SeqFusion achieves competitive accuracy in zero-shot forecasting compared to state-of-the-art methods.","sentences":["Unlike traditional time-series forecasting methods that require extensive in-task data for training, zero-shot forecasting can directly predict future values given a target time series without additional training data.","Current zero-shot approaches primarily rely on pre-trained generalized models, with their performance often depending on the variety and relevance of the pre-training data, which can raise privacy concerns.","Instead of collecting diverse pre-training data, we introduce SeqFusion in this work, a novel framework that collects and fuses diverse pre-trained models (PTMs) sequentially for zero-shot forecasting.","Based on the specific temporal characteristics of the target time series, SeqFusion selects the most suitable PTMs from a batch of pre-collected PTMs, performs sequential predictions, and fuses all the predictions while using minimal data to protect privacy.","Each of these PTMs specializes in different temporal patterns and forecasting tasks, allowing SeqFusion to select by measuring distances in a shared representation space of the target time series with each PTM.","Experiments demonstrate that SeqFusion achieves competitive accuracy in zero-shot forecasting compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2503.02836v1"}
{"created":"2025-03-04 17:58:44","title":"In-Depth Analysis of Automated Acne Disease Recognition and Classification","abstract":"Facial acne is a common disease, especially among adolescents, negatively affecting both physically and psychologically. Classifying acne is vital to providing the appropriate treatment. Traditional visual inspection or expert scanning is time-consuming and difficult to differentiate acne types. This paper introduces an automated expert system for acne recognition and classification. The proposed method employs a machine learning-based technique to classify and evaluate six types of acne diseases to facilitate the diagnosis of dermatologists. The pre-processing phase includes contrast improvement, smoothing filter, and RGB to L*a*b color conversion to eliminate noise and improve the classification accuracy. Then, a clustering-based segmentation method, k-means clustering, is applied for segmenting the disease-affected regions that pass through the feature extraction step. Characteristics of these disease-affected regions are extracted based on a combination of gray-level co-occurrence matrix (GLCM) and Statistical features. Finally, five different machine learning classifiers are employed to classify acne diseases. Experimental results show that the Random Forest (RF) achieves the highest accuracy of 98.50%, which is promising compared to the state-of-the-art methods.","sentences":["Facial acne is a common disease, especially among adolescents, negatively affecting both physically and psychologically.","Classifying acne is vital to providing the appropriate treatment.","Traditional visual inspection or expert scanning is time-consuming and difficult to differentiate acne types.","This paper introduces an automated expert system for acne recognition and classification.","The proposed method employs a machine learning-based technique to classify and evaluate six types of acne diseases to facilitate the diagnosis of dermatologists.","The pre-processing phase includes contrast improvement, smoothing filter, and RGB to L*a*b color conversion to eliminate noise and improve the classification accuracy.","Then, a clustering-based segmentation method, k-means clustering, is applied for segmenting the disease-affected regions that pass through the feature extraction step.","Characteristics of these disease-affected regions are extracted based on a combination of gray-level co-occurrence matrix (GLCM) and Statistical features.","Finally, five different machine learning classifiers are employed to classify acne diseases.","Experimental results show that the Random Forest (RF) achieves the highest accuracy of 98.50%, which is promising compared to the state-of-the-art methods."],"url":"http://arxiv.org/abs/2503.02835v1"}
{"created":"2025-03-04 17:57:35","title":"MuBlE: MuJoCo and Blender simulation Environment and Benchmark for Task Planning in Robot Manipulation","abstract":"Current embodied reasoning agents struggle to plan for long-horizon tasks that require to physically interact with the world to obtain the necessary information (e.g. 'sort the objects from lightest to heaviest'). The improvement of the capabilities of such an agent is highly dependent on the availability of relevant training environments. In order to facilitate the development of such systems, we introduce a novel simulation environment (built on top of robosuite) that makes use of the MuJoCo physics engine and high-quality renderer Blender to provide realistic visual observations that are also accurate to the physical state of the scene. It is the first simulator focusing on long-horizon robot manipulation tasks preserving accurate physics modeling. MuBlE can generate mutlimodal data for training and enable design of closed-loop methods through environment interaction on two levels: visual - action loop, and control - physics loop. Together with the simulator, we propose SHOP-VRB2, a new benchmark composed of 10 classes of multi-step reasoning scenarios that require simultaneous visual and physical measurements.","sentences":["Current embodied reasoning agents struggle to plan for long-horizon tasks that require to physically interact with the world to obtain the necessary information (e.g. 'sort the objects from lightest to heaviest').","The improvement of the capabilities of such an agent is highly dependent on the availability of relevant training environments.","In order to facilitate the development of such systems, we introduce a novel simulation environment (built on top of robosuite) that makes use of the MuJoCo physics engine and high-quality renderer Blender to provide realistic visual observations that are also accurate to the physical state of the scene.","It is the first simulator focusing on long-horizon robot manipulation tasks preserving accurate physics modeling.","MuBlE can generate mutlimodal data for training and enable design of closed-loop methods through environment interaction on two levels: visual - action loop, and control - physics loop.","Together with the simulator, we propose SHOP-VRB2, a new benchmark composed of 10 classes of multi-step reasoning scenarios that require simultaneous visual and physical measurements."],"url":"http://arxiv.org/abs/2503.02834v1"}
{"created":"2025-03-04 17:57:26","title":"The Shift from Writing to Pruning Software: A Bonsai-Inspired IDE for Reshaping AI Generated Code","abstract":"The rise of AI-driven coding assistants signals a fundamental shift in how software is built. While AI coding assistants have been integrated into existing Integrated Development Environments (IDEs), their full potential remains largely untapped. A key challenge is that these AI assistants can suffer from hallucinations, leading developers down decision paths that the AI should not dictate, sometimes even without the users awareness or consent. Moreover, current static-file IDEs lack the mechanisms to address critical issues such as tracking the provenance of AI-generated code and integrating version control in a way that aligns with the dynamic nature of AI-assisted development. As a result, developers are left without the necessary tools to manage, refine, and validate AI generated code systematically, making it difficult to ensure correctness, maintainability, and trust in the development process. Existing IDEs treat AI-generated code as static text, offering limited support for managing its evolution, refinement, or multiple alternative paths.   Drawing inspiration from the ancient art of Japanese Bonsai gardening focused on balance, structure, and deliberate pruning: we propose a new approach to IDEs, where AI is allowed to generate in its true, unconstrained form, free from traditional file structures. This approach fosters a more fluid and interactive method for code evolution. We introduce the concept of a Bonsai-inspired IDE, structured as a graph of generated code snippets and multiple code paths, enabling developers to reshape AI generated code to suit their needs. Our vision calls for a shift away from a static file based model toward a dynamic, evolving system that allows for continuous refinement of generated code, with the IDE evolving alongside AI powered modifications rather than merely serving as a place to write and edit code.","sentences":["The rise of AI-driven coding assistants signals a fundamental shift in how software is built.","While AI coding assistants have been integrated into existing Integrated Development Environments (IDEs), their full potential remains largely untapped.","A key challenge is that these AI assistants can suffer from hallucinations, leading developers down decision paths that the AI should not dictate, sometimes even without the users awareness or consent.","Moreover, current static-file IDEs lack the mechanisms to address critical issues such as tracking the provenance of AI-generated code and integrating version control in a way that aligns with the dynamic nature of AI-assisted development.","As a result, developers are left without the necessary tools to manage, refine, and validate AI generated code systematically, making it difficult to ensure correctness, maintainability, and trust in the development process.","Existing IDEs treat AI-generated code as static text, offering limited support for managing its evolution, refinement, or multiple alternative paths.   ","Drawing inspiration from the ancient art of Japanese Bonsai gardening focused on balance, structure, and deliberate pruning: we propose a new approach to IDEs, where AI is allowed to generate in its true, unconstrained form, free from traditional file structures.","This approach fosters a more fluid and interactive method for code evolution.","We introduce the concept of a Bonsai-inspired IDE, structured as a graph of generated code snippets and multiple code paths, enabling developers to reshape AI generated code to suit their needs.","Our vision calls for a shift away from a static file based model toward a dynamic, evolving system that allows for continuous refinement of generated code, with the IDE evolving alongside AI powered modifications rather than merely serving as a place to write and edit code."],"url":"http://arxiv.org/abs/2503.02833v1"}
{"created":"2025-03-04 17:57:09","title":"AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation","abstract":"In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO). However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation. The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed. To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization. Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model. On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model. Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token. Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization.","sentences":["In modern large language models (LLMs), LLM alignment is of crucial importance and is typically achieved through methods such as reinforcement learning from human feedback (RLHF) and direct preference optimization (DPO).","However, in most existing methods for LLM alignment, all tokens in the response are optimized using a sparse, response-level reward or preference annotation.","The ignorance of token-level rewards may erroneously punish high-quality tokens or encourage low-quality tokens, resulting in suboptimal performance and slow convergence speed.","To address this issue, we propose AlignDistil, an RLHF-equivalent distillation method for token-level reward optimization.","Specifically, we introduce the reward learned by DPO into the RLHF objective and theoretically prove the equivalence between this objective and a token-level distillation process, where the teacher distribution linearly combines the logits from the DPO model and a reference model.","On this basis, we further bridge the accuracy gap between the reward from the DPO model and the pure reward model, by building a contrastive DPO reward with a normal and a reverse DPO model.","Moreover, to avoid under- and over-optimization on different tokens, we design a token adaptive logit extrapolation mechanism to construct an appropriate teacher distribution for each token.","Experimental results demonstrate the superiority of our AlignDistil over existing methods and showcase fast convergence due to its token-level distributional reward optimization."],"url":"http://arxiv.org/abs/2503.02832v1"}
{"created":"2025-03-04 17:55:38","title":"Meta-Learning to Explore via Memory Density Feedback","abstract":"Exploration algorithms for reinforcement learning typically replace or augment the reward function with an additional ``intrinsic'' reward that trains the agent to seek previously unseen states of the environment. Here, we consider an exploration algorithm that exploits meta-learning, or learning to learn, such that the agent learns to maximize its exploration progress within a single episode, even between epochs of training. The agent learns a policy that aims to minimize the probability density of new observations with respect to all of its memories. In addition, it receives as feedback evaluations of the current observation density and retains that feedback in a recurrent network. By remembering trajectories of density, the agent learns to navigate a complex and growing landscape of familiarity in real-time, allowing it to maximize its exploration progress even in completely novel states of the environment for which its policy has not been trained.","sentences":["Exploration algorithms for reinforcement learning typically replace or augment the reward function with an additional ``intrinsic'' reward that trains the agent to seek previously unseen states of the environment.","Here, we consider an exploration algorithm that exploits meta-learning, or learning to learn, such that the agent learns to maximize its exploration progress within a single episode, even between epochs of training.","The agent learns a policy that aims to minimize the probability density of new observations with respect to all of its memories.","In addition, it receives as feedback evaluations of the current observation density and retains that feedback in a recurrent network.","By remembering trajectories of density, the agent learns to navigate a complex and growing landscape of familiarity in real-time, allowing it to maximize its exploration progress even in completely novel states of the environment for which its policy has not been trained."],"url":"http://arxiv.org/abs/2503.02831v1"}
{"created":"2025-03-04 17:49:24","title":"On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate Convergence of Learning in Games","abstract":"Non-ergodic convergence of learning dynamics in games is widely studied recently because of its importance in both theory and practice. Recent work (Cai et al., 2024) showed that a broad class of learning dynamics, including Optimistic Multiplicative Weights Update (OMWU), can exhibit arbitrarily slow last-iterate convergence even in simple $2 \\times 2$ matrix games, despite many of these dynamics being known to converge asymptotically in the last iterate. It remains unclear, however, whether these algorithms achieve fast non-ergodic convergence under weaker criteria, such as best-iterate convergence. We show that for $2\\times 2$ matrix games, OMWU achieves an $O(T^{-1/6})$ best-iterate convergence rate, in stark contrast to its slow last-iterate convergence in the same class of games. Furthermore, we establish a lower bound showing that OMWU does not achieve any polynomial random-iterate convergence rate, measured by the expected duality gaps across all iterates. This result challenges the conventional wisdom that random-iterate convergence is essentially equivalent to best-iterate convergence, with the former often used as a proxy for establishing the latter. Our analysis uncovers a new connection to dynamic regret and presents a novel two-phase approach to best-iterate convergence, which could be of independent interest.","sentences":["Non-ergodic convergence of learning dynamics in games is widely studied recently because of its importance in both theory and practice.","Recent work (Cai et al., 2024) showed that a broad class of learning dynamics, including Optimistic Multiplicative Weights Update (OMWU), can exhibit arbitrarily slow last-iterate convergence even in simple $2 \\times 2$ matrix games, despite many of these dynamics being known to converge asymptotically in the last iterate.","It remains unclear, however, whether these algorithms achieve fast non-ergodic convergence under weaker criteria, such as best-iterate convergence.","We show that for $2\\times 2$ matrix games, OMWU achieves an $O(T^{-1/6})$ best-iterate convergence rate, in stark contrast to its slow last-iterate convergence in the same class of games.","Furthermore, we establish a lower bound showing that OMWU does not achieve any polynomial random-iterate convergence rate, measured by the expected duality gaps across all iterates.","This result challenges the conventional wisdom that random-iterate convergence is essentially equivalent to best-iterate convergence, with the former often used as a proxy for establishing the latter.","Our analysis uncovers a new connection to dynamic regret and presents a novel two-phase approach to best-iterate convergence, which could be of independent interest."],"url":"http://arxiv.org/abs/2503.02825v1"}
{"created":"2025-03-04 17:49:07","title":"Developing a PET/CT Foundation Model for Cross-Modal Anatomical and Functional Imaging","abstract":"In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is widely used in cancer diagnosis, staging, and treatment monitoring, as it combines anatomical details from CT with functional metabolic activity and molecular marker expression information from PET. However, existing artificial intelligence-driven PET/CT analyses rely predominantly on task-specific models trained from scratch or on limited datasets, limiting their generalizability and robustness. To address this, we propose a foundation model approach specifically designed for multimodal PET/CT imaging. We introduce the Cross-Fraternal Twin Masked Autoencoder (FratMAE), a novel framework that effectively integrates whole-body anatomical and functional or molecular information. FratMAE employs separate Vision Transformer (ViT) encoders for PET and CT scans, along with cross-attention decoders that enable synergistic interactions between modalities during masked autoencoder training. Additionally, it incorporates textual metadata to enhance PET representation learning. By pre-training on PET/CT datasets, FratMAE captures intricate cross-modal relationships and global uptake patterns, achieving superior performance on downstream tasks and demonstrating its potential as a generalizable foundation model.","sentences":["In oncology, Positron Emission Tomography-Computed Tomography (PET/CT) is widely used in cancer diagnosis, staging, and treatment monitoring, as it combines anatomical details from CT with functional metabolic activity and molecular marker expression information from PET.","However, existing artificial intelligence-driven PET/CT analyses rely predominantly on task-specific models trained from scratch or on limited datasets, limiting their generalizability and robustness.","To address this, we propose a foundation model approach specifically designed for multimodal PET/CT imaging.","We introduce the Cross-Fraternal Twin Masked Autoencoder (FratMAE), a novel framework that effectively integrates whole-body anatomical and functional or molecular information.","FratMAE employs separate Vision Transformer (ViT) encoders for PET and CT scans, along with cross-attention decoders that enable synergistic interactions between modalities during masked autoencoder training.","Additionally, it incorporates textual metadata to enhance PET representation learning.","By pre-training on PET/CT datasets, FratMAE captures intricate cross-modal relationships and global uptake patterns, achieving superior performance on downstream tasks and demonstrating its potential as a generalizable foundation model."],"url":"http://arxiv.org/abs/2503.02824v1"}
{"created":"2025-03-04 17:48:48","title":"A Multimodal Symphony: Integrating Taste and Sound through Generative AI","abstract":"In recent decades, neuroscientific and psychological research has traced direct relationships between taste and auditory perceptions. This article explores multimodal generative models capable of converting taste information into music, building on this foundational research. We provide a brief review of the state of the art in this field, highlighting key findings and methodologies. We present an experiment in which a fine-tuned version of a generative music model (MusicGEN) is used to generate music based on detailed taste descriptions provided for each musical piece. The results are promising: according the participants' ($n=111$) evaluation, the fine-tuned model produces music that more coherently reflects the input taste descriptions compared to the non-fine-tuned model. This study represents a significant step towards understanding and developing embodied interactions between AI, sound, and taste, opening new possibilities in the field of generative AI. We release our dataset, code and pre-trained model at: https://osf.io/xs5jy/.","sentences":["In recent decades, neuroscientific and psychological research has traced direct relationships between taste and auditory perceptions.","This article explores multimodal generative models capable of converting taste information into music, building on this foundational research.","We provide a brief review of the state of the art in this field, highlighting key findings and methodologies.","We present an experiment in which a fine-tuned version of a generative music model (MusicGEN) is used to generate music based on detailed taste descriptions provided for each musical piece.","The results are promising: according the participants' ($n=111$) evaluation, the fine-tuned model produces music that more coherently reflects the input taste descriptions compared to the non-fine-tuned model.","This study represents a significant step towards understanding and developing embodied interactions between AI, sound, and taste, opening new possibilities in the field of generative AI.","We release our dataset, code and pre-trained model at: https://osf.io/xs5jy/."],"url":"http://arxiv.org/abs/2503.02823v1"}
{"created":"2025-03-04 17:47:27","title":"Integral Forms in Matrix Lie Groups","abstract":"Matrix Lie groups provide a language for describing motion in such fields as robotics, computer vision, and graphics. When using these tools, we are often faced with turning infinite-series expressions into more compact finite series (e.g., the Euler-Rodriques formula), which can sometimes be onerous. In this paper, we identify some useful integral forms in matrix Lie group expressions that offer a more streamlined pathway for computing compact analytic results. Moreover, we present some recursive structures in these integral forms that show many of these expressions are interrelated. Key to our approach is that we are able to apply the minimal polynomial for a Lie algebra quite early in the process to keep expressions compact throughout the derivations. With the series approach, the minimal polynomial is usually applied at the end, making it hard to recognize common analytic expressions in the result. We show that our integral method can reproduce several series-derived results from the literature.","sentences":["Matrix Lie groups provide a language for describing motion in such fields as robotics, computer vision, and graphics.","When using these tools, we are often faced with turning infinite-series expressions into more compact finite series (e.g., the Euler-Rodriques formula), which can sometimes be onerous.","In this paper, we identify some useful integral forms in matrix Lie group expressions that offer a more streamlined pathway for computing compact analytic results.","Moreover, we present some recursive structures in these integral forms that show many of these expressions are interrelated.","Key to our approach is that we are able to apply the minimal polynomial for a Lie algebra quite early in the process to keep expressions compact throughout the derivations.","With the series approach, the minimal polynomial is usually applied at the end, making it hard to recognize common analytic expressions in the result.","We show that our integral method can reproduce several series-derived results from the literature."],"url":"http://arxiv.org/abs/2503.02820v1"}
{"created":"2025-03-04 17:46:51","title":"Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts","abstract":"While score-based generative models are the model of choice across diverse domains, there are limited tools available for controlling inference-time behavior in a principled manner, e.g. for composing multiple pretrained models. Existing classifier-free guidance methods use a simple heuristic to mix conditional and unconditional scores to approximately sample from conditional distributions. However, such methods do not approximate the intermediate distributions, necessitating additional 'corrector' steps. In this work, we provide an efficient and principled method for sampling from a sequence of annealed, geometric-averaged, or product distributions derived from pretrained score-based models. We derive a weighted simulation scheme which we call Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by carefully accounting for terms in the appropriate partial differential equations (PDEs). To simulate these PDEs, we propose Sequential Monte Carlo (SMC) resampling algorithms that leverage inference-time scaling to improve sampling quality. We empirically demonstrate the utility of our methods by proposing amortized sampling via inference-time temperature annealing, improving multi-objective molecule generation using pretrained models, and improving classifier-free guidance for text-to-image generation. Our code is available at https://github.com/martaskrt/fkc-diffusion.","sentences":["While score-based generative models are the model of choice across diverse domains, there are limited tools available for controlling inference-time behavior in a principled manner, e.g. for composing multiple pretrained models.","Existing classifier-free guidance methods use a simple heuristic to mix conditional and unconditional scores to approximately sample from conditional distributions.","However, such methods do not approximate the intermediate distributions, necessitating additional 'corrector' steps.","In this work, we provide an efficient and principled method for sampling from a sequence of annealed, geometric-averaged, or product distributions derived from pretrained score-based models.","We derive a weighted simulation scheme which we call Feynman-Kac Correctors (FKCs) based on the celebrated Feynman-Kac formula by carefully accounting for terms in the appropriate partial differential equations (PDEs).","To simulate these PDEs, we propose Sequential Monte Carlo (SMC) resampling algorithms that leverage inference-time scaling to improve sampling quality.","We empirically demonstrate the utility of our methods by proposing amortized sampling via inference-time temperature annealing, improving multi-objective molecule generation using pretrained models, and improving classifier-free guidance for text-to-image generation.","Our code is available at https://github.com/martaskrt/fkc-diffusion."],"url":"http://arxiv.org/abs/2503.02819v1"}
{"created":"2025-03-04 17:44:01","title":"Open Source at a Crossroads: The Future of Licensing Driven by Monetization","abstract":"The widespread adoption of open source libraries and frameworks can be attributed to their licensing. Open Source Software Licenses (OSS licenses) ensure that software can be sold or distributed as part of aggregate programs from various sources without requiring a royalty or fee. The quality of such code rivals that of commercial software, with open source libraries forming large parts of the supply chain for critical commercial systems in industry. Despite this, most open source projects rely on volunteer contributions, and unpaid library maintainers face significant pressure to sustain their projects. One potential solution for these projects is to change their licensing to ensure that maintainers are compensated accordingly for their work. In this paper, we explore the potential of licensing to help alleviate funding issues, with a review of three different cases where OSS licenses were modified to allow for monetization. In addition, we explore licensing concerns related to the emergence of the use of artificial intelligence (AI) in software development. We argue that open source is at a crossroads, with a growing need to redefine its licensing models and support communities and critical software. We identify specific research opportunities and conclude with a research agenda comprising a series of research questions to guide future studies in this area.","sentences":["The widespread adoption of open source libraries and frameworks can be attributed to their licensing.","Open Source Software Licenses (OSS licenses) ensure that software can be sold or distributed as part of aggregate programs from various sources without requiring a royalty or fee.","The quality of such code rivals that of commercial software, with open source libraries forming large parts of the supply chain for critical commercial systems in industry.","Despite this, most open source projects rely on volunteer contributions, and unpaid library maintainers face significant pressure to sustain their projects.","One potential solution for these projects is to change their licensing to ensure that maintainers are compensated accordingly for their work.","In this paper, we explore the potential of licensing to help alleviate funding issues, with a review of three different cases where OSS licenses were modified to allow for monetization.","In addition, we explore licensing concerns related to the emergence of the use of artificial intelligence (AI) in software development.","We argue that open source is at a crossroads, with a growing need to redefine its licensing models and support communities and critical software.","We identify specific research opportunities and conclude with a research agenda comprising a series of research questions to guide future studies in this area."],"url":"http://arxiv.org/abs/2503.02817v1"}
{"created":"2025-03-04 17:43:36","title":"\"What If Smart Homes Could See Our Homes?\": Exploring DIY Smart Home Building Experiences with VLM-Based Camera Sensors","abstract":"The advancement of Vision-Language Model (VLM) camera sensors, which enable autonomous understanding of household situations without user intervention, has the potential to completely transform the DIY smart home building experience. Will this simplify or complicate the DIY smart home process? Additionally, what features do users want to create using these sensors? To explore this, we conducted a three-week diary-based experience prototyping study with 12 participants. Participants recorded their daily activities, used GPT to analyze the images, and manually customized and tested smart home features based on the analysis. The study revealed three key findings: (1) participants' expectations for VLM camera-based smart homes, (2) the impact of VLM camera sensor characteristics on the DIY process, and (3) users' concerns. Through the findings of this study, we propose design implications to support the DIY smart home building process with VLM camera sensors, and discuss living with intelligence.","sentences":["The advancement of Vision-Language Model (VLM) camera sensors, which enable autonomous understanding of household situations without user intervention, has the potential to completely transform the DIY smart home building experience.","Will this simplify or complicate the DIY smart home process?","Additionally, what features do users want to create using these sensors?","To explore this, we conducted a three-week diary-based experience prototyping study with 12 participants.","Participants recorded their daily activities, used GPT to analyze the images, and manually customized and tested smart home features based on the analysis.","The study revealed three key findings: (1) participants' expectations for VLM camera-based smart homes, (2) the impact of VLM camera sensor characteristics on the DIY process, and (3) users' concerns.","Through the findings of this study, we propose design implications to support the DIY smart home building process with VLM camera sensors, and discuss living with intelligence."],"url":"http://arxiv.org/abs/2503.02816v1"}
{"created":"2025-03-04 17:37:49","title":"Q-Filters: Leveraging QK Geometry for Efficient KV Cache Compression","abstract":"Autoregressive language models rely on a Key-Value (KV) Cache, which avoids re-computing past hidden states during generation, making it faster. As model sizes and context lengths grow, the KV Cache becomes a significant memory bottleneck, which calls for compression methods that limit its size during generation. In this paper, we discover surprising properties of Query (Q) and Key (K) vectors that allow us to efficiently approximate attention scores without computing the attention maps. We propose Q-Filters, a training-free KV Cache compression method that filters out less crucial Key-Value pairs based on a single context-agnostic projection. Contrarily to many alternatives, Q-Filters is compatible with FlashAttention, as it does not require direct access to attention weights. Experimental results in long-context settings demonstrate that Q-Filters is competitive with attention-based compression methods such as SnapKV in retrieval tasks while consistently outperforming efficient compression schemes such as Streaming-LLM in generation setups. Notably, Q-Filters achieves a 99% accuracy in the needle-in-a-haystack task with a x32 compression level while reducing the generation perplexity drop by up to 65% in text generation compared to Streaming-LLM.","sentences":["Autoregressive language models rely on a Key-Value (KV) Cache, which avoids re-computing past hidden states during generation, making it faster.","As model sizes and context lengths grow, the KV Cache becomes a significant memory bottleneck, which calls for compression methods that limit its size during generation.","In this paper, we discover surprising properties of Query (Q) and Key (K) vectors that allow us to efficiently approximate attention scores without computing the attention maps.","We propose Q-Filters, a training-free KV Cache compression method that filters out less crucial Key-Value pairs based on a single context-agnostic projection.","Contrarily to many alternatives, Q-Filters is compatible with FlashAttention, as it does not require direct access to attention weights.","Experimental results in long-context settings demonstrate that Q-Filters is competitive with attention-based compression methods such as SnapKV in retrieval tasks while consistently outperforming efficient compression schemes such as Streaming-LLM in generation setups.","Notably, Q-Filters achieves a 99% accuracy in the needle-in-a-haystack task with a x32 compression level while reducing the generation perplexity drop by up to 65% in text generation compared to Streaming-LLM."],"url":"http://arxiv.org/abs/2503.02812v1"}
{"created":"2025-03-04 17:35:13","title":"A Minimalist Example of Edge-of-Stability and Progressive Sharpening","abstract":"Recent advances in deep learning optimization have unveiled two intriguing phenomena under large learning rates: Edge of Stability (EoS) and Progressive Sharpening (PS), challenging classical Gradient Descent (GD) analyses. Current research approaches, using either generalist frameworks or minimalist examples, face significant limitations in explaining these phenomena. This paper advances the minimalist approach by introducing a two-layer network with a two-dimensional input, where one dimension is relevant to the response and the other is irrelevant. Through this model, we rigorously prove the existence of progressive sharpening and self-stabilization under large learning rates, and establish non-asymptotic analysis of the training dynamics and sharpness along the entire GD trajectory. Besides, we connect our minimalist example to existing works by reconciling the existence of a well-behaved ``stable set\" between minimalist and generalist analyses, and extending the analysis of Gradient Flow Solution sharpness to our two-dimensional input scenario. These findings provide new insights into the EoS phenomenon from both parameter and input data distribution perspectives, potentially informing more effective optimization strategies in deep learning practice.","sentences":["Recent advances in deep learning optimization have unveiled two intriguing phenomena under large learning rates: Edge of Stability (EoS) and Progressive Sharpening (PS), challenging classical Gradient Descent (GD) analyses.","Current research approaches, using either generalist frameworks or minimalist examples, face significant limitations in explaining these phenomena.","This paper advances the minimalist approach by introducing a two-layer network with a two-dimensional input, where one dimension is relevant to the response and the other is irrelevant.","Through this model, we rigorously prove the existence of progressive sharpening and self-stabilization under large learning rates, and establish non-asymptotic analysis of the training dynamics and sharpness along the entire GD trajectory.","Besides, we connect our minimalist example to existing works by reconciling the existence of a well-behaved ``stable set\" between minimalist and generalist analyses, and extending the analysis of Gradient Flow Solution sharpness to our two-dimensional input scenario.","These findings provide new insights into the EoS phenomenon from both parameter and input data distribution perspectives, potentially informing more effective optimization strategies in deep learning practice."],"url":"http://arxiv.org/abs/2503.02809v1"}
{"created":"2025-03-04 17:26:34","title":"Rethinking Reuse in Dependency Supply Chains: Initial Analysis of NPM packages at the End of the Chain","abstract":"The success of modern software development can be largely attributed to the concept of code reuse, such as the ability to reuse existing functionality via third-party package dependencies, evident within massive package networks like NPM, PyPI and Maven. For a long time, the dominant philosophy has been to `reuse as much as possible, without thought for what is being depended upon', resulting in the formation of large dependency supply chains that spread throughout entire software ecosystems. Such heavy reliance on third-party packages has eventually brought forward resilience and maintenance concerns, such as security attacks and outdated dependencies. In this vision paper, we investigate packages that challenge the typical concepts of reuse--that is, packages with no dependencies themselves that bear the responsibility of being at the end of the dependency supply chain. We find that these end-of-chain packages vary in characteristics and not just packages that can be easily replaced: an active, well-maintained package at the end of the chain; a \"classical\" package that has remained unchanged for 11 years; a trivial package nested deep in the dependency chain; a package that may appear trivial; and a package that bundled up and absorbed its dependencies. The vision of this paper is to advocate for a shift in software development practices toward minimizing reliance on third-party packages, particularly those at the end of dependency supply chains. We argue that these end-of-chain packages offer unique insights, as they play a key role in the ecosystem.","sentences":["The success of modern software development can be largely attributed to the concept of code reuse, such as the ability to reuse existing functionality via third-party package dependencies, evident within massive package networks like NPM, PyPI and Maven.","For a long time, the dominant philosophy has been to `reuse as much as possible, without thought for what is being depended upon', resulting in the formation of large dependency supply chains that spread throughout entire software ecosystems.","Such heavy reliance on third-party packages has eventually brought forward resilience and maintenance concerns, such as security attacks and outdated dependencies.","In this vision paper, we investigate packages that challenge the typical concepts of reuse--that is, packages with no dependencies themselves that bear the responsibility of being at the end of the dependency supply chain.","We find that these end-of-chain packages vary in characteristics and not just packages that can be easily replaced: an active, well-maintained package at the end of the chain; a \"classical\" package that has remained unchanged for 11 years; a trivial package nested deep in the dependency chain; a package that may appear trivial; and a package that bundled up and absorbed its dependencies.","The vision of this paper is to advocate for a shift in software development practices toward minimizing reliance on third-party packages, particularly those at the end of dependency supply chains.","We argue that these end-of-chain packages offer unique insights, as they play a key role in the ecosystem."],"url":"http://arxiv.org/abs/2503.02804v1"}
{"created":"2025-03-04 17:20:43","title":"RAAD-LLM: Adaptive Anomaly Detection Using LLMs and RAG Integration","abstract":"Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions. Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge. In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG). This approach addresses the aforementioned PdM challenges. By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring fine-tuning on specific datasets. The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy. We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB). Results show significant improvements over our previous model with an accuracy increase from 70.7 to 89.1 on the real-world dataset. By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators. Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries.","sentences":["Anomaly detection in complex industrial environments poses unique challenges, particularly in contexts characterized by data sparsity and evolving operational conditions.","Predictive maintenance (PdM) in such settings demands methodologies that are adaptive, transferable, and capable of integrating domain-specific knowledge.","In this paper, we present RAAD-LLM, a novel framework for adaptive anomaly detection, leveraging large language models (LLMs) integrated with Retrieval-Augmented Generation (RAG).","This approach addresses the aforementioned PdM challenges.","By effectively utilizing domain-specific knowledge, RAAD-LLM enhances the detection of anomalies in time series data without requiring fine-tuning on specific datasets.","The framework's adaptability mechanism enables it to adjust its understanding of normal operating conditions dynamically, thus increasing detection accuracy.","We validate this methodology through a real-world application for a plastics manufacturing plant and the Skoltech Anomaly Benchmark (SKAB).","Results show significant improvements over our previous model with an accuracy increase from 70.7 to 89.1 on the real-world dataset.","By allowing for the enriching of input series data with semantics, RAAD-LLM incorporates multimodal capabilities that facilitate more collaborative decision-making between the model and plant operators.","Overall, our findings support RAAD-LLM's ability to revolutionize anomaly detection methodologies in PdM, potentially leading to a paradigm shift in how anomaly detection is implemented across various industries."],"url":"http://arxiv.org/abs/2503.02800v1"}
{"created":"2025-03-04 17:18:43","title":"MX-Font++: Mixture of Heterogeneous Aggregation Experts for Few-shot Font Generation","abstract":"Few-shot Font Generation (FFG) aims to create new font libraries using limited reference glyphs, with crucial applications in digital accessibility and equity for low-resource languages, especially in multilingual artificial intelligence systems. Although existing methods have shown promising performance, transitioning to unseen characters in low-resource languages remains a significant challenge, especially when font glyphs vary considerably across training sets. MX-Font considers the content of a character from the perspective of a local component, employing a Mixture of Experts (MoE) approach to adaptively extract the component for better transition. However, the lack of a robust feature extractor prevents them from adequately decoupling content and style, leading to sub-optimal generation results. To alleviate these problems, we propose Heterogeneous Aggregation Experts (HAE), a powerful feature extraction expert that helps decouple content and style downstream from being able to aggregate information in channel and spatial dimensions. Additionally, we propose a novel content-style homogeneity loss to enhance the untangling. Extensive experiments on several datasets demonstrate that our MX-Font++ yields superior visual results in FFG and effectively outperforms state-of-the-art methods. Code and data are available at https://github.com/stephensun11/MXFontpp.","sentences":["Few-shot Font Generation (FFG) aims to create new font libraries using limited reference glyphs, with crucial applications in digital accessibility and equity for low-resource languages, especially in multilingual artificial intelligence systems.","Although existing methods have shown promising performance, transitioning to unseen characters in low-resource languages remains a significant challenge, especially when font glyphs vary considerably across training sets.","MX-Font considers the content of a character from the perspective of a local component, employing a Mixture of Experts (MoE) approach to adaptively extract the component for better transition.","However, the lack of a robust feature extractor prevents them from adequately decoupling content and style, leading to sub-optimal generation results.","To alleviate these problems, we propose Heterogeneous Aggregation Experts (HAE), a powerful feature extraction expert that helps decouple content and style downstream from being able to aggregate information in channel and spatial dimensions.","Additionally, we propose a novel content-style homogeneity loss to enhance the untangling.","Extensive experiments on several datasets demonstrate that our MX-Font++ yields superior visual results in FFG and effectively outperforms state-of-the-art methods.","Code and data are available at https://github.com/stephensun11/MXFontpp."],"url":"http://arxiv.org/abs/2503.02799v1"}
{"created":"2025-03-04 17:15:31","title":"A Causal Framework for Aligning Image Quality Metrics and Deep Neural Network Robustness","abstract":"Image quality plays an important role in the performance of deep neural networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to changes in imaging conditions. Large-scale datasets often contain images under a wide range of conditions prompting a need to quantify and understand their underlying quality distribution in order to better characterize DNN performance and robustness. Aligning the sensitivities of image quality metrics and DNNs ensures that estimates of quality can act as proxies for image/dataset difficulty independent of the task models trained/evaluated on the data. Conventional image quality assessment (IQA) seeks to measure and align quality relative to human perceptual judgments, but here we seek a quality measure that is not only sensitive to imaging conditions but also well-aligned with DNN sensitivities. We first ask whether conventional IQA metrics are also informative of DNN performance. In order to answer this question, we reframe IQA from a causal perspective and examine conditions under which quality metrics are predictive of DNN performance. We show theoretically and empirically that current IQA metrics are weak predictors of DNN performance in the context of classification. We then use our causal framework to provide an alternative formulation and a new image quality metric that is more strongly correlated with DNN performance and can act as a prior on performance without training new task models. Our approach provides a means to directly estimate the quality distribution of large-scale image datasets towards characterizing the relationship between dataset composition and DNN performance.","sentences":["Image quality plays an important role in the performance of deep neural networks (DNNs) and DNNs have been widely shown to exhibit sensitivity to changes in imaging conditions.","Large-scale datasets often contain images under a wide range of conditions prompting a need to quantify and understand their underlying quality distribution in order to better characterize DNN performance and robustness.","Aligning the sensitivities of image quality metrics and DNNs ensures that estimates of quality can act as proxies for image/dataset difficulty independent of the task models trained/evaluated on the data.","Conventional image quality assessment (IQA) seeks to measure and align quality relative to human perceptual judgments, but here we seek a quality measure that is not only sensitive to imaging conditions but also well-aligned with DNN sensitivities.","We first ask whether conventional IQA metrics are also informative of DNN performance.","In order to answer this question, we reframe IQA from a causal perspective and examine conditions under which quality metrics are predictive of DNN performance.","We show theoretically and empirically that current IQA metrics are weak predictors of DNN performance in the context of classification.","We then use our causal framework to provide an alternative formulation and a new image quality metric that is more strongly correlated with DNN performance and can act as a prior on performance without training new task models.","Our approach provides a means to directly estimate the quality distribution of large-scale image datasets towards characterizing the relationship between dataset composition and DNN performance."],"url":"http://arxiv.org/abs/2503.02797v1"}
{"created":"2025-03-04 16:57:53","title":"Do Not Trust Licenses You See -- Dataset Compliance Requires Massive-Scale AI-Powered Lifecycle Tracing","abstract":"This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this process is too complex for legal experts to handle manually at scale. Tracking dataset provenance, verifying redistribution rights, and assessing evolving legal risks across multiple stages require a level of precision and efficiency that exceeds human capabilities. Addressing this challenge effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance, and identify legal risks. We develop an automated data compliance system called NEXUS and show that AI can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts. Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach reveals the discrepancies in legal rights between the original datasets before redistribution and their redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance, we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21%) are legally permissible for commercialization. This work sets a new standard for AI data governance, advocating for a framework that systematically examines the entire lifecycle of dataset redistribution to ensure transparent, legal, and responsible dataset management.","sentences":["This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential.","However, this process is too complex for legal experts to handle manually at scale.","Tracking dataset provenance, verifying redistribution rights, and assessing evolving legal risks across multiple stages require a level of precision and efficiency that exceeds human capabilities.","Addressing this challenge effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance, and identify legal risks.","We develop an automated data compliance system called NEXUS and show that AI can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts.","Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach reveals the discrepancies in legal rights between the original datasets before redistribution and their redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance.","For instance, we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21%) are legally permissible for commercialization.","This work sets a new standard for AI data governance, advocating for a framework that systematically examines the entire lifecycle of dataset redistribution to ensure transparent, legal, and responsible dataset management."],"url":"http://arxiv.org/abs/2503.02784v1"}
{"created":"2025-03-04 16:56:34","title":"IterPref: Focal Preference Learning for Code Generation via Iterative Debugging","abstract":"Preference learning enhances Code LLMs beyond supervised fine-tuning by leveraging relative quality comparisons. Existing methods construct preference pairs from   candidates based on test case success, treating the higher pass rate sample as positive and the lower as negative. However, this approach does not pinpoint specific errors in the code, which prevents the model from learning more informative error correction patterns, as aligning failing code as a whole lacks the granularity needed to capture meaningful error-resolution relationships. To address these issues, we propose IterPref, a new preference alignment framework that mimics human iterative debugging to refine Code LLMs. IterPref explicitly locates error regions and aligns the corresponding tokens via a tailored DPO algorithm. To generate informative pairs, we introduce the CodeFlow dataset, where samples are iteratively refined until passing tests, with modifications capturing error corrections. Extensive experiments show that a diverse suite of Code LLMs equipped with IterPref achieves significant performance gains in code generation and improves on challenging tasks like BigCodeBench. In-depth analysis reveals that IterPref yields fewer errors. Our code and data will be made publicaly available.","sentences":["Preference learning enhances Code LLMs beyond supervised fine-tuning by leveraging relative quality comparisons.","Existing methods construct preference pairs from   candidates based on test case success, treating the higher pass rate sample as positive and the lower as negative.","However, this approach does not pinpoint specific errors in the code, which prevents the model from learning more informative error correction patterns, as aligning failing code as a whole lacks the granularity needed to capture meaningful error-resolution relationships.","To address these issues, we propose IterPref, a new preference alignment framework that mimics human iterative debugging to refine Code LLMs.","IterPref explicitly locates error regions and aligns the corresponding tokens via a tailored DPO algorithm.","To generate informative pairs, we introduce the CodeFlow dataset, where samples are iteratively refined until passing tests, with modifications capturing error corrections.","Extensive experiments show that a diverse suite of Code LLMs equipped with IterPref achieves significant performance gains in code generation and improves on challenging tasks like BigCodeBench.","In-depth analysis reveals that IterPref yields fewer errors.","Our code and data will be made publicaly available."],"url":"http://arxiv.org/abs/2503.02783v1"}
{"created":"2025-03-04 16:56:16","title":"Undetected Error Probability in the Short Blocklength Regime: Approaching Finite-Blocklength Bounds with Polar Codes","abstract":"We analyze the trade-off between the undetected error probability (i.e., the probability that the channel decoder outputs an erroneous message without detecting the error) and the total error probability in the short blocklength regime. We address the problem by developing two new finite blocklength achievability bounds, which we use to benchmark the performance of two coding schemes based on polar codes with outer cyclic redundancy check (CRC) codes -- also referred to as CRC-aided (CA) polar codes. The first bound is obtained by considering an outer detection code, whereas the second bound relies on a threshold test applied to the generalized information density. Similarly, in the first CA polar code scheme, we reserve a fraction of the outer CRC parity bits for error detection, whereas in the second scheme, we apply a threshold test (specifically, Forney's optimal rule) to the output of the successive cancellation list decoder. Numerical simulations performed on the binary-input AWGN channel reveal that, in the short-blocklength regime, the threshold-based approach is superior to the CRC-based approach, both in terms of bounds and performance of CA polar code schemes. We also consider the case of decoding with noisy channel-state information, which leads to a mismatched decoding setting. Our results illustrate that, differently from the previous case, in this scenario, the CRC-based approach outperforms the threshold-based approach, which is more sensitive to the mismatch.","sentences":["We analyze the trade-off between the undetected error probability (i.e., the probability that the channel decoder outputs an erroneous message without detecting the error) and the total error probability in the short blocklength regime.","We address the problem by developing two new finite blocklength achievability bounds, which we use to benchmark the performance of two coding schemes based on polar codes with outer cyclic redundancy check (CRC) codes -- also referred to as CRC-aided (CA) polar codes.","The first bound is obtained by considering an outer detection code, whereas the second bound relies on a threshold test applied to the generalized information density.","Similarly, in the first CA polar code scheme, we reserve a fraction of the outer CRC parity bits for error detection, whereas in the second scheme, we apply a threshold test (specifically, Forney's optimal rule) to the output of the successive cancellation list decoder.","Numerical simulations performed on the binary-input AWGN channel reveal that, in the short-blocklength regime, the threshold-based approach is superior to the CRC-based approach, both in terms of bounds and performance of CA polar code schemes.","We also consider the case of decoding with noisy channel-state information, which leads to a mismatched decoding setting.","Our results illustrate that, differently from the previous case, in this scenario, the CRC-based approach outperforms the threshold-based approach, which is more sensitive to the mismatch."],"url":"http://arxiv.org/abs/2503.02782v1"}
{"created":"2025-03-04 16:52:25","title":"Quantitative Resilience Modeling for Autonomous Cyber Defense","abstract":"Cyber resilience is the ability of a system to recover from an attack with minimal impact on system operations. However, characterizing a network's resilience under a cyber attack is challenging, as there are no formal definitions of resilience applicable to diverse network topologies and attack patterns. In this work, we propose a quantifiable formulation of resilience that considers multiple defender operational goals, the criticality of various network resources for daily operations, and provides interpretability to security operators about their system's resilience under attack. We evaluate our approach within the CybORG environment, a reinforcement learning (RL) framework for autonomous cyber defense, analyzing trade-offs between resilience, costs, and prioritization of operational goals. Furthermore, we introduce methods to aggregate resilience metrics across time-variable attack patterns and multiple network topologies, comprehensively characterizing system resilience. Using insights gained from our resilience metrics, we design RL autonomous defensive agents and compare them against several heuristic baselines, showing that proactive network hardening techniques and prompt recovery of compromised machines are critical for effective cyber defenses.","sentences":["Cyber resilience is the ability of a system to recover from an attack with minimal impact on system operations.","However, characterizing a network's resilience under a cyber attack is challenging, as there are no formal definitions of resilience applicable to diverse network topologies and attack patterns.","In this work, we propose a quantifiable formulation of resilience that considers multiple defender operational goals, the criticality of various network resources for daily operations, and provides interpretability to security operators about their system's resilience under attack.","We evaluate our approach within the CybORG environment, a reinforcement learning (RL) framework for autonomous cyber defense, analyzing trade-offs between resilience, costs, and prioritization of operational goals.","Furthermore, we introduce methods to aggregate resilience metrics across time-variable attack patterns and multiple network topologies, comprehensively characterizing system resilience.","Using insights gained from our resilience metrics, we design RL autonomous defensive agents and compare them against several heuristic baselines, showing that proactive network hardening techniques and prompt recovery of compromised machines are critical for effective cyber defenses."],"url":"http://arxiv.org/abs/2503.02780v1"}
{"created":"2025-03-04 16:49:37","title":"Implicit Bias in LLMs: A Survey","abstract":"Due to the implement of guardrails by developers, Large language models (LLMs) have demonstrated exceptional performance in explicit bias tests. However, bias in LLMs may occur not only explicitly, but also implicitly, much like humans who consciously strive for impartiality yet still harbor implicit bias. The unconscious and automatic nature of implicit bias makes it particularly challenging to study. This paper provides a comprehensive review of the existing literature on implicit bias in LLMs. We begin by introducing key concepts, theories and methods related to implicit bias in psychology, extending them from humans to LLMs. Drawing on the Implicit Association Test (IAT) and other psychological frameworks, we categorize detection methods into three primary approaches: word association, task-oriented text generation and decision-making. We divide our taxonomy of evaluation metrics for implicit bias into two categories: single-value-based metrics and comparison-value-based metrics. We classify datasets into two types: sentences with masked tokens and complete sentences, incorporating datasets from various domains to reflect the broad application of LLMs. Although research on mitigating implicit bias in LLMs is still limited, we summarize existing efforts and offer insights on future challenges. We aim for this work to serve as a clear guide for researchers and inspire innovative ideas to advance exploration in this task.","sentences":["Due to the implement of guardrails by developers, Large language models (LLMs) have demonstrated exceptional performance in explicit bias tests.","However, bias in LLMs may occur not only explicitly, but also implicitly, much like humans who consciously strive for impartiality yet still harbor implicit bias.","The unconscious and automatic nature of implicit bias makes it particularly challenging to study.","This paper provides a comprehensive review of the existing literature on implicit bias in LLMs.","We begin by introducing key concepts, theories and methods related to implicit bias in psychology, extending them from humans to LLMs.","Drawing on the Implicit Association Test (IAT) and other psychological frameworks, we categorize detection methods into three primary approaches: word association, task-oriented text generation and decision-making.","We divide our taxonomy of evaluation metrics for implicit bias into two categories: single-value-based metrics and comparison-value-based metrics.","We classify datasets into two types: sentences with masked tokens and complete sentences, incorporating datasets from various domains to reflect the broad application of LLMs.","Although research on mitigating implicit bias in LLMs is still limited, we summarize existing efforts and offer insights on future challenges.","We aim for this work to serve as a clear guide for researchers and inspire innovative ideas to advance exploration in this task."],"url":"http://arxiv.org/abs/2503.02776v1"}
{"created":"2025-03-04 16:44:53","title":"Digital Model-Driven Genetic Algorithm for Optimizing Layout and Task Allocation in Human-Robot Collaborative Assemblies","abstract":"This paper addresses the optimization of human-robot collaborative work-cells before their physical deployment. Most of the times, such environments are designed based on the experience of the system integrators, often leading to sub-optimal solutions. Accurate simulators of the robotic cell, accounting for the presence of the human as well, are available today and can be used in the pre-deployment. We propose an iterative optimization scheme where a digital model of the work-cell is updated based on a genetic algorithm. The methodology focuses on the layout optimization and task allocation, encoding both the problems simultaneously in the design variables handled by the genetic algorithm, while the task scheduling problem depends on the result of the upper-level one. The final solution balances conflicting objectives in the fitness function and is validated to show the impact of the objectives with respect to a baseline, which represents possible initial choices selected based on the human judgment.","sentences":["This paper addresses the optimization of human-robot collaborative work-cells before their physical deployment.","Most of the times, such environments are designed based on the experience of the system integrators, often leading to sub-optimal solutions.","Accurate simulators of the robotic cell, accounting for the presence of the human as well, are available today and can be used in the pre-deployment.","We propose an iterative optimization scheme where a digital model of the work-cell is updated based on a genetic algorithm.","The methodology focuses on the layout optimization and task allocation, encoding both the problems simultaneously in the design variables handled by the genetic algorithm, while the task scheduling problem depends on the result of the upper-level one.","The final solution balances conflicting objectives in the fitness function and is validated to show the impact of the objectives with respect to a baseline, which represents possible initial choices selected based on the human judgment."],"url":"http://arxiv.org/abs/2503.02774v1"}
{"created":"2025-03-04 16:42:46","title":"Prime Convolutional Model: Breaking the Ground for Theoretical Explainability","abstract":"In this paper, we propose a new theoretical approach to Explainable AI. Following the Scientific Method, this approach consists in formulating on the basis of empirical evidence, a mathematical model to explain and predict the behaviors of Neural Networks. We apply the method to a case study created in a controlled environment, which we call Prime Convolutional Model (p-Conv for short). p-Conv operates on a dataset consisting of the first one million natural numbers and is trained to identify the congruence classes modulo a given integer $m$. Its architecture uses a convolutional-type neural network that contextually processes a sequence of $B$ consecutive numbers to each input. We take an empirical approach and exploit p-Conv to identify the congruence classes of numbers in a validation set using different values for $m$ and $B$. The results show that the different behaviors of p-Conv (i.e., whether it can perform the task or not) can be modeled mathematically in terms of $m$ and $B$. The inferred mathematical model reveals interesting patterns able to explain when and why p-Conv succeeds in performing task and, if not, which error pattern it follows.","sentences":["In this paper, we propose a new theoretical approach to Explainable AI.","Following the Scientific Method, this approach consists in formulating on the basis of empirical evidence, a mathematical model to explain and predict the behaviors of Neural Networks.","We apply the method to a case study created in a controlled environment, which we call Prime Convolutional Model (p-Conv for short).","p-Conv operates on a dataset consisting of the first one million natural numbers and is trained to identify the congruence classes modulo a given integer $m$. Its architecture uses a convolutional-type neural network that contextually processes a sequence of $B$ consecutive numbers to each input.","We take an empirical approach and exploit p-Conv to identify the congruence classes of numbers in a validation set using different values for $m$ and $B$. The results show that the different behaviors of p-Conv (i.e., whether it can perform the task or not) can be modeled mathematically in terms of $m$ and $B$. The inferred mathematical model reveals interesting patterns able to explain when and why p-Conv succeeds in performing task and, if not, which error pattern it follows."],"url":"http://arxiv.org/abs/2503.02773v1"}
{"created":"2025-03-04 16:40:55","title":"ESSPI: ECDSA/Schnorr Signed Program Input for BitVMX","abstract":"The BitVM and BitVMX protocols have long relied on inefficient one-time signature (OTS) schemes like Lamport and Winternitz for signing program inputs. These schemes exhibit significant storage overheads, hindering their practical application. This paper introduces ESSPI, an optimized method leveraging ECDSA/Schnorr signatures to sign the BitVMX program input. With Schnorr signatures we achieve an optimal 1:1 data expansion, compared to the current known best ratio of 1:200 based on Winternitz signatures. To accomplish this we introduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding a challengeable hashing core to it, (2) a new partition-based search to detect fraud during hashing, (3) a new enhanced transaction DAG with added data-carrying transactions with a fraud-verifying smart-contract and (4) a novel timelock-based method for proving data availability to Bitcoin smart contracts. The enhanced BitVMX protocol enables the verification of uncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation integrity proofs, such as STARKs.","sentences":["The BitVM and BitVMX protocols have long relied on inefficient one-time signature (OTS) schemes like Lamport and Winternitz for signing program inputs.","These schemes exhibit significant storage overheads, hindering their practical application.","This paper introduces ESSPI, an optimized method leveraging ECDSA/Schnorr signatures to sign the BitVMX program input.","With Schnorr signatures we achieve an optimal 1:1 data expansion, compared to the current known best ratio of 1:200 based on Winternitz signatures.","To accomplish this we introduce 4 innovations to BitVMX: (1) a modification of the BitVMX CPU, adding a challengeable hashing core to it, (2) a new partition-based search to detect fraud during hashing, (3) a new enhanced transaction DAG with added data-carrying transactions with a fraud-verifying smart-contract and (4) a novel timelock-based method for proving data availability to Bitcoin smart contracts.","The enhanced BitVMX protocol enables the verification of uncompressed inputs such as SPV proofs, NiPoPoWs, or longer computation integrity proofs, such as STARKs."],"url":"http://arxiv.org/abs/2503.02772v1"}
{"created":"2025-03-04 16:37:30","title":"Applying Computational Engineering Modelling to Analyse the Social Impact of Conflict and Violent Events","abstract":"This thesis presents a novel framework for analysing the societal impacts of armed conflict by applying principles from engineering and material science. Building on the idea of a \"social fabric\", it recasts communities as plates with properties, such as resilience and vulnerability, analogous to material parameters like thickness or elasticity. Conflict events are treated as external forces that deform this fabric, revealing how repeated shocks and local weaknesses can compound over time. Using a custom Python-based Finite Element Analysis implementation, the thesis demonstrates how data on socioeconomic indicators (e.g., infrastructure, health, and demographics) and conflict incidents can be translated into a single computational model. Preliminary tests validate that results align with expected physical behaviours, and a proof-of-concept highlights how this approach can capture indirect or spillover effects and illuminate the areas most at risk of long-term harm. By bridging social science insights with computational modelling, this work offers an adaptable frame to inform both academic research and on-the-ground policy decisions for communities affected by violence.","sentences":["This thesis presents a novel framework for analysing the societal impacts of armed conflict by applying principles from engineering and material science.","Building on the idea of a \"social fabric\", it recasts communities as plates with properties, such as resilience and vulnerability, analogous to material parameters like thickness or elasticity.","Conflict events are treated as external forces that deform this fabric, revealing how repeated shocks and local weaknesses can compound over time.","Using a custom Python-based Finite Element Analysis implementation, the thesis demonstrates how data on socioeconomic indicators (e.g., infrastructure, health, and demographics) and conflict incidents can be translated into a single computational model.","Preliminary tests validate that results align with expected physical behaviours, and a proof-of-concept highlights how this approach can capture indirect or spillover effects and illuminate the areas most at risk of long-term harm.","By bridging social science insights with computational modelling, this work offers an adaptable frame to inform both academic research and on-the-ground policy decisions for communities affected by violence."],"url":"http://arxiv.org/abs/2503.02771v1"}
{"created":"2025-03-04 16:35:51","title":"Blaze: Compiling JSON Schema for 10x Faster Validation","abstract":"JSON Schemas provide useful guardrails for developers of Web APIs to guarantee that the semi-structured JSON input provided by clients matches a predefined structure. This is important both to ensure the correctness of the data received as input and also to avoid potential security issues from processing input that is not correctly validated. However, this validation process can be time-consuming and adds overhead to every request. Different keywords in the JSON Schema specification have complex interactions that may increase validation time. Since popular APIs may process thousands of requests per second and schemas change infrequently, we observe that we can resolve some of the complexity ahead of time in order to achieve faster validation.   Our JSON Schema validator, Blaze, compiles complex schemas to an efficient representation in seconds to minutes, adding minimal overhead at build time. Blaze incorporates several unique optimizations to reduce the validation time by an average of approximately 10x compared existing validators on a variety of datasets. In some cases, Blaze achieves a reduction in validation time of multiple orders of magnitude compared to the next fastest validator. We also demonstrate that several popular validators produce incorrect results in some cases, while Blaze maintains strict adherence to the JSON Schema specification.","sentences":["JSON Schemas provide useful guardrails for developers of Web APIs to guarantee that the semi-structured JSON input provided by clients matches a predefined structure.","This is important both to ensure the correctness of the data received as input and also to avoid potential security issues from processing input that is not correctly validated.","However, this validation process can be time-consuming and adds overhead to every request.","Different keywords in the JSON Schema specification have complex interactions that may increase validation time.","Since popular APIs may process thousands of requests per second and schemas change infrequently, we observe that we can resolve some of the complexity ahead of time in order to achieve faster validation.   ","Our JSON Schema validator, Blaze, compiles complex schemas to an efficient representation in seconds to minutes, adding minimal overhead at build time.","Blaze incorporates several unique optimizations to reduce the validation time by an average of approximately 10x compared existing validators on a variety of datasets.","In some cases, Blaze achieves a reduction in validation time of multiple orders of magnitude compared to the next fastest validator.","We also demonstrate that several popular validators produce incorrect results in some cases, while Blaze maintains strict adherence to the JSON Schema specification."],"url":"http://arxiv.org/abs/2503.02770v1"}
{"created":"2025-03-04 16:34:14","title":"InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training","abstract":"Recent advancements in speech large language models (SpeechLLMs) have attracted considerable attention. Nonetheless, current methods exhibit suboptimal performance in adhering to speech instructions. Notably, the intelligence of models significantly diminishes when processing speech-form input as compared to direct text-form input. Prior work has attempted to mitigate this semantic inconsistency between speech and text representations through techniques such as representation and behavior alignment, which involve the meticulous design of data pairs during the post-training phase. In this paper, we introduce a simple and scalable training method called InSerter, which stands for Interleaved Speech-Text Representation Pre-training. InSerter is designed to pre-train large-scale unsupervised speech-text sequences, where the speech is synthesized from randomly selected segments of an extensive text corpus using text-to-speech conversion. Consequently, the model acquires the ability to generate textual continuations corresponding to the provided speech segments, obviating the need for intensive data design endeavors. To systematically evaluate speech instruction-following capabilities, we introduce SpeechInstructBench, the first comprehensive benchmark specifically designed for speech-oriented instruction-following tasks. Our proposed InSerter achieves SOTA performance in SpeechInstructBench and demonstrates superior or competitive results across diverse speech processing tasks.","sentences":["Recent advancements in speech large language models (SpeechLLMs) have attracted considerable attention.","Nonetheless, current methods exhibit suboptimal performance in adhering to speech instructions.","Notably, the intelligence of models significantly diminishes when processing speech-form input as compared to direct text-form input.","Prior work has attempted to mitigate this semantic inconsistency between speech and text representations through techniques such as representation and behavior alignment, which involve the meticulous design of data pairs during the post-training phase.","In this paper, we introduce a simple and scalable training method called InSerter, which stands for Interleaved Speech-Text Representation Pre-training.","InSerter is designed to pre-train large-scale unsupervised speech-text sequences, where the speech is synthesized from randomly selected segments of an extensive text corpus using text-to-speech conversion.","Consequently, the model acquires the ability to generate textual continuations corresponding to the provided speech segments, obviating the need for intensive data design endeavors.","To systematically evaluate speech instruction-following capabilities, we introduce SpeechInstructBench, the first comprehensive benchmark specifically designed for speech-oriented instruction-following tasks.","Our proposed InSerter achieves SOTA performance in SpeechInstructBench and demonstrates superior or competitive results across diverse speech processing tasks."],"url":"http://arxiv.org/abs/2503.02769v1"}
{"created":"2025-03-04 16:33:59","title":"Denotational Semantics for Probabilistic and Concurrent Programs","abstract":"We develop a denotational model for programs that have standard programming constructs such as conditionals and while-loops, as well as probabilistic and concurrent commands. Whereas semantic models for languages with either concurrency or randomization are well studied, their combination is limited to languages with bounded loops. Our work is the first to consider both randomization and concurrency for a language with unbounded looping constructs. The interaction between Boolean tests (arising from the control flow structures), probabilistic actions, and concurrent execution creates challenges in generalizing previous work on pomsets and convex languages, prominent models for those effects, individually. To illustrate the generality of our model, we show that it recovers a typical powerdomain semantics for concurrency, as well as the convex powerset semantics for probabilistic nondeterminism.","sentences":["We develop a denotational model for programs that have standard programming constructs such as conditionals and while-loops, as well as probabilistic and concurrent commands.","Whereas semantic models for languages with either concurrency or randomization are well studied, their combination is limited to languages with bounded loops.","Our work is the first to consider both randomization and concurrency for a language with unbounded looping constructs.","The interaction between Boolean tests (arising from the control flow structures), probabilistic actions, and concurrent execution creates challenges in generalizing previous work on pomsets and convex languages, prominent models for those effects, individually.","To illustrate the generality of our model, we show that it recovers a typical powerdomain semantics for concurrency, as well as the convex powerset semantics for probabilistic nondeterminism."],"url":"http://arxiv.org/abs/2503.02768v1"}
{"created":"2025-03-04 16:22:49","title":"From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine Symbolic Language for Modern Clinical Relevance","abstract":"Metaphorical expressions are abundant in Traditional Chinese Medicine (TCM), conveying complex disease mechanisms and holistic health concepts through culturally rich and often abstract terminology. Bridging these metaphors to anatomically driven Western medical (WM) concepts poses significant challenges for both automated language processing and real-world clinical practice. To address this gap, we propose a novel multi-agent and chain-of-thought (CoT) framework designed to interpret TCM metaphors accurately and map them to WM pathophysiology. Specifically, our approach combines domain-specialized agents (TCM Expert, WM Expert) with a Coordinator Agent, leveraging stepwise chain-of-thought prompts to ensure transparent reasoning and conflict resolution. We detail a methodology for building a metaphor-rich TCM dataset, discuss strategies for effectively integrating multi-agent collaboration and CoT reasoning, and articulate the theoretical underpinnings that guide metaphor interpretation across distinct medical paradigms. We present a comprehensive system design and highlight both the potential benefits and limitations of our approach, while leaving placeholders for future experimental validation. Our work aims to support clinical decision-making, cross-system educational initiatives, and integrated healthcare research, ultimately offering a robust scaffold for reconciling TCM's symbolic language with the mechanistic focus of Western medicine.","sentences":["Metaphorical expressions are abundant in Traditional Chinese Medicine (TCM), conveying complex disease mechanisms and holistic health concepts through culturally rich and often abstract terminology.","Bridging these metaphors to anatomically driven Western medical (WM) concepts poses significant challenges for both automated language processing and real-world clinical practice.","To address this gap, we propose a novel multi-agent and chain-of-thought (CoT) framework designed to interpret TCM metaphors accurately and map them to WM pathophysiology.","Specifically, our approach combines domain-specialized agents (TCM Expert, WM Expert) with a Coordinator Agent, leveraging stepwise chain-of-thought prompts to ensure transparent reasoning and conflict resolution.","We detail a methodology for building a metaphor-rich TCM dataset, discuss strategies for effectively integrating multi-agent collaboration and CoT reasoning, and articulate the theoretical underpinnings that guide metaphor interpretation across distinct medical paradigms.","We present a comprehensive system design and highlight both the potential benefits and limitations of our approach, while leaving placeholders for future experimental validation.","Our work aims to support clinical decision-making, cross-system educational initiatives, and integrated healthcare research, ultimately offering a robust scaffold for reconciling TCM's symbolic language with the mechanistic focus of Western medicine."],"url":"http://arxiv.org/abs/2503.02760v1"}
{"created":"2025-03-04 16:21:33","title":"Efficient and Optimal No-Regret Caching under Partial Observation","abstract":"Online learning algorithms have been successfully used to design caching policies with sublinear regret in the total number of requests, with no statistical assumption about the request sequence. Most existing algorithms involve computationally expensive operations and require knowledge of all past requests. However, this may not be feasible in practical scenarios like caching at a cellular base station. Therefore, we study the caching problem in a more restrictive setting where only a fraction of past requests are observed, and we propose a randomized caching policy with sublinear regret based on the classic online learning algorithm Follow-the-Perturbed-Leader (FPL). Our caching policy is the first to attain the asymptotically optimal regret bound while ensuring asymptotically constant amortized time complexity in the partial observability setting of requests. The experimental evaluation compares the proposed solution against classic caching policies and validates the proposed approach under synthetic and real-world request traces.","sentences":["Online learning algorithms have been successfully used to design caching policies with sublinear regret in the total number of requests, with no statistical assumption about the request sequence.","Most existing algorithms involve computationally expensive operations and require knowledge of all past requests.","However, this may not be feasible in practical scenarios like caching at a cellular base station.","Therefore, we study the caching problem in a more restrictive setting where only a fraction of past requests are observed, and we propose a randomized caching policy with sublinear regret based on the classic online learning algorithm Follow-the-Perturbed-Leader (FPL).","Our caching policy is the first to attain the asymptotically optimal regret bound while ensuring asymptotically constant amortized time complexity in the partial observability setting of requests.","The experimental evaluation compares the proposed solution against classic caching policies and validates the proposed approach under synthetic and real-world request traces."],"url":"http://arxiv.org/abs/2503.02758v1"}
{"created":"2025-03-04 16:20:52","title":"BatchGEMBA: Token-Efficient Machine Translation Evaluation with Batched Prompting and Prompt Compression","abstract":"Recent advancements in Large Language Model (LLM)-based Natural Language Generation evaluation have largely focused on single-example prompting, resulting in significant token overhead and computational inefficiencies. In this work, we introduce BatchGEMBA-MQM, a framework that integrates batched prompting with the GEMBA-MQM metric for machine translation evaluation. Our approach aggregates multiple translation examples into a single prompt, reducing token usage by 2-4 times (depending on the batch size) relative to single-example prompting. Furthermore, we propose a batching-aware prompt compression model that achieves an additional token reduction of 13-15% on average while also showing ability to help mitigate batching-induced quality degradation. Evaluations across several LLMs (GPT-4o, GPT-4o-mini, Mistral Small, Phi4, and CommandR7B) and varying batch sizes reveal that while batching generally negatively affects quality (but sometimes not substantially), prompt compression does not degrade further, and in some cases, recovers quality loss. For instance, GPT-4o retains over 90% of its baseline performance at a batch size of 4 when compression is applied, compared to a 44.6% drop without compression. We plan to release our code and trained models at https://github.com/NL2G/batchgemba to support future research in this domain.","sentences":["Recent advancements in Large Language Model (LLM)-based Natural Language Generation evaluation have largely focused on single-example prompting, resulting in significant token overhead and computational inefficiencies.","In this work, we introduce BatchGEMBA-MQM, a framework that integrates batched prompting with the GEMBA-MQM metric for machine translation evaluation.","Our approach aggregates multiple translation examples into a single prompt, reducing token usage by 2-4 times (depending on the batch size) relative to single-example prompting.","Furthermore, we propose a batching-aware prompt compression model that achieves an additional token reduction of 13-15% on average while also showing ability to help mitigate batching-induced quality degradation.","Evaluations across several LLMs (GPT-4o, GPT-4o-mini, Mistral Small, Phi4, and CommandR7B) and varying batch sizes reveal that while batching generally negatively affects quality (but sometimes not substantially), prompt compression does not degrade further, and in some cases, recovers quality loss.","For instance, GPT-4o retains over 90% of its baseline performance at a batch size of 4 when compression is applied, compared to a 44.6% drop without compression.","We plan to release our code and trained models at https://github.com/NL2G/batchgemba to support future research in this domain."],"url":"http://arxiv.org/abs/2503.02756v1"}
{"created":"2025-03-04 16:19:06","title":"Deep Learning-Enhanced Visual Monitoring in Hazardous Underwater Environments with a Swarm of Micro-Robots","abstract":"Long-term monitoring and exploration of extreme environments, such as underwater storage facilities, is costly, labor-intensive, and hazardous. Automating this process with low-cost, collaborative robots can greatly improve efficiency. These robots capture images from different positions, which must be processed simultaneously to create a spatio-temporal model of the facility. In this paper, we propose a novel approach that integrates data simulation, a multi-modal deep learning network for coordinate prediction, and image reassembly to address the challenges posed by environmental disturbances causing drift and rotation in the robots' positions and orientations. Our approach enhances the precision of alignment in noisy environments by integrating visual information from snapshots, global positional context from masks, and noisy coordinates. We validate our method through extensive experiments using synthetic data that simulate real-world robotic operations in underwater settings. The results demonstrate very high coordinate prediction accuracy and plausible image assembly, indicating the real-world applicability of our approach. The assembled images provide clear and coherent views of the underwater environment for effective monitoring and inspection, showcasing the potential for broader use in extreme settings, further contributing to improved safety, efficiency, and cost reduction in hazardous field monitoring. Code is available on https://github.com/ChrisChen1023/Micro-Robot-Swarm.","sentences":["Long-term monitoring and exploration of extreme environments, such as underwater storage facilities, is costly, labor-intensive, and hazardous.","Automating this process with low-cost, collaborative robots can greatly improve efficiency.","These robots capture images from different positions, which must be processed simultaneously to create a spatio-temporal model of the facility.","In this paper, we propose a novel approach that integrates data simulation, a multi-modal deep learning network for coordinate prediction, and image reassembly to address the challenges posed by environmental disturbances causing drift and rotation in the robots' positions and orientations.","Our approach enhances the precision of alignment in noisy environments by integrating visual information from snapshots, global positional context from masks, and noisy coordinates.","We validate our method through extensive experiments using synthetic data that simulate real-world robotic operations in underwater settings.","The results demonstrate very high coordinate prediction accuracy and plausible image assembly, indicating the real-world applicability of our approach.","The assembled images provide clear and coherent views of the underwater environment for effective monitoring and inspection, showcasing the potential for broader use in extreme settings, further contributing to improved safety, efficiency, and cost reduction in hazardous field monitoring.","Code is available on https://github.com/ChrisChen1023/Micro-Robot-Swarm."],"url":"http://arxiv.org/abs/2503.02752v1"}
{"created":"2025-03-04 16:14:06","title":"Bridging VLM and KMP: Enabling Fine-grained robotic manipulation via Semantic Keypoints Representation","abstract":"From early Movement Primitive (MP) techniques to modern Vision-Language Models (VLMs), autonomous manipulation has remained a pivotal topic in robotics. As two extremes, VLM-based methods emphasize zero-shot and adaptive manipulation but struggle with fine-grained planning. In contrast, MP-based approaches excel in precise trajectory generalization but lack decision-making ability. To leverage the strengths of the two frameworks, we propose VL-MP, which integrates VLM with Kernelized Movement Primitives (KMP) via a low-distortion decision information transfer bridge, enabling fine-grained robotic manipulation under ambiguous situations. One key of VL-MP is the accurate representation of task decision parameters through semantic keypoints constraints, leading to more precise task parameter generation. Additionally, we introduce a local trajectory feature-enhanced KMP to support VL-MP, thereby achieving shape preservation for complex trajectories. Extensive experiments conducted in complex real-world environments validate the effectiveness of VL-MP for adaptive and fine-grained manipulation.","sentences":["From early Movement Primitive (MP) techniques to modern Vision-Language Models (VLMs), autonomous manipulation has remained a pivotal topic in robotics.","As two extremes, VLM-based methods emphasize zero-shot and adaptive manipulation but struggle with fine-grained planning.","In contrast, MP-based approaches excel in precise trajectory generalization but lack decision-making ability.","To leverage the strengths of the two frameworks, we propose VL-MP, which integrates VLM with Kernelized Movement Primitives (KMP) via a low-distortion decision information transfer bridge, enabling fine-grained robotic manipulation under ambiguous situations.","One key of VL-MP is the accurate representation of task decision parameters through semantic keypoints constraints, leading to more precise task parameter generation.","Additionally, we introduce a local trajectory feature-enhanced KMP to support VL-MP, thereby achieving shape preservation for complex trajectories.","Extensive experiments conducted in complex real-world environments validate the effectiveness of VL-MP for adaptive and fine-grained manipulation."],"url":"http://arxiv.org/abs/2503.02748v1"}
{"created":"2025-03-04 16:10:42","title":"ArcPro: Architectural Programs for Structured 3D Abstraction of Sparse Points","abstract":"We introduce ArcPro, a novel learning framework built on architectural programs to recover structured 3D abstractions from highly sparse and low-quality point clouds. Specifically, we design a domain-specific language (DSL) to hierarchically represent building structures as a program, which can be efficiently converted into a mesh. We bridge feedforward and inverse procedural modeling by using a feedforward process for training data synthesis, allowing the network to make reverse predictions. We train an encoder-decoder on the points-program pairs to establish a mapping from unstructured point clouds to architectural programs, where a 3D convolutional encoder extracts point cloud features and a transformer decoder autoregressively predicts the programs in a tokenized form. Inference by our method is highly efficient and produces plausible and faithful 3D abstractions. Comprehensive experiments demonstrate that ArcPro outperforms both traditional architectural proxy reconstruction and learning-based abstraction methods. We further explore its potential to work with multi-view image and natural language inputs.","sentences":["We introduce ArcPro, a novel learning framework built on architectural programs to recover structured 3D abstractions from highly sparse and low-quality point clouds.","Specifically, we design a domain-specific language (DSL) to hierarchically represent building structures as a program, which can be efficiently converted into a mesh.","We bridge feedforward and inverse procedural modeling by using a feedforward process for training data synthesis, allowing the network to make reverse predictions.","We train an encoder-decoder on the points-program pairs to establish a mapping from unstructured point clouds to architectural programs, where a 3D convolutional encoder extracts point cloud features and a transformer decoder autoregressively predicts the programs in a tokenized form.","Inference by our method is highly efficient and produces plausible and faithful 3D abstractions.","Comprehensive experiments demonstrate that ArcPro outperforms both traditional architectural proxy reconstruction and learning-based abstraction methods.","We further explore its potential to work with multi-view image and natural language inputs."],"url":"http://arxiv.org/abs/2503.02745v1"}
{"created":"2025-03-04 16:07:16","title":"Evaluating a Digital Speech Therapy App for Stuttering: A Pilot Validation Study","abstract":"Stuttering is a speech disorder that disrupts fluency and often leads to significant psychological and social challenges. This study evaluates the effectiveness of Eloquent, a digital speech therapy app, by analyzing pre-therapy and post-therapy speech samples using the Stuttering Severity Index-4 (SSI-4) and the S24 communication and attitude scale. Results indicate significant improvements in fluency, with reductions in SSI-4 scores across reading, speaking, duration, and physical concomitant metrics. Additionally, participants demonstrated a more positive attitude towards communication post-therapy, as evidenced by lower S24 scores. These findings highlight the potential of technology-driven, structured speech therapy interventions to deliver measurable improvements in stuttering severity and communication confidence.","sentences":["Stuttering is a speech disorder that disrupts fluency and often leads to significant psychological and social challenges.","This study evaluates the effectiveness of Eloquent, a digital speech therapy app, by analyzing pre-therapy and post-therapy speech samples using the Stuttering Severity Index-4 (SSI-4) and the S24 communication and attitude scale.","Results indicate significant improvements in fluency, with reductions in SSI-4 scores across reading, speaking, duration, and physical concomitant metrics.","Additionally, participants demonstrated a more positive attitude towards communication post-therapy, as evidenced by lower S24 scores.","These findings highlight the potential of technology-driven, structured speech therapy interventions to deliver measurable improvements in stuttering severity and communication confidence."],"url":"http://arxiv.org/abs/2503.02743v1"}
{"created":"2025-03-04 15:57:32","title":"Variable-Friction In-Hand Manipulation for Arbitrary Objects via Diffusion-Based Imitation Learning","abstract":"Dexterous in-hand manipulation (IHM) for arbitrary objects is challenging due to the rich and subtle contact process. Variable-friction manipulation is an alternative approach to dexterity, previously demonstrating robust and versatile 2D IHM capabilities with only two single-joint fingers. However, the hard-coded manipulation methods for variable friction hands are restricted to regular polygon objects and limited target poses, as well as requiring the policy to be tailored for each object. This paper proposes an end-to-end learning-based manipulation method to achieve arbitrary object manipulation for any target pose on real hardware, with minimal engineering efforts and data collection. The method features a diffusion policy-based imitation learning method with co-training from simulation and a small amount of real-world data. With the proposed framework, arbitrary objects including polygons and non-polygons can be precisely manipulated to reach arbitrary goal poses within 2 hours of training on an A100 GPU and only 1 hour of real-world data collection. The precision is higher than previous customized object-specific policies, achieving an average success rate of 71.3% with average pose error being 2.676 mm and 1.902 degrees.","sentences":["Dexterous in-hand manipulation (IHM) for arbitrary objects is challenging due to the rich and subtle contact process.","Variable-friction manipulation is an alternative approach to dexterity, previously demonstrating robust and versatile 2D IHM capabilities with only two single-joint fingers.","However, the hard-coded manipulation methods for variable friction hands are restricted to regular polygon objects and limited target poses, as well as requiring the policy to be tailored for each object.","This paper proposes an end-to-end learning-based manipulation method to achieve arbitrary object manipulation for any target pose on real hardware, with minimal engineering efforts and data collection.","The method features a diffusion policy-based imitation learning method with co-training from simulation and a small amount of real-world data.","With the proposed framework, arbitrary objects including polygons and non-polygons can be precisely manipulated to reach arbitrary goal poses within 2 hours of training on an A100 GPU and only 1 hour of real-world data collection.","The precision is higher than previous customized object-specific policies, achieving an average success rate of 71.3% with average pose error being 2.676 mm and 1.902 degrees."],"url":"http://arxiv.org/abs/2503.02738v1"}
{"created":"2025-03-04 15:56:43","title":"Large Language Models for Multilingual Previously Fact-Checked Claim Detection","abstract":"In our era of widespread false information, human fact-checkers often face the challenge of duplicating efforts when verifying claims that may have already been addressed in other countries or languages. As false information transcends linguistic boundaries, the ability to automatically detect previously fact-checked claims across languages has become an increasingly important task. This paper presents the first comprehensive evaluation of large language models (LLMs) for multilingual previously fact-checked claim detection. We assess seven LLMs across 20 languages in both monolingual and cross-lingual settings. Our results show that while LLMs perform well for high-resource languages, they struggle with low-resource languages. Moreover, translating original texts into English proved to be beneficial for low-resource languages. These findings highlight the potential of LLMs for multilingual previously fact-checked claim detection and provide a foundation for further research on this promising application of LLMs.","sentences":["In our era of widespread false information, human fact-checkers often face the challenge of duplicating efforts when verifying claims that may have already been addressed in other countries or languages.","As false information transcends linguistic boundaries, the ability to automatically detect previously fact-checked claims across languages has become an increasingly important task.","This paper presents the first comprehensive evaluation of large language models (LLMs) for multilingual previously fact-checked claim detection.","We assess seven LLMs across 20 languages in both monolingual and cross-lingual settings.","Our results show that while LLMs perform well for high-resource languages, they struggle with low-resource languages.","Moreover, translating original texts into English proved to be beneficial for low-resource languages.","These findings highlight the potential of LLMs for multilingual previously fact-checked claim detection and provide a foundation for further research on this promising application of LLMs."],"url":"http://arxiv.org/abs/2503.02737v1"}
{"created":"2025-03-04 15:55:55","title":"Clustered KL-barycenter design for policy evaluation","abstract":"In the context of stochastic bandit models, this article examines how to design sample-efficient behavior policies for the importance sampling evaluation of multiple target policies. From importance sampling theory, it is well established that sample efficiency is highly sensitive to the KL divergence between the target and importance sampling distributions. We first analyze a single behavior policy defined as the KL-barycenter of the target policies. Then, we refine this approach by clustering the target policies into groups with small KL divergences and assigning each cluster its own KL-barycenter as a behavior policy. This clustered KL-based policy evaluation (CKL-PE) algorithm provides a novel perspective on optimal policy selection. We prove upper bounds on the sample complexity of our method and demonstrate its effectiveness with numerical validation.","sentences":["In the context of stochastic bandit models, this article examines how to design sample-efficient behavior policies for the importance sampling evaluation of multiple target policies.","From importance sampling theory, it is well established that sample efficiency is highly sensitive to the KL divergence between the target and importance sampling distributions.","We first analyze a single behavior policy defined as the KL-barycenter of the target policies.","Then, we refine this approach by clustering the target policies into groups with small KL divergences and assigning each cluster its own KL-barycenter as a behavior policy.","This clustered KL-based policy evaluation (CKL-PE) algorithm provides a novel perspective on optimal policy selection.","We prove upper bounds on the sample complexity of our method and demonstrate its effectiveness with numerical validation."],"url":"http://arxiv.org/abs/2503.02735v1"}
{"created":"2025-03-04 15:54:57","title":"UAR-NVC: A Unified AutoRegressive Framework for Memory-Efficient Neural Video Compression","abstract":"Implicit Neural Representations (INRs) have demonstrated significant potential in video compression by representing videos as neural networks. However, as the number of frames increases, the memory consumption for training and inference increases substantially, posing challenges in resource-constrained scenarios. Inspired by the success of traditional video compression frameworks, which process video frame by frame and can efficiently compress long videos, we adopt this modeling strategy for INRs to decrease memory consumption, while aiming to unify the frameworks from the perspective of timeline-based autoregressive modeling. In this work, we present a novel understanding of INR models from an autoregressive (AR) perspective and introduce a Unified AutoRegressive Framework for memory-efficient Neural Video Compression (UAR-NVC). UAR-NVC integrates timeline-based and INR-based neural video compression under a unified autoregressive paradigm. It partitions videos into several clips and processes each clip using a different INR model instance, leveraging the advantages of both compression frameworks while allowing seamless adaptation to either in form. To further reduce temporal redundancy between clips, we design two modules to optimize the initialization, training, and compression of these model parameters. UAR-NVC supports adjustable latencies by varying the clip length. Extensive experimental results demonstrate that UAR-NVC, with its flexible video clip setting, can adapt to resource-constrained environments and significantly improve performance compared to different baseline models.","sentences":["Implicit Neural Representations (INRs) have demonstrated significant potential in video compression by representing videos as neural networks.","However, as the number of frames increases, the memory consumption for training and inference increases substantially, posing challenges in resource-constrained scenarios.","Inspired by the success of traditional video compression frameworks, which process video frame by frame and can efficiently compress long videos, we adopt this modeling strategy for INRs to decrease memory consumption, while aiming to unify the frameworks from the perspective of timeline-based autoregressive modeling.","In this work, we present a novel understanding of INR models from an autoregressive (AR) perspective and introduce a Unified AutoRegressive Framework for memory-efficient Neural Video Compression (UAR-NVC).","UAR-NVC integrates timeline-based and INR-based neural video compression under a unified autoregressive paradigm.","It partitions videos into several clips and processes each clip using a different INR model instance, leveraging the advantages of both compression frameworks while allowing seamless adaptation to either in form.","To further reduce temporal redundancy between clips, we design two modules to optimize the initialization, training, and compression of these model parameters.","UAR-NVC supports adjustable latencies by varying the clip length.","Extensive experimental results demonstrate that UAR-NVC, with its flexible video clip setting, can adapt to resource-constrained environments and significantly improve performance compared to different baseline models."],"url":"http://arxiv.org/abs/2503.02733v1"}
{"created":"2025-03-04 15:49:42","title":"Creating Sorted Grid Layouts with Gradient-based Optimization","abstract":"Visually sorted grid layouts provide an efficient method for organizing high-dimensional vectors in two-dimensional space by aligning spatial proximity with similarity relationships. This approach facilitates the effective sorting of diverse elements ranging from data points to images, and enables the simultaneous visualization of a significant number of elements. However, sorting data on two-dimensional grids is a challenge due to its high complexity. Even for a small 8-by-8 grid with 64 elements, the number of possible arrangements exceeds $1.3 \\cdot 10^{89}$ - more than the number of atoms in the universe - making brute-force solutions impractical.   Although various methods have been proposed to address the challenge of determining sorted grid layouts, none have investigated the potential of gradient-based optimization. In this paper, we present a novel method for grid-based sorting that exploits gradient optimization for the first time. We introduce a novel loss function that balances two opposing goals: ensuring the generation of a \"valid\" permutation matrix, and optimizing the arrangement on the grid to reflect the similarity between vectors, inspired by metrics that assess the quality of sorted grids. While learning-based approaches are inherently computationally complex, our method shows promising results in generating sorted grid layouts with superior sorting quality compared to existing techniques.","sentences":["Visually sorted grid layouts provide an efficient method for organizing high-dimensional vectors in two-dimensional space by aligning spatial proximity with similarity relationships.","This approach facilitates the effective sorting of diverse elements ranging from data points to images, and enables the simultaneous visualization of a significant number of elements.","However, sorting data on two-dimensional grids is a challenge due to its high complexity.","Even for a small 8-by-8 grid with 64 elements, the number of possible arrangements exceeds $1.3 \\cdot 10^{89}$ - more than the number of atoms in the universe - making brute-force solutions impractical.   ","Although various methods have been proposed to address the challenge of determining sorted grid layouts, none have investigated the potential of gradient-based optimization.","In this paper, we present a novel method for grid-based sorting that exploits gradient optimization for the first time.","We introduce a novel loss function that balances two opposing goals: ensuring the generation of a \"valid\" permutation matrix, and optimizing the arrangement on the grid to reflect the similarity between vectors, inspired by metrics that assess the quality of sorted grids.","While learning-based approaches are inherently computationally complex, our method shows promising results in generating sorted grid layouts with superior sorting quality compared to existing techniques."],"url":"http://arxiv.org/abs/2503.02730v1"}
{"created":"2025-03-04 15:44:33","title":"A Joint Visual Compression and Perception Framework for Neuralmorphic Spiking Camera","abstract":"The advent of neuralmorphic spike cameras has garnered significant attention for their ability to capture continuous motion with unparalleled temporal resolution.However, this imaging attribute necessitates considerable resources for binary spike data storage and transmission.In light of compression and spike-driven intelligent applications, we present the notion of Spike Coding for Intelligence (SCI), wherein spike sequences are compressed and optimized for both bit-rate and task performance.Drawing inspiration from the mammalian vision system, we propose a dual-pathway architecture for separate processing of spatial semantics and motion information, which is then merged to produce features for compression.A refinement scheme is also introduced to ensure consistency between decoded features and motion vectors.We further propose a temporal regression approach that integrates various motion dynamics, capitalizing on the advancements in warping and deformation simultaneously.Comprehensive experiments demonstrate our scheme achieves state-of-the-art (SOTA) performance for spike compression and analysis.We achieve an average 17.25% BD-rate reduction compared to SOTA codecs and a 4.3% accuracy improvement over SpiReco for spike-based classification, with 88.26% complexity reduction and 42.41% inference time saving on the encoding side.","sentences":["The advent of neuralmorphic spike cameras has garnered significant attention for their ability to capture continuous motion with unparalleled temporal resolution.","However, this imaging attribute necessitates considerable resources for binary spike data storage and transmission.","In light of compression and spike-driven intelligent applications, we present the notion of Spike Coding for Intelligence (SCI), wherein spike sequences are compressed and optimized for both bit-rate and task performance.","Drawing inspiration from the mammalian vision system, we propose a dual-pathway architecture for separate processing of spatial semantics and motion information, which is then merged to produce features for compression.","A refinement scheme is also introduced to ensure consistency between decoded features and motion vectors.","We further propose a temporal regression approach that integrates various motion dynamics, capitalizing on the advancements in warping and deformation simultaneously.","Comprehensive experiments demonstrate our scheme achieves state-of-the-art (SOTA) performance for spike compression and analysis.","We achieve an average 17.25% BD-rate reduction compared to SOTA codecs and a 4.3% accuracy improvement over SpiReco for spike-based classification, with 88.26% complexity reduction and 42.41% inference time saving on the encoding side."],"url":"http://arxiv.org/abs/2503.02725v1"}
{"created":"2025-03-04 15:41:40","title":"ImpedanceGPT: VLM-driven Impedance Control of Swarm of Mini-drones for Intelligent Navigation in Dynamic Environment","abstract":"Swarm robotics plays a crucial role in enabling autonomous operations in dynamic and unpredictable environments. However, a major challenge remains ensuring safe and efficient navigation in environments filled with both dynamic alive (e.g., humans) and dynamic inanimate (e.g., non-living objects) obstacles. In this paper, we propose ImpedanceGPT, a novel system that combines a Vision-Language Model (VLM) with retrieval-augmented generation (RAG) to enable real-time reasoning for adaptive navigation of mini-drone swarms in complex environments.   The key innovation of ImpedanceGPT lies in the integration of VLM and RAG, which provides the drones with enhanced semantic understanding of their surroundings. This enables the system to dynamically adjust impedance control parameters in response to obstacle types and environmental conditions. Our approach not only ensures safe and precise navigation but also improves coordination between drones in the swarm.   Experimental evaluations demonstrate the effectiveness of the system. The VLM-RAG framework achieved an obstacle detection and retrieval accuracy of 80 % under optimal lighting. In static environments, drones navigated dynamic inanimate obstacles at 1.4 m/s but slowed to 0.7 m/s with increased separation around humans. In dynamic environments, speed adjusted to 1.0 m/s near hard obstacles, while reducing to 0.6 m/s with higher deflection to safely avoid moving humans.","sentences":["Swarm robotics plays a crucial role in enabling autonomous operations in dynamic and unpredictable environments.","However, a major challenge remains ensuring safe and efficient navigation in environments filled with both dynamic alive (e.g., humans) and dynamic inanimate (e.g., non-living objects) obstacles.","In this paper, we propose ImpedanceGPT, a novel system that combines a Vision-Language Model (VLM) with retrieval-augmented generation (RAG) to enable real-time reasoning for adaptive navigation of mini-drone swarms in complex environments.   ","The key innovation of ImpedanceGPT lies in the integration of VLM and RAG, which provides the drones with enhanced semantic understanding of their surroundings.","This enables the system to dynamically adjust impedance control parameters in response to obstacle types and environmental conditions.","Our approach not only ensures safe and precise navigation but also improves coordination between drones in the swarm.   ","Experimental evaluations demonstrate the effectiveness of the system.","The VLM-RAG framework achieved an obstacle detection and retrieval accuracy of 80 % under optimal lighting.","In static environments, drones navigated dynamic inanimate obstacles at 1.4 m/s but slowed to 0.7 m/s with increased separation around humans.","In dynamic environments, speed adjusted to 1.0 m/s near hard obstacles, while reducing to 0.6 m/s with higher deflection to safely avoid moving humans."],"url":"http://arxiv.org/abs/2503.02723v1"}
{"created":"2025-03-04 15:36:19","title":"Vibration-Assisted Hysteresis Mitigation for Achieving High Compensation Efficiency","abstract":"Tendon-sheath mechanisms (TSMs) are widely used in minimally invasive surgical (MIS) applications, but their inherent hysteresis-caused by friction, backlash, and tendon elongation-leads to significant tracking errors. Conventional modeling and compensation methods struggle with these nonlinearities and require extensive parameter tuning. To address this, we propose a vibration-assisted hysteresis compensation approach, where controlled vibrational motion is applied along the tendon's movement direction to mitigate friction and reduce dead zones. Experimental results demonstrate that the exerted vibration consistently reduces hysteresis across all tested frequencies, decreasing RMSE by up to 23.41% (from 2.2345 mm to 1.7113 mm) and improving correlation, leading to more accurate trajectory tracking. When combined with a Temporal Convolutional Network (TCN)-based compensation model, vibration further enhances performance, achieving an 85.2% reduction in MAE (from 1.334 mm to 0.1969 mm). Without vibration, the TCN-based approach still reduces MAE by 72.3% (from 1.334 mm to 0.370 mm) under the same parameter settings. These findings confirm that vibration effectively mitigates hysteresis, improving trajectory accuracy and enabling more efficient compensation models with fewer trainable parameters. This approach provides a scalable and practical solution for TSM-based robotic applications, particularly in MIS.","sentences":["Tendon-sheath mechanisms (TSMs) are widely used in minimally invasive surgical (MIS) applications, but their inherent hysteresis-caused by friction, backlash, and tendon elongation-leads to significant tracking errors.","Conventional modeling and compensation methods struggle with these nonlinearities and require extensive parameter tuning.","To address this, we propose a vibration-assisted hysteresis compensation approach, where controlled vibrational motion is applied along the tendon's movement direction to mitigate friction and reduce dead zones.","Experimental results demonstrate that the exerted vibration consistently reduces hysteresis across all tested frequencies, decreasing RMSE by up to 23.41% (from 2.2345 mm to 1.7113 mm) and improving correlation, leading to more accurate trajectory tracking.","When combined with a Temporal Convolutional Network (TCN)-based compensation model, vibration further enhances performance, achieving an 85.2% reduction in MAE (from 1.334 mm to 0.1969 mm).","Without vibration, the TCN-based approach still reduces MAE by 72.3% (from 1.334 mm to 0.370 mm) under the same parameter settings.","These findings confirm that vibration effectively mitigates hysteresis, improving trajectory accuracy and enabling more efficient compensation models with fewer trainable parameters.","This approach provides a scalable and practical solution for TSM-based robotic applications, particularly in MIS."],"url":"http://arxiv.org/abs/2503.02720v1"}
{"created":"2025-03-04 15:33:27","title":"Scalable Multi-Robot Task Allocation and Coordination under Signal Temporal Logic Specifications","abstract":"Motion planning with simple objectives, such as collision-avoidance and goal-reaching, can be solved efficiently using modern planners. However, the complexity of the allowed tasks for these planners is limited. On the other hand, signal temporal logic (STL) can specify complex requirements, but STL-based motion planning and control algorithms often face scalability issues, especially in large multi-robot systems with complex dynamics. In this paper, we propose an algorithm that leverages the best of the two worlds. We first use a single-robot motion planner to efficiently generate a set of alternative reference paths for each robot. Then coordination requirements are specified using STL, which is defined over the assignment of paths and robots' progress along those paths. We use a Mixed Integer Linear Program (MILP) to compute task assignments and robot progress targets over time such that the STL specification is satisfied. Finally, a local controller is used to track the target progress. Simulations demonstrate that our method can handle tasks with complex constraints and scales to large multi-robot teams and intricate task allocation scenarios.","sentences":["Motion planning with simple objectives, such as collision-avoidance and goal-reaching, can be solved efficiently using modern planners.","However, the complexity of the allowed tasks for these planners is limited.","On the other hand, signal temporal logic (STL) can specify complex requirements, but STL-based motion planning and control algorithms often face scalability issues, especially in large multi-robot systems with complex dynamics.","In this paper, we propose an algorithm that leverages the best of the two worlds.","We first use a single-robot motion planner to efficiently generate a set of alternative reference paths for each robot.","Then coordination requirements are specified using STL, which is defined over the assignment of paths and robots' progress along those paths.","We use a Mixed Integer Linear Program (MILP) to compute task assignments and robot progress targets over time such that the STL specification is satisfied.","Finally, a local controller is used to track the target progress.","Simulations demonstrate that our method can handle tasks with complex constraints and scales to large multi-robot teams and intricate task allocation scenarios."],"url":"http://arxiv.org/abs/2503.02719v1"}
{"created":"2025-03-04 15:32:59","title":"Evaluating Knowledge Generation and Self-Refinement Strategies for LLM-based Column Type Annotation","abstract":"Understanding the semantics of columns in relational tables is an important pre-processing step for indexing data lakes in order to provide rich data search. An approach to establishing such understanding is column type annotation (CTA) where the goal is to annotate table columns with terms from a given vocabulary. This paper experimentally compares different knowledge generation and self-refinement strategies for LLM-based column type annotation. The strategies include using LLMs to generate term definitions, error-based refinement of term definitions, self-correction, and fine-tuning using examples and term definitions. We evaluate these strategies along two dimensions: effectiveness measured as F1 performance and efficiency measured in terms of token usage and cost. Our experiments show that the best performing strategy depends on the model/dataset combination. We find that using training data to generate label definitions outperforms using the same data as demonstrations for in-context learning for two out of three datasets using OpenAI models. The experiments further show that using the LLMs to refine label definitions brings an average increase of 3.9% F1 in 10 out of 12 setups compared to the performance of the non-refined definitions. Combining fine-tuned models with self-refined term definitions results in the overall highest performance, outperforming zero-shot prompting fine-tuned models by at least 3% in F1 score. The costs analysis shows that while reaching similar F1 score, self-refinement via prompting is more cost efficient for use cases requiring smaller amounts of tables to be annotated while fine-tuning is more efficient for large amounts of tables.","sentences":["Understanding the semantics of columns in relational tables is an important pre-processing step for indexing data lakes in order to provide rich data search.","An approach to establishing such understanding is column type annotation (CTA) where the goal is to annotate table columns with terms from a given vocabulary.","This paper experimentally compares different knowledge generation and self-refinement strategies for LLM-based column type annotation.","The strategies include using LLMs to generate term definitions, error-based refinement of term definitions, self-correction, and fine-tuning using examples and term definitions.","We evaluate these strategies along two dimensions: effectiveness measured as F1 performance and efficiency measured in terms of token usage and cost.","Our experiments show that the best performing strategy depends on the model/dataset combination.","We find that using training data to generate label definitions outperforms using the same data as demonstrations for in-context learning for two out of three datasets using OpenAI models.","The experiments further show that using the LLMs to refine label definitions brings an average increase of 3.9% F1 in 10 out of 12 setups compared to the performance of the non-refined definitions.","Combining fine-tuned models with self-refined term definitions results in the overall highest performance, outperforming zero-shot prompting fine-tuned models by at least 3% in F1 score.","The costs analysis shows that while reaching similar F1 score, self-refinement via prompting is more cost efficient for use cases requiring smaller amounts of tables to be annotated while fine-tuning is more efficient for large amounts of tables."],"url":"http://arxiv.org/abs/2503.02718v1"}
{"created":"2025-03-04 15:32:32","title":"Catheter Detection and Segmentation in X-ray Images via Multi-task Learning","abstract":"Automated detection and segmentation of surgical devices, such as catheters or wires, in X-ray fluoroscopic images have the potential to enhance image guidance in minimally invasive heart surgeries. In this paper, we present a convolutional neural network model that integrates a resnet architecture with multiple prediction heads to achieve real-time, accurate localization of electrodes on catheters and catheter segmentation in an end-to-end deep learning framework. We also propose a multi-task learning strategy in which our model is trained to perform both accurate electrode detection and catheter segmentation simultaneously. A key challenge with this approach is achieving optimal performance for both tasks. To address this, we introduce a novel multi-level dynamic resource prioritization method. This method dynamically adjusts sample and task weights during training to effectively prioritize more challenging tasks, where task difficulty is inversely proportional to performance and evolves throughout the training process. Experiments on both public and private datasets have demonstrated that the accuracy of our method surpasses the existing state-of-the-art methods in both single segmentation task and in the detection and segmentation multi-task. Our approach achieves a good trade-off between accuracy and efficiency, making it well-suited for real-time surgical guidance applications.","sentences":["Automated detection and segmentation of surgical devices, such as catheters or wires, in X-ray fluoroscopic images have the potential to enhance image guidance in minimally invasive heart surgeries.","In this paper, we present a convolutional neural network model that integrates a resnet architecture with multiple prediction heads to achieve real-time, accurate localization of electrodes on catheters and catheter segmentation in an end-to-end deep learning framework.","We also propose a multi-task learning strategy in which our model is trained to perform both accurate electrode detection and catheter segmentation simultaneously.","A key challenge with this approach is achieving optimal performance for both tasks.","To address this, we introduce a novel multi-level dynamic resource prioritization method.","This method dynamically adjusts sample and task weights during training to effectively prioritize more challenging tasks, where task difficulty is inversely proportional to performance and evolves throughout the training process.","Experiments on both public and private datasets have demonstrated that the accuracy of our method surpasses the existing state-of-the-art methods in both single segmentation task and in the detection and segmentation multi-task.","Our approach achieves a good trade-off between accuracy and efficiency, making it well-suited for real-time surgical guidance applications."],"url":"http://arxiv.org/abs/2503.02717v1"}
{"created":"2025-03-04 15:30:52","title":"Bounds for k-centers of point sets under $L_{\\infty}$-bottleneck distance","abstract":"We consider the $k$-center problem on the space of fixed-size point sets in the plane under the $L_{\\infty}$-bottleneck distance. While this problem is motivated by persistence diagrams in topological data analysis, we illustrate it as a \\emph{Restaurant Supply Problem}: given $n$ restaurant chains of $m$ stores each, we want to place supermarket chains, also of $m$ stores each, such that each restaurant chain can select one supermarket chain to supply all its stores, ensuring that each store is matched to a nearby supermarket. How many supermarket chains are required to supply all restaurants? We address this questions under the constraint that any two restaurant chains are close enough under the $L_{\\infty}$-distance to be satisfied by a single supermarket chain. We provide both upper and lower bounds for this problem and investigate its computational complexity.","sentences":["We consider the $k$-center problem on the space of fixed-size point sets in the plane under the $L_{\\infty}$-bottleneck distance.","While this problem is motivated by persistence diagrams in topological data analysis, we illustrate it as a \\emph{Restaurant Supply Problem}: given $n$ restaurant chains of $m$ stores each, we want to place supermarket chains, also of $m$ stores each, such that each restaurant chain can select one supermarket chain to supply all its stores, ensuring that each store is matched to a nearby supermarket.","How many supermarket chains are required to supply all restaurants?","We address this questions under the constraint that any two restaurant chains are close enough under the $L_{\\infty}$-distance to be satisfied by a single supermarket chain.","We provide both upper and lower bounds for this problem and investigate its computational complexity."],"url":"http://arxiv.org/abs/2503.02715v1"}
{"created":"2025-03-04 15:30:36","title":"S4D-Bio Audio Monitoring of Bone Cement Disintegration in Pulsating Fluid Jet Surgery under Laboratory Conditions","abstract":"This study investigates a pulsating fluid jet as a novel precise, minimally invasive and cold technique for bone cement removal. We utilize the pulsating fluid jet device to remove bone cement from samples designed to mimic clinical conditions. The effectiveness of long nozzles was tested to enable minimally invasive procedures. Audio signal monitoring, complemented by the State Space Model (SSM) S4D-Bio, was employed to optimize the fluid jet parameters dynamically, addressing challenges like visibility obstruction from splashing. Within our experiments, we generate a comprehensive dataset correlating various process parameters and their equivalent audio signals to material erosion. The use of SSMs yields precise control over the predictive erosion process, achieving 98.93 \\% accuracy. The study demonstrates on the one hand, that the pulsating fluid jet device, coupled with advanced audio monitoring techniques, is a highly effective tool for precise bone cement removal. On the other hand, this study presents the first application of SSMs in biomedical surgery technology, marking a significant advancement in the application. This research significantly advances biomedical engineering by integrating machine learning combined with pulsating fluid jet as surgical technology, offering a novel, minimally invasive, cold and adaptive approach for bone cement removal in orthopedic applications.","sentences":["This study investigates a pulsating fluid jet as a novel precise, minimally invasive and cold technique for bone cement removal.","We utilize the pulsating fluid jet device to remove bone cement from samples designed to mimic clinical conditions.","The effectiveness of long nozzles was tested to enable minimally invasive procedures.","Audio signal monitoring, complemented by the State Space Model (SSM) S4D-Bio, was employed to optimize the fluid jet parameters dynamically, addressing challenges like visibility obstruction from splashing.","Within our experiments, we generate a comprehensive dataset correlating various process parameters and their equivalent audio signals to material erosion.","The use of SSMs yields precise control over the predictive erosion process, achieving 98.93 \\% accuracy.","The study demonstrates on the one hand, that the pulsating fluid jet device, coupled with advanced audio monitoring techniques, is a highly effective tool for precise bone cement removal.","On the other hand, this study presents the first application of SSMs in biomedical surgery technology, marking a significant advancement in the application.","This research significantly advances biomedical engineering by integrating machine learning combined with pulsating fluid jet as surgical technology, offering a novel, minimally invasive, cold and adaptive approach for bone cement removal in orthopedic applications."],"url":"http://arxiv.org/abs/2503.02714v1"}
{"created":"2025-03-04 15:21:22","title":"Multilingualism, Transnationality, and K-pop in the Online #StopAsianHate Movement","abstract":"The #StopAsianHate (SAH) movement is a broad social movement against violence targeting Asians and Asian Americans, beginning in 2021 in response to racial discrimination related to COVID-19 and sparking worldwide conversation about anti-Asian hate. However, research on the online SAH movement has focused on English-speaking participants so the spread of the movement outside of the United States is largely unknown. In addition, there have been no long-term studies of SAH so the extent to which it has been successfully sustained over time is not well understood. We present an analysis of 6.5 million \"#StopAsianHate\" tweets from 2.2 million users all over the globe and spanning 60 different languages, constituting the first study of the non-English and transnational component of the online SAH movement. Using a combination of topic modeling, user modeling, and hand annotation, we identify and characterize the dominant discussions and users participating in the movement and draw comparisons of English versus non-English topics and users. We discover clear differences in events driving topics, where spikes in English tweets are driven by violent crimes in the US but spikes in non-English tweets are driven by transnational incidents of anti-Asian sentiment towards symbolic representatives of Asian nations. We also find that global K-pop fans were quick to adopt the SAH movement and, in fact, sustained it for longer than any other user group. Our work contributes to understanding the transnationality and evolution of the SAH movement, and more generally to exploring upward scale shift and public attention in large-scale multilingual online activism.","sentences":["The #StopAsianHate (SAH) movement is a broad social movement against violence targeting Asians and Asian Americans, beginning in 2021 in response to racial discrimination related to COVID-19 and sparking worldwide conversation about anti-Asian hate.","However, research on the online SAH movement has focused on English-speaking participants so the spread of the movement outside of the United States is largely unknown.","In addition, there have been no long-term studies of SAH so the extent to which it has been successfully sustained over time is not well understood.","We present an analysis of 6.5 million \"#StopAsianHate\" tweets from 2.2 million users all over the globe and spanning 60 different languages, constituting the first study of the non-English and transnational component of the online SAH movement.","Using a combination of topic modeling, user modeling, and hand annotation, we identify and characterize the dominant discussions and users participating in the movement and draw comparisons of English versus non-English topics and users.","We discover clear differences in events driving topics, where spikes in English tweets are driven by violent crimes in the US but spikes in non-English tweets are driven by transnational incidents of anti-Asian sentiment towards symbolic representatives of Asian nations.","We also find that global K-pop fans were quick to adopt the SAH movement and, in fact, sustained it for longer than any other user group.","Our work contributes to understanding the transnationality and evolution of the SAH movement, and more generally to exploring upward scale shift and public attention in large-scale multilingual online activism."],"url":"http://arxiv.org/abs/2503.02707v1"}
{"created":"2025-03-04 15:21:13","title":"Optimisation of cyber insurance coverage with selection of cost effective security controls","abstract":"Nowadays, cyber threats are considered among the most dangerous risks by top management of enterprises. One way to deal with these risks is to insure them, but cyber insurance is still quite expensive. The insurance fee can be reduced if organisations improve their cyber security protection, i.e., reducing the insured risk. In other words, organisations need an investment strategy to decide the optimal amount of investments into cyber insurance and self-protection. In this work, we propose an approach to help a risk-averse organisation to distribute its cyber security investments in a cost-efficient way. What makes our approach unique is that next to defining the amount of investments in cyber insurance and self-protection, our proposal also explicitly defines how these investments should be spent by selecting the most cost-efficient security controls. Moreover, we provide an exact algorithm for the control selection problem considering several threats at the same time and compare this algorithm with other approximate algorithmic solutions.","sentences":["Nowadays, cyber threats are considered among the most dangerous risks by top management of enterprises.","One way to deal with these risks is to insure them, but cyber insurance is still quite expensive.","The insurance fee can be reduced if organisations improve their cyber security protection, i.e., reducing the insured risk.","In other words, organisations need an investment strategy to decide the optimal amount of investments into cyber insurance and self-protection.","In this work, we propose an approach to help a risk-averse organisation to distribute its cyber security investments in a cost-efficient way.","What makes our approach unique is that next to defining the amount of investments in cyber insurance and self-protection, our proposal also explicitly defines how these investments should be spent by selecting the most cost-efficient security controls.","Moreover, we provide an exact algorithm for the control selection problem considering several threats at the same time and compare this algorithm with other approximate algorithmic solutions."],"url":"http://arxiv.org/abs/2503.02706v1"}
{"created":"2025-03-04 15:18:50","title":"Generative Tools for Graphical Assets: Empirical Guidelines based on Game Designers' and Developers' Preferences","abstract":"Graphical assets play an important role in the design and development of games. There is potential in the use of generative tools, to aid in creating graphical assets, thus improving game design and development pipelines. However, there is little research to address how the generative methods can fit into the wider pipeline. We conducted a user study with 16 game designers and developers to examine their preferences regarding generative tools for graphical assets. The findings highlight that early design stage is preferred by all participants (mean values above 0.67 and p < .001 for early stages). Designers and developers prefer to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset (mean value 0.17 where 1 is high quality, p < .001). They also strongly (mean value .78, p < .001) raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and integrate smoothly into existing environments (mean 3.5 out of 5, p = .004). The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines. Informed by these results, we provide a set of guidelines for creating tools that meet the expectations and needs of game designers and developers.","sentences":["Graphical assets play an important role in the design and development of games.","There is potential in the use of generative tools, to aid in creating graphical assets, thus improving game design and development pipelines.","However, there is little research to address how the generative methods can fit into the wider pipeline.","We conducted a user study with 16 game designers and developers to examine their preferences regarding generative tools for graphical assets.","The findings highlight that early design stage is preferred by all participants (mean values above 0.67 and p < .001 for early stages).","Designers and developers prefer to use such tools for creating large amounts of variations at the cost of quality as they can improve the quality of the artefacts once they generate a suitable asset (mean value 0.17 where 1 is high quality, p < .001).","They also strongly (mean value .78, p < .001) raised the need for better integration of such tools in existing design and development environments and the need for the outputs to be in common data formats, to be manipulatable and integrate smoothly into existing environments (mean 3.5 out of 5, p = .004).","The study also highlights the requirement for further emphasis on the needs of the users to incorporate these tools effectively in existing pipelines.","Informed by these results, we provide a set of guidelines for creating tools that meet the expectations and needs of game designers and developers."],"url":"http://arxiv.org/abs/2503.02703v1"}
{"created":"2025-03-04 15:18:40","title":"RedChronos: A Large Language Model-Based Log Analysis System for Insider Threat Detection in Enterprises","abstract":"Internal threat detection aims to address security threats within organizations or enterprises by identifying potential or already occurring malicious threats within vast amounts of logs. Although organizations or enterprises have dedicated personnel responsible for reviewing these logs, it is impossible to manually examine all logs entirely. In response to the vast number of logs, we propose a system called RedChronos, which is a Large Language Model-Based Log Analysis System. This system incorporates innovative improvements over previous research by employing Query-Aware Weighted Voting and a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations. On the public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches existing approaches in terms of accuracy, precision, and detection rate. Moreover, RedChronos reduces the need for manual intervention in security log reviews by 90\\% in the Xiaohongshu SOC. Therefore, our RedChronos system demonstrates exceptional performance in handling Internal Threat Detection (IDT) tasks, providing innovative solutions for these challenges. We believe that future research can continue to enhance the system's performance in IDT tasks while also reducing the response time to internal risk events.","sentences":["Internal threat detection aims to address security threats within organizations or enterprises by identifying potential or already occurring malicious threats within vast amounts of logs.","Although organizations or enterprises have dedicated personnel responsible for reviewing these logs, it is impossible to manually examine all logs entirely.","In response to the vast number of logs, we propose a system called RedChronos, which is a Large Language Model-Based Log Analysis System.","This system incorporates innovative improvements over previous research by employing Query-Aware Weighted Voting and a Semantic Expansion-based Genetic Algorithm with LLM-driven Mutations.","On the public datasets CERT 4.2 and 5.2, RedChronos outperforms or matches existing approaches in terms of accuracy, precision, and detection rate.","Moreover, RedChronos reduces the need for manual intervention in security log reviews by 90\\% in the Xiaohongshu SOC.","Therefore, our RedChronos system demonstrates exceptional performance in handling Internal Threat Detection (IDT) tasks, providing innovative solutions for these challenges.","We believe that future research can continue to enhance the system's performance in IDT tasks while also reducing the response time to internal risk events."],"url":"http://arxiv.org/abs/2503.02702v1"}
{"created":"2025-03-04 15:17:57","title":"MindBridge: Scalable and Cross-Model Knowledge Editing via Memory-Augmented Modality","abstract":"Knowledge editing is a technique for efficiently and accurately updating the knowledge of large language models (LLMs) to alleviate obsolescence and correct errors. However, most existing methods overfit to specific models, causing edited knowledge to be discarded during each LLM update and requiring frequent re-editing, which is particularly burdensome in today's rapidly evolving open-source community. To address this issue, we propose the problem of cross-model knowledge editing and introduce MindBridge, a scalable solution inspired by the low coupling between modality processing and LLMs in multi-modal models. MindBridge introduces the novel concept of memory modality, which encodes edited knowledge as an independent modality. It first performs LLM-agnostic pre-training of the memory modality and then integrates it with various LLMs. Extensive experiments on multiple LLMs and popular knowledge editing datasets demonstrate that MindBridge achieves superior performance even in editing tens of thousands of knowledge entries and can flexibly adapt to different LLMs. Our code is available at https://github.com/CrashBugger/MindBridge.","sentences":["Knowledge editing is a technique for efficiently and accurately updating the knowledge of large language models (LLMs) to alleviate obsolescence and correct errors.","However, most existing methods overfit to specific models, causing edited knowledge to be discarded during each LLM update and requiring frequent re-editing, which is particularly burdensome in today's rapidly evolving open-source community.","To address this issue, we propose the problem of cross-model knowledge editing and introduce MindBridge, a scalable solution inspired by the low coupling between modality processing and LLMs in multi-modal models.","MindBridge introduces the novel concept of memory modality, which encodes edited knowledge as an independent modality.","It first performs LLM-agnostic pre-training of the memory modality and then integrates it with various LLMs.","Extensive experiments on multiple LLMs and popular knowledge editing datasets demonstrate that MindBridge achieves superior performance even in editing tens of thousands of knowledge entries and can flexibly adapt to different LLMs.","Our code is available at https://github.com/CrashBugger/MindBridge."],"url":"http://arxiv.org/abs/2503.02701v1"}
{"created":"2025-03-04 15:17:40","title":"Multi-Strategy Enhanced COA for Path Planning in Autonomous Navigation","abstract":"Autonomous navigation is reshaping various domains in people's life by enabling efficient and safe movement in complex environments. Reliable navigation requires algorithmic approaches that compute optimal or near-optimal trajectories while satisfying task-specific constraints and ensuring obstacle avoidance. However, existing methods struggle with slow convergence and suboptimal solutions, particularly in complex environments, limiting their real-world applicability. To address these limitations, this paper presents the Multi-Strategy Enhanced Crayfish Optimization Algorithm (MCOA), a novel approach integrating three key strategies: 1) Refractive Opposition Learning, enhancing population diversity and global exploration, 2) Stochastic Centroid-Guided Exploration, balancing global and local search to prevent premature convergence, and 3) Adaptive Competition-Based Selection, dynamically adjusting selection pressure for faster convergence and improved solution quality. Empirical evaluations underscore the remarkable planning speed and the amazing solution quality of MCOA in both 3D Unmanned Aerial Vehicle (UAV) and 2D mobile robot path planning. Against 11 baseline algorithms, MCOA achieved a 69.2% reduction in computational time and a 16.7% improvement in minimizing overall path cost in 3D UAV scenarios. Furthermore, in 2D path planning, MCOA outperformed baseline approaches by 44% on average, with an impressive 75.6% advantage in the largest 60*60 grid setting. These findings validate MCOA as a powerful tool for optimizing autonomous navigation in complex environments. The source code is available at: https://github.com/coedv-hub/MCOA.","sentences":["Autonomous navigation is reshaping various domains in people's life by enabling efficient and safe movement in complex environments.","Reliable navigation requires algorithmic approaches that compute optimal or near-optimal trajectories while satisfying task-specific constraints and ensuring obstacle avoidance.","However, existing methods struggle with slow convergence and suboptimal solutions, particularly in complex environments, limiting their real-world applicability.","To address these limitations, this paper presents the Multi-Strategy Enhanced Crayfish Optimization Algorithm (MCOA), a novel approach integrating three key strategies: 1) Refractive Opposition Learning, enhancing population diversity and global exploration, 2) Stochastic Centroid-Guided Exploration, balancing global and local search to prevent premature convergence, and 3) Adaptive Competition-Based Selection, dynamically adjusting selection pressure for faster convergence and improved solution quality.","Empirical evaluations underscore the remarkable planning speed and the amazing solution quality of MCOA in both 3D Unmanned Aerial Vehicle (UAV) and 2D mobile robot path planning.","Against 11 baseline algorithms, MCOA achieved a 69.2% reduction in computational time and a 16.7% improvement in minimizing overall path cost in 3D UAV scenarios.","Furthermore, in 2D path planning, MCOA outperformed baseline approaches by 44% on average, with an impressive 75.6% advantage in the largest 60*60 grid setting.","These findings validate MCOA as a powerful tool for optimizing autonomous navigation in complex environments.","The source code is available at: https://github.com/coedv-hub/MCOA."],"url":"http://arxiv.org/abs/2503.02700v1"}
{"created":"2025-03-04 15:17:12","title":"Toward Filling a Critical Knowledge Gap: Charting the Interactions of Age with Task and Visualization","abstract":"We present the results of a study comparing the performance of younger adults (YA) and people in late adulthood (PLA) across ten low-level analysis tasks and five basic visualizations, employing Bayesian regression to aggregate and model participant performance. We analyzed performance at the task level and across combinations of tasks and visualizations, reporting measures of performance at aggregate and individual levels. These analyses showed that PLA on average required more time to complete tasks while demonstrating comparable accuracy. Furthermore, at the individual level, PLA exhibited greater heterogeneity in task performance as well as differences in best-performing visualization types for some tasks. We contribute empirical knowledge on how age interacts with analysis task and visualization type and use these results to offer actionable insights and design recommendations for aging-inclusive visualization design. We invite the visualization research community to further investigate aging-aware data visualization. Supplementary materials can be found at https://osf.io/a7xtz/.","sentences":["We present the results of a study comparing the performance of younger adults (YA) and people in late adulthood (PLA) across ten low-level analysis tasks and five basic visualizations, employing Bayesian regression to aggregate and model participant performance.","We analyzed performance at the task level and across combinations of tasks and visualizations, reporting measures of performance at aggregate and individual levels.","These analyses showed that PLA on average required more time to complete tasks while demonstrating comparable accuracy.","Furthermore, at the individual level, PLA exhibited greater heterogeneity in task performance as well as differences in best-performing visualization types for some tasks.","We contribute empirical knowledge on how age interacts with analysis task and visualization type and use these results to offer actionable insights and design recommendations for aging-inclusive visualization design.","We invite the visualization research community to further investigate aging-aware data visualization.","Supplementary materials can be found at https://osf.io/a7xtz/."],"url":"http://arxiv.org/abs/2503.02699v1"}
{"created":"2025-03-04 15:14:41","title":"FlowPlan: Zero-Shot Task Planning with LLM Flow Engineering for Robotic Instruction Following","abstract":"Robotic instruction following tasks require seamless integration of visual perception, task planning, target localization, and motion execution. However, existing task planning methods for instruction following are either data-driven or underperform in zero-shot scenarios due to difficulties in grounding lengthy instructions into actionable plans under operational constraints. To address this, we propose FlowPlan, a structured multi-stage LLM workflow that elevates zero-shot pipeline and bridges the performance gap between zero-shot and data-driven in-context learning methods. By decomposing the planning process into modular stages--task information retrieval, language-level reasoning, symbolic-level planning, and logical evaluation--FlowPlan generates logically coherent action sequences while adhering to operational constraints and further extracts contextual guidance for precise instance-level target localization. Benchmarked on the ALFRED and validated in real-world applications, our method achieves competitive performance relative to data-driven in-context learning methods and demonstrates adaptability across diverse environments. This work advances zero-shot task planning in robotic systems without reliance on labeled data. Project website: https://instruction-following-project.github.io/.","sentences":["Robotic instruction following tasks require seamless integration of visual perception, task planning, target localization, and motion execution.","However, existing task planning methods for instruction following are either data-driven or underperform in zero-shot scenarios due to difficulties in grounding lengthy instructions into actionable plans under operational constraints.","To address this, we propose FlowPlan, a structured multi-stage LLM workflow that elevates zero-shot pipeline and bridges the performance gap between zero-shot and data-driven in-context learning methods.","By decomposing the planning process into modular stages--task information retrieval, language-level reasoning, symbolic-level planning, and logical evaluation--FlowPlan generates logically coherent action sequences while adhering to operational constraints and further extracts contextual guidance for precise instance-level target localization.","Benchmarked on the ALFRED and validated in real-world applications, our method achieves competitive performance relative to data-driven in-context learning methods and demonstrates adaptability across diverse environments.","This work advances zero-shot task planning in robotic systems without reliance on labeled data.","Project website: https://instruction-following-project.github.io/."],"url":"http://arxiv.org/abs/2503.02698v1"}
{"created":"2025-03-04 15:12:18","title":"Zero-Shot Complex Question-Answering on Long Scientific Documents","abstract":"With the rapid development in Transformer-based language models, the reading comprehension tasks on short documents and simple questions have been largely addressed. Long documents, specifically the scientific documents that are densely packed with knowledge discovered and developed by humans, remain relatively unexplored. These documents often come with a set of complex and more realistic questions, adding to their complexity. We present a zero-shot pipeline framework that enables social science researchers to perform question-answering tasks that are complex yet of predetermined question formats on full-length research papers without requiring machine learning expertise. Our approach integrates pre-trained language models to handle challenging scenarios including multi-span extraction, multi-hop reasoning, and long-answer generation. Evaluating on MLPsych, a novel dataset of social psychology papers with annotated complex questions, we demonstrate that our framework achieves strong performance through combination of extractive and generative models. This work advances document understanding capabilities for social sciences while providing practical tools for researchers.","sentences":["With the rapid development in Transformer-based language models, the reading comprehension tasks on short documents and simple questions have been largely addressed.","Long documents, specifically the scientific documents that are densely packed with knowledge discovered and developed by humans, remain relatively unexplored.","These documents often come with a set of complex and more realistic questions, adding to their complexity.","We present a zero-shot pipeline framework that enables social science researchers to perform question-answering tasks that are complex yet of predetermined question formats on full-length research papers without requiring machine learning expertise.","Our approach integrates pre-trained language models to handle challenging scenarios including multi-span extraction, multi-hop reasoning, and long-answer generation.","Evaluating on MLPsych, a novel dataset of social psychology papers with annotated complex questions, we demonstrate that our framework achieves strong performance through combination of extractive and generative models.","This work advances document understanding capabilities for social sciences while providing practical tools for researchers."],"url":"http://arxiv.org/abs/2503.02695v1"}
{"created":"2025-03-04 15:08:41","title":"Temporal Cycle Detection and Acyclic Temporization","abstract":"In directed graphs, a cycle can be seen as a structure that allows its vertices to loop back to themselves, or as a structure that allows pairs of vertices to reach each other through distinct paths. We extend these concepts to temporal graph theory, resulting in multiple interesting definitions of a \"temporal cycle\". For each of these, we consider the problems of Cycle Detection and Acyclic Temporization. For the former, we are given an input temporal digraph, and we want to decide whether it contains a temporal cycle. Regarding the latter, for a given input (static) digraph, we want to time the arcs such that no temporal cycle exists in the resulting temporal digraph. We're also interested in Acyclic Temporization where we bound the lifetime of the resulting temporal digraph. Multiple results are presented, including polynomial and fixed-parameter tractable search algorithms, polynomial-time reductions from 3-SAT and Not All Equal 3-SAT, and temporizations resulting from arbitrary vertex orderings which cover (almost) all cases.","sentences":["In directed graphs, a cycle can be seen as a structure that allows its vertices to loop back to themselves, or as a structure that allows pairs of vertices to reach each other through distinct paths.","We extend these concepts to temporal graph theory, resulting in multiple interesting definitions of a \"temporal cycle\".","For each of these, we consider the problems of Cycle Detection and Acyclic Temporization.","For the former, we are given an input temporal digraph, and we want to decide whether it contains a temporal cycle.","Regarding the latter, for a given input (static) digraph, we want to time the arcs such that no temporal cycle exists in the resulting temporal digraph.","We're also interested in Acyclic Temporization where we bound the lifetime of the resulting temporal digraph.","Multiple results are presented, including polynomial and fixed-parameter tractable search algorithms, polynomial-time reductions from 3-SAT and Not All Equal 3-SAT, and temporizations resulting from arbitrary vertex orderings which cover (almost) all cases."],"url":"http://arxiv.org/abs/2503.02694v1"}
{"created":"2025-03-04 15:07:25","title":"Federated Learning for Privacy-Preserving Feedforward Control in Multi-Agent Systems","abstract":"Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability. However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs. Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges. This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data. By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability. We demonstrate the effectiveness of our method in an autonomous driving use case. Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control. Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control. We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control. Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications.","sentences":["Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability.","However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs.","Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges.","This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data.","By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability.","We demonstrate the effectiveness of our method in an autonomous driving use case.","Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control.","Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control.","We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control.","Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications."],"url":"http://arxiv.org/abs/2503.02693v1"}
{"created":"2025-03-04 15:04:40","title":"FinArena: A Human-Agent Collaboration Framework for Financial Market Analysis and Forecasting","abstract":"To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework. Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction. The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies. The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements. To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data. Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors' individual risk preferences. Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles. These findings highlight FinArena's potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations.","sentences":["To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework.","Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction.","The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies.","The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements.","To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data.","Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors' individual risk preferences.","Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles.","These findings highlight FinArena's potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations."],"url":"http://arxiv.org/abs/2503.02692v1"}
{"created":"2025-03-04 15:03:47","title":"Memory Efficient Continual Learning for Edge-Based Visual Anomaly Detection","abstract":"Visual Anomaly Detection (VAD) is a critical task in computer vision with numerous real-world applications. However, deploying these models on edge devices presents significant challenges, such as constrained computational and memory resources. Additionally, dynamic data distributions in real-world settings necessitate continuous model adaptation, further complicating deployment under limited resources. To address these challenges, we present a novel investigation into the problem of Continual Learning for Visual Anomaly Detection (CLAD) on edge devices. We evaluate the STFPM approach, given its low memory footprint on edge devices, which demonstrates good performance when combined with the Replay approach. Furthermore, we propose to study the behavior of a recently proposed approach, PaSTe, specifically designed for the edge but not yet explored in the Continual Learning context. Our results show that PaSTe is not only a lighter version of STPFM, but it also achieves superior anomaly detection performance, improving the f1 pixel performance by 10% with the Replay technique. In particular, the structure of PaSTe allows us to test it using a series of Compressed Replay techniques, reducing memory overhead by a maximum of 91.5% compared to the traditional Replay for STFPM. Our study proves the feasibility of deploying VAD models that adapt and learn incrementally on CLAD scenarios on resource-constrained edge devices.","sentences":["Visual Anomaly Detection (VAD) is a critical task in computer vision with numerous real-world applications.","However, deploying these models on edge devices presents significant challenges, such as constrained computational and memory resources.","Additionally, dynamic data distributions in real-world settings necessitate continuous model adaptation, further complicating deployment under limited resources.","To address these challenges, we present a novel investigation into the problem of Continual Learning for Visual Anomaly Detection (CLAD) on edge devices.","We evaluate the STFPM approach, given its low memory footprint on edge devices, which demonstrates good performance when combined with the Replay approach.","Furthermore, we propose to study the behavior of a recently proposed approach, PaSTe, specifically designed for the edge but not yet explored in the Continual Learning context.","Our results show that PaSTe is not only a lighter version of STPFM, but it also achieves superior anomaly detection performance, improving the f1 pixel performance by 10% with the Replay technique.","In particular, the structure of PaSTe allows us to test it using a series of Compressed Replay techniques, reducing memory overhead by a maximum of 91.5% compared to the traditional Replay for STFPM.","Our study proves the feasibility of deploying VAD models that adapt and learn incrementally on CLAD scenarios on resource-constrained edge devices."],"url":"http://arxiv.org/abs/2503.02691v1"}
{"created":"2025-03-04 15:03:15","title":"Generative Modeling of Microweather Wind Velocities for Urban Air Mobility","abstract":"Motivated by the pursuit of safe, reliable, and weather-tolerant urban air mobility (UAM) solutions, this work proposes a generative modeling approach for characterizing microweather wind velocities. Microweather, or the weather conditions in highly localized areas, is particularly complex in urban environments owing to the chaotic and turbulent nature of wind flows. Furthermore, traditional means of assessing local wind fields are not generally viable solutions for UAM applications: 1) field measurements that would rely on permanent wind profiling systems in operational air space are not practical, 2) physics-based models that simulate fluid dynamics at a sufficiently high resolution are not computationally tractable, and 3) data-driven modeling approaches that are largely deterministic ignore the inherent variability in turbulent flows that dictates UAM reliability. Thus, advancements in predictive capabilities are needed to help mitigate the unique operational safety risks that microweather winds pose for smaller, lighter weight UAM aircraft.   This work aims to model microweather wind velocities in a manner that is computationally-efficient, captures random variability, and would only require a temporary, rather than permanent, field measurement campaign. Inspired by recent breakthroughs in conditional generative AI such as text-to-image generation, the proposed approach learns a probabilistic macro-to-microweather mapping between regional weather forecasts and measured local wind velocities using generative modeling (denoising diffusion probabilistic models, flow matching, and Gaussian mixture models). A simple proof of concept was implemented using a dataset comprised of local (micro) measurements from a Sonic Detection and Ranging (SoDAR) wind profiler along with (macro) forecast data from a nearby weather station over the same time period.","sentences":["Motivated by the pursuit of safe, reliable, and weather-tolerant urban air mobility (UAM) solutions, this work proposes a generative modeling approach for characterizing microweather wind velocities.","Microweather, or the weather conditions in highly localized areas, is particularly complex in urban environments owing to the chaotic and turbulent nature of wind flows.","Furthermore, traditional means of assessing local wind fields are not generally viable solutions for UAM applications: 1) field measurements that would rely on permanent wind profiling systems in operational air space are not practical, 2) physics-based models that simulate fluid dynamics at a sufficiently high resolution are not computationally tractable, and 3) data-driven modeling approaches that are largely deterministic ignore the inherent variability in turbulent flows that dictates UAM reliability.","Thus, advancements in predictive capabilities are needed to help mitigate the unique operational safety risks that microweather winds pose for smaller, lighter weight UAM aircraft.   ","This work aims to model microweather wind velocities in a manner that is computationally-efficient, captures random variability, and would only require a temporary, rather than permanent, field measurement campaign.","Inspired by recent breakthroughs in conditional generative AI such as text-to-image generation, the proposed approach learns a probabilistic macro-to-microweather mapping between regional weather forecasts and measured local wind velocities using generative modeling (denoising diffusion probabilistic models, flow matching, and Gaussian mixture models).","A simple proof of concept was implemented using a dataset comprised of local (micro) measurements from a Sonic Detection and Ranging (SoDAR) wind profiler along with (macro) forecast data from a nearby weather station over the same time period."],"url":"http://arxiv.org/abs/2503.02690v1"}
{"created":"2025-03-04 15:02:32","title":"STAA-SNN: Spatial-Temporal Attention Aggregator for Spiking Neural Networks","abstract":"Spiking Neural Networks (SNNs) have gained significant attention due to their biological plausibility and energy efficiency, making them promising alternatives to Artificial Neural Networks (ANNs). However, the performance gap between SNNs and ANNs remains a substantial challenge hindering the widespread adoption of SNNs. In this paper, we propose a Spatial-Temporal Attention Aggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures both spatial and temporal dependencies. First, we introduce a spike-driven self-attention mechanism specifically designed for SNNs. Additionally, we pioneeringly incorporate position encoding to integrate latent temporal relationships into the incoming features. For spatial-temporal information aggregation, we employ step attention to selectively amplify relevant features at different steps. Finally, we implement a time-step random dropout strategy to avoid local optima. As a result, STAA-SNN effectively captures both spatial and temporal dependencies, enabling the model to analyze complex patterns and make accurate predictions. The framework demonstrates exceptional performance across diverse datasets and exhibits strong generalization capabilities. Notably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets CIFAR10-DVS, with remarkable performances of 97.14%, 82.05% and 70.40% on the static datasets CIFAR-10, CIFAR-100 and ImageNet, respectively. Furthermore, our model exhibits improved performance ranging from 0.33\\% to 2.80\\% with fewer time steps. The code for the model is available on GitHub.","sentences":["Spiking Neural Networks (SNNs) have gained significant attention due to their biological plausibility and energy efficiency, making them promising alternatives to Artificial Neural Networks (ANNs).","However, the performance gap between SNNs and ANNs remains a substantial challenge hindering the widespread adoption of SNNs.","In this paper, we propose a Spatial-Temporal Attention Aggregator SNN (STAA-SNN) framework, which dynamically focuses on and captures both spatial and temporal dependencies.","First, we introduce a spike-driven self-attention mechanism specifically designed for SNNs.","Additionally, we pioneeringly incorporate position encoding to integrate latent temporal relationships into the incoming features.","For spatial-temporal information aggregation, we employ step attention to selectively amplify relevant features at different steps.","Finally, we implement a time-step random dropout strategy to avoid local optima.","As a result, STAA-SNN effectively captures both spatial and temporal dependencies, enabling the model to analyze complex patterns and make accurate predictions.","The framework demonstrates exceptional performance across diverse datasets and exhibits strong generalization capabilities.","Notably, STAA-SNN achieves state-of-the-art results on neuromorphic datasets CIFAR10-DVS, with remarkable performances of 97.14%, 82.05% and 70.40% on the static datasets CIFAR-10, CIFAR-100 and ImageNet, respectively.","Furthermore, our model exhibits improved performance ranging from 0.33\\% to 2.80\\% with fewer time steps.","The code for the model is available on GitHub."],"url":"http://arxiv.org/abs/2503.02689v1"}
{"created":"2025-03-04 15:02:15","title":"A user-friendly SPARQL query editor powered by lightweight metadata","abstract":"SPARQL query editors often lack intuitive interfaces to aid SPARQL-savvy users to write queries. To address this issue, we propose an easy-to-deploy, triple store-agnostic and open-source query editor that offers three main features: (i) automatic query example rendering, (ii) precise autocomplete based on existing triple patterns including within SERVICE clauses, and (iii) a data-aware schema visualization. It can be easily set up with a custom HTML element. The tool has been successfully tested on various public endpoints, and is deployed online at https://sib-swiss.github.io/sparql-editor with open-source code available at https://github.com/sib-swiss/sparql-editor.","sentences":["SPARQL query editors often lack intuitive interfaces to aid SPARQL-savvy users to write queries.","To address this issue, we propose an easy-to-deploy, triple store-agnostic and open-source query editor that offers three main features: (i) automatic query example rendering, (ii) precise autocomplete based on existing triple patterns including within SERVICE clauses, and (iii) a data-aware schema visualization.","It can be easily set up with a custom HTML element.","The tool has been successfully tested on various public endpoints, and is deployed online at https://sib-swiss.github.io/sparql-editor with open-source code available at https://github.com/sib-swiss/sparql-editor."],"url":"http://arxiv.org/abs/2503.02688v1"}
{"created":"2025-03-04 15:02:07","title":"Class-Aware PillarMix: Can Mixed Sample Data Augmentation Enhance 3D Object Detection with Radar Point Clouds?","abstract":"Due to the significant effort required for data collection and annotation in 3D perception tasks, mixed sample data augmentation (MSDA) has been widely studied to generate diverse training samples by mixing existing data. Recently, many MSDA techniques have been developed for point clouds, but they mainly target LiDAR data, leaving their application to radar point clouds largely unexplored. In this paper, we examine the feasibility of applying existing MSDA methods to radar point clouds and identify several challenges in adapting these techniques. These obstacles stem from the radar's irregular angular distribution, deviations from a single-sensor polar layout in multi-radar setups, and point sparsity. To address these issues, we propose Class-Aware PillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar level in 3D point clouds, guided by class labels. Unlike methods that rely a single mix ratio to the entire sample, CAPMix assigns an independent ratio to each pillar, boosting sample diversity. To account for the density of different classes, we use class-specific distributions: for dense objects (e.g., large vehicles), we skew ratios to favor points from another sample, while for sparse objects (e.g., pedestrians), we sample more points from the original. This class-aware mixing retains critical details and enriches each sample with new information, ultimately generating more diverse training data. Experimental results demonstrate that our method not only significantly boosts performance but also outperforms existing MSDA approaches across two datasets (Bosch Street and K-Radar). We believe that this straightforward yet effective approach will spark further investigation into MSDA techniques for radar data.","sentences":["Due to the significant effort required for data collection and annotation in 3D perception tasks, mixed sample data augmentation (MSDA) has been widely studied to generate diverse training samples by mixing existing data.","Recently, many MSDA techniques have been developed for point clouds, but they mainly target LiDAR data, leaving their application to radar point clouds largely unexplored.","In this paper, we examine the feasibility of applying existing MSDA methods to radar point clouds and identify several challenges in adapting these techniques.","These obstacles stem from the radar's irregular angular distribution, deviations from a single-sensor polar layout in multi-radar setups, and point sparsity.","To address these issues, we propose Class-Aware PillarMix (CAPMix), a novel MSDA approach that applies MixUp at the pillar level in 3D point clouds, guided by class labels.","Unlike methods that rely a single mix ratio to the entire sample, CAPMix assigns an independent ratio to each pillar, boosting sample diversity.","To account for the density of different classes, we use class-specific distributions: for dense objects (e.g., large vehicles), we skew ratios to favor points from another sample, while for sparse objects (e.g., pedestrians), we sample more points from the original.","This class-aware mixing retains critical details and enriches each sample with new information, ultimately generating more diverse training data.","Experimental results demonstrate that our method not only significantly boosts performance but also outperforms existing MSDA approaches across two datasets (Bosch Street and K-Radar).","We believe that this straightforward yet effective approach will spark further investigation into MSDA techniques for radar data."],"url":"http://arxiv.org/abs/2503.02687v1"}
{"created":"2025-03-04 14:58:59","title":"Seeding for Success: Skill and Stochasticity in Tabletop Games","abstract":"Games often incorporate random elements in the form of dice or shuffled card decks. This randomness is a key contributor to the player experience and the variety of game situations encountered. There is a tension between a level of randomness that makes the game interesting and contributes to the player enjoyment of a game, and a level at which the outcome itself is effectively random and the game becomes dull. The optimal level for a game will depend on the design goals and target audience. We introduce a new technique to quantify the level of randomness in game outcome and use it to compare 15 tabletop games and disentangle the different contributions to the overall randomness from specific parts of some games. We further explore the interaction between game randomness and player skill, and how this innate randomness can affect error analysis in common game experiments.","sentences":["Games often incorporate random elements in the form of dice or shuffled card decks.","This randomness is a key contributor to the player experience and the variety of game situations encountered.","There is a tension between a level of randomness that makes the game interesting and contributes to the player enjoyment of a game, and a level at which the outcome itself is effectively random and the game becomes dull.","The optimal level for a game will depend on the design goals and target audience.","We introduce a new technique to quantify the level of randomness in game outcome and use it to compare 15 tabletop games and disentangle the different contributions to the overall randomness from specific parts of some games.","We further explore the interaction between game randomness and player skill, and how this innate randomness can affect error analysis in common game experiments."],"url":"http://arxiv.org/abs/2503.02686v1"}
{"created":"2025-03-04 14:54:45","title":"MPO: Boosting LLM Agents with Meta Plan Optimization","abstract":"Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios.","sentences":["Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks.","However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent.","To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance.","Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution.","Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines.","Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios."],"url":"http://arxiv.org/abs/2503.02682v1"}
