{"created":"2024-08-15 17:59:57","title":"Can Large Language Models Understand Symbolic Graphics Programs?","abstract":"Assessing the capabilities of large language models (LLMs) is often challenging, in part, because it is hard to find tasks to which they have not been exposed during training. We take one step to address this challenge by turning to a new task: focusing on symbolic graphics programs, which are a popular representation for graphics content that procedurally generates visual data. LLMs have shown exciting promise towards program synthesis, but do they understand symbolic graphics programs? Unlike conventional programs, symbolic graphics programs can be translated to graphics content. Here, we characterize an LLM's understanding of symbolic programs in terms of their ability to answer questions related to the graphics content. This task is challenging as the questions are difficult to answer from the symbolic programs alone -- yet, they would be easy to answer from the corresponding graphics content as we verify through a human experiment. To understand symbolic programs, LLMs may need to possess the ability to imagine how the corresponding graphics content would look without directly accessing the rendered visual content. We use this task to evaluate LLMs by creating a large benchmark for the semantic understanding of symbolic graphics programs. This benchmark is built via program-graphics correspondence, hence requiring minimal human efforts. We evaluate current LLMs on our benchmark to elucidate a preliminary assessment of their ability to reason about visual scenes from programs. We find that this task distinguishes existing LLMs and models considered good at reasoning perform better. Lastly, we introduce Symbolic Instruction Tuning (SIT) to improve this ability. Specifically, we query GPT4-o with questions and images generated by symbolic programs. Such data are then used to finetune an LLM. We also find that SIT data can improve the general instruction following ability of LLMs.","sentences":["Assessing the capabilities of large language models (LLMs) is often challenging, in part, because it is hard to find tasks to which they have not been exposed during training.","We take one step to address this challenge by turning to a new task: focusing on symbolic graphics programs, which are a popular representation for graphics content that procedurally generates visual data.","LLMs have shown exciting promise towards program synthesis, but do they understand symbolic graphics programs?","Unlike conventional programs, symbolic graphics programs can be translated to graphics content.","Here, we characterize an LLM's understanding of symbolic programs in terms of their ability to answer questions related to the graphics content.","This task is challenging as the questions are difficult to answer from the symbolic programs alone -- yet, they would be easy to answer from the corresponding graphics content as we verify through a human experiment.","To understand symbolic programs, LLMs may need to possess the ability to imagine how the corresponding graphics content would look without directly accessing the rendered visual content.","We use this task to evaluate LLMs by creating a large benchmark for the semantic understanding of symbolic graphics programs.","This benchmark is built via program-graphics correspondence, hence requiring minimal human efforts.","We evaluate current LLMs on our benchmark to elucidate a preliminary assessment of their ability to reason about visual scenes from programs.","We find that this task distinguishes existing LLMs and models considered good at reasoning perform better.","Lastly, we introduce Symbolic Instruction Tuning (SIT) to improve this ability.","Specifically, we query GPT4-o with questions and images generated by symbolic programs.","Such data are then used to finetune an LLM.","We also find that SIT data can improve the general instruction following ability of LLMs."],"url":"http://arxiv.org/abs/2408.08313v1"}
{"created":"2024-08-15 17:59:53","title":"HyperTaxel: Hyper-Resolution for Taxel-Based Tactile Signals Through Contrastive Learning","abstract":"To achieve dexterity comparable to that of humans, robots must intelligently process tactile sensor data. Taxel-based tactile signals often have low spatial-resolution, with non-standardized representations. In this paper, we propose a novel framework, HyperTaxel, for learning a geometrically-informed representation of taxel-based tactile signals to address challenges associated with their spatial resolution. We use this representation and a contrastive learning objective to encode and map sparse low-resolution taxel signals to high-resolution contact surfaces. To address the uncertainty inherent in these signals, we leverage joint probability distributions across multiple simultaneous contacts to improve taxel hyper-resolution. We evaluate our representation by comparing it with two baselines and present results that suggest our representation outperforms the baselines. Furthermore, we present qualitative results that demonstrate the learned representation captures the geometric features of the contact surface, such as flatness, curvature, and edges, and generalizes across different objects and sensor configurations. Moreover, we present results that suggest our representation improves the performance of various downstream tasks, such as surface classification, 6D in-hand pose estimation, and sim-to-real transfer.","sentences":["To achieve dexterity comparable to that of humans, robots must intelligently process tactile sensor data.","Taxel-based tactile signals often have low spatial-resolution, with non-standardized representations.","In this paper, we propose a novel framework, HyperTaxel, for learning a geometrically-informed representation of taxel-based tactile signals to address challenges associated with their spatial resolution.","We use this representation and a contrastive learning objective to encode and map sparse low-resolution taxel signals to high-resolution contact surfaces.","To address the uncertainty inherent in these signals, we leverage joint probability distributions across multiple simultaneous contacts to improve taxel hyper-resolution.","We evaluate our representation by comparing it with two baselines and present results that suggest our representation outperforms the baselines.","Furthermore, we present qualitative results that demonstrate the learned representation captures the geometric features of the contact surface, such as flatness, curvature, and edges, and generalizes across different objects and sensor configurations.","Moreover, we present results that suggest our representation improves the performance of various downstream tasks, such as surface classification, 6D in-hand pose estimation, and sim-to-real transfer."],"url":"http://arxiv.org/abs/2408.08312v1"}
{"created":"2024-08-15 17:59:30","title":"ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws","abstract":"High-quality data is crucial for the pre-training performance of large language models. Unfortunately, existing quality filtering methods rely on a known high-quality dataset as reference, which can introduce potential bias and compromise diversity. In this paper, we propose ScalingFilter, a novel approach that evaluates text quality based on the perplexity difference between two language models trained on the same data, thereby eliminating the influence of the reference dataset in the filtering process. An theoretical analysis shows that ScalingFilter is equivalent to an inverse utilization of scaling laws. Through training models with 1.3B parameters on the same data source processed by various quality filters, we find ScalingFilter can improve zero-shot performance of pre-trained models in downstream tasks. To assess the bias introduced by quality filtering, we introduce semantic diversity, a metric of utilizing text embedding models for semantic representations. Extensive experiments reveal that semantic diversity is a reliable indicator of dataset diversity, and ScalingFilter achieves an optimal balance between downstream performance and semantic diversity.","sentences":["High-quality data is crucial for the pre-training performance of large language models.","Unfortunately, existing quality filtering methods rely on a known high-quality dataset as reference, which can introduce potential bias and compromise diversity.","In this paper, we propose ScalingFilter, a novel approach that evaluates text quality based on the perplexity difference between two language models trained on the same data, thereby eliminating the influence of the reference dataset in the filtering process.","An theoretical analysis shows that ScalingFilter is equivalent to an inverse utilization of scaling laws.","Through training models with 1.3B parameters on the same data source processed by various quality filters, we find ScalingFilter can improve zero-shot performance of pre-trained models in downstream tasks.","To assess the bias introduced by quality filtering, we introduce semantic diversity, a metric of utilizing text embedding models for semantic representations.","Extensive experiments reveal that semantic diversity is a reliable indicator of dataset diversity, and ScalingFilter achieves an optimal balance between downstream performance and semantic diversity."],"url":"http://arxiv.org/abs/2408.08310v1"}
{"created":"2024-08-15 17:59:06","title":"Understanding the Local Geometry of Generative Model Manifolds","abstract":"Deep generative models learn continuous representations of complex data manifolds using a finite number of samples during training. For a pre-trained generative model, the common way to evaluate the quality of the manifold representation learned, is by computing global metrics like Fr\\'echet Inception Distance using a large number of generated and real samples. However, generative model performance is not uniform across the learned manifold, e.g., for \\textit{foundation models} like Stable Diffusion generation performance can vary significantly based on the conditioning or initial noise vector being denoised. In this paper we study the relationship between the \\textit{local geometry of the learned manifold} and downstream generation. Based on the theory of continuous piecewise-linear (CPWL) generators, we use three geometric descriptors - scaling ($\\psi$), rank ($\\nu$), and complexity ($\\delta$) - to characterize a pre-trained generative model manifold locally. We provide quantitative and qualitative evidence showing that for a given latent, the local descriptors are correlated with generation aesthetics, artifacts, uncertainty, and even memorization. Finally we demonstrate that training a \\textit{reward model} on the local geometry can allow controlling the likelihood of a generated sample under the learned distribution.","sentences":["Deep generative models learn continuous representations of complex data manifolds using a finite number of samples during training.","For a pre-trained generative model, the common way to evaluate the quality of the manifold representation learned, is by computing global metrics like Fr\\'echet Inception Distance using a large number of generated and real samples.","However, generative model performance is not uniform across the learned manifold, e.g., for \\textit{foundation models} like Stable Diffusion generation performance can vary significantly based on the conditioning or initial noise vector being denoised.","In this paper we study the relationship between the \\textit{local geometry of the learned manifold} and downstream generation.","Based on the theory of continuous piecewise-linear (CPWL) generators, we use three geometric descriptors - scaling ($\\psi$), rank ($\\nu$), and complexity ($\\delta$) - to characterize a pre-trained generative model manifold locally.","We provide quantitative and qualitative evidence showing that for a given latent, the local descriptors are correlated with generation aesthetics, artifacts, uncertainty, and even memorization.","Finally we demonstrate that training a \\textit{reward model} on the local geometry can allow controlling the likelihood of a generated sample under the learned distribution."],"url":"http://arxiv.org/abs/2408.08307v1"}
{"created":"2024-08-15 17:57:38","title":"Towards Flexible Visual Relationship Segmentation","abstract":"Visual relationship understanding has been studied separately in human-object interaction(HOI) detection, scene graph generation(SGG), and referring relationships(RR) tasks. Given the complexity and interconnectedness of these tasks, it is crucial to have a flexible framework that can effectively address these tasks in a cohesive manner. In this work, we propose FleVRS, a single model that seamlessly integrates the above three aspects in standard and promptable visual relationship segmentation, and further possesses the capability for open-vocabulary segmentation to adapt to novel scenarios. FleVRS leverages the synergy between text and image modalities, to ground various types of relationships from images and use textual features from vision-language models to visual conceptual understanding. Empirical validation across various datasets demonstrates that our framework outperforms existing models in standard, promptable, and open-vocabulary tasks, e.g., +1.9 $mAP$ on HICO-DET, +11.4 $Acc$ on VRD, +4.7 $mAP$ on unseen HICO-DET. Our FleVRS represents a significant step towards a more intuitive, comprehensive, and scalable understanding of visual relationships.","sentences":["Visual relationship understanding has been studied separately in human-object interaction(HOI) detection, scene graph generation(SGG), and referring relationships(RR) tasks.","Given the complexity and interconnectedness of these tasks, it is crucial to have a flexible framework that can effectively address these tasks in a cohesive manner.","In this work, we propose FleVRS, a single model that seamlessly integrates the above three aspects in standard and promptable visual relationship segmentation, and further possesses the capability for open-vocabulary segmentation to adapt to novel scenarios.","FleVRS leverages the synergy between text and image modalities, to ground various types of relationships from images and use textual features from vision-language models to visual conceptual understanding.","Empirical validation across various datasets demonstrates that our framework outperforms existing models in standard, promptable, and open-vocabulary tasks, e.g., +1.9 $mAP$ on HICO-DET, +11.4 $Acc$ on VRD, +4.7 $mAP$ on unseen HICO-DET.","Our FleVRS represents a significant step towards a more intuitive, comprehensive, and scalable understanding of visual relationships."],"url":"http://arxiv.org/abs/2408.08305v1"}
{"created":"2024-08-15 17:55:45","title":"Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors","abstract":"In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level transportation engineering problems. We introduce TransportBench, a benchmark dataset that includes a sample of transportation engineering problems on a wide range of subjects in the context of planning, design, management, and control of transportation systems. This dataset is used by human experts to evaluate the capabilities of various commercial and open-sourced LLMs, especially their accuracy, consistency, and reasoning behaviors, in solving transportation engineering problems. Our comprehensive analysis uncovers the unique strengths and limitations of each LLM, e.g. our analysis shows the impressive accuracy and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving TransportBench problems. Our study marks a thrilling first step toward harnessing artificial general intelligence for complex transportation challenges.","sentences":["In this paper, we explore the capabilities of state-of-the-art large language models (LLMs) such as GPT-4, GPT-4o, Claude 3.5 Sonnet, Claude 3 Opus, Gemini 1.5 Pro, Llama 3, and Llama 3.1 in solving some selected undergraduate-level transportation engineering problems.","We introduce TransportBench, a benchmark dataset that includes a sample of transportation engineering problems on a wide range of subjects in the context of planning, design, management, and control of transportation systems.","This dataset is used by human experts to evaluate the capabilities of various commercial and open-sourced LLMs, especially their accuracy, consistency, and reasoning behaviors, in solving transportation engineering problems.","Our comprehensive analysis uncovers the unique strengths and limitations of each LLM, e.g. our analysis shows the impressive accuracy and some unexpected inconsistent behaviors of Claude 3.5 Sonnet in solving TransportBench problems.","Our study marks a thrilling first step toward harnessing artificial general intelligence for complex transportation challenges."],"url":"http://arxiv.org/abs/2408.08302v1"}
{"created":"2024-08-15 17:54:55","title":"VLPG-Nav: Object Navigation Using Visual Language Pose Graph and Object Localization Probability Maps","abstract":"We present VLPG-Nav, a visual language navigation method for guiding robots to specified objects within household scenes. Unlike existing methods primarily focused on navigating the robot toward objects, our approach considers the additional challenge of centering the object within the robot's camera view. Our method builds a visual language pose graph (VLPG) that functions as a spatial map of VL embeddings. Given an open vocabulary object query, we plan a viewpoint for object navigation using the VLPG. Despite navigating to the viewpoint, real-world challenges like object occlusion, displacement, and the robot's localization error can prevent visibility. We build an object localization probability map that leverages the robot's current observations and prior VLPG. When the object isn't visible, the probability map is updated and an alternate viewpoint is computed. In addition, we propose an object-centering formulation that locally adjusts the robot's pose to center the object in the camera view. We evaluate the effectiveness of our approach through simulations and real-world experiments, evaluating its ability to successfully view and center the object within the camera field of view. VLPG-Nav demonstrates improved performance in locating the object, navigating around occlusions, and centering the object within the robot's camera view, outperforming the selected baselines in the evaluation metrics.","sentences":["We present VLPG-Nav, a visual language navigation method for guiding robots to specified objects within household scenes.","Unlike existing methods primarily focused on navigating the robot toward objects, our approach considers the additional challenge of centering the object within the robot's camera view.","Our method builds a visual language pose graph (VLPG) that functions as a spatial map of VL embeddings.","Given an open vocabulary object query, we plan a viewpoint for object navigation using the VLPG.","Despite navigating to the viewpoint, real-world challenges like object occlusion, displacement, and the robot's localization error can prevent visibility.","We build an object localization probability map that leverages the robot's current observations and prior VLPG.","When the object isn't visible, the probability map is updated and an alternate viewpoint is computed.","In addition, we propose an object-centering formulation that locally adjusts the robot's pose to center the object in the camera view.","We evaluate the effectiveness of our approach through simulations and real-world experiments, evaluating its ability to successfully view and center the object within the camera field of view.","VLPG-Nav demonstrates improved performance in locating the object, navigating around occlusions, and centering the object within the robot's camera view, outperforming the selected baselines in the evaluation metrics."],"url":"http://arxiv.org/abs/2408.08301v1"}
{"created":"2024-08-15 17:54:31","title":"HELP: Hierarchical Embeddings-based Log Parsing","abstract":"Logs are a first-hand source of information for software maintenance and failure diagnosis. Log parsing, which converts semi-structured log messages into structured templates, is a prerequisite for automated log analysis tasks such as anomaly detection, troubleshooting, and root cause analysis. However, existing log parsers fail in real-world systems for three main reasons. First, traditional heuristics-based parsers require handcrafted features and domain knowledge, which are difficult to generalize at scale. Second, existing large language model-based parsers rely on periodic offline processing, limiting their effectiveness in real-time use cases. Third, existing online parsing algorithms are susceptible to log drift, where slight log changes create false positives that drown out real anomalies. To address these challenges, we propose HELP, a Hierarchical Embeddings-based Log Parser. HELP is the first online semantic-based parser to leverage LLMs for performant and cost-effective log parsing. We achieve this through a novel hierarchical embeddings module, which fine-tunes a text embedding model to cluster logs before parsing, reducing querying costs by multiple orders of magnitude. To combat log drift, we also develop an iterative rebalancing module, which periodically updates existing log groupings. We evaluate HELP extensively on 14 public large-scale datasets, showing that HELP achieves significantly higher F1-weighted grouping and parsing accuracy than current state-of-the-art online log parsers. We also implement HELP into Iudex's production observability platform, confirming HELP's practicality in a production environment. Our results show that HELP is effective and efficient for high-throughput real-world log parsing.","sentences":["Logs are a first-hand source of information for software maintenance and failure diagnosis.","Log parsing, which converts semi-structured log messages into structured templates, is a prerequisite for automated log analysis tasks such as anomaly detection, troubleshooting, and root cause analysis.","However, existing log parsers fail in real-world systems for three main reasons.","First, traditional heuristics-based parsers require handcrafted features and domain knowledge, which are difficult to generalize at scale.","Second, existing large language model-based parsers rely on periodic offline processing, limiting their effectiveness in real-time use cases.","Third, existing online parsing algorithms are susceptible to log drift, where slight log changes create false positives that drown out real anomalies.","To address these challenges, we propose HELP, a Hierarchical Embeddings-based Log Parser.","HELP is the first online semantic-based parser to leverage LLMs for performant and cost-effective log parsing.","We achieve this through a novel hierarchical embeddings module, which fine-tunes a text embedding model to cluster logs before parsing, reducing querying costs by multiple orders of magnitude.","To combat log drift, we also develop an iterative rebalancing module, which periodically updates existing log groupings.","We evaluate HELP extensively on 14 public large-scale datasets, showing that HELP achieves significantly higher F1-weighted grouping and parsing accuracy than current state-of-the-art online log parsers.","We also implement HELP into Iudex's production observability platform, confirming HELP's practicality in a production environment.","Our results show that HELP is effective and efficient for high-throughput real-world log parsing."],"url":"http://arxiv.org/abs/2408.08300v1"}
{"created":"2024-08-15 17:50:07","title":"SLCA++: Unleash the Power of Sequential Fine-tuning for Continual Learning with Pre-training","abstract":"In recent years, continual learning with pre-training (CLPT) has received widespread interest, instead of its traditional focus of training from scratch. The use of strong pre-trained models (PTMs) can greatly facilitate knowledge transfer and alleviate catastrophic forgetting, but also suffers from progressive overfitting of pre-trained knowledge into specific downstream tasks. A majority of current efforts often keep the PTMs frozen and incorporate task-specific prompts to instruct representation learning, coupled with a prompt selection process for inference. However, due to the limited capacity of prompt parameters, this strategy demonstrates only sub-optimal performance in continual learning. In comparison, tuning all parameters of PTMs often provides the greatest potential for representation learning, making sequential fine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT. To this end, we present an in-depth analysis of the progressive overfitting problem from the lens of Seq FT. Considering that the overly fast representation learning and the biased classification layer constitute this particular problem, we introduce the advanced Slow Learner with Classifier Alignment (SLCA++) framework to unleash the power of Seq FT, serving as a strong baseline approach for CLPT. Our approach involves a Slow Learner to selectively reduce the learning rate of backbone parameters, and a Classifier Alignment to align the disjoint classification layers in a post-hoc fashion. We further enhance the efficacy of SL with a symmetric cross-entropy loss, as well as employ a parameter-efficient strategy to implement Seq FT with SLCA++. Across a variety of continual learning scenarios on image classification benchmarks, our approach provides substantial improvements and outperforms state-of-the-art methods by a large margin. Code: https://github.com/GengDavid/SLCA.","sentences":["In recent years, continual learning with pre-training (CLPT) has received widespread interest, instead of its traditional focus of training from scratch.","The use of strong pre-trained models (PTMs) can greatly facilitate knowledge transfer and alleviate catastrophic forgetting, but also suffers from progressive overfitting of pre-trained knowledge into specific downstream tasks.","A majority of current efforts often keep the PTMs frozen and incorporate task-specific prompts to instruct representation learning, coupled with a prompt selection process for inference.","However, due to the limited capacity of prompt parameters, this strategy demonstrates only sub-optimal performance in continual learning.","In comparison, tuning all parameters of PTMs often provides the greatest potential for representation learning, making sequential fine-tuning (Seq FT) a fundamental baseline that has been overlooked in CLPT.","To this end, we present an in-depth analysis of the progressive overfitting problem from the lens of Seq FT.","Considering that the overly fast representation learning and the biased classification layer constitute this particular problem, we introduce the advanced Slow Learner with Classifier Alignment (SLCA++) framework to unleash the power of Seq FT, serving as a strong baseline approach for CLPT.","Our approach involves a Slow Learner to selectively reduce the learning rate of backbone parameters, and a Classifier Alignment to align the disjoint classification layers in a post-hoc fashion.","We further enhance the efficacy of SL with a symmetric cross-entropy loss, as well as employ a parameter-efficient strategy to implement Seq FT with SLCA++.","Across a variety of continual learning scenarios on image classification benchmarks, our approach provides substantial improvements and outperforms state-of-the-art methods by a large margin.","Code: https://github.com/GengDavid/SLCA."],"url":"http://arxiv.org/abs/2408.08295v1"}
{"created":"2024-08-15 17:46:54","title":"The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community","abstract":"Human-model conversations provide a window into users' real-world scenarios, behavior, and needs, and thus are a valuable resource for model development and research. While for-profit companies collect user data through the APIs of their models, using it internally to improve their own models, the open source and research community lags behind.   We introduce the ShareLM collection, a unified set of human conversations with large language models, and its accompanying plugin, a Web extension for voluntarily contributing user-model conversations. Where few platforms share their chats, the ShareLM plugin adds this functionality, thus, allowing users to share conversations from most platforms. The plugin allows the user to rate their conversations, both at the conversation and the response levels, and delete conversations they prefer to keep private before they ever leave the user's local storage. We release the plugin conversations as part of the ShareLM collection, and call for more community effort in the field of open human-model data.   The code, plugin, and data are available.","sentences":["Human-model conversations provide a window into users' real-world scenarios, behavior, and needs, and thus are a valuable resource for model development and research.","While for-profit companies collect user data through the APIs of their models, using it internally to improve their own models, the open source and research community lags behind.   ","We introduce the ShareLM collection, a unified set of human conversations with large language models, and its accompanying plugin, a Web extension for voluntarily contributing user-model conversations.","Where few platforms share their chats, the ShareLM plugin adds this functionality, thus, allowing users to share conversations from most platforms.","The plugin allows the user to rate their conversations, both at the conversation and the response levels, and delete conversations they prefer to keep private before they ever leave the user's local storage.","We release the plugin conversations as part of the ShareLM collection, and call for more community effort in the field of open human-model data.   ","The code, plugin, and data are available."],"url":"http://arxiv.org/abs/2408.08291v1"}
{"created":"2024-08-15 17:40:11","title":"Absence of Closed-Form Descriptions for Gradient Flow in Two-Layer Narrow Networks","abstract":"In the field of machine learning, comprehending the intricate training dynamics of neural networks poses a significant challenge. This paper explores the training dynamics of neural networks, particularly whether these dynamics can be expressed in a general closed-form solution. We demonstrate that the dynamics of the gradient flow in two-layer narrow networks is not an integrable system. Integrable systems are characterized by trajectories confined to submanifolds defined by level sets of first integrals (invariants), facilitating predictable and reducible dynamics. In contrast, non-integrable systems exhibit complex behaviors that are difficult to predict. To establish the non-integrability, we employ differential Galois theory, which focuses on the solvability of linear differential equations. We demonstrate that under mild conditions, the identity component of the differential Galois group of the variational equations of the gradient flow is non-solvable. This result confirms the system's non-integrability and implies that the training dynamics cannot be represented by Liouvillian functions, precluding a closed-form solution for describing these dynamics. Our findings highlight the necessity of employing numerical methods to tackle optimization problems within neural networks. The results contribute to a deeper understanding of neural network training dynamics and their implications for machine learning optimization strategies.","sentences":["In the field of machine learning, comprehending the intricate training dynamics of neural networks poses a significant challenge.","This paper explores the training dynamics of neural networks, particularly whether these dynamics can be expressed in a general closed-form solution.","We demonstrate that the dynamics of the gradient flow in two-layer narrow networks is not an integrable system.","Integrable systems are characterized by trajectories confined to submanifolds defined by level sets of first integrals (invariants), facilitating predictable and reducible dynamics.","In contrast, non-integrable systems exhibit complex behaviors that are difficult to predict.","To establish the non-integrability, we employ differential Galois theory, which focuses on the solvability of linear differential equations.","We demonstrate that under mild conditions, the identity component of the differential Galois group of the variational equations of the gradient flow is non-solvable.","This result confirms the system's non-integrability and implies that the training dynamics cannot be represented by Liouvillian functions, precluding a closed-form solution for describing these dynamics.","Our findings highlight the necessity of employing numerical methods to tackle optimization problems within neural networks.","The results contribute to a deeper understanding of neural network training dynamics and their implications for machine learning optimization strategies."],"url":"http://arxiv.org/abs/2408.08286v1"}
{"created":"2024-08-15 17:33:32","title":"Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model","abstract":"Enabling humanoid robots to perform autonomously loco-manipulation in unstructured environments is crucial and highly challenging for achieving embodied intelligence. This involves robots being able to plan their actions and behaviors in long-horizon tasks while using multi-modality to perceive deviations between task execution and high-level planning. Recently, large language models (LLMs) have demonstrated powerful planning and reasoning capabilities for comprehension and processing of semantic information through robot control tasks, as well as the usability of analytical judgment and decision-making for multi-modal inputs. To leverage the power of LLMs towards humanoid loco-manipulation, we propose a novel language-model based framework that enables robots to autonomously plan behaviors and low-level execution under given textual instructions, while observing and correcting failures that may occur during task execution. To systematically evaluate this framework in grounding LLMs, we created the robot 'action' and 'sensing' behavior library for task planning, and conducted mobile manipulation tasks and experiments in both simulated and real environments using the CENTAURO robot, and verified the effectiveness and application of this approach in robotic tasks with autonomous behavioral planning.","sentences":["Enabling humanoid robots to perform autonomously loco-manipulation in unstructured environments is crucial and highly challenging for achieving embodied intelligence.","This involves robots being able to plan their actions and behaviors in long-horizon tasks while using multi-modality to perceive deviations between task execution and high-level planning.","Recently, large language models (LLMs) have demonstrated powerful planning and reasoning capabilities for comprehension and processing of semantic information through robot control tasks, as well as the usability of analytical judgment and decision-making for multi-modal inputs.","To leverage the power of LLMs towards humanoid loco-manipulation, we propose a novel language-model based framework that enables robots to autonomously plan behaviors and low-level execution under given textual instructions, while observing and correcting failures that may occur during task execution.","To systematically evaluate this framework in grounding LLMs, we created the robot 'action' and 'sensing' behavior library for task planning, and conducted mobile manipulation tasks and experiments in both simulated and real environments using the CENTAURO robot, and verified the effectiveness and application of this approach in robotic tasks with autonomous behavioral planning."],"url":"http://arxiv.org/abs/2408.08282v1"}
{"created":"2024-08-15 17:21:21","title":"Marker or Markerless? Mode-Switchable Optical Tactile Sensing for Diverse Robot Tasks","abstract":"Optical tactile sensors play a pivotal role in robot perception and manipulation tasks. The membrane of these sensors can be painted with markers or remain markerless, enabling them to function in either marker or markerless mode. However, this uni-modal selection means the sensor is only suitable for either manipulation or perception tasks. While markers are vital for manipulation, they can also obstruct the camera, thereby impeding perception. The dilemma of selecting between marker and markerless modes presents a significant obstacle. To address this issue, we propose a novel mode-switchable optical tactile sensing approach that facilitates transitions between the two modes. The marker-to-markerless transition is achieved through a generative model, whereas its inverse transition is realized using a sparsely supervised regressive model. Our approach allows a single-mode optical sensor to operate effectively in both marker and markerless modes without the need for additional hardware, making it well-suited for both perception and manipulation tasks. Extensive experiments validate the effectiveness of our method. For perception tasks, our approach decreases the number of categories that include misclassified samples by 2 and improves contact area segmentation IoU by 3.53%. For manipulation tasks, our method attains a high success rate of 92.59% in slip detection. Code, dataset and demo videos are available at the project website: https://gitouni.github.io/Marker-Markerless-Transition/","sentences":["Optical tactile sensors play a pivotal role in robot perception and manipulation tasks.","The membrane of these sensors can be painted with markers or remain markerless, enabling them to function in either marker or markerless mode.","However, this uni-modal selection means the sensor is only suitable for either manipulation or perception tasks.","While markers are vital for manipulation, they can also obstruct the camera, thereby impeding perception.","The dilemma of selecting between marker and markerless modes presents a significant obstacle.","To address this issue, we propose a novel mode-switchable optical tactile sensing approach that facilitates transitions between the two modes.","The marker-to-markerless transition is achieved through a generative model, whereas its inverse transition is realized using a sparsely supervised regressive model.","Our approach allows a single-mode optical sensor to operate effectively in both marker and markerless modes without the need for additional hardware, making it well-suited for both perception and manipulation tasks.","Extensive experiments validate the effectiveness of our method.","For perception tasks, our approach decreases the number of categories that include misclassified samples by 2 and improves contact area segmentation IoU by 3.53%.","For manipulation tasks, our method attains a high success rate of 92.59% in slip detection.","Code, dataset and demo videos are available at the project website: https://gitouni.github.io/Marker-Markerless-Transition/"],"url":"http://arxiv.org/abs/2408.08276v1"}
{"created":"2024-08-15 17:19:12","title":"BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts","abstract":"The Mixture of Experts (MoE) framework has become a popular architecture for large language models due to its superior performance over dense models. However, training MoEs from scratch in a large-scale regime is prohibitively expensive. Existing methods mitigate this by pre-training multiple dense expert models independently and using them to initialize an MoE. This is done by using experts' feed-forward network (FFN) to initialize the MoE's experts while merging other parameters. However, this method limits the reuse of dense model parameters to only the FFN layers, thereby constraining the advantages when \"upcycling\" these models into MoEs. We propose BAM (Branch-Attend-Mix), a simple yet effective method that addresses this shortcoming. BAM makes full use of specialized dense models by not only using their FFN to initialize the MoE layers but also leveraging experts' attention parameters fully by initializing them into a soft-variant of Mixture of Attention (MoA) layers. We explore two methods for upcycling attention parameters: 1) initializing separate attention experts from dense models including all attention parameters for the best model performance; and 2) sharing key and value parameters across all experts to facilitate for better inference efficiency. To further improve efficiency, we adopt a parallel attention transformer architecture to MoEs, which allows the attention experts and FFN experts to be computed concurrently. Our experiments on seed models ranging from 590 million to 2 billion parameters demonstrate that BAM surpasses baselines in both perplexity and downstream task performance, within the same computational and data constraints.","sentences":["The Mixture of Experts (MoE) framework has become a popular architecture for large language models due to its superior performance over dense models.","However, training MoEs from scratch in a large-scale regime is prohibitively expensive.","Existing methods mitigate this by pre-training multiple dense expert models independently and using them to initialize an MoE. This is done by using experts' feed-forward network (FFN) to initialize the MoE's experts while merging other parameters.","However, this method limits the reuse of dense model parameters to only the FFN layers, thereby constraining the advantages when \"upcycling\" these models into MoEs.","We propose BAM (Branch-Attend-Mix), a simple yet effective method that addresses this shortcoming.","BAM makes full use of specialized dense models by not only using their FFN to initialize the MoE layers but also leveraging experts' attention parameters fully by initializing them into a soft-variant of Mixture of Attention (MoA) layers.","We explore two methods for upcycling attention parameters: 1) initializing separate attention experts from dense models including all attention parameters for the best model performance; and 2) sharing key and value parameters across all experts to facilitate for better inference efficiency.","To further improve efficiency, we adopt a parallel attention transformer architecture to MoEs, which allows the attention experts and FFN experts to be computed concurrently.","Our experiments on seed models ranging from 590 million to 2 billion parameters demonstrate that BAM surpasses baselines in both perplexity and downstream task performance, within the same computational and data constraints."],"url":"http://arxiv.org/abs/2408.08274v1"}
{"created":"2024-08-15 17:18:33","title":"ESCape the ClassRoom","abstract":"Educational Escape Rooms (EER's), through their use of immersive storytelling and practical application of abstract concepts, present a novel new technique for engaging learners in a variety of subjects. However, there is a significant time and materials investment required to build new physical Escape Rooms, and prior attempts to create digital escape rooms have resulted in games that lack the immersive qualities that make physical escape rooms so compelling. This paper presents ESCape the Classroom, a web framework for creating virtual reality educational escape rooms (VR EERs) that can be delivered to any web-connected device. The framework is equipped with essential tools to design and deploy intricate, multi-room VR escape experiences using HTML and Web-Components. It is designed to be used by educators with rudimentary programming skills, eliminating the need for advanced game programming or development expertise. VR EERs created with this platform can be published online as WebXR sites that are compatible with a broad spectrum of VR hardware, including the Meta Quest 3, allowing educators to share the experiences they create while bypassing the need for additional software installations on devices. This paper will present the design and implementation of ESCape the Classroom, and discuss the potential for this platform to be used in educational settings.","sentences":["Educational Escape Rooms (EER's), through their use of immersive storytelling and practical application of abstract concepts, present a novel new technique for engaging learners in a variety of subjects.","However, there is a significant time and materials investment required to build new physical Escape Rooms, and prior attempts to create digital escape rooms have resulted in games that lack the immersive qualities that make physical escape rooms so compelling.","This paper presents ESCape the Classroom, a web framework for creating virtual reality educational escape rooms (VR EERs) that can be delivered to any web-connected device.","The framework is equipped with essential tools to design and deploy intricate, multi-room VR escape experiences using HTML and Web-Components.","It is designed to be used by educators with rudimentary programming skills, eliminating the need for advanced game programming or development expertise.","VR EERs created with this platform can be published online as WebXR sites that are compatible with a broad spectrum of VR hardware, including the Meta Quest 3, allowing educators to share the experiences they create while bypassing the need for additional software installations on devices.","This paper will present the design and implementation of ESCape the Classroom, and discuss the potential for this platform to be used in educational settings."],"url":"http://arxiv.org/abs/2408.08273v1"}
{"created":"2024-08-15 17:17:56","title":"Is Knowledge Power? On the (Im)possibility of Learning from Strategic Interaction","abstract":"When learning in strategic environments, a key question is whether agents can overcome uncertainty about their preferences to achieve outcomes they could have achieved absent any uncertainty. Can they do this solely through interactions with each other? We focus this question on the ability of agents to attain the value of their Stackelberg optimal strategy and study the impact of information asymmetry. We study repeated interactions in fully strategic environments where players' actions are decided based on learning algorithms that take into account their observed histories and knowledge of the game. We study the pure Nash equilibria (PNE) of a meta-game where players choose these algorithms as their actions. We demonstrate that if one player has perfect knowledge about the game, then any initial informational gap persists. That is, while there is always a PNE in which the informed agent achieves her Stackelberg value, there is a game where no PNE of the meta-game allows the partially informed player to achieve her Stackelberg value. On the other hand, if both players start with some uncertainty about the game, the quality of information alone does not determine which agent can achieve her Stackelberg value. In this case, the concept of information asymmetry becomes nuanced and depends on the game's structure. Overall, our findings suggest that repeated strategic interactions alone cannot facilitate learning effectively enough to earn an uninformed player her Stackelberg value.","sentences":["When learning in strategic environments, a key question is whether agents can overcome uncertainty about their preferences to achieve outcomes they could have achieved absent any uncertainty.","Can they do this solely through interactions with each other?","We focus this question on the ability of agents to attain the value of their Stackelberg optimal strategy and study the impact of information asymmetry.","We study repeated interactions in fully strategic environments where players' actions are decided based on learning algorithms that take into account their observed histories and knowledge of the game.","We study the pure Nash equilibria (PNE) of a meta-game where players choose these algorithms as their actions.","We demonstrate that if one player has perfect knowledge about the game, then any initial informational gap persists.","That is, while there is always a PNE in which the informed agent achieves her Stackelberg value, there is a game where no PNE of the meta-game allows the partially informed player to achieve her Stackelberg value.","On the other hand, if both players start with some uncertainty about the game, the quality of information alone does not determine which agent can achieve her Stackelberg value.","In this case, the concept of information asymmetry becomes nuanced and depends on the game's structure.","Overall, our findings suggest that repeated strategic interactions alone cannot facilitate learning effectively enough to earn an uninformed player her Stackelberg value."],"url":"http://arxiv.org/abs/2408.08272v1"}
{"created":"2024-08-15 17:14:57","title":"HeightLane: BEV Heightmap guided 3D Lane Detection","abstract":"Accurate 3D lane detection from monocular images presents significant challenges due to depth ambiguity and imperfect ground modeling. Previous attempts to model the ground have often used a planar ground assumption with limited degrees of freedom, making them unsuitable for complex road environments with varying slopes. Our study introduces HeightLane, an innovative method that predicts a height map from monocular images by creating anchors based on a multi-slope assumption. This approach provides a detailed and accurate representation of the ground. HeightLane employs the predicted heightmap along with a deformable attention-based spatial feature transform framework to efficiently convert 2D image features into 3D bird's eye view (BEV) features, enhancing spatial understanding and lane structure recognition. Additionally, the heightmap is used for the positional encoding of BEV features, further improving their spatial accuracy. This explicit view transformation bridges the gap between front-view perceptions and spatially accurate BEV representations, significantly improving detection performance. To address the lack of the necessary ground truth (GT) height map in the original OpenLane dataset, we leverage the Waymo dataset and accumulate its LiDAR data to generate a height map for the drivable area of each scene. The GT heightmaps are used to train the heightmap extraction module from monocular images. Extensive experiments on the OpenLane validation set show that HeightLane achieves state-of-the-art performance in terms of F-score, highlighting its potential in real-world applications.","sentences":["Accurate 3D lane detection from monocular images presents significant challenges due to depth ambiguity and imperfect ground modeling.","Previous attempts to model the ground have often used a planar ground assumption with limited degrees of freedom, making them unsuitable for complex road environments with varying slopes.","Our study introduces HeightLane, an innovative method that predicts a height map from monocular images by creating anchors based on a multi-slope assumption.","This approach provides a detailed and accurate representation of the ground.","HeightLane employs the predicted heightmap along with a deformable attention-based spatial feature transform framework to efficiently convert 2D image features into 3D bird's eye view (BEV) features, enhancing spatial understanding and lane structure recognition.","Additionally, the heightmap is used for the positional encoding of BEV features, further improving their spatial accuracy.","This explicit view transformation bridges the gap between front-view perceptions and spatially accurate BEV representations, significantly improving detection performance.","To address the lack of the necessary ground truth (GT) height map in the original OpenLane dataset, we leverage the Waymo dataset and accumulate its LiDAR data to generate a height map for the drivable area of each scene.","The GT heightmaps are used to train the heightmap extraction module from monocular images.","Extensive experiments on the OpenLane validation set show that HeightLane achieves state-of-the-art performance in terms of F-score, highlighting its potential in real-world applications."],"url":"http://arxiv.org/abs/2408.08270v1"}
{"created":"2024-08-15 17:01:57","title":"mhGPT: A Lightweight Generative Pre-Trained Transformer for Mental Health Text Analysis","abstract":"This paper introduces mhGPT, a lightweight generative pre-trained transformer trained on mental health-related social media and PubMed articles. Fine-tuned for specific mental health tasks, mhGPT was evaluated under limited hardware constraints and compared with state-of-the-art models like MentaLLaMA and Gemma. Despite having only 1.98 billion parameters and using just 5% of the dataset, mhGPT outperformed larger models and matched the performance of models trained on significantly more data. The key contributions include integrating diverse mental health data, creating a custom tokenizer, and optimizing a smaller architecture for low-resource settings. This research could advance AI-driven mental health care, especially in areas with limited computing power.","sentences":["This paper introduces mhGPT, a lightweight generative pre-trained transformer trained on mental health-related social media and PubMed articles.","Fine-tuned for specific mental health tasks, mhGPT was evaluated under limited hardware constraints and compared with state-of-the-art models like MentaLLaMA and Gemma.","Despite having only 1.98 billion parameters and using just 5% of the dataset, mhGPT outperformed larger models and matched the performance of models trained on significantly more data.","The key contributions include integrating diverse mental health data, creating a custom tokenizer, and optimizing a smaller architecture for low-resource settings.","This research could advance AI-driven mental health care, especially in areas with limited computing power."],"url":"http://arxiv.org/abs/2408.08261v1"}
{"created":"2024-08-15 17:01:00","title":"GSVD-NMF: Recovering Missing Features in Non-negative Matrix Factorization","abstract":"Non-negative matrix factorization (NMF) is an important tool in signal processing and widely used to separate mixed sources into their components. However, NMF is NP-hard and thus may fail to discover the ideal factorization; moreover, the number of components may not be known in advance and thus features may be missed or incompletely separated. To recover missing components from under-complete NMF, we introduce GSVD-NMF, which proposes new components based on the generalized singular value decomposition (GSVD) between preliminary NMF results and the SVD of the original matrix. Simulation and experimental results demonstrate that GSVD-NMF often recovers missing features from under-complete NMF and helps NMF achieve better local optima.","sentences":["Non-negative matrix factorization (NMF) is an important tool in signal processing and widely used to separate mixed sources into their components.","However, NMF is NP-hard and thus may fail to discover the ideal factorization; moreover, the number of components may not be known in advance and thus features may be missed or incompletely separated.","To recover missing components from under-complete NMF, we introduce GSVD-NMF, which proposes new components based on the generalized singular value decomposition (GSVD) between preliminary NMF results and the SVD of the original matrix.","Simulation and experimental results demonstrate that GSVD-NMF often recovers missing features from under-complete NMF and helps NMF achieve better local optima."],"url":"http://arxiv.org/abs/2408.08260v1"}
{"created":"2024-08-15 16:59:15","title":"Snuffy: Efficient Whole Slide Image Classifier","abstract":"Whole Slide Image (WSI) classification with multiple instance learning (MIL) in digital pathology faces significant computational challenges. Current methods mostly rely on extensive self-supervised learning (SSL) for satisfactory performance, requiring long training periods and considerable computational resources. At the same time, no pre-training affects performance due to domain shifts from natural images to WSIs. We introduce \\textbf{\\textit{Snuffy}} architecture, a novel MIL-pooling method based on sparse transformers that mitigates performance loss with limited pre-training and enables continual few-shot pre-training as a competitive option. Our sparsity pattern is tailored for pathology and is theoretically proven to be a universal approximator with the tightest probabilistic sharp bound on the number of layers for sparse transformers, to date. We demonstrate Snuffy's effectiveness on CAMELYON16 and TCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies. The code is available on \\url{https://github.com/jafarinia/snuffy}.","sentences":["Whole Slide Image (WSI) classification with multiple instance learning (MIL) in digital pathology faces significant computational challenges.","Current methods mostly rely on extensive self-supervised learning (SSL) for satisfactory performance, requiring long training periods and considerable computational resources.","At the same time, no pre-training affects performance due to domain shifts from natural images to WSIs.","We introduce \\textbf{\\textit{Snuffy}} architecture, a novel MIL-pooling method based on sparse transformers that mitigates performance loss with limited pre-training and enables continual few-shot pre-training as a competitive option.","Our sparsity pattern is tailored for pathology and is theoretically proven to be a universal approximator with the tightest probabilistic sharp bound on the number of layers for sparse transformers, to date.","We demonstrate Snuffy's effectiveness on CAMELYON16 and TCGA Lung cancer datasets, achieving superior WSI and patch-level accuracies.","The code is available on \\url{https://github.com/jafarinia/snuffy}."],"url":"http://arxiv.org/abs/2408.08258v1"}
{"created":"2024-08-15 16:55:15","title":"Palette Sparsification for Graphs with Sparse Neighborhoods","abstract":"A celebrated palette sparsification result of Assadi, Chen, and Khanna states that in every $n$-vertex graph of maximum degree $\\Delta$, sampling $\\Theta(\\log n)$ colors per vertex from $\\{1,\\ldots,\\Delta+1\\}$ almost certainly allows for a proper coloring from the sampled colors. Alon and Assadi extended this work proving a similar result for $O(\\Delta/\\log \\Delta)$-coloring triangle-free graphs. Apart from being interesting results from a combinatorial standpoint, their results have various applications to the design of graph coloring algorithms in different models of computation.   In this work, we focus on graphs with sparse neighborhoods. We say a graph $G = (V,E)$ is $k$-locally-sparse if for each vertex $v \\in V$, the subgraph $G[N(v)]$ contains at most $k$ edges. A celebrated result of Alon, Krivelevich, and Sudakov shows that such graphs are $O(\\Delta/\\log (\\Delta/\\sqrt{k}))$-colorable. For any $\\alpha\\in(0,1)$ and $k\\ll\\Delta^{2\\alpha}$, let $G$ be a $k$-locally-sparse graph. We show the following for $q=\\Theta\\left(\\Delta/\\log\\left(\\Delta^\\alpha/\\sqrt{k}\\right)\\right)$:   1. Sampling $O(\\Delta^\\alpha+\\sqrt{\\log n})$ colors per vertex is sufficient to obtain a proper $q$-coloring of $G$ from the sampled colors.   2. There exists a single-pass streaming algorithm which computes a proper $q$-coloring of $G$ with high probability using $\\tilde O(n\\Delta^{2\\alpha})$ space.   3. There exists a randomized non-adaptive sublinear-time algorithm which computes a proper $q$-coloring of $G$ with high probability using at most $\\tilde O\\left(n^{\\frac32+\\frac{\\alpha}{2-2\\alpha}}\\right)$ queries.   Our results recover and improve upon earlier work of Alon and Assadi. A key element in our proof is a proposition regarding correspondence coloring in the so-called color-degree setting, which improves upon recent work of Anderson, Kuchukova, and the author and is of independent interest.","sentences":["A celebrated palette sparsification result of Assadi, Chen, and Khanna states that in every $n$-vertex graph of maximum degree $\\Delta$, sampling $\\Theta(\\log n)$ colors per vertex from $\\{1,\\ldots,\\Delta+1\\}$ almost certainly allows for a proper coloring from the sampled colors.","Alon and Assadi extended this work proving a similar result for $O(\\Delta/\\log \\Delta)$-coloring triangle-free graphs.","Apart from being interesting results from a combinatorial standpoint, their results have various applications to the design of graph coloring algorithms in different models of computation.   ","In this work, we focus on graphs with sparse neighborhoods.","We say a graph $G = (V,E)$ is $k$-locally-sparse if for each vertex $v \\in V$, the subgraph $G[N(v)]$ contains at most $k$ edges.","A celebrated result of Alon, Krivelevich, and Sudakov shows that such graphs are $O(\\Delta/\\log (\\Delta/\\sqrt{k}))$-colorable.","For any $\\alpha\\in(0,1)$ and $k\\ll\\Delta^{2\\alpha}$, let $G$ be a $k$-locally-sparse graph.","We show the following for $q=\\Theta\\left(\\Delta/\\log\\left(\\Delta^\\alpha/\\sqrt{k}\\right)\\right)$:   1.","Sampling $O(\\Delta^\\alpha+\\sqrt{\\log n})$ colors per vertex is sufficient to obtain a proper $q$-coloring of $G$ from the sampled colors.   ","2.","There exists a single-pass streaming algorithm which computes a proper $q$-coloring of $G$ with high probability using $\\tilde O(n\\Delta^{2\\alpha})$ space.   ","3.","There exists a randomized non-adaptive sublinear-time algorithm which computes a proper $q$-coloring of $G$ with high probability using at most $\\tilde O\\left(n^{\\frac32+\\frac{\\alpha}{2-2\\alpha}}\\right)$ queries.   ","Our results recover and improve upon earlier work of Alon and Assadi.","A key element in our proof is a proposition regarding correspondence coloring in the so-called color-degree setting, which improves upon recent work of Anderson, Kuchukova, and the author and is of independent interest."],"url":"http://arxiv.org/abs/2408.08256v1"}
{"created":"2024-08-15 16:47:59","title":"Derivative-Free Guidance in Continuous and Discrete Diffusion Models with Soft Value-Based Decoding","abstract":"Diffusion models excel at capturing the natural design spaces of images, molecules, DNA, RNA, and protein sequences. However, rather than merely generating designs that are natural, we often aim to optimize downstream reward functions while preserving the naturalness of these design spaces. Existing methods for achieving this goal often require ``differentiable'' proxy models (\\textit{e.g.}, classifier guidance or DPS) or involve computationally expensive fine-tuning of diffusion models (\\textit{e.g.}, classifier-free guidance, RL-based fine-tuning). In our work, we propose a new method to address these challenges. Our algorithm is an iterative sampling method that integrates soft value functions, which looks ahead to how intermediate noisy states lead to high rewards in the future, into the standard inference procedure of pre-trained diffusion models. Notably, our approach avoids fine-tuning generative models and eliminates the need to construct differentiable models. This enables us to (1) directly utilize non-differentiable features/reward feedback, commonly used in many scientific domains, and (2) apply our method to recent discrete diffusion models in a principled way. Finally, we demonstrate the effectiveness of our algorithm across several domains, including image generation, molecule generation, and DNA/RNA sequence generation. The code is available at \\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}.","sentences":["Diffusion models excel at capturing the natural design spaces of images, molecules, DNA, RNA, and protein sequences.","However, rather than merely generating designs that are natural, we often aim to optimize downstream reward functions while preserving the naturalness of these design spaces.","Existing methods for achieving this goal often require ``differentiable'' proxy models (\\textit{e.g.}, classifier guidance or DPS) or involve computationally expensive fine-tuning of diffusion models (\\textit{e.g.}, classifier-free guidance, RL-based fine-tuning).","In our work, we propose a new method to address these challenges.","Our algorithm is an iterative sampling method that integrates soft value functions, which looks ahead to how intermediate noisy states lead to high rewards in the future, into the standard inference procedure of pre-trained diffusion models.","Notably, our approach avoids fine-tuning generative models and eliminates the need to construct differentiable models.","This enables us to (1) directly utilize non-differentiable features/reward feedback, commonly used in many scientific domains, and (2) apply our method to recent discrete diffusion models in a principled way.","Finally, we demonstrate the effectiveness of our algorithm across several domains, including image generation, molecule generation, and DNA/RNA sequence generation.","The code is available at \\href{https://github.com/masa-ue/SVDD}{https://github.com/masa-ue/SVDD}."],"url":"http://arxiv.org/abs/2408.08252v1"}
{"created":"2024-08-15 16:41:55","title":"Computer Vision Model Compression Techniques for Embedded Systems: A Survey","abstract":"Deep neural networks have consistently represented the state of the art in most computer vision problems. In these scenarios, larger and more complex models have demonstrated superior performance to smaller architectures, especially when trained with plenty of representative data. With the recent adoption of Vision Transformer (ViT) based architectures and advanced Convolutional Neural Networks (CNNs), the total number of parameters of leading backbone architectures increased from 62M parameters in 2012 with AlexNet to 7B parameters in 2024 with AIM-7B. Consequently, deploying such deep architectures faces challenges in environments with processing and runtime constraints, particularly in embedded systems. This paper covers the main model compression techniques applied for computer vision tasks, enabling modern models to be used in embedded systems. We present the characteristics of compression subareas, compare different approaches, and discuss how to choose the best technique and expected variations when analyzing it on various embedded devices. We also share codes to assist researchers and new practitioners in overcoming initial implementation challenges for each subarea and present trends for Model Compression. Case studies for compression models are available at \\href{https://github.com/venturusbr/cv-model-compression}{https://github.com/venturusbr/cv-model-compression}.","sentences":["Deep neural networks have consistently represented the state of the art in most computer vision problems.","In these scenarios, larger and more complex models have demonstrated superior performance to smaller architectures, especially when trained with plenty of representative data.","With the recent adoption of Vision Transformer (ViT) based architectures and advanced Convolutional Neural Networks (CNNs), the total number of parameters of leading backbone architectures increased from 62M parameters in 2012 with AlexNet to 7B parameters in 2024 with AIM-7B. Consequently, deploying such deep architectures faces challenges in environments with processing and runtime constraints, particularly in embedded systems.","This paper covers the main model compression techniques applied for computer vision tasks, enabling modern models to be used in embedded systems.","We present the characteristics of compression subareas, compare different approaches, and discuss how to choose the best technique and expected variations when analyzing it on various embedded devices.","We also share codes to assist researchers and new practitioners in overcoming initial implementation challenges for each subarea and present trends for Model Compression.","Case studies for compression models are available at \\href{https://github.com/venturusbr/cv-model-compression}{https://github.com/venturusbr/cv-model-compression}."],"url":"http://arxiv.org/abs/2408.08250v1"}
{"created":"2024-08-15 16:36:59","title":"Conformalized Answer Set Prediction for Knowledge Graph Embedding","abstract":"Knowledge graph embeddings (KGE) apply machine learning methods on knowledge graphs (KGs) to provide non-classical reasoning capabilities based on similarities and analogies. The learned KG embeddings are typically used to answer queries by ranking all potential answers, but rankings often lack a meaningful probabilistic interpretation - lower-ranked answers do not necessarily have a lower probability of being true. This limitation makes it difficult to distinguish plausible from implausible answers, posing challenges for the application of KGE methods in high-stakes domains like medicine. We address this issue by applying the theory of conformal prediction that allows generating answer sets, which contain the correct answer with probabilistic guarantees. We explain how conformal prediction can be used to generate such answer sets for link prediction tasks. Our empirical evaluation on four benchmark datasets using six representative KGE methods validates that the generated answer sets satisfy the probabilistic guarantees given by the theory of conformal prediction. We also demonstrate that the generated answer sets often have a sensible size and that the size adapts well with respect to the difficulty of the query.","sentences":["Knowledge graph embeddings (KGE) apply machine learning methods on knowledge graphs (KGs) to provide non-classical reasoning capabilities based on similarities and analogies.","The learned KG embeddings are typically used to answer queries by ranking all potential answers, but rankings often lack a meaningful probabilistic interpretation - lower-ranked answers do not necessarily have a lower probability of being true.","This limitation makes it difficult to distinguish plausible from implausible answers, posing challenges for the application of KGE methods in high-stakes domains like medicine.","We address this issue by applying the theory of conformal prediction that allows generating answer sets, which contain the correct answer with probabilistic guarantees.","We explain how conformal prediction can be used to generate such answer sets for link prediction tasks.","Our empirical evaluation on four benchmark datasets using six representative KGE methods validates that the generated answer sets satisfy the probabilistic guarantees given by the theory of conformal prediction.","We also demonstrate that the generated answer sets often have a sensible size and that the size adapts well with respect to the difficulty of the query."],"url":"http://arxiv.org/abs/2408.08248v1"}
{"created":"2024-08-15 16:10:25","title":"A Conflicts-free, Speed-lossless KAN-based Reinforcement Learning Decision System for Interactive Driving in Roundabouts","abstract":"Safety and efficiency are crucial for autonomous driving in roundabouts, especially in the context of mixed traffic where autonomous vehicles (AVs) and human-driven vehicles coexist. This paper introduces a learning-based algorithm tailored to foster safe and efficient driving behaviors across varying levels of traffic flows in roundabouts. The proposed algorithm employs a deep Q-learning network to effectively learn safe and efficient driving strategies in complex multi-vehicle roundabouts. Additionally, a KAN (Kolmogorov-Arnold network) enhances the AVs' ability to learn their surroundings robustly and precisely. An action inspector is integrated to replace dangerous actions to avoid collisions when the AV interacts with the environment, and a route planner is proposed to enhance the driving efficiency and safety of the AVs. Moreover, a model predictive control is adopted to ensure stability and precision of the driving actions. The results show that our proposed system consistently achieves safe and efficient driving whilst maintaining a stable training process, as evidenced by the smooth convergence of the reward function and the low variance in the training curves across various traffic flows. Compared to state-of-the-art benchmarks, the proposed algorithm achieves a lower number of collisions and reduced travel time to destination.","sentences":["Safety and efficiency are crucial for autonomous driving in roundabouts, especially in the context of mixed traffic where autonomous vehicles (AVs) and human-driven vehicles coexist.","This paper introduces a learning-based algorithm tailored to foster safe and efficient driving behaviors across varying levels of traffic flows in roundabouts.","The proposed algorithm employs a deep Q-learning network to effectively learn safe and efficient driving strategies in complex multi-vehicle roundabouts.","Additionally, a KAN (Kolmogorov-Arnold network) enhances the AVs' ability to learn their surroundings robustly and precisely.","An action inspector is integrated to replace dangerous actions to avoid collisions when the AV interacts with the environment, and a route planner is proposed to enhance the driving efficiency and safety of the AVs.","Moreover, a model predictive control is adopted to ensure stability and precision of the driving actions.","The results show that our proposed system consistently achieves safe and efficient driving whilst maintaining a stable training process, as evidenced by the smooth convergence of the reward function and the low variance in the training curves across various traffic flows.","Compared to state-of-the-art benchmarks, the proposed algorithm achieves a lower number of collisions and reduced travel time to destination."],"url":"http://arxiv.org/abs/2408.08242v1"}
{"created":"2024-08-15 16:06:44","title":"Strong Data Processing Inequalities and their Applications to Reliable Computation","abstract":"In 1952, von Neumann gave a series of groundbreaking lectures that proved it was possible for circuits consisting of 3-input majority gates that have a sufficiently small independent probability $\\delta > 0$ of malfunctioning to reliably compute Boolean functions. In 1999, Evans and Schulman used a strong data-processing inequality (SDPI) to establish the tightest known necessary condition $\\delta < \\frac{1}{2} - \\frac{1}{2\\sqrt{k}}$ for reliable computation when the circuit consists of components that have at most $k$ inputs. In 2017, Polyanskiy and Wu distilled Evans and Schulman's SDPI argument to establish a general result on the contraction of mutual information in Bayesian networks.   In this essay, we will first introduce the problem of reliable computation from unreliable components and establish the existence of noise thresholds. We will then provide an exposition of von Neumann's result with 3-input majority gates and extend it to minority gates. We will then provide an introduction to SDPIs, which have many applications, including in statistical mechanics, portfolio theory, and lower bounds on statistical estimation under privacy constraints. We will then use the introduced material to provide an exposition of Polyanskiy and Wu's 2017 result on Bayesian networks, from which the 1999 result of Evans-Schulman follows.","sentences":["In 1952, von Neumann gave a series of groundbreaking lectures that proved it was possible for circuits consisting of 3-input majority gates that have a sufficiently small independent probability $\\delta > 0$ of malfunctioning to reliably compute Boolean functions.","In 1999, Evans and Schulman used a strong data-processing inequality (SDPI) to establish the tightest known necessary condition $\\delta < \\frac{1}{2} - \\frac{1}{2\\sqrt{k}}$ for reliable computation when the circuit consists of components that have at most $k$ inputs.","In 2017, Polyanskiy and Wu distilled Evans and Schulman's SDPI argument to establish a general result on the contraction of mutual information in Bayesian networks.   ","In this essay, we will first introduce the problem of reliable computation from unreliable components and establish the existence of noise thresholds.","We will then provide an exposition of von Neumann's result with 3-input majority gates and extend it to minority gates.","We will then provide an introduction to SDPIs, which have many applications, including in statistical mechanics, portfolio theory, and lower bounds on statistical estimation under privacy constraints.","We will then use the introduced material to provide an exposition of Polyanskiy and Wu's 2017 result on Bayesian networks, from which the 1999 result of Evans-Schulman follows."],"url":"http://arxiv.org/abs/2408.08239v1"}
{"created":"2024-08-15 16:01:48","title":"Derivatives on Graphs for the Positive Calculus of Relations with Transitive Closure","abstract":"We prove that the equational theory of the positive calculus of relations with transitive closure (PCoR*) is EXPSPACE-complete. PCoR* terms consist of the following standard operators on binary relations: identity, empty, universality, union, intersection, composition, converse, and reflexive-transitive closure (so, PCoR* terms subsume Kleene algebra terms and allegory terms as fragments). Additionally, we show that the equational theory of PCoR* extended with tests and nominals (in hybrid logic) is still EXPSPACE-complete; moreover, it is PSPACE-complete for its intersection-free fragment.","sentences":["We prove that the equational theory of the positive calculus of relations with transitive closure (PCoR*) is EXPSPACE-complete.","PCoR* terms consist of the following standard operators on binary relations: identity, empty, universality, union, intersection, composition, converse, and reflexive-transitive closure (so, PCoR* terms subsume Kleene algebra terms and allegory terms as fragments).","Additionally, we show that the equational theory of PCoR* extended with tests and nominals (in hybrid logic) is still EXPSPACE-complete; moreover, it is PSPACE-complete for its intersection-free fragment."],"url":"http://arxiv.org/abs/2408.08236v1"}
{"created":"2024-08-15 15:58:11","title":"Comparative Evaluation of 3D Reconstruction Methods for Object Pose Estimation","abstract":"Object pose estimation is essential to many industrial applications involving robotic manipulation, navigation, and augmented reality. Current generalizable object pose estimators, i.e., approaches that do not need to be trained per object, rely on accurate 3D models. Predominantly, CAD models are used, which can be hard to obtain in practice. At the same time, it is often possible to acquire images of an object. Naturally, this leads to the question whether 3D models reconstructed from images are sufficient to facilitate accurate object pose estimation. We aim to answer this question by proposing a novel benchmark for measuring the impact of 3D reconstruction quality on pose estimation accuracy. Our benchmark provides calibrated images for object reconstruction registered with the test images of the YCB-V dataset for pose evaluation under the BOP benchmark format. Detailed experiments with multiple state-of-the-art 3D reconstruction and object pose estimation approaches show that the geometry produced by modern reconstruction methods is often sufficient for accurate pose estimation. Our experiments lead to interesting observations: (1) Standard metrics for measuring 3D reconstruction quality are not necessarily indicative of pose estimation accuracy, which shows the need for dedicated benchmarks such as ours. (2) Classical, non-learning-based approaches can perform on par with modern learning-based reconstruction techniques and can even offer a better reconstruction time-pose accuracy tradeoff. (3) There is still a sizable gap between performance with reconstructed and with CAD models. To foster research on closing this gap, our benchmark is publicly available at https://github.com/VarunBurde/reconstruction_pose_benchmark}.","sentences":["Object pose estimation is essential to many industrial applications involving robotic manipulation, navigation, and augmented reality.","Current generalizable object pose estimators, i.e., approaches that do not need to be trained per object, rely on accurate 3D models.","Predominantly, CAD models are used, which can be hard to obtain in practice.","At the same time, it is often possible to acquire images of an object.","Naturally, this leads to the question whether 3D models reconstructed from images are sufficient to facilitate accurate object pose estimation.","We aim to answer this question by proposing a novel benchmark for measuring the impact of 3D reconstruction quality on pose estimation accuracy.","Our benchmark provides calibrated images for object reconstruction registered with the test images of the YCB-V dataset for pose evaluation under the BOP benchmark format.","Detailed experiments with multiple state-of-the-art 3D reconstruction and object pose estimation approaches show that the geometry produced by modern reconstruction methods is often sufficient for accurate pose estimation.","Our experiments lead to interesting observations: (1) Standard metrics for measuring 3D reconstruction quality are not necessarily indicative of pose estimation accuracy, which shows the need for dedicated benchmarks such as ours.","(2) Classical, non-learning-based approaches can perform on par with modern learning-based reconstruction techniques and can even offer a better reconstruction time-pose accuracy tradeoff.","(3) There is still a sizable gap between performance with reconstructed and with CAD models.","To foster research on closing this gap, our benchmark is publicly available at https://github.com/VarunBurde/reconstruction_pose_benchmark}."],"url":"http://arxiv.org/abs/2408.08234v1"}
{"created":"2024-08-15 15:56:23","title":"DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System","abstract":"Benefiting from the strong reasoning capabilities, Large language models (LLMs) have demonstrated remarkable performance in recommender systems. Various efforts have been made to distill knowledge from LLMs to enhance collaborative models, employing techniques like contrastive learning for representation alignment. In this work, we prove that directly aligning the representations of LLMs and collaborative models is sub-optimal for enhancing downstream recommendation tasks performance, based on the information theorem. Consequently, the challenge of effectively aligning semantic representations between collaborative models and LLMs remains unresolved. Inspired by this viewpoint, we propose a novel plug-and-play alignment framework for LLMs and collaborative models. Specifically, we first disentangle the latent representations of both LLMs and collaborative models into specific and shared components via projection layers and representation regularization. Subsequently, we perform both global and local structure alignment on the shared representations to facilitate knowledge transfer. Additionally, we theoretically prove that the specific and shared representations contain more pertinent and less irrelevant information, which can enhance the effectiveness of downstream recommendation tasks. Extensive experimental results on benchmark datasets demonstrate that our method is superior to existing state-of-the-art algorithms.","sentences":["Benefiting from the strong reasoning capabilities, Large language models (LLMs) have demonstrated remarkable performance in recommender systems.","Various efforts have been made to distill knowledge from LLMs to enhance collaborative models, employing techniques like contrastive learning for representation alignment.","In this work, we prove that directly aligning the representations of LLMs and collaborative models is sub-optimal for enhancing downstream recommendation tasks performance, based on the information theorem.","Consequently, the challenge of effectively aligning semantic representations between collaborative models and LLMs remains unresolved.","Inspired by this viewpoint, we propose a novel plug-and-play alignment framework for LLMs and collaborative models.","Specifically, we first disentangle the latent representations of both LLMs and collaborative models into specific and shared components via projection layers and representation regularization.","Subsequently, we perform both global and local structure alignment on the shared representations to facilitate knowledge transfer.","Additionally, we theoretically prove that the specific and shared representations contain more pertinent and less irrelevant information, which can enhance the effectiveness of downstream recommendation tasks.","Extensive experimental results on benchmark datasets demonstrate that our method is superior to existing state-of-the-art algorithms."],"url":"http://arxiv.org/abs/2408.08231v1"}
{"created":"2024-08-15 15:56:15","title":"Explaining an Agent's Future Beliefs through Temporally Decomposing Future Reward Estimators","abstract":"Future reward estimation is a core component of reinforcement learning agents; i.e., Q-value and state-value functions, predicting an agent's sum of future rewards. Their scalar output, however, obfuscates when or what individual future rewards an agent may expect to receive. We address this by modifying an agent's future reward estimator to predict their next N expected rewards, referred to as Temporal Reward Decomposition (TRD). This unlocks novel explanations of agent behaviour. Through TRD we can: estimate when an agent may expect to receive a reward, the value of the reward and the agent's confidence in receiving it; measure an input feature's temporal importance to the agent's action decisions; and predict the influence of different actions on future rewards. Furthermore, we show that DQN agents trained on Atari environments can be efficiently retrained to incorporate TRD with minimal impact on performance.","sentences":["Future reward estimation is a core component of reinforcement learning agents; i.e., Q-value and state-value functions, predicting an agent's sum of future rewards.","Their scalar output, however, obfuscates when or what individual future rewards an agent may expect to receive.","We address this by modifying an agent's future reward estimator to predict their next N expected rewards, referred to as Temporal Reward Decomposition (TRD).","This unlocks novel explanations of agent behaviour.","Through TRD we can: estimate when an agent may expect to receive a reward, the value of the reward and the agent's confidence in receiving it; measure an input feature's temporal importance to the agent's action decisions; and predict the influence of different actions on future rewards.","Furthermore, we show that DQN agents trained on Atari environments can be efficiently retrained to incorporate TRD with minimal impact on performance."],"url":"http://arxiv.org/abs/2408.08230v1"}
{"created":"2024-08-15 15:54:25","title":"Evolving A* to Efficiently Solve the k Shortest-Path Problem (Extended Version)","abstract":"The problem of finding the shortest path in a graph G(V, E) has been widely studied. However, in many applications it is necessary to compute an arbitrary number of them, k. Even though the problem has raised a lot of interest from different research communities and many applications of it are known, it has not been addressed to the same extent as the single shortest path problem. The best algorithm known for efficiently solving this task has a time complexity of O (|E| + |V|log{|V|}+k|V|)$ when computing paths in explicit form, and is based on best-first search. This paper introduces a new search algorithm with the same time complexity, which results from a natural evolution of A* thus, it preserves all its interesting properties, making it widely applicable to many different domains. Experiments in various testbeds show a significant improvement in performance over the state of the art, often by one or two orders of magnitude.","sentences":["The problem of finding the shortest path in a graph G(V, E) has been widely studied.","However, in many applications it is necessary to compute an arbitrary number of them, k.","Even though the problem has raised a lot of interest from different research communities and many applications of it are known, it has not been addressed to the same extent as the single shortest path problem.","The best algorithm known for efficiently solving this task has a time complexity of O (|E| + |V|log{|V|}+k|V|)$ when computing paths in explicit form, and is based on best-first search.","This paper introduces a new search algorithm with the same time complexity, which results from a natural evolution of A* thus, it preserves all its interesting properties, making it widely applicable to many different domains.","Experiments in various testbeds show a significant improvement in performance over the state of the art, often by one or two orders of magnitude."],"url":"http://arxiv.org/abs/2408.08227v1"}
{"created":"2024-08-15 15:54:02","title":"Predictive Multiplicity of Knowledge Graph Embeddings in Link Prediction","abstract":"Knowledge graph embedding (KGE) models are often used to predict missing links for knowledge graphs (KGs). However, multiple KG embeddings can perform almost equally well for link prediction yet suggest conflicting predictions for certain queries, termed \\textit{predictive multiplicity} in literature. This behavior poses substantial risks for KGE-based applications in high-stake domains but has been overlooked in KGE research. In this paper, we define predictive multiplicity in link prediction. We introduce evaluation metrics and measure predictive multiplicity for representative KGE methods on commonly used benchmark datasets. Our empirical study reveals significant predictive multiplicity in link prediction, with $8\\%$ to $39\\%$ testing queries exhibiting conflicting predictions. To address this issue, we propose leveraging voting methods from social choice theory, significantly mitigating conflicts by $66\\%$ to $78\\%$ according to our experiments.","sentences":["Knowledge graph embedding (KGE) models are often used to predict missing links for knowledge graphs (KGs).","However, multiple KG embeddings can perform almost equally well for link prediction yet suggest conflicting predictions for certain queries, termed \\textit{predictive multiplicity} in literature.","This behavior poses substantial risks for KGE-based applications in high-stake domains but has been overlooked in KGE research.","In this paper, we define predictive multiplicity in link prediction.","We introduce evaluation metrics and measure predictive multiplicity for representative KGE methods on commonly used benchmark datasets.","Our empirical study reveals significant predictive multiplicity in link prediction, with $8\\%$ to $39\\%$ testing queries exhibiting conflicting predictions.","To address this issue, we propose leveraging voting methods from social choice theory, significantly mitigating conflicts by $66\\%$ to $78\\%$ according to our experiments."],"url":"http://arxiv.org/abs/2408.08226v1"}
{"created":"2024-08-15 15:48:25","title":"On the Asymptotic Rate of Optimal Codes that Correct Tandem Duplications for Nanopore Sequencing","abstract":"We study codes that can correct backtracking errors during nanopore sequencing. In this channel, a sequence of length $n$ over an alphabet of size $q$ is being read by a sliding window of length $\\ell$, where from each window we obtain only its composition. Backtracking errors cause some windows to repeat, hence manifesting as tandem-duplication errors of length $k$ in the $\\ell$-read vector of window compositions. While existing constructions for duplication-correcting codes can be straightforwardly adapted to this model, even resulting in optimal codes, their asymptotic rate is hard to find. In the regime of unbounded number of duplication errors, we either give the exact asymptotic rate of optimal codes, or bounds on it, depending on the values of $k$, $\\ell$ and $q$. In the regime of a constant number of duplication errors, $t$, we find the redundancy of optimal codes to be $t\\log_q n+O(1)$ when $\\ell|k$, and only upper bounded by this quantity otherwise.","sentences":["We study codes that can correct backtracking errors during nanopore sequencing.","In this channel, a sequence of length $n$ over an alphabet of size $q$ is being read by a sliding window of length $\\ell$, where from each window we obtain only its composition.","Backtracking errors cause some windows to repeat, hence manifesting as tandem-duplication errors of length $k$ in the $\\ell$-read vector of window compositions.","While existing constructions for duplication-correcting codes can be straightforwardly adapted to this model, even resulting in optimal codes, their asymptotic rate is hard to find.","In the regime of unbounded number of duplication errors, we either give the exact asymptotic rate of optimal codes, or bounds on it, depending on the values of $k$, $\\ell$ and $q$. In the regime of a constant number of duplication errors, $t$, we find the redundancy of optimal codes to be $t\\log_q n+O(1)$ when $\\ell|k$, and only upper bounded by this quantity otherwise."],"url":"http://arxiv.org/abs/2408.08223v1"}
{"created":"2024-08-15 15:40:57","title":"Enhancing Sharpness-Aware Minimization by Learning Perturbation Radius","abstract":"Sharpness-aware minimization (SAM) is to improve model generalization by searching for flat minima in the loss landscape. The SAM update consists of one step for computing the perturbation and the other for computing the update gradient. Within the two steps, the choice of the perturbation radius is crucial to the performance of SAM, but finding an appropriate perturbation radius is challenging. In this paper, we propose a bilevel optimization framework called LEarning the perTurbation radiuS (LETS) to learn the perturbation radius for sharpness-aware minimization algorithms. Specifically, in the proposed LETS method, the upper-level problem aims at seeking a good perturbation radius by minimizing the squared generalization gap between the training and validation losses, while the lower-level problem is the SAM optimization problem. Moreover, the LETS method can be combined with any variant of SAM. Experimental results on various architectures and benchmark datasets in computer vision and natural language processing demonstrate the effectiveness of the proposed LETS method in improving the performance of SAM.","sentences":["Sharpness-aware minimization (SAM) is to improve model generalization by searching for flat minima in the loss landscape.","The SAM update consists of one step for computing the perturbation and the other for computing the update gradient.","Within the two steps, the choice of the perturbation radius is crucial to the performance of SAM, but finding an appropriate perturbation radius is challenging.","In this paper, we propose a bilevel optimization framework called LEarning the perTurbation radiuS (LETS) to learn the perturbation radius for sharpness-aware minimization algorithms.","Specifically, in the proposed LETS method, the upper-level problem aims at seeking a good perturbation radius by minimizing the squared generalization gap between the training and validation losses, while the lower-level problem is the SAM optimization problem.","Moreover, the LETS method can be combined with any variant of SAM.","Experimental results on various architectures and benchmark datasets in computer vision and natural language processing demonstrate the effectiveness of the proposed LETS method in improving the performance of SAM."],"url":"http://arxiv.org/abs/2408.08222v1"}
{"created":"2024-08-15 15:31:32","title":"The Generating Idempotent Is a Minimum-Weight Codeword for Some Binary BCH Codes","abstract":"In a paper from 2015, Ding et al. (IEEE Trans. IT, May 2015) conjectured that for odd $m$, the minimum distance of the binary BCH code of length $2^m-1$ and designed distance $2^{m-2}+1$ is equal to the Bose distance calculated in the same paper.   In this paper, we prove the conjecture. In fact, we prove a stronger result: the weight of the generating idempotent is equal to the Bose distance for both odd and even $m$. Our main tools are some new properties of the so-called fibbinary integers, in particular, the splitting field of related polynomials, and the relation of these polynomials to the idempotent of the BCH code.","sentences":["In a paper from 2015, Ding et al. (IEEE Trans.","IT, May 2015) conjectured that for odd $m$, the minimum distance of the binary BCH code of length $2^m-1$ and designed distance $2^{m-2}+1$ is equal to the Bose distance calculated in the same paper.   ","In this paper, we prove the conjecture.","In fact, we prove a stronger result: the weight of the generating idempotent is equal to the Bose distance for both odd and even $m$. Our main tools are some new properties of the so-called fibbinary integers, in particular, the splitting field of related polynomials, and the relation of these polynomials to the idempotent of the BCH code."],"url":"http://arxiv.org/abs/2408.08218v1"}
{"created":"2024-08-15 15:28:37","title":"RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science","abstract":"Large language models (LLMs) have enhanced our ability to rapidly analyze and classify unstructured natural language data. However, concerns regarding cost, network limitations, and security constraints have posed challenges for their integration into work processes. In this study, we adopt a systems design approach to employing LLMs as imperfect data annotators for downstream supervised learning tasks, introducing novel system intervention measures aimed at improving classification performance. Our methodology outperforms LLM-generated labels in seven of eight tests, demonstrating an effective strategy for incorporating LLMs into the design and deployment of specialized, supervised learning models present in many industry use cases.","sentences":["Large language models (LLMs) have enhanced our ability to rapidly analyze and classify unstructured natural language data.","However, concerns regarding cost, network limitations, and security constraints have posed challenges for their integration into work processes.","In this study, we adopt a systems design approach to employing LLMs as imperfect data annotators for downstream supervised learning tasks, introducing novel system intervention measures aimed at improving classification performance.","Our methodology outperforms LLM-generated labels in seven of eight tests, demonstrating an effective strategy for incorporating LLMs into the design and deployment of specialized, supervised learning models present in many industry use cases."],"url":"http://arxiv.org/abs/2408.08217v1"}
{"created":"2024-08-15 15:26:12","title":"The Dawn of KAN in Image-to-Image (I2I) Translation: Integrating Kolmogorov-Arnold Networks with GANs for Unpaired I2I Translation","abstract":"Image-to-Image translation in Generative Artificial Intelligence (Generative AI) has been a central focus of research, with applications spanning healthcare, remote sensing, physics, chemistry, photography, and more. Among the numerous methodologies, Generative Adversarial Networks (GANs) with contrastive learning have been particularly successful. This study aims to demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace the Multi-layer Perceptron (MLP) method in generative AI, particularly in the subdomain of image-to-image translation, to achieve better generative quality. Our novel approach replaces the two-layer MLP with a two-layer KAN in the existing Contrastive Unpaired Image-to-Image Translation (CUT) model, developing the KAN-CUT model. This substitution favors the generation of more informative features in low-dimensional vector representations, which contrastive learning can utilize more effectively to produce high-quality images in the target domain. Extensive experiments, detailed in the results section, demonstrate the applicability of KAN in conjunction with contrastive learning and GANs in Generative AI, particularly for image-to-image translation. This work suggests that KAN could be a valuable component in the broader generative AI domain.","sentences":["Image-to-Image translation in Generative Artificial Intelligence (Generative AI) has been a central focus of research, with applications spanning healthcare, remote sensing, physics, chemistry, photography, and more.","Among the numerous methodologies, Generative Adversarial Networks (GANs) with contrastive learning have been particularly successful.","This study aims to demonstrate that the Kolmogorov-Arnold Network (KAN) can effectively replace the Multi-layer Perceptron (MLP) method in generative AI, particularly in the subdomain of image-to-image translation, to achieve better generative quality.","Our novel approach replaces the two-layer MLP with a two-layer KAN in the existing Contrastive Unpaired Image-to-Image Translation (CUT) model, developing the KAN-CUT model.","This substitution favors the generation of more informative features in low-dimensional vector representations, which contrastive learning can utilize more effectively to produce high-quality images in the target domain.","Extensive experiments, detailed in the results section, demonstrate the applicability of KAN in conjunction with contrastive learning and GANs in Generative AI, particularly for image-to-image translation.","This work suggests that KAN could be a valuable component in the broader generative AI domain."],"url":"http://arxiv.org/abs/2408.08216v1"}
{"created":"2024-08-15 15:23:37","title":"Moving Healthcare AI-Support Systems for Visually Detectable Diseases onto Constrained Devices","abstract":"Image classification usually requires connectivity and access to the cloud which is often limited in many parts of the world, including hard to reach rural areas. TinyML aims to solve this problem by hosting AI assistants on constrained devices, eliminating connectivity issues by processing data within the device itself, without internet or cloud access. This pilot study explores the use of tinyML to provide healthcare support with low spec devices in low connectivity environments, focusing on diagnosis of skin diseases and the ethical use of AI assistants in a healthcare setting. To investigate this, 10,000 images of skin lesions were used to train a model for classifying visually detectable diseases (VDDs). The model weights were then offloaded to a Raspberry Pi with a webcam attached, to be used for the classification of skin lesions without internet access. It was found that the developed prototype achieved a test accuracy of 78% and a test loss of 1.08.","sentences":["Image classification usually requires connectivity and access to the cloud which is often limited in many parts of the world, including hard to reach rural areas.","TinyML aims to solve this problem by hosting AI assistants on constrained devices, eliminating connectivity issues by processing data within the device itself, without internet or cloud access.","This pilot study explores the use of tinyML to provide healthcare support with low spec devices in low connectivity environments, focusing on diagnosis of skin diseases and the ethical use of AI assistants in a healthcare setting.","To investigate this, 10,000 images of skin lesions were used to train a model for classifying visually detectable diseases (VDDs).","The model weights were then offloaded to a Raspberry Pi with a webcam attached, to be used for the classification of skin lesions without internet access.","It was found that the developed prototype achieved a test accuracy of 78% and a test loss of 1.08."],"url":"http://arxiv.org/abs/2408.08215v1"}
{"created":"2024-08-15 15:23:32","title":"Federated Fairness Analytics: Quantifying Fairness in Federated Learning","abstract":"Federated Learning (FL) is a privacy-enhancing technology for distributed ML. By training models locally and aggregating updates - a federation learns together, while bypassing centralised data collection. FL is increasingly popular in healthcare, finance and personal computing. However, it inherits fairness challenges from classical ML and introduces new ones, resulting from differences in data quality, client participation, communication constraints, aggregation methods and underlying hardware. Fairness remains an unresolved issue in FL and the community has identified an absence of succinct definitions and metrics to quantify fairness; to address this, we propose Federated Fairness Analytics - a methodology for measuring fairness. Our definition of fairness comprises four notions with novel, corresponding metrics. They are symptomatically defined and leverage techniques originating from XAI, cooperative game-theory and networking engineering. We tested a range of experimental settings, varying the FL approach, ML task and data settings. The results show that statistical heterogeneity and client participation affect fairness and fairness conscious approaches such as Ditto and q-FedAvg marginally improve fairness-performance trade-offs. Using our techniques, FL practitioners can uncover previously unobtainable insights into their system's fairness, at differing levels of granularity in order to address fairness challenges in FL. We have open-sourced our work at: https://github.com/oscardilley/federated-fairness.","sentences":["Federated Learning (FL) is a privacy-enhancing technology for distributed ML.","By training models locally and aggregating updates - a federation learns together, while bypassing centralised data collection.","FL is increasingly popular in healthcare, finance and personal computing.","However, it inherits fairness challenges from classical ML and introduces new ones, resulting from differences in data quality, client participation, communication constraints, aggregation methods and underlying hardware.","Fairness remains an unresolved issue in FL and the community has identified an absence of succinct definitions and metrics to quantify fairness; to address this, we propose Federated Fairness Analytics - a methodology for measuring fairness.","Our definition of fairness comprises four notions with novel, corresponding metrics.","They are symptomatically defined and leverage techniques originating from XAI, cooperative game-theory and networking engineering.","We tested a range of experimental settings, varying the FL approach, ML task and data settings.","The results show that statistical heterogeneity and client participation affect fairness and fairness conscious approaches such as Ditto and q-FedAvg marginally improve fairness-performance trade-offs.","Using our techniques, FL practitioners can uncover previously unobtainable insights into their system's fairness, at differing levels of granularity in order to address fairness challenges in FL.","We have open-sourced our work at: https://github.com/oscardilley/federated-fairness."],"url":"http://arxiv.org/abs/2408.08214v1"}
{"created":"2024-08-15 15:23:00","title":"Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion","abstract":"While various approaches have recently been studied for bias identification, little is known about how implicit language that does not explicitly convey a viewpoint affects bias amplification in large language models.To examine the severity of bias toward a view, we evaluated the performance of two downstream tasks where the implicit and explicit knowledge of social groups were used. First, we present a stress test evaluation by using a biased model in edge cases of excessive bias scenarios. Then, we evaluate how LLMs calibrate linguistically in response to both implicit and explicit opinions when they are aligned with conflicting viewpoints. Our findings reveal a discrepancy in LLM performance in identifying implicit and explicit opinions, with a general tendency of bias toward explicit opinions of opposing stances. Moreover, the bias-aligned models generate more cautious responses using uncertainty phrases compared to the unaligned (zero-shot) base models. The direct, incautious responses of the unaligned models suggest a need for further refinement of decisiveness by incorporating uncertainty markers to enhance their reliability, especially on socially nuanced topics with high subjectivity.","sentences":["While various approaches have recently been studied for bias identification, little is known about how implicit language that does not explicitly convey a viewpoint affects bias amplification in large language models.","To examine the severity of bias toward a view, we evaluated the performance of two downstream tasks where the implicit and explicit knowledge of social groups were used.","First, we present a stress test evaluation by using a biased model in edge cases of excessive bias scenarios.","Then, we evaluate how LLMs calibrate linguistically in response to both implicit and explicit opinions when they are aligned with conflicting viewpoints.","Our findings reveal a discrepancy in LLM performance in identifying implicit and explicit opinions, with a general tendency of bias toward explicit opinions of opposing stances.","Moreover, the bias-aligned models generate more cautious responses using uncertainty phrases compared to the unaligned (zero-shot) base models.","The direct, incautious responses of the unaligned models suggest a need for further refinement of decisiveness by incorporating uncertainty markers to enhance their reliability, especially on socially nuanced topics with high subjectivity."],"url":"http://arxiv.org/abs/2408.08212v1"}
{"created":"2024-08-15 15:19:11","title":"Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models","abstract":"Recent advances in AI have been significantly driven by the capabilities of large language models (LLMs) to solve complex problems in ways that resemble human thinking. However, there is an ongoing debate about the extent to which LLMs are capable of actual reasoning. Central to this debate are two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS). This paper introduces a framework that is both theoretical and practical, aimed at assessing how effectively LLMs are able to replicate real-world reasoning mechanisms using these probabilistic measures. By viewing LLMs as abstract machines that process information through a natural language interface, we examine the conditions under which it is possible to compute suitable approximations of PN and PS. Our research marks an important step towards gaining a deeper understanding of when LLMs are capable of reasoning, as illustrated by a series of math examples.","sentences":["Recent advances in AI have been significantly driven by the capabilities of large language models (LLMs) to solve complex problems in ways that resemble human thinking.","However, there is an ongoing debate about the extent to which LLMs are capable of actual reasoning.","Central to this debate are two key probabilistic concepts that are essential for connecting causes to their effects: the probability of necessity (PN) and the probability of sufficiency (PS).","This paper introduces a framework that is both theoretical and practical, aimed at assessing how effectively LLMs are able to replicate real-world reasoning mechanisms using these probabilistic measures.","By viewing LLMs as abstract machines that process information through a natural language interface, we examine the conditions under which it is possible to compute suitable approximations of PN and PS.","Our research marks an important step towards gaining a deeper understanding of when LLMs are capable of reasoning, as illustrated by a series of math examples."],"url":"http://arxiv.org/abs/2408.08210v1"}
{"created":"2024-08-15 15:18:55","title":"Modeling Domain and Feedback Transitions for Cross-Domain Sequential Recommendation","abstract":"Nowadays, many recommender systems encompass various domains to cater to users' diverse needs, leading to user behaviors transitioning across different domains. In fact, user behaviors across different domains reveal changes in preference toward recommended items. For instance, a shift from negative feedback to positive feedback indicates improved user satisfaction. However, existing cross-domain sequential recommendation methods typically model user interests by focusing solely on information about domain transitions, often overlooking the valuable insights provided by users' feedback transitions. In this paper, we propose $\\text{Transition}^2$, a novel method to model transitions across both domains and types of user feedback. Specifically, $\\text{Transition}^2$ introduces a transition-aware graph encoder based on user history, assigning different weights to edges according to the feedback type. This enables the graph encoder to extract historical embeddings that capture the transition information between different domains and feedback types. Subsequently, we encode the user history using a cross-transition multi-head self-attention, incorporating various masks to distinguish different types of transitions. Finally, we integrate these modules to make predictions across different domains. Experimental results on two public datasets demonstrate the effectiveness of $\\text{Transition}^2$.","sentences":["Nowadays, many recommender systems encompass various domains to cater to users' diverse needs, leading to user behaviors transitioning across different domains.","In fact, user behaviors across different domains reveal changes in preference toward recommended items.","For instance, a shift from negative feedback to positive feedback indicates improved user satisfaction.","However, existing cross-domain sequential recommendation methods typically model user interests by focusing solely on information about domain transitions, often overlooking the valuable insights provided by users' feedback transitions.","In this paper, we propose $\\text{Transition}^2$, a novel method to model transitions across both domains and types of user feedback.","Specifically, $\\text{Transition}^2$ introduces a transition-aware graph encoder based on user history, assigning different weights to edges according to the feedback type.","This enables the graph encoder to extract historical embeddings that capture the transition information between different domains and feedback types.","Subsequently, we encode the user history using a cross-transition multi-head self-attention, incorporating various masks to distinguish different types of transitions.","Finally, we integrate these modules to make predictions across different domains.","Experimental results on two public datasets demonstrate the effectiveness of $\\text{Transition}^2$."],"url":"http://arxiv.org/abs/2408.08209v1"}
{"created":"2024-08-15 15:18:46","title":"LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation","abstract":"Sequential recommendation systems fundamentally rely on users' historical interaction sequences, which are often contaminated by noisy interactions. Identifying these noisy interactions accurately without additional information is particularly difficult due to the lack of explicit supervisory signals to denote noise. Large Language Models (LLMs), equipped with extensive open knowledge and semantic reasoning abilities, present a promising avenue to bridge this information gap. However, employing LLMs for denoising in sequential recommendation introduces notable challenges: 1) Direct application of pretrained LLMs may not be competent for the denoising task, frequently generating nonsensical responses; 2) Even after fine-tuning, the reliability of LLM outputs remains questionable, especially given the complexity of the task and th inherent hallucinatory issue of LLMs.   To tackle these challenges, we propose LLM4DSR, a tailored approach for denoising sequential recommendation using LLMs. We constructed a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements. Furthermore, we developed an uncertainty estimation module that ensures only high-confidence responses are utilized for sequence corrections. Remarkably, LLM4DSR is model-agnostic, allowing the corrected sequences to be flexibly applied across various recommendation models. Extensive experiments validate the superiority of LLM4DSR over existing methods across three datasets and three recommendation backbones.","sentences":["Sequential recommendation systems fundamentally rely on users' historical interaction sequences, which are often contaminated by noisy interactions.","Identifying these noisy interactions accurately without additional information is particularly difficult due to the lack of explicit supervisory signals to denote noise.","Large Language Models (LLMs), equipped with extensive open knowledge and semantic reasoning abilities, present a promising avenue to bridge this information gap.","However, employing LLMs for denoising in sequential recommendation introduces notable challenges: 1) Direct application of pretrained LLMs may not be competent for the denoising task, frequently generating nonsensical responses; 2) Even after fine-tuning, the reliability of LLM outputs remains questionable, especially given the complexity of the task and th inherent hallucinatory issue of LLMs.   ","To tackle these challenges, we propose LLM4DSR, a tailored approach for denoising sequential recommendation using LLMs.","We constructed a self-supervised fine-tuning task to activate LLMs' capabilities to identify noisy items and suggest replacements.","Furthermore, we developed an uncertainty estimation module that ensures only high-confidence responses are utilized for sequence corrections.","Remarkably, LLM4DSR is model-agnostic, allowing the corrected sequences to be flexibly applied across various recommendation models.","Extensive experiments validate the superiority of LLM4DSR over existing methods across three datasets and three recommendation backbones."],"url":"http://arxiv.org/abs/2408.08208v1"}
{"created":"2024-08-15 15:16:49","title":"WaterSplatting: Fast Underwater 3D Scene Reconstruction Using Gaussian Splatting","abstract":"The underwater 3D scene reconstruction is a challenging, yet interesting problem with applications ranging from naval robots to VR experiences. The problem was successfully tackled by fully volumetric NeRF-based methods which can model both the geometry and the medium (water). Unfortunately, these methods are slow to train and do not offer real-time rendering. More recently, 3D Gaussian Splatting (3DGS) method offered a fast alternative to NeRFs. However, because it is an explicit method that renders only the geometry, it cannot render the medium and is therefore unsuited for underwater reconstruction. Therefore, we propose a novel approach that fuses volumetric rendering with 3DGS to handle underwater data effectively. Our method employs 3DGS for explicit geometry representation and a separate volumetric field (queried once per pixel) for capturing the scattering medium. This dual representation further allows the restoration of the scenes by removing the scattering medium. Our method outperforms state-of-the-art NeRF-based methods in rendering quality on the underwater SeaThru-NeRF dataset. Furthermore, it does so while offering real-time rendering performance, addressing the efficiency limitations of existing methods. Web: https://water-splatting.github.io","sentences":["The underwater 3D scene reconstruction is a challenging, yet interesting problem with applications ranging from naval robots to VR experiences.","The problem was successfully tackled by fully volumetric NeRF-based methods which can model both the geometry and the medium (water).","Unfortunately, these methods are slow to train and do not offer real-time rendering.","More recently, 3D Gaussian Splatting (3DGS) method offered a fast alternative to NeRFs.","However, because it is an explicit method that renders only the geometry, it cannot render the medium and is therefore unsuited for underwater reconstruction.","Therefore, we propose a novel approach that fuses volumetric rendering with 3DGS to handle underwater data effectively.","Our method employs 3DGS for explicit geometry representation and a separate volumetric field (queried once per pixel) for capturing the scattering medium.","This dual representation further allows the restoration of the scenes by removing the scattering medium.","Our method outperforms state-of-the-art NeRF-based methods in rendering quality on the underwater SeaThru-NeRF dataset.","Furthermore, it does so while offering real-time rendering performance, addressing the efficiency limitations of existing methods.","Web: https://water-splatting.github.io"],"url":"http://arxiv.org/abs/2408.08206v1"}
{"created":"2024-08-15 15:13:22","title":"A Multi-task Adversarial Attack Against Face Authentication","abstract":"Deep-learning-based identity management systems, such as face authentication systems, are vulnerable to adversarial attacks. However, existing attacks are typically designed for single-task purposes, which means they are tailored to exploit vulnerabilities unique to the individual target rather than being adaptable for multiple users or systems. This limitation makes them unsuitable for certain attack scenarios, such as morphing, universal, transferable, and counter attacks. In this paper, we propose a multi-task adversarial attack algorithm called MTADV that are adaptable for multiple users or systems. By interpreting these scenarios as multi-task attacks, MTADV is applicable to both single- and multi-task attacks, and feasible in the white- and gray-box settings. Furthermore, MTADV is effective against various face datasets, including LFW, CelebA, and CelebA-HQ, and can work with different deep learning models, such as FaceNet, InsightFace, and CurricularFace. Importantly, MTADV retains its feasibility as a single-task attack targeting a single user/system. To the best of our knowledge, MTADV is the first adversarial attack method that can target all of the aforementioned scenarios in one algorithm.","sentences":["Deep-learning-based identity management systems, such as face authentication systems, are vulnerable to adversarial attacks.","However, existing attacks are typically designed for single-task purposes, which means they are tailored to exploit vulnerabilities unique to the individual target rather than being adaptable for multiple users or systems.","This limitation makes them unsuitable for certain attack scenarios, such as morphing, universal, transferable, and counter attacks.","In this paper, we propose a multi-task adversarial attack algorithm called MTADV that are adaptable for multiple users or systems.","By interpreting these scenarios as multi-task attacks, MTADV is applicable to both single- and multi-task attacks, and feasible in the white- and gray-box settings.","Furthermore, MTADV is effective against various face datasets, including LFW, CelebA, and CelebA-HQ, and can work with different deep learning models, such as FaceNet, InsightFace, and CurricularFace.","Importantly, MTADV retains its feasibility as a single-task attack targeting a single user/system.","To the best of our knowledge, MTADV is the first adversarial attack method that can target all of the aforementioned scenarios in one algorithm."],"url":"http://arxiv.org/abs/2408.08205v1"}
{"created":"2024-08-15 15:11:06","title":"From Clicks to Carbon: The Environmental Toll of Recommender Systems","abstract":"As global warming soars, evaluating the environmental impact of research is more critical now than ever before. However, we find that few to no recommender systems research papers document their impact on the environment. Consequently, in this paper, we conduct a comprehensive analysis of the environmental impact of recommender system research by reproducing a characteristic recommender systems experimental pipeline. We focus on estimating the carbon footprint of recommender systems research papers, highlighting the evolution of the environmental impact of recommender systems research experiments over time. We thoroughly evaluated all 79 full papers from the ACM RecSys conference in the years 2013 and 2023 to analyze representative experimental pipelines for papers utilizing traditional, so-called good old-fashioned AI algorithms and deep learning algorithms, respectively. We reproduced these representative experimental pipelines, measured electricity consumption using a hardware energy meter, and converted the measured energy consumption into CO2 equivalents to estimate the environmental impact. Our results show that a recommender systems research paper utilizing deep learning algorithms emits approximately 42 times more CO2 equivalents than a paper utilizing traditional algorithms. Furthermore, on average, such a paper produces 3,297 kilograms of CO2 equivalents, which is more than one person produces by flying from New York City to Melbourne or the amount one tree sequesters in 300 years.","sentences":["As global warming soars, evaluating the environmental impact of research is more critical now than ever before.","However, we find that few to no recommender systems research papers document their impact on the environment.","Consequently, in this paper, we conduct a comprehensive analysis of the environmental impact of recommender system research by reproducing a characteristic recommender systems experimental pipeline.","We focus on estimating the carbon footprint of recommender systems research papers, highlighting the evolution of the environmental impact of recommender systems research experiments over time.","We thoroughly evaluated all 79 full papers from the ACM RecSys conference in the years 2013 and 2023 to analyze representative experimental pipelines for papers utilizing traditional, so-called good old-fashioned AI algorithms and deep learning algorithms, respectively.","We reproduced these representative experimental pipelines, measured electricity consumption using a hardware energy meter, and converted the measured energy consumption into CO2 equivalents to estimate the environmental impact.","Our results show that a recommender systems research paper utilizing deep learning algorithms emits approximately 42 times more CO2 equivalents than a paper utilizing traditional algorithms.","Furthermore, on average, such a paper produces 3,297 kilograms of CO2 equivalents, which is more than one person produces by flying from New York City to Melbourne or the amount one tree sequesters in 300 years."],"url":"http://arxiv.org/abs/2408.08203v1"}
{"created":"2024-08-15 15:10:01","title":"Towards Practical Human Motion Prediction with LiDAR Point Clouds","abstract":"Human motion prediction is crucial for human-centric multimedia understanding and interacting. Current methods typically rely on ground truth human poses as observed input, which is not practical for real-world scenarios where only raw visual sensor data is available. To implement these methods in practice, a pre-phrase of pose estimation is essential. However, such two-stage approaches often lead to performance degradation due to the accumulation of errors. Moreover, reducing raw visual data to sparse keypoint representations significantly diminishes the density of information, resulting in the loss of fine-grained features. In this paper, we propose \\textit{LiDAR-HMP}, the first single-LiDAR-based 3D human motion prediction approach, which receives the raw LiDAR point cloud as input and forecasts future 3D human poses directly. Building upon our novel structure-aware body feature descriptor, LiDAR-HMP adaptively maps the observed motion manifold to future poses and effectively models the spatial-temporal correlations of human motions for further refinement of prediction results. Extensive experiments show that our method achieves state-of-the-art performance on two public benchmarks and demonstrates remarkable robustness and efficacy in real-world deployments.","sentences":["Human motion prediction is crucial for human-centric multimedia understanding and interacting.","Current methods typically rely on ground truth human poses as observed input, which is not practical for real-world scenarios where only raw visual sensor data is available.","To implement these methods in practice, a pre-phrase of pose estimation is essential.","However, such two-stage approaches often lead to performance degradation due to the accumulation of errors.","Moreover, reducing raw visual data to sparse keypoint representations significantly diminishes the density of information, resulting in the loss of fine-grained features.","In this paper, we propose \\textit{LiDAR-HMP}, the first single-LiDAR-based 3D human motion prediction approach, which receives the raw LiDAR point cloud as input and forecasts future 3D human poses directly.","Building upon our novel structure-aware body feature descriptor, LiDAR-HMP adaptively maps the observed motion manifold to future poses and effectively models the spatial-temporal correlations of human motions for further refinement of prediction results.","Extensive experiments show that our method achieves state-of-the-art performance on two public benchmarks and demonstrates remarkable robustness and efficacy in real-world deployments."],"url":"http://arxiv.org/abs/2408.08202v1"}
{"created":"2024-08-15 15:08:58","title":"Heavy Labels Out! Dataset Distillation with Label Space Lightening","abstract":"Dataset distillation or condensation aims to condense a large-scale training dataset into a much smaller synthetic one such that the training performance of distilled and original sets on neural networks are similar. Although the number of training samples can be reduced substantially, current state-of-the-art methods heavily rely on enormous soft labels to achieve satisfactory performance. As a result, the required storage can be comparable even to original datasets, especially for large-scale ones. To solve this problem, instead of storing these heavy labels, we propose a novel label-lightening framework termed HeLlO aiming at effective image-to-label projectors, with which synthetic labels can be directly generated online from synthetic images. Specifically, to construct such projectors, we leverage prior knowledge in open-source foundation models, e.g., CLIP, and introduce a LoRA-like fine-tuning strategy to mitigate the gap between pre-trained and target distributions, so that original models for soft-label generation can be distilled into a group of low-rank matrices. Moreover, an effective image optimization method is proposed to further mitigate the potential error between the original and distilled label generators. Extensive experiments demonstrate that with only about 0.003% of the original storage required for a complete set of soft labels, we achieve comparable performance to current state-of-the-art dataset distillation methods on large-scale datasets. Our code will be available.","sentences":["Dataset distillation or condensation aims to condense a large-scale training dataset into a much smaller synthetic one such that the training performance of distilled and original sets on neural networks are similar.","Although the number of training samples can be reduced substantially, current state-of-the-art methods heavily rely on enormous soft labels to achieve satisfactory performance.","As a result, the required storage can be comparable even to original datasets, especially for large-scale ones.","To solve this problem, instead of storing these heavy labels, we propose a novel label-lightening framework termed HeLlO aiming at effective image-to-label projectors, with which synthetic labels can be directly generated online from synthetic images.","Specifically, to construct such projectors, we leverage prior knowledge in open-source foundation models, e.g., CLIP, and introduce a LoRA-like fine-tuning strategy to mitigate the gap between pre-trained and target distributions, so that original models for soft-label generation can be distilled into a group of low-rank matrices.","Moreover, an effective image optimization method is proposed to further mitigate the potential error between the original and distilled label generators.","Extensive experiments demonstrate that with only about 0.003% of the original storage required for a complete set of soft labels, we achieve comparable performance to current state-of-the-art dataset distillation methods on large-scale datasets.","Our code will be available."],"url":"http://arxiv.org/abs/2408.08201v1"}
{"created":"2024-08-15 14:53:48","title":"\"I Try to Represent Myself as I Am\": Self-Presentation Preferences of People with Invisible Disabilities through Embodied Social VR Avatars","abstract":"With the increasing adoption of social virtual reality (VR), it is critical to design inclusive avatars. While researchers have investigated how and why blind and d/Deaf people wish to disclose their disabilities in VR, little is known about the preferences of many others with invisible disabilities (e.g., ADHD, dyslexia, chronic conditions). We filled this gap by interviewing 15 participants, each with one to three invisible disabilities, who represented 22 different invisible disabilities in total. We found that invisibly disabled people approached avatar-based disclosure through contextualized considerations informed by their prior experiences. For example, some wished to use VR's embodied affordances, such as facial expressions and body language, to dynamically represent their energy level or willingness to engage with others, while others preferred not to disclose their disability identity in any context. We define a binary framework for embodied invisible disability expression (public and private) and discuss three disclosure patterns (Activists, Non-Disclosers, and Situational Disclosers) to inform the design of future inclusive VR experiences.","sentences":["With the increasing adoption of social virtual reality (VR), it is critical to design inclusive avatars.","While researchers have investigated how and why blind and d/Deaf people wish to disclose their disabilities in VR, little is known about the preferences of many others with invisible disabilities (e.g., ADHD, dyslexia, chronic conditions).","We filled this gap by interviewing 15 participants, each with one to three invisible disabilities, who represented 22 different invisible disabilities in total.","We found that invisibly disabled people approached avatar-based disclosure through contextualized considerations informed by their prior experiences.","For example, some wished to use VR's embodied affordances, such as facial expressions and body language, to dynamically represent their energy level or willingness to engage with others, while others preferred not to disclose their disability identity in any context.","We define a binary framework for embodied invisible disability expression (public and private) and discuss three disclosure patterns (Activists, Non-Disclosers, and Situational Disclosers) to inform the design of future inclusive VR experiences."],"url":"http://arxiv.org/abs/2408.08193v1"}
{"created":"2024-08-15 14:51:50","title":"Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation","abstract":"Mean field games (MFGs) model the interactions within a large-population multi-agent system using the population distribution. Traditional learning methods for MFGs are based on fixed-point iteration (FPI), which calculates best responses and induced population distribution separately and sequentially. However, FPI-type methods suffer from inefficiency and instability, due to oscillations caused by the forward-backward procedure. This paper considers an online learning method for MFGs, where an agent updates its policy and population estimates simultaneously and fully asynchronously, resulting in a simple stochastic gradient descent (SGD) type method called SemiSGD. Not only does SemiSGD exhibit numerical stability and efficiency, but it also provides a novel perspective by treating the value function and population distribution as a unified parameter. We theoretically show that SemiSGD directs this unified parameter along a descent direction to the mean field equilibrium. Motivated by this perspective, we develop a linear function approximation (LFA) for both the value function and the population distribution, resulting in the first population-aware LFA for MFGs on continuous state-action space. Finite-time convergence and approximation error analysis are provided for SemiSGD equipped with population-aware LFA.","sentences":["Mean field games (MFGs) model the interactions within a large-population multi-agent system using the population distribution.","Traditional learning methods for MFGs are based on fixed-point iteration (FPI), which calculates best responses and induced population distribution separately and sequentially.","However, FPI-type methods suffer from inefficiency and instability, due to oscillations caused by the forward-backward procedure.","This paper considers an online learning method for MFGs, where an agent updates its policy and population estimates simultaneously and fully asynchronously, resulting in a simple stochastic gradient descent (SGD) type method called SemiSGD.","Not only does SemiSGD exhibit numerical stability and efficiency, but it also provides a novel perspective by treating the value function and population distribution as a unified parameter.","We theoretically show that SemiSGD directs this unified parameter along a descent direction to the mean field equilibrium.","Motivated by this perspective, we develop a linear function approximation (LFA) for both the value function and the population distribution, resulting in the first population-aware LFA for MFGs on continuous state-action space.","Finite-time convergence and approximation error analysis are provided for SemiSGD equipped with population-aware LFA."],"url":"http://arxiv.org/abs/2408.08192v1"}
{"created":"2024-08-15 14:49:12","title":"Beyond Full Label: Single-Point Prompt for Infrared Small Target Label Generation","abstract":"In this work, we make the first attempt to construct a learning-based single-point annotation paradigm for infrared small target label generation (IRSTLG). Our intuition is that label generation requires just one more point prompt than target detection: IRSTLG can be regarded as an infrared small target detection (IRSTD) task with the target location hint. Based on this insight, we introduce an energy double guided single-point prompt (EDGSP) framework, which adeptly transforms the target detection network into a refined label generation method. Specifically, the proposed EDGSP includes: 1) target energy initialization (TEI) to create a foundational outline for sufficient shape evolution of pseudo label, 2) double prompt embedding (DPE) for rapid localization of interested regions and reinforcement of individual differences to avoid label adhesion, and 3) bounding box-based matching (BBM) to eliminate false alarms. Experimental results show that pseudo labels generated by three baselines equipped with EDGSP achieve 100% object-level probability of detection (Pd) and 0% false-alarm rate (Fa) on SIRST, NUDT-SIRST, and IRSTD-1k datasets, with a pixel-level intersection over union (IoU) improvement of 13.28% over state-of-the-art label generation methods. Additionally, the downstream detection task reveals that our centroid-annotated pseudo labels surpass full labels, even with coarse single-point annotations, it still achieves 99.5% performance of full labeling.","sentences":["In this work, we make the first attempt to construct a learning-based single-point annotation paradigm for infrared small target label generation (IRSTLG).","Our intuition is that label generation requires just one more point prompt than target detection: IRSTLG can be regarded as an infrared small target detection (IRSTD) task with the target location hint.","Based on this insight, we introduce an energy double guided single-point prompt (EDGSP) framework, which adeptly transforms the target detection network into a refined label generation method.","Specifically, the proposed EDGSP includes: 1) target energy initialization (TEI) to create a foundational outline for sufficient shape evolution of pseudo label, 2) double prompt embedding (DPE) for rapid localization of interested regions and reinforcement of individual differences to avoid label adhesion, and 3) bounding box-based matching (BBM) to eliminate false alarms.","Experimental results show that pseudo labels generated by three baselines equipped with EDGSP achieve 100% object-level probability of detection (Pd) and 0% false-alarm rate (Fa) on SIRST, NUDT-SIRST, and IRSTD-1k datasets, with a pixel-level intersection over union (IoU) improvement of 13.28% over state-of-the-art label generation methods.","Additionally, the downstream detection task reveals that our centroid-annotated pseudo labels surpass full labels, even with coarse single-point annotations, it still achieves 99.5% performance of full labeling."],"url":"http://arxiv.org/abs/2408.08191v1"}
{"created":"2024-08-15 14:47:44","title":"FancyVideo: Towards Dynamic and Consistent Video Generation via Cross-frame Textual Guidance","abstract":"Synthesizing motion-rich and temporally consistent videos remains a challenge in artificial intelligence, especially when dealing with extended durations. Existing text-to-video (T2V) models commonly employ spatial cross-attention for text control, equivalently guiding different frame generations without frame-specific textual guidance. Thus, the model's capacity to comprehend the temporal logic conveyed in prompts and generate videos with coherent motion is restricted. To tackle this limitation, we introduce FancyVideo, an innovative video generator that improves the existing text-control mechanism with the well-designed Cross-frame Textual Guidance Module (CTGM). Specifically, CTGM incorporates the Temporal Information Injector (TII), Temporal Affinity Refiner (TAR), and Temporal Feature Booster (TFB) at the beginning, middle, and end of cross-attention, respectively, to achieve frame-specific textual guidance. Firstly, TII injects frame-specific information from latent features into text conditions, thereby obtaining cross-frame textual conditions. Then, TAR refines the correlation matrix between cross-frame textual conditions and latent features along the time dimension. Lastly, TFB boosts the temporal consistency of latent features. Extensive experiments comprising both quantitative and qualitative evaluations demonstrate the effectiveness of FancyVideo. Our approach achieves state-of-the-art T2V generation results on the EvalCrafter benchmark and facilitates the synthesis of dynamic and consistent videos. The video show results can be available at https://fancyvideo.github.io/, and we will make our code and model weights publicly available.","sentences":["Synthesizing motion-rich and temporally consistent videos remains a challenge in artificial intelligence, especially when dealing with extended durations.","Existing text-to-video (T2V) models commonly employ spatial cross-attention for text control, equivalently guiding different frame generations without frame-specific textual guidance.","Thus, the model's capacity to comprehend the temporal logic conveyed in prompts and generate videos with coherent motion is restricted.","To tackle this limitation, we introduce FancyVideo, an innovative video generator that improves the existing text-control mechanism with the well-designed Cross-frame Textual Guidance Module (CTGM).","Specifically, CTGM incorporates the Temporal Information Injector (TII), Temporal Affinity Refiner (TAR), and Temporal Feature Booster (TFB) at the beginning, middle, and end of cross-attention, respectively, to achieve frame-specific textual guidance.","Firstly, TII injects frame-specific information from latent features into text conditions, thereby obtaining cross-frame textual conditions.","Then, TAR refines the correlation matrix between cross-frame textual conditions and latent features along the time dimension.","Lastly, TFB boosts the temporal consistency of latent features.","Extensive experiments comprising both quantitative and qualitative evaluations demonstrate the effectiveness of FancyVideo.","Our approach achieves state-of-the-art T2V generation results on the EvalCrafter benchmark and facilitates the synthesis of dynamic and consistent videos.","The video show results can be available at https://fancyvideo.github.io/, and we will make our code and model weights publicly available."],"url":"http://arxiv.org/abs/2408.08189v1"}
{"created":"2024-08-15 14:46:13","title":"Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy","abstract":"Long-horizon planning is hindered by challenges such as uncertainty accumulation, computational complexity, delayed rewards and incomplete information. This work proposes an approach to exploit the task hierarchy from human instructions to facilitate multi-robot planning. Using Large Language Models (LLMs), we propose a two-step approach to translate multi-sentence instructions into a structured language, Hierarchical Linear Temporal Logic (LTL), which serves as a formal representation for planning. Initially, LLMs transform the instructions into a hierarchical representation defined as Hierarchical Task Tree, capturing the logical and temporal relations among tasks. Following this, a domain-specific fine-tuning of LLM translates sub-tasks of each task into flat LTL formulas, aggregating them to form hierarchical LTL specifications. These specifications are then leveraged for planning using off-the-shelf planners. Our framework not only bridges the gap between instructions and algorithmic planning but also showcases the potential of LLMs in harnessing hierarchical reasoning to automate multi-robot task planning. Through evaluations in both simulation and real-world experiments involving human participants, we demonstrate that our method can handle more complex instructions compared to existing methods. The results indicate that our approach achieves higher success rates and lower costs in multi-robot task allocation and plan generation. Demos videos are available at https://youtu.be/7WOrDKxIMIs .","sentences":["Long-horizon planning is hindered by challenges such as uncertainty accumulation, computational complexity, delayed rewards and incomplete information.","This work proposes an approach to exploit the task hierarchy from human instructions to facilitate multi-robot planning.","Using Large Language Models (LLMs), we propose a two-step approach to translate multi-sentence instructions into a structured language, Hierarchical Linear Temporal Logic (LTL), which serves as a formal representation for planning.","Initially, LLMs transform the instructions into a hierarchical representation defined as Hierarchical Task Tree, capturing the logical and temporal relations among tasks.","Following this, a domain-specific fine-tuning of LLM translates sub-tasks of each task into flat LTL formulas, aggregating them to form hierarchical LTL specifications.","These specifications are then leveraged for planning using off-the-shelf planners.","Our framework not only bridges the gap between instructions and algorithmic planning but also showcases the potential of LLMs in harnessing hierarchical reasoning to automate multi-robot task planning.","Through evaluations in both simulation and real-world experiments involving human participants, we demonstrate that our method can handle more complex instructions compared to existing methods.","The results indicate that our approach achieves higher success rates and lower costs in multi-robot task allocation and plan generation.","Demos videos are available at https://youtu.be/7WOrDKxIMIs ."],"url":"http://arxiv.org/abs/2408.08188v1"}
{"created":"2024-08-15 14:42:02","title":"Not Every Image is Worth a Thousand Words: Quantifying Originality in Stable Diffusion","abstract":"This work addresses the challenge of quantifying originality in text-to-image (T2I) generative diffusion models, with a focus on copyright originality. We begin by evaluating T2I models' ability to innovate and generalize through controlled experiments, revealing that stable diffusion models can effectively recreate unseen elements with sufficiently diverse training data. Then, our key insight is that concepts and combinations of image elements the model is familiar with, and saw more during training, are more concisly represented in the model's latent space. We hence propose a method that leverages textual inversion to measure the originality of an image based on the number of tokens required for its reconstruction by the model. Our approach is inspired by legal definitions of originality and aims to assess whether a model can produce original content without relying on specific prompts or having the training data of the model. We demonstrate our method using both a pre-trained stable diffusion model and a synthetic dataset, showing a correlation between the number of tokens and image originality. This work contributes to the understanding of originality in generative models and has implications for copyright infringement cases.","sentences":["This work addresses the challenge of quantifying originality in text-to-image (T2I) generative diffusion models, with a focus on copyright originality.","We begin by evaluating T2I models' ability to innovate and generalize through controlled experiments, revealing that stable diffusion models can effectively recreate unseen elements with sufficiently diverse training data.","Then, our key insight is that concepts and combinations of image elements the model is familiar with, and saw more during training, are more concisly represented in the model's latent space.","We hence propose a method that leverages textual inversion to measure the originality of an image based on the number of tokens required for its reconstruction by the model.","Our approach is inspired by legal definitions of originality and aims to assess whether a model can produce original content without relying on specific prompts or having the training data of the model.","We demonstrate our method using both a pre-trained stable diffusion model and a synthetic dataset, showing a correlation between the number of tokens and image originality.","This work contributes to the understanding of originality in generative models and has implications for copyright infringement cases."],"url":"http://arxiv.org/abs/2408.08184v1"}
{"created":"2024-08-15 14:36:07","title":"Your Turn: Real-World Turning Angle Estimation for Parkinson's Disease Severity Assessment","abstract":"People with Parkinson's Disease (PD) often experience progressively worsening gait, including changes in how they turn around, as the disease progresses. Existing clinical rating tools are not capable of capturing hour-by-hour variations of PD symptoms, as they are confined to brief assessments within clinic settings. Measuring real-world gait turning angles continuously and passively is a component step towards using gait characteristics as sensitive indicators of disease progression in PD. This paper presents a deep learning-based approach to automatically quantify turning angles by extracting 3D skeletons from videos and calculating the rotation of hip and knee joints. We utilise state-of-the-art human pose estimation models, Fastpose and Strided Transformer, on a total of 1386 turning video clips from 24 subjects (12 people with PD and 12 healthy control volunteers), trimmed from a PD dataset of unscripted free-living videos in a home-like setting (Turn-REMAP). We also curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human pose benchmark with 3D ground truth, to further validate our method. Previous gait research has primarily taken place in clinics or laboratories evaluating scripted gait outcomes, but this work focuses on real-world settings where complexities exist, such as baggy clothing and poor lighting. Due to difficulties in obtaining accurate ground truth data in a free-living setting, we quantise the angle into the nearest bin $45^\\circ$ based on the manual labelling of expert clinicians. Our method achieves a turning calculation accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\\deg}, and a weighted precision WPrec of 68.3% for Turn-REMAP. This is the first work to explore the use of single monocular camera data to quantify turns by PD patients in a home setting.","sentences":["People with Parkinson's Disease (PD) often experience progressively worsening gait, including changes in how they turn around, as the disease progresses.","Existing clinical rating tools are not capable of capturing hour-by-hour variations of PD symptoms, as they are confined to brief assessments within clinic settings.","Measuring real-world gait turning angles continuously and passively is a component step towards using gait characteristics as sensitive indicators of disease progression in PD.","This paper presents a deep learning-based approach to automatically quantify turning angles by extracting 3D skeletons from videos and calculating the rotation of hip and knee joints.","We utilise state-of-the-art human pose estimation models, Fastpose and Strided Transformer, on a total of 1386 turning video clips from 24 subjects (12 people with PD and 12 healthy control volunteers), trimmed from a PD dataset of unscripted free-living videos in a home-like setting (Turn-REMAP).","We also curate a turning video dataset, Turn-H3.6M, from the public Human3.6M human pose benchmark with 3D ground truth, to further validate our method.","Previous gait research has primarily taken place in clinics or laboratories evaluating scripted gait outcomes, but this work focuses on real-world settings where complexities exist, such as baggy clothing and poor lighting.","Due to difficulties in obtaining accurate ground truth data in a free-living setting, we quantise the angle into the nearest bin $45^\\circ$ based on the manual labelling of expert clinicians.","Our method achieves a turning calculation accuracy of 41.6%, a Mean Absolute Error (MAE) of 34.7{\\deg}, and a weighted precision WPrec of 68.3% for Turn-REMAP.","This is the first work to explore the use of single monocular camera data to quantify turns by PD patients in a home setting."],"url":"http://arxiv.org/abs/2408.08182v1"}
{"created":"2024-08-15 14:33:09","title":"Machine learning empowered Modulation detection for OFDM-based signals","abstract":"We propose a blind ML-based modulation detection for OFDM-based technologies. Unlike previous works that assume an ideal environment with precise knowledge of subcarrier count and cyclic prefix location, we consider blind modulation detection while accounting for realistic environmental parameters and imperfections. Our approach employs a ResNet network to simultaneously detect the modulation type and accurately locate the cyclic prefix. Specifically, after eliminating the environmental impact from the signal and accurately extracting the OFDM symbols, we convert these symbols into scatter plots. Due to their unique shapes, these scatter plots are then classified using ResNet. As a result, our proposed modulation classification method can be applied to any OFDM-based technology without prior knowledge of the transmitted signal. We evaluate its performance across various modulation schemes and subcarrier numbers. Simulation results show that our method achieves a modulation detection accuracy exceeding $80\\%$ at an SNR of $10$ dB and $95\\%$ at an SNR of $25$ dB.","sentences":["We propose a blind ML-based modulation detection for OFDM-based technologies.","Unlike previous works that assume an ideal environment with precise knowledge of subcarrier count and cyclic prefix location, we consider blind modulation detection while accounting for realistic environmental parameters and imperfections.","Our approach employs a ResNet network to simultaneously detect the modulation type and accurately locate the cyclic prefix.","Specifically, after eliminating the environmental impact from the signal and accurately extracting the OFDM symbols, we convert these symbols into scatter plots.","Due to their unique shapes, these scatter plots are then classified using ResNet.","As a result, our proposed modulation classification method can be applied to any OFDM-based technology without prior knowledge of the transmitted signal.","We evaluate its performance across various modulation schemes and subcarrier numbers.","Simulation results show that our method achieves a modulation detection accuracy exceeding $80\\%$ at an SNR of $10$ dB and $95\\%$ at an SNR of $25$ dB."],"url":"http://arxiv.org/abs/2408.08179v1"}
{"created":"2024-08-15 14:19:13","title":"Towards flexible perception with visual memory","abstract":"Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is nearly impossible, since all information is distributed across the network's weights. We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database. Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build a simple and flexible visual memory that has the following key capabilities: (1.) The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data; (2.) The ability to remove data through unlearning and memory pruning; (3.) An interpretable decision-mechanism on which we can intervene to control its behavior. Taken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory. We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models -- beyond carving it in ``stone'' weights.","sentences":["Training a neural network is a monolithic endeavor, akin to carving knowledge into stone: once the process is completed, editing the knowledge in a network is nearly impossible, since all information is distributed across the network's weights.","We here explore a simple, compelling alternative by marrying the representational power of deep neural networks with the flexibility of a database.","Decomposing the task of image classification into image similarity (from a pre-trained embedding) and search (via fast nearest neighbor retrieval from a knowledge database), we build a simple and flexible visual memory that has the following key capabilities: (1.)","The ability to flexibly add data across scales: from individual samples all the way to entire classes and billion-scale data; (2.)","The ability to remove data through unlearning and memory pruning; (3.)","An interpretable decision-mechanism on which we can intervene to control its behavior.","Taken together, these capabilities comprehensively demonstrate the benefits of an explicit visual memory.","We hope that it might contribute to a conversation on how knowledge should be represented in deep vision models -- beyond carving it in ``stone'' weights."],"url":"http://arxiv.org/abs/2408.08172v1"}
{"created":"2024-08-15 13:49:14","title":"General-purpose Clothes Manipulation with Semantic Keypoints","abstract":"We have seen much recent progress in task-specific clothes manipulation, but generalizable clothes manipulation is still a challenge. Clothes manipulation requires sequential actions, making it challenging to generalize to unseen tasks. Besides, a general clothes state representation method is crucial. In this paper, we adopt language instructions to specify and decompose clothes manipulation tasks, and propose a large language model based hierarchical learning method to enhance generalization. For state representation, we use semantic keypoints to capture the geometry of clothes and outline their manipulation methods. Simulation experiments show that the proposed method outperforms the baseline method in terms of success rate and generalization for clothes manipulation tasks.","sentences":["We have seen much recent progress in task-specific clothes manipulation, but generalizable clothes manipulation is still a challenge.","Clothes manipulation requires sequential actions, making it challenging to generalize to unseen tasks.","Besides, a general clothes state representation method is crucial.","In this paper, we adopt language instructions to specify and decompose clothes manipulation tasks, and propose a large language model based hierarchical learning method to enhance generalization.","For state representation, we use semantic keypoints to capture the geometry of clothes and outline their manipulation methods.","Simulation experiments show that the proposed method outperforms the baseline method in terms of success rate and generalization for clothes manipulation tasks."],"url":"http://arxiv.org/abs/2408.08160v1"}
{"created":"2024-08-15 13:48:44","title":"EmBARDiment: an Embodied AI Agent for Productivity in XR","abstract":"XR devices running chat-bots powered by Large Language Models (LLMs) have tremendous potential as always-on agents that can enable much better productivity scenarios. However, screen based chat-bots do not take advantage of the the full-suite of natural inputs available in XR, including inward facing sensor data, instead they over-rely on explicit voice or text prompts, sometimes paired with multi-modal data dropped as part of the query. We propose a solution that leverages an attention framework that derives context implicitly from user actions, eye-gaze, and contextual memory within the XR environment. This minimizes the need for engineered explicit prompts, fostering grounded and intuitive interactions that glean user insights for the chat-bot. Our user studies demonstrate the imminent feasibility and transformative potential of our approach to streamline user interaction in XR with chat-bots, while offering insights for the design of future XR-embodied LLM agents.","sentences":["XR devices running chat-bots powered by Large Language Models (LLMs) have tremendous potential as always-on agents that can enable much better productivity scenarios.","However, screen based chat-bots do not take advantage of the the full-suite of natural inputs available in XR, including inward facing sensor data, instead they over-rely on explicit voice or text prompts, sometimes paired with multi-modal data dropped as part of the query.","We propose a solution that leverages an attention framework that derives context implicitly from user actions, eye-gaze, and contextual memory within the XR environment.","This minimizes the need for engineered explicit prompts, fostering grounded and intuitive interactions that glean user insights for the chat-bot.","Our user studies demonstrate the imminent feasibility and transformative potential of our approach to streamline user interaction in XR with chat-bots, while offering insights for the design of future XR-embodied LLM agents."],"url":"http://arxiv.org/abs/2408.08158v1"}
{"created":"2024-08-15 13:40:03","title":"DeepSeek-Prover-V1.5: Harnessing Proof Assistant Feedback for Reinforcement Learning and Monte-Carlo Tree Search","abstract":"We introduce DeepSeek-Prover-V1.5, an open-source language model designed for theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both training and inference processes. Pre-trained on DeepSeekMath-Base with specialization in formal mathematical languages, the model undergoes supervised fine-tuning using an enhanced formal theorem proving dataset derived from DeepSeek-Prover-V1. Further refinement is achieved through reinforcement learning from proof assistant feedback (RLPAF). Beyond the single-pass whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a variant of Monte-Carlo tree search that employs an intrinsic-reward-driven exploration strategy to generate diverse proof paths. DeepSeek-Prover-V1.5 demonstrates significant improvements over DeepSeek-Prover-V1, achieving new state-of-the-art results on the test set of the high school level miniF2F benchmark ($63.5\\%$) and the undergraduate level ProofNet benchmark ($25.3\\%$).","sentences":["We introduce DeepSeek-Prover-V1.5, an open-source language model designed for theorem proving in Lean 4, which enhances DeepSeek-Prover-V1 by optimizing both training and inference processes.","Pre-trained on DeepSeekMath-Base with specialization in formal mathematical languages, the model undergoes supervised fine-tuning using an enhanced formal theorem proving dataset derived from DeepSeek-Prover-V1.","Further refinement is achieved through reinforcement learning from proof assistant feedback (RLPAF).","Beyond the single-pass whole-proof generation approach of DeepSeek-Prover-V1, we propose RMaxTS, a variant of Monte-Carlo tree search that employs an intrinsic-reward-driven exploration strategy to generate diverse proof paths.","DeepSeek-Prover-V1.5 demonstrates significant improvements over DeepSeek-Prover-V1, achieving new state-of-the-art results on the test set of the high school level miniF2F benchmark ($63.5\\%$) and the undergraduate level ProofNet benchmark ($25.3\\%$)."],"url":"http://arxiv.org/abs/2408.08152v1"}
{"created":"2024-08-15 13:37:59","title":"Winning Snake: Design Choices in Multi-Shot ASP","abstract":"Answer set programming is a well-understood and established problem-solving and knowledge representation paradigm. It has become more prominent amongst a wider audience due to its multiple applications in science and industry. The constant development of advanced programming and modeling techniques extends the toolset for developers and users regularly. This paper demonstrates different techniques to reuse logic program parts (multi-shot) by solving the arcade game snake. This game is particularly interesting because a victory can be assured by solving the underlying NP-hard problem of Hamiltonian Cycles. We will demonstrate five hands-on implementations in clingo and compare their performance in an empirical evaluation. In addition, our implementation utilizes clingraph to generate a simple yet informative image representation of the game's progress.","sentences":["Answer set programming is a well-understood and established problem-solving and knowledge representation paradigm.","It has become more prominent amongst a wider audience due to its multiple applications in science and industry.","The constant development of advanced programming and modeling techniques extends the toolset for developers and users regularly.","This paper demonstrates different techniques to reuse logic program parts (multi-shot) by solving the arcade game snake.","This game is particularly interesting because a victory can be assured by solving the underlying NP-hard problem of Hamiltonian Cycles.","We will demonstrate five hands-on implementations in clingo and compare their performance in an empirical evaluation.","In addition, our implementation utilizes clingraph to generate a simple yet informative image representation of the game's progress."],"url":"http://arxiv.org/abs/2408.08150v1"}
{"created":"2024-08-15 13:35:59","title":"Unsupervised Variational Translator for Bridging Image Restoration and High-Level Vision Tasks","abstract":"Recent research tries to extend image restoration capabilities from human perception to machine perception, thereby enhancing the performance of high-level vision tasks in degraded environments. These methods, primarily based on supervised learning, typically involve the retraining of restoration networks or high-level vision networks. However, collecting paired data in real-world scenarios and retraining large-scale models are challenge. To this end, we propose an unsupervised learning method called \\textbf{Va}riational \\textbf{T}ranslator (VaT), which does not require retraining existing restoration and high-level vision networks. Instead, it establishes a lightweight network that serves as an intermediate bridge between them. By variational inference, VaT approximates the joint distribution of restoration output and high-level vision input, dividing the optimization objective into preserving content and maximizing marginal likelihood associated with high-level vision tasks. By cleverly leveraging self-training paradigms, VaT achieves the above optimization objective without requiring labels. As a result, the translated images maintain a close resemblance to their original content while also demonstrating exceptional performance on high-level vision tasks. Extensive experiments in dehazing and low-light enhancement for detection and classification show the superiority of our method over other state-of-the-art unsupervised counterparts, even significantly surpassing supervised methods in some complex real-world scenarios.","sentences":["Recent research tries to extend image restoration capabilities from human perception to machine perception, thereby enhancing the performance of high-level vision tasks in degraded environments.","These methods, primarily based on supervised learning, typically involve the retraining of restoration networks or high-level vision networks.","However, collecting paired data in real-world scenarios and retraining large-scale models are challenge.","To this end, we propose an unsupervised learning method called \\textbf{Va}riational \\textbf{T}ranslator (VaT), which does not require retraining existing restoration and high-level vision networks.","Instead, it establishes a lightweight network that serves as an intermediate bridge between them.","By variational inference, VaT approximates the joint distribution of restoration output and high-level vision input, dividing the optimization objective into preserving content and maximizing marginal likelihood associated with high-level vision tasks.","By cleverly leveraging self-training paradigms, VaT achieves the above optimization objective without requiring labels.","As a result, the translated images maintain a close resemblance to their original content while also demonstrating exceptional performance on high-level vision tasks.","Extensive experiments in dehazing and low-light enhancement for detection and classification show the superiority of our method over other state-of-the-art unsupervised counterparts, even significantly surpassing supervised methods in some complex real-world scenarios."],"url":"http://arxiv.org/abs/2408.08149v1"}
{"created":"2024-08-15 13:33:20","title":"Early Detection of Performance Regressions by Bridging Local Performance Data and Architectural Models","abstract":"During software development, developers often make numerous modifications to the software to address existing issues or implement new features. However, certain changes may inadvertently have a detrimental impact on the overall system performance. To ensure that the performance of new software releases does not degrade, existing practices rely on system-level performance testing, such as load testing, or component-level performance testing to detect performance regressions. However, performance testing for the entire system is often expensive and time-consuming, posing challenges to adapting to the rapid release cycles common in modern DevOps practices. System-level performance testing cannot be conducted until the system is fully built and deployed. On the other hand, component-level testing focuses on isolated components, neglecting overall system performance and the impact of system workloads.   In this paper, we propose a novel approach to early detection of performance regressions by bridging the local performance data generated by component-level testing and the system-level architectural models. Our approach uses local performance data to identify deviations at the component level, and then propagate these deviations to the architectural model. We then use the architectural model to predict regressions in the performance of the overall system. We evaluate our approach on two open-source benchmark systems and show that it can effectively detect end-to-end system performance regressions from local performance deviations with different intensities and under various system workloads. More importantly, our approach can detect regressions as early as in the development phase, in contrast to existing approaches that require the system to be fully built and deployed. Our approach is lightweight and can complement traditional system performance testing when testing resources are scarce.","sentences":["During software development, developers often make numerous modifications to the software to address existing issues or implement new features.","However, certain changes may inadvertently have a detrimental impact on the overall system performance.","To ensure that the performance of new software releases does not degrade, existing practices rely on system-level performance testing, such as load testing, or component-level performance testing to detect performance regressions.","However, performance testing for the entire system is often expensive and time-consuming, posing challenges to adapting to the rapid release cycles common in modern DevOps practices.","System-level performance testing cannot be conducted until the system is fully built and deployed.","On the other hand, component-level testing focuses on isolated components, neglecting overall system performance and the impact of system workloads.   ","In this paper, we propose a novel approach to early detection of performance regressions by bridging the local performance data generated by component-level testing and the system-level architectural models.","Our approach uses local performance data to identify deviations at the component level, and then propagate these deviations to the architectural model.","We then use the architectural model to predict regressions in the performance of the overall system.","We evaluate our approach on two open-source benchmark systems and show that it can effectively detect end-to-end system performance regressions from local performance deviations with different intensities and under various system workloads.","More importantly, our approach can detect regressions as early as in the development phase, in contrast to existing approaches that require the system to be fully built and deployed.","Our approach is lightweight and can complement traditional system performance testing when testing resources are scarce."],"url":"http://arxiv.org/abs/2408.08148v1"}
{"created":"2024-08-15 13:32:25","title":"P/D-Serve: Serving Disaggregated Large Language Model at Scale","abstract":"Serving disaggregated large language models (LLMs) over tens of thousands of xPU devices (GPUs or NPUs) with reliable performance faces multiple challenges. 1) Ignoring the diversity (various prefixes and tidal requests), treating all the prompts in a mixed pool is inadequate. To facilitate the similarity per scenario and minimize the inner mismatch on P/D (prefill and decoding) processing, fine-grained organization is required, dynamically adjusting P/D ratios for better performance. 2) Due to inaccurate estimation on workload (queue status or maintained connections), the global scheduler easily incurs unnecessary timeouts in prefill. 3) Block-fixed device-to-device (D2D) KVCache transfer over cluster-level RDMA (remote direct memory access) fails to achieve desired D2D utilization as expected. To overcome previous problems, this paper proposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps (machine learning operations), which models end-to-end (E2E) P/D performance and enables: 1) fine-grained P/D organization, mapping the service with RoCE (RDMA over converged ethernet) as needed, to facilitate similar processing and dynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for idle prefill, decoupling the scheduler from regular inaccurate reports and local queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer via optimized D2D access. P/D-Serve is implemented upon Ascend and MindSpore, has been deployed over tens of thousands of NPUs for more than eight months in commercial use, and further achieves 60\\%, 42\\% and 46\\% improvements on E2E throughput, time-to-first-token (TTFT) SLO (service level objective) and D2D transfer time. As the E2E system with optimizations, P/D-Serve achieves 6.7x increase on throughput, compared with aggregated LLMs.","sentences":["Serving disaggregated large language models (LLMs) over tens of thousands of xPU devices (GPUs or NPUs) with reliable performance faces multiple challenges.","1) Ignoring the diversity (various prefixes and tidal requests), treating all the prompts in a mixed pool is inadequate.","To facilitate the similarity per scenario and minimize the inner mismatch on P/D (prefill and decoding) processing, fine-grained organization is required, dynamically adjusting P/D ratios for better performance.","2) Due to inaccurate estimation on workload (queue status or maintained connections), the global scheduler easily incurs unnecessary timeouts in prefill.","3) Block-fixed device-to-device (D2D) KVCache transfer over cluster-level RDMA (remote direct memory access) fails to achieve desired D2D utilization as expected.","To overcome previous problems, this paper proposes an end-to-end system P/D-Serve, complying with the paradigm of MLOps (machine learning operations), which models end-to-end (E2E) P/D performance and enables: 1) fine-grained P/D organization, mapping the service with RoCE (RDMA over converged ethernet) as needed, to facilitate similar processing and dynamic adjustments on P/D ratios; 2) on-demand forwarding upon rejections for idle prefill, decoupling the scheduler from regular inaccurate reports and local queues, to avoid timeouts in prefill; and 3) efficient KVCache transfer via optimized D2D access.","P/D-Serve is implemented upon Ascend and MindSpore, has been deployed over tens of thousands of NPUs for more than eight months in commercial use, and further achieves 60\\%, 42\\% and 46\\% improvements on E2E throughput, time-to-first-token (TTFT) SLO (service level objective) and D2D transfer time.","As the E2E system with optimizations, P/D-Serve achieves 6.7x increase on throughput, compared with aggregated LLMs."],"url":"http://arxiv.org/abs/2408.08147v1"}
{"created":"2024-08-15 13:29:48","title":"KOALA: Enhancing Speculative Decoding for LLM via Multi-Layer Draft Heads with Adversarial Learning","abstract":"Large Language Models (LLMs) exhibit high inference latency due to their autoregressive decoding nature. While the draft head in speculative decoding mitigates this issue, its full potential remains unexplored. In this paper, we introduce KOALA (K-layer Optimized Adversarial Learning Architecture), an orthogonal approach to the draft head. By transforming the conventional single-layer draft head into a multi-layer architecture and incorporating adversarial learning into the traditional supervised training, KOALA significantly improves the accuracy of the draft head in predicting subsequent tokens, thus more closely mirroring the functionality of LLMs. Although this improvement comes at the cost of slightly increased drafting overhead, KOALA substantially unlocks the draft head's potential, greatly enhancing speculative decoding. We conducted comprehensive evaluations of KOALA, including both autoregressive and non-autoregressive draft heads across various tasks, demonstrating a latency speedup ratio improvement of 0.24x-0.41x, which is 10.57%-14.09% faster than the original draft heads.","sentences":["Large Language Models (LLMs) exhibit high inference latency due to their autoregressive decoding nature.","While the draft head in speculative decoding mitigates this issue, its full potential remains unexplored.","In this paper, we introduce KOALA (K-layer Optimized Adversarial Learning Architecture), an orthogonal approach to the draft head.","By transforming the conventional single-layer draft head into a multi-layer architecture and incorporating adversarial learning into the traditional supervised training, KOALA significantly improves the accuracy of the draft head in predicting subsequent tokens, thus more closely mirroring the functionality of LLMs.","Although this improvement comes at the cost of slightly increased drafting overhead, KOALA substantially unlocks the draft head's potential, greatly enhancing speculative decoding.","We conducted comprehensive evaluations of KOALA, including both autoregressive and non-autoregressive draft heads across various tasks, demonstrating a latency speedup ratio improvement of 0.24x-0.41x, which is 10.57%-14.09% faster than the original draft heads."],"url":"http://arxiv.org/abs/2408.08146v1"}
{"created":"2024-08-15 13:29:25","title":"Model-based Workflow for the Automated Generation of PDDL Descriptions","abstract":"Manually creating Planning Domain Definition Language (PDDL) descriptions is difficult, error-prone, and requires extensive expert knowledge. However, this knowledge is already embedded in engineering models and can be reused. Therefore, this contribution presents a comprehensive workflow for the automated generation of PDDL descriptions from integrated system and product models. The proposed workflow leverages Model-Based Systems Engineering (MBSE) to organize and manage system and product information, translating it automatically into PDDL syntax for planning purposes. By connecting system and product models with planning aspects, it ensures that changes in these models are quickly reflected in updated PDDL descriptions, facilitating efficient and adaptable planning processes. The workflow is validated within a use case from aircraft assembly.","sentences":["Manually creating Planning Domain Definition Language (PDDL) descriptions is difficult, error-prone, and requires extensive expert knowledge.","However, this knowledge is already embedded in engineering models and can be reused.","Therefore, this contribution presents a comprehensive workflow for the automated generation of PDDL descriptions from integrated system and product models.","The proposed workflow leverages Model-Based Systems Engineering (MBSE) to organize and manage system and product information, translating it automatically into PDDL syntax for planning purposes.","By connecting system and product models with planning aspects, it ensures that changes in these models are quickly reflected in updated PDDL descriptions, facilitating efficient and adaptable planning processes.","The workflow is validated within a use case from aircraft assembly."],"url":"http://arxiv.org/abs/2408.08145v1"}
{"created":"2024-08-15 13:28:18","title":"MIDAS: Multi-level Intent, Domain, And Slot Knowledge Distillation for Multi-turn NLU","abstract":"Although Large Language Models(LLMs) can generate coherent and contextually relevant text, they often struggle to recognise the intent behind the human user's query. Natural Language Understanding (NLU) models, however, interpret the purpose and key information of user's input to enable responsive interactions. Existing NLU models generally map individual utterances to a dual-level semantic frame, involving sentence-level intent and word-level slot labels. However, real-life conversations primarily consist of multi-turn conversations, involving the interpretation of complex and extended dialogues. Researchers encounter challenges addressing all facets of multi-turn dialogue conversations using a unified single NLU model. This paper introduces a novel approach, MIDAS, leveraging a multi-level intent, domain, and slot knowledge distillation for multi-turn NLU. To achieve this, we construct distinct teachers for varying levels of conversation knowledge, namely, sentence-level intent detection, word-level slot filling, and conversation-level domain classification. These teachers are then fine-tuned to acquire specific knowledge of their designated levels. A multi-teacher loss is proposed to facilitate the combination of these multi-level teachers, guiding a student model in multi-turn dialogue tasks. The experimental results demonstrate the efficacy of our model in improving the overall multi-turn conversation understanding, showcasing the potential for advancements in NLU models through the incorporation of multi-level dialogue knowledge distillation techniques.","sentences":["Although Large Language Models(LLMs) can generate coherent and contextually relevant text, they often struggle to recognise the intent behind the human user's query.","Natural Language Understanding (NLU) models, however, interpret the purpose and key information of user's input to enable responsive interactions.","Existing NLU models generally map individual utterances to a dual-level semantic frame, involving sentence-level intent and word-level slot labels.","However, real-life conversations primarily consist of multi-turn conversations, involving the interpretation of complex and extended dialogues.","Researchers encounter challenges addressing all facets of multi-turn dialogue conversations using a unified single NLU model.","This paper introduces a novel approach, MIDAS, leveraging a multi-level intent, domain, and slot knowledge distillation for multi-turn NLU.","To achieve this, we construct distinct teachers for varying levels of conversation knowledge, namely, sentence-level intent detection, word-level slot filling, and conversation-level domain classification.","These teachers are then fine-tuned to acquire specific knowledge of their designated levels.","A multi-teacher loss is proposed to facilitate the combination of these multi-level teachers, guiding a student model in multi-turn dialogue tasks.","The experimental results demonstrate the efficacy of our model in improving the overall multi-turn conversation understanding, showcasing the potential for advancements in NLU models through the incorporation of multi-level dialogue knowledge distillation techniques."],"url":"http://arxiv.org/abs/2408.08144v1"}
{"created":"2024-08-15 13:26:13","title":"Unlearnable Examples Detection via Iterative Filtering","abstract":"Deep neural networks are proven to be vulnerable to data poisoning attacks. Recently, a specific type of data poisoning attack known as availability attacks has led to the failure of data utilization for model learning by adding imperceptible perturbations to images. Consequently, it is quite beneficial and challenging to detect poisoned samples, also known as Unlearnable Examples (UEs), from a mixed dataset. In response, we propose an Iterative Filtering approach for UEs identification. This method leverages the distinction between the inherent semantic mapping rules and shortcuts, without the need for any additional information. We verify that when training a classifier on a mixed dataset containing both UEs and clean data, the model tends to quickly adapt to the UEs compared to the clean data. Due to the accuracy gaps between training with clean/poisoned samples, we employ a model to misclassify clean samples while correctly identifying the poisoned ones. The incorporation of additional classes and iterative refinement enhances the model's ability to differentiate between clean and poisoned samples. Extensive experiments demonstrate the superiority of our method over state-of-the-art detection approaches across various attacks, datasets, and poison ratios, significantly reducing the Half Total Error Rate (HTER) compared to existing methods.","sentences":["Deep neural networks are proven to be vulnerable to data poisoning attacks.","Recently, a specific type of data poisoning attack known as availability attacks has led to the failure of data utilization for model learning by adding imperceptible perturbations to images.","Consequently, it is quite beneficial and challenging to detect poisoned samples, also known as Unlearnable Examples (UEs), from a mixed dataset.","In response, we propose an Iterative Filtering approach for UEs identification.","This method leverages the distinction between the inherent semantic mapping rules and shortcuts, without the need for any additional information.","We verify that when training a classifier on a mixed dataset containing both UEs and clean data, the model tends to quickly adapt to the UEs compared to the clean data.","Due to the accuracy gaps between training with clean/poisoned samples, we employ a model to misclassify clean samples while correctly identifying the poisoned ones.","The incorporation of additional classes and iterative refinement enhances the model's ability to differentiate between clean and poisoned samples.","Extensive experiments demonstrate the superiority of our method over state-of-the-art detection approaches across various attacks, datasets, and poison ratios, significantly reducing the Half Total Error Rate (HTER) compared to existing methods."],"url":"http://arxiv.org/abs/2408.08143v1"}
{"created":"2024-08-15 13:23:59","title":"Impact of Comprehensive Data Preprocessing on Predictive Modelling of COVID-19 Mortality","abstract":"Accurate predictive models are crucial for analysing COVID-19 mortality trends. This study evaluates the impact of a custom data preprocessing pipeline on ten machine learning models predicting COVID-19 mortality using data from Our World in Data (OWID). Our pipeline differs from a standard preprocessing pipeline through four key steps. Firstly, it transforms weekly reported totals into daily updates, correcting reporting biases and providing more accurate estimates. Secondly, it uses localised outlier detection and processing to preserve data variance and enhance accuracy. Thirdly, it utilises computational dependencies among columns to ensure data consistency. Finally, it incorporates an iterative feature selection process to optimise the feature set and improve model performance. Results show a significant improvement with the custom pipeline: the MLP Regressor achieved a test RMSE of 66.556 and a test R-squared of 0.991, surpassing the DecisionTree Regressor from the standard pipeline, which had a test RMSE of 222.858 and a test R-squared of 0.817. These findings highlight the importance of tailored preprocessing techniques in enhancing predictive modelling accuracy for COVID-19 mortality. Although specific to this study, these methodologies offer valuable insights into diverse datasets and domains, improving predictive performance across various contexts.","sentences":["Accurate predictive models are crucial for analysing COVID-19 mortality trends.","This study evaluates the impact of a custom data preprocessing pipeline on ten machine learning models predicting COVID-19 mortality using data from Our World in Data (OWID).","Our pipeline differs from a standard preprocessing pipeline through four key steps.","Firstly, it transforms weekly reported totals into daily updates, correcting reporting biases and providing more accurate estimates.","Secondly, it uses localised outlier detection and processing to preserve data variance and enhance accuracy.","Thirdly, it utilises computational dependencies among columns to ensure data consistency.","Finally, it incorporates an iterative feature selection process to optimise the feature set and improve model performance.","Results show a significant improvement with the custom pipeline: the MLP Regressor achieved a test RMSE of 66.556 and a test R-squared of 0.991, surpassing the DecisionTree Regressor from the standard pipeline, which had a test RMSE of 222.858 and a test R-squared of 0.817.","These findings highlight the importance of tailored preprocessing techniques in enhancing predictive modelling accuracy for COVID-19 mortality.","Although specific to this study, these methodologies offer valuable insights into diverse datasets and domains, improving predictive performance across various contexts."],"url":"http://arxiv.org/abs/2408.08142v1"}
{"created":"2024-08-15 13:19:55","title":"Visual Integration of Static and Dynamic Software Analysis in Code Reviews via Software City Visualization","abstract":"Software visualization approaches for code reviews are often implemented as standalone applications, which use static code analysis. The goal is to visualize the structural changes introduced by a pull / merge request to facilitate the review process. In this way, for example, structural changes that hinder code evolution can be more easily identified, but understanding the changed program behavior is still mainly done by reading the code. For software visualization to be successful in code review, tools must be provided that go beyond an alternative representation of code changes and integrate well into the developers' daily workflow. In this paper, we report on the novel and in-progress design and implementation of a web-based approach capable of combining static and dynamic analysis data in software city visualizations. Our architectural tool design incorporates modern web technologies such as the integration into common Git hosting services. As a result, code reviewers can explore how the modified software evolves and execute its use cases, which is especially helpful for distributed software systems. In this context, developers can be directly linked from the Git hosting service's issue tracking system to the corresponding software city visualization. This approach eliminates the recurring action of manual data collection and setup. We implement our design by extending the web-based software visualization tool ExplorViz. We invite other researchers to extend our open source software and jointly research this approach. Video URL: https://youtu.be/DYxijdCEdrY","sentences":["Software visualization approaches for code reviews are often implemented as standalone applications, which use static code analysis.","The goal is to visualize the structural changes introduced by a pull / merge request to facilitate the review process.","In this way, for example, structural changes that hinder code evolution can be more easily identified, but understanding the changed program behavior is still mainly done by reading the code.","For software visualization to be successful in code review, tools must be provided that go beyond an alternative representation of code changes and integrate well into the developers' daily workflow.","In this paper, we report on the novel and in-progress design and implementation of a web-based approach capable of combining static and dynamic analysis data in software city visualizations.","Our architectural tool design incorporates modern web technologies such as the integration into common Git hosting services.","As a result, code reviewers can explore how the modified software evolves and execute its use cases, which is especially helpful for distributed software systems.","In this context, developers can be directly linked from the Git hosting service's issue tracking system to the corresponding software city visualization.","This approach eliminates the recurring action of manual data collection and setup.","We implement our design by extending the web-based software visualization tool ExplorViz.","We invite other researchers to extend our open source software and jointly research this approach.","Video URL: https://youtu.be/DYxijdCEdrY"],"url":"http://arxiv.org/abs/2408.08141v1"}
{"created":"2024-08-15 13:13:17","title":"Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attribution Explainability","abstract":"Deep neural network predictions are notoriously difficult to interpret. Feature attribution methods aim to explain these predictions by identifying the contribution of each input feature. Faithfulness, often evaluated using the area over the perturbation curve (AOPC), reflects feature attributions' accuracy in describing the internal mechanisms of deep neural networks. However, many studies rely on AOPC to compare faithfulness across different models, which we show can lead to false conclusions about models' faithfulness. Specifically, we find that AOPC is sensitive to variations in the model, resulting in unreliable cross-model comparisons. Moreover, AOPC scores are difficult to interpret in isolation without knowing the model-specific lower and upper limits. To address these issues, we propose a normalization approach, Normalized AOPC (NAOPC), enabling consistent cross-model evaluations and more meaningful interpretation of individual scores. Our experiments demonstrate that this normalization can radically change AOPC results, questioning the conclusions of earlier studies and offering a more robust framework for assessing feature attribution faithfulness.","sentences":["Deep neural network predictions are notoriously difficult to interpret.","Feature attribution methods aim to explain these predictions by identifying the contribution of each input feature.","Faithfulness, often evaluated using the area over the perturbation curve (AOPC), reflects feature attributions' accuracy in describing the internal mechanisms of deep neural networks.","However, many studies rely on AOPC to compare faithfulness across different models, which we show can lead to false conclusions about models' faithfulness.","Specifically, we find that AOPC is sensitive to variations in the model, resulting in unreliable cross-model comparisons.","Moreover, AOPC scores are difficult to interpret in isolation without knowing the model-specific lower and upper limits.","To address these issues, we propose a normalization approach, Normalized AOPC (NAOPC), enabling consistent cross-model evaluations and more meaningful interpretation of individual scores.","Our experiments demonstrate that this normalization can radically change AOPC results, questioning the conclusions of earlier studies and offering a more robust framework for assessing feature attribution faithfulness."],"url":"http://arxiv.org/abs/2408.08137v1"}
{"created":"2024-08-15 13:09:37","title":"CorrAdaptor: Adaptive Local Context Learning for Correspondence Pruning","abstract":"In the fields of computer vision and robotics, accurate pixel-level correspondences are essential for enabling advanced tasks such as structure-from-motion and simultaneous localization and mapping. Recent correspondence pruning methods usually focus on learning local consistency through k-nearest neighbors, which makes it difficult to capture robust context for each correspondence. We propose CorrAdaptor, a novel architecture that introduces a dual-branch structure capable of adaptively adjusting local contexts through both explicit and implicit local graph learning. Specifically, the explicit branch uses KNN-based graphs tailored for initial neighborhood identification, while the implicit branch leverages a learnable matrix to softly assign neighbors and adaptively expand the local context scope, significantly enhancing the model's robustness and adaptability to complex image variations. Moreover, we design a motion injection module to integrate motion consistency into the network to suppress the impact of outliers and refine local context learning, resulting in substantial performance improvements. The experimental results on extensive correspondence-based tasks indicate that our CorrAdaptor achieves state-of-the-art performance both qualitatively and quantitatively. The code and pre-trained models are available at https://github.com/TaoWangzj/CorrAdaptor.","sentences":["In the fields of computer vision and robotics, accurate pixel-level correspondences are essential for enabling advanced tasks such as structure-from-motion and simultaneous localization and mapping.","Recent correspondence pruning methods usually focus on learning local consistency through k-nearest neighbors, which makes it difficult to capture robust context for each correspondence.","We propose CorrAdaptor, a novel architecture that introduces a dual-branch structure capable of adaptively adjusting local contexts through both explicit and implicit local graph learning.","Specifically, the explicit branch uses KNN-based graphs tailored for initial neighborhood identification, while the implicit branch leverages a learnable matrix to softly assign neighbors and adaptively expand the local context scope, significantly enhancing the model's robustness and adaptability to complex image variations.","Moreover, we design a motion injection module to integrate motion consistency into the network to suppress the impact of outliers and refine local context learning, resulting in substantial performance improvements.","The experimental results on extensive correspondence-based tasks indicate that our CorrAdaptor achieves state-of-the-art performance both qualitatively and quantitatively.","The code and pre-trained models are available at https://github.com/TaoWangzj/CorrAdaptor."],"url":"http://arxiv.org/abs/2408.08134v1"}
{"created":"2024-08-15 13:07:51","title":"EXPLAIN, AGREE, LEARN: Scaling Learning for Neural Probabilistic Logic","abstract":"Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm by combining the perceptive and learning capabilities of neural networks with the robustness of probabilistic logic. Learning corresponds to likelihood optimization of the neural networks. However, to obtain the likelihood exactly, expensive probabilistic logic inference is required. To scale learning to more complex systems, we therefore propose to instead optimize a sampling based objective. We prove that the objective has a bounded error with respect to the likelihood, which vanishes when increasing the sample count. Furthermore, the error vanishes faster by exploiting a new concept of sample diversity. We then develop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective. EXPLAIN samples explanations for the data. AGREE reweighs each explanation in concordance with the neural component. LEARN uses the reweighed explanations as a signal for learning. In contrast to previous NeSy methods, EXAL can scale to larger problem sizes while retaining theoretical guarantees on the error. Experimentally, our theoretical claims are verified and EXAL outperforms recent NeSy methods when scaling up the MNIST addition and Warcraft pathfinding problems.","sentences":["Neural probabilistic logic systems follow the neuro-symbolic (NeSy) paradigm by combining the perceptive and learning capabilities of neural networks with the robustness of probabilistic logic.","Learning corresponds to likelihood optimization of the neural networks.","However, to obtain the likelihood exactly, expensive probabilistic logic inference is required.","To scale learning to more complex systems, we therefore propose to instead optimize a sampling based objective.","We prove that the objective has a bounded error with respect to the likelihood, which vanishes when increasing the sample count.","Furthermore, the error vanishes faster by exploiting a new concept of sample diversity.","We then develop the EXPLAIN, AGREE, LEARN (EXAL) method that uses this objective.","EXPLAIN samples explanations for the data.","AGREE reweighs each explanation in concordance with the neural component.","LEARN uses the reweighed explanations as a signal for learning.","In contrast to previous NeSy methods, EXAL can scale to larger problem sizes while retaining theoretical guarantees on the error.","Experimentally, our theoretical claims are verified and EXAL outperforms recent NeSy methods when scaling up the MNIST addition and Warcraft pathfinding problems."],"url":"http://arxiv.org/abs/2408.08133v1"}
{"created":"2024-08-15 13:07:25","title":"Heterogeneous System Design for Cell-Free Massive MIMO in Wideband Communications","abstract":"Cell-free massive multi-input multi-output (CFmMIMO) offers uniform service quality through distributed access points (APs), yet unresolved issues remain. This paper proposes a heterogeneous system design that goes beyond the original CFmMIMO architecture by exploiting the synergy of a base station (BS) and distributed APs. Users are categorized as near users (NUs) and far users (FUs) depending on their proximity to the BS. The BS serves the NUs, while the APs cater to the FUs. Through activating only the closest AP of each FU, the use of downlink pilots is enabled, thereby enhancing performance. This heterogeneous design outperforms other homogeneous massive MIMO configurations, demonstrating superior sum capacity while maintaining comparable user-experienced rates. Moreover, it lowers the costs associated with AP installations and reduces signaling overhead for the fronthaul network.","sentences":["Cell-free massive multi-input multi-output (CFmMIMO) offers uniform service quality through distributed access points (APs), yet unresolved issues remain.","This paper proposes a heterogeneous system design that goes beyond the original CFmMIMO architecture by exploiting the synergy of a base station (BS) and distributed APs.","Users are categorized as near users (NUs) and far users (FUs) depending on their proximity to the BS.","The BS serves the NUs, while the APs cater to the FUs.","Through activating only the closest AP of each FU, the use of downlink pilots is enabled, thereby enhancing performance.","This heterogeneous design outperforms other homogeneous massive MIMO configurations, demonstrating superior sum capacity while maintaining comparable user-experienced rates.","Moreover, it lowers the costs associated with AP installations and reduces signaling overhead for the fronthaul network."],"url":"http://arxiv.org/abs/2408.08132v1"}
{"created":"2024-08-15 13:06:49","title":"Detection and Impact of Debit/Credit Card Fraud: Victims' Experiences","abstract":"It might be intuitive to expect that small or reimbursed financial loss resulting from credit or debit card fraud would have low or no financial impact on victims. However, little is known about the extent to which financial fraud impacts victims psychologically, how victims detect the fraud, which detection methods are most efficient, and how the fraud detection and reporting processes can be improved. To answer these questions, we conducted a 150-participant survey of debit/credit card fraud victims in the US. Our results show that significantly more participants reported that they were impacted psychologically than financially. However, we found no relationship between the amount of direct financial loss and psychological impact, suggesting that people are at risk of being psychologically impacted regardless of the amount lost to fraud. Despite the fact that bank or card issuer notifications were related to faster detection of fraud, more participants reported detecting the fraud after reviewing their card or account statements rather than from notifications. This suggests that notifications may be underutilized. Finally, we provide a set of recommendations distilled from victims' experiences to improve the debit/credit card fraud detection and reporting processes.","sentences":["It might be intuitive to expect that small or reimbursed financial loss resulting from credit or debit card fraud would have low or no financial impact on victims.","However, little is known about the extent to which financial fraud impacts victims psychologically, how victims detect the fraud, which detection methods are most efficient, and how the fraud detection and reporting processes can be improved.","To answer these questions, we conducted a 150-participant survey of debit/credit card fraud victims in the US.","Our results show that significantly more participants reported that they were impacted psychologically than financially.","However, we found no relationship between the amount of direct financial loss and psychological impact, suggesting that people are at risk of being psychologically impacted regardless of the amount lost to fraud.","Despite the fact that bank or card issuer notifications were related to faster detection of fraud, more participants reported detecting the fraud after reviewing their card or account statements rather than from notifications.","This suggests that notifications may be underutilized.","Finally, we provide a set of recommendations distilled from victims' experiences to improve the debit/credit card fraud detection and reporting processes."],"url":"http://arxiv.org/abs/2408.08131v1"}
{"created":"2024-08-15 12:52:40","title":"The evolution of inharmonicity and noisiness in contemporary popular music","abstract":"Much of Western classical music uses instruments based on acoustic resonance. Such instruments produce harmonic or quasi-harmonic sounds. On the other hand, since the early 1970s, popular music has largely been produced in the recording studio. As a result, popular music is not bound to be based on harmonic or quasi-harmonic sounds. In this study, we use modified MPEG-7 features to explore and characterise the way in which the use of noise and inharmonicity has evolved in popular music since 1961. We set this evolution in the context of other broad categories of music, including Western classical piano music, Western classical orchestral music, and musique concr\\`ete. We propose new features that allow us to distinguish between inharmonicity resulting from noise and inharmonicity resulting from interactions between relatively discrete partials. When the history of contemporary popular music is viewed through the lens of these new features, we find that the period since 1961 can be divided into three phases. From 1961 to 1972, there was a steady increase in inharmonicity but no significant increase in noise. From 1972 to 1986, both inharmonicity and noise increased. Then, since 1986, there has been a steady decrease in both inharmonicity and noise to today's popular music which is significantly less noisy but more inharmonic than the music of the sixties. We relate these observed trends to the development of music production practice over the period and illustrate them with focused analyses of certain key artists and tracks.","sentences":["Much of Western classical music uses instruments based on acoustic resonance.","Such instruments produce harmonic or quasi-harmonic sounds.","On the other hand, since the early 1970s, popular music has largely been produced in the recording studio.","As a result, popular music is not bound to be based on harmonic or quasi-harmonic sounds.","In this study, we use modified MPEG-7 features to explore and characterise the way in which the use of noise and inharmonicity has evolved in popular music since 1961.","We set this evolution in the context of other broad categories of music, including Western classical piano music, Western classical orchestral music, and musique concr\\`ete.","We propose new features that allow us to distinguish between inharmonicity resulting from noise and inharmonicity resulting from interactions between relatively discrete partials.","When the history of contemporary popular music is viewed through the lens of these new features, we find that the period since 1961 can be divided into three phases.","From 1961 to 1972, there was a steady increase in inharmonicity but no significant increase in noise.","From 1972 to 1986, both inharmonicity and noise increased.","Then, since 1986, there has been a steady decrease in both inharmonicity and noise to today's popular music which is significantly less noisy but more inharmonic than the music of the sixties.","We relate these observed trends to the development of music production practice over the period and illustrate them with focused analyses of certain key artists and tracks."],"url":"http://arxiv.org/abs/2408.08127v1"}
{"created":"2024-08-15 12:52:06","title":"Decoding Memes: A Comparative Study of Machine Learning Models for Template Identification","abstract":"Image-with-text memes combine text with imagery to achieve comedy, but in today's world, they also play a pivotal role in online communication, influencing politics, marketing, and social norms. A \"meme template\" is a preexisting layout or format that is used to create memes. It typically includes specific visual elements, characters, or scenes with blank spaces or captions that can be customized, allowing users to easily create their versions of popular meme templates by adding personal or contextually relevant content. Despite extensive research on meme virality, the task of automatically identifying meme templates remains a challenge.   This paper presents a comprehensive comparison and evaluation of existing meme template identification methods, including both established approaches from the literature and novel techniques. We introduce a rigorous evaluation framework that not only assesses the ability of various methods to correctly identify meme templates but also tests their capacity to reject non-memes without false assignments. Our study involves extensive data collection from sites that provide meme annotations (Imgflip) and various social media platforms (Reddit, X, and Facebook) to ensure a diverse and representative dataset. We compare meme template identification methods, highlighting their strengths and limitations. These include supervised and unsupervised approaches, such as convolutional neural networks, distance-based classification, and density-based clustering. Our analysis helps researchers and practitioners choose suitable methods and points to future research directions in this evolving field.","sentences":["Image-with-text memes combine text with imagery to achieve comedy, but in today's world, they also play a pivotal role in online communication, influencing politics, marketing, and social norms.","A \"meme template\" is a preexisting layout or format that is used to create memes.","It typically includes specific visual elements, characters, or scenes with blank spaces or captions that can be customized, allowing users to easily create their versions of popular meme templates by adding personal or contextually relevant content.","Despite extensive research on meme virality, the task of automatically identifying meme templates remains a challenge.   ","This paper presents a comprehensive comparison and evaluation of existing meme template identification methods, including both established approaches from the literature and novel techniques.","We introduce a rigorous evaluation framework that not only assesses the ability of various methods to correctly identify meme templates but also tests their capacity to reject non-memes without false assignments.","Our study involves extensive data collection from sites that provide meme annotations (Imgflip) and various social media platforms (Reddit, X, and Facebook) to ensure a diverse and representative dataset.","We compare meme template identification methods, highlighting their strengths and limitations.","These include supervised and unsupervised approaches, such as convolutional neural networks, distance-based classification, and density-based clustering.","Our analysis helps researchers and practitioners choose suitable methods and points to future research directions in this evolving field."],"url":"http://arxiv.org/abs/2408.08126v1"}
{"created":"2024-08-15 12:51:57","title":"Category-Prompt Refined Feature Learning for Long-Tailed Multi-Label Image Classification","abstract":"Real-world data consistently exhibits a long-tailed distribution, often spanning multiple categories. This complexity underscores the challenge of content comprehension, particularly in scenarios requiring Long-Tailed Multi-Label image Classification (LTMLC). In such contexts, imbalanced data distribution and multi-object recognition pose significant hurdles. To address this issue, we propose a novel and effective approach for LTMLC, termed Category-Prompt Refined Feature Learning (CPRFL), utilizing semantic correlations between different categories and decoupling category-specific visual representations for each category. Specifically, CPRFL initializes category-prompts from the pretrained CLIP's embeddings and decouples category-specific visual representations through interaction with visual features, thereby facilitating the establishment of semantic correlations between the head and tail classes. To mitigate the visual-semantic domain bias, we design a progressive Dual-Path Back-Propagation mechanism to refine the prompts by progressively incorporating context-related visual information into prompts. Simultaneously, the refinement process facilitates the progressive purification of the category-specific visual representations under the guidance of the refined prompts. Furthermore, taking into account the negative-positive sample imbalance, we adopt the Asymmetric Loss as our optimization objective to suppress negative samples across all classes and potentially enhance the head-to-tail recognition performance. We validate the effectiveness of our method on two LTMLC benchmarks and extensive experiments demonstrate the superiority of our work over baselines.   The code is available at https://github.com/jiexuanyan/CPRFL.","sentences":["Real-world data consistently exhibits a long-tailed distribution, often spanning multiple categories.","This complexity underscores the challenge of content comprehension, particularly in scenarios requiring Long-Tailed Multi-Label image Classification (LTMLC).","In such contexts, imbalanced data distribution and multi-object recognition pose significant hurdles.","To address this issue, we propose a novel and effective approach for LTMLC, termed Category-Prompt Refined Feature Learning (CPRFL), utilizing semantic correlations between different categories and decoupling category-specific visual representations for each category.","Specifically, CPRFL initializes category-prompts from the pretrained CLIP's embeddings and decouples category-specific visual representations through interaction with visual features, thereby facilitating the establishment of semantic correlations between the head and tail classes.","To mitigate the visual-semantic domain bias, we design a progressive Dual-Path Back-Propagation mechanism to refine the prompts by progressively incorporating context-related visual information into prompts.","Simultaneously, the refinement process facilitates the progressive purification of the category-specific visual representations under the guidance of the refined prompts.","Furthermore, taking into account the negative-positive sample imbalance, we adopt the Asymmetric Loss as our optimization objective to suppress negative samples across all classes and potentially enhance the head-to-tail recognition performance.","We validate the effectiveness of our method on two LTMLC benchmarks and extensive experiments demonstrate the superiority of our work over baselines.   ","The code is available at https://github.com/jiexuanyan/CPRFL."],"url":"http://arxiv.org/abs/2408.08125v1"}
{"created":"2024-08-15 12:38:10","title":"The Unreasonable Effectiveness of Solving Inverse Problems with Neural Networks","abstract":"Finding model parameters from data is an essential task in science and engineering, from weather and climate forecasts to plasma control. Previous works have employed neural networks to greatly accelerate finding solutions to inverse problems. Of particular interest are end-to-end models which utilize differentiable simulations in order to backpropagate feedback from the simulated process to the network weights and enable roll-out of multiple time steps. So far, it has been assumed that, while model inference is faster than classical optimization, this comes at the cost of a decrease in solution accuracy. We show that this is generally not true. In fact, neural networks trained to learn solutions to inverse problems can find better solutions than classical optimizers even on their training set. To demonstrate this, we perform both a theoretical analysis as well an extensive empirical evaluation on challenging problems involving local minima, chaos, and zero-gradient regions. Our findings suggest an alternative use for neural networks: rather than generalizing to new data for fast inference, they can also be used to find better solutions on known data.","sentences":["Finding model parameters from data is an essential task in science and engineering, from weather and climate forecasts to plasma control.","Previous works have employed neural networks to greatly accelerate finding solutions to inverse problems.","Of particular interest are end-to-end models which utilize differentiable simulations in order to backpropagate feedback from the simulated process to the network weights and enable roll-out of multiple time steps.","So far, it has been assumed that, while model inference is faster than classical optimization, this comes at the cost of a decrease in solution accuracy.","We show that this is generally not true.","In fact, neural networks trained to learn solutions to inverse problems can find better solutions than classical optimizers even on their training set.","To demonstrate this, we perform both a theoretical analysis as well an extensive empirical evaluation on challenging problems involving local minima, chaos, and zero-gradient regions.","Our findings suggest an alternative use for neural networks: rather than generalizing to new data for fast inference, they can also be used to find better solutions on known data."],"url":"http://arxiv.org/abs/2408.08119v1"}
