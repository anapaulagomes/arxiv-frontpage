{"created":"2024-09-09 17:59:57","title":"Flash Cache: Reducing Bias in Radiance Cache Based Inverse Rendering","abstract":"State-of-the-art techniques for 3D reconstruction are largely based on volumetric scene representations, which require sampling multiple points to compute the color arriving along a ray. Using these representations for more general inverse rendering -- reconstructing geometry, materials, and lighting from observed images -- is challenging because recursively path-tracing such volumetric representations is expensive. Recent works alleviate this issue through the use of radiance caches: data structures that store the steady-state, infinite-bounce radiance arriving at any point from any direction. However, these solutions rely on approximations that introduce bias into the renderings and, more importantly, into the gradients used for optimization. We present a method that avoids these approximations while remaining computationally efficient. In particular, we leverage two techniques to reduce variance for unbiased estimators of the rendering equation: (1) an occlusion-aware importance sampler for incoming illumination and (2) a fast cache architecture that can be used as a control variate for the radiance from a high-quality, but more expensive, volumetric cache. We show that by removing these biases our approach improves the generality of radiance cache based inverse rendering, as well as increasing quality in the presence of challenging light transport effects such as specular reflections.","sentences":["State-of-the-art techniques for 3D reconstruction are largely based on volumetric scene representations, which require sampling multiple points to compute the color arriving along a ray.","Using these representations for more general inverse rendering -- reconstructing geometry, materials, and lighting from observed images -- is challenging because recursively path-tracing such volumetric representations is expensive.","Recent works alleviate this issue through the use of radiance caches: data structures that store the steady-state, infinite-bounce radiance arriving at any point from any direction.","However, these solutions rely on approximations that introduce bias into the renderings and, more importantly, into the gradients used for optimization.","We present a method that avoids these approximations while remaining computationally efficient.","In particular, we leverage two techniques to reduce variance for unbiased estimators of the rendering equation: (1) an occlusion-aware importance sampler for incoming illumination and (2) a fast cache architecture that can be used as a control variate for the radiance from a high-quality, but more expensive, volumetric cache.","We show that by removing these biases our approach improves the generality of radiance cache based inverse rendering, as well as increasing quality in the presence of challenging light transport effects such as specular reflections."],"url":"http://arxiv.org/abs/2409.05867v1"}
{"created":"2024-09-09 17:59:54","title":"A Framework for Evaluating PM2.5 Forecasts from the Perspective of Individual Decision Making","abstract":"Wildfire frequency is increasing as the climate changes, and the resulting air pollution poses health risks. Just as people routinely use weather forecasts to plan their activities around precipitation, reliable air quality forecasts could help individuals reduce their exposure to air pollution. In the present work, we evaluate several existing forecasts of fine particular matter (PM2.5) within the continental United States in the context of individual decision-making. Our comparison suggests there is meaningful room for improvement in air pollution forecasting, which might be realized by incorporating more data sources and using machine learning tools. To facilitate future machine learning development and benchmarking, we set up a framework to evaluate and compare air pollution forecasts for individual decision making. We introduce a new loss to capture decisions about when to use mitigation measures. We highlight the importance of visualizations when comparing forecasts. Finally, we provide code to download and compare archived forecast predictions.","sentences":["Wildfire frequency is increasing as the climate changes, and the resulting air pollution poses health risks.","Just as people routinely use weather forecasts to plan their activities around precipitation, reliable air quality forecasts could help individuals reduce their exposure to air pollution.","In the present work, we evaluate several existing forecasts of fine particular matter (PM2.5) within the continental United States in the context of individual decision-making.","Our comparison suggests there is meaningful room for improvement in air pollution forecasting, which might be realized by incorporating more data sources and using machine learning tools.","To facilitate future machine learning development and benchmarking, we set up a framework to evaluate and compare air pollution forecasts for individual decision making.","We introduce a new loss to capture decisions about when to use mitigation measures.","We highlight the importance of visualizations when comparing forecasts.","Finally, we provide code to download and compare archived forecast predictions."],"url":"http://arxiv.org/abs/2409.05866v1"}
{"created":"2024-09-09 17:59:50","title":"Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments","abstract":"Robot models, particularly those trained with large amounts of data, have recently shown a plethora of real-world manipulation and navigation capabilities. Several independent efforts have shown that given sufficient training data in an environment, robot policies can generalize to demonstrated variations in that environment. However, needing to finetune robot models to every new environment stands in stark contrast to models in language or vision that can be deployed zero-shot for open-world problems. In this work, we present Robot Utility Models (RUMs), a framework for training and deploying zero-shot robot policies that can directly generalize to new environments without any finetuning. To create RUMs efficiently, we develop new tools to quickly collect data for mobile manipulation tasks, integrate such data into a policy with multi-modal imitation learning, and deploy policies on-device on Hello Robot Stretch, a cheap commodity robot, with an external mLLM verifier for retrying. We train five such utility models for opening cabinet doors, opening drawers, picking up napkins, picking up paper bags, and reorienting fallen objects. Our system, on average, achieves 90% success rate in unseen, novel environments interacting with unseen objects. Moreover, the utility models can also succeed in different robot and camera set-ups with no further data, training, or fine-tuning. Primary among our lessons are the importance of training data over training algorithm and policy class, guidance about data scaling, necessity for diverse yet high-quality demonstrations, and a recipe for robot introspection and retrying to improve performance on individual environments. Our code, data, models, hardware designs, as well as our experiment and deployment videos are open sourced and can be found on our project website: https://robotutilitymodels.com","sentences":["Robot models, particularly those trained with large amounts of data, have recently shown a plethora of real-world manipulation and navigation capabilities.","Several independent efforts have shown that given sufficient training data in an environment, robot policies can generalize to demonstrated variations in that environment.","However, needing to finetune robot models to every new environment stands in stark contrast to models in language or vision that can be deployed zero-shot for open-world problems.","In this work, we present Robot Utility Models (RUMs), a framework for training and deploying zero-shot robot policies that can directly generalize to new environments without any finetuning.","To create RUMs efficiently, we develop new tools to quickly collect data for mobile manipulation tasks, integrate such data into a policy with multi-modal imitation learning, and deploy policies on-device on Hello Robot Stretch, a cheap commodity robot, with an external mLLM verifier for retrying.","We train five such utility models for opening cabinet doors, opening drawers, picking up napkins, picking up paper bags, and reorienting fallen objects.","Our system, on average, achieves 90% success rate in unseen, novel environments interacting with unseen objects.","Moreover, the utility models can also succeed in different robot and camera set-ups with no further data, training, or fine-tuning.","Primary among our lessons are the importance of training data over training algorithm and policy class, guidance about data scaling, necessity for diverse yet high-quality demonstrations, and a recipe for robot introspection and retrying to improve performance on individual environments.","Our code, data, models, hardware designs, as well as our experiment and deployment videos are open sourced and can be found on our project website: https://robotutilitymodels.com"],"url":"http://arxiv.org/abs/2409.05865v1"}
{"created":"2024-09-09 17:59:45","title":"Neural MP: A Generalist Neural Motion Planner","abstract":"The current paradigm for motion planning generates solutions from scratch for every new problem, which consumes significant amounts of time and computational resources. For complex, cluttered scenes, motion planning approaches can often take minutes to produce a solution, while humans are able to accurately and safely reach any goal in seconds by leveraging their prior experience. We seek to do the same by applying data-driven learning at scale to the problem of motion planning. Our approach builds a large number of complex scenes in simulation, collects expert data from a motion planner, then distills it into a reactive generalist policy. We then combine this with lightweight optimization to obtain a safe path for real world deployment. We perform a thorough evaluation of our method on 64 motion planning tasks across four diverse environments with randomized poses, scenes and obstacles, in the real world, demonstrating an improvement of 23%, 17% and 79% motion planning success rate over state of the art sampling, optimization and learning based planning methods. Video results available at mihdalal.github.io/neuralmotionplanner","sentences":["The current paradigm for motion planning generates solutions from scratch for every new problem, which consumes significant amounts of time and computational resources.","For complex, cluttered scenes, motion planning approaches can often take minutes to produce a solution, while humans are able to accurately and safely reach any goal in seconds by leveraging their prior experience.","We seek to do the same by applying data-driven learning at scale to the problem of motion planning.","Our approach builds a large number of complex scenes in simulation, collects expert data from a motion planner, then distills it into a reactive generalist policy.","We then combine this with lightweight optimization to obtain a safe path for real world deployment.","We perform a thorough evaluation of our method on 64 motion planning tasks across four diverse environments with randomized poses, scenes and obstacles, in the real world, demonstrating an improvement of 23%, 17% and 79% motion planning success rate over state of the art sampling, optimization and learning based planning methods.","Video results available at mihdalal.github.io/neuralmotionplanner"],"url":"http://arxiv.org/abs/2409.05864v1"}
{"created":"2024-09-09 17:59:15","title":"Promptable Closed-loop Traffic Simulation","abstract":"Simulation stands as a cornerstone for safe and efficient autonomous driving development. At its core a simulation system ought to produce realistic, reactive, and controllable traffic patterns. In this paper, we propose ProSim, a multimodal promptable closed-loop traffic simulation framework. ProSim allows the user to give a complex set of numerical, categorical or textual prompts to instruct each agent's behavior and intention. ProSim then rolls out a traffic scenario in a closed-loop manner, modeling each agent's interaction with other traffic participants. Our experiments show that ProSim achieves high prompt controllability given different user prompts, while reaching competitive performance on the Waymo Sim Agents Challenge when no prompt is given. To support research on promptable traffic simulation, we create ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with over 10M text prompts for over 520k real-world driving scenarios. We will release code of ProSim as well as data and labeling tools of ProSim-Instruct-520k at https://ariostgx.github.io/ProSim.","sentences":["Simulation stands as a cornerstone for safe and efficient autonomous driving development.","At its core a simulation system ought to produce realistic, reactive, and controllable traffic patterns.","In this paper, we propose ProSim, a multimodal promptable closed-loop traffic simulation framework.","ProSim allows the user to give a complex set of numerical, categorical or textual prompts to instruct each agent's behavior and intention.","ProSim then rolls out a traffic scenario in a closed-loop manner, modeling each agent's interaction with other traffic participants.","Our experiments show that ProSim achieves high prompt controllability given different user prompts, while reaching competitive performance on the Waymo Sim Agents Challenge when no prompt is given.","To support research on promptable traffic simulation, we create ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with over 10M text prompts for over 520k real-world driving scenarios.","We will release code of ProSim as well as data and labeling tools of ProSim-Instruct-520k at https://ariostgx.github.io/ProSim."],"url":"http://arxiv.org/abs/2409.05863v1"}
{"created":"2024-09-09 17:59:13","title":"Evaluating Multiview Object Consistency in Humans and Image Models","abstract":"We introduce a benchmark to directly evaluate the alignment between human observers and vision models on a 3D shape inference task. We leverage an experimental design from the cognitive sciences which requires zero-shot visual inferences about object shape: given a set of images, participants identify which contain the same/different objects, despite considerable viewpoint variation. We draw from a diverse range of images that include common objects (e.g., chairs) as well as abstract shapes (i.e., procedurally generated `nonsense' objects). After constructing over 2000 unique image sets, we administer these tasks to human participants, collecting 35K trials of behavioral data from over 500 participants. This includes explicit choice behaviors as well as intermediate measures, such as reaction time and gaze data. We then evaluate the performance of common vision models (e.g., DINOv2, MAE, CLIP). We find that humans outperform all models by a wide margin. Using a multi-scale evaluation approach, we identify underlying similarities and differences between models and humans: while human-model performance is correlated, humans allocate more time/processing on challenging trials. All images, data, and code can be accessed via our project page.","sentences":["We introduce a benchmark to directly evaluate the alignment between human observers and vision models on a 3D shape inference task.","We leverage an experimental design from the cognitive sciences which requires zero-shot visual inferences about object shape: given a set of images, participants identify which contain the same/different objects, despite considerable viewpoint variation.","We draw from a diverse range of images that include common objects (e.g., chairs) as well as abstract shapes (i.e., procedurally generated `nonsense' objects).","After constructing over 2000 unique image sets, we administer these tasks to human participants, collecting 35K trials of behavioral data from over 500 participants.","This includes explicit choice behaviors as well as intermediate measures, such as reaction time and gaze data.","We then evaluate the performance of common vision models (e.g., DINOv2, MAE, CLIP).","We find that humans outperform all models by a wide margin.","Using a multi-scale evaluation approach, we identify underlying similarities and differences between models and humans: while human-model performance is correlated, humans allocate more time/processing on challenging trials.","All images, data, and code can be accessed via our project page."],"url":"http://arxiv.org/abs/2409.05862v1"}
{"created":"2024-09-09 17:45:45","title":"LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation","abstract":"Despite the promising performance of current video segmentation models on existing benchmarks, these models still struggle with complex scenes. In this paper, we introduce the 6th Large-scale Video Object Segmentation (LSVOS) challenge in conjunction with ECCV 2024 workshop. This year's challenge includes two tasks: Video Object Segmentation (VOS) and Referring Video Object Segmentation (RVOS). In this year, we replace the classic YouTube-VOS and YouTube-RVOS benchmark with latest datasets MOSE, LVOS, and MeViS to assess VOS under more challenging complex environments. This year's challenge attracted 129 registered teams from more than 20 institutes across over 8 countries. This report include the challenge and dataset introduction, and the methods used by top 7 teams in two tracks. More details can be found in our homepage https://lsvos.github.io/.","sentences":["Despite the promising performance of current video segmentation models on existing benchmarks, these models still struggle with complex scenes.","In this paper, we introduce the 6th Large-scale Video Object Segmentation (LSVOS) challenge in conjunction with ECCV 2024 workshop.","This year's challenge includes two tasks: Video Object Segmentation (VOS) and Referring Video Object Segmentation (RVOS).","In this year, we replace the classic YouTube-VOS and YouTube-RVOS benchmark with latest datasets MOSE, LVOS, and MeViS to assess VOS under more challenging complex environments.","This year's challenge attracted 129 registered teams from more than 20 institutes across over 8 countries.","This report include the challenge and dataset introduction, and the methods used by top 7 teams in two tracks.","More details can be found in our homepage https://lsvos.github.io/."],"url":"http://arxiv.org/abs/2409.05847v1"}
{"created":"2024-09-09 17:45:23","title":"Optimizing Vehicular Users Association in Urban Mobile Networks","abstract":"This study aims to optimize vehicular user association to base stations in a mobile network. We propose an efficient heuristic solution that considers the base station average handover frequency, the channel quality indicator, and bandwidth capacity. We evaluate this solution using real-world base station locations from S\\~ao Paulo, Brazil, and the SUMO mobility simulator. We compare our approach against a state of the art solution which uses route prediction, maintaining or surpassing the provided quality of service with the same number of handover operations. Additionally, the proposed solution reduces the execution time by more than 80\\% compared to an exact method, while achieving optimal solutions.","sentences":["This study aims to optimize vehicular user association to base stations in a mobile network.","We propose an efficient heuristic solution that considers the base station average handover frequency, the channel quality indicator, and bandwidth capacity.","We evaluate this solution using real-world base station locations from S\\~ao Paulo, Brazil, and the SUMO mobility simulator.","We compare our approach against a state of the art solution which uses route prediction, maintaining or surpassing the provided quality of service with the same number of handover operations.","Additionally, the proposed solution reduces the execution time by more than 80\\% compared to an exact method, while achieving optimal solutions."],"url":"http://arxiv.org/abs/2409.05845v1"}
{"created":"2024-09-09 17:44:00","title":"MMEvol: Empowering Multimodal Large Language Models with Evol-Instruct","abstract":"The development of Multimodal Large Language Models (MLLMs) has seen significant advancements. However, the quantity and quality of multimodal instruction data have emerged as significant bottlenecks in their progress. Manually creating multimodal instruction data is both time-consuming and inefficient, posing challenges in producing instructions of high complexity. Moreover, distilling instruction data from black-box commercial models (e.g., GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains performance to that of these models. The challenge of curating diverse and complex instruction data remains substantial. We propose MMEvol, a novel multimodal instruction data evolution framework that combines fine-grained perception evolution, cognitive reasoning evolution, and interaction evolution. This iterative approach breaks through data quality bottlenecks to generate a complex and diverse image-text instruction dataset, thereby empowering MLLMs with enhanced capabilities. Beginning with an initial set of instructions, SEED-163K, we utilize MMEvol to systematically broadens the diversity of instruction types, integrates reasoning steps to enhance cognitive capabilities, and extracts detailed information from images to improve visual understanding and robustness. To comprehensively evaluate the effectiveness of our data, we train LLaVA-NeXT using the evolved data and conduct experiments across 13 vision-language tasks. Compared to the baseline trained with seed data, our approach achieves an average accuracy improvement of 3.1 points and reaches state-of-the-art (SOTA) performance on 9 of these tasks.","sentences":["The development of Multimodal Large Language Models (MLLMs) has seen significant advancements.","However, the quantity and quality of multimodal instruction data have emerged as significant bottlenecks in their progress.","Manually creating multimodal instruction data is both time-consuming and inefficient, posing challenges in producing instructions of high complexity.","Moreover, distilling instruction data from black-box commercial models (e.g., GPT-4o, GPT-4V) often results in simplistic instruction data, which constrains performance to that of these models.","The challenge of curating diverse and complex instruction data remains substantial.","We propose MMEvol, a novel multimodal instruction data evolution framework that combines fine-grained perception evolution, cognitive reasoning evolution, and interaction evolution.","This iterative approach breaks through data quality bottlenecks to generate a complex and diverse image-text instruction dataset, thereby empowering MLLMs with enhanced capabilities.","Beginning with an initial set of instructions, SEED-163K, we utilize MMEvol to systematically broadens the diversity of instruction types, integrates reasoning steps to enhance cognitive capabilities, and extracts detailed information from images to improve visual understanding and robustness.","To comprehensively evaluate the effectiveness of our data, we train LLaVA-NeXT using the evolved data and conduct experiments across 13 vision-language tasks.","Compared to the baseline trained with seed data, our approach achieves an average accuracy improvement of 3.1 points and reaches state-of-the-art (SOTA) performance on 9 of these tasks."],"url":"http://arxiv.org/abs/2409.05840v1"}
{"created":"2024-09-09 17:43:05","title":"Fast Generation of Custom Floating-Point Spatial Filters on FPGAs","abstract":"Convolutional Neural Networks (CNNs) have been utilised in many image and video processing applications. The convolution operator, also known as a spatial filter, is usually a linear operation, but this linearity compromises essential features and details inherent in the non-linearity present in many applications. However, due to its slow processing, the use of a nonlinear spatial filter is a significant bottleneck in many software applications. Further, due to their complexity, they are difficult to accelerate in FPGA or VLSI architectures. This paper presents novel FPGA implementations of linear and nonlinear spatial filters. More specifically, the arithmetic computations are carried out in custom floating-point, enabling a tradeoff of precision and hardware compactness, reducing algorithm development time. Further, we show that it is possible to process video at a resolution of 1080p with a frame rate of 60 frames per second, using a low-cost FPGA board. Finally, we show that using a domain-specific language will allow the rapid prototyping of image processing algorithms in custom floating-point arithmetic, allowing non-experts to quickly develop real-time video processing applications.","sentences":["Convolutional Neural Networks (CNNs) have been utilised in many image and video processing applications.","The convolution operator, also known as a spatial filter, is usually a linear operation, but this linearity compromises essential features and details inherent in the non-linearity present in many applications.","However, due to its slow processing, the use of a nonlinear spatial filter is a significant bottleneck in many software applications.","Further, due to their complexity, they are difficult to accelerate in FPGA or VLSI architectures.","This paper presents novel FPGA implementations of linear and nonlinear spatial filters.","More specifically, the arithmetic computations are carried out in custom floating-point, enabling a tradeoff of precision and hardware compactness, reducing algorithm development time.","Further, we show that it is possible to process video at a resolution of 1080p with a frame rate of 60 frames per second, using a low-cost FPGA board.","Finally, we show that using a domain-specific language will allow the rapid prototyping of image processing algorithms in custom floating-point arithmetic, allowing non-experts to quickly develop real-time video processing applications."],"url":"http://arxiv.org/abs/2409.05837v1"}
{"created":"2024-09-09 17:40:30","title":"Vision-Driven 2D Supervised Fine-Tuning Framework for Bird's Eye View Perception","abstract":"Visual bird's eye view (BEV) perception, due to its excellent perceptual capabilities, is progressively replacing costly LiDAR-based perception systems, especially in the realm of urban intelligent driving. However, this type of perception still relies on LiDAR data to construct ground truth databases, a process that is both cumbersome and time-consuming. Moreover, most massproduced autonomous driving systems are only equipped with surround camera sensors and lack LiDAR data for precise annotation. To tackle this challenge, we propose a fine-tuning method for BEV perception network based on visual 2D semantic perception, aimed at enhancing the model's generalization capabilities in new scene data. Considering the maturity and development of 2D perception technologies, our method significantly reduces the dependency on high-cost BEV ground truths and shows promising industrial application prospects. Extensive experiments and comparative analyses conducted on the nuScenes and Waymo public datasets demonstrate the effectiveness of our proposed method.","sentences":["Visual bird's eye view (BEV) perception, due to its excellent perceptual capabilities, is progressively replacing costly LiDAR-based perception systems, especially in the realm of urban intelligent driving.","However, this type of perception still relies on LiDAR data to construct ground truth databases, a process that is both cumbersome and time-consuming.","Moreover, most massproduced autonomous driving systems are only equipped with surround camera sensors and lack LiDAR data for precise annotation.","To tackle this challenge, we propose a fine-tuning method for BEV perception network based on visual 2D semantic perception, aimed at enhancing the model's generalization capabilities in new scene data.","Considering the maturity and development of 2D perception technologies, our method significantly reduces the dependency on high-cost BEV ground truths and shows promising industrial application prospects.","Extensive experiments and comparative analyses conducted on the nuScenes and Waymo public datasets demonstrate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2409.05834v1"}
{"created":"2024-09-09 17:38:18","title":"The Quest to Build Trust Earlier in Digital Design","abstract":"The ever-rising complexity of computer systems presents challenges for maintaining security and trust throughout their lifetime. As hardware forms the foundation of a secure system, we need tools and techniques that support computer hardware engineers to improve trust and help them address security concerns. This paper highlights a vision for tools and techniques to enhance the security of digital hardware in earlier stages of the digital design process, especially during design with hardware description languages. We discuss the challenges that design teams face and explore some recent literature on understanding, identifying, and mitigating hardware security weaknesses as early as possible. We highlight the opportunities that emerge with open-source hardware development and sketch some open questions that guide ongoing research in this domain.","sentences":["The ever-rising complexity of computer systems presents challenges for maintaining security and trust throughout their lifetime.","As hardware forms the foundation of a secure system, we need tools and techniques that support computer hardware engineers to improve trust and help them address security concerns.","This paper highlights a vision for tools and techniques to enhance the security of digital hardware in earlier stages of the digital design process, especially during design with hardware description languages.","We discuss the challenges that design teams face and explore some recent literature on understanding, identifying, and mitigating hardware security weaknesses as early as possible.","We highlight the opportunities that emerge with open-source hardware development and sketch some open questions that guide ongoing research in this domain."],"url":"http://arxiv.org/abs/2409.05832v1"}
{"created":"2024-09-09 17:36:39","title":"Applying Attribution Explanations in Truth-Discovery Quantitative Bipolar Argumentation Frameworks","abstract":"Explaining the strength of arguments under gradual semantics is receiving increasing attention. For example, various studies in the literature offer explanations by computing the attribution scores of arguments or edges in Quantitative Bipolar Argumentation Frameworks (QBAFs). These explanations, known as Argument Attribution Explanations (AAEs) and Relation Attribution Explanations (RAEs), commonly employ removal-based and Shapley-based techniques for computing the attribution scores. While AAEs and RAEs have proven useful in several applications with acyclic QBAFs, they remain largely unexplored for cyclic QBAFs. Furthermore, existing applications tend to focus solely on either AAEs or RAEs, but do not compare them directly. In this paper, we apply both AAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess the trustworthiness of sources (e.g., websites) and their claims (e.g., the severity of a virus), and feature complex cycles. We find that both AAEs and RAEs can provide interesting explanations and can give non-trivial and surprising insights.","sentences":["Explaining the strength of arguments under gradual semantics is receiving increasing attention.","For example, various studies in the literature offer explanations by computing the attribution scores of arguments or edges in Quantitative Bipolar Argumentation Frameworks (QBAFs).","These explanations, known as Argument Attribution Explanations (AAEs) and Relation Attribution Explanations (RAEs), commonly employ removal-based and Shapley-based techniques for computing the attribution scores.","While AAEs and RAEs have proven useful in several applications with acyclic QBAFs, they remain largely unexplored for cyclic QBAFs.","Furthermore, existing applications tend to focus solely on either AAEs or RAEs, but do not compare them directly.","In this paper, we apply both AAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess the trustworthiness of sources (e.g., websites) and their claims (e.g., the severity of a virus), and feature complex cycles.","We find that both AAEs and RAEs can provide interesting explanations and can give non-trivial and surprising insights."],"url":"http://arxiv.org/abs/2409.05831v1"}
{"created":"2024-09-09 17:30:20","title":"Are Large Language Models a Threat to Programming Platforms? An Exploratory Study","abstract":"Competitive programming platforms like LeetCode, Codeforces, and HackerRank evaluate programming skills, often used by recruiters for screening. With the rise of advanced Large Language Models (LLMs) such as ChatGPT, Gemini, and Meta AI, their problem-solving ability on these platforms needs assessment. This study explores LLMs' ability to tackle diverse programming challenges across platforms with varying difficulty, offering insights into their real-time and offline performance and comparing them with human programmers.   We tested 98 problems from LeetCode, 126 from Codeforces, covering 15 categories. Nine online contests from Codeforces and LeetCode were conducted, along with two certification tests on HackerRank, to assess real-time performance. Prompts and feedback mechanisms were used to guide LLMs, and correlations were explored across different scenarios.   LLMs, like ChatGPT (71.43% success on LeetCode), excelled in LeetCode and HackerRank certifications but struggled in virtual contests, particularly on Codeforces. They performed better than users in LeetCode archives, excelling in time and memory efficiency but underperforming in harder Codeforces contests. While not immediately threatening, LLMs performance on these platforms is concerning, and future improvements will need addressing.","sentences":["Competitive programming platforms like LeetCode, Codeforces, and HackerRank evaluate programming skills, often used by recruiters for screening.","With the rise of advanced Large Language Models (LLMs) such as ChatGPT, Gemini, and Meta AI, their problem-solving ability on these platforms needs assessment.","This study explores LLMs' ability to tackle diverse programming challenges across platforms with varying difficulty, offering insights into their real-time and offline performance and comparing them with human programmers.   ","We tested 98 problems from LeetCode, 126 from Codeforces, covering 15 categories.","Nine online contests from Codeforces and LeetCode were conducted, along with two certification tests on HackerRank, to assess real-time performance.","Prompts and feedback mechanisms were used to guide LLMs, and correlations were explored across different scenarios.   ","LLMs, like ChatGPT (71.43% success on LeetCode), excelled in LeetCode and HackerRank certifications but struggled in virtual contests, particularly on Codeforces.","They performed better than users in LeetCode archives, excelling in time and memory efficiency but underperforming in harder Codeforces contests.","While not immediately threatening, LLMs performance on these platforms is concerning, and future improvements will need addressing."],"url":"http://arxiv.org/abs/2409.05824v1"}
{"created":"2024-09-09 17:28:57","title":"GASP: Gaussian Splatting for Physic-Based Simulations","abstract":"Physics simulation is paramount for modeling and utilization of 3D scenes in various real-world applications. However, its integration with state-of-the-art 3D scene rendering techniques such as Gaussian Splatting (GS) remains challenging. Existing models use additional meshing mechanisms, including triangle or tetrahedron meshing, marching cubes, or cage meshes. As an alternative, we can modify the physics grounded Newtonian dynamics to align with 3D Gaussian components. Current models take the first-order approximation of a deformation map, which locally approximates the dynamics by linear transformations. In contrast, our Gaussian Splatting for Physics-Based Simulations (GASP) model uses such a map (without any modifications) and flat Gaussian distributions, which are parameterized by three points (mesh faces). Subsequently, each 3D point (mesh face node) is treated as a discrete entity within a 3D space. Consequently, the problem of modeling Gaussian components is reduced to working with 3D points. Additionally, the information on mesh faces can be used to incorporate further properties into the physics model, facilitating the use of triangles. Resulting solution can be integrated into any physics engine that can be treated as a black box. As demonstrated in our studies, the proposed model exhibits superior performance on a diverse range of benchmark datasets designed for 3D object rendering.","sentences":["Physics simulation is paramount for modeling and utilization of 3D scenes in various real-world applications.","However, its integration with state-of-the-art 3D scene rendering techniques such as Gaussian Splatting (GS) remains challenging.","Existing models use additional meshing mechanisms, including triangle or tetrahedron meshing, marching cubes, or cage meshes.","As an alternative, we can modify the physics grounded Newtonian dynamics to align with 3D Gaussian components.","Current models take the first-order approximation of a deformation map, which locally approximates the dynamics by linear transformations.","In contrast, our Gaussian Splatting for Physics-Based Simulations (GASP) model uses such a map (without any modifications) and flat Gaussian distributions, which are parameterized by three points (mesh faces).","Subsequently, each 3D point (mesh face node) is treated as a discrete entity within a 3D space.","Consequently, the problem of modeling Gaussian components is reduced to working with 3D points.","Additionally, the information on mesh faces can be used to incorporate further properties into the physics model, facilitating the use of triangles.","Resulting solution can be integrated into any physics engine that can be treated as a black box.","As demonstrated in our studies, the proposed model exhibits superior performance on a diverse range of benchmark datasets designed for 3D object rendering."],"url":"http://arxiv.org/abs/2409.05819v1"}
{"created":"2024-09-09 17:23:39","title":"VFA: Vision Frequency Analysis of Foundation Models and Human","abstract":"Machine learning models often struggle with distribution shifts in real-world scenarios, whereas humans exhibit robust adaptation. Models that better align with human perception may achieve higher out-of-distribution generalization. In this study, we investigate how various characteristics of large-scale computer vision models influence their alignment with human capabilities and robustness. Our findings indicate that increasing model and data size and incorporating rich semantic information and multiple modalities enhance models' alignment with human perception and their overall robustness. Our empirical analysis demonstrates a strong correlation between out-of-distribution accuracy and human alignment.","sentences":["Machine learning models often struggle with distribution shifts in real-world scenarios, whereas humans exhibit robust adaptation.","Models that better align with human perception may achieve higher out-of-distribution generalization.","In this study, we investigate how various characteristics of large-scale computer vision models influence their alignment with human capabilities and robustness.","Our findings indicate that increasing model and data size and incorporating rich semantic information and multiple modalities enhance models' alignment with human perception and their overall robustness.","Our empirical analysis demonstrates a strong correlation between out-of-distribution accuracy and human alignment."],"url":"http://arxiv.org/abs/2409.05817v1"}
{"created":"2024-09-09 17:23:29","title":"Improving Pretraining Data Using Perplexity Correlations","abstract":"Quality pretraining data is often seen as the key to high-performance language models. However, progress in understanding pretraining data has been slow due to the costly pretraining runs required for data selection experiments. We present a framework that avoids these costs and selects high-quality pretraining data without any LLM training of our own. Our work is based on a simple observation: LLM losses on many pretraining texts are correlated with downstream benchmark performance, and selecting high-correlation documents is an effective pretraining data selection method. We build a new statistical framework for data selection centered around estimates of perplexity-benchmark correlations and perform data selection using a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of thousands of web domains. In controlled pretraining experiments at the 160M parameter scale on 8 benchmarks, our approach outperforms DSIR on every benchmark, while matching the best data selector found in DataComp-LM, a hand-engineered bigram classifier.","sentences":["Quality pretraining data is often seen as the key to high-performance language models.","However, progress in understanding pretraining data has been slow due to the costly pretraining runs required for data selection experiments.","We present a framework that avoids these costs and selects high-quality pretraining data without any LLM training of our own.","Our work is based on a simple observation: LLM losses on many pretraining texts are correlated with downstream benchmark performance, and selecting high-correlation documents is an effective pretraining data selection method.","We build a new statistical framework for data selection centered around estimates of perplexity-benchmark correlations and perform data selection using a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of thousands of web domains.","In controlled pretraining experiments at the 160M parameter scale on 8 benchmarks, our approach outperforms DSIR on every benchmark, while matching the best data selector found in DataComp-LM, a hand-engineered bigram classifier."],"url":"http://arxiv.org/abs/2409.05816v1"}
{"created":"2024-09-09 17:17:25","title":"Learning control of underactuated double pendulum with Model-Based Reinforcement Learning","abstract":"This report describes our proposed solution for the second AI Olympics competition held at IROS 2024. Our solution is based on a recent Model-Based Reinforcement Learning algorithm named MC-PILCO. Besides briefly reviewing the algorithm, we discuss the most critical aspects of the MC-PILCO implementation in the tasks at hand.","sentences":["This report describes our proposed solution for the second AI Olympics competition held at IROS 2024.","Our solution is based on a recent Model-Based Reinforcement Learning algorithm named MC-PILCO.","Besides briefly reviewing the algorithm, we discuss the most critical aspects of the MC-PILCO implementation in the tasks at hand."],"url":"http://arxiv.org/abs/2409.05811v1"}
{"created":"2024-09-09 17:15:54","title":"State estimation of timed automata under partial observation [Draft version]","abstract":"In this paper, we consider partially observable timed automata endowed with a single clock. A time interval is associated with each transition specifying at which clock values it may occur. In addition, a resetting condition associated to a transition specifies how the clock value is updated upon its occurrence. This work deals with the estimation of the current state given a timed observation, i.e., a succession of pairs of an observable event and the time instant at which the event has occurred. The problem of state reachability in the timed automaton is reduced to the reachability analysis of the associated zone automaton, which provides a purely discrete event description of the behaviour of the timed automaton. An algorithm is formulated to provide an offline approach for state estimation of a timed automaton based on the assumption that the clock is reset upon the occurrence of each observable transition.","sentences":["In this paper, we consider partially observable timed automata endowed with a single clock.","A time interval is associated with each transition specifying at which clock values it may occur.","In addition, a resetting condition associated to a transition specifies how the clock value is updated upon its occurrence.","This work deals with the estimation of the current state given a timed observation, i.e., a succession of pairs of an observable event and the time instant at which the event has occurred.","The problem of state reachability in the timed automaton is reduced to the reachability analysis of the associated zone automaton, which provides a purely discrete event description of the behaviour of the timed automaton.","An algorithm is formulated to provide an offline approach for state estimation of a timed automaton based on the assumption that the clock is reset upon the occurrence of each observable transition."],"url":"http://arxiv.org/abs/2409.05810v1"}
{"created":"2024-09-09 17:12:40","title":"The Future of Software Testing: AI-Powered Test Case Generation and Validation","abstract":"Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release. Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention. These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction. The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges. AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase. This approach enhances regression testing efficiency while expanding overall test coverage. Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases. This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes. It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight. Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems.","sentences":["Software testing is a crucial phase in the software development lifecycle (SDLC), ensuring that products meet necessary functional, performance, and quality benchmarks before release.","Despite advancements in automation, traditional methods of generating and validating test cases still face significant challenges, including prolonged timelines, human error, incomplete test coverage, and high costs of manual intervention.","These limitations often lead to delayed product launches and undetected defects that compromise software quality and user satisfaction.","The integration of artificial intelligence (AI) into software testing presents a promising solution to these persistent challenges.","AI-driven testing methods automate the creation of comprehensive test cases, dynamically adapt to changes, and leverage machine learning to identify high-risk areas in the codebase.","This approach enhances regression testing efficiency while expanding overall test coverage.","Furthermore, AI-powered tools enable continuous testing and self-healing test cases, significantly reducing manual oversight and accelerating feedback loops, ultimately leading to faster and more reliable software releases.","This paper explores the transformative potential of AI in improving test case generation and validation, focusing on its ability to enhance efficiency, accuracy, and scalability in testing processes.","It also addresses key challenges associated with adapting AI for testing, including the need for high quality training data, ensuring model transparency, and maintaining a balance between automation and human oversight.","Through case studies and examples of real-world applications, this paper illustrates how AI can significantly enhance testing efficiency across both legacy and modern software systems."],"url":"http://arxiv.org/abs/2409.05808v1"}
{"created":"2024-09-09 17:11:51","title":"Benchmarking Chinese Knowledge Rectification in Large Language Models","abstract":"While Large Language Models (LLMs) exhibit remarkable generative capabilities, they are not without flaws, particularly in the form of hallucinations. This issue is even more pronounced when LLMs are applied to specific languages and domains. For example, LLMs may generate nonsense information when handling Chinese ancient poetry, proverbs, or idioms, owing to the lack of specific knowledge. To this end, this paper introduces a benchmark for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically, we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of knowledge from various sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony, antithesis, and logical constructs inherent in the Chinese language. Through the analysis of this dataset, we uncover the challenges faced by current LLMs in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques on this dataset unveil the substantial scope for advancement in the rectification of Chinese knowledge. Code and dataset are available at https://github.com/zjunlp/EasyEdit.","sentences":["While Large Language Models (LLMs) exhibit remarkable generative capabilities, they are not without flaws, particularly in the form of hallucinations.","This issue is even more pronounced when LLMs are applied to specific languages and domains.","For example, LLMs may generate nonsense information when handling Chinese ancient poetry, proverbs, or idioms, owing to the lack of specific knowledge.","To this end, this paper introduces a benchmark for rectifying Chinese knowledge in LLMs via knowledge editing.","Specifically, we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of knowledge from various sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony, antithesis, and logical constructs inherent in the Chinese language.","Through the analysis of this dataset, we uncover the challenges faced by current LLMs in mastering Chinese.","Furthermore, our evaluation of state-of-the-art knowledge editing techniques on this dataset unveil the substantial scope for advancement in the rectification of Chinese knowledge.","Code and dataset are available at https://github.com/zjunlp/EasyEdit."],"url":"http://arxiv.org/abs/2409.05806v1"}
{"created":"2024-09-09 17:10:36","title":"Celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling","abstract":"Celcomen leverages a mathematical causality framework to disentangle intra- and inter- cellular gene regulation programs in spatial transcriptomics and single-cell data through a generative graph neural network. It can learn gene-gene interactions, as well as generate post-perturbation counterfactual spatial transcriptomics, thereby offering access to experimentally inaccessible samples. We validated its disentanglement, identifiability, and counterfactual prediction capabilities through simulations and in clinically relevant human glioblastoma, human fetal spleen, and mouse lung cancer samples. Celcomen provides the means to model disease and therapy induced changes allowing for new insights into single-cell spatially resolved tissue responses relevant to human health.","sentences":["Celcomen leverages a mathematical causality framework to disentangle intra- and inter- cellular gene regulation programs in spatial transcriptomics and single-cell data through a generative graph neural network.","It can learn gene-gene interactions, as well as generate post-perturbation counterfactual spatial transcriptomics, thereby offering access to experimentally inaccessible samples.","We validated its disentanglement, identifiability, and counterfactual prediction capabilities through simulations and in clinically relevant human glioblastoma, human fetal spleen, and mouse lung cancer samples.","Celcomen provides the means to model disease and therapy induced changes allowing for new insights into single-cell spatially resolved tissue responses relevant to human health."],"url":"http://arxiv.org/abs/2409.05804v1"}
{"created":"2024-09-09 17:03:43","title":"Input Space Mode Connectivity in Deep Neural Networks","abstract":"We extend the concept of loss landscape mode connectivity to the input space of deep neural networks. Mode connectivity was originally studied within parameter space, where it describes the existence of low-loss paths between different solutions (loss minimizers) obtained through gradient descent. We present theoretical and empirical evidence of its presence in the input space of deep networks, thereby highlighting the broader nature of the phenomenon. We observe that different input images with similar predictions are generally connected, and for trained models, the path tends to be simple, with only a small deviation from being a linear path. Our methodology utilizes real, interpolated, and synthetic inputs created using the input optimization technique for feature visualization. We conjecture that input space mode connectivity in high-dimensional spaces is a geometric effect that takes place even in untrained models and can be explained through percolation theory. We exploit mode connectivity to obtain new insights about adversarial examples and demonstrate its potential for adversarial detection. Additionally, we discuss applications for the interpretability of deep networks.","sentences":["We extend the concept of loss landscape mode connectivity to the input space of deep neural networks.","Mode connectivity was originally studied within parameter space, where it describes the existence of low-loss paths between different solutions (loss minimizers) obtained through gradient descent.","We present theoretical and empirical evidence of its presence in the input space of deep networks, thereby highlighting the broader nature of the phenomenon.","We observe that different input images with similar predictions are generally connected, and for trained models, the path tends to be simple, with only a small deviation from being a linear path.","Our methodology utilizes real, interpolated, and synthetic inputs created using the input optimization technique for feature visualization.","We conjecture that input space mode connectivity in high-dimensional spaces is a geometric effect that takes place even in untrained models and can be explained through percolation theory.","We exploit mode connectivity to obtain new insights about adversarial examples and demonstrate its potential for adversarial detection.","Additionally, we discuss applications for the interpretability of deep networks."],"url":"http://arxiv.org/abs/2409.05800v1"}
{"created":"2024-09-09 17:03:38","title":"PDAF: A Phonetic Debiasing Attention Framework For Speaker Verification","abstract":"Speaker verification systems are crucial for authenticating identity through voice. Traditionally, these systems focus on comparing feature vectors, overlooking the speech's content. However, this paper challenges this by highlighting the importance of phonetic dominance, a measure of the frequency or duration of phonemes, as a crucial cue in speaker verification. A novel Phoneme Debiasing Attention Framework (PDAF) is introduced, integrating with existing attention frameworks to mitigate biases caused by phonetic dominance. PDAF adjusts the weighting for each phoneme and influences feature extraction, allowing for a more nuanced analysis of speech. This approach paves the way for more accurate and reliable identity authentication through voice. Furthermore, by employing various weighting strategies, we evaluate the influence of phonetic features on the efficacy of the speaker verification system.","sentences":["Speaker verification systems are crucial for authenticating identity through voice.","Traditionally, these systems focus on comparing feature vectors, overlooking the speech's content.","However, this paper challenges this by highlighting the importance of phonetic dominance, a measure of the frequency or duration of phonemes, as a crucial cue in speaker verification.","A novel Phoneme Debiasing Attention Framework (PDAF) is introduced, integrating with existing attention frameworks to mitigate biases caused by phonetic dominance.","PDAF adjusts the weighting for each phoneme and influences feature extraction, allowing for a more nuanced analysis of speech.","This approach paves the way for more accurate and reliable identity authentication through voice.","Furthermore, by employing various weighting strategies, we evaluate the influence of phonetic features on the efficacy of the speaker verification system."],"url":"http://arxiv.org/abs/2409.05799v1"}
{"created":"2024-09-09 17:02:47","title":"Enhancing Preference-based Linear Bandits via Human Response Time","abstract":"Binary human choice feedback is widely used in interactive preference learning for its simplicity, but it provides limited information about preference strength. To overcome this limitation, we leverage human response times, which inversely correlate with preference strength, as complementary information. Our work integrates the EZ-diffusion model, which jointly models human choices and response times, into preference-based linear bandits. We introduce a computationally efficient utility estimator that reformulates the utility estimation problem using both choices and response times as a linear regression problem. Theoretical and empirical comparisons with traditional choice-only estimators reveal that for queries with strong preferences (\"easy\" queries), choices alone provide limited information, while response times offer valuable complementary information about preference strength. As a result, incorporating response times makes easy queries more useful. We demonstrate this advantage in the fixed-budget best-arm identification problem, with simulations based on three real-world datasets, consistently showing accelerated learning when response times are incorporated.","sentences":["Binary human choice feedback is widely used in interactive preference learning for its simplicity, but it provides limited information about preference strength.","To overcome this limitation, we leverage human response times, which inversely correlate with preference strength, as complementary information.","Our work integrates the EZ-diffusion model, which jointly models human choices and response times, into preference-based linear bandits.","We introduce a computationally efficient utility estimator that reformulates the utility estimation problem using both choices and response times as a linear regression problem.","Theoretical and empirical comparisons with traditional choice-only estimators reveal that for queries with strong preferences (\"easy\" queries), choices alone provide limited information, while response times offer valuable complementary information about preference strength.","As a result, incorporating response times makes easy queries more useful.","We demonstrate this advantage in the fixed-budget best-arm identification problem, with simulations based on three real-world datasets, consistently showing accelerated learning when response times are incorporated."],"url":"http://arxiv.org/abs/2409.05798v1"}
{"created":"2024-09-09 16:58:51","title":"Parf: Adaptive Parameter Refining for Abstract Interpretation","abstract":"The core challenge in applying abstract interpretation lies in the configuration of abstraction and analysis strategies encoded by a large number of external parameters of static analysis tools. To attain low false-positive rates (i.e., accuracy) while preserving analysis efficiency, tuning the parameters heavily relies on expert knowledge and is thus difficult to automate. In this paper, we present a fully automated framework called Parf to adaptively tune the external parameters of abstract interpretation-based static analyzers. Parf models various types of parameters as random variables subject to probability distributions over latticed parameter spaces. It incrementally refines the probability distributions based on accumulated intermediate results generated by repeatedly sampling and analyzing, thereby ultimately yielding a set of highly accurate parameter settings within a given time budget. We have implemented Parf on top of Frama-C/Eva - an off-the-shelf open-source static analyzer for C programs - and compared it against the expert refinement strategy and Frama-C/Eva's official configurations over the Frama-C OSCS benchmark. Experimental results indicate that Parf achieves the lowest number of false positives on 34/37 (91.9%) program repositories with exclusively best results on 12/37 (32.4%) cases. In particular, Parf exhibits promising performance for analyzing complex, large-scale real-world programs.","sentences":["The core challenge in applying abstract interpretation lies in the configuration of abstraction and analysis strategies encoded by a large number of external parameters of static analysis tools.","To attain low false-positive rates (i.e., accuracy) while preserving analysis efficiency, tuning the parameters heavily relies on expert knowledge and is thus difficult to automate.","In this paper, we present a fully automated framework called Parf to adaptively tune the external parameters of abstract interpretation-based static analyzers.","Parf models various types of parameters as random variables subject to probability distributions over latticed parameter spaces.","It incrementally refines the probability distributions based on accumulated intermediate results generated by repeatedly sampling and analyzing, thereby ultimately yielding a set of highly accurate parameter settings within a given time budget.","We have implemented Parf on top of Frama-C/Eva - an off-the-shelf open-source static analyzer for C programs - and compared it against the expert refinement strategy and Frama-C/Eva's official configurations over the Frama-C OSCS benchmark.","Experimental results indicate that Parf achieves the lowest number of false positives on 34/37 (91.9%) program repositories with exclusively best results on 12/37 (32.4%) cases.","In particular, Parf exhibits promising performance for analyzing complex, large-scale real-world programs."],"url":"http://arxiv.org/abs/2409.05794v1"}
{"created":"2024-09-09 16:50:41","title":"Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks","abstract":"Deep generative models (DGMs) have proven to be powerful in generating realistic data samples. Their capability to learn the underlying distribution of a dataset enable them to generate synthetic data samples that closely resemble the original training dataset, thus addressing the challenge of data scarcity. In this work, we investigated the capabilities of DGMs by developing a conditional variational autoencoder (CVAE) model to augment the critical heat flux (CHF) measurement data that was used to generate the 2006 Groeneveld lookup table. To determine how this approach compared to traditional methods, a fine-tuned deep neural network (DNN) regression model was created and evaluated with the same dataset. Both the CVAE and DNN models achieved small mean absolute relative errors, with the CVAE model maintaining more favorable results. To quantify the uncertainty in the model's predictions, uncertainty quantification (UQ) was performed with repeated sampling of the CVAE model and ensembling of the DNN model. Following UQ, the DNN ensemble notably improved performance when compared to the baseline DNN model, while the CVAE model achieved similar results to its non-UQ results. The CVAE model was shown to have significantly less variability and a higher confidence after assessment of the prediction-wise relative standard deviations. Evaluating domain generalization, both models achieved small mean error values when predicting both inside and outside the training domain, with predictions outside the training domain showing slightly larger errors. Overall, the CVAE model was comparable to the DNN regression model in predicting CHF values but with better uncertainty behavior.","sentences":["Deep generative models (DGMs) have proven to be powerful in generating realistic data samples.","Their capability to learn the underlying distribution of a dataset enable them to generate synthetic data samples that closely resemble the original training dataset, thus addressing the challenge of data scarcity.","In this work, we investigated the capabilities of DGMs by developing a conditional variational autoencoder (CVAE) model to augment the critical heat flux (CHF) measurement data that was used to generate the 2006 Groeneveld lookup table.","To determine how this approach compared to traditional methods, a fine-tuned deep neural network (DNN) regression model was created and evaluated with the same dataset.","Both the CVAE and DNN models achieved small mean absolute relative errors, with the CVAE model maintaining more favorable results.","To quantify the uncertainty in the model's predictions, uncertainty quantification (UQ) was performed with repeated sampling of the CVAE model and ensembling of the DNN model.","Following UQ, the DNN ensemble notably improved performance when compared to the baseline DNN model, while the CVAE model achieved similar results to its non-UQ results.","The CVAE model was shown to have significantly less variability and a higher confidence after assessment of the prediction-wise relative standard deviations.","Evaluating domain generalization, both models achieved small mean error values when predicting both inside and outside the training domain, with predictions outside the training domain showing slightly larger errors.","Overall, the CVAE model was comparable to the DNN regression model in predicting CHF values but with better uncertainty behavior."],"url":"http://arxiv.org/abs/2409.05790v1"}
{"created":"2024-09-09 16:48:42","title":"Leveraging Object Priors for Point Tracking","abstract":"Point tracking is a fundamental problem in computer vision with numerous applications in AR and robotics. A common failure mode in long-term point tracking occurs when the predicted point leaves the object it belongs to and lands on the background or another object. We identify this as the failure to correctly capture objectness properties in learning to track. To address this limitation of prior work, we propose a novel objectness regularization approach that guides points to be aware of object priors by forcing them to stay inside the the boundaries of object instances. By capturing objectness cues at training time, we avoid the need to compute object masks during testing. In addition, we leverage contextual attention to enhance the feature representation for capturing objectness at the feature level more effectively. As a result, our approach achieves state-of-the-art performance on three point tracking benchmarks, and we further validate the effectiveness of our components via ablation studies. The source code is available at: https://github.com/RehgLab/tracking_objectness","sentences":["Point tracking is a fundamental problem in computer vision with numerous applications in AR and robotics.","A common failure mode in long-term point tracking occurs when the predicted point leaves the object it belongs to and lands on the background or another object.","We identify this as the failure to correctly capture objectness properties in learning to track.","To address this limitation of prior work, we propose a novel objectness regularization approach that guides points to be aware of object priors by forcing them to stay inside the the boundaries of object instances.","By capturing objectness cues at training time, we avoid the need to compute object masks during testing.","In addition, we leverage contextual attention to enhance the feature representation for capturing objectness at the feature level more effectively.","As a result, our approach achieves state-of-the-art performance on three point tracking benchmarks, and we further validate the effectiveness of our components via ablation studies.","The source code is available at: https://github.com/RehgLab/tracking_objectness"],"url":"http://arxiv.org/abs/2409.05786v1"}
{"created":"2024-09-09 16:48:09","title":"NeurLZ: On Systematically Enhancing Lossy Compression Performance for Scientific Data based on Neural Learning with Error Control","abstract":"Large-scale scientific simulations generate massive datasets that pose significant challenges for storage and I/O. While traditional lossy compression techniques can improve performance, balancing compression ratio, data quality, and throughput remains difficult. To address this, we propose NeurLZ, a novel cross-field learning-based and error-controlled compression framework for scientific data. By integrating skipping DNN models, cross-field learning, and error control, our framework aims to substantially enhance lossy compression performance. Our contributions are three-fold: (1) We design a lightweight skipping model to provide high-fidelity detail retention, further improving prediction accuracy. (2) We adopt a cross-field learning approach to significantly improve data prediction accuracy, resulting in a substantially improved compression ratio. (3) We develop an error control approach to provide strict error bounds according to user requirements. We evaluated NeurLZ on several real-world HPC application datasets, including Nyx (cosmological simulation), Miranda (large turbulence simulation), and Hurricane (weather simulation). Experiments demonstrate that our framework achieves up to a 90% relative reduction in bit rate under the same data distortion, compared to the best existing approach.","sentences":["Large-scale scientific simulations generate massive datasets that pose significant challenges for storage and I/O.","While traditional lossy compression techniques can improve performance, balancing compression ratio, data quality, and throughput remains difficult.","To address this, we propose NeurLZ, a novel cross-field learning-based and error-controlled compression framework for scientific data.","By integrating skipping DNN models, cross-field learning, and error control, our framework aims to substantially enhance lossy compression performance.","Our contributions are three-fold: (1) We design a lightweight skipping model to provide high-fidelity detail retention, further improving prediction accuracy.","(2) We adopt a cross-field learning approach to significantly improve data prediction accuracy, resulting in a substantially improved compression ratio.","(3) We develop an error control approach to provide strict error bounds according to user requirements.","We evaluated NeurLZ on several real-world HPC application datasets, including Nyx (cosmological simulation), Miranda (large turbulence simulation), and Hurricane (weather simulation).","Experiments demonstrate that our framework achieves up to a 90% relative reduction in bit rate under the same data distortion, compared to the best existing approach."],"url":"http://arxiv.org/abs/2409.05785v1"}
{"created":"2024-09-09 16:46:54","title":"Vector Quantized Diffusion Model Based Speech Bandwidth Extension","abstract":"Recent advancements in neural audio codec (NAC) unlock new potential in audio signal processing. Studies have increasingly explored leveraging the latent features of NAC for various speech signal processing tasks. This paper introduces the first approach to speech bandwidth extension (BWE) that utilizes the discrete features obtained from NAC. By restoring high-frequency details within highly compressed discrete tokens, this approach enhances speech intelligibility and naturalness. Based on Vector Quantized Diffusion, the proposed framework combines the strengths of advanced NAC, diffusion models, and Mamba-2 to reconstruct high-frequency speech components. Extensive experiments demonstrate that this method exhibits superior performance across both log-spectral distance and ViSQOL, significantly improving speech quality.","sentences":["Recent advancements in neural audio codec (NAC) unlock new potential in audio signal processing.","Studies have increasingly explored leveraging the latent features of NAC for various speech signal processing tasks.","This paper introduces the first approach to speech bandwidth extension (BWE) that utilizes the discrete features obtained from NAC.","By restoring high-frequency details within highly compressed discrete tokens, this approach enhances speech intelligibility and naturalness.","Based on Vector Quantized Diffusion, the proposed framework combines the strengths of advanced NAC, diffusion models, and Mamba-2 to reconstruct high-frequency speech components.","Extensive experiments demonstrate that this method exhibits superior performance across both log-spectral distance and ViSQOL, significantly improving speech quality."],"url":"http://arxiv.org/abs/2409.05784v1"}
{"created":"2024-09-09 16:45:26","title":"Unified Neural Network Scaling Laws and Scale-time Equivalence","abstract":"As neural networks continue to grow in size but datasets might not, it is vital to understand how much performance improvement can be expected: is it more important to scale network size or data volume? Thus, neural network scaling laws, which characterize how test error varies with network size and data volume, have become increasingly important. However, existing scaling laws are often applicable only in limited regimes and often do not incorporate or predict well-known phenomena such as double descent. Here, we present a novel theoretical characterization of how three factors -- model size, training time, and data volume -- interact to determine the performance of deep neural networks. We first establish a theoretical and empirical equivalence between scaling the size of a neural network and increasing its training time proportionally. Scale-time equivalence challenges the current practice, wherein large models are trained for small durations, and suggests that smaller models trained over extended periods could match their efficacy. It also leads to a novel method for predicting the performance of large-scale networks from small-scale networks trained for extended epochs, and vice versa. We next combine scale-time equivalence with a linear model analysis of double descent to obtain a unified theoretical scaling law, which we confirm with experiments across vision benchmarks and network architectures. These laws explain several previously unexplained phenomena: reduced data requirements for generalization in larger models, heightened sensitivity to label noise in overparameterized models, and instances where increasing model scale does not necessarily enhance performance. Our findings hold significant implications for the practical deployment of neural networks, offering a more accessible and efficient path to training and fine-tuning large models.","sentences":["As neural networks continue to grow in size but datasets might not, it is vital to understand how much performance improvement can be expected: is it more important to scale network size or data volume?","Thus, neural network scaling laws, which characterize how test error varies with network size and data volume, have become increasingly important.","However, existing scaling laws are often applicable only in limited regimes and often do not incorporate or predict well-known phenomena such as double descent.","Here, we present a novel theoretical characterization of how three factors -- model size, training time, and data volume -- interact to determine the performance of deep neural networks.","We first establish a theoretical and empirical equivalence between scaling the size of a neural network and increasing its training time proportionally.","Scale-time equivalence challenges the current practice, wherein large models are trained for small durations, and suggests that smaller models trained over extended periods could match their efficacy.","It also leads to a novel method for predicting the performance of large-scale networks from small-scale networks trained for extended epochs, and vice versa.","We next combine scale-time equivalence with a linear model analysis of double descent to obtain a unified theoretical scaling law, which we confirm with experiments across vision benchmarks and network architectures.","These laws explain several previously unexplained phenomena: reduced data requirements for generalization in larger models, heightened sensitivity to label noise in overparameterized models, and instances where increasing model scale does not necessarily enhance performance.","Our findings hold significant implications for the practical deployment of neural networks, offering a more accessible and efficient path to training and fine-tuning large models."],"url":"http://arxiv.org/abs/2409.05782v1"}
{"created":"2024-09-09 16:43:09","title":"Breaking Neural Network Scaling Laws with Modularity","abstract":"Modular neural networks outperform nonmodular neural networks on tasks ranging from visual question answering to robotics. These performance improvements are thought to be due to modular networks' superior ability to model the compositional and combinatorial structure of real-world problems. However, a theoretical explanation of how modularity improves generalizability, and how to leverage task modularity while training networks remains elusive. Using recent theoretical progress in explaining neural network generalization, we investigate how the amount of training data required to generalize on a task varies with the intrinsic dimensionality of a task's input. We show theoretically that when applied to modularly structured tasks, while nonmodular networks require an exponential number of samples with task dimensionality, modular networks' sample complexity is independent of task dimensionality: modular networks can generalize in high dimensions. We then develop a novel learning rule for modular networks to exploit this advantage and empirically show the improved generalization of the rule, both in- and out-of-distribution, on high-dimensional, modular tasks.","sentences":["Modular neural networks outperform nonmodular neural networks on tasks ranging from visual question answering to robotics.","These performance improvements are thought to be due to modular networks' superior ability to model the compositional and combinatorial structure of real-world problems.","However, a theoretical explanation of how modularity improves generalizability, and how to leverage task modularity while training networks remains elusive.","Using recent theoretical progress in explaining neural network generalization, we investigate how the amount of training data required to generalize on a task varies with the intrinsic dimensionality of a task's input.","We show theoretically that when applied to modularly structured tasks, while nonmodular networks require an exponential number of samples with task dimensionality, modular networks' sample complexity is independent of task dimensionality: modular networks can generalize in high dimensions.","We then develop a novel learning rule for modular networks to exploit this advantage and empirically show the improved generalization of the rule, both in- and out-of-distribution, on high-dimensional, modular tasks."],"url":"http://arxiv.org/abs/2409.05780v1"}
{"created":"2024-09-09 16:41:04","title":"Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machine Learning Techniques","abstract":"Trading and investing in stocks for some is their full-time career, while for others, it's simply a supplementary income stream. Universal among all investors is the desire to turn a profit. The key to achieving this goal is diversification. Spreading investments across sectors is critical to profitability and maximizing returns. This study aims to gauge the viability of machine learning methods in practicing the principle of diversification to maximize portfolio returns. To test this, the study evaluates the Long-Short Term Memory (LSTM) model across nine different sectors and over 2,200 stocks using Vanguard's sector-based ETFs. The R-squared value across all sectors showed promising results, with an average of 0.8651 and a high of 0.942 for the VNQ ETF. These findings suggest that the LSTM model is a capable and viable model for accurately predicting directional changes across various industry sectors, helping investors diversify and grow their portfolios.","sentences":["Trading and investing in stocks for some is their full-time career, while for others, it's simply a supplementary income stream.","Universal among all investors is the desire to turn a profit.","The key to achieving this goal is diversification.","Spreading investments across sectors is critical to profitability and maximizing returns.","This study aims to gauge the viability of machine learning methods in practicing the principle of diversification to maximize portfolio returns.","To test this, the study evaluates the Long-Short Term Memory (LSTM) model across nine different sectors and over 2,200 stocks using Vanguard's sector-based ETFs.","The R-squared value across all sectors showed promising results, with an average of 0.8651 and a high of 0.942 for the VNQ ETF.","These findings suggest that the LSTM model is a capable and viable model for accurately predicting directional changes across various industry sectors, helping investors diversify and grow their portfolios."],"url":"http://arxiv.org/abs/2409.05778v1"}
{"created":"2024-09-09 16:34:36","title":"Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera","abstract":"This paper explores the integration of visual communication and musical interaction by implementing a robotic camera within a \"Guided Harmony\" musical game. We aim to examine co-creative behaviors between human musicians and robotic systems. Our research explores existing methodologies like improvisational game pieces and extends these concepts to include robotic participation using a PTZ camera. The robotic system interprets and responds to nonverbal cues from musicians, creating a collaborative and adaptive musical experience. This initial case study underscores the importance of intuitive visual communication channels. We also propose future research directions, including parameters for refining the visual cue toolkit and data collection methods to understand human-machine co-creativity further. Our findings contribute to the broader understanding of machine intelligence in augmenting human creativity, particularly in musical settings.","sentences":["This paper explores the integration of visual communication and musical interaction by implementing a robotic camera within a \"Guided Harmony\" musical game.","We aim to examine co-creative behaviors between human musicians and robotic systems.","Our research explores existing methodologies like improvisational game pieces and extends these concepts to include robotic participation using a PTZ camera.","The robotic system interprets and responds to nonverbal cues from musicians, creating a collaborative and adaptive musical experience.","This initial case study underscores the importance of intuitive visual communication channels.","We also propose future research directions, including parameters for refining the visual cue toolkit and data collection methods to understand human-machine co-creativity further.","Our findings contribute to the broader understanding of machine intelligence in augmenting human creativity, particularly in musical settings."],"url":"http://arxiv.org/abs/2409.05773v1"}
{"created":"2024-09-09 16:33:40","title":"A CLIP-based siamese approach for meme classification","abstract":"Memes are an increasingly prevalent element of online discourse in social networks, especially among young audiences. They carry ideas and messages that range from humorous to hateful, and are widely consumed. Their potentially high impact requires adequate means of control to moderate their use in large scale. In this work, we propose SimCLIP a deep learning-based architecture for cross-modal understanding of memes, leveraging a pre-trained CLIP encoder to produce context-aware embeddings and a Siamese fusion technique to capture the interactions between text and image. We perform an extensive experimentation on seven meme classification tasks across six datasets. We establish a new state of the art in Memotion7k with a 7.25% relative F1-score improvement, and achieve super-human performance on Harm-P with 13.73% F1-Score improvement. Our approach demonstrates the potential for compact meme classification models, enabling accurate and efficient meme monitoring. We share our code at https://github.com/jahuerta92/meme-classification-simclip","sentences":["Memes are an increasingly prevalent element of online discourse in social networks, especially among young audiences.","They carry ideas and messages that range from humorous to hateful, and are widely consumed.","Their potentially high impact requires adequate means of control to moderate their use in large scale.","In this work, we propose SimCLIP a deep learning-based architecture for cross-modal understanding of memes, leveraging a pre-trained CLIP encoder to produce context-aware embeddings and a Siamese fusion technique to capture the interactions between text and image.","We perform an extensive experimentation on seven meme classification tasks across six datasets.","We establish a new state of the art in Memotion7k with a 7.25% relative F1-score improvement, and achieve super-human performance on Harm-P with 13.73% F1-Score improvement.","Our approach demonstrates the potential for compact meme classification models, enabling accurate and efficient meme monitoring.","We share our code at https://github.com/jahuerta92/meme-classification-simclip"],"url":"http://arxiv.org/abs/2409.05772v1"}
{"created":"2024-09-09 16:33:16","title":"Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models","abstract":"Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli. Yet, very little is known about the representation properties that enable this high prediction performance. Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task? In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs. We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues. Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs. We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties.","sentences":["Research has repeatedly demonstrated that intermediate hidden states extracted from large language models are able to predict measured brain response to natural language stimuli.","Yet, very little is known about the representation properties that enable this high prediction performance.","Why is it the intermediate layers, and not the output layers, that are most capable for this unique and highly general transfer task?","In this work, we show that evidence from language encoding models in fMRI supports the existence of a two-phase abstraction process within LLMs.","We use manifold learning methods to show that this abstraction process naturally arises over the course of training a language model and that the first \"composition\" phase of this abstraction process is compressed into fewer layers as training continues.","Finally, we demonstrate a strong correspondence between layerwise encoding performance and the intrinsic dimensionality of representations from LLMs.","We give initial evidence that this correspondence primarily derives from the inherent compositionality of LLMs and not their next-word prediction properties."],"url":"http://arxiv.org/abs/2409.05771v1"}
{"created":"2024-09-09 16:32:14","title":"Model Input Verification of Large Scale Simulations","abstract":"Reliable simulations are critical for analyzing and understanding complex systems, but their accuracy depends on correct input data. Incorrect inputs such as invalid or out-of-range values, missing data, and format inconsistencies can cause simulation crashes or unnoticed result distortions, ultimately undermining the validity of the conclusions. This paper presents a methodology for verifying the validity of input data in simulations, a process we term model input verification (MIV). We implement this approach in FabGuard, a toolset that uses established data schema and validation tools for the specific needs of simulation modeling. We introduce a formalism for categorizing MIV patterns and offer a streamlined verification pipeline that integrates into existing simulation workflows. FabGuard's applicability is demonstrated across three diverse domains: conflict-driven migration, disaster evacuation, and disease spread models. We also explore the use of Large Language Models (LLMs) for automating constraint generation and inference. In a case study with a migration simulation, LLMs not only correctly inferred 22 out of 23 developer-defined constraints, but also identified errors in existing constraints and proposed new, valid constraints. Our evaluation demonstrates that MIV is feasible on large datasets, with FabGuard efficiently processing 12,000 input files in 140 seconds and maintaining consistent performance across varying file sizes.","sentences":["Reliable simulations are critical for analyzing and understanding complex systems, but their accuracy depends on correct input data.","Incorrect inputs such as invalid or out-of-range values, missing data, and format inconsistencies can cause simulation crashes or unnoticed result distortions, ultimately undermining the validity of the conclusions.","This paper presents a methodology for verifying the validity of input data in simulations, a process we term model input verification (MIV).","We implement this approach in FabGuard, a toolset that uses established data schema and validation tools for the specific needs of simulation modeling.","We introduce a formalism for categorizing MIV patterns and offer a streamlined verification pipeline that integrates into existing simulation workflows.","FabGuard's applicability is demonstrated across three diverse domains: conflict-driven migration, disaster evacuation, and disease spread models.","We also explore the use of Large Language Models (LLMs) for automating constraint generation and inference.","In a case study with a migration simulation, LLMs not only correctly inferred 22 out of 23 developer-defined constraints, but also identified errors in existing constraints and proposed new, valid constraints.","Our evaluation demonstrates that MIV is feasible on large datasets, with FabGuard efficiently processing 12,000 input files in 140 seconds and maintaining consistent performance across varying file sizes."],"url":"http://arxiv.org/abs/2409.05768v1"}
{"created":"2024-09-09 16:11:07","title":"Are Heterophily-Specific GNNs and Homophily Metrics Really Effective? Evaluation Pitfalls and New Benchmarks","abstract":"Over the past decade, Graph Neural Networks (GNNs) have achieved great success on machine learning tasks with relational data. However, recent studies have found that heterophily can cause significant performance degradation of GNNs, especially on node-level tasks. Numerous heterophilic benchmark datasets have been put forward to validate the efficacy of heterophily-specific GNNs and various homophily metrics have been designed to help people recognize these malignant datasets. Nevertheless, there still exist multiple pitfalls that severely hinder the proper evaluation of new models and metrics. In this paper, we point out three most serious pitfalls: 1) a lack of hyperparameter tuning; 2) insufficient model evaluation on the real challenging heterophilic datasets; 3) missing quantitative evaluation benchmark for homophily metrics on synthetic graphs. To overcome these challenges, we first train and fine-tune baseline models on $27$ most widely used benchmark datasets, categorize them into three distinct groups: malignant, benign and ambiguous heterophilic datasets, and identify the real challenging subsets of tasks. To our best knowledge, we are the first to propose such taxonomy. Then, we re-evaluate $10$ heterophily-specific state-of-the-arts (SOTA) GNNs with fine-tuned hyperparameters on different groups of heterophilic datasets. Based on the model performance, we reassess their effectiveness on addressing heterophily challenge. At last, we evaluate $11$ popular homophily metrics on synthetic graphs with three different generation approaches. To compare the metrics strictly, we propose the first quantitative evaluation method based on Fr\\'echet distance.","sentences":["Over the past decade, Graph Neural Networks (GNNs) have achieved great success on machine learning tasks with relational data.","However, recent studies have found that heterophily can cause significant performance degradation of GNNs, especially on node-level tasks.","Numerous heterophilic benchmark datasets have been put forward to validate the efficacy of heterophily-specific GNNs and various homophily metrics have been designed to help people recognize these malignant datasets.","Nevertheless, there still exist multiple pitfalls that severely hinder the proper evaluation of new models and metrics.","In this paper, we point out three most serious pitfalls: 1) a lack of hyperparameter tuning; 2) insufficient model evaluation on the real challenging heterophilic datasets; 3) missing quantitative evaluation benchmark for homophily metrics on synthetic graphs.","To overcome these challenges, we first train and fine-tune baseline models on $27$ most widely used benchmark datasets, categorize them into three distinct groups: malignant, benign and ambiguous heterophilic datasets, and identify the real challenging subsets of tasks.","To our best knowledge, we are the first to propose such taxonomy.","Then, we re-evaluate $10$ heterophily-specific state-of-the-arts (SOTA) GNNs with fine-tuned hyperparameters on different groups of heterophilic datasets.","Based on the model performance, we reassess their effectiveness on addressing heterophily challenge.","At last, we evaluate $11$ popular homophily metrics on synthetic graphs with three different generation approaches.","To compare the metrics strictly, we propose the first quantitative evaluation method based on Fr\\'echet distance."],"url":"http://arxiv.org/abs/2409.05755v1"}
{"created":"2024-09-09 16:05:41","title":"Design of a Variable Stiffness Quasi-Direct Drive Cable-Actuated Tensegrity Robot","abstract":"Tensegrity robots excel in tasks requiring extreme levels of deformability and robustness. However, there are challenges in state estimation and payload versatility due to their high number of degrees of freedom and unconventional shape. This paper introduces a modular three-bar tensegrity robot featuring a customizable payload design. Our tensegrity robot employs a novel Quasi-Direct Drive (QDD) cable actuator paired with low-stretch polymer cables to achieve accurate proprioception without the need for external force or torque sensors. The design allows for on-the-fly stiffness tuning for better environment and payload adaptability. In this paper, we present the design, fabrication, assembly, and experimental results of the robot. Experimental data demonstrates the high accuracy cable length estimation (<1% error relative to bar length) and variable stiffness control of the cable actuator up to 7 times the minimum stiffness for self support. The presented tensegrity robot serves as a platform for future advancements in autonomous operation and open-source module design.","sentences":["Tensegrity robots excel in tasks requiring extreme levels of deformability and robustness.","However, there are challenges in state estimation and payload versatility due to their high number of degrees of freedom and unconventional shape.","This paper introduces a modular three-bar tensegrity robot featuring a customizable payload design.","Our tensegrity robot employs a novel Quasi-Direct Drive (QDD) cable actuator paired with low-stretch polymer cables to achieve accurate proprioception without the need for external force or torque sensors.","The design allows for on-the-fly stiffness tuning for better environment and payload adaptability.","In this paper, we present the design, fabrication, assembly, and experimental results of the robot.","Experimental data demonstrates the high accuracy cable length estimation (<1% error relative to bar length) and variable stiffness control of the cable actuator up to 7 times the minimum stiffness for self support.","The presented tensegrity robot serves as a platform for future advancements in autonomous operation and open-source module design."],"url":"http://arxiv.org/abs/2409.05751v1"}
{"created":"2024-09-09 16:03:26","title":"ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL","abstract":"To extract robust and generalizable skeleton action recognition features, large amounts of well-curated data are typically required, which is a challenging task hindered by annotation and computation costs. Therefore, unsupervised representation learning is of prime importance to leverage unlabeled skeleton data. In this work, we investigate unsupervised representation learning for skeleton action recognition. For this purpose, we designed a lightweight convolutional transformer framework, named ReL-SAR, exploiting the complementarity of convolutional and attention layers for jointly modeling spatial and temporal cues in skeleton sequences. We also use a Selection-Permutation strategy for skeleton joints to ensure more informative descriptions from skeletal data. Finally, we capitalize on Bootstrap Your Own Latent (BYOL) to learn robust representations from unlabeled skeleton sequence data. We achieved very competitive results on limited-size datasets: MCAD, IXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method against state-of-the-art methods in terms of both performance and computational efficiency. To ensure reproducibility and reusability, the source code including all implementation parameters is provided at: https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL","sentences":["To extract robust and generalizable skeleton action recognition features, large amounts of well-curated data are typically required, which is a challenging task hindered by annotation and computation costs.","Therefore, unsupervised representation learning is of prime importance to leverage unlabeled skeleton data.","In this work, we investigate unsupervised representation learning for skeleton action recognition.","For this purpose, we designed a lightweight convolutional transformer framework, named ReL-SAR, exploiting the complementarity of convolutional and attention layers for jointly modeling spatial and temporal cues in skeleton sequences.","We also use a Selection-Permutation strategy for skeleton joints to ensure more informative descriptions from skeletal data.","Finally, we capitalize on Bootstrap Your Own Latent (BYOL) to learn robust representations from unlabeled skeleton sequence data.","We achieved very competitive results on limited-size datasets: MCAD, IXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method against state-of-the-art methods in terms of both performance and computational efficiency.","To ensure reproducibility and reusability, the source code including all implementation parameters is provided at: https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL"],"url":"http://arxiv.org/abs/2409.05749v1"}
{"created":"2024-09-09 16:02:27","title":"A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System","abstract":"This paper presents a novel conversational AI-enabled active ideation interface as a creative idea-generation tool to assist novice designers in mitigating the initial latency and ideation bottlenecks that are commonly observed. It is a dynamic, interactive, and contextually responsive approach, actively involving a large language model (LLM) from the domain of natural language processing (NLP) in artificial intelligence (AI) to produce multiple statements of potential ideas for different design problems. Integrating such AI models with ideation creates what we refer to as an Active Ideation scenario, which helps foster continuous dialogue-based interaction, context-sensitive conversation, and prolific idea generation. A pilot study was conducted with thirty novice designers to generate ideas for given problems using traditional methods and the new CAI-based interface. The key parameters of fluency, novelty, and variety were used to compare the outcomes qualitatively by a panel of experts. The findings demonstrated the effectiveness of the proposed tool for generating prolific, diverse and novel ideas. The interface was enhanced by incorporating a prompt-engineered structured dialogue style for each ideation stage to make it uniform and more convenient for the designers. The resulting responses of such a structured CAI interface were found to be more succinct and aligned towards the subsequent design stage, namely conceptualization. The paper thus established the rich potential of using Generative AI (Gen-AI) for the early ill-structured phase of the creative product design process.","sentences":["This paper presents a novel conversational AI-enabled active ideation interface as a creative idea-generation tool to assist novice designers in mitigating the initial latency and ideation bottlenecks that are commonly observed.","It is a dynamic, interactive, and contextually responsive approach, actively involving a large language model (LLM) from the domain of natural language processing (NLP) in artificial intelligence (AI) to produce multiple statements of potential ideas for different design problems.","Integrating such AI models with ideation creates what we refer to as an Active Ideation scenario, which helps foster continuous dialogue-based interaction, context-sensitive conversation, and prolific idea generation.","A pilot study was conducted with thirty novice designers to generate ideas for given problems using traditional methods and the new CAI-based interface.","The key parameters of fluency, novelty, and variety were used to compare the outcomes qualitatively by a panel of experts.","The findings demonstrated the effectiveness of the proposed tool for generating prolific, diverse and novel ideas.","The interface was enhanced by incorporating a prompt-engineered structured dialogue style for each ideation stage to make it uniform and more convenient for the designers.","The resulting responses of such a structured CAI interface were found to be more succinct and aligned towards the subsequent design stage, namely conceptualization.","The paper thus established the rich potential of using Generative AI (Gen-AI) for the early ill-structured phase of the creative product design process."],"url":"http://arxiv.org/abs/2409.05747v1"}
{"created":"2024-09-09 16:01:36","title":"The Error Probability of Spatially Coupled Sparse Regression Codes over Memoryless Channels","abstract":"Sparse Regression Codes (SPARCs) are capacity-achieving codes introduced for communication over the Additive White Gaussian Noise (AWGN) channels and were later extended to general memoryless channels. In particular it was shown via threshold saturation that Spatially Coupled Sparse Regression Codes (SC-SPARCs) are capacity-achieving over general memoryless channels when using an Approximate Message Passing decoder (AMP). This paper, for the first time rigorously, analyzes the non-asymptotic performance of the Generalized Approximate Message Passing (GAMP) decoder of SC-SPARCs over memoryless channels, and proves exponential decaying error probability with respect to the code length.","sentences":["Sparse Regression Codes (SPARCs) are capacity-achieving codes introduced for communication over the Additive White Gaussian Noise (AWGN) channels and were later extended to general memoryless channels.","In particular it was shown via threshold saturation that Spatially Coupled Sparse Regression Codes (SC-SPARCs) are capacity-achieving over general memoryless channels when using an Approximate Message Passing decoder (AMP).","This paper, for the first time rigorously, analyzes the non-asymptotic performance of the Generalized Approximate Message Passing (GAMP) decoder of SC-SPARCs over memoryless channels, and proves exponential decaying error probability with respect to the code length."],"url":"http://arxiv.org/abs/2409.05745v1"}
{"created":"2024-09-09 15:56:34","title":"Robust Loss Functions for Object Grasping under Limited Ground Truth","abstract":"Object grasping is a crucial technology enabling robots to perceive and interact with the environment sufficiently. However, in practical applications, researchers are faced with missing or noisy ground truth while training the convolutional neural network, which decreases the accuracy of the model. Therefore, different loss functions are proposed to deal with these problems to improve the accuracy of the neural network. For missing ground truth, a new predicted category probability method is defined for unlabeled samples, which works effectively in conjunction with the pseudo-labeling method. Furthermore, for noisy ground truth, a symmetric loss function is introduced to resist the corruption of label noises. The proposed loss functions are powerful, robust, and easy to use. Experimental results based on the typical grasping neural network show that our method can improve performance by 2 to 13 percent.","sentences":["Object grasping is a crucial technology enabling robots to perceive and interact with the environment sufficiently.","However, in practical applications, researchers are faced with missing or noisy ground truth while training the convolutional neural network, which decreases the accuracy of the model.","Therefore, different loss functions are proposed to deal with these problems to improve the accuracy of the neural network.","For missing ground truth, a new predicted category probability method is defined for unlabeled samples, which works effectively in conjunction with the pseudo-labeling method.","Furthermore, for noisy ground truth, a symmetric loss function is introduced to resist the corruption of label noises.","The proposed loss functions are powerful, robust, and easy to use.","Experimental results based on the typical grasping neural network show that our method can improve performance by 2 to 13 percent."],"url":"http://arxiv.org/abs/2409.05742v1"}
{"created":"2024-09-09 15:51:51","title":"RCM-Constrained Manipulator Trajectory Tracking Using Differential Kinematics Control","abstract":"This paper proposes an approach for controlling surgical robotic systems, while complying with the Remote Center of Motion (RCM) constraint in Robot-Assisted Minimally Invasive Surgery (RA-MIS). In this approach, the RCM-constraint is upheld algorithmically, providing flexibility in the positioning of the insertion point and enabling compatibility with a wide range of general-purpose robots. The paper further investigates the impact of the tool's insertion ratio on the RCM-error, and introduces a manipulability index of the robot which considers the RCM-error that it is used to find a starting configuration. To accurately evaluate the proposed method's trajectory tracking within an RCM-constrained environment, an electromagnetic tracking system is employed. The results demonstrate the effectiveness of the proposed method in addressing the RCM constraint problem in RA-MIS.","sentences":["This paper proposes an approach for controlling surgical robotic systems, while complying with the Remote Center of Motion (RCM) constraint in Robot-Assisted Minimally Invasive Surgery (RA-MIS).","In this approach, the RCM-constraint is upheld algorithmically, providing flexibility in the positioning of the insertion point and enabling compatibility with a wide range of general-purpose robots.","The paper further investigates the impact of the tool's insertion ratio on the RCM-error, and introduces a manipulability index of the robot which considers the RCM-error that it is used to find a starting configuration.","To accurately evaluate the proposed method's trajectory tracking within an RCM-constrained environment, an electromagnetic tracking system is employed.","The results demonstrate the effectiveness of the proposed method in addressing the RCM constraint problem in RA-MIS."],"url":"http://arxiv.org/abs/2409.05740v1"}
{"created":"2024-09-09 15:44:39","title":"A System and Benchmark for LLM-based Q\\&A on Heterogeneous Data","abstract":"In many industrial settings, users wish to ask questions whose answers may be found in structured data sources such as a spreadsheets, databases, APIs, or combinations thereof. Often, the user doesn't know how to identify or access the right data source. This problem is compounded even further if multiple (and potentially siloed) data sources must be assembled to derive the answer. Recently, various Text-to-SQL applications that leverage Large Language Models (LLMs) have addressed some of these problems by enabling users to ask questions in natural language. However, these applications remain impractical in realistic industrial settings because they fail to cope with the data source heterogeneity that typifies such environments. In this paper, we address heterogeneity by introducing the siwarex platform, which enables seamless natural language access to both databases and APIs. To demonstrate the effectiveness of siwarex, we extend the popular Spider dataset and benchmark by replacing some of its tables by data retrieval APIs. We find that siwarex does a good job of coping with data source heterogeneity. Our modified Spider benchmark will soon be available to the research community","sentences":["In many industrial settings, users wish to ask questions whose answers may be found in structured data sources such as a spreadsheets, databases, APIs, or combinations thereof.","Often, the user doesn't know how to identify or access the right data source.","This problem is compounded even further if multiple (and potentially siloed) data sources must be assembled to derive the answer.","Recently, various Text-to-SQL applications that leverage Large Language Models (LLMs) have addressed some of these problems by enabling users to ask questions in natural language.","However, these applications remain impractical in realistic industrial settings because they fail to cope with the data source heterogeneity that typifies such environments.","In this paper, we address heterogeneity by introducing the siwarex platform, which enables seamless natural language access to both databases and APIs.","To demonstrate the effectiveness of siwarex, we extend the popular Spider dataset and benchmark by replacing some of its tables by data retrieval APIs.","We find that siwarex does a good job of coping with data source heterogeneity.","Our modified Spider benchmark will soon be available to the research community"],"url":"http://arxiv.org/abs/2409.05735v1"}
{"created":"2024-09-09 15:42:19","title":"Towards Democratizing Multilingual Large Language Models For Medicine Through A Two-Stage Instruction Fine-tuning Approach","abstract":"Open-source, multilingual medical large language models (LLMs) have the potential to serve linguistically diverse populations across different regions. Adapting generic LLMs for healthcare often requires continual pretraining, but this approach is computationally expensive and sometimes impractical. Instruction fine-tuning on a specific task may not always guarantee optimal performance due to the lack of broader domain knowledge that the model needs to understand and reason effectively in diverse scenarios. To address these challenges, we introduce two multilingual instruction fine-tuning datasets, MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in six languages. We propose a two-stage training paradigm: the first stage injects general medical knowledge using MMed-IFT, while the second stage fine-tunes task-specific multiple-choice questions with MMed-IFT-MC. Our method achieves competitive results on both English and multilingual benchmarks, striking a balance between computational efficiency and performance. We plan to make our dataset and model weights public at \\url{https://github.com/SpassMed/Med-Llama3} in the future.","sentences":["Open-source, multilingual medical large language models (LLMs) have the potential to serve linguistically diverse populations across different regions.","Adapting generic LLMs for healthcare often requires continual pretraining, but this approach is computationally expensive and sometimes impractical.","Instruction fine-tuning on a specific task may not always guarantee optimal performance due to the lack of broader domain knowledge that the model needs to understand and reason effectively in diverse scenarios.","To address these challenges, we introduce two multilingual instruction fine-tuning datasets, MMed-IFT and MMed-IFT-MC, containing over 200k high-quality medical samples in six languages.","We propose a two-stage training paradigm: the first stage injects general medical knowledge using MMed-IFT, while the second stage fine-tunes task-specific multiple-choice questions with MMed-IFT-MC.","Our method achieves competitive results on both English and multilingual benchmarks, striking a balance between computational efficiency and performance.","We plan to make our dataset and model weights public at \\url{https://github.com/SpassMed/Med-Llama3} in the future."],"url":"http://arxiv.org/abs/2409.05732v1"}
{"created":"2024-09-09 15:41:53","title":"What Did My Car Say? Autonomous Vehicle Explanation Errors, Context, and Personal Traits Impact Comfort, Reliance, Satisfaction, and Driving Confidence","abstract":"Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger's comfort in relying on an AV, preference for control, confidence in the AV's ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV's driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems.","sentences":["Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors.","In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger's comfort in relying on an AV, preference for control, confidence in the AV's ability, and explanation satisfaction.","Errors negatively affected all outcomes.","Surprisingly, despite identical driving, explanation errors reduced ratings of the AV's driving ability.","Severity and potential harm amplified the negative impact of errors.","Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes.","Prior trust and expertise were positively associated with outcome ratings.","Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence.","We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems."],"url":"http://arxiv.org/abs/2409.05731v1"}
{"created":"2024-09-09 15:35:43","title":"OTFS-MDMA: An Elastic Multi-Domain Resource Utilization Mechanism for High Mobility Scenarios","abstract":"By harnessing the delay-Doppler (DD) resource domain, orthogonal time-frequency space (OTFS) substantially improves the communication performance under high-mobility scenarios by maintaining quasi-time-invariant channel characteristics. However, conventional multiple access (MA) techniques fail to efficiently support OTFS in the face of diverse communication requirements. Recently, multi-dimensional MA (MDMA) has emerged as a flexible channel access technique by elastically exploiting multi-domain resources for tailored service provision. Therefore, we conceive an elastic multi-domain resource utilization mechanism for a novel multi-user OTFS-MDMA system by leveraging user-specific channel characteristics across the DD, power, and spatial resource domains. Specifically, we divide all DD resource bins into separate subregions called DD resource slots (RSs), each of which supports a fraction of users, thus reducing the multi-user interference. Then, the most suitable MA, including orthogonal, non-orthogonal, or spatial division MA (OMA/ NOMA/ SDMA), will be selected with each RS based on the interference levels in the power and spatial domains, thus enhancing the spectrum efficiency. Then, we jointly optimize the user assignment, access scheme selection, and power allocation in all DD RSs to maximize the weighted sum-rate subject to their minimum rate and various practical constraints. Since this results in a non-convex problem, we develop a dynamic programming and monotonic optimization (DPMO) method to find the globally optimal solution in the special case of disregarding rate constraints. Subsequently, we apply a low-complexity algorithm to find sub-optimal solutions in general cases.","sentences":["By harnessing the delay-Doppler (DD) resource domain, orthogonal time-frequency space (OTFS) substantially improves the communication performance under high-mobility scenarios by maintaining quasi-time-invariant channel characteristics.","However, conventional multiple access (MA) techniques fail to efficiently support OTFS in the face of diverse communication requirements.","Recently, multi-dimensional MA (MDMA) has emerged as a flexible channel access technique by elastically exploiting multi-domain resources for tailored service provision.","Therefore, we conceive an elastic multi-domain resource utilization mechanism for a novel multi-user OTFS-MDMA system by leveraging user-specific channel characteristics across the DD, power, and spatial resource domains.","Specifically, we divide all DD resource bins into separate subregions called DD resource slots (RSs), each of which supports a fraction of users, thus reducing the multi-user interference.","Then, the most suitable MA, including orthogonal, non-orthogonal, or spatial division MA (OMA/ NOMA/ SDMA), will be selected with each RS based on the interference levels in the power and spatial domains, thus enhancing the spectrum efficiency.","Then, we jointly optimize the user assignment, access scheme selection, and power allocation in all DD RSs to maximize the weighted sum-rate subject to their minimum rate and various practical constraints.","Since this results in a non-convex problem, we develop a dynamic programming and monotonic optimization (DPMO) method to find the globally optimal solution in the special case of disregarding rate constraints.","Subsequently, we apply a low-complexity algorithm to find sub-optimal solutions in general cases."],"url":"http://arxiv.org/abs/2409.05724v1"}
{"created":"2024-09-09 15:33:07","title":"Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding","abstract":"We propose an approach to referring expression generation (REG) in visually grounded dialogue that is meant to produce referring expressions (REs) that are both discriminative and discourse-appropriate. Our method constitutes a two-stage process. First, we model REG as a text- and image-conditioned next-token prediction task. REs are autoregressively generated based on their preceding linguistic context and a visual representation of the referent. Second, we propose the use of discourse-aware comprehension guiding as part of a generate-and-rerank strategy through which candidate REs generated with our REG model are reranked based on their discourse-dependent discriminatory power. Results from our human evaluation indicate that our proposed two-stage approach is effective in producing discriminative REs, with higher performance in terms of text-image retrieval accuracy for reranked REs compared to those generated using greedy decoding.","sentences":["We propose an approach to referring expression generation (REG) in visually grounded dialogue that is meant to produce referring expressions (REs) that are both discriminative and discourse-appropriate.","Our method constitutes a two-stage process.","First, we model REG as a text- and image-conditioned next-token prediction task.","REs are autoregressively generated based on their preceding linguistic context and a visual representation of the referent.","Second, we propose the use of discourse-aware comprehension guiding as part of a generate-and-rerank strategy through which candidate REs generated with our REG model are reranked based on their discourse-dependent discriminatory power.","Results from our human evaluation indicate that our proposed two-stage approach is effective in producing discriminative REs, with higher performance in terms of text-image retrieval accuracy for reranked REs compared to those generated using greedy decoding."],"url":"http://arxiv.org/abs/2409.05721v1"}
{"created":"2024-09-09 15:22:36","title":"Cooperative Decision-Making for CAVs at Unsignalized Intersections: A MARL Approach with Attention and Hierarchical Game Priors","abstract":"The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems. However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles. While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors. In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations. Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents. The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety. Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort.","sentences":["The development of autonomous vehicles has shown great potential to enhance the efficiency and safety of transportation systems.","However, the decision-making issue in complex human-machine mixed traffic scenarios, such as unsignalized intersections, remains a challenge for autonomous vehicles.","While reinforcement learning (RL) has been used to solve complex decision-making problems, existing RL methods still have limitations in dealing with cooperative decision-making of multiple connected autonomous vehicles (CAVs), ensuring safety during exploration, and simulating realistic human driver behaviors.","In this paper, a novel and efficient algorithm, Multi-Agent Game-prior Attention Deep Deterministic Policy Gradient (MA-GA-DDPG), is proposed to address these limitations.","Our proposed algorithm formulates the decision-making problem of CAVs at unsignalized intersections as a decentralized multi-agent reinforcement learning problem and incorporates an attention mechanism to capture interaction dependencies between ego CAV and other agents.","The attention weights between the ego vehicle and other agents are then used to screen interaction objects and obtain prior hierarchical game relations, based on which a safety inspector module is designed to improve the traffic safety.","Furthermore, both simulation and hardware-in-the-loop experiments were conducted, demonstrating that our method outperforms other baseline approaches in terms of driving safety, efficiency, and comfort."],"url":"http://arxiv.org/abs/2409.05712v1"}
{"created":"2024-09-09 15:14:31","title":"The Influence of Task and Group Disparities over Users' Attitudes Toward Using Large Language Models for Psychotherapy","abstract":"The population suffering from mental health disorders has kept increasing in recent years. With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention. However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored. As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools. Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China. The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools. Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention. These findings can guide the design of future LLM-based psychotherapy services.","sentences":["The population suffering from mental health disorders has kept increasing in recent years.","With the advancements in large language models (LLMs) in diverse fields, LLM-based psychotherapy has also attracted increasingly more attention.","However, the factors influencing users' attitudes to LLM-based psychotherapy have rarely been explored.","As the first attempt, this paper investigated the influence of task and group disparities on user attitudes toward LLM-based psychotherapy tools.","Utilizing the Technology Acceptance Model (TAM) and Automation Acceptance Model (AAM), based on an online survey, we collected and analyzed responses from 222 LLM-based psychotherapy users in mainland China.","The results revealed that group disparity (i.e., mental health conditions) can influence users' attitudes toward LLM tools.","Further, one of the typical task disparities, i.e., the privacy concern, was not found to have a significant effect on trust and usage intention.","These findings can guide the design of future LLM-based psychotherapy services."],"url":"http://arxiv.org/abs/2409.05703v1"}
{"created":"2024-09-09 15:13:56","title":"pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning","abstract":"Federated Learning (FL) offers a decentralized approach to model training, where data remains local and only model parameters are shared between the clients and the central server. Traditional methods, such as Federated Averaging (FedAvg), linearly aggregate these parameters which are usually trained on heterogeneous data distributions, potentially overlooking the complex, high-dimensional nature of the parameter space. This can result in degraded performance of the aggregated model. While personalized FL approaches can mitigate the heterogeneous data issue to some extent, the limitation of linear aggregation remains unresolved. To alleviate this issue, we investigate the generative approach of diffusion model and propose a novel generative parameter aggregation framework for personalized FL, \\texttt{pFedGPA}. In this framework, we deploy a diffusion model on the server to integrate the diverse parameter distributions and propose a parameter inversion method to efficiently generate a set of personalized parameters for each client. This inversion method transforms the uploaded parameters into a latent code, which is then aggregated through denoising sampling to produce the final personalized parameters. By encoding the dependence of a client's model parameters on the specific data distribution using the high-capacity diffusion model, \\texttt{pFedGPA} can effectively decouple the complexity of the overall distribution of all clients' model parameters from the complexity of each individual client's parameter distribution. Our experimental results consistently demonstrate the superior performance of the proposed method across multiple datasets, surpassing baseline approaches.","sentences":["Federated Learning (FL) offers a decentralized approach to model training, where data remains local and only model parameters are shared between the clients and the central server.","Traditional methods, such as Federated Averaging (FedAvg), linearly aggregate these parameters which are usually trained on heterogeneous data distributions, potentially overlooking the complex, high-dimensional nature of the parameter space.","This can result in degraded performance of the aggregated model.","While personalized FL approaches can mitigate the heterogeneous data issue to some extent, the limitation of linear aggregation remains unresolved.","To alleviate this issue, we investigate the generative approach of diffusion model and propose a novel generative parameter aggregation framework for personalized FL, \\texttt{pFedGPA}.","In this framework, we deploy a diffusion model on the server to integrate the diverse parameter distributions and propose a parameter inversion method to efficiently generate a set of personalized parameters for each client.","This inversion method transforms the uploaded parameters into a latent code, which is then aggregated through denoising sampling to produce the final personalized parameters.","By encoding the dependence of a client's model parameters on the specific data distribution using the high-capacity diffusion model, \\texttt{pFedGPA} can effectively decouple the complexity of the overall distribution of all clients' model parameters from the complexity of each individual client's parameter distribution.","Our experimental results consistently demonstrate the superior performance of the proposed method across multiple datasets, surpassing baseline approaches."],"url":"http://arxiv.org/abs/2409.05701v1"}
{"created":"2024-09-09 15:12:28","title":"Boosting CNN-based Handwriting Recognition Systems with Learnable Relaxation Labeling","abstract":"The primary challenge for handwriting recognition systems lies in managing long-range contextual dependencies, an issue that traditional models often struggle with. To mitigate it, attention mechanisms have recently been employed to enhance context-aware labelling, thereby achieving state-of-the-art performance. In the field of pattern recognition and image analysis, however, the use of contextual information in labelling problems has a long history and goes back at least to the early 1970's. Among the various approaches developed in those years, Relaxation Labelling (RL) processes have played a prominent role and have been the method of choice in the field for more than a decade. Contrary to recent transformer-based architectures, RL processes offer a principled approach to the use of contextual constraints, having a solid theoretic foundation grounded on variational inequality and game theory, as well as effective algorithms with convergence guarantees. In this paper, we propose a novel approach to handwriting recognition that integrates the strengths of two distinct methodologies. In particular, we propose integrating (trainable) RL processes with various well-established neural architectures and we introduce a sparsification technique that accelerates the convergence of the algorithm and enhances the overall system's performance. Experiments over several benchmark datasets show that RL processes can improve the generalisation ability, even surpassing in some cases transformer-based architectures.","sentences":["The primary challenge for handwriting recognition systems lies in managing long-range contextual dependencies, an issue that traditional models often struggle with.","To mitigate it, attention mechanisms have recently been employed to enhance context-aware labelling, thereby achieving state-of-the-art performance.","In the field of pattern recognition and image analysis, however, the use of contextual information in labelling problems has a long history and goes back at least to the early 1970's.","Among the various approaches developed in those years, Relaxation Labelling (RL) processes have played a prominent role and have been the method of choice in the field for more than a decade.","Contrary to recent transformer-based architectures, RL processes offer a principled approach to the use of contextual constraints, having a solid theoretic foundation grounded on variational inequality and game theory, as well as effective algorithms with convergence guarantees.","In this paper, we propose a novel approach to handwriting recognition that integrates the strengths of two distinct methodologies.","In particular, we propose integrating (trainable) RL processes with various well-established neural architectures and we introduce a sparsification technique that accelerates the convergence of the algorithm and enhances the overall system's performance.","Experiments over several benchmark datasets show that RL processes can improve the generalisation ability, even surpassing in some cases transformer-based architectures."],"url":"http://arxiv.org/abs/2409.05699v1"}
{"created":"2024-09-09 15:12:24","title":"MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction","abstract":"It is widely acknowledged that extracting market sentiments from news data benefits market predictions. However, existing methods of using financial sentiments remain simplistic, relying on equal-weight and static aggregation to manage sentiments from multiple news items. This leads to a critical issue termed ``Aggregated Sentiment Homogenization'', which has been explored through our analysis of a large financial news dataset from industry practice. This phenomenon occurs when aggregating numerous sentiments, causing representations to converge towards the mean values of sentiment distributions and thereby smoothing out unique and important information. Consequently, the aggregated sentiment representations lose much predictive value of news data. To address this problem, we introduce the Market Attention-weighted News Aggregation Network (MANA-Net), a novel method that leverages a dynamic market-news attention mechanism to aggregate news sentiments for market prediction. MANA-Net learns the relevance of news sentiments to price changes and assigns varying weights to individual news items. By integrating the news aggregation step into the networks for market prediction, MANA-Net allows for trainable sentiment representations that are optimized directly for prediction. We evaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with financial news spanning from 2003 to 2018. Experimental results demonstrate that MANA-Net outperforms various recent market prediction methods, enhancing Profit & Loss by 1.1% and the daily Sharpe ratio by 0.252.","sentences":["It is widely acknowledged that extracting market sentiments from news data benefits market predictions.","However, existing methods of using financial sentiments remain simplistic, relying on equal-weight and static aggregation to manage sentiments from multiple news items.","This leads to a critical issue termed ``Aggregated Sentiment Homogenization'', which has been explored through our analysis of a large financial news dataset from industry practice.","This phenomenon occurs when aggregating numerous sentiments, causing representations to converge towards the mean values of sentiment distributions and thereby smoothing out unique and important information.","Consequently, the aggregated sentiment representations lose much predictive value of news data.","To address this problem, we introduce the Market Attention-weighted News Aggregation Network (MANA-Net), a novel method that leverages a dynamic market-news attention mechanism to aggregate news sentiments for market prediction.","MANA-Net learns the relevance of news sentiments to price changes and assigns varying weights to individual news items.","By integrating the news aggregation step into the networks for market prediction, MANA-Net allows for trainable sentiment representations that are optimized directly for prediction.","We evaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with financial news spanning from 2003 to 2018.","Experimental results demonstrate that MANA-Net outperforms various recent market prediction methods, enhancing Profit & Loss by 1.1% and the daily Sharpe ratio by 0.252."],"url":"http://arxiv.org/abs/2409.05698v1"}
{"created":"2024-09-09 15:11:45","title":"Segmentation by Factorization: Unsupervised Semantic Segmentation for Pathology by Factorizing Foundation Model Features","abstract":"We introduce Segmentation by Factorization (F-SEG), an unsupervised segmentation method for pathology that generates segmentation masks from pre-trained deep learning models. F-SEG allows the use of pre-trained deep neural networks, including recently developed pathology foundation models, for semantic segmentation. It achieves this without requiring additional training or finetuning, by factorizing the spatial features extracted by the models into segmentation masks and their associated concept features. We create generic tissue phenotypes for H&E images by training clustering models for multiple numbers of clusters on features extracted from several deep learning models on The Cancer Genome Atlas Program (TCGA), and then show how the clusters can be used for factorizing corresponding segmentation masks using off-the-shelf deep learning models. Our results show that F-SEG provides robust unsupervised segmentation capabilities for H&E pathology images, and that the segmentation quality is greatly improved by utilizing pathology foundation models. We discuss and propose methods for evaluating the performance of unsupervised segmentation in pathology.","sentences":["We introduce Segmentation by Factorization (F-SEG), an unsupervised segmentation method for pathology that generates segmentation masks from pre-trained deep learning models.","F-SEG allows the use of pre-trained deep neural networks, including recently developed pathology foundation models, for semantic segmentation.","It achieves this without requiring additional training or finetuning, by factorizing the spatial features extracted by the models into segmentation masks and their associated concept features.","We create generic tissue phenotypes for H&E images by training clustering models for multiple numbers of clusters on features extracted from several deep learning models on The Cancer Genome Atlas Program (TCGA), and then show how the clusters can be used for factorizing corresponding segmentation masks using off-the-shelf deep learning models.","Our results show that F-SEG provides robust unsupervised segmentation capabilities for H&E pathology images, and that the segmentation quality is greatly improved by utilizing pathology foundation models.","We discuss and propose methods for evaluating the performance of unsupervised segmentation in pathology."],"url":"http://arxiv.org/abs/2409.05697v1"}
{"created":"2024-09-09 15:11:21","title":"Citizen-Led Personalization of User Interfaces: Investigating How People Customize Interfaces for Themselves and Others","abstract":"User interface (UI) personalization can improve usability and user experience. However, current systems offer limited opportunities for customization, and third-party solutions often require significant effort and technical skills beyond the reach of most users, impeding the future adoption of interface personalization. In our research, we explore the concept of UI customization for the self and others. We performed a two-week study where nine participants used a custom-designed tool that allows websites' UI customization for oneself and to create and reply to customization assistance requests from others. Results suggest that people enjoy customizing for others more than for themselves. They see requests as challenges to solve and are motivated by the positive feeling of helping others. To customize for themselves, people need help with the creative process. We discuss challenges and opportunities for future research seeking to democratize access to personalized UIs, particularly through community-based approaches.","sentences":["User interface (UI) personalization can improve usability and user experience.","However, current systems offer limited opportunities for customization, and third-party solutions often require significant effort and technical skills beyond the reach of most users, impeding the future adoption of interface personalization.","In our research, we explore the concept of UI customization for the self and others.","We performed a two-week study where nine participants used a custom-designed tool that allows websites' UI customization for oneself and to create and reply to customization assistance requests from others.","Results suggest that people enjoy customizing for others more than for themselves.","They see requests as challenges to solve and are motivated by the positive feeling of helping others.","To customize for themselves, people need help with the creative process.","We discuss challenges and opportunities for future research seeking to democratize access to personalized UIs, particularly through community-based approaches."],"url":"http://arxiv.org/abs/2409.05696v1"}
{"created":"2024-09-09 15:05:27","title":"Extracting the U.S. building types from OpenStreetMap data","abstract":"Building type information is crucial for population estimation, traffic planning, urban planning, and emergency response applications. Although essential, such data is often not readily available. To alleviate this problem, this work creates a comprehensive dataset by providing residential/non-residential building classification covering the entire United States. We propose and utilize an unsupervised machine learning method to classify building types based on building footprints and available OpenStreetMap information. The classification result is validated using authoritative ground truth data for select counties in the U.S. The validation shows a high precision for non-residential building classification and a high recall for residential buildings. We identified various approaches to improving the quality of the classification, such as removing sheds and garages from the dataset. Furthermore, analyzing the misclassifications revealed that they are mainly due to missing and scarce metadata in OSM. A major result of this work is the resulting dataset of classifying 67,705,475 buildings. We hope that this data is of value to the scientific community, including urban and transportation planners.","sentences":["Building type information is crucial for population estimation, traffic planning, urban planning, and emergency response applications.","Although essential, such data is often not readily available.","To alleviate this problem, this work creates a comprehensive dataset by providing residential/non-residential building classification covering the entire United States.","We propose and utilize an unsupervised machine learning method to classify building types based on building footprints and available OpenStreetMap information.","The classification result is validated using authoritative ground truth data for select counties in the U.S.","The validation shows a high precision for non-residential building classification and a high recall for residential buildings.","We identified various approaches to improving the quality of the classification, such as removing sheds and garages from the dataset.","Furthermore, analyzing the misclassifications revealed that they are mainly due to missing and scarce metadata in OSM.","A major result of this work is the resulting dataset of classifying 67,705,475 buildings.","We hope that this data is of value to the scientific community, including urban and transportation planners."],"url":"http://arxiv.org/abs/2409.05692v1"}
{"created":"2024-09-09 15:01:29","title":"LayeredFlow: A Real-World Benchmark for Non-Lambertian Multi-Layer Optical Flow","abstract":"Achieving 3D understanding of non-Lambertian objects is an important task with many useful applications, but most existing algorithms struggle to deal with such objects. One major obstacle towards progress in this field is the lack of holistic non-Lambertian benchmarks -- most benchmarks have low scene and object diversity, and none provide multi-layer 3D annotations for objects occluded by transparent surfaces. In this paper, we introduce LayeredFlow, a real world benchmark containing multi-layer ground truth annotation for optical flow of non-Lambertian objects. Compared to previous benchmarks, our benchmark exhibits greater scene and object diversity, with 150k high quality optical flow and stereo pairs taken over 185 indoor and outdoor scenes and 360 unique objects. Using LayeredFlow as evaluation data, we propose a new task called multi-layer optical flow. To provide training data for this task, we introduce a large-scale densely-annotated synthetic dataset containing 60k images within 30 scenes tailored for non-Lambertian objects. Training on our synthetic dataset enables model to predict multi-layer optical flow, while fine-tuning existing optical flow methods on the dataset notably boosts their performance on non-Lambertian objects without compromising the performance on diffuse objects. Data is available at https://layeredflow.cs.princeton.edu.","sentences":["Achieving 3D understanding of non-Lambertian objects is an important task with many useful applications, but most existing algorithms struggle to deal with such objects.","One major obstacle towards progress in this field is the lack of holistic non-Lambertian benchmarks -- most benchmarks have low scene and object diversity, and none provide multi-layer 3D annotations for objects occluded by transparent surfaces.","In this paper, we introduce LayeredFlow, a real world benchmark containing multi-layer ground truth annotation for optical flow of non-Lambertian objects.","Compared to previous benchmarks, our benchmark exhibits greater scene and object diversity, with 150k high quality optical flow and stereo pairs taken over 185 indoor and outdoor scenes and 360 unique objects.","Using LayeredFlow as evaluation data, we propose a new task called multi-layer optical flow.","To provide training data for this task, we introduce a large-scale densely-annotated synthetic dataset containing 60k images within 30 scenes tailored for non-Lambertian objects.","Training on our synthetic dataset enables model to predict multi-layer optical flow, while fine-tuning existing optical flow methods on the dataset notably boosts their performance on non-Lambertian objects without compromising the performance on diffuse objects.","Data is available at https://layeredflow.cs.princeton.edu."],"url":"http://arxiv.org/abs/2409.05688v1"}
{"created":"2024-09-09 14:49:54","title":"SX-Stitch: An Efficient VMS-UNet Based Framework for Intraoperative Scoliosis X-Ray Image Stitching","abstract":"In scoliosis surgery, the limited field of view of the C-arm X-ray machine restricts the surgeons' holistic analysis of spinal structures .This paper presents an end-to-end efficient and robust intraoperative X-ray image stitching method for scoliosis surgery,named SX-Stitch. The method is divided into two stages:segmentation and stitching. In the segmentation stage, We propose a medical image segmentation model named Vision Mamba of Spine-UNet (VMS-UNet), which utilizes the state space Mamba to capture long-distance contextual information while maintaining linear computational complexity, and incorporates the SimAM attention mechanism, significantly improving the segmentation performance.In the stitching stage, we simplify the alignment process between images to the minimization of a registration energy function. The total energy function is then optimized to order unordered images, and a hybrid energy function is introduced to optimize the best seam, effectively eliminating parallax artifacts. On the clinical dataset, Sx-Stitch demonstrates superiority over SOTA schemes both qualitatively and quantitatively.","sentences":["In scoliosis surgery, the limited field of view of the C-arm X-ray machine restricts the surgeons' holistic analysis of spinal structures .This paper presents an end-to-end efficient and robust intraoperative X-ray image stitching method for scoliosis surgery,named SX-Stitch.","The method is divided into two stages:segmentation and stitching.","In the segmentation stage, We propose a medical image segmentation model named Vision Mamba of Spine-UNet (VMS-UNet), which utilizes the state space Mamba to capture long-distance contextual information while maintaining linear computational complexity, and incorporates the SimAM attention mechanism, significantly improving the segmentation performance.","In the stitching stage, we simplify the alignment process between images to the minimization of a registration energy function.","The total energy function is then optimized to order unordered images, and a hybrid energy function is introduced to optimize the best seam, effectively eliminating parallax artifacts.","On the clinical dataset, Sx-Stitch demonstrates superiority over SOTA schemes both qualitatively and quantitatively."],"url":"http://arxiv.org/abs/2409.05681v1"}
{"created":"2024-09-09 14:47:57","title":"AnomalyCD: A benchmark for Earth anomaly change detection with high-resolution and time-series observations","abstract":"Various Earth anomalies have destroyed the stable, balanced state, resulting in fatalities and serious destruction of property. With the advantages of large-scale and precise observation, high-resolution remote sensing images have been widely used for anomaly monitoring and localization. Powered by the deep representation, the existing methods have achieved remarkable advances, primarily in classification and change detection techniques. However, labeled samples are difficult to acquire due to the low probability of anomaly occurrence, and the trained models are limited to fixed anomaly categories, which hinders the application for anomalies with few samples or unknown anomalies. In this paper, to tackle this problem, we propose the anomaly change detection (AnomalyCD) technique, which accepts time-series observations and learns to identify anomalous changes by learning from the historical normal change pattern. Compared to the existing techniques, AnomalyCD processes an unfixed number of time steps and can localize the various anomalies in a unified manner, without human supervision. To benchmark AnomalyCD, we constructed a high-resolution dataset with time-series images dedicated to various Earth anomalies (the AnomalyCDD dataset). AnomalyCDD contains high-resolution (from 0.15 to 2.39 m/pixel), time-series (from 3 to 7 time steps), and large-scale images (1927.93 km2 in total) collected globally Furthermore, we developed a zero-shot baseline model (AnomalyCDM), which implements the AnomalyCD technique by extracting a general representation from the segment anything model (SAM) and conducting temporal comparison to distinguish the anomalous changes from normal changes. AnomalyCDM is designed as a two-stage workflow to enhance the efficiency, and has the ability to process the unseen images directly, without retraining for each scene.","sentences":["Various Earth anomalies have destroyed the stable, balanced state, resulting in fatalities and serious destruction of property.","With the advantages of large-scale and precise observation, high-resolution remote sensing images have been widely used for anomaly monitoring and localization.","Powered by the deep representation, the existing methods have achieved remarkable advances, primarily in classification and change detection techniques.","However, labeled samples are difficult to acquire due to the low probability of anomaly occurrence, and the trained models are limited to fixed anomaly categories, which hinders the application for anomalies with few samples or unknown anomalies.","In this paper, to tackle this problem, we propose the anomaly change detection (AnomalyCD) technique, which accepts time-series observations and learns to identify anomalous changes by learning from the historical normal change pattern.","Compared to the existing techniques, AnomalyCD processes an unfixed number of time steps and can localize the various anomalies in a unified manner, without human supervision.","To benchmark AnomalyCD, we constructed a high-resolution dataset with time-series images dedicated to various Earth anomalies (the AnomalyCDD dataset).","AnomalyCDD contains high-resolution (from 0.15 to 2.39 m/pixel), time-series (from 3 to 7 time steps), and large-scale images (1927.93 km2 in total) collected globally Furthermore, we developed a zero-shot baseline model (AnomalyCDM), which implements the AnomalyCD technique by extracting a general representation from the segment anything model (SAM) and conducting temporal comparison to distinguish the anomalous changes from normal changes.","AnomalyCDM is designed as a two-stage workflow to enhance the efficiency, and has the ability to process the unseen images directly, without retraining for each scene."],"url":"http://arxiv.org/abs/2409.05679v1"}
{"created":"2024-09-09 14:44:19","title":"RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation","abstract":"Regulatory documents, issued by governmental regulatory bodies, establish rules, guidelines, and standards that organizations must adhere to for legal compliance. These documents, characterized by their length, complexity and frequent updates, are challenging to interpret, requiring significant allocation of time and expertise on the part of organizations to ensure ongoing compliance.Regulatory Natural Language Processing (RegNLP) is a multidisciplinary subfield aimed at simplifying access to and interpretation of regulatory rules and obligations. We define an Automated Question-Passage Generation task for RegNLP, create the ObliQA dataset containing 27,869 questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation document collection, design a baseline Regulatory Information Retrieval and Answer Generation system, and evaluate it with RePASs, a novel evaluation metric that tests whether generated answers accurately capture all relevant obligations and avoid contradictions.","sentences":["Regulatory documents, issued by governmental regulatory bodies, establish rules, guidelines, and standards that organizations must adhere to for legal compliance.","These documents, characterized by their length, complexity and frequent updates, are challenging to interpret, requiring significant allocation of time and expertise on the part of organizations to ensure ongoing compliance.","Regulatory Natural Language Processing (RegNLP) is a multidisciplinary subfield aimed at simplifying access to and interpretation of regulatory rules and obligations.","We define an Automated Question-Passage Generation task for RegNLP, create the ObliQA dataset containing 27,869 questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation document collection, design a baseline Regulatory Information Retrieval and Answer Generation system, and evaluate it with RePASs, a novel evaluation metric that tests whether generated answers accurately capture all relevant obligations and avoid contradictions."],"url":"http://arxiv.org/abs/2409.05677v1"}
{"created":"2024-09-09 14:41:57","title":"Evaluation of real-time transcriptions using end-to-end ASR models","abstract":"Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly evolved in the last few years. Traditional architectures based on pipelines have been replaced by joint end-to-end (E2E) architectures that simplify and streamline the model training process. In addition, new AI training methods, such as weak-supervised learning have reduced the need for high-quality audio datasets for model training. However, despite all these advancements, little to no research has been done on real-time transcription. In real-time scenarios, the audio is not pre-recorded, and the input audio must be fragmented to be processed by the ASR systems. To achieve real-time requirements, these fragments must be as short as possible to reduce latency. However, audio cannot be split at any point as dividing an utterance into two separate fragments will generate an incorrect transcription. Also, shorter fragments provide less context for the ASR model. For this reason, it is necessary to design and test different splitting algorithms to optimize the quality and delay of the resulting transcription. In this paper, three audio splitting algorithms are evaluated with different ASR models to determine their impact on both the quality of the transcription and the end-to-end delay. The algorithms are fragmentation at fixed intervals, voice activity detection (VAD), and fragmentation with feedback. The results are compared to the performance of the same model, without audio fragmentation, to determine the effects of this division. The results show that VAD fragmentation provides the best quality with the highest delay, whereas fragmentation at fixed intervals provides the lowest quality and the lowest delay. The newly proposed feedback algorithm exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively, to the VAD splitting.","sentences":["Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly evolved in the last few years.","Traditional architectures based on pipelines have been replaced by joint end-to-end (E2E) architectures that simplify and streamline the model training process.","In addition, new AI training methods, such as weak-supervised learning have reduced the need for high-quality audio datasets for model training.","However, despite all these advancements, little to no research has been done on real-time transcription.","In real-time scenarios, the audio is not pre-recorded, and the input audio must be fragmented to be processed by the ASR systems.","To achieve real-time requirements, these fragments must be as short as possible to reduce latency.","However, audio cannot be split at any point as dividing an utterance into two separate fragments will generate an incorrect transcription.","Also, shorter fragments provide less context for the ASR model.","For this reason, it is necessary to design and test different splitting algorithms to optimize the quality and delay of the resulting transcription.","In this paper, three audio splitting algorithms are evaluated with different ASR models to determine their impact on both the quality of the transcription and the end-to-end delay.","The algorithms are fragmentation at fixed intervals, voice activity detection (VAD), and fragmentation with feedback.","The results are compared to the performance of the same model, without audio fragmentation, to determine the effects of this division.","The results show that VAD fragmentation provides the best quality with the highest delay, whereas fragmentation at fixed intervals provides the lowest quality and the lowest delay.","The newly proposed feedback algorithm exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively, to the VAD splitting."],"url":"http://arxiv.org/abs/2409.05674v1"}
{"created":"2024-09-09 14:41:24","title":"Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!","abstract":"Outlier detection (OD) has a vast literature as it finds numerous applications in environmental monitoring, cybersecurity, finance, and medicine to name a few. Being an inherently unsupervised task, model selection is a key bottleneck for OD (both algorithm and hyperparameter selection) without label supervision. There is a long list of techniques to choose from -- both classical algorithms and deep neural architectures -- and while several studies report their hyperparameter sensitivity, the literature is quite slim on unsupervised model selection -- limiting the effective use of OD in practice. In this paper we present FoMo-0D, for zero/0-shot OD exploring a transformative new direction that bypasses the hurdle of model selection altogether (!), thus breaking new ground. The fundamental idea behind FoMo-0D is the Prior-data Fitted Networks, recently introduced by Muller et al.(2022), which trains a Transformer model on a large body of synthetically generated data from a prior data distribution. In essence, FoMo-0D is a pretrained Foundation Model for zero/0-shot OD on tabular data, which can directly predict the (outlier/inlier) label of any test data at inference time, by merely a single forward pass -- making obsolete the need for choosing an algorithm/architecture, tuning its associated hyperparameters, and even training any model parameters when given a new OD dataset. Extensive experiments on 57 public benchmark datasets against 26 baseline methods show that FoMo-0D performs statistically no different from the top 2nd baseline, while significantly outperforming the majority of the baselines, with an average inference time of 7.7 ms per test sample.","sentences":["Outlier detection (OD) has a vast literature as it finds numerous applications in environmental monitoring, cybersecurity, finance, and medicine to name a few.","Being an inherently unsupervised task, model selection is a key bottleneck for OD (both algorithm and hyperparameter selection) without label supervision.","There is a long list of techniques to choose from -- both classical algorithms and deep neural architectures -- and while several studies report their hyperparameter sensitivity, the literature is quite slim on unsupervised model selection -- limiting the effective use of OD in practice.","In this paper we present FoMo-0D, for zero/0-shot OD exploring a transformative new direction that bypasses the hurdle of model selection altogether (!), thus breaking new ground.","The fundamental idea behind FoMo-0D is the Prior-data Fitted Networks, recently introduced by Muller et al.(2022), which trains a Transformer model on a large body of synthetically generated data from a prior data distribution.","In essence, FoMo-0D is a pretrained Foundation Model for zero/0-shot OD on tabular data, which can directly predict the (outlier/inlier) label of any test data at inference time, by merely a single forward pass -- making obsolete the need for choosing an algorithm/architecture, tuning its associated hyperparameters, and even training any model parameters when given a new OD dataset.","Extensive experiments on 57 public benchmark datasets against 26 baseline methods show that FoMo-0D performs statistically no different from the top 2nd baseline, while significantly outperforming the majority of the baselines, with an average inference time of 7.7 ms per test sample."],"url":"http://arxiv.org/abs/2409.05672v1"}
{"created":"2024-09-09 14:40:21","title":"HyperSteiner: Computing Heuristic Hyperbolic Steiner Minimal Trees","abstract":"We propose HyperSteiner -- an efficient heuristic algorithm for computing Steiner minimal trees in the hyperbolic space. HyperSteiner extends the Euclidean Smith-Lee-Liebman algorithm, which is grounded in a divide-and-conquer approach involving the Delaunay triangulation. The central idea is rephrasing Steiner tree problems with three terminals as a system of equations in the Klein-Beltrami model. Motivated by the fact that hyperbolic geometry is well-suited for representing hierarchies, we explore applications to hierarchy discovery in data. Results show that HyperSteiner infers more realistic hierarchies than the Minimum Spanning Tree and is more scalable to large datasets than Neighbor Joining.","sentences":["We propose HyperSteiner -- an efficient heuristic algorithm for computing Steiner minimal trees in the hyperbolic space.","HyperSteiner extends the Euclidean Smith-Lee-Liebman algorithm, which is grounded in a divide-and-conquer approach involving the Delaunay triangulation.","The central idea is rephrasing Steiner tree problems with three terminals as a system of equations in the Klein-Beltrami model.","Motivated by the fact that hyperbolic geometry is well-suited for representing hierarchies, we explore applications to hierarchy discovery in data.","Results show that HyperSteiner infers more realistic hierarchies than the Minimum Spanning Tree and is more scalable to large datasets than Neighbor Joining."],"url":"http://arxiv.org/abs/2409.05671v1"}
{"created":"2024-09-09 14:38:31","title":"Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models","abstract":"Recent research has seen significant interest in methods for concept removal and targeted forgetting in diffusion models. In this paper, we conduct a comprehensive white-box analysis to expose significant vulnerabilities in existing diffusion model unlearning methods. We show that the objective functions used for unlearning in the existing methods lead to decoupling of the targeted concepts (meant to be forgotten) for the corresponding prompts. This is concealment and not actual unlearning, which was the original goal. The ineffectiveness of current methods stems primarily from their narrow focus on reducing generation probabilities for specific prompt sets, neglecting the diverse modalities of intermediate guidance employed during the inference process. The paper presents a rigorous theoretical and empirical examination of four commonly used techniques for unlearning in diffusion models. We introduce two new evaluation metrics: Concept Retrieval Score (CRS) and Concept Confidence Score (CCS). These metrics are based on a successful adversarial attack setup that can recover forgotten concepts from unlearned diffusion models. The CRS measures the similarity between the latent representations of the unlearned and fully trained models after unlearning. It reports the extent of retrieval of the forgotten concepts with increasing amount of guidance. The CCS quantifies the confidence of the model in assigning the target concept to the manipulated data. It reports the probability of the unlearned model's generations to be aligned with the original domain knowledge with increasing amount of guidance. Evaluating existing unlearning methods with our proposed stringent metrics for diffusion models reveals significant shortcomings in their ability to truly unlearn concepts. Source Code: https://respailab.github.io/unlearning-or-concealment","sentences":["Recent research has seen significant interest in methods for concept removal and targeted forgetting in diffusion models.","In this paper, we conduct a comprehensive white-box analysis to expose significant vulnerabilities in existing diffusion model unlearning methods.","We show that the objective functions used for unlearning in the existing methods lead to decoupling of the targeted concepts (meant to be forgotten) for the corresponding prompts.","This is concealment and not actual unlearning, which was the original goal.","The ineffectiveness of current methods stems primarily from their narrow focus on reducing generation probabilities for specific prompt sets, neglecting the diverse modalities of intermediate guidance employed during the inference process.","The paper presents a rigorous theoretical and empirical examination of four commonly used techniques for unlearning in diffusion models.","We introduce two new evaluation metrics: Concept Retrieval Score (CRS) and Concept Confidence Score (CCS).","These metrics are based on a successful adversarial attack setup that can recover forgotten concepts from unlearned diffusion models.","The CRS measures the similarity between the latent representations of the unlearned and fully trained models after unlearning.","It reports the extent of retrieval of the forgotten concepts with increasing amount of guidance.","The CCS quantifies the confidence of the model in assigning the target concept to the manipulated data.","It reports the probability of the unlearned model's generations to be aligned with the original domain knowledge with increasing amount of guidance.","Evaluating existing unlearning methods with our proposed stringent metrics for diffusion models reveals significant shortcomings in their ability to truly unlearn concepts.","Source Code: https://respailab.github.io/unlearning-or-concealment"],"url":"http://arxiv.org/abs/2409.05668v1"}
