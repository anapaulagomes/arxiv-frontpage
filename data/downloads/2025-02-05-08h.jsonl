{"created":"2025-02-04 18:59:55","title":"Articulate AnyMesh: Open-Vocabulary 3D Articulated Objects Modeling","abstract":"3D articulated objects modeling has long been a challenging problem, since it requires to capture both accurate surface geometries and semantically meaningful and spatially precise structures, parts, and joints. Existing methods heavily depend on training data from a limited set of handcrafted articulated object categories (e.g., cabinets and drawers), which restricts their ability to model a wide range of articulated objects in an open-vocabulary context. To address these limitations, we propose Articulate Anymesh, an automated framework that is able to convert any rigid 3D mesh into its articulated counterpart in an open-vocabulary manner. Given a 3D mesh, our framework utilizes advanced Vision-Language Models and visual prompting techniques to extract semantic information, allowing for both the segmentation of object parts and the construction of functional joints. Our experiments show that Articulate Anymesh can generate large-scale, high-quality 3D articulated objects, including tools, toys, mechanical devices, and vehicles, significantly expanding the coverage of existing 3D articulated object datasets. Additionally, we show that these generated assets can facilitate the acquisition of new articulated object manipulation skills in simulation, which can then be transferred to a real robotic system. Our Github website is https://articulate-anymesh.github.io.","sentences":["3D articulated objects modeling has long been a challenging problem, since it requires to capture both accurate surface geometries and semantically meaningful and spatially precise structures, parts, and joints.","Existing methods heavily depend on training data from a limited set of handcrafted articulated object categories (e.g., cabinets and drawers), which restricts their ability to model a wide range of articulated objects in an open-vocabulary context.","To address these limitations, we propose Articulate Anymesh, an automated framework that is able to convert any rigid 3D mesh into its articulated counterpart in an open-vocabulary manner.","Given a 3D mesh, our framework utilizes advanced Vision-Language Models and visual prompting techniques to extract semantic information, allowing for both the segmentation of object parts and the construction of functional joints.","Our experiments show that Articulate Anymesh can generate large-scale, high-quality 3D articulated objects, including tools, toys, mechanical devices, and vehicles, significantly expanding the coverage of existing 3D articulated object datasets.","Additionally, we show that these generated assets can facilitate the acquisition of new articulated object manipulation skills in simulation, which can then be transferred to a real robotic system.","Our Github website is https://articulate-anymesh.github.io."],"url":"http://arxiv.org/abs/2502.02590v1"}
{"created":"2025-02-04 18:59:46","title":"COCONut-PanCap: Joint Panoptic Segmentation and Grounded Captions for Fine-Grained Understanding and Generation","abstract":"This paper introduces the COCONut-PanCap dataset, created to enhance panoptic segmentation and grounded image captioning. Building upon the COCO dataset with advanced COCONut panoptic masks, this dataset aims to overcome limitations in existing image-text datasets that often lack detailed, scene-comprehensive descriptions. The COCONut-PanCap dataset incorporates fine-grained, region-level captions grounded in panoptic segmentation masks, ensuring consistency and improving the detail of generated captions. Through human-edited, densely annotated descriptions, COCONut-PanCap supports improved training of vision-language models (VLMs) for image understanding and generative models for text-to-image tasks. Experimental results demonstrate that COCONut-PanCap significantly boosts performance across understanding and generation tasks, offering complementary benefits to large-scale datasets. This dataset sets a new benchmark for evaluating models on joint panoptic segmentation and grounded captioning tasks, addressing the need for high-quality, detailed image-text annotations in multi-modal learning.","sentences":["This paper introduces the COCONut-PanCap dataset, created to enhance panoptic segmentation and grounded image captioning.","Building upon the COCO dataset with advanced COCONut panoptic masks, this dataset aims to overcome limitations in existing image-text datasets that often lack detailed, scene-comprehensive descriptions.","The COCONut-PanCap dataset incorporates fine-grained, region-level captions grounded in panoptic segmentation masks, ensuring consistency and improving the detail of generated captions.","Through human-edited, densely annotated descriptions, COCONut-PanCap supports improved training of vision-language models (VLMs) for image understanding and generative models for text-to-image tasks.","Experimental results demonstrate that COCONut-PanCap significantly boosts performance across understanding and generation tasks, offering complementary benefits to large-scale datasets.","This dataset sets a new benchmark for evaluating models on joint panoptic segmentation and grounded captioning tasks, addressing the need for high-quality, detailed image-text annotations in multi-modal learning."],"url":"http://arxiv.org/abs/2502.02589v1"}
{"created":"2025-02-04 18:59:23","title":"Calibrated Multi-Preference Optimization for Aligning Diffusion Models","abstract":"Aligning text-to-image (T2I) diffusion models with preference optimization is valuable for human-annotated datasets, but the heavy cost of manual data collection limits scalability. Using reward models offers an alternative, however, current preference optimization methods fall short in exploiting the rich information, as they only consider pairwise preference distribution. Furthermore, they lack generalization to multi-preference scenarios and struggle to handle inconsistencies between rewards. To address this, we present Calibrated Preference Optimization (CaPO), a novel method to align T2I diffusion models by incorporating the general preference from multiple reward models without human annotated data. The core of our approach involves a reward calibration method to approximate the general preference by computing the expected win-rate against the samples generated by the pretrained models. Additionally, we propose a frontier-based pair selection method that effectively manages the multi-preference distribution by selecting pairs from Pareto frontiers. Finally, we use regression loss to fine-tune diffusion models to match the difference between calibrated rewards of a selected pair. Experimental results show that CaPO consistently outperforms prior methods, such as Direct Preference Optimization (DPO), in both single and multi-reward settings validated by evaluation on T2I benchmarks, including GenEval and T2I-Compbench.","sentences":["Aligning text-to-image (T2I) diffusion models with preference optimization is valuable for human-annotated datasets, but the heavy cost of manual data collection limits scalability.","Using reward models offers an alternative, however, current preference optimization methods fall short in exploiting the rich information, as they only consider pairwise preference distribution.","Furthermore, they lack generalization to multi-preference scenarios and struggle to handle inconsistencies between rewards.","To address this, we present Calibrated Preference Optimization (CaPO), a novel method to align T2I diffusion models by incorporating the general preference from multiple reward models without human annotated data.","The core of our approach involves a reward calibration method to approximate the general preference by computing the expected win-rate against the samples generated by the pretrained models.","Additionally, we propose a frontier-based pair selection method that effectively manages the multi-preference distribution by selecting pairs from Pareto frontiers.","Finally, we use regression loss to fine-tune diffusion models to match the difference between calibrated rewards of a selected pair.","Experimental results show that CaPO consistently outperforms prior methods, such as Direct Preference Optimization (DPO), in both single and multi-reward settings validated by evaluation on T2I benchmarks, including GenEval and T2I-Compbench."],"url":"http://arxiv.org/abs/2502.02588v1"}
{"created":"2025-02-04 18:59:19","title":"Spatio-temporal transformer to support automatic sign language translation","abstract":"Sign Language Translation (SLT) systems support hearing-impaired people communication by finding equivalences between signed and spoken languages. This task is however challenging due to multiple sign variations, complexity in language and inherent richness of expressions. Computational approaches have evidenced capabilities to support SLT. Nonetheless, these approaches remain limited to cover gestures variability and support long sequence translations. This paper introduces a Transformer-based architecture that encodes spatio-temporal motion gestures, preserving both local and long-range spatial information through the use of multiple convolutional and attention mechanisms. The proposed approach was validated on the Colombian Sign Language Translation Dataset (CoL-SLTD) outperforming baseline approaches, and achieving a BLEU4 of 46.84%. Additionally, the proposed approach was validated on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T), achieving a BLEU4 score of 30.77%, demonstrating its robustness and effectiveness in handling real-world variations","sentences":["Sign Language Translation (SLT) systems support hearing-impaired people communication by finding equivalences between signed and spoken languages.","This task is however challenging due to multiple sign variations, complexity in language and inherent richness of expressions.","Computational approaches have evidenced capabilities to support SLT.","Nonetheless, these approaches remain limited to cover gestures variability and support long sequence translations.","This paper introduces a Transformer-based architecture that encodes spatio-temporal motion gestures, preserving both local and long-range spatial information through the use of multiple convolutional and attention mechanisms.","The proposed approach was validated on the Colombian Sign Language Translation Dataset (CoL-SLTD) outperforming baseline approaches, and achieving a BLEU4 of 46.84%.","Additionally, the proposed approach was validated on the RWTH-PHOENIX-Weather-2014T (PHOENIX14T), achieving a BLEU4 score of 30.77%, demonstrating its robustness and effectiveness in handling real-world variations"],"url":"http://arxiv.org/abs/2502.02587v1"}
{"created":"2025-02-04 18:58:31","title":"QLASS: Boosting Language Agent Inference via Q-Guided Stepwise Search","abstract":"Language agents have become a promising solution to complex interactive tasks. One of the key ingredients to the success of language agents is the reward model on the trajectory of the agentic workflow, which provides valuable guidance during training or inference. However, due to the lack of annotations of intermediate interactions, most existing works use an outcome reward model to optimize policies across entire trajectories. This may lead to sub-optimal policies and hinder the overall performance. To address this, we propose QLASS (Q-guided Language Agent Stepwise Search), to automatically generate annotations by estimating Q-values in a stepwise manner for open language agents. By introducing a reasoning tree and performing process reward modeling, QLASS provides effective intermediate guidance for each step. With the stepwise guidance, we propose a Q-guided generation strategy to enable language agents to better adapt to long-term value, resulting in significant performance improvement during model inference on complex interactive agent tasks. Notably, even with almost half the annotated data, QLASS retains strong performance, demonstrating its efficiency in handling limited supervision. We also empirically demonstrate that QLASS can lead to more effective decision making through qualitative analysis. We will release our code and data.","sentences":["Language agents have become a promising solution to complex interactive tasks.","One of the key ingredients to the success of language agents is the reward model on the trajectory of the agentic workflow, which provides valuable guidance during training or inference.","However, due to the lack of annotations of intermediate interactions, most existing works use an outcome reward model to optimize policies across entire trajectories.","This may lead to sub-optimal policies and hinder the overall performance.","To address this, we propose QLASS (Q-guided Language Agent Stepwise Search), to automatically generate annotations by estimating Q-values in a stepwise manner for open language agents.","By introducing a reasoning tree and performing process reward modeling, QLASS provides effective intermediate guidance for each step.","With the stepwise guidance, we propose a Q-guided generation strategy to enable language agents to better adapt to long-term value, resulting in significant performance improvement during model inference on complex interactive agent tasks.","Notably, even with almost half the annotated data, QLASS retains strong performance, demonstrating its efficiency in handling limited supervision.","We also empirically demonstrate that QLASS can lead to more effective decision making through qualitative analysis.","We will release our code and data."],"url":"http://arxiv.org/abs/2502.02584v1"}
{"created":"2025-02-04 18:56:47","title":"Open Materials Generation with Stochastic Interpolants","abstract":"The discovery of new materials is essential for enabling technological advancements. Computational approaches for predicting novel materials must effectively learn the manifold of stable crystal structures within an infinite design space. We introduce Open Materials Generation (OMG), a unifying framework for the generative design and discovery of inorganic crystalline materials. OMG employs stochastic interpolants (SI) to bridge an arbitrary base distribution to the target distribution of inorganic crystals via a broad class of tunable stochastic processes, encompassing both diffusion models and flow matching as special cases. In this work, we adapt the SI framework by integrating an equivariant graph representation of crystal structures and extending it to account for periodic boundary conditions in unit cell representations. Additionally, we couple the SI flow over spatial coordinates and lattice vectors with discrete flow matching for atomic species. We benchmark OMG's performance on two tasks: Crystal Structure Prediction (CSP) for specified compositions, and 'de novo' generation (DNG) aimed at discovering stable, novel, and unique structures. In our ground-up implementation of OMG, we refine and extend both CSP and DNG metrics compared to previous works. OMG establishes a new state-of-the-art in generative modeling for materials discovery, outperforming purely flow-based and diffusion-based implementations. These results underscore the importance of designing flexible deep learning frameworks to accelerate progress in materials science.","sentences":["The discovery of new materials is essential for enabling technological advancements.","Computational approaches for predicting novel materials must effectively learn the manifold of stable crystal structures within an infinite design space.","We introduce Open Materials Generation (OMG), a unifying framework for the generative design and discovery of inorganic crystalline materials.","OMG employs stochastic interpolants (SI) to bridge an arbitrary base distribution to the target distribution of inorganic crystals via a broad class of tunable stochastic processes, encompassing both diffusion models and flow matching as special cases.","In this work, we adapt the SI framework by integrating an equivariant graph representation of crystal structures and extending it to account for periodic boundary conditions in unit cell representations.","Additionally, we couple the SI flow over spatial coordinates and lattice vectors with discrete flow matching for atomic species.","We benchmark OMG's performance on two tasks: Crystal Structure Prediction (CSP) for specified compositions, and 'de novo' generation (DNG) aimed at discovering stable, novel, and unique structures.","In our ground-up implementation of OMG, we refine and extend both CSP and DNG metrics compared to previous works.","OMG establishes a new state-of-the-art in generative modeling for materials discovery, outperforming purely flow-based and diffusion-based implementations.","These results underscore the importance of designing flexible deep learning frameworks to accelerate progress in materials science."],"url":"http://arxiv.org/abs/2502.02582v1"}
{"created":"2025-02-04 18:56:00","title":"Hecate: Unlocking Efficient Sparse Model Training via Fully Sharded Sparse Data Parallelism","abstract":"Mixture-of-Experts (MoE) has emerged as a promising sparse paradigm for scaling up pre-trained models (PTMs) with remarkable cost-effectiveness. However, the dynamic nature of MoE leads to rapid fluctuations and imbalances in expert loads during training, resulting in significant straggler effects that hinder training performance when using expert parallelism (EP). Existing MoE training systems attempt to mitigate these effects through expert rearrangement strategies, but they face challenges in terms of memory efficiency and timeliness of rearrangement. This paper proposes Fully Sharded Sparse Data Parallelism (FSSDP), an innovative approach that tackles the parallelization of MoE layers and potential straggler effects caused by imbalanced expert loads from a new perspective. FSSDP fully shards the parameters and optimizer states of MoE layers across devices and sparsely materializes MoE parameters from scratch in each iteration with two sparse collectives SparseAllGather and SparseReduceScatter. We build Hecate, a high-performance MoE training system that incorporates FSSDP to fully unlock its potential. Hecate introduces heterogeneous sharding, sparse materialization, and re-materialization techniques to construct flexible and efficient expert placements with low memory and communication overhead. Our evaluation reveals that Hecate achieves up to 3.54x speedup compared over state-of-the-art MoE training systems and consistently demonstrates improvements across model architectures and hardware environments.","sentences":["Mixture-of-Experts (MoE) has emerged as a promising sparse paradigm for scaling up pre-trained models (PTMs) with remarkable cost-effectiveness.","However, the dynamic nature of MoE leads to rapid fluctuations and imbalances in expert loads during training, resulting in significant straggler effects that hinder training performance when using expert parallelism (EP).","Existing MoE training systems attempt to mitigate these effects through expert rearrangement strategies, but they face challenges in terms of memory efficiency and timeliness of rearrangement.","This paper proposes Fully Sharded Sparse Data Parallelism (FSSDP), an innovative approach that tackles the parallelization of MoE layers and potential straggler effects caused by imbalanced expert loads from a new perspective.","FSSDP fully shards the parameters and optimizer states of MoE layers across devices and sparsely materializes MoE parameters from scratch in each iteration with two sparse collectives SparseAllGather and SparseReduceScatter.","We build Hecate, a high-performance MoE training system that incorporates FSSDP to fully unlock its potential.","Hecate introduces heterogeneous sharding, sparse materialization, and re-materialization techniques to construct flexible and efficient expert placements with low memory and communication overhead.","Our evaluation reveals that Hecate achieves up to 3.54x speedup compared over state-of-the-art MoE training systems and consistently demonstrates improvements across model architectures and hardware environments."],"url":"http://arxiv.org/abs/2502.02581v1"}
{"created":"2025-02-04 18:54:43","title":"Innovating the software engineering class through multi-team development","abstract":"Often software engineering classes have the student concentrate on designing and planning the project but stop short of actual student team development of code. This leads to criticism by employers of new graduates that they are missing skills in working in teams and coordinating multiple overlapping changes to a code base. Additionally, students that are not actively experiencing team development are unprepared to understand and modify existing legacy-code bases written by others. This paper presents a new approach to teaching undergraduate software engineering that emphasizes not only software engineering methodology but also experiencing development as a member of a team and modifying a legacy code base. Our innovative software engineering course begins with learning the fundamentals of software engineering, followed by examining an existing framework of a social media application. The students are then grouped into multiple software teams, each focusing on a different aspect of the app. The separate teams must define requirements, design, and provide documentation on the services. Using an Agile development approach, the teams incrementally add to the code base and demonstrate features as the application evolves. Subsequent iterations of the class pick up the prior students code base, providing experience working with a legacy code base. Preliminary results of using this approach at the university are presented in this paper including quantitative analysis. Analysis of student software submissions to the cloud-based code repository shows student engagement and contributions over the span of the course. Positive student evaluations show the effectiveness of applying the principles of software engineering to the development of a complex solution in a team environment. Keywords: Software engineering, teaching, college computer science, innovative methods, agile.","sentences":["Often software engineering classes have the student concentrate on designing and planning the project but stop short of actual student team development of code.","This leads to criticism by employers of new graduates that they are missing skills in working in teams and coordinating multiple overlapping changes to a code base.","Additionally, students that are not actively experiencing team development are unprepared to understand and modify existing legacy-code bases written by others.","This paper presents a new approach to teaching undergraduate software engineering that emphasizes not only software engineering methodology but also experiencing development as a member of a team and modifying a legacy code base.","Our innovative software engineering course begins with learning the fundamentals of software engineering, followed by examining an existing framework of a social media application.","The students are then grouped into multiple software teams, each focusing on a different aspect of the app.","The separate teams must define requirements, design, and provide documentation on the services.","Using an Agile development approach, the teams incrementally add to the code base and demonstrate features as the application evolves.","Subsequent iterations of the class pick up the prior students code base, providing experience working with a legacy code base.","Preliminary results of using this approach at the university are presented in this paper including quantitative analysis.","Analysis of student software submissions to the cloud-based code repository shows student engagement and contributions over the span of the course.","Positive student evaluations show the effectiveness of applying the principles of software engineering to the development of a complex solution in a team environment.","Keywords: Software engineering, teaching, college computer science, innovative methods, agile."],"url":"http://arxiv.org/abs/2502.02578v1"}
{"created":"2025-02-04 18:53:42","title":"A comparison of translation performance between DeepL and Supertext","abstract":"As strong machine translation (MT) systems are increasingly based on large language models (LLMs), reliable quality benchmarking requires methods that capture their ability to leverage extended context. This study compares two commercial MT systems -- DeepL and Supertext -- by assessing their performance on unsegmented texts. We evaluate translation quality across four language directions with professional translators assessing segments with full document-level context. While segment-level assessments indicate no strong preference between the systems in most cases, document-level analysis reveals a preference for Supertext in three out of four language directions, suggesting superior consistency across longer texts. We advocate for more context-sensitive evaluation methodologies to ensure that MT quality assessments reflect real-world usability. We release all evaluation data and scripts for further analysis and reproduction at https://github.com/supertext/evaluation_deepl_supertext.","sentences":["As strong machine translation (MT) systems are increasingly based on large language models (LLMs), reliable quality benchmarking requires methods that capture their ability to leverage extended context.","This study compares two commercial MT systems -- DeepL and Supertext -- by assessing their performance on unsegmented texts.","We evaluate translation quality across four language directions with professional translators assessing segments with full document-level context.","While segment-level assessments indicate no strong preference between the systems in most cases, document-level analysis reveals a preference for Supertext in three out of four language directions, suggesting superior consistency across longer texts.","We advocate for more context-sensitive evaluation methodologies to ensure that MT quality assessments reflect real-world usability.","We release all evaluation data and scripts for further analysis and reproduction at https://github.com/supertext/evaluation_deepl_supertext."],"url":"http://arxiv.org/abs/2502.02577v1"}
{"created":"2025-02-04 18:47:31","title":"Are Language Models Up to Sequential Optimization Problems? From Evaluation to a Hegelian-Inspired Enhancement","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem-solving, a crucial, ubiquitous, and complex domain. This paper explores the proficiency of LLMs in handling Sequential Optimization Problems (SOPs). We introduce WorldGen, a dynamic framework for generating unseen SOPs with controllable complexities, to evaluate LLM performance. Our initial observations reveal that while LLMs perform well on simple SOPs, their performance significantly degrades with increased complexity. Motivated by this, we revisit philosophical hypotheses on reasoning to enhance LLM performance. Inspired by the influential framework of Hegelian Dialectics, we propose ACE, demonstrating how the performance of LLMs in SOP contexts can be significantly improved without any retraining or further fine-tuning.","sentences":["Large Language Models (LLMs) have demonstrated impressive capabilities across numerous fields, presenting an opportunity to revolutionize optimization problem-solving, a crucial, ubiquitous, and complex domain.","This paper explores the proficiency of LLMs in handling Sequential Optimization Problems (SOPs).","We introduce WorldGen, a dynamic framework for generating unseen SOPs with controllable complexities, to evaluate LLM performance.","Our initial observations reveal that while LLMs perform well on simple SOPs, their performance significantly degrades with increased complexity.","Motivated by this, we revisit philosophical hypotheses on reasoning to enhance LLM performance.","Inspired by the influential framework of Hegelian Dialectics, we propose ACE, demonstrating how the performance of LLMs in SOP contexts can be significantly improved without any retraining or further fine-tuning."],"url":"http://arxiv.org/abs/2502.02573v1"}
{"created":"2025-02-04 18:47:19","title":"Algorithms and Hardness Results for the $(k,\\ell)$-Cover Problem","abstract":"A connected graph has a $(k,\\ell)$-cover if each of its edges is contained in at least $\\ell$ cliques of order $k$. Motivated by recent advances in extremal combinatorics and the literature on edge modification problems, we study the algorithmic version of the $(k,\\ell)$-cover problem. Given a connected graph $G$, the $(k, \\ell)$-cover problem is to identify the smallest subset of non-edges of $G$ such that their addition to $G$ results in a graph with a $(k, \\ell)$-cover. For every constant $k\\geq3$, we show that the $(k,1)$-cover problem is $\\mathbb{NP}$-complete for general graphs. Moreover, we show that for every constant $k\\geq 3$, the $(k,1)$-cover problem admits no polynomial-time constant-factor approximation algorithm unless $\\mathbb{P}=\\mathbb{NP}$. However, we show that the $(3,1)$-cover problem can be solved in polynomial time when the input graph is chordal. For the class of trees and general values of $k$, we show that the $(k,1)$-cover problem is $\\mathbb{NP}$-hard even for spiders. However, we show that for every $k\\geq4$, the $(3,k-2)$-cover and the $(k,1)$-cover problems are constant-factor approximable when the input graph is a tree.","sentences":["A connected graph has a $(k,\\ell)$-cover if each of its edges is contained in at least $\\ell$ cliques of order $k$. Motivated by recent advances in extremal combinatorics and the literature on edge modification problems, we study the algorithmic version of the $(k,\\ell)$-cover problem.","Given a connected graph $G$, the $(k, \\ell)$-cover problem is to identify the smallest subset of non-edges of $G$ such that their addition to $G$ results in a graph with a $(k, \\ell)$-cover.","For every constant $k\\geq3$, we show that the $(k,1)$-cover problem is $\\mathbb{NP}$-complete for general graphs.","Moreover, we show that for every constant $k\\geq 3$, the $(k,1)$-cover problem admits no polynomial-time constant-factor approximation algorithm unless $\\mathbb{P}=\\mathbb{NP}$. However, we show that the $(3,1)$-cover problem can be solved in polynomial time when the input graph is chordal.","For the class of trees and general values of $k$, we show that the $(k,1)$-cover problem is $\\mathbb{NP}$-hard even for spiders.","However, we show that for every $k\\geq4$, the $(3,k-2)$-cover and the $(k,1)$-cover problems are constant-factor approximable when the input graph is a tree."],"url":"http://arxiv.org/abs/2502.02572v1"}
{"created":"2025-02-04 18:40:38","title":"Fairness in Survival Analysis: A Novel Conditional Mutual Information Augmentation Approach","abstract":"Survival analysis, a vital tool for predicting the time to event, has been used in many domains such as healthcare, criminal justice, and finance. Like classification tasks, survival analysis can exhibit bias against disadvantaged groups, often due to biases inherent in data or algorithms. Several studies in both the IS and CS communities have attempted to address fairness in survival analysis. However, existing methods often overlook the importance of prediction fairness at pre-defined evaluation time points, which is crucial in real-world applications where decision making often hinges on specific time frames. To address this critical research gap, we introduce a new fairness concept: equalized odds (EO) in survival analysis, which emphasizes prediction fairness at pre-defined time points. To achieve the EO fairness in survival analysis, we propose a Conditional Mutual Information Augmentation (CMIA) approach, which features a novel fairness regularization term based on conditional mutual information and an innovative censored data augmentation technique. Our CMIA approach can effectively balance prediction accuracy and fairness, and it is applicable to various survival models. We evaluate the CMIA approach against several state-of-the-art methods within three different application domains, and the results demonstrate that CMIA consistently reduces prediction disparity while maintaining good accuracy and significantly outperforms the other competing methods across multiple datasets and survival models (e.g., linear COX, deep AFT).","sentences":["Survival analysis, a vital tool for predicting the time to event, has been used in many domains such as healthcare, criminal justice, and finance.","Like classification tasks, survival analysis can exhibit bias against disadvantaged groups, often due to biases inherent in data or algorithms.","Several studies in both the IS and CS communities have attempted to address fairness in survival analysis.","However, existing methods often overlook the importance of prediction fairness at pre-defined evaluation time points, which is crucial in real-world applications where decision making often hinges on specific time frames.","To address this critical research gap, we introduce a new fairness concept: equalized odds (EO) in survival analysis, which emphasizes prediction fairness at pre-defined time points.","To achieve the EO fairness in survival analysis, we propose a Conditional Mutual Information Augmentation (CMIA) approach, which features a novel fairness regularization term based on conditional mutual information and an innovative censored data augmentation technique.","Our CMIA approach can effectively balance prediction accuracy and fairness, and it is applicable to various survival models.","We evaluate the CMIA approach against several state-of-the-art methods within three different application domains, and the results demonstrate that CMIA consistently reduces prediction disparity while maintaining good accuracy and significantly outperforms the other competing methods across multiple datasets and survival models (e.g., linear COX, deep AFT)."],"url":"http://arxiv.org/abs/2502.02567v1"}
{"created":"2025-02-04 18:40:32","title":"Revisiting Expected Possession Value in Football: Introducing a Benchmark, U-Net Architecture, and Reward and Risk for Passes","abstract":"This paper introduces the first Expected Possession Value (EPV) benchmark and a new and improved EPV model for football. Through the introduction of the OJN-Pass-EPV benchmark, we present a novel method to quantitatively assess the quality of EPV models by using pairs of game states with given relative EPVs. Next, we attempt to replicate the results of Fern\\'andez et al. (2021) using a dataset containing Dutch Eredivisie and World Cup matches. Following our failure to do so, we propose a new architecture based on U-net-type convolutional neural networks, achieving good results in model loss and Expected Calibration Error. Finally, we present an improved pass model that incorporates ball height and contains a new dual-component pass value model that analyzes reward and risk. The resulting EPV model correctly identifies the higher value state in 78% of the game state pairs in the OJN-Pass-EPV benchmark, demonstrating its ability to accurately assess goal-scoring potential. Our findings can help assess the quality of EPV models, improve EPV predictions, help assess potential reward and risk of passing decisions, and improve player and team performance.","sentences":["This paper introduces the first Expected Possession Value (EPV) benchmark and a new and improved EPV model for football.","Through the introduction of the OJN-Pass-EPV benchmark, we present a novel method to quantitatively assess the quality of EPV models by using pairs of game states with given relative EPVs.","Next, we attempt to replicate the results of Fern\\'andez et al.","(2021) using a dataset containing Dutch Eredivisie and World Cup matches.","Following our failure to do so, we propose a new architecture based on U-net-type convolutional neural networks, achieving good results in model loss and Expected Calibration Error.","Finally, we present an improved pass model that incorporates ball height and contains a new dual-component pass value model that analyzes reward and risk.","The resulting EPV model correctly identifies the higher value state in 78% of the game state pairs in the OJN-Pass-EPV benchmark, demonstrating its ability to accurately assess goal-scoring potential.","Our findings can help assess the quality of EPV models, improve EPV predictions, help assess potential reward and risk of passing decisions, and improve player and team performance."],"url":"http://arxiv.org/abs/2502.02565v1"}
{"created":"2025-02-04 18:39:10","title":"CReIS: Computation Reuse through Image Similarity in ICN-Based Edge Computing","abstract":"At the edge, there is a high level of similarity in computing. One approach that has been proposed to enhance the efficiency of edge computing is computation reuse, which eliminates redundant computations. Edge computing is integrated with the ICN architecture, capitalizing on its inherent intelligence to facilitate computation reuse and reduce redundancies in computing operations. In many past works, ICN's ability to enable computation reuse through caching has been limited. In this context, a new approach is proposed that considers computation requests with similar input data, which yield identical results, as equivalent. This method facilitates computation reuse through caching in ICN. The use of approximate results to reduce redundant computations without requiring high accuracy in input matching is provided. This concept is termed the Similarity Index, which effectively considers images to be similar despite minor changes in the angle of photography. The Similarity Index is determined through an algorithm known as HNSW and utilizes the SIFT descriptor to identify similar data. This approach helps reduce user latency times by providing quick access to results. The evaluation, simulated using the ndnSIM tool, showed an 86% improvement in completion time compared to scenarios without computation reuse, whereas previous works reported only a 70% improvement. To strengthen this method, an analytical model for computing request transfer considering computation reuse in ICN-based edge computing is provided. To assess the accuracy of the model, several evaluations have been conducted in the simulator by varying the parameters, resulting in a maximum error percentage of approximately 16%.","sentences":["At the edge, there is a high level of similarity in computing.","One approach that has been proposed to enhance the efficiency of edge computing is computation reuse, which eliminates redundant computations.","Edge computing is integrated with the ICN architecture, capitalizing on its inherent intelligence to facilitate computation reuse and reduce redundancies in computing operations.","In many past works, ICN's ability to enable computation reuse through caching has been limited.","In this context, a new approach is proposed that considers computation requests with similar input data, which yield identical results, as equivalent.","This method facilitates computation reuse through caching in ICN.","The use of approximate results to reduce redundant computations without requiring high accuracy in input matching is provided.","This concept is termed the Similarity Index, which effectively considers images to be similar despite minor changes in the angle of photography.","The Similarity Index is determined through an algorithm known as HNSW and utilizes the SIFT descriptor to identify similar data.","This approach helps reduce user latency times by providing quick access to results.","The evaluation, simulated using the ndnSIM tool, showed an 86% improvement in completion time compared to scenarios without computation reuse, whereas previous works reported only a 70% improvement.","To strengthen this method, an analytical model for computing request transfer considering computation reuse in ICN-based edge computing is provided.","To assess the accuracy of the model, several evaluations have been conducted in the simulator by varying the parameters, resulting in a maximum error percentage of approximately 16%."],"url":"http://arxiv.org/abs/2502.02564v1"}
{"created":"2025-02-04 18:37:17","title":"Learning the RoPEs: Better 2D and 3D Position Encodings with STRING","abstract":"We introduce STRING: Separable Translationally Invariant Position Encodings. STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework. Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint. These properties are especially important in robotics, where efficient 3D token representation is key. We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers. We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods.","sentences":["We introduce STRING:","Separable Translationally Invariant Position Encodings.","STRING extends Rotary Position Encodings, a recently proposed and widely used algorithm in large language models, via a unifying theoretical framework.","Importantly, STRING still provides exact translation invariance, including token coordinates of arbitrary dimensionality, whilst maintaining a low computational footprint.","These properties are especially important in robotics, where efficient 3D token representation is key.","We integrate STRING into Vision Transformers with RGB(-D) inputs (color plus optional depth), showing substantial gains, e.g. in open-vocabulary object detection and for robotics controllers.","We complement our experiments with a rigorous mathematical analysis, proving the universality of our methods."],"url":"http://arxiv.org/abs/2502.02562v1"}
{"created":"2025-02-04 18:37:10","title":"Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents","abstract":"A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions in ways that can usefully inform downstream action. This interface between prediction uncertainty and decision-making is especially important in risk-sensitive domains, such as medicine. In this paper, we develop decision-theoretic foundations that connect uncertainty quantification using prediction sets with risk-averse decision-making. Specifically, we answer three fundamental questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers? We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk. (2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions? We show that a simple max-min decision policy is optimal for risk-averse decision makers. Finally, (3) How can we derive prediction sets that are optimal for such decision makers? We provide an exact characterization in the population regime and a distribution free finite-sample construction. Answering these questions naturally leads to an algorithm, Risk-Averse Calibration (RAC), which follows a provably optimal design for deriving action policies from predictions. RAC is designed to be both practical-capable of leveraging the quality of predictions in a black-box manner to enhance downstream utility-and safe-adhering to a user-defined risk threshold and optimizing the corresponding risk quantile of the user's downstream utility. Finally, we experimentally demonstrate the significant advantages of RAC in applications such as medical diagnosis and recommendation systems. Specifically, we show that RAC achieves a substantially improved trade-off between safety and utility, offering higher utility compared to existing methods while maintaining the safety guarantee.","sentences":["A fundamental question in data-driven decision making is how to quantify the uncertainty of predictions in ways that can usefully inform downstream action.","This interface between prediction uncertainty and decision-making is especially important in risk-sensitive domains, such as medicine.","In this paper, we develop decision-theoretic foundations that connect uncertainty quantification using prediction sets with risk-averse decision-making.","Specifically, we answer three fundamental questions: (1) What is the correct notion of uncertainty quantification for risk-averse decision makers?","We prove that prediction sets are optimal for decision makers who wish to optimize their value at risk.","(2) What is the optimal policy that a risk averse decision maker should use to map prediction sets to actions?","We show that a simple max-min decision policy is optimal for risk-averse decision makers.","Finally, (3) How can we derive prediction sets that are optimal for such decision makers?","We provide an exact characterization in the population regime and a distribution free finite-sample construction.","Answering these questions naturally leads to an algorithm, Risk-Averse Calibration (RAC), which follows a provably optimal design for deriving action policies from predictions.","RAC is designed to be both practical-capable of leveraging the quality of predictions in a black-box manner to enhance downstream utility-and safe-adhering to a user-defined risk threshold and optimizing the corresponding risk quantile of the user's downstream utility.","Finally, we experimentally demonstrate the significant advantages of RAC in applications such as medical diagnosis and recommendation systems.","Specifically, we show that RAC achieves a substantially improved trade-off between safety and utility, offering higher utility compared to existing methods while maintaining the safety guarantee."],"url":"http://arxiv.org/abs/2502.02561v1"}
{"created":"2025-02-04 18:34:17","title":"A Family-Based Approach to Safety Cases for Controlled Airspaces in Small Uncrewed Aerial Systems","abstract":"As small Uncrewed Aircraft Systems (sUAS) increasingly operate in the national airspace, safety concerns arise due to a corresponding rise in reported airspace violations and incidents, highlighting the need for a safe mechanism for sUAS entry control to manage the potential overload. This paper presents work toward our aim of establishing automated, customized safety-claim support for managing on-entry requests from sUAS to enter controlled airspace. We describe our approach, Safety Case Software Product Line Engineering (SafeSPLE), which is a novel method to extend product-family techniques to on-entry safety cases. It begins with a hazard analysis and design of a safety case feature model defining key points in variation, followed by the creation of a parameterized safety case. We use these together to automate the generation of instances for specific sUAS. Finally we use a case study to demonstrate that the SafeSPLE method can be used to facilitate creation of safety cases for specific flights.","sentences":["As small Uncrewed Aircraft Systems (sUAS) increasingly operate in the national airspace, safety concerns arise due to a corresponding rise in reported airspace violations and incidents, highlighting the need for a safe mechanism for sUAS entry control to manage the potential overload.","This paper presents work toward our aim of establishing automated, customized safety-claim support for managing on-entry requests from sUAS to enter controlled airspace.","We describe our approach, Safety Case Software Product Line Engineering (SafeSPLE), which is a novel method to extend product-family techniques to on-entry safety cases.","It begins with a hazard analysis and design of a safety case feature model defining key points in variation, followed by the creation of a parameterized safety case.","We use these together to automate the generation of instances for specific sUAS.","Finally we use a case study to demonstrate that the SafeSPLE method can be used to facilitate creation of safety cases for specific flights."],"url":"http://arxiv.org/abs/2502.02559v1"}
{"created":"2025-02-04 18:23:22","title":"Hierarchical Sparse Bayesian Multitask Model with Scalable Inference for Microbiome Analysis","abstract":"This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks. We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution. We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile. Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods. Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks. Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics. Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results.","sentences":["This paper proposes a hierarchical Bayesian multitask learning model that is applicable to the general multi-task binary classification learning problem where the model assumes a shared sparsity structure across different tasks.","We derive a computationally efficient inference algorithm based on variational inference to approximate the posterior distribution.","We demonstrate the potential of the new approach on various synthetic datasets and for predicting human health status based on microbiome profile.","Our analysis incorporates data pooled from multiple microbiome studies, along with a comprehensive comparison with other benchmark methods.","Results in synthetic datasets show that the proposed approach has superior support recovery property when the underlying regression coefficients share a common sparsity structure across different tasks.","Our experiments on microbiome classification demonstrate the utility of the method in extracting informative taxa while providing well-calibrated predictions with uncertainty quantification and achieving competitive performance in terms of prediction metrics.","Notably, despite the heterogeneity of the pooled datasets (e.g., different experimental objectives, laboratory setups, sequencing equipment, patient demographics), our method delivers robust results."],"url":"http://arxiv.org/abs/2502.02552v1"}
{"created":"2025-02-04 18:19:40","title":"Anytime Incremental $\u03c1$POMDP Planning in Continuous Spaces","abstract":"Partially Observable Markov Decision Processes (POMDPs) provide a robust framework for decision-making under uncertainty in applications such as autonomous driving and robotic exploration. Their extension, $\\rho$POMDPs, introduces belief-dependent rewards, enabling explicit reasoning about uncertainty. Existing online $\\rho$POMDP solvers for continuous spaces rely on fixed belief representations, limiting adaptability and refinement - critical for tasks such as information-gathering. We present $\\rho$POMCPOW, an anytime solver that dynamically refines belief representations, with formal guarantees of improvement over time. To mitigate the high computational cost of updating belief-dependent rewards, we propose a novel incremental computation approach. We demonstrate its effectiveness for common entropy estimators, reducing computational cost by orders of magnitude. Experimental results show that $\\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency and solution quality.","sentences":["Partially Observable Markov Decision Processes (POMDPs) provide a robust framework for decision-making under uncertainty in applications such as autonomous driving and robotic exploration.","Their extension, $\\rho$POMDPs, introduces belief-dependent rewards, enabling explicit reasoning about uncertainty.","Existing online $\\rho$POMDP solvers for continuous spaces rely on fixed belief representations, limiting adaptability and refinement - critical for tasks such as information-gathering.","We present $\\rho$POMCPOW, an anytime solver that dynamically refines belief representations, with formal guarantees of improvement over time.","To mitigate the high computational cost of updating belief-dependent rewards, we propose a novel incremental computation approach.","We demonstrate its effectiveness for common entropy estimators, reducing computational cost by orders of magnitude.","Experimental results show that $\\rho$POMCPOW outperforms state-of-the-art solvers in both efficiency and solution quality."],"url":"http://arxiv.org/abs/2502.02549v1"}
{"created":"2025-02-04 18:18:50","title":"Mosaic3D: Foundation Dataset and Model for Open-Vocabulary 3D Segmentation","abstract":"We tackle open-vocabulary 3D scene understanding by introducing a novel data generation pipeline and training framework. Our method addresses three critical requirements for effective training: precise 3D region segmentation, comprehensive textual descriptions, and sufficient dataset scale. By leveraging state-of-the-art open-vocabulary image segmentation models and region-aware Vision-Language Models, we develop an automatic pipeline that generates high-quality 3D mask-text pairs. Applying this pipeline to multiple 3D scene datasets, we create Mosaic3D-5.6M, a dataset of over 30K annotated scenes with 5.6M mask-text pairs, significantly larger than existing datasets. Building upon this data, we propose Mosaic3D, a foundation model combining a 3D encoder trained with contrastive learning and a lightweight mask decoder for open-vocabulary 3D semantic and instance segmentation. Our approach achieves state-of-the-art results on open-vocabulary 3D semantic and instance segmentation tasks including ScanNet200, Matterport3D, and ScanNet++, with ablation studies validating the effectiveness of our large-scale training data.","sentences":["We tackle open-vocabulary 3D scene understanding by introducing a novel data generation pipeline and training framework.","Our method addresses three critical requirements for effective training: precise 3D region segmentation, comprehensive textual descriptions, and sufficient dataset scale.","By leveraging state-of-the-art open-vocabulary image segmentation models and region-aware Vision-Language Models, we develop an automatic pipeline that generates high-quality 3D mask-text pairs.","Applying this pipeline to multiple 3D scene datasets, we create Mosaic3D-5.6M, a dataset of over 30K annotated scenes with 5.6M mask-text pairs, significantly larger than existing datasets.","Building upon this data, we propose Mosaic3D, a foundation model combining a 3D encoder trained with contrastive learning and a lightweight mask decoder for open-vocabulary 3D semantic and instance segmentation.","Our approach achieves state-of-the-art results on open-vocabulary 3D semantic and instance segmentation tasks including ScanNet200, Matterport3D, and ScanNet++, with ablation studies validating the effectiveness of our large-scale training data."],"url":"http://arxiv.org/abs/2502.02548v1"}
{"created":"2025-02-04 18:15:51","title":"Optimal Spectral Transitions in High-Dimensional Multi-Index Models","abstract":"We consider the problem of how many samples from a Gaussian multi-index model are required to weakly reconstruct the relevant index subspace. Despite its increasing popularity as a testbed for investigating the computational complexity of neural networks, results beyond the single-index setting remain elusive. In this work, we introduce spectral algorithms based on the linearization of a message passing scheme tailored to this problem. Our main contribution is to show that the proposed methods achieve the optimal reconstruction threshold. Leveraging a high-dimensional characterization of the algorithms, we show that above the critical threshold the leading eigenvector correlates with the relevant index subspace, a phenomenon reminiscent of the Baik-Ben Arous-Peche (BBP) transition in spiked models arising in random matrix theory. Supported by numerical experiments and a rigorous theoretical framework, our work bridges critical gaps in the computational limits of weak learnability in multi-index model.","sentences":["We consider the problem of how many samples from a Gaussian multi-index model are required to weakly reconstruct the relevant index subspace.","Despite its increasing popularity as a testbed for investigating the computational complexity of neural networks, results beyond the single-index setting remain elusive.","In this work, we introduce spectral algorithms based on the linearization of a message passing scheme tailored to this problem.","Our main contribution is to show that the proposed methods achieve the optimal reconstruction threshold.","Leveraging a high-dimensional characterization of the algorithms, we show that above the critical threshold the leading eigenvector correlates with the relevant index subspace, a phenomenon reminiscent of the Baik-Ben Arous-Peche (BBP) transition in spiked models arising in random matrix theory.","Supported by numerical experiments and a rigorous theoretical framework, our work bridges critical gaps in the computational limits of weak learnability in multi-index model."],"url":"http://arxiv.org/abs/2502.02545v1"}
{"created":"2025-02-04 18:14:27","title":"Addressing Label Shift in Distributed Learning via Entropy Regularization","abstract":"We address the challenge of minimizing true risk in multi-node distributed learning. These systems are frequently exposed to both inter-node and intra-node label shifts, which present a critical obstacle to effectively optimizing model performance while ensuring that data remains confined to each node. To tackle this, we propose the Versatile Robust Label Shift (VRLS) method, which enhances the maximum likelihood estimation of the test-to-train label density ratio. VRLS incorporates Shannon entropy-based regularization and adjusts the density ratio during training to better handle label shifts at the test time. In multi-node learning environments, VRLS further extends its capabilities by learning and adapting density ratios across nodes, effectively mitigating label shifts and improving overall model performance. Experiments conducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness of VRLS, outperforming baselines by up to 20% in imbalanced settings. These results highlight the significant improvements VRLS offers in addressing label shifts. Our theoretical analysis further supports this by establishing high-probability bounds on estimation errors.","sentences":["We address the challenge of minimizing true risk in multi-node distributed learning.","These systems are frequently exposed to both inter-node and intra-node label shifts, which present a critical obstacle to effectively optimizing model performance while ensuring that data remains confined to each node.","To tackle this, we propose the Versatile Robust Label Shift (VRLS) method, which enhances the maximum likelihood estimation of the test-to-train label density ratio.","VRLS incorporates Shannon entropy-based regularization and adjusts the density ratio during training to better handle label shifts at the test time.","In multi-node learning environments, VRLS further extends its capabilities by learning and adapting density ratios across nodes, effectively mitigating label shifts and improving overall model performance.","Experiments conducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness of VRLS, outperforming baselines by up to 20% in imbalanced settings.","These results highlight the significant improvements VRLS offers in addressing label shifts.","Our theoretical analysis further supports this by establishing high-probability bounds on estimation errors."],"url":"http://arxiv.org/abs/2502.02544v1"}
{"created":"2025-02-04 18:13:50","title":"Posted Price Mechanisms for Online Allocation with Diseconomies of Scale","abstract":"This paper addresses the online $k$-selection problem with diseconomies of scale (OSDoS), where a seller seeks to maximize social welfare by optimally pricing items for sequentially arriving buyers, accounting for increasing marginal production costs. Previous studies have investigated deterministic dynamic pricing mechanisms for such settings. However, significant challenges remain, particularly in achieving optimality with small or finite inventories and developing effective randomized posted price mechanisms. To bridge this gap, we propose a novel randomized dynamic pricing mechanism for OSDoS, providing a tighter lower bound on the competitive ratio compared to prior work. Our approach ensures optimal performance in small inventory settings (i.e., when $k$ is small) and surpasses existing online mechanisms in large inventory settings (i.e., when $k$ is large), leading to the best-known posted price mechanism for optimizing online selection and allocation with diseconomies of scale across varying inventory sizes.","sentences":["This paper addresses the online $k$-selection problem with diseconomies of scale (OSDoS), where a seller seeks to maximize social welfare by optimally pricing items for sequentially arriving buyers, accounting for increasing marginal production costs.","Previous studies have investigated deterministic dynamic pricing mechanisms for such settings.","However, significant challenges remain, particularly in achieving optimality with small or finite inventories and developing effective randomized posted price mechanisms.","To bridge this gap, we propose a novel randomized dynamic pricing mechanism for OSDoS, providing a tighter lower bound on the competitive ratio compared to prior work.","Our approach ensures optimal performance in small inventory settings (i.e., when $k$ is small) and surpasses existing online mechanisms in large inventory settings (i.e., when $k$ is large), leading to the best-known posted price mechanism for optimizing online selection and allocation with diseconomies of scale across varying inventory sizes."],"url":"http://arxiv.org/abs/2502.02543v1"}
{"created":"2025-02-04 18:12:41","title":"OVERTHINKING: Slowdown Attacks on Reasoning LLMs","abstract":"We increase overhead for applications that rely on reasoning LLMs-we force models to spend an amplified number of reasoning tokens, i.e., \"overthink\", to respond to the user query while providing contextually correct answers. The adversary performs an OVERTHINK attack by injecting decoy reasoning problems into the public content that is used by the reasoning LLM (e.g., for RAG applications) during inference time. Due to the nature of our decoy problems (e.g., a Markov Decision Process), modified texts do not violate safety guardrails. We evaluated our attack across closed-(OpenAI o1, o1-mini, o3-mini) and open-(DeepSeek R1) weights reasoning models on the FreshQA and SQuAD datasets. Our results show up to 46x slowdown and high transferability of the attack across models. To protect applications, we discuss and implement defenses leveraging LLM-based and system design approaches. Finally, we discuss societal, financial, and energy impacts of OVERTHINK attack which could amplify the costs for third party applications operating reasoning models.","sentences":["We increase overhead for applications that rely on reasoning LLMs-we force models to spend an amplified number of reasoning tokens, i.e., \"overthink\", to respond to the user query while providing contextually correct answers.","The adversary performs an OVERTHINK attack by injecting decoy reasoning problems into the public content that is used by the reasoning LLM (e.g., for RAG applications) during inference time.","Due to the nature of our decoy problems (e.g., a Markov Decision Process), modified texts do not violate safety guardrails.","We evaluated our attack across closed-(OpenAI o1, o1-mini, o3-mini) and open-(DeepSeek R1) weights reasoning models on the FreshQA and SQuAD datasets.","Our results show up to 46x slowdown and high transferability of the attack across models.","To protect applications, we discuss and implement defenses leveraging LLM-based and system design approaches.","Finally, we discuss societal, financial, and energy impacts of OVERTHINK attack which could amplify the costs for third party applications operating reasoning models."],"url":"http://arxiv.org/abs/2502.02542v1"}
{"created":"2025-02-04 18:10:10","title":"Optimal Security Response to Network Intrusions in IT Systems","abstract":"Cybersecurity is one of the most pressing technological challenges of our time and requires measures from all sectors of society. A key measure is automated security response, which enables automated mitigation and recovery from cyber attacks. Significant strides toward such automation have been made due to the development of rule-based response systems. However, these systems have a critical drawback: they depend on domain experts to configure the rules, a process that is both error-prone and inefficient. Framing security response as an optimal control problem shows promise in addressing this limitation but introduces new challenges. Chief among them is bridging the gap between theoretical optimality and operational performance. Current response systems with theoretical optimality guarantees have only been validated analytically or in simulation, leaving their practical utility unproven.   This thesis tackles the aforementioned challenges by developing a practical methodology for optimal security response in IT infrastructures. It encompasses two systems. First, it includes an emulation system that replicates key components of the target infrastructure. We use this system to gather measurements and logs, based on which we identify a game-theoretic model. Second, it includes a simulation system where game-theoretic response strategies are optimized through stochastic approximation to meet a given objective, such as mitigating potential attacks while maintaining operational services. These strategies are then evaluated and refined in the emulation system to close the gap between theoretical and operational performance. We prove structural properties of optimal response strategies and derive efficient algorithms for computing them. This enables us to solve a previously unsolved problem: demonstrating optimal security response against network intrusions on an IT infrastructure.","sentences":["Cybersecurity is one of the most pressing technological challenges of our time and requires measures from all sectors of society.","A key measure is automated security response, which enables automated mitigation and recovery from cyber attacks.","Significant strides toward such automation have been made due to the development of rule-based response systems.","However, these systems have a critical drawback: they depend on domain experts to configure the rules, a process that is both error-prone and inefficient.","Framing security response as an optimal control problem shows promise in addressing this limitation but introduces new challenges.","Chief among them is bridging the gap between theoretical optimality and operational performance.","Current response systems with theoretical optimality guarantees have only been validated analytically or in simulation, leaving their practical utility unproven.   ","This thesis tackles the aforementioned challenges by developing a practical methodology for optimal security response in IT infrastructures.","It encompasses two systems.","First, it includes an emulation system that replicates key components of the target infrastructure.","We use this system to gather measurements and logs, based on which we identify a game-theoretic model.","Second, it includes a simulation system where game-theoretic response strategies are optimized through stochastic approximation to meet a given objective, such as mitigating potential attacks while maintaining operational services.","These strategies are then evaluated and refined in the emulation system to close the gap between theoretical and operational performance.","We prove structural properties of optimal response strategies and derive efficient algorithms for computing them.","This enables us to solve a previously unsolved problem: demonstrating optimal security response against network intrusions on an IT infrastructure."],"url":"http://arxiv.org/abs/2502.02541v1"}
{"created":"2025-02-04 18:06:04","title":"LLMs for Generation of Architectural Components: An Exploratory Empirical Study in the Serverless World","abstract":"Recently, the exponential growth in capability and pervasiveness of Large Language Models (LLMs) has led to significant work done in the field of code generation. However, this generation has been limited to code snippets. Going one step further, our desideratum is to automatically generate architectural components. This would not only speed up development time, but would also enable us to eventually completely skip the development phase, moving directly from design decisions to deployment. To this end, we conduct an exploratory study on the capability of LLMs to generate architectural components for Functions as a Service (FaaS), commonly known as serverless functions. The small size of their architectural components make this architectural style amenable for generation using current LLMs compared to other styles like monoliths and microservices. We perform the study by systematically selecting open source serverless repositories, masking a serverless function and utilizing state of the art LLMs provided with varying levels of context information about the overall system to generate the masked function. We evaluate correctness through existing tests present in the repositories and use metrics from the Software Engineering (SE) and Natural Language Processing (NLP) domains to evaluate code quality and the degree of similarity between human and LLM generated code respectively. Along with our findings, we also present a discussion on the path forward for using GenAI in architectural component generation.","sentences":["Recently, the exponential growth in capability and pervasiveness of Large Language Models (LLMs) has led to significant work done in the field of code generation.","However, this generation has been limited to code snippets.","Going one step further, our desideratum is to automatically generate architectural components.","This would not only speed up development time, but would also enable us to eventually completely skip the development phase, moving directly from design decisions to deployment.","To this end, we conduct an exploratory study on the capability of LLMs to generate architectural components for Functions as a Service (FaaS), commonly known as serverless functions.","The small size of their architectural components make this architectural style amenable for generation using current LLMs compared to other styles like monoliths and microservices.","We perform the study by systematically selecting open source serverless repositories, masking a serverless function and utilizing state of the art LLMs provided with varying levels of context information about the overall system to generate the masked function.","We evaluate correctness through existing tests present in the repositories and use metrics from the Software Engineering (SE) and Natural Language Processing (NLP) domains to evaluate code quality and the degree of similarity between human and LLM generated code respectively.","Along with our findings, we also present a discussion on the path forward for using GenAI in architectural component generation."],"url":"http://arxiv.org/abs/2502.02539v1"}
{"created":"2025-02-04 18:04:05","title":"Flow Q-Learning","abstract":"We present flow Q-learning (FQL), a simple and performant offline reinforcement learning (RL) method that leverages an expressive flow-matching policy to model arbitrarily complex action distributions in data. Training a flow policy with RL is a tricky problem, due to the iterative nature of the action generation process. We address this challenge by training an expressive one-step policy with RL, rather than directly guiding an iterative flow policy to maximize values. This way, we can completely avoid unstable recursive backpropagation, eliminate costly iterative action generation at test time, yet still mostly maintain expressivity. We experimentally show that FQL leads to strong performance across 73 challenging state- and pixel-based OGBench and D4RL tasks in offline RL and offline-to-online RL. Project page: https://seohong.me/projects/fql/","sentences":["We present flow Q-learning (FQL), a simple and performant offline reinforcement learning (RL) method that leverages an expressive flow-matching policy to model arbitrarily complex action distributions in data.","Training a flow policy with RL is a tricky problem, due to the iterative nature of the action generation process.","We address this challenge by training an expressive one-step policy with RL, rather than directly guiding an iterative flow policy to maximize values.","This way, we can completely avoid unstable recursive backpropagation, eliminate costly iterative action generation at test time, yet still mostly maintain expressivity.","We experimentally show that FQL leads to strong performance across 73 challenging state- and pixel-based OGBench and D4RL tasks in offline RL and offline-to-online RL.","Project page: https://seohong.me/projects/fql/"],"url":"http://arxiv.org/abs/2502.02538v1"}
{"created":"2025-02-04 18:03:32","title":"Uncertainty Quantification for Collaborative Object Detection Under Adversarial Attacks","abstract":"Collaborative Object Detection (COD) and collaborative perception can integrate data or features from various entities, and improve object detection accuracy compared with individual perception. However, adversarial attacks pose a potential threat to the deep learning COD models, and introduce high output uncertainty. With unknown attack models, it becomes even more challenging to improve COD resiliency and quantify the output uncertainty for highly dynamic perception scenes such as autonomous vehicles. In this study, we propose the Trusted Uncertainty Quantification in Collaborative Perception framework (TUQCP). TUQCP leverages both adversarial training and uncertainty quantification techniques to enhance the adversarial robustness of existing COD models. More specifically, TUQCP first adds perturbations to the shared information of randomly selected agents during object detection collaboration by adversarial training. TUQCP then alleviates the impacts of adversarial attacks by providing output uncertainty estimation through learning-based module and uncertainty calibration through conformal prediction. Our framework works for early and intermediate collaboration COD models and single-agent object detection models. We evaluate TUQCP on V2X-Sim, a comprehensive collaborative perception dataset for autonomous driving, and demonstrate a 80.41% improvement in object detection accuracy compared to the baselines under the same adversarial attacks. TUQCP demonstrates the importance of uncertainty quantification to COD under adversarial attacks.","sentences":["Collaborative Object Detection (COD) and collaborative perception can integrate data or features from various entities, and improve object detection accuracy compared with individual perception.","However, adversarial attacks pose a potential threat to the deep learning COD models, and introduce high output uncertainty.","With unknown attack models, it becomes even more challenging to improve COD resiliency and quantify the output uncertainty for highly dynamic perception scenes such as autonomous vehicles.","In this study, we propose the Trusted Uncertainty Quantification in Collaborative Perception framework (TUQCP).","TUQCP leverages both adversarial training and uncertainty quantification techniques to enhance the adversarial robustness of existing COD models.","More specifically, TUQCP first adds perturbations to the shared information of randomly selected agents during object detection collaboration by adversarial training.","TUQCP then alleviates the impacts of adversarial attacks by providing output uncertainty estimation through learning-based module and uncertainty calibration through conformal prediction.","Our framework works for early and intermediate collaboration COD models and single-agent object detection models.","We evaluate TUQCP on V2X-Sim, a comprehensive collaborative perception dataset for autonomous driving, and demonstrate a 80.41% improvement in object detection accuracy compared to the baselines under the same adversarial attacks.","TUQCP demonstrates the importance of uncertainty quantification to COD under adversarial attacks."],"url":"http://arxiv.org/abs/2502.02537v1"}
{"created":"2025-02-04 17:57:17","title":"Adaptive Self-improvement LLM Agentic System for ML Library Development","abstract":"ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for experienced human programmers and 2) there are limited code examples because of the esoteric and evolving nature of ASPLs. Therefore, LLMs need complex reasoning with limited data in order to complete this task. To address these challenges, we introduce an adaptive self-improvement agentic system. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\\times$ over a baseline single LLM.","sentences":["ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems.","However, writing these high-performance ML libraries is challenging because it requires expert knowledge of ML algorithms and the ASPL.","Large language models (LLMs), on the other hand, have shown general coding capabilities.","However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for experienced human programmers and 2) there are limited code examples because of the esoteric and evolving nature of ASPLs.","Therefore, LLMs need complex reasoning with limited data in order to complete this task.","To address these challenges, we introduce an adaptive self-improvement agentic system.","In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark.","Our results show improvements of up to $3.9\\times$ over a baseline single LLM."],"url":"http://arxiv.org/abs/2502.02534v1"}
{"created":"2025-02-04 17:56:44","title":"Multi-Agent Design: Optimizing Agents with Better Prompts and Topologies","abstract":"Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks. The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents. Designing prompts and topologies for multi-agent systems (MAS) is inherently complex. To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS. We reveal that prompts together with topologies play critical roles in enabling more effective MAS design. Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages. We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin. Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems.","sentences":["Large language models, employed as multiple agents that interact and collaborate with each other, have excelled at solving complex tasks.","The agents are programmed with prompts that declare their functionality, along with the topologies that orchestrate interactions across agents.","Designing prompts and topologies for multi-agent systems (MAS) is inherently complex.","To automate the entire design process, we first conduct an in-depth analysis of the design space aiming to understand the factors behind building effective MAS.","We reveal that prompts together with topologies play critical roles in enabling more effective MAS design.","Based on the insights, we propose Multi-Agent System Search (MASS), a MAS optimization framework that efficiently exploits the complex MAS design space by interleaving its optimization stages, from local to global, from prompts to topologies, over three stages: 1) block-level (local) prompt optimization; 2) workflow topology optimization; 3) workflow-level (global) prompt optimization, where each stage is conditioned on the iteratively optimized prompts/topologies from former stages.","We show that MASS-optimized multi-agent systems outperform a spectrum of existing alternatives by a substantial margin.","Based on the MASS-found systems, we finally propose design principles behind building effective multi-agent systems."],"url":"http://arxiv.org/abs/2502.02533v1"}
{"created":"2025-02-04 17:50:55","title":"Max-Min Diversification with Asymmetric Distances","abstract":"One of the most well-known and simplest models for diversity maximization is the Max-Min Diversification (MMD) model, which has been extensively studied in the data mining and database literature. In this paper, we initiate the study of the Asymmetric Max-Min Diversification (AMMD) problem. The input is a positive integer $k$ and a complete digraph over $n$ vertices, together with a nonnegative distance function over the edges obeying the directed triangle inequality. The objective is to select a set of $k$ vertices, which maximizes the smallest pairwise distance between them. AMMD reduces to the well-studied MMD problem in case the distances are symmetric, and has natural applications to query result diversification, web search, and facility location problems. Although the MMD problem admits a simple $\\frac{1}{2}$-approximation by greedily selecting the next-furthest point, this strategy fails for AMMD and it remained unclear how to design good approximation algorithms for AMMD. We propose a combinatorial $\\frac{1}{6k}$-approximation algorithm for AMMD by leveraging connections with the Maximum Antichain problem. We discuss several ways of speeding up the algorithm and compare its performance against heuristic baselines on real-life and synthetic datasets.","sentences":["One of the most well-known and simplest models for diversity maximization is the Max-Min Diversification (MMD) model, which has been extensively studied in the data mining and database literature.","In this paper, we initiate the study of the Asymmetric Max-Min Diversification (AMMD) problem.","The input is a positive integer $k$ and a complete digraph over $n$ vertices, together with a nonnegative distance function over the edges obeying the directed triangle inequality.","The objective is to select a set of $k$ vertices, which maximizes the smallest pairwise distance between them.","AMMD reduces to the well-studied MMD problem in case the distances are symmetric, and has natural applications to query result diversification, web search, and facility location problems.","Although the MMD problem admits a simple $\\frac{1}{2}$-approximation by greedily selecting the next-furthest point, this strategy fails for AMMD and it remained unclear how to design good approximation algorithms for AMMD.","We propose a combinatorial $\\frac{1}{6k}$-approximation algorithm for AMMD by leveraging connections with the Maximum Antichain problem.","We discuss several ways of speeding up the algorithm and compare its performance against heuristic baselines on real-life and synthetic datasets."],"url":"http://arxiv.org/abs/2502.02530v1"}
{"created":"2025-02-04 17:50:55","title":"Deep Linear Network Training Dynamics from Random Initialization: Data, Width, Depth, and Hyperparameter Transfer","abstract":"We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data. Our theory captures the ``wider is better\" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width. We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\\sqrt{\\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration. Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works.","sentences":["We theoretically characterize gradient descent dynamics in deep linear networks trained at large width from random initialization and on large quantities of random data.","Our theory captures the ``wider is better\" effect of mean-field/maximum-update parameterized networks as well as hyperparameter transfer effects, which can be contrasted with the neural-tangent parameterization where optimal learning rates shift with model width.","We provide asymptotic descriptions of both non-residual and residual neural networks, the latter of which enables an infinite depth limit when branches are scaled as $1/\\sqrt{\\text{depth}}$. We also compare training with one-pass stochastic gradient descent to the dynamics when training data are repeated at each iteration.","Lastly, we show that this model recovers the accelerated power law training dynamics for power law structured data in the rich regime observed in recent works."],"url":"http://arxiv.org/abs/2502.02531v1"}
{"created":"2025-02-04 17:50:08","title":"Why human-AI relationships need socioaffective alignment","abstract":"Humans strive to design safe AI systems that align with our goals and remain under our control. However, as AI capabilities advance, we face a new challenge: the emergence of deeper, more persistent relationships between humans and AI systems. We explore how increasingly capable AI agents may generate the perception of deeper relationships with users, especially as AI becomes more personalised and agentic. This shift, from transactional interaction to ongoing sustained social engagement with AI, necessitates a new focus on socioaffective alignment-how an AI system behaves within the social and psychological ecosystem co-created with its user, where preferences and perceptions evolve through mutual influence. Addressing these dynamics involves resolving key intrapersonal dilemmas, including balancing immediate versus long-term well-being, protecting autonomy, and managing AI companionship alongside the desire to preserve human social bonds. By framing these challenges through a notion of basic psychological needs, we seek AI systems that support, rather than exploit, our fundamental nature as social and emotional beings.","sentences":["Humans strive to design safe AI systems that align with our goals and remain under our control.","However, as AI capabilities advance, we face a new challenge: the emergence of deeper, more persistent relationships between humans and AI systems.","We explore how increasingly capable AI agents may generate the perception of deeper relationships with users, especially as AI becomes more personalised and agentic.","This shift, from transactional interaction to ongoing sustained social engagement with AI, necessitates a new focus on socioaffective alignment-how an AI system behaves within the social and psychological ecosystem co-created with its user, where preferences and perceptions evolve through mutual influence.","Addressing these dynamics involves resolving key intrapersonal dilemmas, including balancing immediate versus long-term well-being, protecting autonomy, and managing AI companionship alongside the desire to preserve human social bonds.","By framing these challenges through a notion of basic psychological needs, we seek AI systems that support, rather than exploit, our fundamental nature as social and emotional beings."],"url":"http://arxiv.org/abs/2502.02528v1"}
{"created":"2025-02-04 17:49:44","title":"TabPFN Unleashed: A Scalable and Effective Solution to Tabular Classification Problems","abstract":"TabPFN has emerged as a promising in-context learning model for tabular data, capable of directly predicting the labels of test samples given labeled training examples. It has demonstrated competitive performance, particularly on small-scale classification tasks. However, despite its effectiveness, TabPFN still requires further refinement in several areas, including handling high-dimensional features, aligning with downstream datasets, and scaling to larger datasets. In this paper, we revisit existing variants of TabPFN and observe that most approaches focus either on reducing bias or variance, often neglecting the need to address the other side, while also increasing inference overhead. To fill this gap, we propose Beta (Bagging and Encoder-based Fine-tuning for TabPFN Adaptation), a novel and effective method designed to minimize both bias and variance. To reduce bias, we introduce a lightweight encoder to better align downstream tasks with the pre-trained TabPFN. By increasing the number of encoders in a lightweight manner, Beta mitigate variance, thereby further improving the model's performance. Additionally, bootstrapped sampling is employed to further reduce the impact of data perturbations on the model, all while maintaining computational efficiency during inference. Our approach enhances TabPFN's ability to handle high-dimensional data and scale to larger datasets. Experimental results on over 200 benchmark classification datasets demonstrate that Beta either outperforms or matches state-of-the-art methods.","sentences":["TabPFN has emerged as a promising in-context learning model for tabular data, capable of directly predicting the labels of test samples given labeled training examples.","It has demonstrated competitive performance, particularly on small-scale classification tasks.","However, despite its effectiveness, TabPFN still requires further refinement in several areas, including handling high-dimensional features, aligning with downstream datasets, and scaling to larger datasets.","In this paper, we revisit existing variants of TabPFN and observe that most approaches focus either on reducing bias or variance, often neglecting the need to address the other side, while also increasing inference overhead.","To fill this gap, we propose Beta (Bagging and Encoder-based Fine-tuning for TabPFN Adaptation), a novel and effective method designed to minimize both bias and variance.","To reduce bias, we introduce a lightweight encoder to better align downstream tasks with the pre-trained TabPFN.","By increasing the number of encoders in a lightweight manner, Beta mitigate variance, thereby further improving the model's performance.","Additionally, bootstrapped sampling is employed to further reduce the impact of data perturbations on the model, all while maintaining computational efficiency during inference.","Our approach enhances TabPFN's ability to handle high-dimensional data and scale to larger datasets.","Experimental results on over 200 benchmark classification datasets demonstrate that Beta either outperforms or matches state-of-the-art methods."],"url":"http://arxiv.org/abs/2502.02527v1"}
{"created":"2025-02-04 17:46:34","title":"Diff9D: Diffusion-Based Domain-Generalized Category-Level 9-DoF Object Pose Estimation","abstract":"Nine-degrees-of-freedom (9-DoF) object pose and size estimation is crucial for enabling augmented reality and robotic manipulation. Category-level methods have received extensive research attention due to their potential for generalization to intra-class unknown objects. However, these methods require manual collection and labeling of large-scale real-world training data. To address this problem, we introduce a diffusion-based paradigm for domain-generalized category-level 9-DoF object pose estimation. Our motivation is to leverage the latent generalization ability of the diffusion model to address the domain generalization challenge in object pose estimation. This entails training the model exclusively on rendered synthetic data to achieve generalization to real-world scenes. We propose an effective diffusion model to redefine 9-DoF object pose estimation from a generative perspective. Our model does not require any 3D shape priors during training or inference. By employing the Denoising Diffusion Implicit Model, we demonstrate that the reverse diffusion process can be executed in as few as 3 steps, achieving near real-time performance. Finally, we design a robotic grasping system comprising both hardware and software components. Through comprehensive experiments on two benchmark datasets and the real-world robotic system, we show that our method achieves state-of-the-art domain generalization performance. Our code will be made public at https://github.com/CNJianLiu/Diff9D.","sentences":["Nine-degrees-of-freedom (9-DoF) object pose and size estimation is crucial for enabling augmented reality and robotic manipulation.","Category-level methods have received extensive research attention due to their potential for generalization to intra-class unknown objects.","However, these methods require manual collection and labeling of large-scale real-world training data.","To address this problem, we introduce a diffusion-based paradigm for domain-generalized category-level 9-DoF object pose estimation.","Our motivation is to leverage the latent generalization ability of the diffusion model to address the domain generalization challenge in object pose estimation.","This entails training the model exclusively on rendered synthetic data to achieve generalization to real-world scenes.","We propose an effective diffusion model to redefine 9-DoF object pose estimation from a generative perspective.","Our model does not require any 3D shape priors during training or inference.","By employing the Denoising Diffusion Implicit Model, we demonstrate that the reverse diffusion process can be executed in as few as 3 steps, achieving near real-time performance.","Finally, we design a robotic grasping system comprising both hardware and software components.","Through comprehensive experiments on two benchmark datasets and the real-world robotic system, we show that our method achieves state-of-the-art domain generalization performance.","Our code will be made public at https://github.com/CNJianLiu/Diff9D."],"url":"http://arxiv.org/abs/2502.02525v1"}
{"created":"2025-02-04 17:45:32","title":"Brief analysis of DeepSeek R1 and it's implications for Generative AI","abstract":"In late January 2025, DeepSeek released their new reasoning model (DeepSeek R1); which was developed at a fraction of the cost yet remains competitive with OpenAI's models, despite the US's GPU export ban. This report discusses the model, and what its release means for the field of Generative AI more widely. We briefly discuss other models released from China in recent weeks, their similarities; innovative use of Mixture of Experts (MoE), Reinforcement Learning (RL) and clever engineering appear to be key factors in the capabilities of these models. This think piece has been written to a tight time-scale, providing broad coverage of the topic, and serves as introductory material for those looking to understand the model's technical advancements, as well as it's place in the ecosystem. Several further areas of research are identified.","sentences":["In late January 2025, DeepSeek released their new reasoning model (DeepSeek R1); which was developed at a fraction of the cost yet remains competitive with OpenAI's models, despite the US's GPU export ban.","This report discusses the model, and what its release means for the field of Generative AI more widely.","We briefly discuss other models released from China in recent weeks, their similarities; innovative use of Mixture of Experts (MoE), Reinforcement Learning (RL) and clever engineering appear to be key factors in the capabilities of these models.","This think piece has been written to a tight time-scale, providing broad coverage of the topic, and serves as introductory material for those looking to understand the model's technical advancements, as well as it's place in the ecosystem.","Several further areas of research are identified."],"url":"http://arxiv.org/abs/2502.02523v1"}
{"created":"2025-02-04 17:42:29","title":"Privacy by Design for Self-Sovereign Identity Systems: An in-depth Component Analysis completed by a Design Assistance Dashboard","abstract":"The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest. Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens. The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet. These developments, which fall within the sovereign domain, raise questions about individual privacy.   The purpose of this article is to help SSI solution designers make informed choices to ensure that the designed solution is privacy-friendly. The observation is that the range of possible solutions is very broad, from DID and DID resolution methods to verifiable credential types, publicly available information (e.g. in a blockchain), type of infrastructure, etc. As a result, the article proposes (1) to group the elementary building blocks of a SSI system into 5 structuring layers, (2) to analyze for each layer the privacy implications of using the chosen building block, and (3) to provide a design assistance dashboard that gives the complete picture of the SSI, and shows the interdependencies between architectural choices and technical building blocks, allowing designers to make informed choices and graphically achieve a SSI solution that meets their need for privacy.","sentences":["The use of Self-Sovereign Identity (SSI) systems for digital identity management is gaining traction and interest.","Countries such as Bhutan have already implemented an SSI infrastructure to manage the identity of their citizens.","The EU, thanks to the revised eIDAS regulation, is opening the door for SSI vendors to develop SSI systems for the planned EU digital identity wallet.","These developments, which fall within the sovereign domain, raise questions about individual privacy.   ","The purpose of this article is to help SSI solution designers make informed choices to ensure that the designed solution is privacy-friendly.","The observation is that the range of possible solutions is very broad, from DID and DID resolution methods to verifiable credential types, publicly available information (e.g. in a blockchain), type of infrastructure, etc.","As a result, the article proposes (1) to group the elementary building blocks of a SSI system into 5 structuring layers, (2) to analyze for each layer the privacy implications of using the chosen building block, and (3) to provide a design assistance dashboard that gives the complete picture of the SSI, and shows the interdependencies between architectural choices and technical building blocks, allowing designers to make informed choices and graphically achieve a SSI solution that meets their need for privacy."],"url":"http://arxiv.org/abs/2502.02520v1"}
{"created":"2025-02-04 17:35:51","title":"Adaptive Exploration for Multi-Reward Multi-Policy Evaluation","abstract":"We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions must be evaluated simultaneously for different policies. We adopt an $(\\epsilon,\\delta)$-PAC perspective to achieve $\\epsilon$-accurate estimates with high confidence across finite or convex sets of rewards, a setting that has not been investigated in the literature. Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme to jointly minimize sample complexity for evaluating different policies across different reward sets. Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy. Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets. Experiments in tabular domains demonstrate the effectiveness of this adaptive exploration scheme.","sentences":["We study the policy evaluation problem in an online multi-reward multi-policy discounted setting, where multiple reward functions must be evaluated simultaneously for different policies.","We adopt an $(\\epsilon,\\delta)$-PAC perspective to achieve $\\epsilon$-accurate estimates with high confidence across finite or convex sets of rewards, a setting that has not been investigated in the literature.","Building on prior work on Multi-Reward Best Policy Identification, we adapt the MR-NaS exploration scheme to jointly minimize sample complexity for evaluating different policies across different reward sets.","Our approach leverages an instance-specific lower bound revealing how the sample complexity scales with a measure of value deviation, guiding the design of an efficient exploration policy.","Although computing this bound entails a hard non-convex optimization, we propose an efficient convex approximation that holds for both finite and convex reward sets.","Experiments in tabular domains demonstrate the effectiveness of this adaptive exploration scheme."],"url":"http://arxiv.org/abs/2502.02516v1"}
{"created":"2025-02-04 17:33:08","title":"Privacy Attacks on Image AutoRegressive Models","abstract":"Image autoregressive (IAR) models have surpassed diffusion models (DMs) in both image quality (FID: 1.48 vs. 1.58) and generation speed. However, their privacy risks remain largely unexplored. To address this, we conduct a comprehensive privacy analysis comparing IARs to DMs. We develop a novel membership inference attack (MIA) that achieves a significantly higher success rate in detecting training images (TPR@FPR=1%: 86.38% for IARs vs. 4.91% for DMs). Using this MIA, we perform dataset inference (DI) and find that IARs require as few as six samples to detect dataset membership, compared to 200 for DMs, indicating higher information leakage. Additionally, we extract hundreds of training images from an IAR (e.g., 698 from VAR-d30). Our findings highlight a fundamental privacy-utility trade-off: while IARs excel in generation quality and speed, they are significantly more vulnerable to privacy attacks. This suggests that incorporating techniques from DMs, such as per-token probability modeling using diffusion, could help mitigate IARs' privacy risks. Our code is available at https://github.com/sprintml/privacy_attacks_against_iars.","sentences":["Image autoregressive (IAR) models have surpassed diffusion models (DMs) in both image quality (FID: 1.48 vs. 1.58) and generation speed.","However, their privacy risks remain largely unexplored.","To address this, we conduct a comprehensive privacy analysis comparing IARs to DMs.","We develop a novel membership inference attack (MIA) that achieves a significantly higher success rate in detecting training images (TPR@FPR=1%: 86.38% for IARs vs. 4.91% for DMs).","Using this MIA, we perform dataset inference (DI) and find that IARs require as few as six samples to detect dataset membership, compared to 200 for DMs, indicating higher information leakage.","Additionally, we extract hundreds of training images from an IAR (e.g., 698 from VAR-d30).","Our findings highlight a fundamental privacy-utility trade-off: while IARs excel in generation quality and speed, they are significantly more vulnerable to privacy attacks.","This suggests that incorporating techniques from DMs, such as per-token probability modeling using diffusion, could help mitigate IARs' privacy risks.","Our code is available at https://github.com/sprintml/privacy_attacks_against_iars."],"url":"http://arxiv.org/abs/2502.02514v1"}
{"created":"2025-02-04 17:32:17","title":"Generative Modeling on Lie Groups via Euclidean Generalized Score Matching","abstract":"We extend Euclidean score-based diffusion processes to generative modeling on Lie groups. Through the formalism of Generalized Score Matching, our approach yields a Langevin dynamics which decomposes as a direct sum of Lie algebra representations, enabling generative processes on Lie groups while operating in Euclidean space. Unlike equivariant models, which restrict the space of learnable functions by quotienting out group orbits, our method can model any target distribution on any (non-Abelian) Lie group. Standard score matching emerges as a special case of our framework when the Lie group is the translation group. We prove that our generalized generative processes arise as solutions to a new class of paired stochastic differential equations (SDEs), introduced here for the first time. We validate our approach through experiments on diverse data types, demonstrating its effectiveness in real-world applications such as SO(3)-guided molecular conformer generation and modeling ligand-specific global SE(3) transformations for molecular docking, showing improvement in comparison to Riemannian diffusion on the group itself. We show that an appropriate choice of Lie group enhances learning efficiency by reducing the effective dimensionality of the trajectory space and enables the modeling of transitions between complex data distributions. Additionally, we demonstrate the universality of our approach by deriving how it extends to flow matching.","sentences":["We extend Euclidean score-based diffusion processes to generative modeling on Lie groups.","Through the formalism of Generalized Score Matching, our approach yields a Langevin dynamics which decomposes as a direct sum of Lie algebra representations, enabling generative processes on Lie groups while operating in Euclidean space.","Unlike equivariant models, which restrict the space of learnable functions by quotienting out group orbits, our method can model any target distribution on any (non-Abelian) Lie group.","Standard score matching emerges as a special case of our framework when the Lie group is the translation group.","We prove that our generalized generative processes arise as solutions to a new class of paired stochastic differential equations (SDEs), introduced here for the first time.","We validate our approach through experiments on diverse data types, demonstrating its effectiveness in real-world applications such as SO(3)-guided molecular conformer generation and modeling ligand-specific global SE(3) transformations for molecular docking, showing improvement in comparison to Riemannian diffusion on the group itself.","We show that an appropriate choice of Lie group enhances learning efficiency by reducing the effective dimensionality of the trajectory space and enables the modeling of transitions between complex data distributions.","Additionally, we demonstrate the universality of our approach by deriving how it extends to flow matching."],"url":"http://arxiv.org/abs/2502.02513v1"}
{"created":"2025-02-04 17:26:58","title":"Satori: Reinforcement Learning with Chain-of-Action-Thought Enhances LLM Reasoning via Autoregressive Search","abstract":"Large language models (LLMs) have demonstrated remarkable reasoning capabilities across diverse domains. Recent studies have shown that increasing test-time computation enhances LLMs' reasoning capabilities. This typically involves extensive sampling at inference time guided by an external LLM verifier, resulting in a two-player system. Despite external guidance, the effectiveness of this system demonstrates the potential of a single LLM to tackle complex tasks. Thus, we pose a new research problem: Can we internalize the searching capabilities to fundamentally enhance the reasoning abilities of a single LLM? This work explores an orthogonal direction focusing on post-training LLMs for autoregressive searching (i.e., an extended reasoning process with self-reflection and self-exploration of new strategies). To achieve this, we propose the Chain-of-Action-Thought (COAT) reasoning and a two-stage training paradigm: 1) a small-scale format tuning stage to internalize the COAT reasoning format and 2) a large-scale self-improvement stage leveraging reinforcement learning. Our approach results in Satori, a 7B LLM trained on open-source models and data. Extensive empirical evaluations demonstrate that Satori achieves state-of-the-art performance on mathematical reasoning benchmarks while exhibits strong generalization to out-of-domain tasks. Code, data, and models will be fully open-sourced.","sentences":["Large language models (LLMs) have demonstrated remarkable reasoning capabilities across diverse domains.","Recent studies have shown that increasing test-time computation enhances LLMs' reasoning capabilities.","This typically involves extensive sampling at inference time guided by an external LLM verifier, resulting in a two-player system.","Despite external guidance, the effectiveness of this system demonstrates the potential of a single LLM to tackle complex tasks.","Thus, we pose a new research problem: Can we internalize the searching capabilities to fundamentally enhance the reasoning abilities of a single LLM?","This work explores an orthogonal direction focusing on post-training LLMs for autoregressive searching (i.e., an extended reasoning process with self-reflection and self-exploration of new strategies).","To achieve this, we propose the Chain-of-Action-Thought (COAT) reasoning and a two-stage training paradigm: 1) a small-scale format tuning stage to internalize the COAT reasoning format and 2) a large-scale self-improvement stage leveraging reinforcement learning.","Our approach results in Satori, a 7B LLM trained on open-source models and data.","Extensive empirical evaluations demonstrate that Satori achieves state-of-the-art performance on mathematical reasoning benchmarks while exhibits strong generalization to out-of-domain tasks.","Code, data, and models will be fully open-sourced."],"url":"http://arxiv.org/abs/2502.02508v1"}
{"created":"2025-02-04 17:18:54","title":"Unified Spatial-Temporal Edge-Enhanced Graph Networks for Pedestrian Trajectory Prediction","abstract":"Pedestrian trajectory prediction aims to forecast future movements based on historical paths. Spatial-temporal (ST) methods often separately model spatial interactions among pedestrians and temporal dependencies of individuals. They overlook the direct impacts of interactions among different pedestrians across various time steps (i.e., high-order cross-time interactions). This limits their ability to capture ST inter-dependencies and hinders prediction performance. To address these limitations, we propose UniEdge with three major designs. Firstly, we introduce a unified ST graph data structure that simplifies high-order cross-time interactions into first-order relationships, enabling the learning of ST inter-dependencies in a single step. This avoids the information loss caused by multi-step aggregation. Secondly, traditional GNNs focus on aggregating pedestrian node features, neglecting the propagation of implicit interaction patterns encoded in edge features. We propose the Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph network that jointly models explicit N2N social interactions among pedestrians and implicit E2E influence propagation across these interaction patterns. Finally, to overcome the limited receptive fields and challenges in capturing long-range dependencies of auto-regressive architectures, we introduce a transformer encoder-based predictor that enables global modeling of temporal correlation. UniEdge outperforms state-of-the-arts on multiple datasets, including ETH, UCY, and SDD.","sentences":["Pedestrian trajectory prediction aims to forecast future movements based on historical paths.","Spatial-temporal (ST) methods often separately model spatial interactions among pedestrians and temporal dependencies of individuals.","They overlook the direct impacts of interactions among different pedestrians across various time steps (i.e., high-order cross-time interactions).","This limits their ability to capture ST inter-dependencies and hinders prediction performance.","To address these limitations, we propose UniEdge with three major designs.","Firstly, we introduce a unified ST graph data structure that simplifies high-order cross-time interactions into first-order relationships, enabling the learning of ST inter-dependencies in a single step.","This avoids the information loss caused by multi-step aggregation.","Secondly, traditional GNNs focus on aggregating pedestrian node features, neglecting the propagation of implicit interaction patterns encoded in edge features.","We propose the Edge-to-Edge-Node-to-Node Graph Convolution (E2E-N2N-GCN), a novel dual-graph network that jointly models explicit N2N social interactions among pedestrians and implicit E2E influence propagation across these interaction patterns.","Finally, to overcome the limited receptive fields and challenges in capturing long-range dependencies of auto-regressive architectures, we introduce a transformer encoder-based predictor that enables global modeling of temporal correlation.","UniEdge outperforms state-of-the-arts on multiple datasets, including ETH, UCY, and SDD."],"url":"http://arxiv.org/abs/2502.02504v1"}
{"created":"2025-02-04 17:17:00","title":"Near-Feasible Solutions to Complex Stable Matching Problems","abstract":"In this paper, we demonstrate that in many NP-complete variants of the stable matching problem -- such as the Stable Hypergraph Matching problem and the College Admission problem with Common Quotas -- a near-feasible stable solution -- that is, a solution which is stable, but may slightly violate some capacities -- always exists. Our results provide strong theoretical guarantees that even under complex constraints, stability can be restored with minimal capacity modifications.   To achieve this, we present an iterative rounding algorithm that starts from a stable fractional solution and systematically adjusts capacities to ensure the existence of an integral stable solution. This approach leverages Scarf's algorithm to compute an initial fractional stable solution, which serves as the foundation for our rounding process. Notably, in the case of the Stable Fixtures problem, where a stable fractional matching can be computed efficiently, our method runs in polynomial time.   These findings have significant practical implications for market design, college admissions, and other real-world allocation problems, where small adjustments to institutional constraints can guarantee stable and implementable outcomes.","sentences":["In this paper, we demonstrate that in many NP-complete variants of the stable matching problem -- such as the Stable Hypergraph Matching problem and the College Admission problem with Common Quotas -- a near-feasible stable solution -- that is, a solution which is stable, but may slightly violate some capacities -- always exists.","Our results provide strong theoretical guarantees that even under complex constraints, stability can be restored with minimal capacity modifications.   ","To achieve this, we present an iterative rounding algorithm that starts from a stable fractional solution and systematically adjusts capacities to ensure the existence of an integral stable solution.","This approach leverages Scarf's algorithm to compute an initial fractional stable solution, which serves as the foundation for our rounding process.","Notably, in the case of the Stable Fixtures problem, where a stable fractional matching can be computed efficiently, our method runs in polynomial time.   ","These findings have significant practical implications for market design, college admissions, and other real-world allocation problems, where small adjustments to institutional constraints can guarantee stable and implementable outcomes."],"url":"http://arxiv.org/abs/2502.02503v1"}
{"created":"2025-02-04 17:16:14","title":"Graph-based Document Structure Analysis","abstract":"When reading a document, glancing at the spatial layout of a document is an initial step to understand it roughly. Traditional document layout analysis (DLA) methods, however, offer only a superficial parsing of documents, focusing on basic instance detection and often failing to capture the nuanced spatial and logical relations between instances. These limitations hinder DLA-based models from achieving a gradually deeper comprehension akin to human reading. In this work, we propose a novel graph-based Document Structure Analysis (gDSA) task. This task requires that model not only detects document elements but also generates spatial and logical relations in form of a graph structure, allowing to understand documents in a holistic and intuitive manner. For this new task, we construct a relation graph-based document structure analysis dataset (GraphDoc) with 80K document images and 4.13M relation annotations, enabling training models to complete multiple tasks like reading order, hierarchical structures analysis, and complex inter-element relation inference. Furthermore, a document relation graph generator (DRGG) is proposed to address the gDSA task, which achieves performance with 57.6% at mAP$_g$@0.5 for a strong benchmark baseline on this novel task and dataset. We hope this graphical representation of document structure can mark an innovative advancement in document structure analysis and understanding. The new dataset and code will be made publicly available at https://yufanchen96.github.io/projects/GraphDoc.","sentences":["When reading a document, glancing at the spatial layout of a document is an initial step to understand it roughly.","Traditional document layout analysis (DLA) methods, however, offer only a superficial parsing of documents, focusing on basic instance detection and often failing to capture the nuanced spatial and logical relations between instances.","These limitations hinder DLA-based models from achieving a gradually deeper comprehension akin to human reading.","In this work, we propose a novel graph-based Document Structure Analysis (gDSA) task.","This task requires that model not only detects document elements but also generates spatial and logical relations in form of a graph structure, allowing to understand documents in a holistic and intuitive manner.","For this new task, we construct a relation graph-based document structure analysis dataset (GraphDoc) with 80K document images and 4.13M relation annotations, enabling training models to complete multiple tasks like reading order, hierarchical structures analysis, and complex inter-element relation inference.","Furthermore, a document relation graph generator (DRGG) is proposed to address the gDSA task, which achieves performance with 57.6% at mAP$_g$@0.5 for a strong benchmark baseline on this novel task and dataset.","We hope this graphical representation of document structure can mark an innovative advancement in document structure analysis and understanding.","The new dataset and code will be made publicly available at https://yufanchen96.github.io/projects/GraphDoc."],"url":"http://arxiv.org/abs/2502.02501v1"}
{"created":"2025-02-04 17:14:41","title":"Learning to generate physical ocean states: Towards hybrid climate modeling","abstract":"Ocean General Circulation Models require extensive computational resources to reach equilibrium states, while deep learning emulators, despite offering fast predictions, lack the physical interpretability and long-term stability necessary for climate scientists to understand climate sensitivity (to greenhouse gas emissions) and mechanisms of abrupt % variability such as tipping points. We propose to take the best from both worlds by leveraging deep generative models to produce physically consistent oceanic states that can serve as initial conditions for climate projections. We assess the viability of this hybrid approach through both physical metrics and numerical experiments, and highlight the benefits of enforcing physical constraints during generation. Although we train here on ocean variables from idealized numerical simulations, we claim that this hybrid approach, combining the computational efficiency of deep learning with the physical accuracy of numerical models, can effectively reduce the computational burden of running climate models to equilibrium, and reduce uncertainties in climate projections by minimizing drifts in baseline simulations.","sentences":["Ocean General Circulation Models require extensive computational resources to reach equilibrium states, while deep learning emulators, despite offering fast predictions, lack the physical interpretability and long-term stability necessary for climate scientists to understand climate sensitivity (to greenhouse gas emissions) and mechanisms of abrupt % variability such as tipping points.","We propose to take the best from both worlds by leveraging deep generative models to produce physically consistent oceanic states that can serve as initial conditions for climate projections.","We assess the viability of this hybrid approach through both physical metrics and numerical experiments, and highlight the benefits of enforcing physical constraints during generation.","Although we train here on ocean variables from idealized numerical simulations, we claim that this hybrid approach, combining the computational efficiency of deep learning with the physical accuracy of numerical models, can effectively reduce the computational burden of running climate models to equilibrium, and reduce uncertainties in climate projections by minimizing drifts in baseline simulations."],"url":"http://arxiv.org/abs/2502.02499v1"}
{"created":"2025-02-04 17:12:56","title":"Deep Weight Factorization: Sparse Learning Through the Lens of Artificial Symmetries","abstract":"Sparse regularization techniques are well-established in machine learning, yet their application in neural networks remains challenging due to the non-differentiability of penalties like the $L_1$ norm, which is incompatible with stochastic gradient descent. A promising alternative is shallow weight factorization, where weights are decomposed into two factors, allowing for smooth optimization of $L_1$-penalized neural networks by adding differentiable $L_2$ regularization to the factors. In this work, we introduce deep weight factorization, extending previous shallow approaches to more than two factors. We theoretically establish equivalence of our deep factorization with non-convex sparse regularization and analyze its impact on training dynamics and optimization. Due to the limitations posed by standard training practices, we propose a tailored initialization scheme and identify important learning rate requirements necessary for training factorized networks. We demonstrate the effectiveness of our deep weight factorization through experiments on various architectures and datasets, consistently outperforming its shallow counterpart and widely used pruning methods.","sentences":["Sparse regularization techniques are well-established in machine learning, yet their application in neural networks remains challenging due to the non-differentiability of penalties like the $L_1$ norm, which is incompatible with stochastic gradient descent.","A promising alternative is shallow weight factorization, where weights are decomposed into two factors, allowing for smooth optimization of $L_1$-penalized neural networks by adding differentiable $L_2$ regularization to the factors.","In this work, we introduce deep weight factorization, extending previous shallow approaches to more than two factors.","We theoretically establish equivalence of our deep factorization with non-convex sparse regularization and analyze its impact on training dynamics and optimization.","Due to the limitations posed by standard training practices, we propose a tailored initialization scheme and identify important learning rate requirements necessary for training factorized networks.","We demonstrate the effectiveness of our deep weight factorization through experiments on various architectures and datasets, consistently outperforming its shallow counterpart and widely used pruning methods."],"url":"http://arxiv.org/abs/2502.02496v1"}
{"created":"2025-02-04 17:12:23","title":"The Causal-Effect Score in Data Management","abstract":"The Causal Effect (CE) is a numerical measure of causal influence of variables on observed results. Despite being widely used in many areas, only preliminary attempts have been made to use CE as an attribution score in data management, to measure the causal strength of tuples for query answering in databases. In this work, we introduce, generalize and investigate the so-called Causal-Effect Score in the context of classical and probabilistic databases.","sentences":["The Causal Effect (CE) is a numerical measure of causal influence of variables on observed results.","Despite being widely used in many areas, only preliminary attempts have been made to use CE as an attribution score in data management, to measure the causal strength of tuples for query answering in databases.","In this work, we introduce, generalize and investigate the so-called Causal-Effect Score in the context of classical and probabilistic databases."],"url":"http://arxiv.org/abs/2502.02495v1"}
{"created":"2025-02-04 17:09:44","title":"Analyzing Similarity Metrics for Data Selection for Language Model Pretraining","abstract":"Similarity between training examples is used to curate pretraining datasets for language models by many methods -- for diversification and to select examples similar to high-quality data. However, similarity is typically measured with off-the-shelf embedding models that are generic or trained for tasks such as retrieval. This paper introduces a framework to analyze the suitability of embedding models specifically for data curation in the language model pretraining setting. We quantify the correlation between similarity in the embedding space to similarity in pretraining loss between different training examples, and how diversifying in the embedding space affects pretraining quality. We analyze a variety of embedding models in our framework, with experiments using the Pile dataset for pretraining a 1.7B parameter decoder-only language model. We find that the embedding models we consider are all useful for pretraining data curation. Moreover, a simple approach of averaging per-token embeddings proves to be surprisingly competitive with more sophisticated embedding models -- likely because the latter are not designed specifically for pretraining data curation. Indeed, we believe our analysis and evaluation framework can serve as a foundation for the design of embedding models that specifically reason about similarity in pretraining datasets.","sentences":["Similarity between training examples is used to curate pretraining datasets for language models by many methods -- for diversification and to select examples similar to high-quality data.","However, similarity is typically measured with off-the-shelf embedding models that are generic or trained for tasks such as retrieval.","This paper introduces a framework to analyze the suitability of embedding models specifically for data curation in the language model pretraining setting.","We quantify the correlation between similarity in the embedding space to similarity in pretraining loss between different training examples, and how diversifying in the embedding space affects pretraining quality.","We analyze a variety of embedding models in our framework, with experiments using the Pile dataset for pretraining a 1.7B parameter decoder-only language model.","We find that the embedding models we consider are all useful for pretraining data curation.","Moreover, a simple approach of averaging per-token embeddings proves to be surprisingly competitive with more sophisticated embedding models -- likely because the latter are not designed specifically for pretraining data curation.","Indeed, we believe our analysis and evaluation framework can serve as a foundation for the design of embedding models that specifically reason about similarity in pretraining datasets."],"url":"http://arxiv.org/abs/2502.02494v1"}
{"created":"2025-02-04 17:09:21","title":"EasySpec: Layer-Parallel Speculative Decoding for Efficient Multi-GPU Utilization","abstract":"Speculative decoding is an effective and lossless method for Large Language Model (LLM) inference acceleration. It employs a smaller model to generate a draft token sequence, which is then verified by the original base model. In multi-GPU systems, inference latency can be further reduced through tensor parallelism (TP), while the optimal TP size of the draft model is typically smaller than that of the base model, leading to GPU idling during the drafting stage. To solve this problem, we propose EasySpec, a layer-parallel speculation strategy that optimizes the efficiency of multi-GPU utilization.EasySpec breaks the sequential execution order of layers in the drafting model, enabling multi-layer parallelization across devices, albeit with some induced approximation errors. After each drafting-and-verification iteration, the draft model's key-value (KV) cache is calibrated in a single forward pass, preventing long-term error accumulation at minimal additional latency. We evaluated EasySpec on several mainstream open-source LLMs, using smaller versions of models from the same series as drafters. The results demonstrate that EasySpec can achieve a peak speedup of 4.17x compared to vanilla decoding, while preserving the original distribution of the base LLMs. Specifically, the drafting stage can be accelerated by up to 1.62x with a maximum accuracy drop of only 7%, requiring no training or fine-tuning on the draft models.","sentences":["Speculative decoding is an effective and lossless method for Large Language Model (LLM) inference acceleration.","It employs a smaller model to generate a draft token sequence, which is then verified by the original base model.","In multi-GPU systems, inference latency can be further reduced through tensor parallelism (TP), while the optimal TP size of the draft model is typically smaller than that of the base model, leading to GPU idling during the drafting stage.","To solve this problem, we propose EasySpec, a layer-parallel speculation strategy that optimizes the efficiency of multi-GPU utilization.","EasySpec breaks the sequential execution order of layers in the drafting model, enabling multi-layer parallelization across devices, albeit with some induced approximation errors.","After each drafting-and-verification iteration, the draft model's key-value (KV) cache is calibrated in a single forward pass, preventing long-term error accumulation at minimal additional latency.","We evaluated EasySpec on several mainstream open-source LLMs, using smaller versions of models from the same series as drafters.","The results demonstrate that EasySpec can achieve a peak speedup of 4.17x compared to vanilla decoding, while preserving the original distribution of the base LLMs.","Specifically, the drafting stage can be accelerated by up to 1.62x with a maximum accuracy drop of only 7%, requiring no training or fine-tuning on the draft models."],"url":"http://arxiv.org/abs/2502.02493v1"}
{"created":"2025-02-04 17:07:10","title":"VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models","abstract":"Despite tremendous recent progress, generative video models still struggle to capture real-world motion, dynamics, and physics. We show that this limitation arises from the conventional pixel reconstruction objective, which biases models toward appearance fidelity at the expense of motion coherence. To address this, we introduce VideoJAM, a novel framework that instills an effective motion prior to video generators, by encouraging the model to learn a joint appearance-motion representation. VideoJAM is composed of two complementary units. During training, we extend the objective to predict both the generated pixels and their corresponding motion from a single learned representation. During inference, we introduce Inner-Guidance, a mechanism that steers the generation toward coherent motion by leveraging the model's own evolving motion prediction as a dynamic guidance signal. Notably, our framework can be applied to any video model with minimal adaptations, requiring no modifications to the training data or scaling of the model. VideoJAM achieves state-of-the-art performance in motion coherence, surpassing highly competitive proprietary models while also enhancing the perceived visual quality of the generations. These findings emphasize that appearance and motion can be complementary and, when effectively integrated, enhance both the visual quality and the coherence of video generation. Project website: https://hila-chefer.github.io/videojam-paper.github.io/","sentences":["Despite tremendous recent progress, generative video models still struggle to capture real-world motion, dynamics, and physics.","We show that this limitation arises from the conventional pixel reconstruction objective, which biases models toward appearance fidelity at the expense of motion coherence.","To address this, we introduce VideoJAM, a novel framework that instills an effective motion prior to video generators, by encouraging the model to learn a joint appearance-motion representation.","VideoJAM is composed of two complementary units.","During training, we extend the objective to predict both the generated pixels and their corresponding motion from a single learned representation.","During inference, we introduce Inner-Guidance, a mechanism that steers the generation toward coherent motion by leveraging the model's own evolving motion prediction as a dynamic guidance signal.","Notably, our framework can be applied to any video model with minimal adaptations, requiring no modifications to the training data or scaling of the model.","VideoJAM achieves state-of-the-art performance in motion coherence, surpassing highly competitive proprietary models while also enhancing the perceived visual quality of the generations.","These findings emphasize that appearance and motion can be complementary and, when effectively integrated, enhance both the visual quality and the coherence of video generation.","Project website: https://hila-chefer.github.io/videojam-paper.github.io/"],"url":"http://arxiv.org/abs/2502.02492v1"}
{"created":"2025-02-04 17:06:41","title":"A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation","abstract":"Ultrasound (US) imaging is clinically invaluable due to its noninvasive and safe nature. However, interpreting US images is challenging, requires significant expertise, and time, and is often prone to errors. Deep learning offers assistive solutions such as segmentation. Supervised methods rely on large, high-quality, and consistently labeled datasets, which are challenging to curate. Moreover, these methods tend to underperform on out-of-distribution data, limiting their clinical utility. Self-supervised learning (SSL) has emerged as a promising alternative, leveraging unlabeled data to enhance model performance and generalisability. We introduce a contrastive SSL approach tailored for B-mode US images, incorporating a novel Relation Contrastive Loss (RCL). RCL encourages learning of distinct features by differentiating positive and negative sample pairs through a learnable metric. Additionally, we propose spatial and frequency-based augmentation strategies for the representation learning on US images. Our approach significantly outperforms traditional supervised segmentation methods across three public breast US datasets, particularly in data-limited scenarios. Notable improvements on the Dice similarity metric include a 4% increase on 20% and 50% of the BUSI dataset, nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4% and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively. Furthermore, we demonstrate superior generalisability on the out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6% compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST training data, respectively. Our research highlights that domain-inspired SSL can improve US segmentation, especially under data-limited conditions.","sentences":["Ultrasound (US) imaging is clinically invaluable due to its noninvasive and safe nature.","However, interpreting US images is challenging, requires significant expertise, and time, and is often prone to errors.","Deep learning offers assistive solutions such as segmentation.","Supervised methods rely on large, high-quality, and consistently labeled datasets, which are challenging to curate.","Moreover, these methods tend to underperform on out-of-distribution data, limiting their clinical utility.","Self-supervised learning (SSL) has emerged as a promising alternative, leveraging unlabeled data to enhance model performance and generalisability.","We introduce a contrastive SSL approach tailored for B-mode US images, incorporating a novel Relation Contrastive Loss (RCL).","RCL encourages learning of distinct features by differentiating positive and negative sample pairs through a learnable metric.","Additionally, we propose spatial and frequency-based augmentation strategies for the representation learning on US images.","Our approach significantly outperforms traditional supervised segmentation methods across three public breast US datasets, particularly in data-limited scenarios.","Notable improvements on the Dice similarity metric include a 4% increase on 20% and 50% of the BUSI dataset, nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4% and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively.","Furthermore, we demonstrate superior generalisability on the out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6% compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST training data, respectively.","Our research highlights that domain-inspired SSL can improve US segmentation, especially under data-limited conditions."],"url":"http://arxiv.org/abs/2502.02489v1"}
{"created":"2025-02-04 17:04:16","title":"Do Graph Diffusion Models Accurately Capture and Generate Substructure Distributions?","abstract":"Diffusion models have gained popularity in graph generation tasks; however, the extent of their expressivity concerning the graph distributions they can learn is not fully understood. Unlike models in other domains, popular backbones for graph diffusion models, such as Graph Transformers, do not possess universal expressivity to accurately model the distribution scores of complex graph data. Our work addresses this limitation by focusing on the frequency of specific substructures as a key characteristic of target graph distributions. When evaluating existing models using this metric, we find that they fail to maintain the distribution of substructure counts observed in the training set when generating new graphs. To address this issue, we establish a theoretical connection between the expressivity of Graph Neural Networks (GNNs) and the overall performance of graph diffusion models, demonstrating that more expressive GNN backbones can better capture complex distribution patterns. By integrating advanced GNNs into the backbone architecture, we achieve significant improvements in substructure generation.","sentences":["Diffusion models have gained popularity in graph generation tasks; however, the extent of their expressivity concerning the graph distributions they can learn is not fully understood.","Unlike models in other domains, popular backbones for graph diffusion models, such as Graph Transformers, do not possess universal expressivity to accurately model the distribution scores of complex graph data.","Our work addresses this limitation by focusing on the frequency of specific substructures as a key characteristic of target graph distributions.","When evaluating existing models using this metric, we find that they fail to maintain the distribution of substructure counts observed in the training set when generating new graphs.","To address this issue, we establish a theoretical connection between the expressivity of Graph Neural Networks (GNNs) and the overall performance of graph diffusion models, demonstrating that more expressive GNN backbones can better capture complex distribution patterns.","By integrating advanced GNNs into the backbone architecture, we achieve significant improvements in substructure generation."],"url":"http://arxiv.org/abs/2502.02488v1"}
{"created":"2025-02-04 17:03:49","title":"Hier-EgoPack: Hierarchical Egocentric Video Understanding with Diverse Task Perspectives","abstract":"Our comprehension of video streams depicting human activities is naturally multifaceted: in just a few moments, we can grasp what is happening, identify the relevance and interactions of objects in the scene, and forecast what will happen soon, everything all at once. To endow autonomous systems with such a holistic perception, learning how to correlate concepts, abstract knowledge across diverse tasks, and leverage tasks synergies when learning novel skills is essential. A significant step in this direction is EgoPack, a unified framework for understanding human activities across diverse tasks with minimal overhead. EgoPack promotes information sharing and collaboration among downstream tasks, essential for efficiently learning new skills. In this paper, we introduce Hier-EgoPack, which advances EgoPack by enabling reasoning also across diverse temporal granularities, which expands its applicability to a broader range of downstream tasks. To achieve this, we propose a novel hierarchical architecture for temporal reasoning equipped with a GNN layer specifically designed to tackle the challenges of multi-granularity reasoning effectively. We evaluate our approach on multiple Ego4d benchmarks involving both clip-level and frame-level reasoning, demonstrating how our hierarchical unified architecture effectively solves these diverse tasks simultaneously.","sentences":["Our comprehension of video streams depicting human activities is naturally multifaceted: in just a few moments, we can grasp what is happening, identify the relevance and interactions of objects in the scene, and forecast what will happen soon, everything all at once.","To endow autonomous systems with such a holistic perception, learning how to correlate concepts, abstract knowledge across diverse tasks, and leverage tasks synergies when learning novel skills is essential.","A significant step in this direction is EgoPack, a unified framework for understanding human activities across diverse tasks with minimal overhead.","EgoPack promotes information sharing and collaboration among downstream tasks, essential for efficiently learning new skills.","In this paper, we introduce Hier-EgoPack, which advances EgoPack by enabling reasoning also across diverse temporal granularities, which expands its applicability to a broader range of downstream tasks.","To achieve this, we propose a novel hierarchical architecture for temporal reasoning equipped with a GNN layer specifically designed to tackle the challenges of multi-granularity reasoning effectively.","We evaluate our approach on multiple Ego4d benchmarks involving both clip-level and frame-level reasoning, demonstrating how our hierarchical unified architecture effectively solves these diverse tasks simultaneously."],"url":"http://arxiv.org/abs/2502.02487v1"}
{"created":"2025-02-04 16:59:03","title":"Distributional Diffusion Models with Scoring Rules","abstract":"Diffusion models generate high-quality synthetic data. They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted. The corresponding reverse process progressively \"denoises\" a Gaussian sample into a sample from the data distribution. However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process. This is expensive and has motivated the development of many acceleration methods. We propose to accomplish sample generation by learning the posterior {\\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution. This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output. This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule. We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps.","sentences":["Diffusion models generate high-quality synthetic data.","They operate by defining a continuous-time forward process which gradually adds Gaussian noise to data until fully corrupted.","The corresponding reverse process progressively \"denoises\" a Gaussian sample into a sample from the data distribution.","However, generating high-quality outputs requires many discretization steps to obtain a faithful approximation of the reverse process.","This is expensive and has motivated the development of many acceleration methods.","We propose to accomplish sample generation by learning the posterior {\\em distribution} of clean data samples given their noisy versions, instead of only the mean of this distribution.","This allows us to sample from the probability transitions of the reverse process on a coarse time scale, significantly accelerating inference with minimal degradation of the quality of the output.","This is accomplished by replacing the standard regression loss used to estimate conditional means with a scoring rule.","We validate our method on image and robot trajectory generation, where we consistently outperform standard diffusion models at few discretization steps."],"url":"http://arxiv.org/abs/2502.02483v1"}
{"created":"2025-02-04 16:57:03","title":"Multilingual Machine Translation with Open Large Language Models at Practical Scale: An Empirical Study","abstract":"Large language models (LLMs) have shown continuously improving multilingual capabilities, and even small-scale open-source models have demonstrated rapid performance enhancement. In this paper, we systematically explore the abilities of open LLMs with less than ten billion parameters to handle multilingual machine translation (MT) tasks. We conduct comprehensive evaluations on six popular LLMs and find that models like Gemma2-9B exhibit impressive multilingual translation capabilities. We then introduce the Parallel-First Monolingual-Second (PFMS) data mixing strategy in the continual pretraining stage to further enhance the MT performance and present GemmaX2-28, a 9B model achieving top-tier multilingual translation performance across 28 languages. Specifically, GemmaX2-28 consistently outperforms the state-of-the-art (SOTA) models such as TowerInstruct and XALMA and achieves competitive performance with Google Translate and GPT-4-turbo.","sentences":["Large language models (LLMs) have shown continuously improving multilingual capabilities, and even small-scale open-source models have demonstrated rapid performance enhancement.","In this paper, we systematically explore the abilities of open LLMs with less than ten billion parameters to handle multilingual machine translation (MT) tasks.","We conduct comprehensive evaluations on six popular LLMs and find that models like Gemma2-9B exhibit impressive multilingual translation capabilities.","We then introduce the Parallel-First Monolingual-Second (PFMS) data mixing strategy in the continual pretraining stage to further enhance the MT performance and present GemmaX2-28, a 9B model achieving top-tier multilingual translation performance across 28 languages.","Specifically, GemmaX2-28 consistently outperforms the state-of-the-art (SOTA) models such as TowerInstruct and XALMA and achieves competitive performance with Google Translate and GPT-4-turbo."],"url":"http://arxiv.org/abs/2502.02481v1"}
{"created":"2025-02-04 16:57:02","title":"Stable Port-Hamiltonian Neural Networks","abstract":"In recent years, nonlinear dynamic system identification using artificial neural networks has garnered attention due to its manifold potential applications in virtually all branches of science and engineering. However, purely data-driven approaches often struggle with extrapolation and may yield physically implausible forecasts. Furthermore, the learned dynamics can exhibit instabilities, making it difficult to apply such models safely and robustly. This article proposes stable port-Hamiltonian neural networks, a machine learning architecture that incorporates the physical biases of energy conservation or dissipation while guaranteeing global Lyapunov stability of the learned dynamics. Evaluations with illustrative examples and real-world measurement data demonstrate the model's ability to generalize from sparse data, outperforming purely data-driven approaches and avoiding instability issues. In addition, the model's potential for data-driven surrogate modeling is highlighted in application to multi-physics simulation data.","sentences":["In recent years, nonlinear dynamic system identification using artificial neural networks has garnered attention due to its manifold potential applications in virtually all branches of science and engineering.","However, purely data-driven approaches often struggle with extrapolation and may yield physically implausible forecasts.","Furthermore, the learned dynamics can exhibit instabilities, making it difficult to apply such models safely and robustly.","This article proposes stable port-Hamiltonian neural networks, a machine learning architecture that incorporates the physical biases of energy conservation or dissipation while guaranteeing global Lyapunov stability of the learned dynamics.","Evaluations with illustrative examples and real-world measurement data demonstrate the model's ability to generalize from sparse data, outperforming purely data-driven approaches and avoiding instability issues.","In addition, the model's potential for data-driven surrogate modeling is highlighted in application to multi-physics simulation data."],"url":"http://arxiv.org/abs/2502.02480v1"}
{"created":"2025-02-04 16:54:28","title":"Using Random Noise Equivariantly to Boost Graph Neural Networks Universally","abstract":"Recent advances in Graph Neural Networks (GNNs) have explored the potential of random noise as an input feature to enhance expressivity across diverse tasks. However, naively incorporating noise can degrade performance, while architectures tailored to exploit noise for specific tasks excel yet lack broad applicability. This paper tackles these issues by laying down a theoretical framework that elucidates the increased sample complexity when introducing random noise into GNNs without careful design. We further propose Equivariant Noise GNN (ENGNN), a novel architecture that harnesses the symmetrical properties of noise to mitigate sample complexity and bolster generalization. Our experiments demonstrate that using noise equivariantly significantly enhances performance on node-level, link-level, subgraph, and graph-level tasks and achieves comparable performance to models designed for specific tasks, thereby offering a general method to boost expressivity across various graph tasks.","sentences":["Recent advances in Graph Neural Networks (GNNs) have explored the potential of random noise as an input feature to enhance expressivity across diverse tasks.","However, naively incorporating noise can degrade performance, while architectures tailored to exploit noise for specific tasks excel yet lack broad applicability.","This paper tackles these issues by laying down a theoretical framework that elucidates the increased sample complexity when introducing random noise into GNNs without careful design.","We further propose Equivariant Noise GNN (ENGNN), a novel architecture that harnesses the symmetrical properties of noise to mitigate sample complexity and bolster generalization.","Our experiments demonstrate that using noise equivariantly significantly enhances performance on node-level, link-level, subgraph, and graph-level tasks and achieves comparable performance to models designed for specific tasks, thereby offering a general method to boost expressivity across various graph tasks."],"url":"http://arxiv.org/abs/2502.02479v1"}
{"created":"2025-02-04 16:53:10","title":"A Clique Partitioning-Based Algorithm for Graph Compression","abstract":"Reducing the running time of graph algorithms is vital for tackling real-world problems such as shortest paths and matching in large-scale graphs, where path information plays a crucial role. This paper addresses this critical challenge of reducing the running time of graph algorithms by proposing a new graph compression algorithm that partitions the graph into bipartite cliques and uses the partition to obtain a compressed graph having a smaller number of edges while preserving the path information. This compressed graph can then be used as input to other graph algorithms for which path information is essential, leading to a significant reduction of their running time, especially for large, dense graphs. The running time of the proposed algorithm is~$O(mn^\\delta)$, where $0 \\leq \\delta \\leq 1$, which is better than $O(mn^\\delta \\log^2 n)$, the running time of the best existing clique partitioning-based graph compression algorithm (the Feder-Motwani (\\textsf{FM}) algorithm). Our extensive experimental analysis show that our algorithm achieves a compression ratio of up to~$26\\%$ greater and executes up to~105.18 times faster than the \\textsf{FM} algorithm. In addition, on large graphs with up to 1.05 billion edges, it achieves a compression ratio of up to~3.9, reducing the number of edges up to~$74.36\\%$. Finally, our tests with a matching algorithm on sufficiently large, dense graphs, demonstrate a reduction in the running time of up to 72.83\\% when the input is the compressed graph obtained by our algorithm, compared to the case where the input is the original uncompressed graph.","sentences":["Reducing the running time of graph algorithms is vital for tackling real-world problems such as shortest paths and matching in large-scale graphs, where path information plays a crucial role.","This paper addresses this critical challenge of reducing the running time of graph algorithms by proposing a new graph compression algorithm that partitions the graph into bipartite cliques and uses the partition to obtain a compressed graph having a smaller number of edges while preserving the path information.","This compressed graph can then be used as input to other graph algorithms for which path information is essential, leading to a significant reduction of their running time, especially for large, dense graphs.","The running time of the proposed algorithm is~$O(mn^\\delta)$, where $0 \\leq \\delta \\leq 1$, which is better than $O(mn^\\delta \\log^2 n)$, the running time of the best existing clique partitioning-based graph compression algorithm (the Feder-Motwani (\\textsf{FM}) algorithm).","Our extensive experimental analysis show that our algorithm achieves a compression ratio of up to~$26\\%$ greater and executes up to~105.18 times faster than the \\textsf{FM} algorithm.","In addition, on large graphs with up to 1.05 billion edges, it achieves a compression ratio of up to~3.9, reducing the number of edges up to~$74.36\\%$.","Finally, our tests with a matching algorithm on sufficiently large, dense graphs, demonstrate a reduction in the running time of up to 72.83\\% when the input is the compressed graph obtained by our algorithm, compared to the case where the input is the original uncompressed graph."],"url":"http://arxiv.org/abs/2502.02477v1"}
{"created":"2025-02-04 16:47:00","title":"Mind the Gap: Evaluating Patch Embeddings from General-Purpose and Histopathology Foundation Models for Cell Segmentation and Classification","abstract":"Recent advancements in foundation models have transformed computer vision, driving significant performance improvements across diverse domains, including digital histopathology. However, the advantages of domain-specific histopathology foundation models over general-purpose models for specialized tasks such as cell analysis remain underexplored. This study investigates the representation learning gap between these two categories by analyzing multi-level patch embeddings applied to cell instance segmentation and classification. We implement an encoder-decoder architecture with a consistent decoder and various encoders. These include convolutional, vision transformer (ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M, representing general-purpose foundation models. These are compared against ViT encoders from the recently released UNI, Virchow2, and Prov-GigaPath foundation models, trained on patches extracted from hundreds of thousands of histopathology whole-slide images. The decoder integrates patch embeddings from different encoder depths via skip connections to generate semantic and distance maps. These maps are then post-processed to create instance segmentation masks where each label corresponds to an individual cell and to perform cell-type classification. All encoders remain frozen during training to assess their pre-trained feature extraction capabilities. Using the PanNuke and CoNIC histopathology datasets, and the newly introduced Nissl-stained CytoDArk0 dataset for brain cytoarchitecture studies, we evaluate instance-level detection, segmentation accuracy, and cell-type classification. This study provides insights into the comparative strengths and limitations of general-purpose vs. histopathology foundation models, offering guidance for model selection in cell-focused histopathology and brain cytoarchitecture analysis workflows.","sentences":["Recent advancements in foundation models have transformed computer vision, driving significant performance improvements across diverse domains, including digital histopathology.","However, the advantages of domain-specific histopathology foundation models over general-purpose models for specialized tasks such as cell analysis remain underexplored.","This study investigates the representation learning gap between these two categories by analyzing multi-level patch embeddings applied to cell instance segmentation and classification.","We implement an encoder-decoder architecture with a consistent decoder and various encoders.","These include convolutional, vision transformer (ViT), and hybrid encoders pre-trained on ImageNet-22K or LVD-142M, representing general-purpose foundation models.","These are compared against ViT encoders from the recently released UNI, Virchow2, and Prov-GigaPath foundation models, trained on patches extracted from hundreds of thousands of histopathology whole-slide images.","The decoder integrates patch embeddings from different encoder depths via skip connections to generate semantic and distance maps.","These maps are then post-processed to create instance segmentation masks where each label corresponds to an individual cell and to perform cell-type classification.","All encoders remain frozen during training to assess their pre-trained feature extraction capabilities.","Using the PanNuke and CoNIC histopathology datasets, and the newly introduced Nissl-stained CytoDArk0 dataset for brain cytoarchitecture studies, we evaluate instance-level detection, segmentation accuracy, and cell-type classification.","This study provides insights into the comparative strengths and limitations of general-purpose vs. histopathology foundation models, offering guidance for model selection in cell-focused histopathology and brain cytoarchitecture analysis workflows."],"url":"http://arxiv.org/abs/2502.02471v1"}
{"created":"2025-02-04 16:44:38","title":"Modular Training of Neural Networks aids Interpretability","abstract":"An approach to improve neural network interpretability is via clusterability, i.e., splitting a model into disjoint clusters that can be studied independently. We define a measure for clusterability and show that pre-trained models form highly enmeshed clusters via spectral graph clustering. We thus train models to be more modular using a ``clusterability loss'' function that encourages the formation of non-interacting clusters. Using automated interpretability techniques, we show that our method can help train models that are more modular and learn different, disjoint, and smaller circuits. We investigate CNNs trained on MNIST and CIFAR, small transformers trained on modular addition, and language models. Our approach provides a promising direction for training neural networks that learn simpler functions and are easier to interpret.","sentences":["An approach to improve neural network interpretability is via clusterability, i.e., splitting a model into disjoint clusters that can be studied independently.","We define a measure for clusterability and show that pre-trained models form highly enmeshed clusters via spectral graph clustering.","We thus train models to be more modular using a ``clusterability loss'' function that encourages the formation of non-interacting clusters.","Using automated interpretability techniques, we show that our method can help train models that are more modular and learn different, disjoint, and smaller circuits.","We investigate CNNs trained on MNIST and CIFAR, small transformers trained on modular addition, and language models.","Our approach provides a promising direction for training neural networks that learn simpler functions and are easier to interpret."],"url":"http://arxiv.org/abs/2502.02470v1"}
{"created":"2025-02-04 16:40:19","title":"High-Fidelity Human Avatars from Laptop Webcams using Edge Compute","abstract":"Applications of generating photo-realistic human avatars are many, however, high-fidelity avatar generation traditionally required expensive professional camera rigs and artistic labor, but recent research has enabled constructing them automatically from smartphones with RGB and IR sensors. However, these new methods still rely on the presence of high-resolution cameras on modern smartphones and often require offloading the processing to powerful servers with GPUs. Modern applications such as video conferencing call for the ability to generate these avatars from consumer-grade laptop webcams using limited compute available on-device. In this work, we develop a novel method based on 3D morphable models, landmark detection, photo-realistic texture GANs, and differentiable rendering to tackle the problem of low webcam image quality and edge computation. We build an automatic system to generate high-fidelity animatable avatars under these limitations, leveraging the neural compute capabilities of mobile chips.","sentences":["Applications of generating photo-realistic human avatars are many, however, high-fidelity avatar generation traditionally required expensive professional camera rigs and artistic labor, but recent research has enabled constructing them automatically from smartphones with RGB and IR sensors.","However, these new methods still rely on the presence of high-resolution cameras on modern smartphones and often require offloading the processing to powerful servers with GPUs.","Modern applications such as video conferencing call for the ability to generate these avatars from consumer-grade laptop webcams using limited compute available on-device.","In this work, we develop a novel method based on 3D morphable models, landmark detection, photo-realistic texture GANs, and differentiable rendering to tackle the problem of low webcam image quality and edge computation.","We build an automatic system to generate high-fidelity animatable avatars under these limitations, leveraging the neural compute capabilities of mobile chips."],"url":"http://arxiv.org/abs/2502.02468v1"}
{"created":"2025-02-04 16:36:07","title":"Towards Consistent and Controllable Image Synthesis for Face Editing","abstract":"Current face editing methods mainly rely on GAN-based techniques, but recent focus has shifted to diffusion-based models due to their success in image reconstruction. However, diffusion models still face challenges in manipulating fine-grained attributes and preserving consistency of attributes that should remain unchanged. To address these issues and facilitate more convenient editing of face images, we propose a novel approach that leverages the power of Stable-Diffusion models and crude 3D face models to control the lighting, facial expression and head pose of a portrait photo. We observe that this task essentially involve combinations of target background, identity and different face attributes. We aim to sufficiently disentangle the control of these factors to enable high-quality of face editing. Specifically, our method, coined as RigFace, contains: 1) A Spatial Arrtibute Encoder that provides presise and decoupled conditions of background, pose, expression and lighting; 2) An Identity Encoder that transfers identity features to the denoising UNet of a pre-trained Stable-Diffusion model; 3) An Attribute Rigger that injects those conditions into the denoising UNet. Our model achieves comparable or even superior performance in both identity preservation and photorealism compared to existing face editing models.","sentences":["Current face editing methods mainly rely on GAN-based techniques, but recent focus has shifted to diffusion-based models due to their success in image reconstruction.","However, diffusion models still face challenges in manipulating fine-grained attributes and preserving consistency of attributes that should remain unchanged.","To address these issues and facilitate more convenient editing of face images, we propose a novel approach that leverages the power of Stable-Diffusion models and crude 3D face models to control the lighting, facial expression and head pose of a portrait photo.","We observe that this task essentially involve combinations of target background, identity and different face attributes.","We aim to sufficiently disentangle the control of these factors to enable high-quality of face editing.","Specifically, our method, coined as RigFace, contains: 1) A Spatial Arrtibute Encoder that provides presise and decoupled conditions of background, pose, expression and lighting; 2) An Identity Encoder that transfers identity features to the denoising UNet of a pre-trained Stable-Diffusion model; 3) An Attribute Rigger that injects those conditions into the denoising UNet.","Our model achieves comparable or even superior performance in both identity preservation and photorealism compared to existing face editing models."],"url":"http://arxiv.org/abs/2502.02465v1"}
{"created":"2025-02-04 16:33:25","title":"Rankify: A Comprehensive Python Toolkit for Retrieval, Re-Ranking, and Retrieval-Augmented Generation","abstract":"Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern natural language processing (NLP) applications in information retrieval, question answering, and knowledge-based text generation. However, existing solutions are often fragmented, lacking a unified framework that easily integrates these essential processes. The absence of a standardized implementation, coupled with the complexity of retrieval and re-ranking workflows, makes it challenging for researchers to compare and evaluate different approaches in a consistent environment. While existing toolkits such as Rerankers and RankLLM provide general-purpose reranking pipelines, they often lack the flexibility required for fine-grained experimentation and benchmarking. In response to these challenges, we introduce \\textbf{Rankify}, a powerful and modular open-source toolkit designed to unify retrieval, re-ranking, and RAG within a cohesive framework. Rankify supports a wide range of retrieval techniques, including dense and sparse retrievers, while incorporating state-of-the-art re-ranking models to enhance retrieval quality. Additionally, Rankify includes a collection of pre-retrieved datasets to facilitate benchmarking, available at Huggingface (https://huggingface.co/datasets/abdoelsayed/reranking-datasets). To encourage adoption and ease of integration, we provide comprehensive documentation (http://rankify.readthedocs.io/), an open-source implementation on GitHub(https://github.com/DataScienceUIBK/rankify), and a PyPI package for effortless installation(https://pypi.org/project/rankify/). By providing a unified and lightweight framework, Rankify allows researchers and practitioners to advance retrieval and re-ranking methodologies while ensuring consistency, scalability, and ease of use.","sentences":["Retrieval, re-ranking, and retrieval-augmented generation (RAG) are critical components of modern natural language processing (NLP) applications in information retrieval, question answering, and knowledge-based text generation.","However, existing solutions are often fragmented, lacking a unified framework that easily integrates these essential processes.","The absence of a standardized implementation, coupled with the complexity of retrieval and re-ranking workflows, makes it challenging for researchers to compare and evaluate different approaches in a consistent environment.","While existing toolkits such as Rerankers and RankLLM provide general-purpose reranking pipelines, they often lack the flexibility required for fine-grained experimentation and benchmarking.","In response to these challenges, we introduce \\textbf{Rankify}, a powerful and modular open-source toolkit designed to unify retrieval, re-ranking, and RAG within a cohesive framework.","Rankify supports a wide range of retrieval techniques, including dense and sparse retrievers, while incorporating state-of-the-art re-ranking models to enhance retrieval quality.","Additionally, Rankify includes a collection of pre-retrieved datasets to facilitate benchmarking, available at Huggingface (https://huggingface.co/datasets/abdoelsayed/reranking-datasets).","To encourage adoption and ease of integration, we provide comprehensive documentation (http://rankify.readthedocs.io/), an open-source implementation on GitHub(https://github.com/DataScienceUIBK/rankify), and a PyPI package for effortless installation(https://pypi.org/project/rankify/).","By providing a unified and lightweight framework, Rankify allows researchers and practitioners to advance retrieval and re-ranking methodologies while ensuring consistency, scalability, and ease of use."],"url":"http://arxiv.org/abs/2502.02464v1"}
{"created":"2025-02-04 16:29:42","title":"Computing with Smart Rings: A Systematic Literature Review","abstract":"A smart ring is a wearable electronic device in the form of a ring that incorporates diverse sensors and computing technologies to perform a variety of functions. Designed for use with fingers, smart rings are capable of sensing more subtle and abundant hand movements, thus making them a good platform for interaction. Meanwhile, fingers are abundant with blood vessels and nerve endings and accustomed to wearing rings, providing an ideal site for continuous health monitoring through smart rings, which combine comfort with the ability to capture vital biometric data, making them suitable for all-day wear. We collected in total of 206 smart ring-related publications and conducted a systematic literature review. We provide a taxonomy regarding the sensing and feedback modalities, applications, and phenomena. We review and categorize these literatures into four main areas: (1) interaction - input, (2) interaction - output, (3) passive sensing - in body feature, (4) passive sensing - out body activity. This comprehensive review highlights the current advancements within the field of smart ring and identifies potential areas for future research.","sentences":["A smart ring is a wearable electronic device in the form of a ring that incorporates diverse sensors and computing technologies to perform a variety of functions.","Designed for use with fingers, smart rings are capable of sensing more subtle and abundant hand movements, thus making them a good platform for interaction.","Meanwhile, fingers are abundant with blood vessels and nerve endings and accustomed to wearing rings, providing an ideal site for continuous health monitoring through smart rings, which combine comfort with the ability to capture vital biometric data, making them suitable for all-day wear.","We collected in total of 206 smart ring-related publications and conducted a systematic literature review.","We provide a taxonomy regarding the sensing and feedback modalities, applications, and phenomena.","We review and categorize these literatures into four main areas: (1) interaction - input, (2) interaction - output, (3) passive sensing - in body feature, (4) passive sensing - out body activity.","This comprehensive review highlights the current advancements within the field of smart ring and identifies potential areas for future research."],"url":"http://arxiv.org/abs/2502.02459v1"}
{"created":"2025-02-04 16:28:53","title":"SAISA: Towards Multimodal Large Language Models with Both Training and Inference Efficiency","abstract":"Multimodal Large Language Models (MLLMs) mainly fall into two architectures, each involving a trade-off between training and inference efficiency: embedding space alignment (e.g., LLaVA-1.5) is inefficient during inference, while cross-attention space alignment (e.g., Flamingo) is inefficient in training. In this paper, we compare these two architectures and identify the key factors for building efficient MLLMs. A primary difference between them lies in how attention is applied to visual tokens, particularly in their interactions with each other. To investigate whether attention among visual tokens is necessary, we propose a new self-attention mechanism, NAAViT (\\textbf{N}o \\textbf{A}ttention \\textbf{A}mong \\textbf{Vi}sual \\textbf{T}okens), which eliminates this type of attention. Our pilot experiment on LLaVA-1.5 shows that attention among visual tokens is highly redundant. Based on these insights, we introduce SAISA (\\textbf{S}elf-\\textbf{A}ttention \\textbf{I}nput \\textbf{S}pace \\textbf{A}lignment), a novel architecture that enhance both training and inference efficiency. SAISA directly aligns visual features with the input spaces of NAAViT self-attention blocks, reducing computational overhead in both self-attention blocks and feed-forward networks (FFNs). Using the same configuration as LLaVA-1.5, SAISA reduces inference FLOPs by 66\\% and training budget by 26\\%, while achieving superior performance in terms of accuracy. Comprehensive ablation studies further validate the effectiveness of SAISA across various LLMs and visual encoders. The code and model will be publicly available at https://github.com/icip-cas/SAISA.","sentences":["Multimodal Large Language Models (MLLMs) mainly fall into two architectures, each involving a trade-off between training and inference efficiency: embedding space alignment (e.g., LLaVA-1.5) is inefficient during inference, while cross-attention space alignment (e.g., Flamingo) is inefficient in training.","In this paper, we compare these two architectures and identify the key factors for building efficient MLLMs.","A primary difference between them lies in how attention is applied to visual tokens, particularly in their interactions with each other.","To investigate whether attention among visual tokens is necessary, we propose a new self-attention mechanism, NAAViT (\\textbf{N}o \\textbf{A}ttention \\textbf{A}mong \\textbf{Vi}sual \\textbf{T}okens), which eliminates this type of attention.","Our pilot experiment on LLaVA-1.5 shows that attention among visual tokens is highly redundant.","Based on these insights, we introduce SAISA (\\textbf{S}elf-\\textbf{A}ttention \\textbf{I}nput \\textbf{S}pace \\textbf{A}lignment), a novel architecture that enhance both training and inference efficiency.","SAISA directly aligns visual features with the input spaces of NAAViT self-attention blocks, reducing computational overhead in both self-attention blocks and feed-forward networks (FFNs).","Using the same configuration as LLaVA-1.5, SAISA reduces inference FLOPs by 66\\% and training budget by 26\\%, while achieving superior performance in terms of accuracy.","Comprehensive ablation studies further validate the effectiveness of SAISA across various LLMs and visual encoders.","The code and model will be publicly available at https://github.com/icip-cas/SAISA."],"url":"http://arxiv.org/abs/2502.02458v1"}
{"created":"2025-02-04 16:25:15","title":"Orientation-aware interaction-based deep material network in polycrystalline materials modeling","abstract":"Multiscale simulations are indispensable for connecting microstructural features to the macroscopic behavior of polycrystalline materials, but their high computational demands limit their practicality. Deep material networks (DMNs) have been proposed as efficient surrogate models, yet they fall short of capturing texture evolution. To address this limitation, we propose the orientation-aware interaction-based deep material network (ODMN), which incorporates an orientation-aware mechanism and an interaction mechanism grounded in the Hill-Mandel principle. The orientation-aware mechanism learns the crystallographic textures, while the interaction mechanism captures stress-equilibrium directions among representative volume element (RVE) subregions, offering insight into internal microstructural mechanics. Notably, ODMN requires only linear elastic data for training yet generalizes effectively to complex nonlinear and anisotropic responses. Our results show that ODMN accurately predicts both mechanical responses and texture evolution under complex plastic deformation, thus expanding the applicability of DMNs to polycrystalline materials. By balancing computational efficiency with predictive fidelity, ODMN provides a robust framework for multiscale simulations of polycrystalline materials.","sentences":["Multiscale simulations are indispensable for connecting microstructural features to the macroscopic behavior of polycrystalline materials, but their high computational demands limit their practicality.","Deep material networks (DMNs) have been proposed as efficient surrogate models, yet they fall short of capturing texture evolution.","To address this limitation, we propose the orientation-aware interaction-based deep material network (ODMN), which incorporates an orientation-aware mechanism and an interaction mechanism grounded in the Hill-Mandel principle.","The orientation-aware mechanism learns the crystallographic textures, while the interaction mechanism captures stress-equilibrium directions among representative volume element (RVE) subregions, offering insight into internal microstructural mechanics.","Notably, ODMN requires only linear elastic data for training yet generalizes effectively to complex nonlinear and anisotropic responses.","Our results show that ODMN accurately predicts both mechanical responses and texture evolution under complex plastic deformation, thus expanding the applicability of DMNs to polycrystalline materials.","By balancing computational efficiency with predictive fidelity, ODMN provides a robust framework for multiscale simulations of polycrystalline materials."],"url":"http://arxiv.org/abs/2502.02457v1"}
{"created":"2025-02-04 16:24:42","title":"Model Human Learners: Computational Models to Guide Instructional Design","abstract":"Instructional designers face an overwhelming array of design choices, making it challenging to identify the most effective interventions. To address this issue, I propose the concept of a Model Human Learner, a unified computational model of learning that can aid designers in evaluating candidate interventions. This paper presents the first successful demonstration of this concept, showing that a computational model can accurately predict the outcomes of two human A/B experiments -- one testing a problem sequencing intervention and the other testing an item design intervention. It also demonstrates that such a model can generate learning curves without requiring human data and provide theoretical insights into why an instructional intervention is effective. These findings lay the groundwork for future Model Human Learners that integrate cognitive and learning theories to support instructional design across diverse tasks and interventions.","sentences":["Instructional designers face an overwhelming array of design choices, making it challenging to identify the most effective interventions.","To address this issue, I propose the concept of a Model Human Learner, a unified computational model of learning that can aid designers in evaluating candidate interventions.","This paper presents the first successful demonstration of this concept, showing that a computational model can accurately predict the outcomes of two human A/B experiments -- one testing a problem sequencing intervention and the other testing an item design intervention.","It also demonstrates that such a model can generate learning curves without requiring human data and provide theoretical insights into why an instructional intervention is effective.","These findings lay the groundwork for future Model Human Learners that integrate cognitive and learning theories to support instructional design across diverse tasks and interventions."],"url":"http://arxiv.org/abs/2502.02456v1"}
{"created":"2025-02-04 16:21:02","title":"A note on Ordered Ruzsa-Szemer\u00e9di graphs","abstract":"A recent breakthrough of Behnezhad and Ghafari [FOCS 2024] and subsequent work of Assadi, Khanna, and Kiss [SODA 2025] gave algorithms for the fully dynamic $(1-\\varepsilon)$-approximate maximum matching problem whose runtimes are determined by a purely combinatorial quantity: the maximum density of Ordered Ruzsa-Szemer\\'edi (ORS) graphs. We say a graph $G$ is an $(r,t)$-ORS graph if its edges can be partitioned into $t$ matchings $M_1,M_2, \\ldots, M_t$ each of size $r$, such that for every $i$, $M_i$ is an induced matching in the subgraph $M_{i} \\cup M_{i+1} \\cup \\cdots \\cup M_t$. This is a relaxation of the extensively-studied notion of a Ruzsa-Szemer\\'edi (RS) graph, the difference being that in an RS graph each $M_i$ must be an induced matching in $G$.   In this note, we show that these two notions are roughly equivalent. Specifically, let $\\mathrm{ORS}(n)$ be the largest $t$ such that there exists an $n$-vertex ORS-$(\\Omega(n), t)$ graph, and define $\\mathrm{RS}(n)$ analogously. We show that if $\\mathrm{ORS}(n) \\ge \\Omega(n^c)$, then for any fixed $\\delta > 0$, $\\mathrm{RS}(n) \\ge \\Omega(n^{c(1-\\delta)})$. This resolves a question of Behnezhad and Ghafari.","sentences":["A recent breakthrough of Behnezhad and Ghafari [FOCS 2024] and subsequent work of Assadi, Khanna, and Kiss","[SODA 2025] gave algorithms for the fully dynamic $(1-\\varepsilon)$-approximate maximum matching problem whose runtimes are determined by a purely combinatorial quantity: the maximum density of Ordered Ruzsa-Szemer\\'edi (ORS) graphs.","We say a graph $G$ is an $(r,t)$-ORS graph if its edges can be partitioned into $t$ matchings $M_1,M_2, \\ldots, M_t$ each of size $r$, such that for every $i$, $M_i$ is an induced matching in the subgraph $M_{i} \\cup M_{i+1} \\cup \\cdots \\cup M_t$. This is a relaxation of the extensively-studied notion of a Ruzsa-Szemer\\'edi (RS) graph, the difference being that in an RS graph each $M_i$ must be an induced matching in $G$.   In this note, we show that these two notions are roughly equivalent.","Specifically, let $\\mathrm{ORS}(n)$ be the largest $t$ such that there exists an $n$-vertex ORS-$(\\Omega(n), t)$ graph, and define $\\mathrm{RS}(n)$ analogously.","We show that if $\\mathrm{ORS}(n) \\ge \\Omega(n^c)$, then for any fixed $\\delta > 0$, $\\mathrm{RS}(n) \\ge \\Omega(n^{c(1-\\delta)})$.","This resolves a question of Behnezhad and Ghafari."],"url":"http://arxiv.org/abs/2502.02455v1"}
{"created":"2025-02-04 16:20:41","title":"IMDPrompter: Adapting SAM to Image Manipulation Detection by Cross-View Automated Prompt Learning","abstract":"Using extensive training data from SA-1B, the Segment Anything Model (SAM) has demonstrated exceptional generalization and zero-shot capabilities, attracting widespread attention in areas such as medical image segmentation and remote sensing image segmentation. However, its performance in the field of image manipulation detection remains largely unexplored and unconfirmed. There are two main challenges in applying SAM to image manipulation detection: a) reliance on manual prompts, and b) the difficulty of single-view information in supporting cross-dataset generalization. To address these challenges, we develops a cross-view prompt learning paradigm called IMDPrompter based on SAM. Benefiting from the design of automated prompts, IMDPrompter no longer relies on manual guidance, enabling automated detection and localization. Additionally, we propose components such as Cross-view Feature Perception, Optimal Prompt Selection, and Cross-View Prompt Consistency, which facilitate cross-view perceptual learning and guide SAM to generate accurate masks. Extensive experimental results from five datasets (CASIA, Columbia, Coverage, IMD2020, and NIST16) validate the effectiveness of our proposed method.","sentences":["Using extensive training data from SA-1B, the Segment Anything Model (SAM) has demonstrated exceptional generalization and zero-shot capabilities, attracting widespread attention in areas such as medical image segmentation and remote sensing image segmentation.","However, its performance in the field of image manipulation detection remains largely unexplored and unconfirmed.","There are two main challenges in applying SAM to image manipulation detection: a) reliance on manual prompts, and b) the difficulty of single-view information in supporting cross-dataset generalization.","To address these challenges, we develops a cross-view prompt learning paradigm called IMDPrompter based on SAM.","Benefiting from the design of automated prompts, IMDPrompter no longer relies on manual guidance, enabling automated detection and localization.","Additionally, we propose components such as Cross-view Feature Perception, Optimal Prompt Selection, and Cross-View Prompt Consistency, which facilitate cross-view perceptual learning and guide SAM to generate accurate masks.","Extensive experimental results from five datasets (CASIA, Columbia, Coverage, IMD2020, and NIST16) validate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2502.02454v1"}
{"created":"2025-02-04 16:19:20","title":"Personalization Toolkit: Training Free Personalization of Large Vision Language Models","abstract":"Large Vision Language Models (LVLMs) have significant potential to deliver personalized assistance by adapting to individual users' unique needs and preferences. Personalization of LVLMs is an emerging area that involves customizing models to recognize specific object instances and provide tailored responses. However, existing approaches rely on time-consuming test-time training for each user and object, rendering them impractical. This paper proposes a novel, training-free approach to LVLM personalization by leveraging pre-trained vision foundation models to extract distinct features, retrieval-augmented generation (RAG) techniques to recognize instances in the visual input, and visual prompting methods. Our model-agnostic vision toolkit enables flexible and efficient personalization without extensive retraining. We demonstrate state-of-the-art results, outperforming conventional training-based approaches and establish a new standard for LVLM personalization.","sentences":["Large Vision Language Models (LVLMs) have significant potential to deliver personalized assistance by adapting to individual users' unique needs and preferences.","Personalization of LVLMs is an emerging area that involves customizing models to recognize specific object instances and provide tailored responses.","However, existing approaches rely on time-consuming test-time training for each user and object, rendering them impractical.","This paper proposes a novel, training-free approach to LVLM personalization by leveraging pre-trained vision foundation models to extract distinct features, retrieval-augmented generation (RAG) techniques to recognize instances in the visual input, and visual prompting methods.","Our model-agnostic vision toolkit enables flexible and efficient personalization without extensive retraining.","We demonstrate state-of-the-art results, outperforming conventional training-based approaches and establish a new standard for LVLM personalization."],"url":"http://arxiv.org/abs/2502.02452v1"}
{"created":"2025-02-04 16:17:01","title":"Beyond English: Evaluating Automated Measurement of Moral Foundations in Non-English Discourse with a Chinese Case Study","abstract":"This study explores computational approaches for measuring moral foundations (MFs) in non-English corpora. Since most resources are developed primarily for English, cross-linguistic applications of moral foundation theory remain limited. Using Chinese as a case study, this paper evaluates the effectiveness of applying English resources to machine translated text, local language lexicons, multilingual language models, and large language models (LLMs) in measuring MFs in non-English texts. The results indicate that machine translation and local lexicon approaches are insufficient for complex moral assessments, frequently resulting in a substantial loss of cultural information. In contrast, multilingual models and LLMs demonstrate reliable cross-language performance with transfer learning, with LLMs excelling in terms of data efficiency. Importantly, this study also underscores the need for human-in-the-loop validation of automated MF assessment, as the most advanced models may overlook cultural nuances in cross-language measurements. The findings highlight the potential of LLMs for cross-language MF measurements and other complex multilingual deductive coding tasks.","sentences":["This study explores computational approaches for measuring moral foundations (MFs) in non-English corpora.","Since most resources are developed primarily for English, cross-linguistic applications of moral foundation theory remain limited.","Using Chinese as a case study, this paper evaluates the effectiveness of applying English resources to machine translated text, local language lexicons, multilingual language models, and large language models (LLMs) in measuring MFs in non-English texts.","The results indicate that machine translation and local lexicon approaches are insufficient for complex moral assessments, frequently resulting in a substantial loss of cultural information.","In contrast, multilingual models and LLMs demonstrate reliable cross-language performance with transfer learning, with LLMs excelling in terms of data efficiency.","Importantly, this study also underscores the need for human-in-the-loop validation of automated MF assessment, as the most advanced models may overlook cultural nuances in cross-language measurements.","The findings highlight the potential of LLMs for cross-language MF measurements and other complex multilingual deductive coding tasks."],"url":"http://arxiv.org/abs/2502.02451v1"}
{"created":"2025-02-04 16:14:40","title":"TUMTraffic-VideoQA: A Benchmark for Unified Spatio-Temporal Video Understanding in Traffic Scenes","abstract":"We present TUMTraffic-VideoQA, a novel dataset and benchmark designed for spatio-temporal video understanding in complex roadside traffic scenarios. The dataset comprises 1,000 videos, featuring 85,000 multiple-choice QA pairs, 2,300 object captioning, and 5,700 object grounding annotations, encompassing diverse real-world conditions such as adverse weather and traffic anomalies. By incorporating tuple-based spatio-temporal object expressions, TUMTraffic-VideoQA unifies three essential tasks-multiple-choice video question answering, referred object captioning, and spatio-temporal object grounding-within a cohesive evaluation framework. We further introduce the TUMTraffic-Qwen baseline model, enhanced with visual token sampling strategies, providing valuable insights into the challenges of fine-grained spatio-temporal reasoning. Extensive experiments demonstrate the dataset's complexity, highlight the limitations of existing models, and position TUMTraffic-VideoQA as a robust foundation for advancing research in intelligent transportation systems. The dataset and benchmark are publicly available to facilitate further exploration.","sentences":["We present TUMTraffic-VideoQA, a novel dataset and benchmark designed for spatio-temporal video understanding in complex roadside traffic scenarios.","The dataset comprises 1,000 videos, featuring 85,000 multiple-choice QA pairs, 2,300 object captioning, and 5,700 object grounding annotations, encompassing diverse real-world conditions such as adverse weather and traffic anomalies.","By incorporating tuple-based spatio-temporal object expressions, TUMTraffic-VideoQA unifies three essential tasks-multiple-choice video question answering, referred object captioning, and spatio-temporal object grounding-within a cohesive evaluation framework.","We further introduce the TUMTraffic-Qwen baseline model, enhanced with visual token sampling strategies, providing valuable insights into the challenges of fine-grained spatio-temporal reasoning.","Extensive experiments demonstrate the dataset's complexity, highlight the limitations of existing models, and position TUMTraffic-VideoQA as a robust foundation for advancing research in intelligent transportation systems.","The dataset and benchmark are publicly available to facilitate further exploration."],"url":"http://arxiv.org/abs/2502.02449v1"}
{"created":"2025-02-04 16:14:28","title":"Sparse Data Generation Using Diffusion Models","abstract":"Sparse data is ubiquitous, appearing in numerous domains, from economics and recommender systems to astronomy and biomedical sciences. However, efficiently and realistically generating sparse data remains a significant challenge. We introduce Sparse Data Diffusion (SDD), a novel method for generating sparse data. SDD extends continuous state-space diffusion models by explicitly modeling sparsity through the introduction of Sparsity Bits. Empirical validation on image data from various domains-including two scientific applications, physics and biology-demonstrates that SDD achieves high fidelity in representing data sparsity while preserving the quality of the generated data.","sentences":["Sparse data is ubiquitous, appearing in numerous domains, from economics and recommender systems to astronomy and biomedical sciences.","However, efficiently and realistically generating sparse data remains a significant challenge.","We introduce Sparse Data Diffusion (SDD), a novel method for generating sparse data.","SDD extends continuous state-space diffusion models by explicitly modeling sparsity through the introduction of Sparsity Bits.","Empirical validation on image data from various domains-including two scientific applications, physics and biology-demonstrates that SDD achieves high fidelity in representing data sparsity while preserving the quality of the generated data."],"url":"http://arxiv.org/abs/2502.02448v1"}
{"created":"2025-02-04 16:11:41","title":"Towards graph neural networks for provably solving convex optimization problems","abstract":"Recently, message-passing graph neural networks (MPNNs) have shown potential for solving combinatorial and continuous optimization problems due to their ability to capture variable-constraint interactions. While existing approaches leverage MPNNs to approximate solutions or warm-start traditional solvers, they often lack guarantees for feasibility, particularly in convex optimization settings. Here, we propose an iterative MPNN framework to solve convex optimization problems with provable feasibility guarantees. First, we demonstrate that MPNNs can provably simulate standard interior-point methods for solving quadratic problems with linear constraints, covering relevant problems such as SVMs. Secondly, to ensure feasibility, we introduce a variant that starts from a feasible point and iteratively restricts the search within the feasible region. Experimental results show that our approach outperforms existing neural baselines in solution quality and feasibility, generalizes well to unseen problem sizes, and, in some cases, achieves faster solution times than state-of-the-art solvers such as Gurobi.","sentences":["Recently, message-passing graph neural networks (MPNNs) have shown potential for solving combinatorial and continuous optimization problems due to their ability to capture variable-constraint interactions.","While existing approaches leverage MPNNs to approximate solutions or warm-start traditional solvers, they often lack guarantees for feasibility, particularly in convex optimization settings.","Here, we propose an iterative MPNN framework to solve convex optimization problems with provable feasibility guarantees.","First, we demonstrate that MPNNs can provably simulate standard interior-point methods for solving quadratic problems with linear constraints, covering relevant problems such as SVMs.","Secondly, to ensure feasibility, we introduce a variant that starts from a feasible point and iteratively restricts the search within the feasible region.","Experimental results show that our approach outperforms existing neural baselines in solution quality and feasibility, generalizes well to unseen problem sizes, and, in some cases, achieves faster solution times than state-of-the-art solvers such as Gurobi."],"url":"http://arxiv.org/abs/2502.02446v1"}
{"created":"2025-02-04 16:10:55","title":"Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models","abstract":"Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics. Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values. Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored. This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems. Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs. For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge AI priorities. Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values.","sentences":["Values are core drivers of individual and collective perception, cognition, and behavior.","Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics.","Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values.","Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored.","This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems.","Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs.","For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge AI priorities.","Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values."],"url":"http://arxiv.org/abs/2502.02444v1"}
{"created":"2025-02-04 16:10:22","title":"A Null Space Compliance Approach for Maintaining Safety and Tracking Performance in Human-Robot Interactions","abstract":"In recent years, the focus on developing robot manipulators has shifted towards prioritizing safety in Human-Robot Interaction (HRI). Impedance control is a typical approach for interaction control in collaboration tasks. However, such a control approach has two main limitations: 1) the end-effector (EE)'s limited compliance to adapt to unknown physical interactions, and 2) inability of the robot body to compliantly adapt to unknown physical interactions. In this work, we present an approach to address these drawbacks. We introduce a modified Cartesian impedance control method combined with a Dynamical System (DS)-based motion generator, aimed at enhancing the interaction capability of the EE without compromising main task tracking performance. This approach enables human coworkers to interact with the EE on-the-fly, e.g. tool changeover, after which the robot compliantly resumes its task. Additionally, combining with a new null space impedance control method enables the robot body to exhibit compliant behaviour in response to interactions, avoiding serious injuries from accidental contact while mitigating the impact on main task tracking performance. Finally, we prove the passivity of the system and validate the proposed approach through comprehensive comparative experiments on a 7 Degree-of-Freedom (DOF) KUKA LWR IV+ robot.","sentences":["In recent years, the focus on developing robot manipulators has shifted towards prioritizing safety in Human-Robot Interaction (HRI).","Impedance control is a typical approach for interaction control in collaboration tasks.","However, such a control approach has two main limitations: 1) the end-effector (EE)'s limited compliance to adapt to unknown physical interactions, and 2) inability of the robot body to compliantly adapt to unknown physical interactions.","In this work, we present an approach to address these drawbacks.","We introduce a modified Cartesian impedance control method combined with a Dynamical System (DS)-based motion generator, aimed at enhancing the interaction capability of the EE without compromising main task tracking performance.","This approach enables human coworkers to interact with the EE on-the-fly, e.g. tool changeover, after which the robot compliantly resumes its task.","Additionally, combining with a new null space impedance control method enables the robot body to exhibit compliant behaviour in response to interactions, avoiding serious injuries from accidental contact while mitigating the impact on main task tracking performance.","Finally, we prove the passivity of the system and validate the proposed approach through comprehensive comparative experiments on a 7 Degree-of-Freedom (DOF) KUKA LWR IV+ robot."],"url":"http://arxiv.org/abs/2502.02443v1"}
{"created":"2025-02-04 16:09:46","title":"The Algebraic Cost of a Boolean Sum","abstract":"The P versus NP problem is about the computational power of an existential $\\exists_{w \\in \\{0,1\\}^n}$ quantifier. The VP versus VNP problem is about the power of a boolean sum $\\sum_{w \\in \\{0,1\\}^n}$ operation. We study the power of a single boolean sum $\\sum_{w \\in \\{0,1\\}}$, and prove that in some cases the cost of eliminating this sum is large. This identifies a fundamental difference between the permanent and the determinant. This investigation also leads to the simplest proof we are aware of that the permanent is VNP-complete.","sentences":["The P versus NP problem is about the computational power of an existential $\\exists_{w \\in \\{0,1\\}^n}$ quantifier.","The VP versus VNP problem is about the power of a boolean sum $\\sum_{w \\in \\{0,1\\}^n}$ operation.","We study the power of a single boolean sum $\\sum_{w \\in \\{0,1\\}}$, and prove that in some cases the cost of eliminating this sum is large.","This identifies a fundamental difference between the permanent and the determinant.","This investigation also leads to the simplest proof we are aware of that the permanent is VNP-complete."],"url":"http://arxiv.org/abs/2502.02442v1"}
{"created":"2025-02-04 16:08:48","title":"LLMER: Crafting Interactive Extended Reality Worlds with JSON Data Generated by Large Language Models","abstract":"The integration of Large Language Models (LLMs) like GPT-4 with Extended Reality (XR) technologies offers the potential to build truly immersive XR environments that interact with human users through natural language, e.g., generating and animating 3D scenes from audio inputs. However, the complexity of XR environments makes it difficult to accurately extract relevant contextual data and scene/object parameters from an overwhelming volume of XR artifacts. It leads to not only increased costs with pay-per-use models, but also elevated levels of generation errors. Moreover, existing approaches focusing on coding script generation are often prone to generation errors, resulting in flawed or invalid scripts, application crashes, and ultimately a degraded user experience. To overcome these challenges, we introduce LLMER, a novel framework that creates interactive XR worlds using JSON data generated by LLMs. Unlike prior approaches focusing on coding script generation, LLMER translates natural language inputs into JSON data, significantly reducing the likelihood of application crashes and processing latency. It employs a multi-stage strategy to supply only the essential contextual information adapted to the user's request and features multiple modules designed for various XR tasks. Our preliminary user study reveals the effectiveness of the proposed system, with over 80% reduction in consumed tokens and around 60% reduction in task completion time compared to state-of-the-art approaches. The analysis of users' feedback also illuminates a series of directions for further optimization.","sentences":["The integration of Large Language Models (LLMs) like GPT-4 with Extended Reality (XR) technologies offers the potential to build truly immersive XR environments that interact with human users through natural language, e.g., generating and animating 3D scenes from audio inputs.","However, the complexity of XR environments makes it difficult to accurately extract relevant contextual data and scene/object parameters from an overwhelming volume of XR artifacts.","It leads to not only increased costs with pay-per-use models, but also elevated levels of generation errors.","Moreover, existing approaches focusing on coding script generation are often prone to generation errors, resulting in flawed or invalid scripts, application crashes, and ultimately a degraded user experience.","To overcome these challenges, we introduce LLMER, a novel framework that creates interactive XR worlds using JSON data generated by LLMs.","Unlike prior approaches focusing on coding script generation, LLMER translates natural language inputs into JSON data, significantly reducing the likelihood of application crashes and processing latency.","It employs a multi-stage strategy to supply only the essential contextual information adapted to the user's request and features multiple modules designed for various XR tasks.","Our preliminary user study reveals the effectiveness of the proposed system, with over 80% reduction in consumed tokens and around 60% reduction in task completion time compared to state-of-the-art approaches.","The analysis of users' feedback also illuminates a series of directions for further optimization."],"url":"http://arxiv.org/abs/2502.02441v1"}
{"created":"2025-02-04 16:04:48","title":"Medical Multimodal Model Stealing Attacks via Adversarial Domain Alignment","abstract":"Medical multimodal large language models (MLLMs) are becoming an instrumental part of healthcare systems, assisting medical personnel with decision making and results analysis. Models for radiology report generation are able to interpret medical imagery, thus reducing the workload of radiologists. As medical data is scarce and protected by privacy regulations, medical MLLMs represent valuable intellectual property. However, these assets are potentially vulnerable to model stealing, where attackers aim to replicate their functionality via black-box access. So far, model stealing for the medical domain has focused on classification; however, existing attacks are not effective against MLLMs. In this paper, we introduce Adversarial Domain Alignment (ADA-STEAL), the first stealing attack against medical MLLMs. ADA-STEAL relies on natural images, which are public and widely available, as opposed to their medical counterparts. We show that data augmentation with adversarial noise is sufficient to overcome the data distribution gap between natural images and the domain-specific distribution of the victim MLLM. Experiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that Adversarial Domain Alignment enables attackers to steal the medical MLLM without any access to medical data.","sentences":["Medical multimodal large language models (MLLMs) are becoming an instrumental part of healthcare systems, assisting medical personnel with decision making and results analysis.","Models for radiology report generation are able to interpret medical imagery, thus reducing the workload of radiologists.","As medical data is scarce and protected by privacy regulations, medical MLLMs represent valuable intellectual property.","However, these assets are potentially vulnerable to model stealing, where attackers aim to replicate their functionality via black-box access.","So far, model stealing for the medical domain has focused on classification; however, existing attacks are not effective against MLLMs.","In this paper, we introduce Adversarial Domain Alignment (ADA-STEAL), the first stealing attack against medical MLLMs.","ADA-STEAL relies on natural images, which are public and widely available, as opposed to their medical counterparts.","We show that data augmentation with adversarial noise is sufficient to overcome the data distribution gap between natural images and the domain-specific distribution of the victim MLLM.","Experiments on the IU X-RAY and MIMIC-CXR radiology datasets demonstrate that Adversarial Domain Alignment enables attackers to steal the medical MLLM without any access to medical data."],"url":"http://arxiv.org/abs/2502.02438v1"}
{"created":"2025-02-04 16:03:52","title":"H-MBR: Hypervisor-level Memory Bandwidth Reservation for Mixed Criticality Systems","abstract":"Recent advancements in fields such as automotive and aerospace have driven a growing demand for robust computational resources. Applications that were once designed for basic MCUs are now deployed on highly heterogeneous SoC platforms. While these platforms deliver the necessary computational performance, they also present challenges related to resource sharing and predictability. These challenges are particularly pronounced when consolidating safety and non-safety-critical systems, the so-called Mixed-Criticality Systems (MCS) to adhere to strict SWaP-C requirements. MCS consolidation on shared platforms requires stringent spatial and temporal isolation to comply with functional safety standards. Virtualization, mainly leveraged by hypervisors, is a key technology that ensures spatial isolation across multiple OSes and applications; however, ensuring temporal isolation remains challenging due to contention on shared hardwar resources, which impacts real-time performance and predictability. To mitigate this problem, several strategies as cache coloring and memory bandwidth reservation have been proposed. Although cache coloring is typically implemented on state-of-the-art hypervisors, memory bandwidth reservation approaches are commonly implemented at the Linux kernel level or rely on dedicated hardware and typically do not consider the concept of VMs that can run different OSes. To fill the gap between current memory bandwidth reservation solutions and the deployment of MCSs that operate on a hypervisor, this work introduces H-MBR, an open-source VM-centric memory bandwidth reservation mechanism. H-MBR features (i) VM-centric bandwidth reservation, (ii) OS and platform agnosticism, and (iii) reduced overhead. Empirical results evidenced no overhead on non-regulated workloads, and negligible overhead (<1%) for regulated workloads for regulation periods of 2 us or higher.","sentences":["Recent advancements in fields such as automotive and aerospace have driven a growing demand for robust computational resources.","Applications that were once designed for basic MCUs are now deployed on highly heterogeneous SoC platforms.","While these platforms deliver the necessary computational performance, they also present challenges related to resource sharing and predictability.","These challenges are particularly pronounced when consolidating safety and non-safety-critical systems, the so-called Mixed-Criticality Systems (MCS) to adhere to strict SWaP-C requirements.","MCS consolidation on shared platforms requires stringent spatial and temporal isolation to comply with functional safety standards.","Virtualization, mainly leveraged by hypervisors, is a key technology that ensures spatial isolation across multiple OSes and applications; however, ensuring temporal isolation remains challenging due to contention on shared hardwar resources, which impacts real-time performance and predictability.","To mitigate this problem, several strategies as cache coloring and memory bandwidth reservation have been proposed.","Although cache coloring is typically implemented on state-of-the-art hypervisors, memory bandwidth reservation approaches are commonly implemented at the Linux kernel level or rely on dedicated hardware and typically do not consider the concept of VMs that can run different OSes.","To fill the gap between current memory bandwidth reservation solutions and the deployment of MCSs that operate on a hypervisor, this work introduces H-MBR, an open-source VM-centric memory bandwidth reservation mechanism.","H-MBR features (i) VM-centric bandwidth reservation, (ii) OS and platform agnosticism, and (iii) reduced overhead.","Empirical results evidenced no overhead on non-regulated workloads, and negligible overhead (<1%) for regulated workloads for regulation periods of 2 us or higher."],"url":"http://arxiv.org/abs/2502.02437v1"}
{"created":"2025-02-04 15:58:12","title":"mPOLICE: Provable Enforcement of Multi-Region Affine Constraints in Deep Neural Networks","abstract":"Deep neural networks are increasingly employed in fields such as climate modeling, robotics, and industrial control, where strict output constraints must be upheld. Although prior methods like the POLICE algorithm can enforce affine constraints in a single convex region by adjusting network parameters, they struggle with multiple disjoint regions, often leading to conflicts or unintended affine extensions. We present mPOLICE, a new method that extends POLICE to handle constraints imposed on multiple regions. mPOLICE assigns a distinct activation pattern to each constrained region, preserving exact affine behavior locally while avoiding overreach into other parts of the input domain. We formulate a layer-wise optimization problem that adjusts both the weights and biases to assign unique activation patterns to each convex region, ensuring that constraints are met without conflicts, while maintaining the continuity and smoothness of the learned function. Our experiments show the enforcement of multi-region constraints for multiple scenarios, including regression and classification, function approximation, and non-convex regions through approximation. Notably, mPOLICE adds zero inference overhead and minimal training overhead.","sentences":["Deep neural networks are increasingly employed in fields such as climate modeling, robotics, and industrial control, where strict output constraints must be upheld.","Although prior methods like the POLICE algorithm can enforce affine constraints in a single convex region by adjusting network parameters, they struggle with multiple disjoint regions, often leading to conflicts or unintended affine extensions.","We present mPOLICE, a new method that extends POLICE to handle constraints imposed on multiple regions.","mPOLICE assigns a distinct activation pattern to each constrained region, preserving exact affine behavior locally while avoiding overreach into other parts of the input domain.","We formulate a layer-wise optimization problem that adjusts both the weights and biases to assign unique activation patterns to each convex region, ensuring that constraints are met without conflicts, while maintaining the continuity and smoothness of the learned function.","Our experiments show the enforcement of multi-region constraints for multiple scenarios, including regression and classification, function approximation, and non-convex regions through approximation.","Notably, mPOLICE adds zero inference overhead and minimal training overhead."],"url":"http://arxiv.org/abs/2502.02434v1"}
{"created":"2025-02-04 15:57:19","title":"A coding theoretic study of homogeneous Markovian predictive games","abstract":"This paper explores a predictive game in which a Forecaster announces odds based on a time-homogeneous Markov kernel, establishing a game-theoretic law of large numbers for the relative frequencies of occurrences of all finite strings. A key feature of our proof is a betting strategy built on a universal coding scheme, inspired by the martingale convergence theorem and algorithmic randomness theory, without relying on a diversified betting approach that involves countably many operating accounts. We apply these insights to thermodynamics, offering a game-theoretic perspective on Le\\'o Szil\\'ard's thought experiment.","sentences":["This paper explores a predictive game in which a Forecaster announces odds based on a time-homogeneous Markov kernel, establishing a game-theoretic law of large numbers for the relative frequencies of occurrences of all finite strings.","A key feature of our proof is a betting strategy built on a universal coding scheme, inspired by the martingale convergence theorem and algorithmic randomness theory, without relying on a diversified betting approach that involves countably many operating accounts.","We apply these insights to thermodynamics, offering a game-theoretic perspective on Le\\'o Szil\\'ard's thought experiment."],"url":"http://arxiv.org/abs/2502.02433v1"}
{"created":"2025-02-04 15:55:35","title":"Connections between Schedule-Free Optimizers, AdEMAMix, and Accelerated SGD Variants","abstract":"Recent advancements in deep learning optimization have introduced new algorithms, such as Schedule-Free optimizers, AdEMAMix, MARS and Lion which modify traditional momentum mechanisms. In a separate line of work, theoretical acceleration of stochastic gradient descent (SGD) in noise-dominated regime has been achieved by decoupling the momentum coefficient from the current gradient's weight. In this paper, we establish explicit connections between these two lines of work. We substantiate our theoretical findings with preliminary experiments on a 150m language modeling task. We find that AdEMAMix, which most closely resembles accelerated versions of stochastic gradient descent, exhibits superior performance. Building on these insights, we introduce a modification to AdEMAMix, termed Simplified-AdEMAMix, which maintains the same performance as AdEMAMix across both large and small batch-size settings while eliminating the need for two different momentum terms. The code for Simplified-AdEMAMix is available on the repository: https://github.com/DepenM/Simplified-AdEMAMix/.","sentences":["Recent advancements in deep learning optimization have introduced new algorithms, such as Schedule-Free optimizers, AdEMAMix, MARS and Lion which modify traditional momentum mechanisms.","In a separate line of work, theoretical acceleration of stochastic gradient descent (SGD) in noise-dominated regime has been achieved by decoupling the momentum coefficient from the current gradient's weight.","In this paper, we establish explicit connections between these two lines of work.","We substantiate our theoretical findings with preliminary experiments on a 150m language modeling task.","We find that AdEMAMix, which most closely resembles accelerated versions of stochastic gradient descent, exhibits superior performance.","Building on these insights, we introduce a modification to AdEMAMix, termed Simplified-AdEMAMix, which maintains the same performance as AdEMAMix across both large and small batch-size settings while eliminating the need for two different momentum terms.","The code for Simplified-AdEMAMix is available on the repository: https://github.com/DepenM/Simplified-AdEMAMix/."],"url":"http://arxiv.org/abs/2502.02431v1"}
{"created":"2025-02-04 15:53:30","title":"TransformDAS: Mapping \u03a6-OTDR Signals to Riemannian Manifold for Robust Classification","abstract":"Phase-sensitive optical time-domain reflectometry ({\\Phi}-OTDR) is a widely used distributed fiber optic sensing system in engineering. Machine learning algorithms for {\\Phi}-OTDR event classification require high volumes and quality of datasets; however, high-quality datasets are currently extremely scarce in the field, leading to a lack of robustness in models, which is manifested by higher false alarm rates in real-world scenarios. One promising approach to address this issue is to augment existing data using generative models combined with a small amount of real-world data. We explored mapping both {\\Phi}-OTDR features in a GAN-based generative pipeline and signal features in a Transformer classifier to hyperbolic space to seek more effective model generalization. The results indicate that state-of-the-art models exhibit stronger generalization performance and lower false alarm rates in real-world scenarios when trained on augmented datasets. TransformDAS, in particular, demonstrates the best classification performance, highlighting the benefits of Riemannian manifold mapping in {\\Phi}-OTDR data generation and model classification.","sentences":["Phase-sensitive optical time-domain reflectometry ({\\Phi}-OTDR) is a widely used distributed fiber optic sensing system in engineering.","Machine learning algorithms for {\\Phi}-OTDR event classification require high volumes and quality of datasets; however, high-quality datasets are currently extremely scarce in the field, leading to a lack of robustness in models, which is manifested by higher false alarm rates in real-world scenarios.","One promising approach to address this issue is to augment existing data using generative models combined with a small amount of real-world data.","We explored mapping both {\\Phi}-OTDR features in a GAN-based generative pipeline and signal features in a Transformer classifier to hyperbolic space to seek more effective model generalization.","The results indicate that state-of-the-art models exhibit stronger generalization performance and lower false alarm rates in real-world scenarios when trained on augmented datasets.","TransformDAS, in particular, demonstrates the best classification performance, highlighting the benefits of Riemannian manifold mapping in {\\Phi}-OTDR data generation and model classification."],"url":"http://arxiv.org/abs/2502.02428v1"}
{"created":"2025-02-04 15:44:15","title":"Pruning-aware Loss Functions for STOI-Optimized Pruned Recurrent Autoencoders for the Compression of the Stimulation Patterns of Cochlear Implants at Zero Delay","abstract":"Cochlear implants (CIs) are surgically implanted hearing devices, which allow to restore a sense of hearing in people suffering from profound hearing loss. Wireless streaming of audio from external devices to CI signal processors has become common place. Specialized compression based on the stimulation patterns of a CI by deep recurrent autoencoders can decrease the power consumption in such a wireless streaming application through bit-rate reduction at zero latency.   While previous research achieved considerable bit-rate reductions, model sizes were ignored, which can be of crucial importance in hearing-aids due to their limited computational resources. This work investigates maximizing objective speech intelligibility of the coded stimulation patterns of deep recurrent autoencoders while minimizing model size. For this purpose, a pruning-aware loss is proposed, which captures the impact of pruning during training. This training with a pruning-aware loss is compared to conventional magnitude-informed pruning and is found to yield considerable improvements in objective intelligibility, especially at higher pruning rates. After fine-tuning, little to no degradation of objective intelligibility is observed up to a pruning rate of about 55\\,\\%. The proposed pruning-aware loss yields substantial gains in objective speech intelligibility scores after pruning compared to the magnitude-informed baseline for pruning rates above 45\\,\\%.","sentences":["Cochlear implants (CIs) are surgically implanted hearing devices, which allow to restore a sense of hearing in people suffering from profound hearing loss.","Wireless streaming of audio from external devices to CI signal processors has become common place.","Specialized compression based on the stimulation patterns of a CI by deep recurrent autoencoders can decrease the power consumption in such a wireless streaming application through bit-rate reduction at zero latency.   ","While previous research achieved considerable bit-rate reductions, model sizes were ignored, which can be of crucial importance in hearing-aids due to their limited computational resources.","This work investigates maximizing objective speech intelligibility of the coded stimulation patterns of deep recurrent autoencoders while minimizing model size.","For this purpose, a pruning-aware loss is proposed, which captures the impact of pruning during training.","This training with a pruning-aware loss is compared to conventional magnitude-informed pruning and is found to yield considerable improvements in objective intelligibility, especially at higher pruning rates.","After fine-tuning, little to no degradation of objective intelligibility is observed up to a pruning rate of about 55\\,\\%.","The proposed pruning-aware loss yields substantial gains in objective speech intelligibility scores after pruning compared to the magnitude-informed baseline for pruning rates above 45\\,\\%."],"url":"http://arxiv.org/abs/2502.02424v1"}
{"created":"2025-02-04 15:42:03","title":"Activation-Informed Merging of Large Language Models","abstract":"Model merging, a method that combines the parameters and embeddings of multiple fine-tuned large language models (LLMs), offers a promising approach to enhance model performance across various tasks while maintaining computational efficiency. This paper introduces Activation-Informed Merging (AIM), a technique that integrates the information from the activation space of LLMs into the merging process to improve performance and robustness. AIM is designed as a flexible, complementary solution that is applicable to any existing merging method. It aims to preserve critical weights from the base model, drawing on principles from continual learning~(CL) and model compression. Utilizing a task-agnostic calibration set, AIM selectively prioritizes essential weights during merging. We empirically demonstrate that AIM significantly enhances the performance of merged models across multiple benchmarks. Our findings suggest that considering the activation-space information can provide substantial advancements in the model merging strategies for LLMs with up to 40\\% increase in benchmark performance.","sentences":["Model merging, a method that combines the parameters and embeddings of multiple fine-tuned large language models (LLMs), offers a promising approach to enhance model performance across various tasks while maintaining computational efficiency.","This paper introduces Activation-Informed Merging (AIM), a technique that integrates the information from the activation space of LLMs into the merging process to improve performance and robustness.","AIM is designed as a flexible, complementary solution that is applicable to any existing merging method.","It aims to preserve critical weights from the base model, drawing on principles from continual learning~(CL) and model compression.","Utilizing a task-agnostic calibration set, AIM selectively prioritizes essential weights during merging.","We empirically demonstrate that AIM significantly enhances the performance of merged models across multiple benchmarks.","Our findings suggest that considering the activation-space information can provide substantial advancements in the model merging strategies for LLMs with up to 40\\% increase in benchmark performance."],"url":"http://arxiv.org/abs/2502.02421v1"}
{"created":"2025-02-04 15:38:14","title":"CVKAN: Complex-Valued Kolmogorov-Arnold Networks","abstract":"In this work we propose CKAN, a complex-valued KAN, to join the intrinsic interpretability of KANs and the advantages of Complex-Valued Neural Networks (CVNNs). We show how to transfer a KAN and the necessary associated mechanisms into the complex domain. To confirm that CKAN meets expectations we conduct experiments on symbolic complex-valued function fitting and physically meaningful formulae as well as on a more realistic dataset from knot theory. Our proposed CKAN is more stable and performs on par or better than real-valued KANs while requiring less parameters and a shallower network architecture, making it more explainable.","sentences":["In this work we propose CKAN, a complex-valued KAN, to join the intrinsic interpretability of KANs and the advantages of Complex-Valued Neural Networks (CVNNs).","We show how to transfer a KAN and the necessary associated mechanisms into the complex domain.","To confirm that CKAN meets expectations we conduct experiments on symbolic complex-valued function fitting and physically meaningful formulae as well as on a more realistic dataset from knot theory.","Our proposed CKAN is more stable and performs on par or better than real-valued KANs while requiring less parameters and a shallower network architecture, making it more explainable."],"url":"http://arxiv.org/abs/2502.02417v1"}
{"created":"2025-02-04 15:35:25","title":"Towards Fast Graph Generation via Autoregressive Noisy Filtration Modeling","abstract":"Graph generative models often face a critical trade-off between learning complex distributions and achieving fast generation speed. We introduce Autoregressive Noisy Filtration Modeling (ANFM), a novel approach that addresses both challenges. ANFM leverages filtration, a concept from topological data analysis, to transform graphs into short sequences of monotonically increasing subgraphs. This formulation extends the sequence families used in previous autoregressive models. To learn from these sequences, we propose a novel autoregressive graph mixer model. Our experiments suggest that exposure bias might represent a substantial hurdle in autoregressive graph generation and we introduce two mitigation strategies to address it: noise augmentation and a reinforcement learning approach. Incorporating these techniques leads to substantial performance gains, making ANFM competitive with state-of-the-art diffusion models across diverse synthetic and real-world datasets. Notably, ANFM produces remarkably short sequences, achieving a 100-fold speedup in generation time compared to diffusion models. This work marks a significant step toward high-throughput graph generation.","sentences":["Graph generative models often face a critical trade-off between learning complex distributions and achieving fast generation speed.","We introduce Autoregressive Noisy Filtration Modeling (ANFM), a novel approach that addresses both challenges.","ANFM leverages filtration, a concept from topological data analysis, to transform graphs into short sequences of monotonically increasing subgraphs.","This formulation extends the sequence families used in previous autoregressive models.","To learn from these sequences, we propose a novel autoregressive graph mixer model.","Our experiments suggest that exposure bias might represent a substantial hurdle in autoregressive graph generation and we introduce two mitigation strategies to address it: noise augmentation and a reinforcement learning approach.","Incorporating these techniques leads to substantial performance gains, making ANFM competitive with state-of-the-art diffusion models across diverse synthetic and real-world datasets.","Notably, ANFM produces remarkably short sequences, achieving a 100-fold speedup in generation time compared to diffusion models.","This work marks a significant step toward high-throughput graph generation."],"url":"http://arxiv.org/abs/2502.02415v1"}
{"created":"2025-02-04 15:33:50","title":"Transolver++: An Accurate Neural Solver for PDEs on Million-Scale Geometries","abstract":"Although deep models have been widely explored in solving partial differential equations (PDEs), previous works are primarily limited to data only with up to tens of thousands of mesh points, far from the million-point scale required by industrial simulations that involve complex geometries. In the spirit of advancing neural PDE solvers to real industrial applications, we present Transolver++, a highly parallel and efficient neural solver that can accurately solve PDEs on million-scale geometries. Building upon previous advancements in solving PDEs by learning physical states via Transolver, Transolver++ is further equipped with an extremely optimized parallelism framework and a local adaptive mechanism to efficiently capture eidetic physical states from massive mesh points, successfully tackling the thorny challenges in computation and physics learning when scaling up input mesh size. Transolver++ increases the single-GPU input capacity to million-scale points for the first time and is capable of continuously scaling input size in linear complexity by increasing GPUs. Experimentally, Transolver++ yields 13% relative promotion across six standard PDE benchmarks and achieves over 20% performance gain in million-scale high-fidelity industrial simulations, whose sizes are 100$\\times$ larger than previous benchmarks, covering car and 3D aircraft designs.","sentences":["Although deep models have been widely explored in solving partial differential equations (PDEs), previous works are primarily limited to data only with up to tens of thousands of mesh points, far from the million-point scale required by industrial simulations that involve complex geometries.","In the spirit of advancing neural PDE solvers to real industrial applications, we present Transolver++, a highly parallel and efficient neural solver that can accurately solve PDEs on million-scale geometries.","Building upon previous advancements in solving PDEs by learning physical states via Transolver, Transolver++ is further equipped with an extremely optimized parallelism framework and a local adaptive mechanism to efficiently capture eidetic physical states from massive mesh points, successfully tackling the thorny challenges in computation and physics learning when scaling up input mesh size.","Transolver++ increases the single-GPU input capacity to million-scale points for the first time and is capable of continuously scaling input size in linear complexity by increasing GPUs.","Experimentally, Transolver++ yields 13% relative promotion across six standard PDE benchmarks and achieves over 20% performance gain in million-scale high-fidelity industrial simulations, whose sizes are 100$\\times$ larger than previous benchmarks, covering car and 3D aircraft designs."],"url":"http://arxiv.org/abs/2502.02414v1"}
{"created":"2025-02-04 15:32:34","title":"AI-Powered, But Power-Hungry? Energy Efficiency of LLM-Generated Code","abstract":"Large language models (LLMs) are used in software development to assist in various tasks, e.g., code generation and code completion, but empirical evaluations of the quality of the results produced by these models focus on correctness and ignore other relevant aspects, such as their performance and energy efficiency. Studying the performance of LLM-produced programs is essential to understand how well LLMs can support the construction of performance- and energy-critical software, such as operating systems, servers, and mobile applications. This paper presents the first study analyzing the energy efficiency and performance of LLM-generated code for three programming languages Python, Java, and C++, on two platforms, a Mac and a PC, leveraging three frontier LLMs, Github Copilot, GPT-4o, and the recently-released OpenAI o1-mini, and targeting ``hard'' programming problems from LeetCode. Our results show that the models are much more successful in generating Python and Java than C++ code.","sentences":["Large language models (LLMs) are used in software development to assist in various tasks, e.g., code generation and code completion, but empirical evaluations of the quality of the results produced by these models focus on correctness and ignore other relevant aspects, such as their performance and energy efficiency.","Studying the performance of LLM-produced programs is essential to understand how well LLMs can support the construction of performance- and energy-critical software, such as operating systems, servers, and mobile applications.","This paper presents the first study analyzing the energy efficiency and performance of LLM-generated code for three programming languages Python, Java, and C++, on two platforms, a Mac and a PC, leveraging three frontier LLMs, Github Copilot, GPT-4o, and the recently-released OpenAI o1-mini, and targeting ``hard'' programming problems from LeetCode.","Our results show that the models are much more successful in generating Python and Java than C++ code."],"url":"http://arxiv.org/abs/2502.02412v1"}
{"created":"2025-02-04 15:29:00","title":"Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting","abstract":"Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential. The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD). However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset. In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows. We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees. Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models. Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees.","sentences":["Many forms of sensitive data, such as web traffic, mobility data, or hospital occupancy, are inherently sequential.","The standard method for training machine learning models while ensuring privacy for units of sensitive information, such as individual hospital visits, is differentially private stochastic gradient descent (DP-SGD).","However, we observe in this work that the formal guarantees of DP-SGD are incompatible with timeseries-specific tasks like forecasting, since they rely on the privacy amplification attained by training on small, unstructured batches sampled from an unstructured dataset.","In contrast, batches for forecasting are generated by (1) sampling sequentially structured time series from a dataset, (2) sampling contiguous subsequences from these series, and (3) partitioning them into context and ground-truth forecast windows.","We theoretically analyze the privacy amplification attained by this structured subsampling to enable the training of forecasting models with sound and tight event- and user-level privacy guarantees.","Towards more private models, we additionally prove how data augmentation amplifies privacy in self-supervised training of sequence models.","Our empirical evaluation demonstrates that amplification by structured subsampling enables the training of forecasting models with strong formal privacy guarantees."],"url":"http://arxiv.org/abs/2502.02410v1"}
{"created":"2025-02-04 15:26:57","title":"Extending SEEDS to a Supervoxel Algorithm for Medical Image Analysis","abstract":"In this work, we extend the SEEDS superpixel algorithm from 2D images to 3D volumes, resulting in 3D SEEDS, a faster, better, and open-source supervoxel algorithm for medical image analysis. We compare 3D SEEDS with the widely used supervoxel algorithm SLIC on 13 segmentation tasks across 10 organs. 3D SEEDS accelerates supervoxel generation by a factor of 10, improves the achievable Dice score by +6.5%, and reduces the under-segmentation error by -0.16%. The code is available at https://github.com/Zch0414/3d_seeds","sentences":["In this work, we extend the SEEDS superpixel algorithm from 2D images to 3D volumes, resulting in 3D SEEDS, a faster, better, and open-source supervoxel algorithm for medical image analysis.","We compare 3D SEEDS with the widely used supervoxel algorithm SLIC on 13 segmentation tasks across 10 organs.","3D SEEDS accelerates supervoxel generation by a factor of 10, improves the achievable Dice score by +6.5%, and reduces the under-segmentation error by -0.16%.","The code is available at https://github.com/Zch0414/3d_seeds"],"url":"http://arxiv.org/abs/2502.02409v1"}
{"created":"2025-02-04 15:25:47","title":"Avoiding spurious sharpness minimization broadens applicability of SAM","abstract":"Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks. However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget. We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself. We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation. Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements. Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale). On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs).","sentences":["Curvature regularization techniques like Sharpness Aware Minimization (SAM) have shown great promise in improving generalization on vision tasks.","However, we find that SAM performs poorly in domains like natural language processing (NLP), often degrading performance -- even with twice the compute budget.","We investigate the discrepancy across domains and find that in the NLP setting, SAM is dominated by regularization of the logit statistics -- instead of improving the geometry of the function itself.","We use this observation to develop an alternative algorithm we call Functional-SAM, which regularizes curvature only through modification of the statistics of the overall function implemented by the neural network, and avoids spurious minimization through logit manipulation.","Furthermore, we argue that preconditioning the SAM perturbation also prevents spurious minimization, and when combined with Functional-SAM, it gives further improvements.","Our proposed algorithms show improved performance over AdamW and SAM baselines when trained for an equal number of steps, in both fixed-length and Chinchilla-style training settings, at various model scales (including billion-parameter scale).","On the whole, our work highlights the importance of more precise characterizations of sharpness in broadening the applicability of curvature regularization to large language models (LLMs)."],"url":"http://arxiv.org/abs/2502.02407v1"}
{"created":"2025-02-04 15:24:16","title":"LV-XAttn: Distributed Cross-Attention for Long Visual Inputs in Multimodal Large Language Models","abstract":"Cross-attention is commonly adopted in multimodal large language models (MLLMs) for integrating visual information into the language backbone. However, in applications with large visual inputs, such as video understanding, processing a large number of visual tokens in cross-attention layers leads to high memory demands and often necessitates distributed computation across multiple GPUs. Existing distributed attention mechanisms face significant communication overheads, making cross-attention layers a critical bottleneck for efficient training and inference of MLLMs. To address this, we propose LV-XAttn, a distributed, exact cross-attention mechanism with minimal communication overhead. We observe that in applications involving large visual inputs the size of the query block is typically much smaller than that of the key-value blocks. Thus, in LV-XAttn we keep the large key-value blocks locally on each GPU and exchange smaller query blocks across GPUs. We also introduce an efficient activation recomputation technique enabling support for longer visual context. We theoretically analyze the communication benefits of LV-XAttn and show that it can achieve speedups for a wide range of models. Our evaluations with mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to 5.58$\\times$ end-to-end speedup compared to existing approaches.","sentences":["Cross-attention is commonly adopted in multimodal large language models (MLLMs) for integrating visual information into the language backbone.","However, in applications with large visual inputs, such as video understanding, processing a large number of visual tokens in cross-attention layers leads to high memory demands and often necessitates distributed computation across multiple GPUs.","Existing distributed attention mechanisms face significant communication overheads, making cross-attention layers a critical bottleneck for efficient training and inference of MLLMs.","To address this, we propose LV-XAttn, a distributed, exact cross-attention mechanism with minimal communication overhead.","We observe that in applications involving large visual inputs the size of the query block is typically much smaller than that of the key-value blocks.","Thus, in LV-XAttn we keep the large key-value blocks locally on each GPU and exchange smaller query blocks across GPUs.","We also introduce an efficient activation recomputation technique enabling support for longer visual context.","We theoretically analyze the communication benefits of LV-XAttn and show that it can achieve speedups for a wide range of models.","Our evaluations with mPLUG-Owl3 and OpenFlamingo models find that LV-XAttn achieves up to 5.58$\\times$ end-to-end speedup compared to existing approaches."],"url":"http://arxiv.org/abs/2502.02406v1"}
{"created":"2025-02-04 15:23:43","title":"FPGA Innovation Research in the Netherlands: Present Landscape and Future Outlook","abstract":"FPGAs have transformed digital design by enabling versatile and customizable solutions that balance performance and power efficiency, yielding them essential for today's diverse computing challenges. Research in the Netherlands, both in academia and industry, plays a major role in developing new innovative FPGA solutions. This survey presents the current landscape of FPGA innovation research in the Netherlands by delving into ongoing projects, advancements, and breakthroughs in the field. Focusing on recent research outcome (within the past 5 years), we have identified five key research areas: a) FPGA architecture, b) FPGA robustness, c) data center infrastructure and high-performance computing, d) programming models and tools, and e) applications. This survey provides in-depth insights beyond a mere snapshot of the current innovation research landscape by highlighting future research directions within each key area; these insights can serve as a foundational resource to inform potential national-level investments in FPGA technology.","sentences":["FPGAs have transformed digital design by enabling versatile and customizable solutions that balance performance and power efficiency, yielding them essential for today's diverse computing challenges.","Research in the Netherlands, both in academia and industry, plays a major role in developing new innovative FPGA solutions.","This survey presents the current landscape of FPGA innovation research in the Netherlands by delving into ongoing projects, advancements, and breakthroughs in the field.","Focusing on recent research outcome (within the past 5 years), we have identified five key research areas: a) FPGA architecture, b) FPGA robustness, c) data center infrastructure and high-performance computing, d) programming models and tools, and e) applications.","This survey provides in-depth insights beyond a mere snapshot of the current innovation research landscape by highlighting future research directions within each key area; these insights can serve as a foundational resource to inform potential national-level investments in FPGA technology."],"url":"http://arxiv.org/abs/2502.02404v1"}
{"created":"2025-02-04 15:15:22","title":"An inherently parallel H2-ULV factorization for solving dense linear systems on GPUs","abstract":"Hierarchical low-rank approximation of dense matrices can reduce the complexity of their factorization from O(N^3) to O(N). However, the complex structure of such hierarchical matrices makes them difficult to parallelize. The block size and ranks can vary between the sub-blocks, which creates load imbalance. The dependency between the sub-blocks during factorization results in serialization. Since many sub-blocks are low-rank, their small computational load exposes the overhead of runtime systems. The combination of these factors makes it challenging to implement these methods on GPUs. In this work, we show that dense matrices can be factorized with linear complexity, while extracting the potential parallelism of GPUs. This is made possible through the H2-ULV factorization, which removes the dependency on trailing sub-matrices.","sentences":["Hierarchical low-rank approximation of dense matrices can reduce the complexity of their factorization from O(N^3) to O(N).","However, the complex structure of such hierarchical matrices makes them difficult to parallelize.","The block size and ranks can vary between the sub-blocks, which creates load imbalance.","The dependency between the sub-blocks during factorization results in serialization.","Since many sub-blocks are low-rank, their small computational load exposes the overhead of runtime systems.","The combination of these factors makes it challenging to implement these methods on GPUs.","In this work, we show that dense matrices can be factorized with linear complexity, while extracting the potential parallelism of GPUs.","This is made possible through the H2-ULV factorization, which removes the dependency on trailing sub-matrices."],"url":"http://arxiv.org/abs/2502.02395v1"}
{"created":"2025-02-04 15:14:01","title":"Lower Bounds for Chain-of-Thought Reasoning in Hard-Attention Transformers","abstract":"Chain-of-thought reasoning and scratchpads have emerged as critical tools for enhancing the computational capabilities of transformers. While theoretical results show that polynomial-length scratchpads can extend transformers' expressivity from $TC^0$ to $PTIME$, their required length remains poorly understood. Empirical evidence even suggests that transformers need scratchpads even for many problems in $TC^0$, such as Parity or Multiplication, challenging optimistic bounds derived from circuit complexity. In this work, we initiate the study of systematic lower bounds for the number of CoT steps across different algorithmic problems, in the hard-attention regime. We study a variety of algorithmic problems, and provide bounds that are tight up to logarithmic factors. Overall, these results contribute to emerging understanding of the power and limitations of chain-of-thought reasoning.","sentences":["Chain-of-thought reasoning and scratchpads have emerged as critical tools for enhancing the computational capabilities of transformers.","While theoretical results show that polynomial-length scratchpads can extend transformers' expressivity from $TC^0$ to $PTIME$, their required length remains poorly understood.","Empirical evidence even suggests that transformers need scratchpads even for many problems in $TC^0$, such as Parity or Multiplication, challenging optimistic bounds derived from circuit complexity.","In this work, we initiate the study of systematic lower bounds for the number of CoT steps across different algorithmic problems, in the hard-attention regime.","We study a variety of algorithmic problems, and provide bounds that are tight up to logarithmic factors.","Overall, these results contribute to emerging understanding of the power and limitations of chain-of-thought reasoning."],"url":"http://arxiv.org/abs/2502.02393v1"}
{"created":"2025-02-04 15:13:40","title":"FewTopNER: Integrating Few-Shot Learning with Topic Modeling and Named Entity Recognition in a Multilingual Framework","abstract":"We introduce FewTopNER, a novel framework that integrates few-shot named entity recognition (NER) with topic-aware contextual modeling to address the challenges of cross-lingual and low-resource scenarios. FewTopNER leverages a shared multilingual encoder based on XLM-RoBERTa, augmented with language-specific calibration mechanisms, to generate robust contextual embeddings. The architecture comprises a prototype-based entity recognition branch, employing BiLSTM and Conditional Random Fields for sequence labeling, and a topic modeling branch that extracts document-level semantic features through hybrid probabilistic and neural methods. A cross-task bridge facilitates dynamic bidirectional attention and feature fusion between entity and topic representations, thereby enhancing entity disambiguation by incorporating global semantic context. Empirical evaluations on multilingual benchmarks across English, French, Spanish, German, and Italian demonstrate that FewTopNER significantly outperforms existing state-of-the-art few-shot NER models. In particular, the framework achieves improvements of 2.5-4.0 percentage points in F1 score and exhibits enhanced topic coherence, as measured by normalized pointwise mutual information. Ablation studies further confirm the critical contributions of the shared encoder and cross-task integration mechanisms to the overall performance. These results underscore the efficacy of incorporating topic-aware context into few-shot NER and highlight the potential of FewTopNER for robust cross-lingual applications in low-resource settings.","sentences":["We introduce FewTopNER, a novel framework that integrates few-shot named entity recognition (NER) with topic-aware contextual modeling to address the challenges of cross-lingual and low-resource scenarios.","FewTopNER leverages a shared multilingual encoder based on XLM-RoBERTa, augmented with language-specific calibration mechanisms, to generate robust contextual embeddings.","The architecture comprises a prototype-based entity recognition branch, employing BiLSTM and Conditional Random Fields for sequence labeling, and a topic modeling branch that extracts document-level semantic features through hybrid probabilistic and neural methods.","A cross-task bridge facilitates dynamic bidirectional attention and feature fusion between entity and topic representations, thereby enhancing entity disambiguation by incorporating global semantic context.","Empirical evaluations on multilingual benchmarks across English, French, Spanish, German, and Italian demonstrate that FewTopNER significantly outperforms existing state-of-the-art few-shot NER models.","In particular, the framework achieves improvements of 2.5-4.0 percentage points in F1 score and exhibits enhanced topic coherence, as measured by normalized pointwise mutual information.","Ablation studies further confirm the critical contributions of the shared encoder and cross-task integration mechanisms to the overall performance.","These results underscore the efficacy of incorporating topic-aware context into few-shot NER and highlight the potential of FewTopNER for robust cross-lingual applications in low-resource settings."],"url":"http://arxiv.org/abs/2502.02391v1"}
{"created":"2025-02-04 15:10:33","title":"CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning","abstract":"Research on LLM technologies is rapidly emerging, with most of them employing a 'fast thinking' approach to inference. Most LLMs generate the final result based solely on a single query and LLM's reasoning capabilities. However, with the advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing attention because its process is closer to the human thought process. Inspired by the human ability to constantly associate and replenish knowledge during thinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework, which introduces an innovative synergy between the Monte Carlo Tree Search (MCTS) algorithm and a dynamic mechanism for integrating new key information, termed 'associative memory'. By combining the structured exploration capabilities of MCTS with the adaptive learning capacity of associative memory, CoAT significantly expands the LLM search space, enabling our framework to explore diverse reasoning pathways and dynamically update its knowledge base in real-time. This allows the framework to not only revisit and refine earlier inferences but also adaptively incorporate evolving information, ensuring that the final output is both accurate and comprehensive. To validate the effectiveness of our framework, we conducted extensive experiments across a range of generative and reasoning tasks. These experiments demonstrated that our framework outperforms conventional inference processes on accuracy, coherence, and diversity. The framework's ability to iteratively expand its search space while retaining contextually relevant information results.","sentences":["Research on LLM technologies is rapidly emerging, with most of them employing a 'fast thinking' approach to inference.","Most LLMs generate the final result based solely on a single query and LLM's reasoning capabilities.","However, with the advent of OpenAI-o1, 'slow thinking' techniques have garnered increasing attention because its process is closer to the human thought process.","Inspired by the human ability to constantly associate and replenish knowledge during thinking, we developed the novel Chain-of-Associated-Thoughts (CoAT) framework, which introduces an innovative synergy between the Monte Carlo Tree Search (MCTS) algorithm and a dynamic mechanism for integrating new key information, termed 'associative memory'.","By combining the structured exploration capabilities of MCTS with the adaptive learning capacity of associative memory, CoAT significantly expands the LLM search space, enabling our framework to explore diverse reasoning pathways and dynamically update its knowledge base in real-time.","This allows the framework to not only revisit and refine earlier inferences but also adaptively incorporate evolving information, ensuring that the final output is both accurate and comprehensive.","To validate the effectiveness of our framework, we conducted extensive experiments across a range of generative and reasoning tasks.","These experiments demonstrated that our framework outperforms conventional inference processes on accuracy, coherence, and diversity.","The framework's ability to iteratively expand its search space while retaining contextually relevant information results."],"url":"http://arxiv.org/abs/2502.02390v1"}
