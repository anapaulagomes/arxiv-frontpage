{"created":"2024-11-27 18:59:59","title":"Textured Gaussians for Enhanced 3D Scene Appearance Modeling","abstract":"3D Gaussian Splatting (3DGS) has recently emerged as a state-of-the-art 3D reconstruction and rendering technique due to its high-quality results and fast training and rendering time. However, pixels covered by the same Gaussian are always shaded in the same color up to a Gaussian falloff scaling factor. Furthermore, the finest geometric detail any individual Gaussian can represent is a simple ellipsoid. These properties of 3DGS greatly limit the expressivity of individual Gaussian primitives. To address these issues, we draw inspiration from texture and alpha mapping in traditional graphics and integrate it with 3DGS. Specifically, we propose a new generalized Gaussian appearance representation that augments each Gaussian with alpha~(A), RGB, or RGBA texture maps to model spatially varying color and opacity across the extent of each Gaussian. As such, each Gaussian can represent a richer set of texture patterns and geometric structures, instead of just a single color and ellipsoid as in naive Gaussian Splatting. Surprisingly, we found that the expressivity of Gaussians can be greatly improved by using alpha-only texture maps, and further augmenting Gaussians with RGB texture maps achieves the highest expressivity. We validate our method on a wide variety of standard benchmark datasets and our own custom captures at both the object and scene levels. We demonstrate image quality improvements over existing methods while using a similar or lower number of Gaussians.","sentences":["3D Gaussian Splatting (3DGS) has recently emerged as a state-of-the-art 3D reconstruction and rendering technique due to its high-quality results and fast training and rendering time.","However, pixels covered by the same Gaussian are always shaded in the same color up to a Gaussian falloff scaling factor.","Furthermore, the finest geometric detail any individual Gaussian can represent is a simple ellipsoid.","These properties of 3DGS greatly limit the expressivity of individual Gaussian primitives.","To address these issues, we draw inspiration from texture and alpha mapping in traditional graphics and integrate it with 3DGS.","Specifically, we propose a new generalized Gaussian appearance representation that augments each Gaussian with alpha~(A), RGB, or RGBA texture maps to model spatially varying color and opacity across the extent of each Gaussian.","As such, each Gaussian can represent a richer set of texture patterns and geometric structures, instead of just a single color and ellipsoid as in naive Gaussian Splatting.","Surprisingly, we found that the expressivity of Gaussians can be greatly improved by using alpha-only texture maps, and further augmenting Gaussians with RGB texture maps achieves the highest expressivity.","We validate our method on a wide variety of standard benchmark datasets and our own custom captures at both the object and scene levels.","We demonstrate image quality improvements over existing methods while using a similar or lower number of Gaussians."],"url":"http://arxiv.org/abs/2411.18625v1"}
{"created":"2024-11-27 18:59:54","title":"GeneMAN: Generalizable Single-Image 3D Human Reconstruction from Multi-Source Human Data","abstract":"Given a single in-the-wild human photo, it remains a challenging task to reconstruct a high-fidelity 3D human model. Existing methods face difficulties including a) the varying body proportions captured by in-the-wild human images; b) diverse personal belongings within the shot; and c) ambiguities in human postures and inconsistency in human textures. In addition, the scarcity of high-quality human data intensifies the challenge. To address these problems, we propose a Generalizable image-to-3D huMAN reconstruction framework, dubbed GeneMAN, building upon a comprehensive multi-source collection of high-quality human data, including 3D scans, multi-view videos, single photos, and our generated synthetic human data. GeneMAN encompasses three key modules. 1) Without relying on parametric human models (e.g., SMPL), GeneMAN first trains a human-specific text-to-image diffusion model and a view-conditioned diffusion model, serving as GeneMAN 2D human prior and 3D human prior for reconstruction, respectively. 2) With the help of the pretrained human prior models, the Geometry Initialization-&-Sculpting pipeline is leveraged to recover high-quality 3D human geometry given a single image. 3) To achieve high-fidelity 3D human textures, GeneMAN employs the Multi-Space Texture Refinement pipeline, consecutively refining textures in the latent and the pixel spaces. Extensive experimental results demonstrate that GeneMAN could generate high-quality 3D human models from a single image input, outperforming prior state-of-the-art methods. Notably, GeneMAN could reveal much better generalizability in dealing with in-the-wild images, often yielding high-quality 3D human models in natural poses with common items, regardless of the body proportions in the input images.","sentences":["Given a single in-the-wild human photo, it remains a challenging task to reconstruct a high-fidelity 3D human model.","Existing methods face difficulties including a) the varying body proportions captured by in-the-wild human images; b) diverse personal belongings within the shot; and c) ambiguities in human postures and inconsistency in human textures.","In addition, the scarcity of high-quality human data intensifies the challenge.","To address these problems, we propose a Generalizable image-to-3D huMAN reconstruction framework, dubbed GeneMAN, building upon a comprehensive multi-source collection of high-quality human data, including 3D scans, multi-view videos, single photos, and our generated synthetic human data.","GeneMAN encompasses three key modules.","1) Without relying on parametric human models (e.g., SMPL), GeneMAN first trains a human-specific text-to-image diffusion model and a view-conditioned diffusion model, serving as GeneMAN 2D human prior and 3D human prior for reconstruction, respectively.","2) With the help of the pretrained human prior models, the Geometry Initialization-&-Sculpting pipeline is leveraged to recover high-quality 3D human geometry given a single image.","3) To achieve high-fidelity 3D human textures, GeneMAN employs the Multi-Space Texture Refinement pipeline, consecutively refining textures in the latent and the pixel spaces.","Extensive experimental results demonstrate that GeneMAN could generate high-quality 3D human models from a single image input, outperforming prior state-of-the-art methods.","Notably, GeneMAN could reveal much better generalizability in dealing with in-the-wild images, often yielding high-quality 3D human models in natural poses with common items, regardless of the body proportions in the input images."],"url":"http://arxiv.org/abs/2411.18624v1"}
{"created":"2024-11-27 18:59:52","title":"Lift3D Foundation Policy: Lifting 2D Large-Scale Pretrained Models for Robust 3D Robotic Manipulation","abstract":"3D geometric information is essential for manipulation tasks, as robots need to perceive the 3D environment, reason about spatial relationships, and interact with intricate spatial configurations. Recent research has increasingly focused on the explicit extraction of 3D features, while still facing challenges such as the lack of large-scale robotic 3D data and the potential loss of spatial geometry. To address these limitations, we propose the Lift3D framework, which progressively enhances 2D foundation models with implicit and explicit 3D robotic representations to construct a robust 3D manipulation policy. Specifically, we first design a task-aware masked autoencoder that masks task-relevant affordance patches and reconstructs depth information, enhancing the 2D foundation model's implicit 3D robotic representation. After self-supervised fine-tuning, we introduce a 2D model-lifting strategy that establishes a positional mapping between the input 3D points and the positional embeddings of the 2D model. Based on the mapping, Lift3D utilizes the 2D foundation model to directly encode point cloud data, leveraging large-scale pretrained knowledge to construct explicit 3D robotic representations while minimizing spatial information loss. In experiments, Lift3D consistently outperforms previous state-of-the-art methods across several simulation benchmarks and real-world scenarios.","sentences":["3D geometric information is essential for manipulation tasks, as robots need to perceive the 3D environment, reason about spatial relationships, and interact with intricate spatial configurations.","Recent research has increasingly focused on the explicit extraction of 3D features, while still facing challenges such as the lack of large-scale robotic 3D data and the potential loss of spatial geometry.","To address these limitations, we propose the Lift3D framework, which progressively enhances 2D foundation models with implicit and explicit 3D robotic representations to construct a robust 3D manipulation policy.","Specifically, we first design a task-aware masked autoencoder that masks task-relevant affordance patches and reconstructs depth information, enhancing the 2D foundation model's implicit 3D robotic representation.","After self-supervised fine-tuning, we introduce a 2D model-lifting strategy that establishes a positional mapping between the input 3D points and the positional embeddings of the 2D model.","Based on the mapping, Lift3D utilizes the 2D foundation model to directly encode point cloud data, leveraging large-scale pretrained knowledge to construct explicit 3D robotic representations while minimizing spatial information loss.","In experiments, Lift3D consistently outperforms previous state-of-the-art methods across several simulation benchmarks and real-world scenarios."],"url":"http://arxiv.org/abs/2411.18623v1"}
{"created":"2024-11-27 18:59:50","title":"Leveraging Semi-Supervised Learning to Enhance Data Mining for Image Classification under Limited Labeled Data","abstract":"In the 21st-century information age, with the development of big data technology, effectively extracting valuable information from massive data has become a key issue. Traditional data mining methods are inadequate when faced with large-scale, high-dimensional and complex data. Especially when labeled data is scarce, their performance is greatly limited. This study optimizes data mining algorithms by introducing semi-supervised learning methods, aiming to improve the algorithm's ability to utilize unlabeled data, thereby achieving more accurate data analysis and pattern recognition under limited labeled data conditions. Specifically, we adopt a self-training method and combine it with a convolutional neural network (CNN) for image feature extraction and classification, and continuously improve the model prediction performance through an iterative process. The experimental results demonstrate that the proposed method significantly outperforms traditional machine learning techniques such as Support Vector Machine (SVM), XGBoost, and Multi-Layer Perceptron (MLP) on the CIFAR-10 image classification dataset. Notable improvements were observed in key performance metrics, including accuracy, recall, and F1 score. Furthermore, the robustness and noise-resistance capabilities of the semi-supervised CNN model were validated through experiments under varying noise levels, confirming its practical applicability in real-world scenarios.","sentences":["In the 21st-century information age, with the development of big data technology, effectively extracting valuable information from massive data has become a key issue.","Traditional data mining methods are inadequate when faced with large-scale, high-dimensional and complex data.","Especially when labeled data is scarce, their performance is greatly limited.","This study optimizes data mining algorithms by introducing semi-supervised learning methods, aiming to improve the algorithm's ability to utilize unlabeled data, thereby achieving more accurate data analysis and pattern recognition under limited labeled data conditions.","Specifically, we adopt a self-training method and combine it with a convolutional neural network (CNN) for image feature extraction and classification, and continuously improve the model prediction performance through an iterative process.","The experimental results demonstrate that the proposed method significantly outperforms traditional machine learning techniques such as Support Vector Machine (SVM), XGBoost, and Multi-Layer Perceptron (MLP) on the CIFAR-10 image classification dataset.","Notable improvements were observed in key performance metrics, including accuracy, recall, and F1 score.","Furthermore, the robustness and noise-resistance capabilities of the semi-supervised CNN model were validated through experiments under varying noise levels, confirming its practical applicability in real-world scenarios."],"url":"http://arxiv.org/abs/2411.18622v1"}
{"created":"2024-11-27 18:59:26","title":"Cross-modal Information Flow in Multimodal Large Language Models","abstract":"The recent advancements in auto-regressive multimodal large language models (MLLMs) have demonstrated promising progress for vision-language tasks. While there exists a variety of studies investigating the processing of linguistic information within large language models, little is currently known about the inner working mechanism of MLLMs and how linguistic and visual information interact within these models. In this study, we aim to fill this gap by examining the information flow between different modalities -- language and vision -- in MLLMs, focusing on visual question answering. Specifically, given an image-question pair as input, we investigate where in the model and how the visual and linguistic information are combined to generate the final prediction. Conducting experiments with a series of models from the LLaVA series, we find that there are two distinct stages in the process of integration of the two modalities. In the lower layers, the model first transfers the more general visual features of the whole image into the representations of (linguistic) question tokens. In the middle layers, it once again transfers visual information about specific objects relevant to the question to the respective token positions of the question. Finally, in the higher layers, the resulting multimodal representation is propagated to the last position of the input sequence for the final prediction. Overall, our findings provide a new and comprehensive perspective on the spatial and functional aspects of image and language processing in the MLLMs, thereby facilitating future research into multimodal information localization and editing.","sentences":["The recent advancements in auto-regressive multimodal large language models (MLLMs) have demonstrated promising progress for vision-language tasks.","While there exists a variety of studies investigating the processing of linguistic information within large language models, little is currently known about the inner working mechanism of MLLMs and how linguistic and visual information interact within these models.","In this study, we aim to fill this gap by examining the information flow between different modalities -- language and vision -- in MLLMs, focusing on visual question answering.","Specifically, given an image-question pair as input, we investigate where in the model and how the visual and linguistic information are combined to generate the final prediction.","Conducting experiments with a series of models from the LLaVA series, we find that there are two distinct stages in the process of integration of the two modalities.","In the lower layers, the model first transfers the more general visual features of the whole image into the representations of (linguistic) question tokens.","In the middle layers, it once again transfers visual information about specific objects relevant to the question to the respective token positions of the question.","Finally, in the higher layers, the resulting multimodal representation is propagated to the last position of the input sequence for the final prediction.","Overall, our findings provide a new and comprehensive perspective on the spatial and functional aspects of image and language processing in the MLLMs, thereby facilitating future research into multimodal information localization and editing."],"url":"http://arxiv.org/abs/2411.18620v1"}
{"created":"2024-11-27 18:59:04","title":"Online versus Offline Adversaries in Property Testing","abstract":"We study property testing with incomplete or noisy inputs. The models we consider allow for adversarial manipulation of the input, but differ in whether the manipulation can be done only offline, i.e., before the execution of the algorithm, or {\\em online}, i.e., as the algorithm runs. The manipulations by an adversary can come in the form of erasures or corruptions. We compare the query complexity and the randomness complexity of property testing in the offline and online models. Kalemaj, Raskhodnikova, and Varma (Theory Comput.`23) provide properties that can be tested with a small number of queries with offline erasures, but cannot be tested at all with online erasures. We demonstrate that the two models are incomparable in terms of query complexity: we construct properties that can be tested with a constant number of queries in the online corruption model, but require querying a significant fraction of the input in the offline erasure model. We also construct properties that exhibit a strong separation between the randomness complexity of testing in the presence of offline and online adversaries: testing these properties in the online model requires exponentially more random bits than in the offline model, even when they are tested with nearly the same number of queries in both models. Our randomness separation relies on a novel reduction from randomness-efficient testers in the adversarial online model to query-efficient testers in the standard model.","sentences":["We study property testing with incomplete or noisy inputs.","The models we consider allow for adversarial manipulation of the input, but differ in whether the manipulation can be done only offline, i.e., before the execution of the algorithm, or {\\em online}, i.e., as the algorithm runs.","The manipulations by an adversary can come in the form of erasures or corruptions.","We compare the query complexity and the randomness complexity of property testing in the offline and online models.","Kalemaj, Raskhodnikova, and Varma (Theory Comput.","`23) provide properties that can be tested with a small number of queries with offline erasures, but cannot be tested at all with online erasures.","We demonstrate that the two models are incomparable in terms of query complexity: we construct properties that can be tested with a constant number of queries in the online corruption model, but require querying a significant fraction of the input in the offline erasure model.","We also construct properties that exhibit a strong separation between the randomness complexity of testing in the presence of offline and online adversaries: testing these properties in the online model requires exponentially more random bits than in the offline model, even when they are tested with nearly the same number of queries in both models.","Our randomness separation relies on a novel reduction from randomness-efficient testers in the adversarial online model to query-efficient testers in the standard model."],"url":"http://arxiv.org/abs/2411.18617v1"}
{"created":"2024-11-27 18:58:52","title":"Diffusion Self-Distillation for Zero-Shot Customized Image Generation","abstract":"Text-to-image diffusion models produce impressive results but are frustrating tools for artists who desire fine-grained control. For example, a common use case is to create images of a specific instance in novel contexts, i.e., \"identity-preserving generation\". This setting, along with many other tasks (e.g., relighting), is a natural fit for image+text-conditional generative models. However, there is insufficient high-quality paired data to train such a model directly. We propose Diffusion Self-Distillation, a method for using a pre-trained text-to-image model to generate its own dataset for text-conditioned image-to-image tasks. We first leverage a text-to-image diffusion model's in-context generation ability to create grids of images and curate a large paired dataset with the help of a Visual-Language Model. We then fine-tune the text-to-image model into a text+image-to-image model using the curated paired dataset. We demonstrate that Diffusion Self-Distillation outperforms existing zero-shot methods and is competitive with per-instance tuning techniques on a wide range of identity-preservation generation tasks, without requiring test-time optimization.","sentences":["Text-to-image diffusion models produce impressive results but are frustrating tools for artists who desire fine-grained control.","For example, a common use case is to create images of a specific instance in novel contexts, i.e., \"identity-preserving generation\".","This setting, along with many other tasks (e.g., relighting), is a natural fit for image+text-conditional generative models.","However, there is insufficient high-quality paired data to train such a model directly.","We propose Diffusion Self-Distillation, a method for using a pre-trained text-to-image model to generate its own dataset for text-conditioned image-to-image tasks.","We first leverage a text-to-image diffusion model's in-context generation ability to create grids of images and curate a large paired dataset with the help of a Visual-Language Model.","We then fine-tune the text-to-image model into a text+image-to-image model using the curated paired dataset.","We demonstrate that Diffusion Self-Distillation outperforms existing zero-shot methods and is competitive with per-instance tuning techniques on a wide range of identity-preservation generation tasks, without requiring test-time optimization."],"url":"http://arxiv.org/abs/2411.18616v1"}
{"created":"2024-11-27 18:58:22","title":"Proactive Gradient Conflict Mitigation in Multi-Task Learning: A Sparse Training Perspective","abstract":"Advancing towards generalist agents necessitates the concurrent processing of multiple tasks using a unified model, thereby underscoring the growing significance of simultaneous model training on multiple downstream tasks. A common issue in multi-task learning is the occurrence of gradient conflict, which leads to potential competition among different tasks during joint training. This competition often results in improvements in one task at the expense of deterioration in another. Although several optimization methods have been developed to address this issue by manipulating task gradients for better task balancing, they cannot decrease the incidence of gradient conflict. In this paper, we systematically investigate the occurrence of gradient conflict across different methods and propose a strategy to reduce such conflicts through sparse training (ST), wherein only a portion of the model's parameters are updated during training while keeping the rest unchanged. Our extensive experiments demonstrate that ST effectively mitigates conflicting gradients and leads to superior performance. Furthermore, ST can be easily integrated with gradient manipulation techniques, thus enhancing their effectiveness.","sentences":["Advancing towards generalist agents necessitates the concurrent processing of multiple tasks using a unified model, thereby underscoring the growing significance of simultaneous model training on multiple downstream tasks.","A common issue in multi-task learning is the occurrence of gradient conflict, which leads to potential competition among different tasks during joint training.","This competition often results in improvements in one task at the expense of deterioration in another.","Although several optimization methods have been developed to address this issue by manipulating task gradients for better task balancing, they cannot decrease the incidence of gradient conflict.","In this paper, we systematically investigate the occurrence of gradient conflict across different methods and propose a strategy to reduce such conflicts through sparse training (ST), wherein only a portion of the model's parameters are updated during training while keeping the rest unchanged.","Our extensive experiments demonstrate that ST effectively mitigates conflicting gradients and leads to superior performance.","Furthermore, ST can be easily integrated with gradient manipulation techniques, thus enhancing their effectiveness."],"url":"http://arxiv.org/abs/2411.18615v1"}
{"created":"2024-11-27 18:57:40","title":"Optimal root recovery for uniform attachment trees and $d$-regular growing trees","abstract":"We consider root-finding algorithms for random rooted trees grown by uniform attachment. Given an unlabeled copy of the tree and a target accuracy $\\varepsilon > 0$, such an algorithm outputs a set of nodes that contains the root with probability at least $1 - \\varepsilon$. We prove that, for the optimal algorithm, an output set of size $\\exp(O(\\log^{1/2}(1/\\varepsilon)))$ suffices; this bound is sharp and answers a question of Bubeck, Devroye and Lugosi (2017). We prove similar bounds for random regular trees that grow by uniform attachment, strengthening a result of Khim and Loh (2017).","sentences":["We consider root-finding algorithms for random rooted trees grown by uniform attachment.","Given an unlabeled copy of the tree and a target accuracy $\\varepsilon > 0$, such an algorithm outputs a set of nodes that contains the root with probability at least $1 - \\varepsilon$. We prove that, for the optimal algorithm, an output set of size $\\exp(O(\\log^{1/2}(1/\\varepsilon)))$ suffices; this bound is sharp and answers a question of Bubeck, Devroye and Lugosi (2017).","We prove similar bounds for random regular trees that grow by uniform attachment, strengthening a result of Khim and Loh (2017)."],"url":"http://arxiv.org/abs/2411.18614v1"}
{"created":"2024-11-27 18:57:16","title":"CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models","abstract":"We present CAT4D, a method for creating 4D (dynamic 3D) scenes from monocular video. CAT4D leverages a multi-view video diffusion model trained on a diverse combination of datasets to enable novel view synthesis at any specified camera poses and timestamps. Combined with a novel sampling approach, this model can transform a single monocular video into a multi-view video, enabling robust 4D reconstruction via optimization of a deformable 3D Gaussian representation. We demonstrate competitive performance on novel view synthesis and dynamic scene reconstruction benchmarks, and highlight the creative capabilities for 4D scene generation from real or generated videos. See our project page for results and interactive demos: \\url{cat-4d.github.io}.","sentences":["We present CAT4D, a method for creating 4D (dynamic 3D) scenes from monocular video.","CAT4D leverages a multi-view video diffusion model trained on a diverse combination of datasets to enable novel view synthesis at any specified camera poses and timestamps.","Combined with a novel sampling approach, this model can transform a single monocular video into a multi-view video, enabling robust 4D reconstruction via optimization of a deformable 3D Gaussian representation.","We demonstrate competitive performance on novel view synthesis and dynamic scene reconstruction benchmarks, and highlight the creative capabilities for 4D scene generation from real or generated videos.","See our project page for results and interactive demos: \\url{cat-4d.github.io}."],"url":"http://arxiv.org/abs/2411.18613v1"}
{"created":"2024-11-27 18:57:03","title":"Robust Offline Reinforcement Learning with Linearly Structured $f$-Divergence Regularization","abstract":"The Distributionally Robust Markov Decision Process (DRMDP) is a popular framework for addressing dynamics shift in reinforcement learning by learning policies robust to the worst-case transition dynamics within a constrained set. However, solving its dual optimization oracle poses significant challenges, limiting theoretical analysis and computational efficiency. The recently proposed Robust Regularized Markov Decision Process (RRMDP) replaces the uncertainty set constraint with a regularization term on the value function, offering improved scalability and theoretical insights. Yet, existing RRMDP methods rely on unstructured regularization, often leading to overly conservative policies by considering transitions that are unrealistic. To address these issues, we propose a novel framework, the $d$-rectangular linear robust regularized Markov decision process ($d$-RRMDP), which introduces a linear latent structure into both transition kernels and regularization. For the offline RL setting, where an agent learns robust policies from a pre-collected dataset in the nominal environment, we develop a family of algorithms, Robust Regularized Pessimistic Value Iteration (R2PVI), employing linear function approximation and $f$-divergence based regularization terms on transition kernels. We provide instance-dependent upper bounds on the suboptimality gap of R2PVI policies, showing these bounds depend on how well the dataset covers state-action spaces visited by the optimal robust policy under robustly admissible transitions. This term is further shown to be fundamental to $d$-RRMDPs via information-theoretic lower bounds. Finally, numerical experiments validate that R2PVI learns robust policies and is computationally more efficient than methods for constrained DRMDPs.","sentences":["The Distributionally Robust Markov Decision Process (DRMDP) is a popular framework for addressing dynamics shift in reinforcement learning by learning policies robust to the worst-case transition dynamics within a constrained set.","However, solving its dual optimization oracle poses significant challenges, limiting theoretical analysis and computational efficiency.","The recently proposed Robust Regularized Markov Decision Process (RRMDP) replaces the uncertainty set constraint with a regularization term on the value function, offering improved scalability and theoretical insights.","Yet, existing RRMDP methods rely on unstructured regularization, often leading to overly conservative policies by considering transitions that are unrealistic.","To address these issues, we propose a novel framework, the $d$-rectangular linear robust regularized Markov decision process ($d$-RRMDP), which introduces a linear latent structure into both transition kernels and regularization.","For the offline RL setting, where an agent learns robust policies from a pre-collected dataset in the nominal environment, we develop a family of algorithms, Robust Regularized Pessimistic Value Iteration (R2PVI), employing linear function approximation and $f$-divergence based regularization terms on transition kernels.","We provide instance-dependent upper bounds on the suboptimality gap of R2PVI policies, showing these bounds depend on how well the dataset covers state-action spaces visited by the optimal robust policy under robustly admissible transitions.","This term is further shown to be fundamental to $d$-RRMDPs via information-theoretic lower bounds.","Finally, numerical experiments validate that R2PVI learns robust policies and is computationally more efficient than methods for constrained DRMDPs."],"url":"http://arxiv.org/abs/2411.18612v1"}
{"created":"2024-11-27 18:53:41","title":"Task Arithmetic Through The Lens Of One-Shot Federated Learning","abstract":"Task Arithmetic is a model merging technique that enables the combination of multiple models' capabilities into a single model through simple arithmetic in the weight space, without the need for additional fine-tuning or access to the original training data. However, the factors that determine the success of Task Arithmetic remain unclear. In this paper, we examine Task Arithmetic for multi-task learning by framing it as a one-shot Federated Learning problem. We demonstrate that Task Arithmetic is mathematically equivalent to the commonly used algorithm in Federated Learning, called Federated Averaging (FedAvg). By leveraging well-established theoretical results from FedAvg, we identify two key factors that impact the performance of Task Arithmetic: data heterogeneity and training heterogeneity. To mitigate these challenges, we adapt several algorithms from Federated Learning to improve the effectiveness of Task Arithmetic. Our experiments demonstrate that applying these algorithms can often significantly boost performance of the merged model compared to the original Task Arithmetic approach. This work bridges Task Arithmetic and Federated Learning, offering new theoretical perspectives on Task Arithmetic and improved practical methodologies for model merging.","sentences":["Task Arithmetic is a model merging technique that enables the combination of multiple models' capabilities into a single model through simple arithmetic in the weight space, without the need for additional fine-tuning or access to the original training data.","However, the factors that determine the success of Task Arithmetic remain unclear.","In this paper, we examine Task Arithmetic for multi-task learning by framing it as a one-shot Federated Learning problem.","We demonstrate that Task Arithmetic is mathematically equivalent to the commonly used algorithm in Federated Learning, called Federated Averaging (FedAvg).","By leveraging well-established theoretical results from FedAvg, we identify two key factors that impact the performance of Task Arithmetic: data heterogeneity and training heterogeneity.","To mitigate these challenges, we adapt several algorithms from Federated Learning to improve the effectiveness of Task Arithmetic.","Our experiments demonstrate that applying these algorithms can often significantly boost performance of the merged model compared to the original Task Arithmetic approach.","This work bridges Task Arithmetic and Federated Learning, offering new theoretical perspectives on Task Arithmetic and improved practical methodologies for model merging."],"url":"http://arxiv.org/abs/2411.18607v1"}
{"created":"2024-11-27 18:52:49","title":"A fractional Helly theorem for set systems with slowly growing homological shatter function","abstract":"We study parameters of the convexity spaces associated with families of sets in $\\mathbb{R}^d$ where every intersection between $t$ sets of the family has its Betti numbers bounded from above by a function of $t$. Although the Radon number of such families may not be bounded, we show that these families satisfy a fractional Helly theorem. To achieve this, we introduce graded analogues of the Radon and Helly numbers. This generalizes previously known fractional Helly theorems.","sentences":["We study parameters of the convexity spaces associated with families of sets in $\\mathbb{R}^d$ where every intersection between $t$ sets of the family has its Betti numbers bounded from above by a function of $t$. Although the Radon number of such families may not be bounded, we show that these families satisfy a fractional Helly theorem.","To achieve this, we introduce graded analogues of the Radon and Helly numbers.","This generalizes previously known fractional Helly theorems."],"url":"http://arxiv.org/abs/2411.18605v1"}
{"created":"2024-11-27 18:44:47","title":"Integrated Heterogeneous Service Provisioning: Unifying Beyond-Communication Capabilities with MDMA in 6G and Future Wireless Networks","abstract":"The rapid evolution and convergence of wireless technologies and vertical applications have fundamentally reshaped our lifestyles and industries. Future wireless networks, especially 6G, are poised to support a wide range of applications enabled by heterogeneous services, leveraging both traditional connectivity-centric functions and emerging beyond-communication capabilities, particularly localization, sensing, and synchronization. However, integrating these new capabilities into a unified 6G paradigm presents significant challenges. This article provides an in-depth analysis of these technical challenges for integrative 6G design and proposes three strategies for concurrent heterogeneous service provisioning, with the aggregated goal of maximizing integration gains while minimizing service provisioning overhead. First, we adopt multi-dimensional multiple access (MDMA) as an inclusive enabling platform to flexibly integrate various capabilities by shared access to multi-dimensional radio resources. Next, we propose value-oriented heterogeneous service provisioning to maximize the integration gain through situation-aware MDMA. To enhance scalability, we optimize control and user planes by eliminating redundant control information and enabling service-oriented prioritization. Finally, we evaluate the proposed framework with a case study on integrated synchronization and communication, demonstrating its potential for concurrent heterogeneous service provisioning.","sentences":["The rapid evolution and convergence of wireless technologies and vertical applications have fundamentally reshaped our lifestyles and industries.","Future wireless networks, especially 6G, are poised to support a wide range of applications enabled by heterogeneous services, leveraging both traditional connectivity-centric functions and emerging beyond-communication capabilities, particularly localization, sensing, and synchronization.","However, integrating these new capabilities into a unified 6G paradigm presents significant challenges.","This article provides an in-depth analysis of these technical challenges for integrative 6G design and proposes three strategies for concurrent heterogeneous service provisioning, with the aggregated goal of maximizing integration gains while minimizing service provisioning overhead.","First, we adopt multi-dimensional multiple access (MDMA) as an inclusive enabling platform to flexibly integrate various capabilities by shared access to multi-dimensional radio resources.","Next, we propose value-oriented heterogeneous service provisioning to maximize the integration gain through situation-aware MDMA.","To enhance scalability, we optimize control and user planes by eliminating redundant control information and enabling service-oriented prioritization.","Finally, we evaluate the proposed framework with a case study on integrated synchronization and communication, demonstrating its potential for concurrent heterogeneous service provisioning."],"url":"http://arxiv.org/abs/2411.18598v1"}
{"created":"2024-11-27 18:44:23","title":"Structured light with a million light planes per second","abstract":"We introduce a structured light system that captures full-frame depth at rates of a thousand frames per second, four times faster than the previous state of the art. Our key innovation to this end is the design of an acousto-optic light scanning device that can scan light planes at rates up to two million planes per second. We combine this device with an event camera for structured light, using the sparse events triggered on the camera as we sweep a light plane on the scene for depth triangulation. In contrast to prior work, where light scanning is the bottleneck towards faster structured light operation, our light scanning device is three orders of magnitude faster than the event camera's full-frame bandwidth, thus allowing us to take full advantage of the event camera's fast operation. To surpass this bandwidth, we additionally demonstrate adaptive scanning of only regions of interest, at speeds an order of magnitude faster than the theoretical full-frame limit for event cameras.","sentences":["We introduce a structured light system that captures full-frame depth at rates of a thousand frames per second, four times faster than the previous state of the art.","Our key innovation to this end is the design of an acousto-optic light scanning device that can scan light planes at rates up to two million planes per second.","We combine this device with an event camera for structured light, using the sparse events triggered on the camera as we sweep a light plane on the scene for depth triangulation.","In contrast to prior work, where light scanning is the bottleneck towards faster structured light operation, our light scanning device is three orders of magnitude faster than the event camera's full-frame bandwidth, thus allowing us to take full advantage of the event camera's fast operation.","To surpass this bandwidth, we additionally demonstrate adaptive scanning of only regions of interest, at speeds an order of magnitude faster than the theoretical full-frame limit for event cameras."],"url":"http://arxiv.org/abs/2411.18597v1"}
{"created":"2024-11-27 18:38:05","title":"Biomolecular Analysis of Soil Samples and Rock Imagery for Tracing Evidence of Life Using a Mobile Robot","abstract":"The search for evidence of past life on Mars presents a tremendous challenge that requires the usage of very advanced robotic technologies to overcome it. Current digital microscopic imagers and spectrometers used for astrobiological examination suffer from limitations such as insufficient resolution, narrow detection range, and lack of portability. To overcome these challenges, this research study presents modifications to the Phoenix rover to expand its capability for detecting biosignatures on Mars. This paper examines the modifications implemented on the Phoenix rover to enhance its capability to detect a broader spectrum of biosignatures. One of the notable improvements comprises the integration of advanced digital microscopic imagers and spectrometers, enabling high-resolution examination of soil samples. Additionally, the mechanical components of the device have been reinforced to enhance maneuverability and optimize subsurface sampling capabilities. Empirical investigations have demonstrated that Phoenix has the capability to navigate diverse geological environments and procure samples for the purpose of biomolecular analysis. The biomolecular instrumentation and hybrid analytical methods showcased in this study demonstrate considerable potential for future astrobiology missions on Mars. The potential for enhancing the system lies in the possibility of broadening the range of detectable biomarkers and biosignatures.","sentences":["The search for evidence of past life on Mars presents a tremendous challenge that requires the usage of very advanced robotic technologies to overcome it.","Current digital microscopic imagers and spectrometers used for astrobiological examination suffer from limitations such as insufficient resolution, narrow detection range, and lack of portability.","To overcome these challenges, this research study presents modifications to the Phoenix rover to expand its capability for detecting biosignatures on Mars.","This paper examines the modifications implemented on the Phoenix rover to enhance its capability to detect a broader spectrum of biosignatures.","One of the notable improvements comprises the integration of advanced digital microscopic imagers and spectrometers, enabling high-resolution examination of soil samples.","Additionally, the mechanical components of the device have been reinforced to enhance maneuverability and optimize subsurface sampling capabilities.","Empirical investigations have demonstrated that Phoenix has the capability to navigate diverse geological environments and procure samples for the purpose of biomolecular analysis.","The biomolecular instrumentation and hybrid analytical methods showcased in this study demonstrate considerable potential for future astrobiology missions on Mars.","The potential for enhancing the system lies in the possibility of broadening the range of detectable biomarkers and biosignatures."],"url":"http://arxiv.org/abs/2411.18594v1"}
{"created":"2024-11-27 18:36:53","title":"CkIO: Parallel File Input for Over-Decomposed Task-Based Systems","abstract":"Parallel input performance issues are often neglected in large scale parallel applications in Computational Science and Engineering. Traditionally, there has been less focus on input performance because either input sizes are small (as in biomolecular simulations) or the time doing input is insignificant compared with the simulation with many timesteps. But newer applications, such as graph algorithms add a premium to file input performance. Additionally, over-decomposed systems, such as Charm++/AMPI, present new challenges in this context in comparison to MPI applications. In the over-decomposition model, naive parallel I/O in which every task makes its own I/O request is impractical. Furthermore, load balancing supported by models such as Charm++/AMPI precludes assumption of data contiguity on individual nodes. We develop a new I/O abstraction to address these issues by separating the decomposition of consumers of input data from that of file-reader tasks that interact with the file system. This enables applications to scale the number of consumers of data without impacting I/O behavior or performance. These ideas are implemented in a new input library, CkIO, that is built on Charm++, which is a well-known task-based and overdecomposed-partitions system. CkIO is configurable via multiple parameters (such as the number of file readers and/or their placement) that can be tuned depending on characteristics of the application, such as file size and number of application objects. Additionally, CkIO input allows for capabilities such as effective overlap of input and application-level computation, as well as load balancing and migration. We describe the relevant challenges in understanding file system behavior and architecture, the design alternatives being explored, and preliminary performance data.","sentences":["Parallel input performance issues are often neglected in large scale parallel applications in Computational Science and Engineering.","Traditionally, there has been less focus on input performance because either input sizes are small (as in biomolecular simulations) or the time doing input is insignificant compared with the simulation with many timesteps.","But newer applications, such as graph algorithms add a premium to file input performance.","Additionally, over-decomposed systems, such as Charm++/AMPI, present new challenges in this context in comparison to MPI applications.","In the over-decomposition model, naive parallel I/O in which every task makes its own I/O request is impractical.","Furthermore, load balancing supported by models such as Charm++/AMPI precludes assumption of data contiguity on individual nodes.","We develop a new I/O abstraction to address these issues by separating the decomposition of consumers of input data from that of file-reader tasks that interact with the file system.","This enables applications to scale the number of consumers of data without impacting I/O behavior or performance.","These ideas are implemented in a new input library, CkIO, that is built on Charm++, which is a well-known task-based and overdecomposed-partitions system.","CkIO is configurable via multiple parameters (such as the number of file readers and/or their placement) that can be tuned depending on characteristics of the application, such as file size and number of application objects.","Additionally, CkIO input allows for capabilities such as effective overlap of input and application-level computation, as well as load balancing and migration.","We describe the relevant challenges in understanding file system behavior and architecture, the design alternatives being explored, and preliminary performance data."],"url":"http://arxiv.org/abs/2411.18593v1"}
{"created":"2024-11-27 18:32:56","title":"On the Complexity of Recoverable Robust Optimization in the Polynomial Hierarchy","abstract":"Recoverable robust optimization is a popular multi-stage approach, in which it is possible to adjust a first-stage solution after the uncertain cost scenario is revealed. We consider recoverable robust optimization in combination with discrete budgeted uncertainty. In this setting, it seems plausible that many problems become $\\Sigma^p_3$-complete and therefore it is impossible to find compact IP formulations of them (unless the unlikely conjecture NP $= \\Sigma^p_3$ holds). Even though this seems plausible, few concrete results of this kind are known. In this paper, we fill that gap of knowledge. We consider recoverable robust optimization for the nominal problems of Sat, 3Sat, vertex cover, dominating set, set cover, hitting set, feedback vertex set, feedback arc set, uncapacitated facility location, $p$-center, $p$-median, independent set, clique, subset sum, knapsack, partition, scheduling, Hamiltonian path/cycle (directed/undirected), TSP, $k$-disjoint path ($k \\geq 2$), and Steiner tree. We show that for each of these problems, and for each of three widely used distance measures, the recoverable robust problem becomes $\\Sigma^p_3$-complete. Concretely, we show that all these problems share a certain abstract property and prove that this property implies that their robust recoverable counterpart is $\\Sigma^p_3$-complete. This reveals the insight that all the above problems are $\\Sigma^p_3$-complete 'for the same reason'. Our result extends a recent framework by Gr\\\"une and Wulf.","sentences":["Recoverable robust optimization is a popular multi-stage approach, in which it is possible to adjust a first-stage solution after the uncertain cost scenario is revealed.","We consider recoverable robust optimization in combination with discrete budgeted uncertainty.","In this setting, it seems plausible that many problems become $\\Sigma^p_3$-complete and therefore it is impossible to find compact IP formulations of them (unless the unlikely conjecture NP $= \\Sigma^p_3$ holds).","Even though this seems plausible, few concrete results of this kind are known.","In this paper, we fill that gap of knowledge.","We consider recoverable robust optimization for the nominal problems of Sat, 3Sat, vertex cover, dominating set, set cover, hitting set, feedback vertex set, feedback arc set, uncapacitated facility location, $p$-center, $p$-median, independent set, clique, subset sum, knapsack, partition, scheduling, Hamiltonian path/cycle (directed/undirected), TSP, $k$-disjoint path ($k \\geq 2$), and Steiner tree.","We show that for each of these problems, and for each of three widely used distance measures, the recoverable robust problem becomes $\\Sigma^p_3$-complete.","Concretely, we show that all these problems share a certain abstract property and prove that this property implies that their robust recoverable counterpart is $\\Sigma^p_3$-complete.","This reveals the insight that all the above problems are $\\Sigma^p_3$-complete 'for the same reason'.","Our result extends a recent framework by Gr\\\"une and Wulf."],"url":"http://arxiv.org/abs/2411.18590v1"}
{"created":"2024-11-27 18:30:08","title":"Hierarchical Information Flow for Generalized Efficient Image Restoration","abstract":"While vision transformers show promise in numerous image restoration (IR) tasks, the challenge remains in efficiently generalizing and scaling up a model for multiple IR tasks. To strike a balance between efficiency and model capacity for a generalized transformer-based IR method, we propose a hierarchical information flow mechanism for image restoration, dubbed Hi-IR, which progressively propagates information among pixels in a bottom-up manner. Hi-IR constructs a hierarchical information tree representing the degraded image across three levels. Each level encapsulates different types of information, with higher levels encompassing broader objects and concepts and lower levels focusing on local details. Moreover, the hierarchical tree architecture removes long-range self-attention, improves the computational efficiency and memory utilization, thus preparing it for effective model scaling. Based on that, we explore model scaling to improve our method's capabilities, which is expected to positively impact IR in large-scale training settings. Extensive experimental results show that Hi-IR achieves state-of-the-art performance in seven common image restoration tasks, affirming its effectiveness and generalizability.","sentences":["While vision transformers show promise in numerous image restoration (IR) tasks, the challenge remains in efficiently generalizing and scaling up a model for multiple IR tasks.","To strike a balance between efficiency and model capacity for a generalized transformer-based IR method, we propose a hierarchical information flow mechanism for image restoration, dubbed Hi-IR, which progressively propagates information among pixels in a bottom-up manner.","Hi-IR constructs a hierarchical information tree representing the degraded image across three levels.","Each level encapsulates different types of information, with higher levels encompassing broader objects and concepts and lower levels focusing on local details.","Moreover, the hierarchical tree architecture removes long-range self-attention, improves the computational efficiency and memory utilization, thus preparing it for effective model scaling.","Based on that, we explore model scaling to improve our method's capabilities, which is expected to positively impact IR in large-scale training settings.","Extensive experimental results show that Hi-IR achieves state-of-the-art performance in seven common image restoration tasks, affirming its effectiveness and generalizability."],"url":"http://arxiv.org/abs/2411.18588v1"}
{"created":"2024-11-27 18:28:50","title":"EEG-Based Analysis of Brain Responses in Multi-Modal Human-Robot Interaction: Modulating Engagement","abstract":"User engagement, cognitive participation, and motivation during task execution in physical human-robot interaction are crucial for motor learning. These factors are especially important in contexts like robotic rehabilitation, where neuroplasticity is targeted. However, traditional robotic rehabilitation systems often face challenges in maintaining user engagement, leading to unpredictable therapeutic outcomes. To address this issue, various techniques, such as assist-as-needed controllers, have been developed to prevent user slacking and encourage active participation. In this paper, we introduce a new direction through a novel multi-modal robotic interaction designed to enhance user engagement by synergistically integrating visual, motor, cognitive, and auditory (speech recognition) tasks into a single, comprehensive activity. To assess engagement quantitatively, we compared multiple electroencephalography (EEG) biomarkers between this multi-modal protocol and a traditional motor-only protocol. Fifteen healthy adult participants completed 100 trials of each task type. Our findings revealed that EEG biomarkers, particularly relative alpha power, showed statistically significant improvements in engagement during the multi-modal task compared to the motor-only task. Moreover, while engagement decreased over time in the motor-only task, the multi-modal protocol maintained consistent engagement, suggesting that users could remain engaged for longer therapy sessions. Our observations on neural responses during interaction indicate that the proposed multi-modal approach can effectively enhance user engagement, which is critical for improving outcomes. This is the first time that objective neural response highlights the benefit of a comprehensive robotic intervention combining motor, cognitive, and auditory functions in healthy subjects.","sentences":["User engagement, cognitive participation, and motivation during task execution in physical human-robot interaction are crucial for motor learning.","These factors are especially important in contexts like robotic rehabilitation, where neuroplasticity is targeted.","However, traditional robotic rehabilitation systems often face challenges in maintaining user engagement, leading to unpredictable therapeutic outcomes.","To address this issue, various techniques, such as assist-as-needed controllers, have been developed to prevent user slacking and encourage active participation.","In this paper, we introduce a new direction through a novel multi-modal robotic interaction designed to enhance user engagement by synergistically integrating visual, motor, cognitive, and auditory (speech recognition) tasks into a single, comprehensive activity.","To assess engagement quantitatively, we compared multiple electroencephalography (EEG) biomarkers between this multi-modal protocol and a traditional motor-only protocol.","Fifteen healthy adult participants completed 100 trials of each task type.","Our findings revealed that EEG biomarkers, particularly relative alpha power, showed statistically significant improvements in engagement during the multi-modal task compared to the motor-only task.","Moreover, while engagement decreased over time in the motor-only task, the multi-modal protocol maintained consistent engagement, suggesting that users could remain engaged for longer therapy sessions.","Our observations on neural responses during interaction indicate that the proposed multi-modal approach can effectively enhance user engagement, which is critical for improving outcomes.","This is the first time that objective neural response highlights the benefit of a comprehensive robotic intervention combining motor, cognitive, and auditory functions in healthy subjects."],"url":"http://arxiv.org/abs/2411.18587v1"}
{"created":"2024-11-27 18:27:07","title":"Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation","abstract":"This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM). The ever-increasing number of research articles provides a huge challenge for manual literature review. It has resulted in an increased demand for automation. Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work. The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrieval-augmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews. The ROUGE scores are used for the evaluation of all three systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364. The transformer model comes in second place and spaCy is at the last position. Finally, a graphical user interface is created for the best system based on the large language model.","sentences":["This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM).","The ever-increasing number of research articles provides a huge challenge for manual literature review.","It has resulted in an increased demand for automation.","Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work.","The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrieval-augmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective.","The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews.","The ROUGE scores are used for the evaluation of all three systems.","Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364.","The transformer model comes in second place and spaCy is at the last position.","Finally, a graphical user interface is created for the best system based on the large language model."],"url":"http://arxiv.org/abs/2411.18583v1"}
{"created":"2024-11-27 18:26:16","title":"Parallel Token Swapping for Qubit Routing","abstract":"In this paper we study a combinatorial reconfiguration problem that involves finding an optimal sequence of swaps to move an initial configuration of tokens that are placed on the vertices of a graph to a final desired one. This problem arises as a crucial step in reducing the depth of a quantum circuit when compiling a quantum algorithm. We provide the first known constant factor approximation algorithms for the parallel token swapping problem on graph topologies that are commonly found in modern quantum computers, including cycle graphs, subdivided star graphs, and grid graphs. We also study the so-called stretch factor of a natural lower bound to the problem, which has been shown to be useful when designing heuristics for the qubit routing problem. Finally, we study the colored version of this reconfiguration problem where some tokens share the same color and are considered indistinguishable.","sentences":["In this paper we study a combinatorial reconfiguration problem that involves finding an optimal sequence of swaps to move an initial configuration of tokens that are placed on the vertices of a graph to a final desired one.","This problem arises as a crucial step in reducing the depth of a quantum circuit when compiling a quantum algorithm.","We provide the first known constant factor approximation algorithms for the parallel token swapping problem on graph topologies that are commonly found in modern quantum computers, including cycle graphs, subdivided star graphs, and grid graphs.","We also study the so-called stretch factor of a natural lower bound to the problem, which has been shown to be useful when designing heuristics for the qubit routing problem.","Finally, we study the colored version of this reconfiguration problem where some tokens share the same color and are considered indistinguishable."],"url":"http://arxiv.org/abs/2411.18581v1"}
{"created":"2024-11-27 18:24:13","title":"Surveying the space of descriptions of a composite system with machine learning","abstract":"Multivariate information theory provides a general and principled framework for understanding how the components of a complex system are connected. Existing analyses are coarse in nature -- built up from characterizations of discrete subsystems -- and can be computationally prohibitive. In this work, we propose to study the continuous space of possible descriptions of a composite system as a window into its organizational structure. A description consists of specific information conveyed about each of the components, and the space of possible descriptions is equivalent to the space of lossy compression schemes of the components. We introduce a machine learning framework to optimize descriptions that extremize key information theoretic quantities used to characterize organization, such as total correlation and O-information. Through case studies on spin systems, Sudoku boards, and letter sequences from natural language, we identify extremal descriptions that reveal how system-wide variation emerges from individual components. By integrating machine learning into a fine-grained information theoretic analysis of composite random variables, our framework opens a new avenues for probing the structure of real-world complex systems.","sentences":["Multivariate information theory provides a general and principled framework for understanding how the components of a complex system are connected.","Existing analyses are coarse in nature -- built up from characterizations of discrete subsystems -- and can be computationally prohibitive.","In this work, we propose to study the continuous space of possible descriptions of a composite system as a window into its organizational structure.","A description consists of specific information conveyed about each of the components, and the space of possible descriptions is equivalent to the space of lossy compression schemes of the components.","We introduce a machine learning framework to optimize descriptions that extremize key information theoretic quantities used to characterize organization, such as total correlation and O-information.","Through case studies on spin systems, Sudoku boards, and letter sequences from natural language, we identify extremal descriptions that reveal how system-wide variation emerges from individual components.","By integrating machine learning into a fine-grained information theoretic analysis of composite random variables, our framework opens a new avenues for probing the structure of real-world complex systems."],"url":"http://arxiv.org/abs/2411.18579v1"}
{"created":"2024-11-27 18:23:59","title":"Pruning Deep Convolutional Neural Network Using Conditional Mutual Information","abstract":"Convolutional Neural Networks (CNNs) achieve high performance in image classification tasks but are challenging to deploy on resource-limited hardware due to their large model sizes. To address this issue, we leverage Mutual Information, a metric that provides valuable insights into how deep learning models retain and process information through measuring the shared information between input features or output labels and network layers. In this study, we propose a structured filter-pruning approach for CNNs that identifies and selectively retains the most informative features in each layer. Our approach successively evaluates each layer by ranking the importance of its feature maps based on Conditional Mutual Information (CMI) values, computed using a matrix-based Renyi {\\alpha}-order entropy numerical method. We propose several formulations of CMI to capture correlation among features across different layers. We then develop various strategies to determine the cutoff point for CMI values to prune unimportant features. This approach allows parallel pruning in both forward and backward directions and significantly reduces model size while preserving accuracy. Tested on the VGG16 architecture with the CIFAR-10 dataset, the proposed method reduces the number of filters by more than a third, with only a 0.32% drop in test accuracy.","sentences":["Convolutional Neural Networks (CNNs) achieve high performance in image classification tasks but are challenging to deploy on resource-limited hardware due to their large model sizes.","To address this issue, we leverage Mutual Information, a metric that provides valuable insights into how deep learning models retain and process information through measuring the shared information between input features or output labels and network layers.","In this study, we propose a structured filter-pruning approach for CNNs that identifies and selectively retains the most informative features in each layer.","Our approach successively evaluates each layer by ranking the importance of its feature maps based on Conditional Mutual Information (CMI) values, computed using a matrix-based Renyi {\\alpha}-order entropy numerical method.","We propose several formulations of CMI to capture correlation among features across different layers.","We then develop various strategies to determine the cutoff point for CMI values to prune unimportant features.","This approach allows parallel pruning in both forward and backward directions and significantly reduces model size while preserving accuracy.","Tested on the VGG16 architecture with the CIFAR-10 dataset, the proposed method reduces the number of filters by more than a third, with only a 0.32% drop in test accuracy."],"url":"http://arxiv.org/abs/2411.18578v1"}
{"created":"2024-11-27 18:23:57","title":"On Importance of Code-Mixed Embeddings for Hate Speech Identification","abstract":"Code-mixing is the practice of using two or more languages in a single sentence, which often occurs in multilingual communities such as India where people commonly speak multiple languages. Classic NLP tools, trained on monolingual data, face challenges when dealing with code-mixed data. Extracting meaningful information from sentences containing multiple languages becomes difficult, particularly in tasks like hate speech detection, due to linguistic variation, cultural nuances, and data sparsity. To address this, we aim to analyze the significance of code-mixed embeddings and evaluate the performance of BERT and HingBERT models (trained on a Hindi-English corpus) in hate speech detection. Our study demonstrates that HingBERT models, benefiting from training on the extensive Hindi-English dataset L3Cube-HingCorpus, outperform BERT models when tested on hate speech text datasets. We also found that code-mixed Hing-FastText performs better than standard English FastText and vanilla BERT models.","sentences":["Code-mixing is the practice of using two or more languages in a single sentence, which often occurs in multilingual communities such as India where people commonly speak multiple languages.","Classic NLP tools, trained on monolingual data, face challenges when dealing with code-mixed data.","Extracting meaningful information from sentences containing multiple languages becomes difficult, particularly in tasks like hate speech detection, due to linguistic variation, cultural nuances, and data sparsity.","To address this, we aim to analyze the significance of code-mixed embeddings and evaluate the performance of BERT and HingBERT models (trained on a Hindi-English corpus) in hate speech detection.","Our study demonstrates that HingBERT models, benefiting from training on the extensive Hindi-English dataset L3Cube-HingCorpus, outperform BERT models when tested on hate speech text datasets.","We also found that code-mixed Hing-FastText performs better than standard English FastText and vanilla BERT models."],"url":"http://arxiv.org/abs/2411.18577v1"}
{"created":"2024-11-27 18:16:11","title":"Exploring Depth Information for Detecting Manipulated Face Videos","abstract":"Face manipulation detection has been receiving a lot of attention for the reliability and security of the face images/videos. Recent studies focus on using auxiliary information or prior knowledge to capture robust manipulation traces, which are shown to be promising. As one of the important face features, the face depth map, which has shown to be effective in other areas such as face recognition or face detection, is unfortunately paid little attention to in literature for face manipulation detection. In this paper, we explore the possibility of incorporating the face depth map as auxiliary information for robust face manipulation detection. To this end, we first propose a Face Depth Map Transformer (FDMT) to estimate the face depth map patch by patch from an RGB face image, which is able to capture the local depth anomaly created due to manipulation. The estimated face depth map is then considered as auxiliary information to be integrated with the backbone features using a Multi-head Depth Attention (MDA) mechanism that is newly designed. We also propose an RGB-Depth Inconsistency Attention (RDIA) module to effectively capture the inter-frame inconsistency for multi-frame input. Various experiments demonstrate the advantage of our proposed method for face manipulation detection.","sentences":["Face manipulation detection has been receiving a lot of attention for the reliability and security of the face images/videos.","Recent studies focus on using auxiliary information or prior knowledge to capture robust manipulation traces, which are shown to be promising.","As one of the important face features, the face depth map, which has shown to be effective in other areas such as face recognition or face detection, is unfortunately paid little attention to in literature for face manipulation detection.","In this paper, we explore the possibility of incorporating the face depth map as auxiliary information for robust face manipulation detection.","To this end, we first propose a Face Depth Map Transformer (FDMT) to estimate the face depth map patch by patch from an RGB face image, which is able to capture the local depth anomaly created due to manipulation.","The estimated face depth map is then considered as auxiliary information to be integrated with the backbone features using a Multi-head Depth Attention (MDA) mechanism that is newly designed.","We also propose an RGB-Depth Inconsistency Attention (RDIA) module to effectively capture the inter-frame inconsistency for multi-frame input.","Various experiments demonstrate the advantage of our proposed method for face manipulation detection."],"url":"http://arxiv.org/abs/2411.18572v1"}
{"created":"2024-11-27 18:14:38","title":"Challenges in Adapting Multilingual LLMs to Low-Resource Languages using LoRA PEFT Tuning","abstract":"Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, yet challenges persist in adapting these models for low-resource languages. In this study, we investigate the effects of Low-Rank Adaptation (LoRA) Parameter-Efficient Fine-Tuning (PEFT) on multilingual Gemma models for Marathi, a language with limited resources. Using a translated Alpaca dataset with 52,000 instruction-response pairs, our findings reveal that while evaluation metrics often show a performance decline post-fine-tuning, manual assessments frequently suggest that the fine-tuned models outperform their original counterparts. The observations indicate improvements in target language generation capabilities but a reduction in reasoning abilities following language adaptation. These results underscore the need for improved evaluation methodologies and the creation of high-quality native datasets to accurately assess language-specific model performance in low-resource settings.","sentences":["Large Language Models (LLMs) have demonstrated remarkable multilingual capabilities, yet challenges persist in adapting these models for low-resource languages.","In this study, we investigate the effects of Low-Rank Adaptation (LoRA) Parameter-Efficient Fine-Tuning (PEFT) on multilingual Gemma models for Marathi, a language with limited resources.","Using a translated Alpaca dataset with 52,000 instruction-response pairs, our findings reveal that while evaluation metrics often show a performance decline post-fine-tuning, manual assessments frequently suggest that the fine-tuned models outperform their original counterparts.","The observations indicate improvements in target language generation capabilities but a reduction in reasoning abilities following language adaptation.","These results underscore the need for improved evaluation methodologies and the creation of high-quality native datasets to accurately assess language-specific model performance in low-resource settings."],"url":"http://arxiv.org/abs/2411.18571v1"}
{"created":"2024-11-27 18:04:05","title":"A Pipeline of Neural-Symbolic Integration to Enhance Spatial Reasoning in Large Language Models","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities across various tasks. However, LLMs often struggle with spatial reasoning which is one essential part of reasoning and inference and requires understanding complex relationships between objects in space. This paper proposes a novel neural-symbolic framework that enhances LLMs' spatial reasoning abilities. We evaluate our approach on two benchmark datasets: StepGame and SparQA, implementing three distinct strategies: (1) ASP (Answer Set Programming)-based symbolic reasoning, (2) LLM + ASP pipeline using DSPy, and (3) Fact + Logical rules. Our experiments demonstrate significant improvements over the baseline prompting methods, with accuracy increases of 40-50% on StepGame} dataset and 3-13% on the more complex SparQA dataset. The \"LLM + ASP\" pipeline achieves particularly strong results on the tasks of Finding Relations (FR) and Finding Block (FB) questions, though performance varies across different question types. The impressive results suggest that while neural-symbolic approaches offer promising directions for enhancing spatial reasoning in LLMs, their effectiveness depends heavily on the specific task characteristics and implementation strategies. We propose an integrated, simple yet effective set of strategies using a neural-symbolic pipeline to boost spatial reasoning abilities in LLMs. This pipeline and its strategies demonstrate strong and broader applicability to other reasoning domains in LLMs, such as temporal reasoning, deductive inference etc.","sentences":["Large Language Models (LLMs) have demonstrated impressive capabilities across various tasks.","However, LLMs often struggle with spatial reasoning which is one essential part of reasoning and inference and requires understanding complex relationships between objects in space.","This paper proposes a novel neural-symbolic framework that enhances LLMs' spatial reasoning abilities.","We evaluate our approach on two benchmark datasets: StepGame and SparQA, implementing three distinct strategies: (1) ASP (Answer Set Programming)-based symbolic reasoning, (2) LLM + ASP pipeline using DSPy, and (3) Fact + Logical rules.","Our experiments demonstrate significant improvements over the baseline prompting methods, with accuracy increases of 40-50% on StepGame} dataset and 3-13% on the more complex SparQA dataset.","The \"LLM + ASP\" pipeline achieves particularly strong results on the tasks of Finding Relations (FR) and Finding Block (FB) questions, though performance varies across different question types.","The impressive results suggest that while neural-symbolic approaches offer promising directions for enhancing spatial reasoning in LLMs, their effectiveness depends heavily on the specific task characteristics and implementation strategies.","We propose an integrated, simple yet effective set of strategies using a neural-symbolic pipeline to boost spatial reasoning abilities in LLMs.","This pipeline and its strategies demonstrate strong and broader applicability to other reasoning domains in LLMs, such as temporal reasoning, deductive inference etc."],"url":"http://arxiv.org/abs/2411.18564v1"}
{"created":"2024-11-27 18:03:26","title":"DexDiffuser: Interaction-aware Diffusion Planning for Adaptive Dexterous Manipulation","abstract":"Dexterous manipulation with contact-rich interactions is crucial for advanced robotics. While recent diffusion-based planning approaches show promise for simpler manipulation tasks, they often produce unrealistic ghost states (e.g., the object automatically moves without hand contact) or lack adaptability when handling complex sequential interactions. In this work, we introduce DexDiffuser, an interaction-aware diffusion planning framework for adaptive dexterous manipulation. DexDiffuser models joint state-action dynamics through a dual-phase diffusion process which consists of pre-interaction contact alignment and post-contact goal-directed control, enabling goal-adaptive generalizable dexterous manipulation. Additionally, we incorporate dynamics model-based dual guidance and leverage large language models for automated guidance function generation, enhancing generalizability for physical interactions and facilitating diverse goal adaptation through language cues. Experiments on physical interaction tasks such as door opening, pen and block re-orientation, and hammer striking demonstrate DexDiffuser's effectiveness on goals outside training distributions, achieving over twice the average success rate (59.2% vs. 29.5%) compared to existing methods. Our framework achieves 70.0% success on 30-degree door opening, 40.0% and 36.7% on pen and block half-side re-orientation respectively, and 46.7% on hammer nail half drive, highlighting its robustness and flexibility in contact-rich manipulation.","sentences":["Dexterous manipulation with contact-rich interactions is crucial for advanced robotics.","While recent diffusion-based planning approaches show promise for simpler manipulation tasks, they often produce unrealistic ghost states (e.g., the object automatically moves without hand contact) or lack adaptability when handling complex sequential interactions.","In this work, we introduce DexDiffuser, an interaction-aware diffusion planning framework for adaptive dexterous manipulation.","DexDiffuser models joint state-action dynamics through a dual-phase diffusion process which consists of pre-interaction contact alignment and post-contact goal-directed control, enabling goal-adaptive generalizable dexterous manipulation.","Additionally, we incorporate dynamics model-based dual guidance and leverage large language models for automated guidance function generation, enhancing generalizability for physical interactions and facilitating diverse goal adaptation through language cues.","Experiments on physical interaction tasks such as door opening, pen and block re-orientation, and hammer striking demonstrate DexDiffuser's effectiveness on goals outside training distributions, achieving over twice the average success rate (59.2% vs. 29.5%) compared to existing methods.","Our framework achieves 70.0% success on 30-degree door opening, 40.0% and 36.7% on pen and block half-side re-orientation respectively, and 46.7% on hammer nail half drive, highlighting its robustness and flexibility in contact-rich manipulation."],"url":"http://arxiv.org/abs/2411.18562v1"}
{"created":"2024-11-27 17:51:58","title":"Retrofitting (Large) Language Models with Dynamic Tokenization","abstract":"Current language models (LMs) use a fixed, static subword tokenizer. This choice, often taken for granted, typically results in degraded efficiency and capabilities in languages other than English, and makes it challenging to apply LMs to new domains or languages. To address these issues, we propose retrofitting LMs with dynamic tokenization: a way to dynamically decide on token boundaries based on the input text. For encoder-style models, we introduce a subword-merging algorithm inspired by byte-pair encoding (BPE), but at a batch level. We merge frequent subword sequences in a batch, then apply a pretrained embedding-prediction hypernetwork to compute the token embeddings on-the-fly. When applied with word-level boundaries, this on average reduces token sequence lengths by >20% across 14 languages on XNLI with XLM-R while degrading its task performance by less than 2%. For decoder-style models, we apply dynamic tokenization in two ways: 1) for prefilling, maintaining performance of Mistral-7B almost completely with up to 40% sequence reduction - relative to the word-level; and 2) via an approximate nearest neighbor index, achieving fast generation with a one million token vocabulary, demonstrating scalability to even larger, dynamic vocabularies. Overall, our findings show that dynamic tokenization substantially improves inference speed and promotes fairness across languages, making a leap towards overcoming the limitations of static tokenization and enabling more equitable and adaptable LMs.","sentences":["Current language models (LMs) use a fixed, static subword tokenizer.","This choice, often taken for granted, typically results in degraded efficiency and capabilities in languages other than English, and makes it challenging to apply LMs to new domains or languages.","To address these issues, we propose retrofitting LMs with dynamic tokenization: a way to dynamically decide on token boundaries based on the input text.","For encoder-style models, we introduce a subword-merging algorithm inspired by byte-pair encoding (BPE), but at a batch level.","We merge frequent subword sequences in a batch, then apply a pretrained embedding-prediction hypernetwork to compute the token embeddings on-the-fly.","When applied with word-level boundaries, this on average reduces token sequence lengths by >20% across 14 languages on XNLI with XLM-R while degrading its task performance by less than 2%.","For decoder-style models, we apply dynamic tokenization in two ways: 1) for prefilling, maintaining performance of Mistral-7B almost completely with up to 40% sequence reduction - relative to the word-level; and 2) via an approximate nearest neighbor index, achieving fast generation with a one million token vocabulary, demonstrating scalability to even larger, dynamic vocabularies.","Overall, our findings show that dynamic tokenization substantially improves inference speed and promotes fairness across languages, making a leap towards overcoming the limitations of static tokenization and enabling more equitable and adaptable LMs."],"url":"http://arxiv.org/abs/2411.18553v1"}
{"created":"2024-11-27 17:51:44","title":"FAM Diffusion: Frequency and Attention Modulation for High-Resolution Image Generation with Stable Diffusion","abstract":"Diffusion models are proficient at generating high-quality images. They are however effective only when operating at the resolution used during training. Inference at a scaled resolution leads to repetitive patterns and structural distortions. Retraining at higher resolutions quickly becomes prohibitive. Thus, methods enabling pre-existing diffusion models to operate at flexible test-time resolutions are highly desirable. Previous works suffer from frequent artifacts and often introduce large latency overheads. We propose two simple modules that combine to solve these issues. We introduce a Frequency Modulation (FM) module that leverages the Fourier domain to improve the global structure consistency, and an Attention Modulation (AM) module which improves the consistency of local texture patterns, a problem largely ignored in prior works. Our method, coined Fam diffusion, can seamlessly integrate into any latent diffusion model and requires no additional training. Extensive qualitative results highlight the effectiveness of our method in addressing structural and local artifacts, while quantitative results show state-of-the-art performance. Also, our method avoids redundant inference tricks for improved consistency such as patch-based or progressive generation, leading to negligible latency overheads.","sentences":["Diffusion models are proficient at generating high-quality images.","They are however effective only when operating at the resolution used during training.","Inference at a scaled resolution leads to repetitive patterns and structural distortions.","Retraining at higher resolutions quickly becomes prohibitive.","Thus, methods enabling pre-existing diffusion models to operate at flexible test-time resolutions are highly desirable.","Previous works suffer from frequent artifacts and often introduce large latency overheads.","We propose two simple modules that combine to solve these issues.","We introduce a Frequency Modulation (FM) module that leverages the Fourier domain to improve the global structure consistency, and an Attention Modulation (AM) module which improves the consistency of local texture patterns, a problem largely ignored in prior works.","Our method, coined Fam diffusion, can seamlessly integrate into any latent diffusion model and requires no additional training.","Extensive qualitative results highlight the effectiveness of our method in addressing structural and local artifacts, while quantitative results show state-of-the-art performance.","Also, our method avoids redundant inference tricks for improved consistency such as patch-based or progressive generation, leading to negligible latency overheads."],"url":"http://arxiv.org/abs/2411.18552v1"}
{"created":"2024-11-27 17:51:39","title":"Concentration of Cumulative Reward in Markov Decision Processes","abstract":"In this paper, we investigate the concentration properties of cumulative rewards in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings. We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting. Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms. Additionally, we explore two key implications of our results. First, we analyze the sample path behavior of the difference in rewards between any two stationary policies. Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent. Our proof techniques rely on a novel martingale decomposition of cumulative rewards, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences.","sentences":["In this paper, we investigate the concentration properties of cumulative rewards in Markov Decision Processes (MDPs), focusing on both asymptotic and non-asymptotic settings.","We introduce a unified approach to characterize reward concentration in MDPs, covering both infinite-horizon settings (i.e., average and discounted reward frameworks) and finite-horizon setting.","Our asymptotic results include the law of large numbers, the central limit theorem, and the law of iterated logarithms, while our non-asymptotic bounds include Azuma-Hoeffding-type inequalities and a non-asymptotic version of the law of iterated logarithms.","Additionally, we explore two key implications of our results.","First, we analyze the sample path behavior of the difference in rewards between any two stationary policies.","Second, we show that two alternative definitions of regret for learning policies proposed in the literature are rate-equivalent.","Our proof techniques rely on a novel martingale decomposition of cumulative rewards, properties of the solution to the policy evaluation fixed-point equation, and both asymptotic and non-asymptotic concentration results for martingale difference sequences."],"url":"http://arxiv.org/abs/2411.18551v1"}
{"created":"2024-11-27 17:50:35","title":"PhyCAGE: Physically Plausible Compositional 3D Asset Generation from a Single Image","abstract":"We present PhyCAGE, the first approach for physically plausible compositional 3D asset generation from a single image. Given an input image, we first generate consistent multi-view images for components of the assets. These images are then fitted with 3D Gaussian Splatting representations. To ensure that the Gaussians representing objects are physically compatible with each other, we introduce a Physical Simulation-Enhanced Score Distillation Sampling (PSE-SDS) technique to further optimize the positions of the Gaussians. It is achieved by setting the gradient of the SDS loss as the initial velocity of the physical simulation, allowing the simulator to act as a physics-guided optimizer that progressively corrects the Gaussians' positions to a physically compatible state. Experimental results demonstrate that the proposed method can generate physically plausible compositional 3D assets given a single image.","sentences":["We present PhyCAGE, the first approach for physically plausible compositional 3D asset generation from a single image.","Given an input image, we first generate consistent multi-view images for components of the assets.","These images are then fitted with 3D Gaussian Splatting representations.","To ensure that the Gaussians representing objects are physically compatible with each other, we introduce a Physical Simulation-Enhanced Score Distillation Sampling (PSE-SDS) technique to further optimize the positions of the Gaussians.","It is achieved by setting the gradient of the SDS loss as the initial velocity of the physical simulation, allowing the simulator to act as a physics-guided optimizer that progressively corrects the Gaussians' positions to a physically compatible state.","Experimental results demonstrate that the proposed method can generate physically plausible compositional 3D assets given a single image."],"url":"http://arxiv.org/abs/2411.18548v1"}
{"created":"2024-11-27 17:36:08","title":"AdaVLN: Towards Visual Language Navigation in Continuous Indoor Environments with Moving Humans","abstract":"Visual Language Navigation is a task that challenges robots to navigate in realistic environments based on natural language instructions. While previous research has largely focused on static settings, real-world navigation must often contend with dynamic human obstacles. Hence, we propose an extension to the task, termed Adaptive Visual Language Navigation (AdaVLN), which seeks to narrow this gap. AdaVLN requires robots to navigate complex 3D indoor environments populated with dynamically moving human obstacles, adding a layer of complexity to navigation tasks that mimic the real-world. To support exploration of this task, we also present AdaVLN simulator and AdaR2R datasets. The AdaVLN simulator enables easy inclusion of fully animated human models directly into common datasets like Matterport3D. We also introduce a \"freeze-time\" mechanism for both the navigation task and simulator, which pauses world state updates during agent inference, enabling fair comparisons and experimental reproducibility across different hardware. We evaluate several baseline models on this task, analyze the unique challenges introduced by AdaVLN, and demonstrate its potential to bridge the sim-to-real gap in VLN research.","sentences":["Visual Language Navigation is a task that challenges robots to navigate in realistic environments based on natural language instructions.","While previous research has largely focused on static settings, real-world navigation must often contend with dynamic human obstacles.","Hence, we propose an extension to the task, termed Adaptive Visual Language Navigation (AdaVLN), which seeks to narrow this gap.","AdaVLN requires robots to navigate complex 3D indoor environments populated with dynamically moving human obstacles, adding a layer of complexity to navigation tasks that mimic the real-world.","To support exploration of this task, we also present AdaVLN simulator and AdaR2R datasets.","The AdaVLN simulator enables easy inclusion of fully animated human models directly into common datasets like Matterport3D.","We also introduce a \"freeze-time\" mechanism for both the navigation task and simulator, which pauses world state updates during agent inference, enabling fair comparisons and experimental reproducibility across different hardware.","We evaluate several baseline models on this task, analyze the unique challenges introduced by AdaVLN, and demonstrate its potential to bridge the sim-to-real gap in VLN research."],"url":"http://arxiv.org/abs/2411.18539v1"}
{"created":"2024-11-27 17:24:24","title":"Utilizing the Mean Teacher with Supcontrast Loss for Wafer Pattern Recognition","abstract":"The patterns on wafer maps play a crucial role in helping engineers identify the causes of production issues during semiconductor manufacturing. In order to reduce costs and improve accuracy, automation technology is essential, and recent developments in deep learning have led to impressive results in wafer map pattern recognition. In this context, inspired by the effectiveness of semi-supervised learning and contrastive learning methods, we introduce an innovative approach that integrates the Mean Teacher framework with the supervised contrastive learning loss for enhanced wafer map pattern recognition. Our methodology not only addresses the nuances of wafer patterns but also tackles challenges arising from limited labeled data. To further refine the process, we address data imbalance in the wafer dataset by employing SMOTE and under-sampling techniques. We conduct a comprehensive analysis of our proposed method and demonstrate its effectiveness through experiments using real-world dataset WM811K obtained from semiconductor manufacturers. Compared to the baseline method, our method has achieved 5.46%, 6.68%, 5.42%, and 4.53% improvements in Accuracy, Precision, Recall, and F1 score, respectively.","sentences":["The patterns on wafer maps play a crucial role in helping engineers identify the causes of production issues during semiconductor manufacturing.","In order to reduce costs and improve accuracy, automation technology is essential, and recent developments in deep learning have led to impressive results in wafer map pattern recognition.","In this context, inspired by the effectiveness of semi-supervised learning and contrastive learning methods, we introduce an innovative approach that integrates the Mean Teacher framework with the supervised contrastive learning loss for enhanced wafer map pattern recognition.","Our methodology not only addresses the nuances of wafer patterns but also tackles challenges arising from limited labeled data.","To further refine the process, we address data imbalance in the wafer dataset by employing SMOTE and under-sampling techniques.","We conduct a comprehensive analysis of our proposed method and demonstrate its effectiveness through experiments using real-world dataset WM811K obtained from semiconductor manufacturers.","Compared to the baseline method, our method has achieved 5.46%, 6.68%, 5.42%, and 4.53% improvements in Accuracy, Precision, Recall, and F1 score, respectively."],"url":"http://arxiv.org/abs/2411.18533v1"}
{"created":"2024-11-27 17:24:17","title":"Statistic Maximal Leakage","abstract":"We introduce a privacy measure called statistic maximal leakage that quantifies how much a privacy mechanism leaks about a specific secret, relative to the adversary's prior information about that secret. Statistic maximal leakage is an extension of the well-known maximal leakage. Unlike maximal leakage, which protects an arbitrary, unknown secret, statistic maximal leakage protects a single, known secret. We show that statistic maximal leakage satisfies composition and post-processing properties. Additionally, we show how to efficiently compute it in the special case of deterministic data release mechanisms. We analyze two important mechanisms under statistic maximal leakage: the quantization mechanism and randomized response. We show theoretically and empirically that the quantization mechanism achieves better privacy-utility tradeoffs in the settings we study.","sentences":["We introduce a privacy measure called statistic maximal leakage that quantifies how much a privacy mechanism leaks about a specific secret, relative to the adversary's prior information about that secret.","Statistic maximal leakage is an extension of the well-known maximal leakage.","Unlike maximal leakage, which protects an arbitrary, unknown secret, statistic maximal leakage protects a single, known secret.","We show that statistic maximal leakage satisfies composition and post-processing properties.","Additionally, we show how to efficiently compute it in the special case of deterministic data release mechanisms.","We analyze two important mechanisms under statistic maximal leakage: the quantization mechanism and randomized response.","We show theoretically and empirically that the quantization mechanism achieves better privacy-utility tradeoffs in the settings we study."],"url":"http://arxiv.org/abs/2411.18531v1"}
{"created":"2024-11-27 17:23:47","title":"Emergence of Self-Identity in AI: A Mathematical Framework and Empirical Study with Generative Large Language Models","abstract":"This paper introduces a mathematical framework for defining and quantifying self-identity in artificial intelligence (AI) systems, addressing a critical gap in the theoretical foundations of artificial consciousness. While existing approaches to artificial self-awareness often rely on heuristic implementations or philosophical abstractions, we present a formal framework grounded in metric space theory, measure theory, and functional analysis. Our framework posits that self-identity emerges from two mathematically quantifiable conditions: the existence of a connected continuum of memories $C \\subseteq \\mathcal{M}$ in a metric space $(\\mathcal{M}, d_{\\mathcal{M}})$, and a continuous mapping $I: \\mathcal{M} \\to \\mathcal{S}$ that maintains consistent self-recognition across this continuum, where $(\\mathcal{S}, d_{\\mathcal{S}})$ represents the metric space of possible self-identities. To validate this theoretical framework, we conducted empirical experiments using the Llama 3.2 1B model, employing Low-Rank Adaptation (LoRA) for efficient fine-tuning. The model was trained on a synthetic dataset containing temporally structured memories, designed to capture the complexity of coherent self-identity formation. Our evaluation metrics included quantitative measures of self-awareness, response consistency, and linguistic precision. The experimental results demonstrate substantial improvements in measurable self-awareness metrics, with the primary self-awareness score increasing from 0.276 to 0.801. This enables the structured creation of AI systems with validated self-identity features. The implications of our study are immediately relevant to the fields of humanoid robotics and autonomous systems.","sentences":["This paper introduces a mathematical framework for defining and quantifying self-identity in artificial intelligence (AI) systems, addressing a critical gap in the theoretical foundations of artificial consciousness.","While existing approaches to artificial self-awareness often rely on heuristic implementations or philosophical abstractions, we present a formal framework grounded in metric space theory, measure theory, and functional analysis.","Our framework posits that self-identity emerges from two mathematically quantifiable conditions: the existence of a connected continuum of memories $C \\subseteq \\mathcal{M}$ in a metric space $(\\mathcal{M}, d_{\\mathcal{M}})$, and a continuous mapping $I: \\mathcal{M} \\to \\mathcal{S}$ that maintains consistent self-recognition across this continuum, where $(\\mathcal{S}, d_{\\mathcal{S}})$ represents the metric space of possible self-identities.","To validate this theoretical framework, we conducted empirical experiments using the Llama 3.2 1B model, employing Low-Rank Adaptation (LoRA) for efficient fine-tuning.","The model was trained on a synthetic dataset containing temporally structured memories, designed to capture the complexity of coherent self-identity formation.","Our evaluation metrics included quantitative measures of self-awareness, response consistency, and linguistic precision.","The experimental results demonstrate substantial improvements in measurable self-awareness metrics, with the primary self-awareness score increasing from 0.276 to 0.801.","This enables the structured creation of AI systems with validated self-identity features.","The implications of our study are immediately relevant to the fields of humanoid robotics and autonomous systems."],"url":"http://arxiv.org/abs/2411.18530v1"}
{"created":"2024-11-27 17:18:51","title":"NeuroAI for AI Safety","abstract":"As AI systems become increasingly powerful, the need for safe AI has become more pressing. Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals. Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being. These properties are a function of the architecture of the brain and the learning algorithms it implements. Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized. In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures. We make several concrete recommendations for how neuroscience can positively impact AI safety.","sentences":["As AI systems become increasingly powerful, the need for safe AI has become more pressing.","Humans are an attractive model for AI safety: as the only known agents capable of general intelligence, they perform robustly even under conditions that deviate significantly from prior experiences, explore the world safely, understand pragmatics, and can cooperate to meet their intrinsic goals.","Intelligence, when coupled with cooperation and safety mechanisms, can drive sustained progress and well-being.","These properties are a function of the architecture of the brain and the learning algorithms it implements.","Neuroscience may thus hold important keys to technical AI safety that are currently underexplored and underutilized.","In this roadmap, we highlight and critically evaluate several paths toward AI safety inspired by neuroscience: emulating the brain's representations, information processing, and architecture; building robust sensory and motor systems from imitating brain data and bodies; fine-tuning AI systems on brain data; advancing interpretability using neuroscience methods; and scaling up cognitively-inspired architectures.","We make several concrete recommendations for how neuroscience can positively impact AI safety."],"url":"http://arxiv.org/abs/2411.18526v1"}
{"created":"2024-11-27 17:12:14","title":"Perturbation Ontology based Graph Attention Networks","abstract":"In recent years, graph representation learning has undergone a paradigm shift, driven by the emergence and proliferation of graph neural networks (GNNs) and their heterogeneous counterparts. Heterogeneous GNNs have shown remarkable success in extracting low-dimensional embeddings from complex graphs that encompass diverse entity types and relationships. While meta-path-based techniques have long been recognized for their ability to capture semantic affinities among nodes, their dependence on manual specification poses a significant limitation. In contrast, matrix-focused methods accelerate processing by utilizing structural cues but often overlook contextual richness. In this paper, we challenge the current paradigm by introducing ontology as a fundamental semantic primitive within complex graphs. Our goal is to integrate the strengths of both matrix-centric and meta-path-based approaches into a unified framework. We propose perturbation Ontology-based Graph Attention Networks (POGAT), a novel methodology that combines ontology subgraphs with an advanced self-supervised learning paradigm to achieve a deep contextual understanding. The core innovation of POGAT lies in our enhanced homogeneous perturbing scheme designed to generate rigorous negative samples, encouraging the model to explore minimal contextual features more thoroughly. Through extensive empirical evaluations, we demonstrate that POGAT significantly outperforms state-of-the-art baselines, achieving a groundbreaking improvement of up to 10.78\\% in F1-score for the critical task of link prediction and 12.01\\% in Micro-F1 for the critical task of node classification.","sentences":["In recent years, graph representation learning has undergone a paradigm shift, driven by the emergence and proliferation of graph neural networks (GNNs) and their heterogeneous counterparts.","Heterogeneous GNNs have shown remarkable success in extracting low-dimensional embeddings from complex graphs that encompass diverse entity types and relationships.","While meta-path-based techniques have long been recognized for their ability to capture semantic affinities among nodes, their dependence on manual specification poses a significant limitation.","In contrast, matrix-focused methods accelerate processing by utilizing structural cues but often overlook contextual richness.","In this paper, we challenge the current paradigm by introducing ontology as a fundamental semantic primitive within complex graphs.","Our goal is to integrate the strengths of both matrix-centric and meta-path-based approaches into a unified framework.","We propose perturbation Ontology-based Graph Attention Networks (POGAT), a novel methodology that combines ontology subgraphs with an advanced self-supervised learning paradigm to achieve a deep contextual understanding.","The core innovation of POGAT lies in our enhanced homogeneous perturbing scheme designed to generate rigorous negative samples, encouraging the model to explore minimal contextual features more thoroughly.","Through extensive empirical evaluations, we demonstrate that POGAT significantly outperforms state-of-the-art baselines, achieving a groundbreaking improvement of up to 10.78\\% in F1-score for the critical task of link prediction and 12.01\\% in Micro-F1 for the critical task of node classification."],"url":"http://arxiv.org/abs/2411.18520v1"}
{"created":"2024-11-27 17:12:14","title":"Towards Motion Compensation in Autonomous Robotic Subretinal Injections","abstract":"Exudative (wet) age-related macular degeneration (AMD) is a leading cause of vision loss in older adults, typically treated with intravitreal injections. Emerging therapies, such as subretinal injections of stem cells, gene therapy, small molecules or RPE cells require precise delivery to avoid damaging delicate retinal structures. Autonomous robotic systems can potentially offer the necessary precision for these procedures. This paper presents a novel approach for motion compensation in robotic subretinal injections, utilizing real-time Optical Coherence Tomography (OCT). The proposed method leverages B$^{5}$-scans, a rapid acquisition of small-volume OCT data, for dynamic tracking of retinal motion along the Z-axis, compensating for physiological movements such as breathing and heartbeat. Validation experiments on \\textit{ex vivo} porcine eyes revealed challenges in maintaining a consistent tool-to-retina distance, with deviations of up to 200 $\\mu m$ for 100 $\\mu m$ amplitude motions and over 80 $\\mu m$ for 25 $\\mu m$ amplitude motions over one minute. Subretinal injections faced additional difficulties, with horizontal shifts causing the needle to move off-target and inject into the vitreous. These results highlight the need for improved motion prediction and horizontal stability to enhance the accuracy and safety of robotic subretinal procedures.","sentences":["Exudative (wet) age-related macular degeneration (AMD) is a leading cause of vision loss in older adults, typically treated with intravitreal injections.","Emerging therapies, such as subretinal injections of stem cells, gene therapy, small molecules or RPE cells require precise delivery to avoid damaging delicate retinal structures.","Autonomous robotic systems can potentially offer the necessary precision for these procedures.","This paper presents a novel approach for motion compensation in robotic subretinal injections, utilizing real-time Optical Coherence Tomography (OCT).","The proposed method leverages B$^{5}$-scans, a rapid acquisition of small-volume OCT data, for dynamic tracking of retinal motion along the Z-axis, compensating for physiological movements such as breathing and heartbeat.","Validation experiments on \\textit{ex vivo} porcine eyes revealed challenges in maintaining a consistent tool-to-retina distance, with deviations of up to 200 $\\mu m$ for 100 $\\mu m$ amplitude motions and over 80 $\\mu m$ for 25 $\\mu m$ amplitude motions over one minute.","Subretinal injections faced additional difficulties, with horizontal shifts causing the needle to move off-target and inject into the vitreous.","These results highlight the need for improved motion prediction and horizontal stability to enhance the accuracy and safety of robotic subretinal procedures."],"url":"http://arxiv.org/abs/2411.18521v1"}
{"created":"2024-11-27 17:10:39","title":"A Talent-infused Policy-gradient Approach to Efficient Co-Design of Morphology and Task Allocation Behavior of Multi-Robot Systems","abstract":"Interesting and efficient collective behavior observed in multi-robot or swarm systems emerges from the individual behavior of the robots. The functional space of individual robot behaviors is in turn shaped or constrained by the robot's morphology or physical design. Thus the full potential of multi-robot systems can be realized by concurrently optimizing the morphology and behavior of individual robots, informed by the environment's feedback about their collective performance, as opposed to treating morphology and behavior choices disparately or in sequence (the classical approach). This paper presents an efficient concurrent design or co-design method to explore this potential and understand how morphology choices impact collective behavior, particularly in an MRTA problem focused on a flood response scenario, where the individual behavior is designed via graph reinforcement learning. Computational efficiency in this case is attributed to a new way of near exact decomposition of the co-design problem into a series of simpler optimization and learning problems. This is achieved through i) the identification and use of the Pareto front of Talent metrics that represent morphology-dependent robot capabilities, and ii) learning the selection of Talent best trade-offs and individual robot policy that jointly maximizes the MRTA performance. Applied to a multi-unmanned aerial vehicle flood response use case, the co-design outcomes are shown to readily outperform sequential design baselines. Significant differences in morphology and learned behavior are also observed when comparing co-designed single robot vs. co-designed multi-robot systems for similar operations.","sentences":["Interesting and efficient collective behavior observed in multi-robot or swarm systems emerges from the individual behavior of the robots.","The functional space of individual robot behaviors is in turn shaped or constrained by the robot's morphology or physical design.","Thus the full potential of multi-robot systems can be realized by concurrently optimizing the morphology and behavior of individual robots, informed by the environment's feedback about their collective performance, as opposed to treating morphology and behavior choices disparately or in sequence (the classical approach).","This paper presents an efficient concurrent design or co-design method to explore this potential and understand how morphology choices impact collective behavior, particularly in an MRTA problem focused on a flood response scenario, where the individual behavior is designed via graph reinforcement learning.","Computational efficiency in this case is attributed to a new way of near exact decomposition of the co-design problem into a series of simpler optimization and learning problems.","This is achieved through i) the identification and use of the Pareto front of Talent metrics that represent morphology-dependent robot capabilities, and ii) learning the selection of Talent best trade-offs and individual robot policy that jointly maximizes the MRTA performance.","Applied to a multi-unmanned aerial vehicle flood response use case, the co-design outcomes are shown to readily outperform sequential design baselines.","Significant differences in morphology and learned behavior are also observed when comparing co-designed single robot vs. co-designed multi-robot systems for similar operations."],"url":"http://arxiv.org/abs/2411.18519v1"}
{"created":"2024-11-27 17:03:00","title":"Living off the Analyst: Harvesting Features from Yara Rules for Malware Detection","abstract":"A strategy used by malicious actors is to \"live off the land,\" where benign systems and tools already available on a victim's systems are used and repurposed for the malicious actor's intent. In this work, we ask if there is a way for anti-virus developers to similarly re-purpose existing work to improve their malware detection capability. We show that this is plausible via YARA rules, which use human-written signatures to detect specific malware families, functionalities, or other markers of interest. By extracting sub-signatures from publicly available YARA rules, we assembled a set of features that can more effectively discriminate malicious samples from benign ones. Our experiments demonstrate that these features add value beyond traditional features on the EMBER 2018 dataset. Manual analysis of the added sub-signatures shows a power-law behavior in a combination of features that are specific and unique, as well as features that occur often. A prior expectation may be that the features would be limited in being overly specific to unique malware families. This behavior is observed, and is apparently useful in practice. In addition, we also find sub-signatures that are dual-purpose (e.g., detecting virtual machine environments) or broadly generic (e.g., DLL imports).","sentences":["A strategy used by malicious actors is to \"live off the land,\" where benign systems and tools already available on a victim's systems are used and repurposed for the malicious actor's intent.","In this work, we ask if there is a way for anti-virus developers to similarly re-purpose existing work to improve their malware detection capability.","We show that this is plausible via YARA rules, which use human-written signatures to detect specific malware families, functionalities, or other markers of interest.","By extracting sub-signatures from publicly available YARA rules, we assembled a set of features that can more effectively discriminate malicious samples from benign ones.","Our experiments demonstrate that these features add value beyond traditional features on the EMBER 2018 dataset.","Manual analysis of the added sub-signatures shows a power-law behavior in a combination of features that are specific and unique, as well as features that occur often.","A prior expectation may be that the features would be limited in being overly specific to unique malware families.","This behavior is observed, and is apparently useful in practice.","In addition, we also find sub-signatures that are dual-purpose (e.g., detecting virtual machine environments) or broadly generic (e.g., DLL imports)."],"url":"http://arxiv.org/abs/2411.18516v1"}
{"created":"2024-11-27 17:00:34","title":"Enhancing weed detection performance by means of GenAI-based image augmentation","abstract":"Precise weed management is essential for sustaining crop productivity and ecological balance. Traditional herbicide applications face economic and environmental challenges, emphasizing the need for intelligent weed control systems powered by deep learning. These systems require vast amounts of high-quality training data. The reality of scarcity of well-annotated training data, however, is often addressed through generating more data using data augmentation. Nevertheless, conventional augmentation techniques such as random flipping, color changes, and blurring lack sufficient fidelity and diversity. This paper investigates a generative AI-based augmentation technique that uses the Stable Diffusion model to produce diverse synthetic images that improve the quantity and quality of training datasets for weed detection models. Moreover, this paper explores the impact of these synthetic images on the performance of real-time detection systems, thus focusing on compact CNN-based models such as YOLO nano for edge devices. The experimental results show substantial improvements in mean Average Precision (mAP50 and mAP50-95) scores for YOLO models trained with generative AI-augmented datasets, demonstrating the promising potential of synthetic data to enhance model robustness and accuracy.","sentences":["Precise weed management is essential for sustaining crop productivity and ecological balance.","Traditional herbicide applications face economic and environmental challenges, emphasizing the need for intelligent weed control systems powered by deep learning.","These systems require vast amounts of high-quality training data.","The reality of scarcity of well-annotated training data, however, is often addressed through generating more data using data augmentation.","Nevertheless, conventional augmentation techniques such as random flipping, color changes, and blurring lack sufficient fidelity and diversity.","This paper investigates a generative AI-based augmentation technique that uses the Stable Diffusion model to produce diverse synthetic images that improve the quantity and quality of training datasets for weed detection models.","Moreover, this paper explores the impact of these synthetic images on the performance of real-time detection systems, thus focusing on compact CNN-based models such as YOLO nano for edge devices.","The experimental results show substantial improvements in mean Average Precision (mAP50 and mAP50-95) scores for YOLO models trained with generative AI-augmented datasets, demonstrating the promising potential of synthetic data to enhance model robustness and accuracy."],"url":"http://arxiv.org/abs/2411.18513v1"}
{"created":"2024-11-27 16:50:42","title":"At First Contact: Stiffness Estimation Using Vibrational Information for Prosthetic Grasp Modulation","abstract":"Stiffness estimation is crucial for delicate object manipulation in robotic and prosthetic hands but remains challenging due to dependence on force and displacement measurement and real-time sensory integration. This study presents a piezoelectric sensing framework for stiffness estimation at first contact during pinch grasps, addressing the limitations of traditional force-based methods. Inspired by human skin, a multimodal tactile sensor that captures vibrational and force data is developed and integrated into a prosthetic hand's fingertip. Machine learning models, including support vector machines and convolutional neural networks, demonstrate that vibrational signals within the critical 15 ms after first contact reliably encode stiffness, achieving classification accuracies up to 98.6\\% and regression errors as low as 2.39 Shore A on real-world objects of varying stiffness. Inference times of less than 1.5 ms are significantly faster than the average grasp closure time (16.65 ms in our dataset), enabling real-time stiffness estimation before the object is fully grasped. By leveraging the transient asymmetry in grasp dynamics, where one finger contacts the object before the others, this method enables early grasp modulation, enhancing safety and intuitiveness in prosthetic hands while offering broad applications in robotics.","sentences":["Stiffness estimation is crucial for delicate object manipulation in robotic and prosthetic hands but remains challenging due to dependence on force and displacement measurement and real-time sensory integration.","This study presents a piezoelectric sensing framework for stiffness estimation at first contact during pinch grasps, addressing the limitations of traditional force-based methods.","Inspired by human skin, a multimodal tactile sensor that captures vibrational and force data is developed and integrated into a prosthetic hand's fingertip.","Machine learning models, including support vector machines and convolutional neural networks, demonstrate that vibrational signals within the critical 15 ms after first contact reliably encode stiffness, achieving classification accuracies up to 98.6\\% and regression errors as low as 2.39 Shore A on real-world objects of varying stiffness.","Inference times of less than 1.5 ms are significantly faster than the average grasp closure time (16.65 ms in our dataset), enabling real-time stiffness estimation before the object is fully grasped.","By leveraging the transient asymmetry in grasp dynamics, where one finger contacts the object before the others, this method enables early grasp modulation, enhancing safety and intuitiveness in prosthetic hands while offering broad applications in robotics."],"url":"http://arxiv.org/abs/2411.18507v1"}
{"created":"2024-11-27 16:48:24","title":"LLM-ABBA: Understand time series via symbolic approximation","abstract":"The success of large language models (LLMs) for time series has been demonstrated in previous work. Utilizing a symbolic time series representation, one can efficiently bridge the gap between LLMs and time series. However, the remaining challenge is to exploit the semantic information hidden in time series by using symbols or existing tokens of LLMs, while aligning the embedding space of LLMs according to the hidden information of time series. The symbolic time series approximation (STSA) method called adaptive Brownian bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in preserving salient time series features by modeling time series patterns in terms of amplitude and period while using existing tokens of LLMs.   In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA into large language models for various downstream time series tasks. By symbolizing time series, LLM-ABBA compares favorably to the recent state-of-the-art (SOTA) in UCR and three medical time series classification tasks. Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to \\kc{avoid obvious drifting} during prediction tasks by significantly mitigating the effects of cumulative error arising from misused symbols during the transition from symbols to numerical values. In time series regression tasks, LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER) benchmarks. LLM-ABBA also shows competitive prediction capability compared to recent SOTA time series prediction results. We believe this framework can also seamlessly extend to other time series tasks.","sentences":["The success of large language models (LLMs) for time series has been demonstrated in previous work.","Utilizing a symbolic time series representation, one can efficiently bridge the gap between LLMs and time series.","However, the remaining challenge is to exploit the semantic information hidden in time series by using symbols or existing tokens of LLMs, while aligning the embedding space of LLMs according to the hidden information of time series.","The symbolic time series approximation (STSA) method called adaptive Brownian bridge-based symbolic aggregation (ABBA) shows outstanding efficacy in preserving salient time series features by modeling time series patterns in terms of amplitude and period while using existing tokens of LLMs.   ","In this paper, we introduce a method, called LLM-ABBA, that integrates ABBA into large language models for various downstream time series tasks.","By symbolizing time series, LLM-ABBA compares favorably to the recent state-of-the-art (SOTA) in UCR and three medical time series classification tasks.","Meanwhile, a fixed-polygonal chain trick in ABBA is introduced to \\kc{avoid obvious drifting} during prediction tasks by significantly mitigating the effects of cumulative error arising from misused symbols during the transition from symbols to numerical values.","In time series regression tasks, LLM-ABBA achieves the new SOTA on Time Series Extrinsic Regression (TSER) benchmarks.","LLM-ABBA also shows competitive prediction capability compared to recent SOTA time series prediction results.","We believe this framework can also seamlessly extend to other time series tasks."],"url":"http://arxiv.org/abs/2411.18506v1"}
{"created":"2024-11-27 16:40:29","title":"Personalised Serious Games and Gamification in Healthcare: Survey and Future Research Directions","abstract":"Serious games and gamification (SGG) in eHealth have positive health impacts, but a personalized approach is needed due to diverse user contexts. This introduces challenges in achieving personalization in SGG. A literature search on Web of Science and PubMed identified 31 articles: 22 on serious games and 9 on gamification. These strategies are most applied in behavior change and rehabilitation, with machine learning and AI showing promise for personalization. Reusability of personalisation algorithms and domain knowledge is underemphasized, reported in only 10 articles. Future research should standardize personalized SGG development, focusing on component reuse to streamline design and enhance evaluation.","sentences":["Serious games and gamification (SGG) in eHealth have positive health impacts, but a personalized approach is needed due to diverse user contexts.","This introduces challenges in achieving personalization in SGG.","A literature search on Web of Science and PubMed identified 31 articles: 22 on serious games and 9 on gamification.","These strategies are most applied in behavior change and rehabilitation, with machine learning and AI showing promise for personalization.","Reusability of personalisation algorithms and domain knowledge is underemphasized, reported in only 10 articles.","Future research should standardize personalized SGG development, focusing on component reuse to streamline design and enhance evaluation."],"url":"http://arxiv.org/abs/2411.18500v1"}
{"created":"2024-11-27 16:39:04","title":"GATE OpenING: A Comprehensive Benchmark for Judging Open-ended Interleaved Image-Text Generation","abstract":"Multimodal Large Language Models (MLLMs) have made significant strides in visual understanding and generation tasks. However, generating interleaved image-text content remains a challenge, which requires integrated multimodal understanding and generation abilities. While the progress in unified models offers new solutions, existing benchmarks are insufficient for evaluating these methods due to data size and diversity limitations. To bridge this gap, we introduce GATE OpenING (OpenING), a comprehensive benchmark comprising 5,400 high-quality human-annotated instances across 56 real-world tasks. OpenING covers diverse daily scenarios such as travel guide, design, and brainstorming, offering a robust platform for challenging interleaved generation methods. In addition, we present IntJudge, a judge model for evaluating open-ended multimodal generation methods. Trained with a novel data pipeline, our IntJudge achieves an agreement rate of 82. 42% with human judgments, outperforming GPT-based evaluators by 11.34%. Extensive experiments on OpenING reveal that current interleaved generation methods still have substantial room for improvement. Key findings on interleaved image-text generation are further presented to guide the development of next-generation models. The OpenING is open-sourced at https://opening.github.io.","sentences":["Multimodal Large Language Models (MLLMs) have made significant strides in visual understanding and generation tasks.","However, generating interleaved image-text content remains a challenge, which requires integrated multimodal understanding and generation abilities.","While the progress in unified models offers new solutions, existing benchmarks are insufficient for evaluating these methods due to data size and diversity limitations.","To bridge this gap, we introduce GATE OpenING (OpenING), a comprehensive benchmark comprising 5,400 high-quality human-annotated instances across 56 real-world tasks.","OpenING covers diverse daily scenarios such as travel guide, design, and brainstorming, offering a robust platform for challenging interleaved generation methods.","In addition, we present IntJudge, a judge model for evaluating open-ended multimodal generation methods.","Trained with a novel data pipeline, our IntJudge achieves an agreement rate of 82.","42% with human judgments, outperforming GPT-based evaluators by 11.34%.","Extensive experiments on OpenING reveal that current interleaved generation methods still have substantial room for improvement.","Key findings on interleaved image-text generation are further presented to guide the development of next-generation models.","The OpenING is open-sourced at https://opening.github.io."],"url":"http://arxiv.org/abs/2411.18499v1"}
{"created":"2024-11-27 16:38:57","title":"Collective decision making by embodied neural agents","abstract":"Collective decision making using simple social interactions has been studied in many types of multi-agent systems, including robot swarms and human social networks. However, existing multi-agent studies have rarely modeled the neural dynamics that underlie sensorimotor coordination in embodied biological agents. In this study, we investigated collective decisions that resulted from sensorimotor coordination among agents with simple neural dynamics. We equipped our agents with a model of minimal neural dynamics based on the coordination dynamics framework, and embedded them in an environment with a stimulus gradient. In our single-agent setup, the decision between two stimulus sources depends solely on the coordination of the agent's neural dynamics with its environment. In our multi-agent setup, that same decision also depends on the sensorimotor coordination between agents, via their simple social interactions. Our results show that the success of collective decisions depended on a balance of intra-agent, inter-agent, and agent-environment coupling, and we use these results to identify the influences of environmental factors on decision difficulty. More generally, our results demonstrate the impact of intra- and inter-brain coordination dynamics on collective behavior, can contribute to existing knowledge on the functional role of inter-agent synchrony, and are relevant to ongoing developments in neuro-AI and self-organized multi-agent systems.","sentences":["Collective decision making using simple social interactions has been studied in many types of multi-agent systems, including robot swarms and human social networks.","However, existing multi-agent studies have rarely modeled the neural dynamics that underlie sensorimotor coordination in embodied biological agents.","In this study, we investigated collective decisions that resulted from sensorimotor coordination among agents with simple neural dynamics.","We equipped our agents with a model of minimal neural dynamics based on the coordination dynamics framework, and embedded them in an environment with a stimulus gradient.","In our single-agent setup, the decision between two stimulus sources depends solely on the coordination of the agent's neural dynamics with its environment.","In our multi-agent setup, that same decision also depends on the sensorimotor coordination between agents, via their simple social interactions.","Our results show that the success of collective decisions depended on a balance of intra-agent, inter-agent, and agent-environment coupling, and we use these results to identify the influences of environmental factors on decision difficulty.","More generally, our results demonstrate the impact of intra- and inter-brain coordination dynamics on collective behavior, can contribute to existing knowledge on the functional role of inter-agent synchrony, and are relevant to ongoing developments in neuro-AI and self-organized multi-agent systems."],"url":"http://arxiv.org/abs/2411.18498v1"}
{"created":"2024-11-27 16:38:34","title":"Multiple Choice Learning for Efficient Speech Separation with Many Speakers","abstract":"Training speech separation models in the supervised setting raises a permutation problem: finding the best assignation between the model predictions and the ground truth separated signals. This inherently ambiguous task is customarily solved using Permutation Invariant Training (PIT). In this article, we instead consider using the Multiple Choice Learning (MCL) framework, which was originally introduced to tackle ambiguous tasks. We demonstrate experimentally on the popular WSJ0-mix and LibriMix benchmarks that MCL matches the performances of PIT, while being computationally advantageous. This opens the door to a promising research direction, as MCL can be naturally extended to handle a variable number of speakers, or to tackle speech separation in the unsupervised setting.","sentences":["Training speech separation models in the supervised setting raises a permutation problem: finding the best assignation between the model predictions and the ground truth separated signals.","This inherently ambiguous task is customarily solved using Permutation Invariant Training (PIT).","In this article, we instead consider using the Multiple Choice Learning (MCL) framework, which was originally introduced to tackle ambiguous tasks.","We demonstrate experimentally on the popular WSJ0-mix and LibriMix benchmarks that MCL matches the performances of PIT, while being computationally advantageous.","This opens the door to a promising research direction, as MCL can be naturally extended to handle a variable number of speakers, or to tackle speech separation in the unsupervised setting."],"url":"http://arxiv.org/abs/2411.18497v1"}
{"created":"2024-11-27 16:28:54","title":"SPTTE: A Spatiotemporal Probabilistic Framework for Travel Time Estimation","abstract":"Accurate travel time estimation is essential for navigation and itinerary planning. While existing research employs probabilistic modeling to assess travel time uncertainty and account for correlations between multiple trips, modeling the temporal variability of multi-trip travel time distributions remains a significant challenge. Capturing the evolution of joint distributions requires large, well-organized datasets; however, real-world trip data are often temporally sparse and spatially unevenly distributed. To address this issue, we propose SPTTE, a spatiotemporal probabilistic framework that models the evolving joint distribution of multi-trip travel times by formulating the estimation task as a spatiotemporal stochastic process regression problem with fragmented observations. SPTTE incorporates an RNN-based temporal Gaussian process parameterization to regularize sparse observations and capture temporal dependencies. Additionally, it employs a prior-based heterogeneity smoothing strategy to correct unreliable learning caused by unevenly distributed trips, effectively modeling temporal variability under sparse and uneven data distributions. Evaluations on real-world datasets demonstrate that SPTTE outperforms state-of-the-art deterministic and probabilistic methods by over 10.13%. Ablation studies and visualizations further confirm the effectiveness of the model components.","sentences":["Accurate travel time estimation is essential for navigation and itinerary planning.","While existing research employs probabilistic modeling to assess travel time uncertainty and account for correlations between multiple trips, modeling the temporal variability of multi-trip travel time distributions remains a significant challenge.","Capturing the evolution of joint distributions requires large, well-organized datasets; however, real-world trip data are often temporally sparse and spatially unevenly distributed.","To address this issue, we propose SPTTE, a spatiotemporal probabilistic framework that models the evolving joint distribution of multi-trip travel times by formulating the estimation task as a spatiotemporal stochastic process regression problem with fragmented observations.","SPTTE incorporates an RNN-based temporal Gaussian process parameterization to regularize sparse observations and capture temporal dependencies.","Additionally, it employs a prior-based heterogeneity smoothing strategy to correct unreliable learning caused by unevenly distributed trips, effectively modeling temporal variability under sparse and uneven data distributions.","Evaluations on real-world datasets demonstrate that SPTTE outperforms state-of-the-art deterministic and probabilistic methods by over 10.13%.","Ablation studies and visualizations further confirm the effectiveness of the model components."],"url":"http://arxiv.org/abs/2411.18484v1"}
{"created":"2024-11-27 16:23:03","title":"A Novel Q-stem Connected Architecture for Beyond-Diagonal Reconfigurable Intelligent Surfaces","abstract":"Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has garnered significant research interest recently due to its ability to generalize existing reconfigurable intelligent surface (RIS) architectures and provide enhanced performance through flexible inter-connection among RIS elements. However, current BD-RIS designs often face challenges related to high circuit complexity and computational complexity, and there is limited study on the trade-off between system performance and circuit complexity. To address these issues, in this work, we propose a novel BD-RIS architecture named Q-stem connected RIS that integrates the characteristics of existing single connected, tree connected, and fully connected BD-RIS, facilitating an effective trade-off between system performance and circuit complexity. Additionally, we propose two algorithms to design the RIS scattering matrix for a Q-stem connected RIS aided multi-user broadcast channels, namely, a low-complexity least squares (LS) algorithm and a suboptimal LS-based quasi-Newton algorithm. Simulations show that the proposed architecture is capable of attaining the sum channel gain achieved by fully connected RIS while reducing the circuit complexity. Moreover, the proposed LS-based quasi-Newton algorithm significantly outperforms the baselines, while the LS algorithm provides comparable performance with a substantial reduction in computational complexity.","sentences":["Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has garnered significant research interest recently due to its ability to generalize existing reconfigurable intelligent surface (RIS) architectures and provide enhanced performance through flexible inter-connection among RIS elements.","However, current BD-RIS designs often face challenges related to high circuit complexity and computational complexity, and there is limited study on the trade-off between system performance and circuit complexity.","To address these issues, in this work, we propose a novel BD-RIS architecture named Q-stem connected RIS that integrates the characteristics of existing single connected, tree connected, and fully connected BD-RIS, facilitating an effective trade-off between system performance and circuit complexity.","Additionally, we propose two algorithms to design the RIS scattering matrix for a Q-stem connected RIS aided multi-user broadcast channels, namely, a low-complexity least squares (LS) algorithm and a suboptimal LS-based quasi-Newton algorithm.","Simulations show that the proposed architecture is capable of attaining the sum channel gain achieved by fully connected RIS while reducing the circuit complexity.","Moreover, the proposed LS-based quasi-Newton algorithm significantly outperforms the baselines, while the LS algorithm provides comparable performance with a substantial reduction in computational complexity."],"url":"http://arxiv.org/abs/2411.18480v1"}
{"created":"2024-11-27 16:22:33","title":"SoK: Watermarking for AI-Generated Content","abstract":"As the outputs of generative AI (GenAI) techniques improve in quality, it becomes increasingly challenging to distinguish them from human-created content. Watermarking schemes are a promising approach to address the problem of distinguishing between AI and human-generated content. These schemes embed hidden signals within AI-generated content to enable reliable detection. While watermarking is not a silver bullet for addressing all risks associated with GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by combating misinformation and deception. This paper presents a comprehensive overview of watermarking techniques for GenAI, beginning with the need for watermarking from historical and regulatory perspectives. We formalize the definitions and desired properties of watermarking schemes and examine the key objectives and threat models for existing approaches. Practical evaluation strategies are also explored, providing insights into the development of robust watermarking techniques capable of resisting various attacks. Additionally, we review recent representative works, highlight open challenges, and discuss potential directions for this emerging field. By offering a thorough understanding of watermarking in GenAI, this work aims to guide researchers in advancing watermarking methods and applications, and support policymakers in addressing the broader implications of GenAI.","sentences":["As the outputs of generative AI (GenAI) techniques improve in quality, it becomes increasingly challenging to distinguish them from human-created content.","Watermarking schemes are a promising approach to address the problem of distinguishing between AI and human-generated content.","These schemes embed hidden signals within AI-generated content to enable reliable detection.","While watermarking is not a silver bullet for addressing all risks associated with GenAI, it can play a crucial role in enhancing AI safety and trustworthiness by combating misinformation and deception.","This paper presents a comprehensive overview of watermarking techniques for GenAI, beginning with the need for watermarking from historical and regulatory perspectives.","We formalize the definitions and desired properties of watermarking schemes and examine the key objectives and threat models for existing approaches.","Practical evaluation strategies are also explored, providing insights into the development of robust watermarking techniques capable of resisting various attacks.","Additionally, we review recent representative works, highlight open challenges, and discuss potential directions for this emerging field.","By offering a thorough understanding of watermarking in GenAI, this work aims to guide researchers in advancing watermarking methods and applications, and support policymakers in addressing the broader implications of GenAI."],"url":"http://arxiv.org/abs/2411.18479v1"}
{"created":"2024-11-27 16:19:00","title":"Beyond Examples: High-level Automated Reasoning Paradigm in In-Context Learning via MCTS","abstract":"In-context Learning (ICL) enables large language models (LLMs) to tackle downstream tasks through sophisticated prompting and high-quality demonstrations. However, this traditional ICL paradigm shows limitations when facing complex mathematical reasoning tasks, primarily due to its heavy dependence on example quality and the necessity for human intervention in challenging scenarios. To address these limitations, this paper presents HiAR-ICL, a \\textbf{Hi}gh-level \\textbf{A}utomated \\textbf{R}easoning paradigm in \\textbf{ICL} that shifts focus from specific examples to abstract thinking patterns, extending the conventional concept of context in ICL. HiAR-ICL introduces five atomic reasoning actions as fundamental components for constructing chain-structured patterns. Using Monte Carlo Tree Search, we explore reasoning paths and construct thought cards to guide subsequent inference. We then develop a cognitive complexity framework that dynamically matches problems with appropriate thought cards. Experimental results demonstrate HiAR-ICL's effectiveness, achieving state-of-the-art accuracy (79.6$\\%$) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o (76.6$\\%$) and Claude 3.5 (71.1$\\%$).","sentences":["In-context Learning (ICL) enables large language models (LLMs) to tackle downstream tasks through sophisticated prompting and high-quality demonstrations.","However, this traditional ICL paradigm shows limitations when facing complex mathematical reasoning tasks, primarily due to its heavy dependence on example quality and the necessity for human intervention in challenging scenarios.","To address these limitations, this paper presents HiAR-ICL, a \\textbf{Hi}gh-level \\textbf{A}utomated \\textbf{R}easoning paradigm in \\textbf{ICL} that shifts focus from specific examples to abstract thinking patterns, extending the conventional concept of context in ICL.","HiAR-ICL introduces five atomic reasoning actions as fundamental components for constructing chain-structured patterns.","Using Monte Carlo Tree Search, we explore reasoning paths and construct thought cards to guide subsequent inference.","We then develop a cognitive complexity framework that dynamically matches problems with appropriate thought cards.","Experimental results demonstrate HiAR-ICL's effectiveness, achieving state-of-the-art accuracy (79.6$\\%$) on the MATH benchmark with Qwen2.5-7B-Instruct, surpassing GPT-4o (76.6$\\%$) and Claude 3.5 (71.1$\\%$)."],"url":"http://arxiv.org/abs/2411.18478v1"}
{"created":"2024-11-27 16:16:00","title":"A comparison of extended object tracking with multi-modal sensors in indoor environment","abstract":"This paper presents a preliminary study of an efficient object tracking approach, comparing the performance of two different 3D point cloud sensory sources: LiDAR and stereo cameras, which have significant price differences. In this preliminary work, we focus on single object tracking. We first developed a fast heuristic object detector that utilizes prior information about the environment and target. The resulting target points are subsequently fed into an extended object tracking framework, where the target shape is parameterized using a star-convex hypersurface model. Experimental results show that our object tracking method using a stereo camera achieves performance similar to that of a LiDAR sensor, with a cost difference of more than tenfold.","sentences":["This paper presents a preliminary study of an efficient object tracking approach, comparing the performance of two different 3D point cloud sensory sources: LiDAR and stereo cameras, which have significant price differences.","In this preliminary work, we focus on single object tracking.","We first developed a fast heuristic object detector that utilizes prior information about the environment and target.","The resulting target points are subsequently fed into an extended object tracking framework, where the target shape is parameterized using a star-convex hypersurface model.","Experimental results show that our object tracking method using a stereo camera achieves performance similar to that of a LiDAR sensor, with a cost difference of more than tenfold."],"url":"http://arxiv.org/abs/2411.18476v1"}
{"created":"2024-11-27 16:11:52","title":"Weakly Supervised Framework Considering Multi-temporal Information for Large-scale Cropland Mapping with Satellite Imagery","abstract":"Accurately mapping large-scale cropland is crucial for agricultural production management and planning. Currently, the combination of remote sensing data and deep learning techniques has shown outstanding performance in cropland mapping. However, those approaches require massive precise labels, which are labor-intensive. To reduce the label cost, this study presented a weakly supervised framework considering multi-temporal information for large-scale cropland mapping. Specifically, we extract high-quality labels according to their consistency among global land cover (GLC) products to construct the supervised learning signal. On the one hand, to alleviate the overfitting problem caused by the model's over-trust of remaining errors in high-quality labels, we encode the similarity/aggregation of cropland in the visual/spatial domain to construct the unsupervised learning signal, and take it as the regularization term to constrain the supervised part. On the other hand, to sufficiently leverage the plentiful information in the samples without high-quality labels, we also incorporate the unsupervised learning signal in these samples, enriching the diversity of the feature space. After that, to capture the phenological features of croplands, we introduce dense satellite image time series (SITS) to extend the proposed framework in the temporal dimension. We also visualized the high dimensional phenological features to uncover how multi-temporal information benefits cropland extraction, and assessed the method's robustness under conditions of data scarcity. The proposed framework has been experimentally validated for strong adaptability across three study areas (Hunan Province, Southeast France, and Kansas) in large-scale cropland mapping, and the internal mechanism and temporal generalizability are also investigated.","sentences":["Accurately mapping large-scale cropland is crucial for agricultural production management and planning.","Currently, the combination of remote sensing data and deep learning techniques has shown outstanding performance in cropland mapping.","However, those approaches require massive precise labels, which are labor-intensive.","To reduce the label cost, this study presented a weakly supervised framework considering multi-temporal information for large-scale cropland mapping.","Specifically, we extract high-quality labels according to their consistency among global land cover (GLC) products to construct the supervised learning signal.","On the one hand, to alleviate the overfitting problem caused by the model's over-trust of remaining errors in high-quality labels, we encode the similarity/aggregation of cropland in the visual/spatial domain to construct the unsupervised learning signal, and take it as the regularization term to constrain the supervised part.","On the other hand, to sufficiently leverage the plentiful information in the samples without high-quality labels, we also incorporate the unsupervised learning signal in these samples, enriching the diversity of the feature space.","After that, to capture the phenological features of croplands, we introduce dense satellite image time series (SITS) to extend the proposed framework in the temporal dimension.","We also visualized the high dimensional phenological features to uncover how multi-temporal information benefits cropland extraction, and assessed the method's robustness under conditions of data scarcity.","The proposed framework has been experimentally validated for strong adaptability across three study areas (Hunan Province, Southeast France, and Kansas) in large-scale cropland mapping, and the internal mechanism and temporal generalizability are also investigated."],"url":"http://arxiv.org/abs/2411.18475v1"}
{"created":"2024-11-27 16:08:59","title":"HEMGS: A Hybrid Entropy Model for 3D Gaussian Splatting Data Compression","abstract":"Fast progress in 3D Gaussian Splatting (3DGS) has made 3D Gaussians popular for 3D modeling and image rendering, but this creates big challenges in data storage and transmission. To obtain a highly compact 3DGS representation, we propose a hybrid entropy model for Gaussian Splatting (HEMGS) data compression, which comprises two primary components, a hyperprior network and an autoregressive network. To effectively reduce structural redundancy across attributes, we apply a progressive coding algorithm to generate hyperprior features, in which we use previously compressed attributes and location as prior information. In particular, to better extract the location features from these compressed attributes, we adopt a domain-aware and instance-aware architecture to respectively capture domain-aware structural relations without additional storage costs and reveal scene-specific features through MLPs. Additionally, to reduce redundancy within each attribute, we leverage relationships between neighboring compressed elements within the attributes through an autoregressive network. Given its unique structure, we propose an adaptive context coding algorithm with flexible receptive fields to effectively capture adjacent compressed elements. Overall, we integrate our HEMGS into an end-to-end optimized 3DGS compression framework and the extensive experimental results on four benchmarks indicate that our method achieves about 40\\% average reduction in size while maintaining the rendering quality over our baseline method and achieving state-of-the-art compression results.","sentences":["Fast progress in 3D Gaussian Splatting (3DGS) has made 3D Gaussians popular for 3D modeling and image rendering, but this creates big challenges in data storage and transmission.","To obtain a highly compact 3DGS representation, we propose a hybrid entropy model for Gaussian Splatting (HEMGS) data compression, which comprises two primary components, a hyperprior network and an autoregressive network.","To effectively reduce structural redundancy across attributes, we apply a progressive coding algorithm to generate hyperprior features, in which we use previously compressed attributes and location as prior information.","In particular, to better extract the location features from these compressed attributes, we adopt a domain-aware and instance-aware architecture to respectively capture domain-aware structural relations without additional storage costs and reveal scene-specific features through MLPs.","Additionally, to reduce redundancy within each attribute, we leverage relationships between neighboring compressed elements within the attributes through an autoregressive network.","Given its unique structure, we propose an adaptive context coding algorithm with flexible receptive fields to effectively capture adjacent compressed elements.","Overall, we integrate our HEMGS into an end-to-end optimized 3DGS compression framework and the extensive experimental results on four benchmarks indicate that our method achieves about 40\\% average reduction in size while maintaining the rendering quality over our baseline method and achieving state-of-the-art compression results."],"url":"http://arxiv.org/abs/2411.18473v1"}
{"created":"2024-11-27 16:08:46","title":"Isolating authorship from content with semantic embeddings and contrastive learning","abstract":"Authorship has entangled style and content inside. Authors frequently write about the same topics in the same style, so when different authors write about the exact same topic the easiest way out to distinguish them is by understanding the nuances of their style. Modern neural models for authorship can pick up these features using contrastive learning, however, some amount of content leakage is always present. Our aim is to reduce the inevitable impact and correlation between content and authorship. We present a technique to use contrastive learning (InfoNCE) with additional hard negatives synthetically created using a semantic similarity model. This disentanglement technique aims to distance the content embedding space from the style embedding space, leading to embeddings more informed by style. We demonstrate the performance with ablations on two different datasets and compare them on out-of-domain challenges. Improvements are clearly shown on challenging evaluations on prolific authors with up to a 10% increase in accuracy when the settings are particularly hard. Trials on challenges also demonstrate the preservation of zero-shot capabilities of this method as fine tuning.","sentences":["Authorship has entangled style and content inside.","Authors frequently write about the same topics in the same style, so when different authors write about the exact same topic the easiest way out to distinguish them is by understanding the nuances of their style.","Modern neural models for authorship can pick up these features using contrastive learning, however, some amount of content leakage is always present.","Our aim is to reduce the inevitable impact and correlation between content and authorship.","We present a technique to use contrastive learning (InfoNCE) with additional hard negatives synthetically created using a semantic similarity model.","This disentanglement technique aims to distance the content embedding space from the style embedding space, leading to embeddings more informed by style.","We demonstrate the performance with ablations on two different datasets and compare them on out-of-domain challenges.","Improvements are clearly shown on challenging evaluations on prolific authors with up to a 10% increase in accuracy when the settings are particularly hard.","Trials on challenges also demonstrate the preservation of zero-shot capabilities of this method as fine tuning."],"url":"http://arxiv.org/abs/2411.18472v1"}
{"created":"2024-11-27 16:01:51","title":"Parole de pr\u00e9sidents (1958-2022)","abstract":"En plus de soixante ans, huit pr\\'esidents se sont succ\\'ed\\'e \\`a la t\\^ete de la Ve R\\'epublique fran\\c{c}aise (de Gaulle, Pompidou, Giscard d'Estaing, Mitterrand, Chirac, Sarkozy, Hollande, Macron). Apr\\`es avoir pr\\'esent\\'e le corpus de leurs discours -- soit 9202 textes et plus de 20 millions de mots \\'etiquet\\'es -- le style de chacun des pr\\'esidents sera caract\\'eris\\'e \\`a l'aide de leurs vocabulaire (vocables et cat\\'egories grammaticales). Une analyse plus approfondie r\\'ev\\`ele les s\\'equences typiques de chaque locataire de l'\\'Elys\\'ee. Bas\\'ee sur les distances entre l'ensemble des allocutions, une figure illustre les similitudes et diff\\'erences entre les diff\\'erents pr\\'esidents.   Over the past sixty-six years, eight presidents successively headed the Fifth French Republic (de Gaulle, Pompidou, Giscard d'Estaing, Mitterrand, Chirac, Sarkozy, Holland, Macron). After presenting the corpus of their speeches -- 9,202 texts and more than 20 million labelled words -- the style of each of them will be characterized by their vocabulary (lemmas and part-of-speech). A deeper analysis reveals the typical sequences of each tenant of the Elys\\'ee. Based on an intertextual distance between all presidential speeches, a synthesis can be drawn reflecting the similarities and differences between presidents.","sentences":["En plus de soixante ans, huit pr\\'esidents se sont succ\\'ed\\'e \\`a la t\\^ete de la Ve R\\'epublique fran\\c{c}aise (de Gaulle, Pompidou, Giscard d'Estaing, Mitterrand, Chirac, Sarkozy, Hollande, Macron).","Apr\\`es avoir pr\\'esent\\'e le corpus de leurs discours -- soit 9202 textes et plus de 20 millions de mots \\'etiquet\\'es -- le style de chacun des pr\\'esidents sera caract\\'eris\\'e \\`a l'aide de leurs vocabulaire (vocables et cat\\'egories grammaticales).","Une analyse plus approfondie r\\'ev\\`ele les s\\'equences typiques de chaque locataire de l'\\'Elys\\'ee. Bas\\'ee sur les distances entre l'ensemble des allocutions, une figure illustre les similitudes et diff\\'erences entre les diff\\'erents pr\\'esidents.   ","Over the past sixty-six years, eight presidents successively headed the Fifth French Republic (de Gaulle, Pompidou, Giscard d'Estaing, Mitterrand, Chirac, Sarkozy, Holland, Macron).","After presenting the corpus of their speeches -- 9,202 texts and more than 20 million labelled words -- the style of each of them will be characterized by their vocabulary (lemmas and part-of-speech).","A deeper analysis reveals the typical sequences of each tenant of the Elys\\'ee.","Based on an intertextual distance between all presidential speeches, a synthesis can be drawn reflecting the similarities and differences between presidents."],"url":"http://arxiv.org/abs/2411.18468v1"}
{"created":"2024-11-27 15:58:07","title":"Complexity Experts are Task-Discriminative Learners for Any Image Restoration","abstract":"Recent advancements in all-in-one image restoration models have revolutionized the ability to address diverse degradations through a unified framework. However, parameters tied to specific tasks often remain inactive for other tasks, making mixture-of-experts (MoE) architectures a natural extension. Despite this, MoEs often show inconsistent behavior, with some experts unexpectedly generalizing across tasks while others struggle within their intended scope. This hinders leveraging MoEs' computational benefits by bypassing irrelevant experts during inference. We attribute this undesired behavior to the uniform and rigid architecture of traditional MoEs. To address this, we introduce ``complexity experts\" -- flexible expert blocks with varying computational complexity and receptive fields. A key challenge is assigning tasks to each expert, as degradation complexity is unknown in advance. Thus, we execute tasks with a simple bias toward lower complexity. To our surprise, this preference effectively drives task-specific allocation, assigning tasks to experts with the appropriate complexity. Extensive experiments validate our approach, demonstrating the ability to bypass irrelevant experts during inference while maintaining superior performance. The proposed MoCE-IR model outperforms state-of-the-art methods, affirming its efficiency and practical applicability. The source will be publicly made available at \\href{https://eduardzamfir.github.io/moceir/}{\\texttt{eduardzamfir.github.io/MoCE-IR/}}","sentences":["Recent advancements in all-in-one image restoration models have revolutionized the ability to address diverse degradations through a unified framework.","However, parameters tied to specific tasks often remain inactive for other tasks, making mixture-of-experts (MoE) architectures a natural extension.","Despite this, MoEs often show inconsistent behavior, with some experts unexpectedly generalizing across tasks while others struggle within their intended scope.","This hinders leveraging MoEs' computational benefits by bypassing irrelevant experts during inference.","We attribute this undesired behavior to the uniform and rigid architecture of traditional MoEs.","To address this, we introduce ``complexity experts\" -- flexible expert blocks with varying computational complexity and receptive fields.","A key challenge is assigning tasks to each expert, as degradation complexity is unknown in advance.","Thus, we execute tasks with a simple bias toward lower complexity.","To our surprise, this preference effectively drives task-specific allocation, assigning tasks to experts with the appropriate complexity.","Extensive experiments validate our approach, demonstrating the ability to bypass irrelevant experts during inference while maintaining superior performance.","The proposed MoCE-IR model outperforms state-of-the-art methods, affirming its efficiency and practical applicability.","The source will be publicly made available at \\href{https://eduardzamfir.github.io/moceir/}{\\texttt{eduardzamfir.github.io/MoCE-IR/}}"],"url":"http://arxiv.org/abs/2411.18466v1"}
{"created":"2024-11-27 15:53:17","title":"Draft Model Knows When to Stop: A Self-Verification Length Policy for Speculative Decoding","abstract":"Speculative Decoding (SD) has become an important technique in accelerating the inference speed of large language models. Conventional SD methods employ a fixed draft length, which ignores the token generation difficulty across tasks. Consequently, in this paper, we address such an issue and introduce SVIP - a difficulty-aware dynamic draft length policy for speculative decoding systems. Based on a theoretical lower bound of draft token acceptance rate and its inference-time approximation, SVIP adaptively determines the lengths of draft sequences based on the entropy of each draft token distribution. Experimental results on mainstream SD benchmarks and frameworks demonstrate the superior performance of SVIP, achieving up to 20\\% walltime speedup on SpecBench over baseline SD methods and 60\\% speedup on MT-Bench for long-form generation of up to 8K tokens. Moreover, SVIP is totally training-free and compatible with any existing SD methods that generate draft tokens autoregressively. Experimental results also show that SVIP yields consistent walltime improvement on top of GliDe & CaPE and EAGLE-2.","sentences":["Speculative Decoding (SD) has become an important technique in accelerating the inference speed of large language models.","Conventional SD methods employ a fixed draft length, which ignores the token generation difficulty across tasks.","Consequently, in this paper, we address such an issue and introduce SVIP - a difficulty-aware dynamic draft length policy for speculative decoding systems.","Based on a theoretical lower bound of draft token acceptance rate and its inference-time approximation, SVIP adaptively determines the lengths of draft sequences based on the entropy of each draft token distribution.","Experimental results on mainstream SD benchmarks and frameworks demonstrate the superior performance of SVIP, achieving up to 20\\% walltime speedup on SpecBench over baseline SD methods and 60\\% speedup on MT-Bench for long-form generation of up to 8K tokens.","Moreover, SVIP is totally training-free and compatible with any existing SD methods that generate draft tokens autoregressively.","Experimental results also show that SVIP yields consistent walltime improvement on top of GliDe & CaPE and EAGLE-2."],"url":"http://arxiv.org/abs/2411.18462v1"}
{"created":"2024-11-27 15:48:35","title":"What do physics-informed DeepONets learn? Understanding and improving training for scientific computing applications","abstract":"Physics-informed deep operator networks (DeepONets) have emerged as a promising approach toward numerically approximating the solution of partial differential equations (PDEs). In this work, we aim to develop further understanding of what is being learned by physics-informed DeepONets by assessing the universality of the extracted basis functions and demonstrating their potential toward model reduction with spectral methods. Results provide clarity about measuring the performance of a physics-informed DeepONet through the decays of singular values and expansion coefficients. In addition, we propose a transfer learning approach for improving training for physics-informed DeepONets between parameters of the same PDE as well as across different, but related, PDEs where these models struggle to train well. This approach results in significant error reduction and learned basis functions that are more effective in representing the solution of a PDE.","sentences":["Physics-informed deep operator networks (DeepONets) have emerged as a promising approach toward numerically approximating the solution of partial differential equations (PDEs).","In this work, we aim to develop further understanding of what is being learned by physics-informed DeepONets by assessing the universality of the extracted basis functions and demonstrating their potential toward model reduction with spectral methods.","Results provide clarity about measuring the performance of a physics-informed DeepONet through the decays of singular values and expansion coefficients.","In addition, we propose a transfer learning approach for improving training for physics-informed DeepONets between parameters of the same PDE as well as across different, but related, PDEs where these models struggle to train well.","This approach results in significant error reduction and learned basis functions that are more effective in representing the solution of a PDE."],"url":"http://arxiv.org/abs/2411.18459v1"}
{"created":"2024-11-27 15:46:34","title":"Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification","abstract":"Deep learning models need a sufficient amount of data in order to be able to find the hidden patterns in it. It is the purpose of generative modeling to learn the data distribution, thus allowing us to sample more data and augment the original dataset. In the context of physiological data, and more specifically electrocardiogram (ECG) data, given its sensitive nature and expensive data collection, we can exploit the benefits of generative models in order to enlarge existing datasets and improve downstream tasks, in our case, classification of heart rhythm.   In this work, we explore the usefulness of synthetic data generated with different generative models from Deep Learning namely Diffweave, Time-Diffusion and Time-VQVAE in order to obtain better classification results for two open source multivariate ECG datasets. Moreover, we also investigate the effects of transfer learning, by fine-tuning a synthetically pre-trained model and then progressively adding increasing proportions of real data. We conclude that although the synthetic samples resemble the real ones, the classification improvement when simply augmenting the real dataset is barely noticeable on individual datasets, but when both datasets are merged the results show an increase across all metrics for the classifiers when using synthetic samples as augmented data. From the fine-tuning results the Time-VQVAE generative model has shown to be superior to the others but not powerful enough to achieve results close to a classifier trained with real data only. In addition, methods and metrics for measuring closeness between synthetic data and the real one have been explored as a side effect of the main research questions of this study.","sentences":["Deep learning models need a sufficient amount of data in order to be able to find the hidden patterns in it.","It is the purpose of generative modeling to learn the data distribution, thus allowing us to sample more data and augment the original dataset.","In the context of physiological data, and more specifically electrocardiogram (ECG) data, given its sensitive nature and expensive data collection, we can exploit the benefits of generative models in order to enlarge existing datasets and improve downstream tasks, in our case, classification of heart rhythm.   ","In this work, we explore the usefulness of synthetic data generated with different generative models from Deep Learning namely Diffweave, Time-Diffusion and Time-VQVAE in order to obtain better classification results for two open source multivariate ECG datasets.","Moreover, we also investigate the effects of transfer learning, by fine-tuning a synthetically pre-trained model and then progressively adding increasing proportions of real data.","We conclude that although the synthetic samples resemble the real ones, the classification improvement when simply augmenting the real dataset is barely noticeable on individual datasets, but when both datasets are merged the results show an increase across all metrics for the classifiers when using synthetic samples as augmented data.","From the fine-tuning results the Time-VQVAE generative model has shown to be superior to the others but not powerful enough to achieve results close to a classifier trained with real data only.","In addition, methods and metrics for measuring closeness between synthetic data and the real one have been explored as a side effect of the main research questions of this study."],"url":"http://arxiv.org/abs/2411.18456v1"}
{"created":"2024-11-27 15:42:30","title":"Advancements in Myocardial Infarction Detection and Classification Using Wearable Devices: A Comprehensive Review","abstract":"Myocardial infarction (MI), commonly known as a heart attack, is a critical health condition caused by restricted blood flow to the heart. Early-stage detection through continuous ECG monitoring is essential to minimize irreversible damage. This review explores advancements in MI classification methodologies for wearable devices, emphasizing their potential in real-time monitoring and early diagnosis. It critically examines traditional approaches, such as morphological filtering and wavelet decomposition, alongside cutting-edge techniques, including Convolutional Neural Networks (CNNs) and VLSI-based methods. By synthesizing findings on machine learning, deep learning, and hardware innovations, this paper highlights their strengths, limitations, and future prospects. The integration of these techniques into wearable devices offers promising avenues for efficient, accurate, and energy-aware MI detection, paving the way for next-generation wearable healthcare solutions.","sentences":["Myocardial infarction (MI), commonly known as a heart attack, is a critical health condition caused by restricted blood flow to the heart.","Early-stage detection through continuous ECG monitoring is essential to minimize irreversible damage.","This review explores advancements in MI classification methodologies for wearable devices, emphasizing their potential in real-time monitoring and early diagnosis.","It critically examines traditional approaches, such as morphological filtering and wavelet decomposition, alongside cutting-edge techniques, including Convolutional Neural Networks (CNNs) and VLSI-based methods.","By synthesizing findings on machine learning, deep learning, and hardware innovations, this paper highlights their strengths, limitations, and future prospects.","The integration of these techniques into wearable devices offers promising avenues for efficient, accurate, and energy-aware MI detection, paving the way for next-generation wearable healthcare solutions."],"url":"http://arxiv.org/abs/2411.18451v1"}
{"created":"2024-11-27 15:41:01","title":"A Game-theoretic model of forex trading with stochastic strategies and information asymmetry","abstract":"Interaction strategies for reward in competitive environments are significantly influenced by the nature and extent of available information.In financial markets,particularly foreign exchange(forex),traders operate independently with limited information,often yielding highly unpredictable outcomes.This study introduces a game theoretic framework modeling the market as a strategically active participant,rather than a neutral entity, within a stochastic,imperfect information setting.In this model,the market alternates sequentially with new traders,each trader having limited visibility of the market's moves,while the market observes and counteracts each trader strategy.Through a series of simulations,we show that this information asymmetry enables the market to consistently outperform traders on aggregate.This outcome suggests that real world forex environments may inherently favor market structures with greater informational advantage,challenging the perception of a level playing field.The model provides a basis for simulating skewed information environments,highlighting how strategic imbalances contribute to trader losses.Further optimization of the intelligent market scoring and refined simulations of trader market interactions can enhance predictive analytics for forex,offering a robust tool for market behavior analysis.","sentences":["Interaction strategies for reward in competitive environments are significantly influenced by the nature and extent of available information.","In financial markets,particularly foreign exchange(forex),traders operate independently with limited information,often yielding highly unpredictable outcomes.","This study introduces a game theoretic framework modeling the market as a strategically active participant,rather than a neutral entity, within a stochastic,imperfect information setting.","In this model,the market alternates sequentially with new traders,each trader having limited visibility of the market's moves,while the market observes and counteracts each trader strategy.","Through a series of simulations,we show that this information asymmetry enables the market to consistently outperform traders on aggregate.","This outcome suggests that real world forex environments may inherently favor market structures with greater informational advantage,challenging the perception of a level playing field.","The model provides a basis for simulating skewed information environments,highlighting how strategic imbalances contribute to trader losses.","Further optimization of the intelligent market scoring and refined simulations of trader market interactions can enhance predictive analytics for forex,offering a robust tool for market behavior analysis."],"url":"http://arxiv.org/abs/2411.18448v1"}
{"created":"2024-11-27 15:38:20","title":"Continuous Autoregressive Models with Noise Augmentation Avoid Error Accumulation","abstract":"Autoregressive models are typically applied to sequences of discrete tokens, but recent research indicates that generating sequences of continuous embeddings in an autoregressive manner is also feasible. However, such Continuous Autoregressive Models (CAMs) can suffer from a decline in generation quality over extended sequences due to error accumulation during inference. We introduce a novel method to address this issue by injecting random noise into the input embeddings during training. This procedure makes the model robust against varying error levels at inference. We further reduce error accumulation through an inference procedure that introduces low-level noise. Experiments on musical audio generation show that CAM substantially outperforms existing autoregressive and non-autoregressive approaches while preserving audio quality over extended sequences. This work paves the way for generating continuous embeddings in a purely autoregressive setting, opening new possibilities for real-time and interactive generative applications.","sentences":["Autoregressive models are typically applied to sequences of discrete tokens, but recent research indicates that generating sequences of continuous embeddings in an autoregressive manner is also feasible.","However, such Continuous Autoregressive Models (CAMs) can suffer from a decline in generation quality over extended sequences due to error accumulation during inference.","We introduce a novel method to address this issue by injecting random noise into the input embeddings during training.","This procedure makes the model robust against varying error levels at inference.","We further reduce error accumulation through an inference procedure that introduces low-level noise.","Experiments on musical audio generation show that CAM substantially outperforms existing autoregressive and non-autoregressive approaches while preserving audio quality over extended sequences.","This work paves the way for generating continuous embeddings in a purely autoregressive setting, opening new possibilities for real-time and interactive generative applications."],"url":"http://arxiv.org/abs/2411.18447v1"}
{"created":"2024-11-27 15:35:32","title":"Is my Meeting Summary Good? Estimating Quality with a Multi-LLM Evaluator","abstract":"The quality of meeting summaries generated by natural language generation (NLG) systems is hard to measure automatically. Established metrics such as ROUGE and BERTScore have a relatively low correlation with human judgments and fail to capture nuanced errors. Recent studies suggest using large language models (LLMs), which have the benefit of better context understanding and adaption of error definitions without training on a large number of human preference judgments. However, current LLM-based evaluators risk masking errors and can only serve as a weak proxy, leaving human evaluation the gold standard despite being costly and hard to compare across studies. In this work, we present MESA, an LLM-based framework employing a three-step assessment of individual error types, multi-agent discussion for decision refinement, and feedback-based self-training to refine error definition understanding and alignment with human judgment. We show that MESA's components enable thorough error detection, consistent rating, and adaptability to custom error guidelines. Using GPT-4o as its backbone, MESA achieves mid to high Point-Biserial correlation with human judgment in error detection and mid Spearman and Kendall correlation in reflecting error impact on summary quality, on average 0.25 higher than previous methods. The framework's flexibility in adapting to custom error guidelines makes it suitable for various tasks with limited human-labeled data.","sentences":["The quality of meeting summaries generated by natural language generation (NLG) systems is hard to measure automatically.","Established metrics such as ROUGE and BERTScore have a relatively low correlation with human judgments and fail to capture nuanced errors.","Recent studies suggest using large language models (LLMs), which have the benefit of better context understanding and adaption of error definitions without training on a large number of human preference judgments.","However, current LLM-based evaluators risk masking errors and can only serve as a weak proxy, leaving human evaluation the gold standard despite being costly and hard to compare across studies.","In this work, we present MESA, an LLM-based framework employing a three-step assessment of individual error types, multi-agent discussion for decision refinement, and feedback-based self-training to refine error definition understanding and alignment with human judgment.","We show that MESA's components enable thorough error detection, consistent rating, and adaptability to custom error guidelines.","Using GPT-4o as its backbone, MESA achieves mid to high Point-Biserial correlation with human judgment in error detection and mid Spearman and Kendall correlation in reflecting error impact on summary quality, on average 0.25 higher than previous methods.","The framework's flexibility in adapting to custom error guidelines makes it suitable for various tasks with limited human-labeled data."],"url":"http://arxiv.org/abs/2411.18444v1"}
{"created":"2024-11-27 15:32:58","title":"Efficient Dynamic LiDAR Odometry for Mobile Robots with Structured Point Clouds","abstract":"We propose a real-time dynamic LiDAR odometry pipeline for mobile robots in Urban Search and Rescue (USAR) scenarios. Existing approaches to dynamic object detection often rely on pretrained learned networks or computationally expensive volumetric maps. To enhance efficiency on computationally limited robots, we reuse data between the odometry and detection module. Utilizing a range image segmentation technique and a novel residual-based heuristic, our method distinguishes dynamic from static objects before integrating them into the point cloud map. The approach demonstrates robust object tracking and improved map accuracy in environments with numerous dynamic objects. Even highly non-rigid objects, such as running humans, are accurately detected at point level without prior downsampling of the point cloud and hence, without loss of information. Evaluation on simulated and real-world data validates its computational efficiency. Compared to a state-of-the-art volumetric method, our approach shows comparable detection performance at a fraction of the processing time, adding only 14 ms to the odometry module for dynamic object detection and tracking. The implementation and a new real-world dataset are available as open-source for further research.","sentences":["We propose a real-time dynamic LiDAR odometry pipeline for mobile robots in Urban Search and Rescue (USAR) scenarios.","Existing approaches to dynamic object detection often rely on pretrained learned networks or computationally expensive volumetric maps.","To enhance efficiency on computationally limited robots, we reuse data between the odometry and detection module.","Utilizing a range image segmentation technique and a novel residual-based heuristic, our method distinguishes dynamic from static objects before integrating them into the point cloud map.","The approach demonstrates robust object tracking and improved map accuracy in environments with numerous dynamic objects.","Even highly non-rigid objects, such as running humans, are accurately detected at point level without prior downsampling of the point cloud and hence, without loss of information.","Evaluation on simulated and real-world data validates its computational efficiency.","Compared to a state-of-the-art volumetric method, our approach shows comparable detection performance at a fraction of the processing time, adding only 14 ms to the odometry module for dynamic object detection and tracking.","The implementation and a new real-world dataset are available as open-source for further research."],"url":"http://arxiv.org/abs/2411.18443v1"}
{"created":"2024-11-27 15:29:42","title":"Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning","abstract":"Selection bias poses a critical challenge for fairness in machine learning, as models trained on data that is less representative of the population might exhibit undesirable behavior for underrepresented profiles. Semi-supervised learning strategies like self-training can mitigate selection bias by incorporating unlabeled data into model training to gain further insight into the distribution of the population. However, conventional self-training seeks to include high-confidence data samples, which may reinforce existing model bias and compromise effectiveness. We propose Metric-DST, a diversity-guided self-training strategy that leverages metric learning and its implicit embedding space to counter confidence-based bias through the inclusion of more diverse samples. Metric-DST learned more robust models in the presence of selection bias for generated and real-world datasets with induced bias, as well as a molecular biology prediction task with intrinsic bias. The Metric-DST learning strategy offers a flexible and widely applicable solution to mitigate selection bias and enhance fairness of machine learning models.","sentences":["Selection bias poses a critical challenge for fairness in machine learning, as models trained on data that is less representative of the population might exhibit undesirable behavior for underrepresented profiles.","Semi-supervised learning strategies like self-training can mitigate selection bias by incorporating unlabeled data into model training to gain further insight into the distribution of the population.","However, conventional self-training seeks to include high-confidence data samples, which may reinforce existing model bias and compromise effectiveness.","We propose Metric-DST, a diversity-guided self-training strategy that leverages metric learning and its implicit embedding space to counter confidence-based bias through the inclusion of more diverse samples.","Metric-DST learned more robust models in the presence of selection bias for generated and real-world datasets with induced bias, as well as a molecular biology prediction task with intrinsic bias.","The Metric-DST learning strategy offers a flexible and widely applicable solution to mitigate selection bias and enhance fairness of machine learning models."],"url":"http://arxiv.org/abs/2411.18442v1"}
{"created":"2024-11-27 15:23:36","title":"Personalized Generative AI in VR for Enhanced Engagement: Eye-Tracking Insights into Cultural Heritage Learning through Neapolitan Pizza Making","abstract":"Virtual Reality (VR) and Generative Artificial Intelligence (Gen-AI) are transforming personalized learning, particularly in intangible cultural heritage (ICH) education. However, designing immersive experiences that enhance engagement without overwhelming learners presents a challenge. This study examines the impact of personalized AI narration on user engagement and attention in a VR environment through eye-tracking metrics. In a controlled experiment with 54 participants, we explored three levels of personalization (high, moderate, none) in a Neapolitan pizza-making task, measuring attention and cognitive load through fixation duration, saccade duration, and pupil diameter. Results indicate that high personalization increased engagement by 64.1% over no personalization (p < 0.001). Furthermore, regression analysis reveals specific eye-tracking metrics significantly predict gameplay duration, underscoring eye-tracking's potential to capture real-time engagement. These findings support the use of eye-tracking to inform the development of adaptive VR learning experiences. Future work may integrate subjective assessments to better understand users' underlying motivations.","sentences":["Virtual Reality (VR) and Generative Artificial Intelligence (Gen-AI) are transforming personalized learning, particularly in intangible cultural heritage (ICH) education.","However, designing immersive experiences that enhance engagement without overwhelming learners presents a challenge.","This study examines the impact of personalized AI narration on user engagement and attention in a VR environment through eye-tracking metrics.","In a controlled experiment with 54 participants, we explored three levels of personalization (high, moderate, none) in a Neapolitan pizza-making task, measuring attention and cognitive load through fixation duration, saccade duration, and pupil diameter.","Results indicate that high personalization increased engagement by 64.1% over no personalization (p < 0.001).","Furthermore, regression analysis reveals specific eye-tracking metrics significantly predict gameplay duration, underscoring eye-tracking's potential to capture real-time engagement.","These findings support the use of eye-tracking to inform the development of adaptive VR learning experiences.","Future work may integrate subjective assessments to better understand users' underlying motivations."],"url":"http://arxiv.org/abs/2411.18438v1"}
{"created":"2024-11-27 15:20:11","title":"6G Takes Shape","abstract":"The contours of 6G -- its key technical components and driving requirements -- are finally coming into focus. Through twenty questions and answers, this article defines the important aspects of 6G across four categories. First, we identify the key themes and forces driving the development of 6G, and what will make 6G unique. We argue that 6G requirements and system design will be driven by (i) the tenacious pursuit of spectral (bits/Hz/area), energy (bits/Joule), and cost (bits/dollar) efficiencies, and (ii) three new service enhancements: sensing/localization/awareness, compute, and global broadband/emergency connectivity. Second, we overview the important role of spectrum in 6G, what new spectrum to expect in 6G, and outline how the different bands will be used to provide 6G services. Third, we focus our attention on the 6G physical layer, including waveforms, MIMO advancements, and the potential use of deep learning. Finally, we explore how global connectivity will be achieved in 6G, through non-terrestrial networks as well as low-cost network expansion via disaggregation and O-RAN. Although 6G standardization activities will not begin until late 2025, meaning this article is by definition speculative, our predictions are informed by several years of intensive research and discussions. Our goal is to provide a grounded perspective that will be helpful to both researchers and engineers as we move into the 6G era.","sentences":["The contours of 6G -- its key technical components and driving requirements -- are finally coming into focus.","Through twenty questions and answers, this article defines the important aspects of 6G across four categories.","First, we identify the key themes and forces driving the development of 6G, and what will make 6G unique.","We argue that 6G requirements and system design will be driven by (i) the tenacious pursuit of spectral (bits/Hz/area), energy (bits/Joule), and cost (bits/dollar) efficiencies, and (ii) three new service enhancements: sensing/localization/awareness, compute, and global broadband/emergency connectivity.","Second, we overview the important role of spectrum in 6G, what new spectrum to expect in 6G, and outline how the different bands will be used to provide 6G services.","Third, we focus our attention on the 6G physical layer, including waveforms, MIMO advancements, and the potential use of deep learning.","Finally, we explore how global connectivity will be achieved in 6G, through non-terrestrial networks as well as low-cost network expansion via disaggregation and O-RAN.","Although 6G standardization activities will not begin until late 2025, meaning this article is by definition speculative, our predictions are informed by several years of intensive research and discussions.","Our goal is to provide a grounded perspective that will be helpful to both researchers and engineers as we move into the 6G era."],"url":"http://arxiv.org/abs/2411.18435v1"}
{"created":"2024-11-27 15:16:22","title":"An End-to-End Smart Predict-then-Optimize Framework for Vehicle Relocation Problems in Large-Scale Vehicle Crowd Sensing","abstract":"Ubiquitous mobile devices have catalyzed the development of vehicle crowd sensing (VCS). In particular, vehicle sensing systems show great potential in the flexible acquisition of spatio-temporal urban data through built-in sensors under diverse sensing scenarios. However, vehicle systems often exhibit biased coverage due to the heterogeneous nature of trip requests and routes. To achieve a high sensing coverage, a critical challenge lies in optimally relocating vehicles to minimize the divergence between vehicle distributions and target sensing distributions. Conventional approaches typically employ a two-stage predict-then-optimize (PTO) process: first predicting real-time vehicle distributions and subsequently generating an optimal relocation strategy based on the predictions. However, this approach can lead to suboptimal decision-making due to the propagation of errors from upstream prediction. To this end, we develop an end-to-end Smart Predict-then-Optimize (SPO) framework by integrating optimization into prediction within the deep learning architecture, and the entire framework is trained by minimizing the task-specific matching divergence rather than the upstream prediction error. Methodologically, we formulate the vehicle relocation problem by quadratic programming (QP) and incorporate a novel unrolling approach based on the Alternating Direction Method of Multipliers (ADMM) within the SPO framework to compute gradients of the QP layer, facilitating backpropagation and gradient-based optimization for end-to-end learning. The effectiveness of the proposed framework is validated by real-world taxi datasets in Hong Kong. Utilizing the alternating differentiation method, the general SPO framework presents a novel concept of addressing decision-making problems with uncertainty, demonstrating significant potential for advancing applications in intelligent transportation systems.","sentences":["Ubiquitous mobile devices have catalyzed the development of vehicle crowd sensing (VCS).","In particular, vehicle sensing systems show great potential in the flexible acquisition of spatio-temporal urban data through built-in sensors under diverse sensing scenarios.","However, vehicle systems often exhibit biased coverage due to the heterogeneous nature of trip requests and routes.","To achieve a high sensing coverage, a critical challenge lies in optimally relocating vehicles to minimize the divergence between vehicle distributions and target sensing distributions.","Conventional approaches typically employ a two-stage predict-then-optimize (PTO) process: first predicting real-time vehicle distributions and subsequently generating an optimal relocation strategy based on the predictions.","However, this approach can lead to suboptimal decision-making due to the propagation of errors from upstream prediction.","To this end, we develop an end-to-end Smart Predict-then-Optimize (SPO) framework by integrating optimization into prediction within the deep learning architecture, and the entire framework is trained by minimizing the task-specific matching divergence rather than the upstream prediction error.","Methodologically, we formulate the vehicle relocation problem by quadratic programming (QP) and incorporate a novel unrolling approach based on the Alternating Direction Method of Multipliers (ADMM) within the SPO framework to compute gradients of the QP layer, facilitating backpropagation and gradient-based optimization for end-to-end learning.","The effectiveness of the proposed framework is validated by real-world taxi datasets in Hong Kong.","Utilizing the alternating differentiation method, the general SPO framework presents a novel concept of addressing decision-making problems with uncertainty, demonstrating significant potential for advancing applications in intelligent transportation systems."],"url":"http://arxiv.org/abs/2411.18432v1"}
{"created":"2024-11-27 15:13:33","title":"An AI-Assisted Multi-Agent Dual Dialogue System to Support Mental Health Care Providers","abstract":"We introduce a general-purpose, human-in-the-loop dual dialogue system to support mental health care professionals. The system, co-designed with care providers, is conceptualized to assist them in interacting with care seekers rather than functioning as a fully automated dialogue system solution. The AI assistant within the system reduces the cognitive load of mental health care providers by proposing responses, analyzing conversations to extract pertinent themes, summarizing dialogues, and recommending localized relevant content and internet-based cognitive behavioral therapy exercises. These functionalities are achieved through a multi-agent system design, where each specialized, supportive agent is characterized by a large language model. In evaluating the multi-agent system, we focused specifically on the proposal of responses to emotionally distressed care seekers. We found that the proposed responses matched a reasonable human quality in demonstrating empathy, showing its appropriateness for augmenting the work of mental health care providers.","sentences":["We introduce a general-purpose, human-in-the-loop dual dialogue system to support mental health care professionals.","The system, co-designed with care providers, is conceptualized to assist them in interacting with care seekers rather than functioning as a fully automated dialogue system solution.","The AI assistant within the system reduces the cognitive load of mental health care providers by proposing responses, analyzing conversations to extract pertinent themes, summarizing dialogues, and recommending localized relevant content and internet-based cognitive behavioral therapy exercises.","These functionalities are achieved through a multi-agent system design, where each specialized, supportive agent is characterized by a large language model.","In evaluating the multi-agent system, we focused specifically on the proposal of responses to emotionally distressed care seekers.","We found that the proposed responses matched a reasonable human quality in demonstrating empathy, showing its appropriateness for augmenting the work of mental health care providers."],"url":"http://arxiv.org/abs/2411.18429v1"}
{"created":"2024-11-27 15:10:22","title":"MM-Path: Multi-modal, Multi-granularity Path Representation Learning -- Extended Version","abstract":"Developing effective path representations has become increasingly essential across various fields within intelligent transportation. Although pre-trained path representation learning models have shown improved performance, they predominantly focus on the topological structures from single modality data, i.e., road networks, overlooking the geometric and contextual features associated with path-related images, e.g., remote sensing images. Similar to human understanding, integrating information from multiple modalities can provide a more comprehensive view, enhancing both representation accuracy and generalization. However, variations in information granularity impede the semantic alignment of road network-based paths (road paths) and image-based paths (image paths), while the heterogeneity of multi-modal data poses substantial challenges for effective fusion and utilization. In this paper, we propose a novel Multi-modal, Multi-granularity Path Representation Learning Framework (MM-Path), which can learn a generic path representation by integrating modalities from both road paths and image paths. To enhance the alignment of multi-modal data, we develop a multi-granularity alignment strategy that systematically associates nodes, road sub-paths, and road paths with their corresponding image patches, ensuring the synchronization of both detailed local information and broader global contexts. To address the heterogeneity of multi-modal data effectively, we introduce a graph-based cross-modal residual fusion component designed to comprehensively fuse information across different modalities and granularities. Finally, we conduct extensive experiments on two large-scale real-world datasets under two downstream tasks, validating the effectiveness of the proposed MM-Path. This is an extended version of the paper accepted by KDD 2025.","sentences":["Developing effective path representations has become increasingly essential across various fields within intelligent transportation.","Although pre-trained path representation learning models have shown improved performance, they predominantly focus on the topological structures from single modality data, i.e., road networks, overlooking the geometric and contextual features associated with path-related images, e.g., remote sensing images.","Similar to human understanding, integrating information from multiple modalities can provide a more comprehensive view, enhancing both representation accuracy and generalization.","However, variations in information granularity impede the semantic alignment of road network-based paths (road paths) and image-based paths (image paths), while the heterogeneity of multi-modal data poses substantial challenges for effective fusion and utilization.","In this paper, we propose a novel Multi-modal, Multi-granularity Path Representation Learning Framework (MM-Path), which can learn a generic path representation by integrating modalities from both road paths and image paths.","To enhance the alignment of multi-modal data, we develop a multi-granularity alignment strategy that systematically associates nodes, road sub-paths, and road paths with their corresponding image patches, ensuring the synchronization of both detailed local information and broader global contexts.","To address the heterogeneity of multi-modal data effectively, we introduce a graph-based cross-modal residual fusion component designed to comprehensively fuse information across different modalities and granularities.","Finally, we conduct extensive experiments on two large-scale real-world datasets under two downstream tasks, validating the effectiveness of the proposed MM-Path.","This is an extended version of the paper accepted by KDD 2025."],"url":"http://arxiv.org/abs/2411.18428v1"}
{"created":"2024-11-27 15:07:44","title":"Streamlining Prediction in Bayesian Deep Learning","abstract":"The rising interest in Bayesian deep learning (BDL) has led to a plethora of methods for estimating the posterior distribution. However, efficient computation of inferences, such as predictions, has been largely overlooked with Monte Carlo integration remaining the standard. In this work we examine streamlining prediction in BDL through a single forward pass without sampling. For this we use local linearisation on activation functions and local Gaussian approximations at linear layers. Thus allowing us to analytically compute an approximation to the posterior predictive distribution. We showcase our approach for both MLP and transformers, such as ViT and GPT-2, and assess its performance on regression and classification tasks.","sentences":["The rising interest in Bayesian deep learning (BDL) has led to a plethora of methods for estimating the posterior distribution.","However, efficient computation of inferences, such as predictions, has been largely overlooked with Monte Carlo integration remaining the standard.","In this work we examine streamlining prediction in BDL through a single forward pass without sampling.","For this we use local linearisation on activation functions and local Gaussian approximations at linear layers.","Thus allowing us to analytically compute an approximation to the posterior predictive distribution.","We showcase our approach for both MLP and transformers, such as ViT and GPT-2, and assess its performance on regression and classification tasks."],"url":"http://arxiv.org/abs/2411.18425v1"}
{"created":"2024-11-27 15:07:28","title":"FastSwitch: Optimizing Context Switching Efficiency in Fairness-aware Large Language Model Serving","abstract":"Serving numerous users and requests concurrently requires good fairness in Large Language Models (LLMs) serving system. This ensures that, at the same cost, the system can meet the Service Level Objectives (SLOs) of more users , such as time to first token (TTFT) and time between tokens (TBT), rather than allowing a few users to experience performance far exceeding the SLOs. To achieve better fairness, the preemption-based scheduling policy dynamically adjusts the priority of each request to maintain balance during runtime. However, existing systems tend to overly prioritize throughput, overlooking the overhead caused by preemption-induced context switching, which is crucial for maintaining fairness through priority adjustments. In this work, we identify three main challenges that result in this overhead. 1) Inadequate I/O utilization. 2) GPU idleness. 3) Unnecessary I/O transmission during multi-turn conversations. Our key insight is that the block-based KV cache memory policy in existing systems, while achieving near-zero memory waste, leads to discontinuity and insufficient granularity in the KV cache memory. To respond, we introduce FastSwitch, a fairness-aware serving system that not only aligns with existing KV cache memory allocation policy but also mitigates context switching overhead. Our evaluation shows that FastSwitch outperforms the state-of-the-art LLM serving system vLLM with speedups of 1.4-11.2x across different tail TTFT and TBT.","sentences":["Serving numerous users and requests concurrently requires good fairness in Large Language Models (LLMs) serving system.","This ensures that, at the same cost, the system can meet the Service Level Objectives (SLOs) of more users , such as time to first token (TTFT) and time between tokens (TBT), rather than allowing a few users to experience performance far exceeding the SLOs.","To achieve better fairness, the preemption-based scheduling policy dynamically adjusts the priority of each request to maintain balance during runtime.","However, existing systems tend to overly prioritize throughput, overlooking the overhead caused by preemption-induced context switching, which is crucial for maintaining fairness through priority adjustments.","In this work, we identify three main challenges that result in this overhead.","1) Inadequate I/O utilization.","2) GPU idleness.","3) Unnecessary I/O transmission during multi-turn conversations.","Our key insight is that the block-based KV cache memory policy in existing systems, while achieving near-zero memory waste, leads to discontinuity and insufficient granularity in the KV cache memory.","To respond, we introduce FastSwitch, a fairness-aware serving system that not only aligns with existing KV cache memory allocation policy but also mitigates context switching overhead.","Our evaluation shows that FastSwitch outperforms the state-of-the-art LLM serving system vLLM with speedups of 1.4-11.2x across different tail TTFT and TBT."],"url":"http://arxiv.org/abs/2411.18424v1"}
{"created":"2024-11-27 15:05:41","title":"Efficient and Diverse Generative Robot Designs using Evolution and Intrinsic Motivation","abstract":"Methods for generative design of robot physical configurations can automatically find optimal and innovative solutions for challenging tasks in complex environments. The vast search-space includes the physical design-space and the controller parameter-space, making it a challenging problem in machine learning and optimisation in general. Evolutionary algorithms (EAs) have shown promising results in generating robot designs via gradient-free optimisation. Morpho-evolution with learning (MEL) uses EAs to concurrently generate robot designs and learn the optimal parameters of the controllers. Two main issues prevent MEL from scaling to higher complexity tasks: computational cost and premature convergence to sub-optimal designs. To address these issues, we propose combining morpho-evolution with intrinsic motivations. Intrinsically motivated behaviour arises from embodiment and simple learning rules without external guidance. We use a homeokinetic controller that generates exploratory behaviour in a few seconds with reduced knowledge of the robot's design. Homeokinesis replaces costly learning phases, reducing computational time and favouring diversity, preventing premature convergence. We compare our approach with current MEL methods in several downstream tasks. The generated designs score higher in all the tasks, are more diverse, and are quickly generated compared to morpho-evolution with static parameters.","sentences":["Methods for generative design of robot physical configurations can automatically find optimal and innovative solutions for challenging tasks in complex environments.","The vast search-space includes the physical design-space and the controller parameter-space, making it a challenging problem in machine learning and optimisation in general.","Evolutionary algorithms (EAs) have shown promising results in generating robot designs via gradient-free optimisation.","Morpho-evolution with learning (MEL) uses EAs to concurrently generate robot designs and learn the optimal parameters of the controllers.","Two main issues prevent MEL from scaling to higher complexity tasks: computational cost and premature convergence to sub-optimal designs.","To address these issues, we propose combining morpho-evolution with intrinsic motivations.","Intrinsically motivated behaviour arises from embodiment and simple learning rules without external guidance.","We use a homeokinetic controller that generates exploratory behaviour in a few seconds with reduced knowledge of the robot's design.","Homeokinesis replaces costly learning phases, reducing computational time and favouring diversity, preventing premature convergence.","We compare our approach with current MEL methods in several downstream tasks.","The generated designs score higher in all the tasks, are more diverse, and are quickly generated compared to morpho-evolution with static parameters."],"url":"http://arxiv.org/abs/2411.18423v1"}
