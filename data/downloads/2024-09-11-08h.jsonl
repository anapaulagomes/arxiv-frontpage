{"created":"2024-09-10 17:59:55","title":"GeoCalib: Learning Single-image Calibration with Geometric Optimization","abstract":"From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction. This single-image calibration can benefit various downstream applications like image editing and 3D mapping. Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end. The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts. We hypothesize that they lack the constraints that 3D geometry provides. In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process. GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data. Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches. Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization. The code and trained models are publicly available at https://github.com/cvg/GeoCalib.","sentences":["From a single image, visual cues can help deduce intrinsic and extrinsic camera parameters like the focal length and the gravity direction.","This single-image calibration can benefit various downstream applications like image editing and 3D mapping.","Current approaches to this problem are based on either classical geometry with lines and vanishing points or on deep neural networks trained end-to-end.","The learned approaches are more robust but struggle to generalize to new environments and are less accurate than their classical counterparts.","We hypothesize that they lack the constraints that 3D geometry provides.","In this work, we introduce GeoCalib, a deep neural network that leverages universal rules of 3D geometry through an optimization process.","GeoCalib is trained end-to-end to estimate camera parameters and learns to find useful visual cues from the data.","Experiments on various benchmarks show that GeoCalib is more robust and more accurate than existing classical and learned approaches.","Its internal optimization estimates uncertainties, which help flag failure cases and benefit downstream applications like visual localization.","The code and trained models are publicly available at https://github.com/cvg/GeoCalib."],"url":"http://arxiv.org/abs/2409.06704v1"}
{"created":"2024-09-10 17:59:53","title":"LEIA: Latent View-invariant Embeddings for Implicit 3D Articulation","abstract":"Neural Radiance Fields (NeRFs) have revolutionized the reconstruction of static scenes and objects in 3D, offering unprecedented quality. However, extending NeRFs to model dynamic objects or object articulations remains a challenging problem. Previous works have tackled this issue by focusing on part-level reconstruction and motion estimation for objects, but they often rely on heuristics regarding the number of moving parts or object categories, which can limit their practical use. In this work, we introduce LEIA, a novel approach for representing dynamic 3D objects. Our method involves observing the object at distinct time steps or \"states\" and conditioning a hypernetwork on the current state, using this to parameterize our NeRF. This approach allows us to learn a view-invariant latent representation for each state. We further demonstrate that by interpolating between these states, we can generate novel articulation configurations in 3D space that were previously unseen. Our experimental results highlight the effectiveness of our method in articulating objects in a manner that is independent of the viewing angle and joint configuration. Notably, our approach outperforms previous methods that rely on motion information for articulation registration.","sentences":["Neural Radiance Fields (NeRFs) have revolutionized the reconstruction of static scenes and objects in 3D, offering unprecedented quality.","However, extending NeRFs to model dynamic objects or object articulations remains a challenging problem.","Previous works have tackled this issue by focusing on part-level reconstruction and motion estimation for objects, but they often rely on heuristics regarding the number of moving parts or object categories, which can limit their practical use.","In this work, we introduce LEIA, a novel approach for representing dynamic 3D objects.","Our method involves observing the object at distinct time steps or \"states\" and conditioning a hypernetwork on the current state, using this to parameterize our NeRF.","This approach allows us to learn a view-invariant latent representation for each state.","We further demonstrate that by interpolating between these states, we can generate novel articulation configurations in 3D space that were previously unseen.","Our experimental results highlight the effectiveness of our method in articulating objects in a manner that is independent of the viewing angle and joint configuration.","Notably, our approach outperforms previous methods that rely on motion information for articulation registration."],"url":"http://arxiv.org/abs/2409.06703v1"}
{"created":"2024-09-10 17:59:40","title":"Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving","abstract":"End-to-end architectures in autonomous driving (AD) face a significant challenge in interpretability, impeding human-AI trust. Human-friendly natural language has been explored for tasks such as driving explanation and 3D captioning. However, previous works primarily focused on the paradigm of declarative interpretability, where the natural language interpretations are not grounded in the intermediate outputs of AD systems, making the interpretations only declarative. In contrast, aligned interpretability establishes a connection between language and the intermediate outputs of AD systems. Here we introduce Hint-AD, an integrated AD-language system that generates language aligned with the holistic perception-prediction-planning outputs of the AD model. By incorporating the intermediate outputs and a holistic token mixer sub-network for effective feature adaptation, Hint-AD achieves desirable accuracy, achieving state-of-the-art results in driving language tasks including driving explanation, 3D dense captioning, and command prediction. To facilitate further study on driving explanation task on nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and models will be publicly available.","sentences":["End-to-end architectures in autonomous driving (AD) face a significant challenge in interpretability, impeding human-AI trust.","Human-friendly natural language has been explored for tasks such as driving explanation and 3D captioning.","However, previous works primarily focused on the paradigm of declarative interpretability, where the natural language interpretations are not grounded in the intermediate outputs of AD systems, making the interpretations only declarative.","In contrast, aligned interpretability establishes a connection between language and the intermediate outputs of AD systems.","Here we introduce Hint-AD, an integrated AD-language system that generates language aligned with the holistic perception-prediction-planning outputs of the AD model.","By incorporating the intermediate outputs and a holistic token mixer sub-network for effective feature adaptation, Hint-AD achieves desirable accuracy, achieving state-of-the-art results in driving language tasks including driving explanation, 3D dense captioning, and command prediction.","To facilitate further study on driving explanation task on nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and models will be publicly available."],"url":"http://arxiv.org/abs/2409.06702v1"}
{"created":"2024-09-10 17:55:59","title":"DANCE: Deep Learning-Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images","abstract":"Cancer is a complex disease characterized by uncontrolled cell growth. T cell receptors (TCRs), crucial proteins in the immune system, play a key role in recognizing antigens, including those associated with cancer. Recent advancements in sequencing technologies have facilitated comprehensive profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity and enabling TCR-based immunotherapies. However, analyzing these intricate biomolecules necessitates efficient representations that capture their structural and functional information. T-cell protein sequences pose unique challenges due to their relatively smaller lengths compared to other biomolecules. An image-based representation approach becomes a preferred choice for efficient embeddings, allowing for the preservation of essential details and enabling comprehensive analysis of T-cell protein sequences. In this paper, we propose to generate images from the protein sequences using the idea of Chaos Game Representation (CGR) using the Kaleidoscopic images approach. This Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein sequences by recursively applying chaos game rules around a central seed point. we perform the classification of the T cell receptors (TCRs) protein sequences in terms of their respective target cancer cells, as TCRs are known for their immune response against cancer disease. The TCR sequences are converted into images using the DANCE method. We employ deep-learning vision models to perform the classification to obtain insights into the relationship between the visual patterns observed in the generated kaleidoscopic images and the underlying protein properties. By combining CGR-based image generation with deep learning classification, this study opens novel possibilities in the protein analysis domain.","sentences":["Cancer is a complex disease characterized by uncontrolled cell growth.","T cell receptors (TCRs), crucial proteins in the immune system, play a key role in recognizing antigens, including those associated with cancer.","Recent advancements in sequencing technologies have facilitated comprehensive profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity and enabling TCR-based immunotherapies.","However, analyzing these intricate biomolecules necessitates efficient representations that capture their structural and functional information.","T-cell protein sequences pose unique challenges due to their relatively smaller lengths compared to other biomolecules.","An image-based representation approach becomes a preferred choice for efficient embeddings, allowing for the preservation of essential details and enabling comprehensive analysis of T-cell protein sequences.","In this paper, we propose to generate images from the protein sequences using the idea of Chaos Game Representation (CGR) using the Kaleidoscopic images approach.","This Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein sequences by recursively applying chaos game rules around a central seed point.","we perform the classification of the T cell receptors (TCRs) protein sequences in terms of their respective target cancer cells, as TCRs are known for their immune response against cancer disease.","The TCR sequences are converted into images using the DANCE method.","We employ deep-learning vision models to perform the classification to obtain insights into the relationship between the visual patterns observed in the generated kaleidoscopic images and the underlying protein properties.","By combining CGR-based image generation with deep learning classification, this study opens novel possibilities in the protein analysis domain."],"url":"http://arxiv.org/abs/2409.06694v1"}
{"created":"2024-09-10 17:55:29","title":"Technical Report of Mobile Manipulator Robot for Industrial Environments","abstract":"This paper presents the development of the Auriga @Work robot, designed by the Robotics and Intelligent Automation Lab at Shahid Beheshti University, Department of Electrical Engineering, for the RoboCup 2024 competition. The robot is tailored for industrial applications, focusing on enhancing efficiency in repetitive or hazardous environments. It is equipped with a 4-wheel Mecanum drive system for omnidirectional mobility and a 5-degree-of-freedom manipulator arm with a custom 3D-printed gripper for object manipulation and navigation tasks. The robot's electronics are powered by custom-designed boards utilizing ESP32 microcontrollers and an Nvidia Jetson Nano for real-time control and decision-making. The key software stack integrates Hector SLAM for mapping, the A* algorithm for path planning, and YOLO for object detection, along with advanced sensor fusion for improved navigation and collision avoidance.","sentences":["This paper presents the development of the Auriga @Work robot, designed by the Robotics and Intelligent Automation Lab at Shahid Beheshti University, Department of Electrical Engineering, for the RoboCup 2024 competition.","The robot is tailored for industrial applications, focusing on enhancing efficiency in repetitive or hazardous environments.","It is equipped with a 4-wheel Mecanum drive system for omnidirectional mobility and a 5-degree-of-freedom manipulator arm with a custom 3D-printed gripper for object manipulation and navigation tasks.","The robot's electronics are powered by custom-designed boards utilizing ESP32 microcontrollers and an Nvidia Jetson Nano for real-time control and decision-making.","The key software stack integrates Hector SLAM for mapping, the A* algorithm for path planning, and YOLO for object detection, along with advanced sensor fusion for improved navigation and collision avoidance."],"url":"http://arxiv.org/abs/2409.06693v1"}
{"created":"2024-09-10 17:55:00","title":"HybridFC: A Hybrid Fact-Checking Approach for Knowledge Graphs","abstract":"We consider fact-checking approaches that aim to predict the veracity of assertions in knowledge graphs. Five main categories of fact-checking approaches for knowledge graphs have been proposed in the recent literature, of which each is subject to partially overlapping limitations. In particular, current text-based approaches are limited by manual feature engineering. Path-based and rule-based approaches are limited by their exclusive use of knowledge graphs as background knowledge, and embedding-based approaches suffer from low accuracy scores on current fact-checking tasks. We propose a hybrid approach -- dubbed HybridFC -- that exploits the diversity of existing categories of fact-checking approaches within an ensemble learning setting to achieve a significantly better prediction performance. In particular, our approach outperforms the state of the art by 0.14 to 0.27 in terms of Area Under the Receiver Operating Characteristic curve on the FactBench dataset. Our code is open-source and can be found at https://github.com/dice-group/HybridFC.","sentences":["We consider fact-checking approaches that aim to predict the veracity of assertions in knowledge graphs.","Five main categories of fact-checking approaches for knowledge graphs have been proposed in the recent literature, of which each is subject to partially overlapping limitations.","In particular, current text-based approaches are limited by manual feature engineering.","Path-based and rule-based approaches are limited by their exclusive use of knowledge graphs as background knowledge, and embedding-based approaches suffer from low accuracy scores on current fact-checking tasks.","We propose a hybrid approach -- dubbed HybridFC -- that exploits the diversity of existing categories of fact-checking approaches within an ensemble learning setting to achieve a significantly better prediction performance.","In particular, our approach outperforms the state of the art by 0.14 to 0.27 in terms of Area Under the Receiver Operating Characteristic curve on the FactBench dataset.","Our code is open-source and can be found at https://github.com/dice-group/HybridFC."],"url":"http://arxiv.org/abs/2409.06692v1"}
{"created":"2024-09-10 17:54:28","title":"Geometric-Averaged Preference Optimization for Soft Preference Labels","abstract":"Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic. However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses. In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function. In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero. This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from. In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research. In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority.","sentences":["Many algorithms for aligning LLMs with human preferences assume that human preferences are binary and deterministic.","However, it is reasonable to think that they can vary with different individuals, and thus should be distributional to reflect the fine-grained relationship between the responses.","In this work, we introduce the distributional soft preference labels and improve Direct Preference Optimization (DPO) with a weighted geometric average of the LLM output likelihood in the loss function.","In doing so, the scale of learning loss is adjusted based on the soft labels, and the loss with equally preferred responses would be close to zero.","This simple modification can be easily applied to any DPO family and helps the models escape from the over-optimization and objective mismatch prior works suffer from.","In our experiments, we simulate the soft preference labels with AI feedback from LLMs and demonstrate that geometric averaging consistently improves performance on standard benchmarks for alignment research.","In particular, we observe more preferable responses than binary labels and significant improvements with data where modestly-confident labels are in the majority."],"url":"http://arxiv.org/abs/2409.06691v1"}
{"created":"2024-09-10 17:54:00","title":"Benchmarking Sub-Genre Classification For Mainstage Dance Music","abstract":"Music classification, with a wide range of applications, is one of the most prominent tasks in music information retrieval. To address the absence of comprehensive datasets and high-performing methods in the classification of mainstage dance music, this work introduces a novel benchmark comprising a new dataset and a baseline. Our dataset extends the number of sub-genres to cover most recent mainstage live sets by top DJs worldwide in music festivals. A continuous soft labeling approach is employed to account for tracks that span multiple sub-genres, preserving the inherent sophistication. For the baseline, we developed deep learning models that outperform current state-of-the-art multimodel language models, which struggle to identify house music sub-genres, emphasizing the need for specialized models trained on fine-grained datasets. Our benchmark is applicable to serve for application scenarios such as music recommendation, DJ set curation, and interactive multimedia, where we also provide video demos. Our code is on \\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.","sentences":["Music classification, with a wide range of applications, is one of the most prominent tasks in music information retrieval.","To address the absence of comprehensive datasets and high-performing methods in the classification of mainstage dance music, this work introduces a novel benchmark comprising a new dataset and a baseline.","Our dataset extends the number of sub-genres to cover most recent mainstage live sets by top DJs worldwide in music festivals.","A continuous soft labeling approach is employed to account for tracks that span multiple sub-genres, preserving the inherent sophistication.","For the baseline, we developed deep learning models that outperform current state-of-the-art multimodel language models, which struggle to identify house music sub-genres, emphasizing the need for specialized models trained on fine-grained datasets.","Our benchmark is applicable to serve for application scenarios such as music recommendation, DJ set curation, and interactive multimedia, where we also provide video demos.","Our code is on \\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}."],"url":"http://arxiv.org/abs/2409.06690v1"}
{"created":"2024-09-10 17:53:39","title":"Designing Resource Allocation Tools to Promote Fair Allocation: Do Visualization and Information Framing Matter?","abstract":"Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources. However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases. This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness. We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals). In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities. Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs. This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions.","sentences":["Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources.","However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases.","This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness.","We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals).","In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities.","Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs.","This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions."],"url":"http://arxiv.org/abs/2409.06688v1"}
{"created":"2024-09-10 17:51:39","title":"GigaGS: Scaling up Planar-Based 3D Gaussians for Large Scene Surface Reconstruction","abstract":"3D Gaussian Splatting (3DGS) has shown promising performance in novel view synthesis. Previous methods adapt it to obtaining surfaces of either individual 3D objects or within limited scenes. In this paper, we make the first attempt to tackle the challenging task of large-scale scene surface reconstruction. This task is particularly difficult due to the high GPU memory consumption, different levels of details for geometric representation, and noticeable inconsistencies in appearance. To this end, we propose GigaGS, the first work for high-quality surface reconstruction for large-scale scenes using 3DGS. GigaGS first applies a partitioning strategy based on the mutual visibility of spatial regions, which effectively grouping cameras for parallel processing. To enhance the quality of the surface, we also propose novel multi-view photometric and geometric consistency constraints based on Level-of-Detail representation. In doing so, our method can reconstruct detailed surface structures. Comprehensive experiments are conducted on various datasets. The consistent improvement demonstrates the superiority of GigaGS.","sentences":["3D Gaussian Splatting (3DGS) has shown promising performance in novel view synthesis.","Previous methods adapt it to obtaining surfaces of either individual 3D objects or within limited scenes.","In this paper, we make the first attempt to tackle the challenging task of large-scale scene surface reconstruction.","This task is particularly difficult due to the high GPU memory consumption, different levels of details for geometric representation, and noticeable inconsistencies in appearance.","To this end, we propose GigaGS, the first work for high-quality surface reconstruction for large-scale scenes using 3DGS.","GigaGS first applies a partitioning strategy based on the mutual visibility of spatial regions, which effectively grouping cameras for parallel processing.","To enhance the quality of the surface, we also propose novel multi-view photometric and geometric consistency constraints based on Level-of-Detail representation.","In doing so, our method can reconstruct detailed surface structures.","Comprehensive experiments are conducted on various datasets.","The consistent improvement demonstrates the superiority of GigaGS."],"url":"http://arxiv.org/abs/2409.06685v1"}
{"created":"2024-09-10 17:51:03","title":"Alignist: CAD-Informed Orientation Distribution Estimation by Fusing Shape and Correspondences","abstract":"Object pose distribution estimation is crucial in robotics for better path planning and handling of symmetric objects. Recent distribution estimation approaches employ contrastive learning-based approaches by maximizing the likelihood of a single pose estimate in the absence of a CAD model. We propose a pose distribution estimation method leveraging symmetry respecting correspondence distributions and shape information obtained using a CAD model. Contrastive learning-based approaches require an exhaustive amount of training images from different viewpoints to learn the distribution properly, which is not possible in realistic scenarios. Instead, we propose a pipeline that can leverage correspondence distributions and shape information from the CAD model, which are later used to learn pose distributions. Besides, having access to pose distribution based on correspondences before learning pose distributions conditioned on images, can help formulate the loss between distributions. The prior knowledge of distribution also helps the network to focus on getting sharper modes instead. With the CAD prior, our approach converges much faster and learns distribution better by focusing on learning sharper distribution near all the valid modes, unlike contrastive approaches, which focus on a single mode at a time. We achieve benchmark results on SYMSOL-I and T-Less datasets.","sentences":["Object pose distribution estimation is crucial in robotics for better path planning and handling of symmetric objects.","Recent distribution estimation approaches employ contrastive learning-based approaches by maximizing the likelihood of a single pose estimate in the absence of a CAD model.","We propose a pose distribution estimation method leveraging symmetry respecting correspondence distributions and shape information obtained using a CAD model.","Contrastive learning-based approaches require an exhaustive amount of training images from different viewpoints to learn the distribution properly, which is not possible in realistic scenarios.","Instead, we propose a pipeline that can leverage correspondence distributions and shape information from the CAD model, which are later used to learn pose distributions.","Besides, having access to pose distribution based on correspondences before learning pose distributions conditioned on images, can help formulate the loss between distributions.","The prior knowledge of distribution also helps the network to focus on getting sharper modes instead.","With the CAD prior, our approach converges much faster and learns distribution better by focusing on learning sharper distribution near all the valid modes, unlike contrastive approaches, which focus on a single mode at a time.","We achieve benchmark results on SYMSOL-I and T-Less datasets."],"url":"http://arxiv.org/abs/2409.06683v1"}
{"created":"2024-09-10 17:44:35","title":"E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning","abstract":"In the realm of Large Language Models (LLMs), the ability to process long contexts is increasingly crucial for tasks such as multi-round dialogues, code generation, and document summarization. This paper addresses the challenges of enhancing the long-context performance, reducing computational complexity, and leveraging pretrained models collectively termed the \"impossible triangle.\" We introduce E2LLM (Encoder Elongated Large Language Models), a novel approach that effectively navigates this paradox. The method involves splitting long contexts into chunks, compressing each into embedding vectors via a pretrained text encoder, and utilizing an adapter to align these representations with a decoder-only LLM. Two training objectives, focusing on reconstruction of the encoder output and long-context instruction fine-tuning, are employed to facilitate the understanding of soft prompts by the LLM. Experimental results demonstrate that E2LLM achieves superior performance in long-context scenarios while balancing efficiency, performance, and compatibility with pretrained models. Our framework thus represents a significant advancement in the field, contributing to effective long-text modeling.","sentences":["In the realm of Large Language Models (LLMs), the ability to process long contexts is increasingly crucial for tasks such as multi-round dialogues, code generation, and document summarization.","This paper addresses the challenges of enhancing the long-context performance, reducing computational complexity, and leveraging pretrained models collectively termed the \"impossible triangle.\"","We introduce E2LLM (Encoder Elongated Large Language Models), a novel approach that effectively navigates this paradox.","The method involves splitting long contexts into chunks, compressing each into embedding vectors via a pretrained text encoder, and utilizing an adapter to align these representations with a decoder-only LLM.","Two training objectives, focusing on reconstruction of the encoder output and long-context instruction fine-tuning, are employed to facilitate the understanding of soft prompts by the LLM.","Experimental results demonstrate that E2LLM achieves superior performance in long-context scenarios while balancing efficiency, performance, and compatibility with pretrained models.","Our framework thus represents a significant advancement in the field, contributing to effective long-text modeling."],"url":"http://arxiv.org/abs/2409.06679v1"}
{"created":"2024-09-10 17:41:31","title":"Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI","abstract":"As AI systems become more autonomous and capable, experts warn of them potentially causing catastrophic losses. Drawing on the successful precedent set by the nuclear power industry, this paper argues that developers of frontier AI models should be assigned limited, strict, and exclusive third party liability for harms resulting from Critical AI Occurrences (CAIOs) - events that cause or easily could have caused catastrophic losses. Mandatory insurance for CAIO liability is recommended to overcome developers' judgment-proofness, mitigate winner's curse dynamics, and leverage insurers' quasi-regulatory abilities. Based on theoretical arguments and observations from the analogous nuclear power context, insurers are expected to engage in a mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and providing loss prevention guidance in the context of insuring against heavy-tail risks from AI. While not a substitute for regulation, clear liability assignment and mandatory insurance can help efficiently allocate resources to risk-modeling and safe design, facilitating future regulatory efforts.","sentences":["As AI systems become more autonomous and capable, experts warn of them potentially causing catastrophic losses.","Drawing on the successful precedent set by the nuclear power industry, this paper argues that developers of frontier AI models should be assigned limited, strict, and exclusive third party liability for harms resulting from Critical AI Occurrences (CAIOs) - events that cause or easily could have caused catastrophic losses.","Mandatory insurance for CAIO liability is recommended to overcome developers' judgment-proofness, mitigate winner's curse dynamics, and leverage insurers' quasi-regulatory abilities.","Based on theoretical arguments and observations from the analogous nuclear power context, insurers are expected to engage in a mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and providing loss prevention guidance in the context of insuring against heavy-tail risks from AI.","While not a substitute for regulation, clear liability assignment and mandatory insurance can help efficiently allocate resources to risk-modeling and safe design, facilitating future regulatory efforts."],"url":"http://arxiv.org/abs/2409.06673v1"}
{"created":"2024-09-10 17:41:24","title":"Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort","abstract":"Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.","sentences":["Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks.","This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe.","This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers.","The program uses risk-priced indemnity fees to induce socially optimal levels of care.","Risk-estimates are determined by surveying experts, including indemnified developers.","The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses.","Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees.","It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good.","Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds."],"url":"http://arxiv.org/abs/2409.06672v1"}
{"created":"2024-09-10 17:40:46","title":"A Semantic Segmentation Approach on Sweet Orange Leaf Diseases Detection Utilizing YOLO","abstract":"This research introduces an advanced method for diagnosing diseases in sweet orange leaves by utilising advanced artificial intelligence models like YOLOv8 . Due to their significance as a vital agricultural product, sweet oranges encounter significant threats from a variety of diseases that harmfully affect both their yield and quality. Conventional methods for disease detection primarily depend on manual inspection which is ineffective and frequently leads to errors, resulting in delayed treatment and increased financial losses. In response to this challenge, the research utilized YOLOv8 , harnessing their proficiencies in detecting objects and analyzing images. YOLOv8 is recognized for its rapid and precise performance, while VIT is acknowledged for its detailed feature extraction abilities. Impressively, during both the training and validation stages, YOLOv8 exhibited a perfect accuracy of 80.4%, while VIT achieved an accuracy of 99.12%, showcasing their potential to transform disease detection in agriculture. The study comprehensively examined the practical challenges related to the implementation of AI technologies in agriculture, encompassing the computational demands and user accessibility, and offering viable solutions for broader usage. Moreover, it underscores the environmental considerations, particularly the potential for reduced pesticide usage, thereby promoting sustainable farming and environmental conservation. These findings provide encouraging insights into the application of AI in agriculture, suggesting a transition towards more effective, sustainable, and technologically advanced farming methods. This research not only highlights the efficacy of YOLOv8 within a specific agricultural domain but also lays the foundation for further studies that encompass a broader application in crop management and sustainable agricultural practices.","sentences":["This research introduces an advanced method for diagnosing diseases in sweet orange leaves by utilising advanced artificial intelligence models like YOLOv8 .","Due to their significance as a vital agricultural product, sweet oranges encounter significant threats from a variety of diseases that harmfully affect both their yield and quality.","Conventional methods for disease detection primarily depend on manual inspection which is ineffective and frequently leads to errors, resulting in delayed treatment and increased financial losses.","In response to this challenge, the research utilized YOLOv8 , harnessing their proficiencies in detecting objects and analyzing images.","YOLOv8 is recognized for its rapid and precise performance, while VIT is acknowledged for its detailed feature extraction abilities.","Impressively, during both the training and validation stages, YOLOv8 exhibited a perfect accuracy of 80.4%, while VIT achieved an accuracy of 99.12%, showcasing their potential to transform disease detection in agriculture.","The study comprehensively examined the practical challenges related to the implementation of AI technologies in agriculture, encompassing the computational demands and user accessibility, and offering viable solutions for broader usage.","Moreover, it underscores the environmental considerations, particularly the potential for reduced pesticide usage, thereby promoting sustainable farming and environmental conservation.","These findings provide encouraging insights into the application of AI in agriculture, suggesting a transition towards more effective, sustainable, and technologically advanced farming methods.","This research not only highlights the efficacy of YOLOv8 within a specific agricultural domain but also lays the foundation for further studies that encompass a broader application in crop management and sustainable agricultural practices."],"url":"http://arxiv.org/abs/2409.06671v1"}
{"created":"2024-09-10 17:36:15","title":"DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models","abstract":"Transformer-based Mixture-of-Experts (MoE) models have been driving several recent technological advancements in Natural Language Processing (NLP). These MoE models adopt a router mechanism to determine which experts to activate for routing input tokens. However, existing router mechanisms allocate a fixed number of experts to each token, which neglects the varying importance of different input tokens. In this study, we propose a novel dynamic router mechanism that Dynamically Allocates a variable number of experts for Mixture-of-Experts (DA-MoE) models based on an effective token importance measure. First, we show that the Transformer attention mechanism provides a natural and effective way of calculating token importance. Second, we propose a dynamic router mechanism that effectively decides the optimal number of experts (K) and allocates the top-K experts for each input token. Third, comprehensive experiments on several benchmark datasets demonstrate that our DA-MoE approach consistently outperforms the state-of-the-art Transformer based MoE model on the popular GLUE benchmark.","sentences":["Transformer-based Mixture-of-Experts (MoE) models have been driving several recent technological advancements in Natural Language Processing (NLP).","These MoE models adopt a router mechanism to determine which experts to activate for routing input tokens.","However, existing router mechanisms allocate a fixed number of experts to each token, which neglects the varying importance of different input tokens.","In this study, we propose a novel dynamic router mechanism that Dynamically Allocates a variable number of experts for Mixture-of-Experts (DA-MoE) models based on an effective token importance measure.","First, we show that the Transformer attention mechanism provides a natural and effective way of calculating token importance.","Second, we propose a dynamic router mechanism that effectively decides the optimal number of experts (K) and allocates the top-K experts for each input token.","Third, comprehensive experiments on several benchmark datasets demonstrate that our DA-MoE approach consistently outperforms the state-of-the-art Transformer based MoE model on the popular GLUE benchmark."],"url":"http://arxiv.org/abs/2409.06669v1"}
{"created":"2024-09-10 17:34:34","title":"LLaMA-Omni: Seamless Speech Interaction with Large Language Models","abstract":"Models like GPT-4o enable real-time interaction with large language models (LLMs) through speech, significantly enhancing user experience compared to traditional text-based interaction. However, there is still a lack of exploration on how to build speech interaction models based on open-source LLMs. To address this, we propose LLaMA-Omni, a novel model architecture designed for low-latency and high-quality speech interaction with LLMs. LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM, and a streaming speech decoder. It eliminates the need for speech transcription, and can simultaneously generate text and speech responses directly from speech instructions with extremely low latency. We build our model based on the latest Llama-3.1-8B-Instruct model. To align the model with speech interaction scenarios, we construct a dataset named InstructS2S-200K, which includes 200K speech instructions and corresponding speech responses. Experimental results show that compared to previous speech-language models, LLaMA-Omni provides better responses in both content and style, with a response latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3 days on just 4 GPUs, paving the way for the efficient development of speech-language models in the future.","sentences":["Models like GPT-4o enable real-time interaction with large language models (LLMs) through speech, significantly enhancing user experience compared to traditional text-based interaction.","However, there is still a lack of exploration on how to build speech interaction models based on open-source LLMs.","To address this, we propose LLaMA-Omni, a novel model architecture designed for low-latency and high-quality speech interaction with LLMs.","LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM, and a streaming speech decoder.","It eliminates the need for speech transcription, and can simultaneously generate text and speech responses directly from speech instructions with extremely low latency.","We build our model based on the latest Llama-3.1-8B-Instruct model.","To align the model with speech interaction scenarios, we construct a dataset named InstructS2S-200K, which includes 200K speech instructions and corresponding speech responses.","Experimental results show that compared to previous speech-language models, LLaMA-Omni provides better responses in both content and style, with a response latency as low as 226ms.","Additionally, training LLaMA-Omni takes less than 3 days on just 4 GPUs, paving the way for the efficient development of speech-language models in the future."],"url":"http://arxiv.org/abs/2409.06666v1"}
{"created":"2024-09-10 17:34:07","title":"Data Collection-free Masked Video Modeling","abstract":"Pre-training video transformers generally requires a large amount of data, presenting significant challenges in terms of data collection costs and concerns related to privacy, licensing, and inherent biases. Synthesizing data is one of the promising ways to solve these issues, yet pre-training solely on synthetic data has its own challenges. In this paper, we introduce an effective self-supervised learning framework for videos that leverages readily available and less costly static images. Specifically, we define the Pseudo Motion Generator (PMG) module that recursively applies image transformations to generate pseudo-motion videos from images. These pseudo-motion videos are then leveraged in masked video modeling. Our approach is applicable to synthetic images as well, thus entirely freeing video pre-training from data collection costs and other concerns in real data. Through experiments in action recognition tasks, we demonstrate that this framework allows effective learning of spatio-temporal features through pseudo-motion videos, significantly improving over existing methods which also use static images and partially outperforming those using both real and synthetic videos. These results uncover fragments of what video transformers learn through masked video modeling.","sentences":["Pre-training video transformers generally requires a large amount of data, presenting significant challenges in terms of data collection costs and concerns related to privacy, licensing, and inherent biases.","Synthesizing data is one of the promising ways to solve these issues, yet pre-training solely on synthetic data has its own challenges.","In this paper, we introduce an effective self-supervised learning framework for videos that leverages readily available and less costly static images.","Specifically, we define the Pseudo Motion Generator (PMG) module that recursively applies image transformations to generate pseudo-motion videos from images.","These pseudo-motion videos are then leveraged in masked video modeling.","Our approach is applicable to synthetic images as well, thus entirely freeing video pre-training from data collection costs and other concerns in real data.","Through experiments in action recognition tasks, we demonstrate that this framework allows effective learning of spatio-temporal features through pseudo-motion videos, significantly improving over existing methods which also use static images and partially outperforming those using both real and synthetic videos.","These results uncover fragments of what video transformers learn through masked video modeling."],"url":"http://arxiv.org/abs/2409.06665v1"}
{"created":"2024-09-10 17:25:47","title":"World-Grounded Human Motion Recovery via Gravity-View Coordinates","abstract":"We present a novel method for recovering world-grounded human motion from monocular video. The main challenge lies in the ambiguity of defining the world coordinate system, which varies between sequences. Previous approaches attempt to alleviate this issue by predicting relative motion in an autoregressive manner, but are prone to accumulating errors. Instead, we propose estimating human poses in a novel Gravity-View (GV) coordinate system, which is defined by the world gravity and the camera view direction. The proposed GV system is naturally gravity-aligned and uniquely defined for each video frame, largely reducing the ambiguity of learning image-pose mapping. The estimated poses can be transformed back to the world coordinate system using camera rotations, forming a global motion sequence. Additionally, the per-frame estimation avoids error accumulation in the autoregressive methods. Experiments on in-the-wild benchmarks demonstrate that our method recovers more realistic motion in both the camera space and world-grounded settings, outperforming state-of-the-art methods in both accuracy and speed. The code is available at https://zju3dv.github.io/gvhmr/.","sentences":["We present a novel method for recovering world-grounded human motion from monocular video.","The main challenge lies in the ambiguity of defining the world coordinate system, which varies between sequences.","Previous approaches attempt to alleviate this issue by predicting relative motion in an autoregressive manner, but are prone to accumulating errors.","Instead, we propose estimating human poses in a novel Gravity-View (GV) coordinate system, which is defined by the world gravity and the camera view direction.","The proposed GV system is naturally gravity-aligned and uniquely defined for each video frame, largely reducing the ambiguity of learning image-pose mapping.","The estimated poses can be transformed back to the world coordinate system using camera rotations, forming a global motion sequence.","Additionally, the per-frame estimation avoids error accumulation in the autoregressive methods.","Experiments on in-the-wild benchmarks demonstrate that our method recovers more realistic motion in both the camera space and world-grounded settings, outperforming state-of-the-art methods in both accuracy and speed.","The code is available at https://zju3dv.github.io/gvhmr/."],"url":"http://arxiv.org/abs/2409.06662v1"}
{"created":"2024-09-10 17:16:42","title":"Human Perception of LLM-generated Text Content in Social Media Environments","abstract":"Emerging technologies, particularly artificial intelligence (AI), and more specifically Large Language Models (LLMs) have provided malicious actors with powerful tools for manipulating digital discourse. LLMs have the potential to affect traditional forms of democratic engagements, such as voter choice, government surveys, or even online communication with regulators; since bots are capable of producing large quantities of credible text. To investigate the human perception of LLM-generated content, we recruited over 1,000 participants who then tried to differentiate bot from human posts in social media discussion threads. We found that humans perform poorly at identifying the true nature of user posts on social media. We also found patterns in how humans identify LLM-generated text content in social media discourse. Finally, we observed the Uncanny Valley effect in text dialogue in both user perception and identification. This indicates that despite humans being poor at the identification process, they can still sense discomfort when reading LLM-generated content.","sentences":["Emerging technologies, particularly artificial intelligence (AI), and more specifically Large Language Models (LLMs) have provided malicious actors with powerful tools for manipulating digital discourse.","LLMs have the potential to affect traditional forms of democratic engagements, such as voter choice, government surveys, or even online communication with regulators; since bots are capable of producing large quantities of credible text.","To investigate the human perception of LLM-generated content, we recruited over 1,000 participants who then tried to differentiate bot from human posts in social media discussion threads.","We found that humans perform poorly at identifying the true nature of user posts on social media.","We also found patterns in how humans identify LLM-generated text content in social media discourse.","Finally, we observed the Uncanny Valley effect in text dialogue in both user perception and identification.","This indicates that despite humans being poor at the identification process, they can still sense discomfort when reading LLM-generated content."],"url":"http://arxiv.org/abs/2409.06653v1"}
{"created":"2024-09-10 17:06:54","title":"Image Vectorization with Depth: convexified shape layers with depth ordering","abstract":"Image vectorization is a process to convert a raster image into a scalable vector graphic format. Objective is to effectively remove the pixelization effect while representing boundaries of image by scaleable parameterized curves. We propose new image vectorization with depth which considers depth ordering among shapes and use curvature-based inpainting for convexifying shapes in vectorization process.From a given color quantized raster image, we first define each connected component of the same color as a shape layer, and construct depth ordering among them using a newly proposed depth ordering energy. Global depth ordering among all shapes is described by a directed graph, and we propose an energy to remove cycle within the graph. After constructing depth ordering of shapes, we convexify occluded regions by Euler's elastica curvature-based variational inpainting, and leverage on the stability of Modica-Mortola double-well potential energy to inpaint large regions. This is following human vision perception that boundaries of shapes extend smoothly, and we assume shapes are likely to be convex. Finally, we fit B\\'{e}zier curves to the boundaries and save vectorization as a SVG file which allows superposition of curvature-based inpainted shapes following the depth ordering. This is a new way to vectorize images, by decomposing an image into scalable shape layers with computed depth ordering. This approach makes editing shapes and images more natural and intuitive. We also consider grouping shape layers for semantic vectorization. We present various numerical results and comparisons against recent layer-based vectorization methods to validate the proposed model.","sentences":["Image vectorization is a process to convert a raster image into a scalable vector graphic format.","Objective is to effectively remove the pixelization effect while representing boundaries of image by scaleable parameterized curves.","We propose new image vectorization with depth which considers depth ordering among shapes and use curvature-based inpainting for convexifying shapes in vectorization process.","From a given color quantized raster image, we first define each connected component of the same color as a shape layer, and construct depth ordering among them using a newly proposed depth ordering energy.","Global depth ordering among all shapes is described by a directed graph, and we propose an energy to remove cycle within the graph.","After constructing depth ordering of shapes, we convexify occluded regions by Euler's elastica curvature-based variational inpainting, and leverage on the stability of Modica-Mortola double-well potential energy to inpaint large regions.","This is following human vision perception that boundaries of shapes extend smoothly, and we assume shapes are likely to be convex.","Finally, we fit B\\'{e}zier curves to the boundaries and save vectorization as a SVG file which allows superposition of curvature-based inpainted shapes following the depth ordering.","This is a new way to vectorize images, by decomposing an image into scalable shape layers with computed depth ordering.","This approach makes editing shapes and images more natural and intuitive.","We also consider grouping shape layers for semantic vectorization.","We present various numerical results and comparisons against recent layer-based vectorization methods to validate the proposed model."],"url":"http://arxiv.org/abs/2409.06648v1"}
{"created":"2024-09-10 17:05:11","title":"Optimal Workload Placement on Multi-Instance GPUs","abstract":"There is an urgent and pressing need to optimize usage of Graphical Processing Units (GPUs), which have arguably become one of the most expensive and sought after IT resources. To help with this goal, several of the current generation of GPUs support a partitioning feature, called Multi-Instance GPU (MIG) to allow multiple workloads to share a GPU, albeit with some constraints. In this paper we investigate how to optimize the placement of Large Language Model (LLM)-based AI Inferencing workloads on GPUs. We first identify and present several use cases that are encountered in practice that require workloads to be efficiently placed or migrated to other GPUs to make room for incoming workloads. The overarching goal is to use as few GPUs as possible and to further minimize memory and compute wastage on GPUs that are utilized. We have developed two approaches to address this problem: an optimization method and a heuristic method. We benchmark these with two workload scheduling heuristics for multiple use cases. Our results show up to 2.85x improvement in the number of GPUs used and up to 70% reduction in GPU wastage over baseline heuristics. We plan to enable the SRE community to leverage our proposed method in production environments.","sentences":["There is an urgent and pressing need to optimize usage of Graphical Processing Units (GPUs), which have arguably become one of the most expensive and sought after IT resources.","To help with this goal, several of the current generation of GPUs support a partitioning feature, called Multi-Instance GPU (MIG) to allow multiple workloads to share a GPU, albeit with some constraints.","In this paper we investigate how to optimize the placement of Large Language Model (LLM)-based AI Inferencing workloads on GPUs.","We first identify and present several use cases that are encountered in practice that require workloads to be efficiently placed or migrated to other GPUs to make room for incoming workloads.","The overarching goal is to use as few GPUs as possible and to further minimize memory and compute wastage on GPUs that are utilized.","We have developed two approaches to address this problem: an optimization method and a heuristic method.","We benchmark these with two workload scheduling heuristics for multiple use cases.","Our results show up to 2.85x improvement in the number of GPUs used and up to 70% reduction in GPU wastage over baseline heuristics.","We plan to enable the SRE community to leverage our proposed method in production environments."],"url":"http://arxiv.org/abs/2409.06646v1"}
{"created":"2024-09-10 17:00:19","title":"EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis","abstract":"Early detection of eye diseases like glaucoma, macular degeneration, and diabetic retinopathy is crucial for preventing vision loss. While artificial intelligence (AI) foundation models hold significant promise for addressing these challenges, existing ophthalmic foundation models primarily focus on a single modality, whereas diagnosing eye diseases requires multiple modalities. A critical yet often overlooked aspect is harnessing the multi-view information across various modalities for the same patient. Additionally, due to the long-tail nature of ophthalmic diseases, standard fully supervised or unsupervised learning approaches often struggle. Therefore, it is essential to integrate clinical text to capture a broader spectrum of diseases. We propose EyeCLIP, a visual-language foundation model developed using over 2.77 million multi-modal ophthalmology images with partial text data. To fully leverage the large multi-modal unlabeled and labeled data, we introduced a pretraining strategy that combines self-supervised reconstructions, multi-modal image contrastive learning, and image-text contrastive learning to learn a shared representation of multiple modalities. Through evaluation using 14 benchmark datasets, EyeCLIP can be transferred to a wide range of downstream tasks involving ocular and systemic diseases, achieving state-of-the-art performance in disease classification, visual question answering, and cross-modal retrieval. EyeCLIP represents a significant advancement over previous methods, especially showcasing few-shot, even zero-shot capabilities in real-world long-tail scenarios.","sentences":["Early detection of eye diseases like glaucoma, macular degeneration, and diabetic retinopathy is crucial for preventing vision loss.","While artificial intelligence (AI) foundation models hold significant promise for addressing these challenges, existing ophthalmic foundation models primarily focus on a single modality, whereas diagnosing eye diseases requires multiple modalities.","A critical yet often overlooked aspect is harnessing the multi-view information across various modalities for the same patient.","Additionally, due to the long-tail nature of ophthalmic diseases, standard fully supervised or unsupervised learning approaches often struggle.","Therefore, it is essential to integrate clinical text to capture a broader spectrum of diseases.","We propose EyeCLIP, a visual-language foundation model developed using over 2.77 million multi-modal ophthalmology images with partial text data.","To fully leverage the large multi-modal unlabeled and labeled data, we introduced a pretraining strategy that combines self-supervised reconstructions, multi-modal image contrastive learning, and image-text contrastive learning to learn a shared representation of multiple modalities.","Through evaluation using 14 benchmark datasets, EyeCLIP can be transferred to a wide range of downstream tasks involving ocular and systemic diseases, achieving state-of-the-art performance in disease classification, visual question answering, and cross-modal retrieval.","EyeCLIP represents a significant advancement over previous methods, especially showcasing few-shot, even zero-shot capabilities in real-world long-tail scenarios."],"url":"http://arxiv.org/abs/2409.06644v1"}
{"created":"2024-09-10 16:59:33","title":"Strategic management analysis: from data to strategy diagram by LLM","abstract":"Strategy management analyses are created by business consultants with common analysis frameworks (i.e. comparative analyses) and associated diagrams. We show these can be largely constructed using LLMs, starting with the extraction of insights from data, organization of those insights according to a strategy management framework, and then depiction in the typical strategy management diagram for that framework (static textual visualizations). We discuss caveats and future directions to generalize for broader uses.","sentences":["Strategy management analyses are created by business consultants with common analysis frameworks (i.e. comparative analyses) and associated diagrams.","We show these can be largely constructed using LLMs, starting with the extraction of insights from data, organization of those insights according to a strategy management framework, and then depiction in the typical strategy management diagram for that framework (static textual visualizations).","We discuss caveats and future directions to generalize for broader uses."],"url":"http://arxiv.org/abs/2409.06643v1"}
{"created":"2024-09-10 16:54:32","title":"TeXBLEU: Automatic Metric for Evaluate LaTeX Format","abstract":"LaTeX is highly suited to creating documents with special formatting, particularly in the fields of science, technology, mathematics, and computer science. Despite the increasing use of mathematical expressions in LaTeX format with language models, there are no evaluation metrics for evaluating them. In this study, we propose TeXBLEU, an evaluation metric tailored for mathematical expressions in LaTeX format, based on the n-gram-based BLEU metric that is widely used for translation tasks. The proposed TeXBLEU includes a predefined tokenizer trained on the arXiv paper dataset and a finetuned embedding model. It also considers the positional embedding of tokens. Simultaneously, TeXBLEU compares tokens based on n-grams and computes the score using exponentiation of a logarithmic sum, similar to the original BLEU. Experimental results show that TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER, and WER when compared to human evaluation data on the test dataset of the MathBridge dataset, which contains 1,000 data points. The average correlation coefficient with human evaluation was 0.71, which is an improvement of 87% compared with BLEU, which had the highest correlation with human evaluation data among the existing metrics. The code is available at https://github.com/KyuDan1/TeXBLEU.","sentences":["LaTeX is highly suited to creating documents with special formatting, particularly in the fields of science, technology, mathematics, and computer science.","Despite the increasing use of mathematical expressions in LaTeX format with language models, there are no evaluation metrics for evaluating them.","In this study, we propose TeXBLEU, an evaluation metric tailored for mathematical expressions in LaTeX format, based on the n-gram-based BLEU metric that is widely used for translation tasks.","The proposed TeXBLEU includes a predefined tokenizer trained on the arXiv paper dataset and a finetuned embedding model.","It also considers the positional embedding of tokens.","Simultaneously, TeXBLEU compares tokens based on n-grams and computes the score using exponentiation of a logarithmic sum, similar to the original BLEU.","Experimental results show that TeXBLEU outperformed traditional evaluation metrics such as BLEU, Rouge, CER, and WER when compared to human evaluation data on the test dataset of the MathBridge dataset, which contains 1,000 data points.","The average correlation coefficient with human evaluation was 0.71, which is an improvement of 87% compared with BLEU, which had the highest correlation with human evaluation data among the existing metrics.","The code is available at https://github.com/KyuDan1/TeXBLEU."],"url":"http://arxiv.org/abs/2409.06639v1"}
{"created":"2024-09-10 16:48:05","title":"Critical Features Tracking on Triangulated Irregular Networks by a Scale-Space Method","abstract":"The scale-space method is a well-established framework that constructs a hierarchical representation of an input signal and facilitates coarse-to-fine visual reasoning. Considering the terrain elevation function as the input signal, the scale-space method can identify and track significant topographic features across different scales. The number of scales a feature persists, called its life span, indicates the importance of that feature. In this way, important topographic features of a landscape can be selected, which are useful for many applications, including cartography, nautical charting, and land-use planning. The scale-space methods developed for terrain data use gridded Digital Elevation Models (DEMs) to represent the terrain. However, gridded DEMs lack the flexibility to adapt to the irregular distribution of input data and the varied topological complexity of different regions. Instead, Triangulated Irregular Networks (TINs) can be directly generated from irregularly distributed point clouds and accurately preserve important features. In this work, we introduce a novel scale-space analysis pipeline for TINs, addressing the multiple challenges in extending grid-based scale-space methods to TINs. Our pipeline can efficiently identify and track topologically important features on TINs. Moreover, it is capable of analyzing terrains with irregular boundaries, which poses challenges for grid-based methods. Comprehensive experiments show that, compared to grid-based methods, our TIN-based pipeline is more efficient, accurate, and has better resolution robustness.","sentences":["The scale-space method is a well-established framework that constructs a hierarchical representation of an input signal and facilitates coarse-to-fine visual reasoning.","Considering the terrain elevation function as the input signal, the scale-space method can identify and track significant topographic features across different scales.","The number of scales a feature persists, called its life span, indicates the importance of that feature.","In this way, important topographic features of a landscape can be selected, which are useful for many applications, including cartography, nautical charting, and land-use planning.","The scale-space methods developed for terrain data use gridded Digital Elevation Models (DEMs) to represent the terrain.","However, gridded DEMs lack the flexibility to adapt to the irregular distribution of input data and the varied topological complexity of different regions.","Instead, Triangulated Irregular Networks (TINs) can be directly generated from irregularly distributed point clouds and accurately preserve important features.","In this work, we introduce a novel scale-space analysis pipeline for TINs, addressing the multiple challenges in extending grid-based scale-space methods to TINs.","Our pipeline can efficiently identify and track topologically important features on TINs.","Moreover, it is capable of analyzing terrains with irregular boundaries, which poses challenges for grid-based methods.","Comprehensive experiments show that, compared to grid-based methods, our TIN-based pipeline is more efficient, accurate, and has better resolution robustness."],"url":"http://arxiv.org/abs/2409.06638v1"}
{"created":"2024-09-10 16:46:18","title":"MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders","abstract":"The rapid advancements in large language models (LLMs) have significantly enhanced natural language processing capabilities, facilitating the development of AudioLLMs that process and understand speech and audio inputs alongside text. Existing AudioLLMs typically combine a pre-trained audio encoder with a pre-trained LLM, which are subsequently finetuned on specific audio tasks. However, the pre-trained audio encoder has constrained capacity to capture features for new tasks and datasets. To address this, we propose to incorporate mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE supplements a base encoder with a pool of relatively light weight encoders, selectively activated based on the audio input to enhance feature extraction without significantly increasing model size. Our empirical results demonstrate that MoWE effectively improves multi-task performance, broadening the applicability of AudioLLMs to more diverse audio tasks.","sentences":["The rapid advancements in large language models (LLMs) have significantly enhanced natural language processing capabilities, facilitating the development of AudioLLMs that process and understand speech and audio inputs alongside text.","Existing AudioLLMs typically combine a pre-trained audio encoder with a pre-trained LLM, which are subsequently finetuned on specific audio tasks.","However, the pre-trained audio encoder has constrained capacity to capture features for new tasks and datasets.","To address this, we propose to incorporate mixtures of `weak' encoders (MoWE) into the AudioLLM framework.","MoWE supplements a base encoder with a pool of relatively light weight encoders, selectively activated based on the audio input to enhance feature extraction without significantly increasing model size.","Our empirical results demonstrate that MoWE effectively improves multi-task performance, broadening the applicability of AudioLLMs to more diverse audio tasks."],"url":"http://arxiv.org/abs/2409.06635v1"}
{"created":"2024-09-10 16:46:09","title":"Delay-Optimum Adder Circuits with Linear Size","abstract":"We present efficient circuits for the addition of binary numbers. We assume that we are given arrival times for all input bits and optimize the delay of the circuits, i.e.\\ the time when the last output bit is computed. This contains the classical optimization of depth as a special case where all arrival times are $0$. In this model, we present, among other results, the fastest adder circuits of sub-quadratic size and the fastest adder circuits of linear size. In particular, for adding two $n$-numbers we get a circuits with linear size and delay $\\log_2W+3\\log_2\\log_2n+4\\log_2\\log_2\\log_2n +const$ where $\\log_2W$ is a lower bound for the delay of any adder circuit (no matter what size it has).","sentences":["We present efficient circuits for the addition of binary numbers.","We assume that we are given arrival times for all input bits and optimize the delay of the circuits, i.e.\\ the time when the last output bit is computed.","This contains the classical optimization of depth as a special case where all arrival times are $0$. In this model, we present, among other results, the fastest adder circuits of sub-quadratic size and the fastest adder circuits of linear size.","In particular, for adding two $n$-numbers we get a circuits with linear size and delay $\\log_2W+3\\log_2\\log_2n+4\\log_2\\log_2\\log_2n +const$ where $\\log_2W$ is a lower bound for the delay of any adder circuit (no matter what size it has)."],"url":"http://arxiv.org/abs/2409.06634v1"}
{"created":"2024-09-10 16:44:47","title":"SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation","abstract":"In recent years, the development of diffusion models has led to significant progress in image and video generation tasks, with pre-trained models like the Stable Diffusion series playing a crucial role. Inspired by model pruning which lightens large pre-trained models by removing unimportant parameters, we propose a novel model fine-tuning method to make full use of these ineffective parameters and enable the pre-trained model with new task-specified capabilities. In this work, we first investigate the importance of parameters in pre-trained diffusion models, and discover that the smallest 10% to 20% of parameters by absolute values do not contribute to the generation process. Based on this observation, we propose a method termed SaRA that re-utilizes these temporarily ineffective parameters, equating to optimizing a sparse weight matrix to learn the task-specific knowledge. To mitigate overfitting, we propose a nuclear-norm-based low-rank sparse training scheme for efficient fine-tuning. Furthermore, we design a new progressive parameter adjustment strategy to make full use of the re-trained/finetuned parameters. Finally, we propose a novel unstructural backpropagation strategy, which significantly reduces memory costs during fine-tuning. Our method enhances the generative capabilities of pre-trained models in downstream applications and outperforms traditional fine-tuning methods like LoRA in maintaining model's generalization ability. We validate our approach through fine-tuning experiments on SD models, demonstrating significant improvements. SaRA also offers a practical advantage that requires only a single line of code modification for efficient implementation and is seamlessly compatible with existing methods.","sentences":["In recent years, the development of diffusion models has led to significant progress in image and video generation tasks, with pre-trained models like the Stable Diffusion series playing a crucial role.","Inspired by model pruning which lightens large pre-trained models by removing unimportant parameters, we propose a novel model fine-tuning method to make full use of these ineffective parameters and enable the pre-trained model with new task-specified capabilities.","In this work, we first investigate the importance of parameters in pre-trained diffusion models, and discover that the smallest 10% to 20% of parameters by absolute values do not contribute to the generation process.","Based on this observation, we propose a method termed SaRA that re-utilizes these temporarily ineffective parameters, equating to optimizing a sparse weight matrix to learn the task-specific knowledge.","To mitigate overfitting, we propose a nuclear-norm-based low-rank sparse training scheme for efficient fine-tuning.","Furthermore, we design a new progressive parameter adjustment strategy to make full use of the re-trained/finetuned parameters.","Finally, we propose a novel unstructural backpropagation strategy, which significantly reduces memory costs during fine-tuning.","Our method enhances the generative capabilities of pre-trained models in downstream applications and outperforms traditional fine-tuning methods like LoRA in maintaining model's generalization ability.","We validate our approach through fine-tuning experiments on SD models, demonstrating significant improvements.","SaRA also offers a practical advantage that requires only a single line of code modification for efficient implementation and is seamlessly compatible with existing methods."],"url":"http://arxiv.org/abs/2409.06633v1"}
{"created":"2024-09-10 16:30:20","title":"Advanced Gaze Analytics Dashboard","abstract":"Eye movements can provide informative cues to understand human visual scan/search behavior and cognitive load during varying tasks. Visualizations of real-time gaze measures during tasks, provide an understanding of human behavior as the experiment is being conducted. Even though existing eye tracking analysis tools provide calculation and visualization of eye-tracking data, none of them support real-time visualizations of advanced gaze measures, such as ambient or focal processing, or eye-tracked measures of cognitive load. In this paper, we present an eye movements analytics dashboard that enables visualizations of various gaze measures, fixations, saccades, cognitive load, ambient-focal attention, and gaze transitions analysis by extracting eye movements from participants utilizing common off-the-shelf eye trackers. We validate the proposed eye movement visualizations by using two publicly available eye-tracking datasets. We showcase that, the proposed dashboard could be utilized to visualize advanced eye movement measures generated using multiple data sources.","sentences":["Eye movements can provide informative cues to understand human visual scan/search behavior and cognitive load during varying tasks.","Visualizations of real-time gaze measures during tasks, provide an understanding of human behavior as the experiment is being conducted.","Even though existing eye tracking analysis tools provide calculation and visualization of eye-tracking data, none of them support real-time visualizations of advanced gaze measures, such as ambient or focal processing, or eye-tracked measures of cognitive load.","In this paper, we present an eye movements analytics dashboard that enables visualizations of various gaze measures, fixations, saccades, cognitive load, ambient-focal attention, and gaze transitions analysis by extracting eye movements from participants utilizing common off-the-shelf eye trackers.","We validate the proposed eye movement visualizations by using two publicly available eye-tracking datasets.","We showcase that, the proposed dashboard could be utilized to visualize advanced eye movement measures generated using multiple data sources."],"url":"http://arxiv.org/abs/2409.06628v1"}
{"created":"2024-09-10 16:29:30","title":"\"The struggle is a part of the experience\": Engaging Discontents in the Design of Family Meal Technologies","abstract":"Meals are a central (and messy) part of family life. Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics. In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences. Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals. Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences.","sentences":["Meals are a central (and messy) part of family life.","Previous design framings for mealtime technologies have focused on supporting dietary needs or social and celebratory interactions at the dinner table; however, family meals involve the coordination of many activities and complicated family dynamics.","In this paper, we report on findings from interviews and design sessions with 18 families from the Midwestern United States (including both partners/parents and children) to uncover important family differences and tensions that arise around domestic meal experiences.","Drawing on feminist theory, we unpack the work of feeding a family as a form of care, drawing attention to the social and emotional complexity of family meals.","Critically situating our data within current design narratives, we propose the sensitizing concepts of generative and systemic discontents as a productive way towards troubling the design space of family-food interaction to contend with the struggles that are a part of everyday family meal experiences."],"url":"http://arxiv.org/abs/2409.06627v1"}
{"created":"2024-09-10 16:28:09","title":"Towards Localizing Structural Elements: Merging Geometrical Detection with Semantic Verification in RGB-D Data","abstract":"RGB-D cameras supply rich and dense visual and spatial information for various robotics tasks such as scene understanding, map reconstruction, and localization. Integrating depth and visual information can aid robots in localization and element mapping, advancing applications like 3D scene graph generation and Visual Simultaneous Localization and Mapping (VSLAM). While point cloud data containing such information is primarily used for enhanced scene understanding, exploiting their potential to capture and represent rich semantic information has yet to be adequately targeted. This paper presents a real-time pipeline for localizing building components, including wall and ground surfaces, by integrating geometric calculations for pure 3D plane detection followed by validating their semantic category using point cloud data from RGB-D cameras. It has a parallel multi-thread architecture to precisely estimate poses and equations of all the planes detected in the environment, filters the ones forming the map structure using a panoptic segmentation validation, and keeps only the validated building components. Incorporating the proposed method into a VSLAM framework confirmed that constraining the map with the detected environment-driven semantic elements can improve scene understanding and map reconstruction accuracy. It can also ensure (re-)association of these detected components into a unified 3D scene graph, bridging the gap between geometric accuracy and semantic understanding. Additionally, the pipeline allows for the detection of potential higher-level structural entities, such as rooms, by identifying the relationships between building components based on their layout.","sentences":["RGB-D cameras supply rich and dense visual and spatial information for various robotics tasks such as scene understanding, map reconstruction, and localization.","Integrating depth and visual information can aid robots in localization and element mapping, advancing applications like 3D scene graph generation and Visual Simultaneous Localization and Mapping (VSLAM).","While point cloud data containing such information is primarily used for enhanced scene understanding, exploiting their potential to capture and represent rich semantic information has yet to be adequately targeted.","This paper presents a real-time pipeline for localizing building components, including wall and ground surfaces, by integrating geometric calculations for pure 3D plane detection followed by validating their semantic category using point cloud data from RGB-D cameras.","It has a parallel multi-thread architecture to precisely estimate poses and equations of all the planes detected in the environment, filters the ones forming the map structure using a panoptic segmentation validation, and keeps only the validated building components.","Incorporating the proposed method into a VSLAM framework confirmed that constraining the map with the detected environment-driven semantic elements can improve scene understanding and map reconstruction accuracy.","It can also ensure (re-)association of these detected components into a unified 3D scene graph, bridging the gap between geometric accuracy and semantic understanding.","Additionally, the pipeline allows for the detection of potential higher-level structural entities, such as rooms, by identifying the relationships between building components based on their layout."],"url":"http://arxiv.org/abs/2409.06625v1"}
{"created":"2024-09-10 16:26:43","title":"A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio","abstract":"Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to obtain the unfamiliar language skill or adapt into new domains. The huge training cost of CPT often asks for cautious choice of key hyper-parameters such as the mixture ratio of extra language or domain corpus. However, there is no systematic study which bridge the gap between the optimal mixture ratio and the actual model performance, and the gap between experimental scaling law and the actual deployment in the full model size. In this paper, we perform CPT on Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal correlation between the Additional Language Mixture Ratio (ALMR) and the Learning Rate (LR) on the 8B size which directly indicate the optimal experimental set up. By thorough choice of hyper-parameter, and subsequent fine-tuning, the model capability is improved not only on the Chinese-related benchmark, but also some specific domains including math, coding and emotional intelligence. We deploy the final 70B version of LLM on an real-life chat system which obtain satisfying performance.","sentences":["Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to obtain the unfamiliar language skill or adapt into new domains.","The huge training cost of CPT often asks for cautious choice of key hyper-parameters such as the mixture ratio of extra language or domain corpus.","However, there is no systematic study which bridge the gap between the optimal mixture ratio and the actual model performance, and the gap between experimental scaling law and the actual deployment in the full model size.","In this paper, we perform CPT on Llama-3 8B and 70B to enhance its Chinese ability.","We study the optimal correlation between the Additional Language Mixture Ratio (ALMR) and the Learning Rate (LR) on the 8B size which directly indicate the optimal experimental set up.","By thorough choice of hyper-parameter, and subsequent fine-tuning, the model capability is improved not only on the Chinese-related benchmark, but also some specific domains including math, coding and emotional intelligence.","We deploy the final 70B version of LLM on an real-life chat system which obtain satisfying performance."],"url":"http://arxiv.org/abs/2409.06624v1"}
{"created":"2024-09-10 16:22:18","title":"Exploring Italian sentence embeddings properties through multi-tasking","abstract":"We investigate to what degree existing LLMs encode abstract linguistic information in Italian in a multi-task setting. We exploit curated synthetic data on a large scale -- several Blackbird Language Matrices (BLMs) problems in Italian -- and use them to study how sentence representations built using pre-trained language models encode specific syntactic and semantic information. We use a two-level architecture to model separately a compression of the sentence embeddings into a representation that contains relevant information for a task, and a BLM task. We then investigate whether we can obtain compressed sentence representations that encode syntactic and semantic information relevant to several BLM tasks. While we expected that the sentence structure -- in terms of sequence of phrases/chunks -- and chunk properties could be shared across tasks, performance and error analysis show that the clues for the different tasks are encoded in different manners in the sentence embeddings, suggesting that abstract linguistic notions such as constituents or thematic roles does not seem to be present in the pretrained sentence embeddings.","sentences":["We investigate to what degree existing LLMs encode abstract linguistic information in Italian in a multi-task setting.","We exploit curated synthetic data on a large scale -- several Blackbird Language Matrices (BLMs) problems in Italian -- and use them to study how sentence representations built using pre-trained language models encode specific syntactic and semantic information.","We use a two-level architecture to model separately a compression of the sentence embeddings into a representation that contains relevant information for a task, and a BLM task.","We then investigate whether we can obtain compressed sentence representations that encode syntactic and semantic information relevant to several BLM tasks.","While we expected that the sentence structure -- in terms of sequence of phrases/chunks -- and chunk properties could be shared across tasks, performance and error analysis show that the clues for the different tasks are encoded in different manners in the sentence embeddings, suggesting that abstract linguistic notions such as constituents or thematic roles does not seem to be present in the pretrained sentence embeddings."],"url":"http://arxiv.org/abs/2409.06622v1"}
{"created":"2024-09-10 16:16:34","title":"MVGaussian: High-Fidelity text-to-3D Content Generation with Multi-View Guidance and Surface Densification","abstract":"The field of text-to-3D content generation has made significant progress in generating realistic 3D objects, with existing methodologies like Score Distillation Sampling (SDS) offering promising guidance. However, these methods often encounter the \"Janus\" problem-multi-face ambiguities due to imprecise guidance. Additionally, while recent advancements in 3D gaussian splitting have shown its efficacy in representing 3D volumes, optimization of this representation remains largely unexplored. This paper introduces a unified framework for text-to-3D content generation that addresses these critical gaps. Our approach utilizes multi-view guidance to iteratively form the structure of the 3D model, progressively enhancing detail and accuracy. We also introduce a novel densification algorithm that aligns gaussians close to the surface, optimizing the structural integrity and fidelity of the generated models. Extensive experiments validate our approach, demonstrating that it produces high-quality visual outputs with minimal time cost. Notably, our method achieves high-quality results within half an hour of training, offering a substantial efficiency gain over most existing methods, which require hours of training time to achieve comparable results.","sentences":["The field of text-to-3D content generation has made significant progress in generating realistic 3D objects, with existing methodologies like Score Distillation Sampling (SDS) offering promising guidance.","However, these methods often encounter the \"Janus\" problem-multi-face ambiguities due to imprecise guidance.","Additionally, while recent advancements in 3D gaussian splitting have shown its efficacy in representing 3D volumes, optimization of this representation remains largely unexplored.","This paper introduces a unified framework for text-to-3D content generation that addresses these critical gaps.","Our approach utilizes multi-view guidance to iteratively form the structure of the 3D model, progressively enhancing detail and accuracy.","We also introduce a novel densification algorithm that aligns gaussians close to the surface, optimizing the structural integrity and fidelity of the generated models.","Extensive experiments validate our approach, demonstrating that it produces high-quality visual outputs with minimal time cost.","Notably, our method achieves high-quality results within half an hour of training, offering a substantial efficiency gain over most existing methods, which require hours of training time to achieve comparable results."],"url":"http://arxiv.org/abs/2409.06620v1"}
{"created":"2024-09-10 16:15:01","title":"Hierarchical Multi-Label Classification with Missing Information for Benthic Habitat Imagery","abstract":"In this work, we apply state-of-the-art self-supervised learning techniques on a large dataset of seafloor imagery, \\textit{BenthicNet}, and study their performance for a complex hierarchical multi-label (HML) classification downstream task. In particular, we demonstrate the capacity to conduct HML training in scenarios where there exist multiple levels of missing annotation information, an important scenario for handling heterogeneous real-world data collected by multiple research groups with differing data collection protocols. We find that, when using smaller one-hot image label datasets typical of local or regional scale benthic science projects, models pre-trained with self-supervision on a larger collection of in-domain benthic data outperform models pre-trained on ImageNet. In the HML setting, we find the model can attain a deeper and more precise classification if it is pre-trained with self-supervision on in-domain data. We hope this work can establish a benchmark for future models in the field of automated underwater image annotation tasks and can guide work in other domains with hierarchical annotations of mixed resolution.","sentences":["In this work, we apply state-of-the-art self-supervised learning techniques on a large dataset of seafloor imagery, \\textit{BenthicNet}, and study their performance for a complex hierarchical multi-label (HML) classification downstream task.","In particular, we demonstrate the capacity to conduct HML training in scenarios where there exist multiple levels of missing annotation information, an important scenario for handling heterogeneous real-world data collected by multiple research groups with differing data collection protocols.","We find that, when using smaller one-hot image label datasets typical of local or regional scale benthic science projects, models pre-trained with self-supervision on a larger collection of in-domain benthic data outperform models pre-trained on ImageNet.","In the HML setting, we find the model can attain a deeper and more precise classification if it is pre-trained with self-supervision on in-domain data.","We hope this work can establish a benchmark for future models in the field of automated underwater image annotation tasks and can guide work in other domains with hierarchical annotations of mixed resolution."],"url":"http://arxiv.org/abs/2409.06618v1"}
{"created":"2024-09-10 16:14:46","title":"When to Extract ReID Features: A Selective Approach for Improved Multiple Object Tracking","abstract":"Extracting and matching Re-Identification (ReID) features is used by many state-of-the-art (SOTA) Multiple Object Tracking (MOT) methods, particularly effective against frequent and long-term occlusions. While end-to-end object detection and tracking have been the main focus of recent research, they have yet to outperform traditional methods in benchmarks like MOT17 and MOT20. Thus, from an application standpoint, methods with separate detection and embedding remain the best option for accuracy, modularity, and ease of implementation, though they are impractical for edge devices due to the overhead involved. In this paper, we investigate a selective approach to minimize the overhead of feature extraction while preserving accuracy, modularity, and ease of implementation. This approach can be integrated into various SOTA methods. We demonstrate its effectiveness by applying it to StrongSORT and Deep OC-SORT. Experiments on MOT17, MOT20, and DanceTrack datasets show that our mechanism retains the advantages of feature extraction during occlusions while significantly reducing runtime. Additionally, it improves accuracy by preventing confusion in the feature-matching stage, particularly in cases of deformation and appearance similarity, which are common in DanceTrack. https://github.com/emirhanbayar/Fast-StrongSORT, https://github.com/emirhanbayar/Fast-Deep-OC-SORT","sentences":["Extracting and matching Re-Identification (ReID) features is used by many state-of-the-art (SOTA)","Multiple Object Tracking (MOT) methods, particularly effective against frequent and long-term occlusions.","While end-to-end object detection and tracking have been the main focus of recent research, they have yet to outperform traditional methods in benchmarks like MOT17 and MOT20.","Thus, from an application standpoint, methods with separate detection and embedding remain the best option for accuracy, modularity, and ease of implementation, though they are impractical for edge devices due to the overhead involved.","In this paper, we investigate a selective approach to minimize the overhead of feature extraction while preserving accuracy, modularity, and ease of implementation.","This approach can be integrated into various SOTA methods.","We demonstrate its effectiveness by applying it to StrongSORT and Deep OC-SORT.","Experiments on MOT17, MOT20, and DanceTrack datasets show that our mechanism retains the advantages of feature extraction during occlusions while significantly reducing runtime.","Additionally, it improves accuracy by preventing confusion in the feature-matching stage, particularly in cases of deformation and appearance similarity, which are common in DanceTrack.","https://github.com/emirhanbayar/Fast-StrongSORT, https://github.com/emirhanbayar/Fast-Deep-OC-SORT"],"url":"http://arxiv.org/abs/2409.06617v1"}
{"created":"2024-09-10 16:11:57","title":"One-Shot Imitation under Mismatched Execution","abstract":"Human demonstrations as prompts are a powerful way to program robots to do long-horizon manipulation tasks. However, directly translating such demonstrations into robot-executable actions poses significant challenges due to execution mismatches, such as different movement styles and physical capabilities. Existing methods either rely on robot-demonstrator paired data, which is infeasible to scale, or overly rely on frame-level visual similarities, which fail to hold. To address these challenges, we propose RHyME, a novel framework that automatically establishes task execution correspondences between the robot and the demonstrator by using optimal transport costs. Given long-horizon robot demonstrations, RHyME synthesizes semantically equivalent human demonstrations by retrieving and composing similar short-horizon human clips, facilitating effective policy training without the need for paired data. We show that RHyME outperforms a range of baselines across various cross-embodiment datasets on all degrees of mismatches. Through detailed analysis, we uncover insights for learning and leveraging cross-embodiment visual representations.","sentences":["Human demonstrations as prompts are a powerful way to program robots to do long-horizon manipulation tasks.","However, directly translating such demonstrations into robot-executable actions poses significant challenges due to execution mismatches, such as different movement styles and physical capabilities.","Existing methods either rely on robot-demonstrator paired data, which is infeasible to scale, or overly rely on frame-level visual similarities, which fail to hold.","To address these challenges, we propose RHyME, a novel framework that automatically establishes task execution correspondences between the robot and the demonstrator by using optimal transport costs.","Given long-horizon robot demonstrations, RHyME synthesizes semantically equivalent human demonstrations by retrieving and composing similar short-horizon human clips, facilitating effective policy training without the need for paired data.","We show that RHyME outperforms a range of baselines across various cross-embodiment datasets on all degrees of mismatches.","Through detailed analysis, we uncover insights for learning and leveraging cross-embodiment visual representations."],"url":"http://arxiv.org/abs/2409.06615v1"}
{"created":"2024-09-10 16:06:23","title":"Fixed-budget and Multiple-issue Quadratic Voting","abstract":"Quadratic Voting (QV) is a social choice mechanism that addresses the \"tyranny of the majority\" of one-person-one-vote mechanisms. Agents express not only their preference ordering but also their preference intensity by purchasing $x$ votes at a cost of $x^2$. Although this pricing rule maximizes utilitarian social welfare and is robust against strategic manipulation, it has not yet found many real-life applications. One key reason is that the original QV mechanism does not limit voter budgets. Two variations have since been proposed: a (no-budget) multiple-issue generalization and a fixed-budget version that allocates a constant number of credits to agents for use in multiple binary elections. While some analysis has been undertaken with respect to the multiple-issue variation, the fixed-budget version has not yet been rigorously studied. In this work, we formally propose a novel fixed-budget multiple-issue QV mechanism. This integrates the advantages of both the aforementioned variations, laying the theoretical foundations for practical use cases of QV, such as multi-agent resource allocation. We analyse our fixed-budget multiple-issue QV by comparing it with traditional voting systems, exploring potential collusion strategies, and showing that checking whether strategy profiles form a Nash equilibrium is tractable.","sentences":["Quadratic Voting (QV) is a social choice mechanism that addresses the \"tyranny of the majority\" of one-person-one-vote mechanisms.","Agents express not only their preference ordering but also their preference intensity by purchasing $x$ votes at a cost of $x^2$. Although this pricing rule maximizes utilitarian social welfare and is robust against strategic manipulation, it has not yet found many real-life applications.","One key reason is that the original QV mechanism does not limit voter budgets.","Two variations have since been proposed: a (no-budget) multiple-issue generalization and a fixed-budget version that allocates a constant number of credits to agents for use in multiple binary elections.","While some analysis has been undertaken with respect to the multiple-issue variation, the fixed-budget version has not yet been rigorously studied.","In this work, we formally propose a novel fixed-budget multiple-issue QV mechanism.","This integrates the advantages of both the aforementioned variations, laying the theoretical foundations for practical use cases of QV, such as multi-agent resource allocation.","We analyse our fixed-budget multiple-issue QV by comparing it with traditional voting systems, exploring potential collusion strategies, and showing that checking whether strategy profiles form a Nash equilibrium is tractable."],"url":"http://arxiv.org/abs/2409.06614v1"}
{"created":"2024-09-10 16:05:25","title":"DemoStart: Demonstration-led auto-curriculum applied to sim-to-real with multi-fingered robots","abstract":"We present DemoStart, a novel auto-curriculum reinforcement learning method capable of learning complex manipulation behaviors on an arm equipped with a three-fingered robotic hand, from only a sparse reward and a handful of demonstrations in simulation. Learning from simulation drastically reduces the development cycle of behavior generation, and domain randomization techniques are leveraged to achieve successful zero-shot sim-to-real transfer. Transferred policies are learned directly from raw pixels from multiple cameras and robot proprioception. Our approach outperforms policies learned from demonstrations on the real robot and requires 100 times fewer demonstrations, collected in simulation. More details and videos in https://sites.google.com/view/demostart.","sentences":["We present DemoStart, a novel auto-curriculum reinforcement learning method capable of learning complex manipulation behaviors on an arm equipped with a three-fingered robotic hand, from only a sparse reward and a handful of demonstrations in simulation.","Learning from simulation drastically reduces the development cycle of behavior generation, and domain randomization techniques are leveraged to achieve successful zero-shot sim-to-real transfer.","Transferred policies are learned directly from raw pixels from multiple cameras and robot proprioception.","Our approach outperforms policies learned from demonstrations on the real robot and requires 100 times fewer demonstrations, collected in simulation.","More details and videos in https://sites.google.com/view/demostart."],"url":"http://arxiv.org/abs/2409.06613v1"}
{"created":"2024-09-10 16:04:10","title":"Label-free Monitoring of Self-Supervised Learning Progress","abstract":"Self-supervised learning (SSL) is an effective method for exploiting unlabelled data to learn a high-level embedding space that can be used for various downstream tasks. However, existing methods to monitor the quality of the encoder -- either during training for one model or to compare several trained models -- still rely on access to annotated data. When SSL methodologies are applied to new data domains, a sufficiently large labelled dataset may not always be available. In this study, we propose several evaluation metrics which can be applied on the embeddings of unlabelled data and investigate their viability by comparing them to linear probe accuracy (a common metric which utilizes an annotated dataset). In particular, we apply $k$-means clustering and measure the clustering quality with the silhouette score and clustering agreement. We also measure the entropy of the embedding distribution. We find that while the clusters did correspond better to the ground truth annotations as training of the network progressed, label-free clustering metrics correlated with the linear probe accuracy only when training with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally, although entropy did not always have strong correlations with LP accuracy, this appears to be due to instability arising from early training, with the metric stabilizing and becoming more reliable at later stages of learning. Furthermore, while entropy generally decreases as learning progresses, this trend reverses for SimSiam. More research is required to establish the cause for this unexpected behaviour. Lastly, we find that while clustering based approaches are likely only viable for same-architecture comparisons, entropy may be architecture-independent.","sentences":["Self-supervised learning (SSL) is an effective method for exploiting unlabelled data to learn a high-level embedding space that can be used for various downstream tasks.","However, existing methods to monitor the quality of the encoder -- either during training for one model or to compare several trained models -- still rely on access to annotated data.","When SSL methodologies are applied to new data domains, a sufficiently large labelled dataset may not always be available.","In this study, we propose several evaluation metrics which can be applied on the embeddings of unlabelled data and investigate their viability by comparing them to linear probe accuracy (a common metric which utilizes an annotated dataset).","In particular, we apply $k$-means clustering and measure the clustering quality with the silhouette score and clustering agreement.","We also measure the entropy of the embedding distribution.","We find that while the clusters did correspond better to the ground truth annotations as training of the network progressed, label-free clustering metrics correlated with the linear probe accuracy only when training with SSL methods SimCLR and MoCo-v2, but not with SimSiam.","Additionally, although entropy did not always have strong correlations with LP accuracy, this appears to be due to instability arising from early training, with the metric stabilizing and becoming more reliable at later stages of learning.","Furthermore, while entropy generally decreases as learning progresses, this trend reverses for SimSiam.","More research is required to establish the cause for this unexpected behaviour.","Lastly, we find that while clustering based approaches are likely only viable for same-architecture comparisons, entropy may be architecture-independent."],"url":"http://arxiv.org/abs/2409.06612v1"}
{"created":"2024-09-10 16:03:27","title":"Bayesian hypergame approach to equilibrium stability and robustness in moving target defense","abstract":"We investigate the equilibrium stability and robustness in a class of moving target defense problems, in which players have both incomplete information and asymmetric cognition. We first establish a Bayesian Stackelberg game model for incomplete information and then employ a hypergame reformulation to address asymmetric cognition. With the core concept of the hyper Bayesian Nash equilibrium (HBNE), a condition for achieving both the strategic and cognitive stability in equilibria can be realized by solving linear equations. Moreover, to deal with players' underlying perturbed knowledge, we study the equilibrium robustness by presenting a condition of robust HBNE under the given configuration. Experiments evaluate our theoretical results.","sentences":["We investigate the equilibrium stability and robustness in a class of moving target defense problems, in which players have both incomplete information and asymmetric cognition.","We first establish a Bayesian Stackelberg game model for incomplete information and then employ a hypergame reformulation to address asymmetric cognition.","With the core concept of the hyper Bayesian Nash equilibrium (HBNE), a condition for achieving both the strategic and cognitive stability in equilibria can be realized by solving linear equations.","Moreover, to deal with players' underlying perturbed knowledge, we study the equilibrium robustness by presenting a condition of robust HBNE under the given configuration.","Experiments evaluate our theoretical results."],"url":"http://arxiv.org/abs/2409.06610v1"}
{"created":"2024-09-10 16:02:12","title":"Improving the Precision of CNNs for Magnetic Resonance Spectral Modeling","abstract":"Magnetic resonance spectroscopic imaging is a widely available imaging modality that can non-invasively provide a metabolic profile of the tissue of interest, yet is challenging to integrate clinically. One major reason is the expensive, expert data processing and analysis that is required. Using machine learning to predict MRS-related quantities offers avenues around this problem, but deep learning models bring their own challenges, especially model trust. Current research trends focus primarily on mean error metrics, but comprehensive precision metrics are also needed, e.g. standard deviations, confidence intervals, etc.. This work highlights why more comprehensive error characterization is important and how to improve the precision of CNNs for spectral modeling, a quantitative task. The results highlight advantages and trade-offs of these techniques that should be considered when addressing such regression tasks with CNNs. Detailed insights into the underlying mechanisms of each technique, and how they interact with other techniques, are discussed in depth.","sentences":["Magnetic resonance spectroscopic imaging is a widely available imaging modality that can non-invasively provide a metabolic profile of the tissue of interest, yet is challenging to integrate clinically.","One major reason is the expensive, expert data processing and analysis that is required.","Using machine learning to predict MRS-related quantities offers avenues around this problem, but deep learning models bring their own challenges, especially model trust.","Current research trends focus primarily on mean error metrics, but comprehensive precision metrics are also needed, e.g. standard deviations, confidence intervals, etc.. This work highlights why more comprehensive error characterization is important and how to improve the precision of CNNs for spectral modeling, a quantitative task.","The results highlight advantages and trade-offs of these techniques that should be considered when addressing such regression tasks with CNNs.","Detailed insights into the underlying mechanisms of each technique, and how they interact with other techniques, are discussed in depth."],"url":"http://arxiv.org/abs/2409.06609v1"}
{"created":"2024-09-10 16:00:26","title":"Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy","abstract":"Application of Unmanned Aerial Vehicles (UAVs) in search and rescue, emergency management, and law enforcement has gained traction with the advent of low-cost platforms and sensor payloads. The emergence of hybrid neural and symbolic AI approaches for complex reasoning is expected to further push the boundaries of these applications with decreasing levels of human intervention. However, current UAV simulation environments lack semantic context suited to this hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing) provides a simulation-based autonomy software framework that supports the training, testing and assurance of neuro-symbolic algorithms for autonomous maneuver and perception reasoning. HAMERITT includes scenario generation capabilities that offer mission-relevant contextual symbolic information in addition to raw sensor data. Scenarios include symbolic descriptions for entities of interest and their relations to scene elements, as well as spatial-temporal constraints in the form of time-bounded areas of interest with prior probabilities and restricted zones within those areas. HAMERITT also features support for training distinct algorithm threads for maneuver vs. perception within an end-to-end mission run. Future work includes improving scenario realism and scaling symbolic context generation through automated workflow.","sentences":["Application of Unmanned Aerial Vehicles (UAVs) in search and rescue, emergency management, and law enforcement has gained traction with the advent of low-cost platforms and sensor payloads.","The emergence of hybrid neural and symbolic AI approaches for complex reasoning is expected to further push the boundaries of these applications with decreasing levels of human intervention.","However, current UAV simulation environments lack semantic context suited to this hybrid approach.","To address this gap, HAMERITT (Hybrid Ai Mission Environment for RapId Training and Testing) provides a simulation-based autonomy software framework that supports the training, testing and assurance of neuro-symbolic algorithms for autonomous maneuver and perception reasoning.","HAMERITT includes scenario generation capabilities that offer mission-relevant contextual symbolic information in addition to raw sensor data.","Scenarios include symbolic descriptions for entities of interest and their relations to scene elements, as well as spatial-temporal constraints in the form of time-bounded areas of interest with prior probabilities and restricted zones within those areas.","HAMERITT also features support for training distinct algorithm threads for maneuver vs. perception within an end-to-end mission run.","Future work includes improving scenario realism and scaling symbolic context generation through automated workflow."],"url":"http://arxiv.org/abs/2409.06608v1"}
{"created":"2024-09-10 16:00:22","title":"An Ontology-based Approach Towards Traceable Behavior Specifications in Automated Driving","abstract":"Vehicles in public traffic that are equipped with Automated Driving Systems are subject to a number of expectations: Among other aspects, their behavior should be safe, conforming to the rules of the road and provide mobility to their users. This poses challenges for the developers of such systems: Developers are responsible for specifying this behavior, for example, in terms of requirements at system design time. As we will discuss in the article, this specification always involves the need for assumptions and trade-offs. As a result, insufficiencies in such a behavior specification can occur that can potentially lead to unsafe system behavior. In order to support the identification of specification insufficiencies, requirements and respective assumptions need to be made explicit. In this article, we propose the Semantic Norm Behavior Analysis as an ontology-based approach to specify the behavior for an Automated Driving System equipped vehicle. We use ontologies to formally represent specified behavior for a targeted operational environment, and to establish traceability between specified behavior and the addressed stakeholder needs. Furthermore, we illustrate the application of the Semantic Norm Behavior Analysis in two example scenarios and evaluate our results.","sentences":["Vehicles in public traffic that are equipped with Automated Driving Systems are subject to a number of expectations: Among other aspects, their behavior should be safe, conforming to the rules of the road and provide mobility to their users.","This poses challenges for the developers of such systems: Developers are responsible for specifying this behavior, for example, in terms of requirements at system design time.","As we will discuss in the article, this specification always involves the need for assumptions and trade-offs.","As a result, insufficiencies in such a behavior specification can occur that can potentially lead to unsafe system behavior.","In order to support the identification of specification insufficiencies, requirements and respective assumptions need to be made explicit.","In this article, we propose the Semantic Norm Behavior Analysis as an ontology-based approach to specify the behavior for an Automated Driving System equipped vehicle.","We use ontologies to formally represent specified behavior for a targeted operational environment, and to establish traceability between specified behavior and the addressed stakeholder needs.","Furthermore, we illustrate the application of the Semantic Norm Behavior Analysis in two example scenarios and evaluate our results."],"url":"http://arxiv.org/abs/2409.06607v1"}
{"created":"2024-09-10 15:55:53","title":"A Practical Gated Recurrent Transformer Network Incorporating Multiple Fusions for Video Denoising","abstract":"State-of-the-art (SOTA) video denoising methods employ multi-frame simultaneous denoising mechanisms, resulting in significant delays (e.g., 16 frames), making them impractical for real-time cameras. To overcome this limitation, we propose a multi-fusion gated recurrent Transformer network (GRTN) that achieves SOTA denoising performance with only a single-frame delay. Specifically, the spatial denoising module extracts features from the current frame, while the reset gate selects relevant information from the previous frame and fuses it with current frame features via the temporal denoising module. The update gate then further blends this result with the previous frame features, and the reconstruction module integrates it with the current frame. To robustly compute attention for noisy features, we propose a residual simplified Swin Transformer with Euclidean distance (RSSTE) in the spatial and temporal denoising modules. Comparative objective and subjective results show that our GRTN achieves denoising performance comparable to SOTA multi-frame delay networks, with only a single-frame delay.","sentences":["State-of-the-art (SOTA) video denoising methods employ multi-frame simultaneous denoising mechanisms, resulting in significant delays (e.g., 16 frames), making them impractical for real-time cameras.","To overcome this limitation, we propose a multi-fusion gated recurrent Transformer network (GRTN) that achieves SOTA denoising performance with only a single-frame delay.","Specifically, the spatial denoising module extracts features from the current frame, while the reset gate selects relevant information from the previous frame and fuses it with current frame features via the temporal denoising module.","The update gate then further blends this result with the previous frame features, and the reconstruction module integrates it with the current frame.","To robustly compute attention for noisy features, we propose a residual simplified Swin Transformer with Euclidean distance (RSSTE) in the spatial and temporal denoising modules.","Comparative objective and subjective results show that our GRTN achieves denoising performance comparable to SOTA multi-frame delay networks, with only a single-frame delay."],"url":"http://arxiv.org/abs/2409.06603v1"}
{"created":"2024-09-10 15:51:15","title":"Alleviating Hallucinations in Large Language Models with Scepticism Modeling","abstract":"Hallucinations is a major challenge for large language models (LLMs), prevents adoption in diverse fields. Uncertainty estimation could be used for alleviating the damages of hallucinations. The skeptical emotion of human could be useful for enhancing the ability of self estimation. Inspirited by this observation, we proposed a new approach called Skepticism Modeling (SM). This approach is formalized by combining the information of token and logits for self estimation. We construct the doubt emotion aware data, perform continual pre-training, and then fine-tune the LLMs, improve their ability of self estimation. Experimental results demonstrate this new approach effectively enhances a model's ability to estimate their uncertainty, and validate its generalization ability of other tasks by out-of-domain experiments.","sentences":["Hallucinations is a major challenge for large language models (LLMs), prevents adoption in diverse fields.","Uncertainty estimation could be used for alleviating the damages of hallucinations.","The skeptical emotion of human could be useful for enhancing the ability of self estimation.","Inspirited by this observation, we proposed a new approach called Skepticism Modeling (SM).","This approach is formalized by combining the information of token and logits for self estimation.","We construct the doubt emotion aware data, perform continual pre-training, and then fine-tune the LLMs, improve their ability of self estimation.","Experimental results demonstrate this new approach effectively enhances a model's ability to estimate their uncertainty, and validate its generalization ability of other tasks by out-of-domain experiments."],"url":"http://arxiv.org/abs/2409.06601v1"}
{"created":"2024-09-10 15:39:32","title":"GroUSE: A Benchmark to Evaluate Evaluators in Grounded Question Answering","abstract":"Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use Large Language Models (LLMs) alongside private and up-to-date knowledge bases. In this work, we address the challenges of using LLM-as-a-Judge when evaluating grounded answers generated by RAG systems. To assess the calibration and discrimination capabilities of judge models, we identify 7 generator failure modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a meta-evaluation benchmark of 144 unit tests. This benchmark reveals that existing automated RAG evaluation frameworks often overlook important failure modes, even when using GPT-4 as a judge.   To improve on the current design of automated RAG evaluation frameworks, we propose a novel pipeline and find that while closed models perform well on GroUSE, state-of-the-art open-source judges do not generalize to our proposed criteria, despite strong correlation with GPT-4's judgement. Our findings suggest that correlation with GPT-4 is an incomplete proxy for the practical performance of judge models and should be supplemented with evaluations on unit tests for precise failure mode detection.   We further show that finetuning Llama-3 on GPT-4's reasoning traces significantly boosts its evaluation capabilities, improving upon both correlation with GPT-4's evaluations and calibration on reference situations.","sentences":["Retrieval-Augmented Generation (RAG) has emerged as a common paradigm to use Large Language Models (LLMs) alongside private and up-to-date knowledge bases.","In this work, we address the challenges of using LLM-as-a-Judge when evaluating grounded answers generated by RAG systems.","To assess the calibration and discrimination capabilities of judge models, we identify 7 generator failure modes and introduce GroUSE (Grounded QA Unitary Scoring of Evaluators), a meta-evaluation benchmark of 144 unit tests.","This benchmark reveals that existing automated RAG evaluation frameworks often overlook important failure modes, even when using GPT-4 as a judge.   ","To improve on the current design of automated RAG evaluation frameworks, we propose a novel pipeline and find that while closed models perform well on GroUSE, state-of-the-art open-source judges do not generalize to our proposed criteria, despite strong correlation with GPT-4's judgement.","Our findings suggest that correlation with GPT-4 is an incomplete proxy for the practical performance of judge models and should be supplemented with evaluations on unit tests for precise failure mode detection.   ","We further show that finetuning Llama-3 on GPT-4's reasoning traces significantly boosts its evaluation capabilities, improving upon both correlation with GPT-4's evaluations and calibration on reference situations."],"url":"http://arxiv.org/abs/2409.06595v1"}
{"created":"2024-09-10 15:37:23","title":"How to Verify Any (Reasonable) Distribution Property: Computationally Sound Argument Systems for Distributions","abstract":"As statistical analyses become more central to science, industry and society, there is a growing need to ensure correctness of their results. Approximate correctness can be verified by replicating the entire analysis, but can we verify without replication? Building on a recent line of work, we study proof-systems that allow a probabilistic verifier to ascertain that the results of an analysis are approximately correct, while drawing fewer samples and using less computational resources than would be needed to replicate the analysis. We focus on distribution testing problems: verifying that an unknown distribution is close to having a claimed property.   Our main contribution is a interactive protocol between a verifier and an untrusted prover, which can be used to verify any distribution property that can be decided in polynomial time given a full and explicit description of the distribution. If the distribution is at statistical distance $\\varepsilon$ from having the property, then the verifier rejects with high probability. This soundness property holds against any polynomial-time strategy that a cheating prover might follow, assuming the existence of collision-resistant hash functions (a standard assumption in cryptography). For distributions over a domain of size $N$, the protocol consists of $4$ messages and the communication complexity and verifier runtime are roughly $\\widetilde{O}\\left(\\sqrt{N} / \\varepsilon^2 \\right)$. The verifier's sample complexity is $\\widetilde{O}\\left(\\sqrt{N} / \\varepsilon^2 \\right)$, and this is optimal up to $\\polylog(N)$ factors (for any protocol, regardless of its communication complexity). Even for simple properties, approximately deciding whether an unknown distribution has the property can require quasi-linear sample complexity and running time. For any such property, our protocol provides a quadratic speedup over replicating the analysis.","sentences":["As statistical analyses become more central to science, industry and society, there is a growing need to ensure correctness of their results.","Approximate correctness can be verified by replicating the entire analysis, but can we verify without replication?","Building on a recent line of work, we study proof-systems that allow a probabilistic verifier to ascertain that the results of an analysis are approximately correct, while drawing fewer samples and using less computational resources than would be needed to replicate the analysis.","We focus on distribution testing problems: verifying that an unknown distribution is close to having a claimed property.   ","Our main contribution is a interactive protocol between a verifier and an untrusted prover, which can be used to verify any distribution property that can be decided in polynomial time given a full and explicit description of the distribution.","If the distribution is at statistical distance $\\varepsilon$ from having the property, then the verifier rejects with high probability.","This soundness property holds against any polynomial-time strategy that a cheating prover might follow, assuming the existence of collision-resistant hash functions (a standard assumption in cryptography).","For distributions over a domain of size $N$, the protocol consists of $4$ messages and the communication complexity and verifier runtime are roughly $\\widetilde{O}\\left(\\sqrt{N} / \\varepsilon^2","\\right)$.","The verifier's sample complexity is $\\widetilde{O}\\left(\\sqrt{N} / \\varepsilon^2 \\right)$, and this is optimal up to $\\polylog(N)$ factors (for any protocol, regardless of its communication complexity).","Even for simple properties, approximately deciding whether an unknown distribution has the property can require quasi-linear sample complexity and running time.","For any such property, our protocol provides a quadratic speedup over replicating the analysis."],"url":"http://arxiv.org/abs/2409.06594v1"}
{"created":"2024-09-10 15:31:37","title":"Lightweight Multiscale Feature Fusion Super-Resolution Network Based on Two-branch Convolution and Transformer","abstract":"The single image super-resolution(SISR) algorithms under deep learning currently have two main models, one based on convolutional neural networks and the other based on Transformer. The former uses the stacking of convolutional layers with different convolutional kernel sizes to design the model, which enables the model to better extract the local features of the image; the latter uses the self-attention mechanism to design the model, which allows the model to establish long-distance dependencies between image pixel points through the self-attention mechanism and then better extract the global features of the image. However, both of the above methods face their problems. Based on this, this paper proposes a new lightweight multi-scale feature fusion network model based on two-way complementary convolutional and Transformer, which integrates the respective features of Transformer and convolutional neural networks through a two-branch network architecture, to realize the mutual fusion of global and local information. Meanwhile, considering the partial loss of information caused by the low-pixel images trained by the deep neural network, this paper designs a modular connection method of multi-stage feature supplementation to fuse the feature maps extracted from the shallow stage of the model with those extracted from the deep stage of the model, to minimize the loss of the information in the feature images that is beneficial to the image restoration as much as possible, to facilitate the obtaining of a higher-quality restored image. The practical results finally show that the model proposed in this paper is optimal in image recovery performance when compared with other lightweight models with the same amount of parameters.","sentences":["The single image super-resolution(SISR) algorithms under deep learning currently have two main models, one based on convolutional neural networks and the other based on Transformer.","The former uses the stacking of convolutional layers with different convolutional kernel sizes to design the model, which enables the model to better extract the local features of the image; the latter uses the self-attention mechanism to design the model, which allows the model to establish long-distance dependencies between image pixel points through the self-attention mechanism and then better extract the global features of the image.","However, both of the above methods face their problems.","Based on this, this paper proposes a new lightweight multi-scale feature fusion network model based on two-way complementary convolutional and Transformer, which integrates the respective features of Transformer and convolutional neural networks through a two-branch network architecture, to realize the mutual fusion of global and local information.","Meanwhile, considering the partial loss of information caused by the low-pixel images trained by the deep neural network, this paper designs a modular connection method of multi-stage feature supplementation to fuse the feature maps extracted from the shallow stage of the model with those extracted from the deep stage of the model, to minimize the loss of the information in the feature images that is beneficial to the image restoration as much as possible, to facilitate the obtaining of a higher-quality restored image.","The practical results finally show that the model proposed in this paper is optimal in image recovery performance when compared with other lightweight models with the same amount of parameters."],"url":"http://arxiv.org/abs/2409.06590v1"}
{"created":"2024-09-10 15:30:20","title":"Seg-HGNN: Unsupervised and Light-Weight Image Segmentation with Hyperbolic Graph Neural Networks","abstract":"Image analysis in the euclidean space through linear hyperspaces is well studied. However, in the quest for more effective image representations, we turn to hyperbolic manifolds. They provide a compelling alternative to capture complex hierarchical relationships in images with remarkably small dimensionality. To demonstrate hyperbolic embeddings' competence, we introduce a light-weight hyperbolic graph neural network for image segmentation, encompassing patch-level features in a very small embedding size. Our solution, Seg-HGNN, surpasses the current best unsupervised method by 2.5\\%, 4\\% on VOC-07, VOC-12 for localization, and by 0.8\\%, 1.3\\% on CUB-200, ECSSD for segmentation, respectively. With less than 7.5k trainable parameters, Seg-HGNN delivers effective and fast ($\\approx 2$ images/second) results on very standard GPUs like the GTX1650. This empirical evaluation presents compelling evidence of the efficacy and potential of hyperbolic representations for vision tasks.","sentences":["Image analysis in the euclidean space through linear hyperspaces is well studied.","However, in the quest for more effective image representations, we turn to hyperbolic manifolds.","They provide a compelling alternative to capture complex hierarchical relationships in images with remarkably small dimensionality.","To demonstrate hyperbolic embeddings' competence, we introduce a light-weight hyperbolic graph neural network for image segmentation, encompassing patch-level features in a very small embedding size.","Our solution, Seg-HGNN, surpasses the current best unsupervised method by 2.5\\%, 4\\% on VOC-07, VOC-12 for localization, and by 0.8\\%, 1.3\\% on CUB-200, ECSSD for segmentation, respectively.","With less than 7.5k trainable parameters, Seg-HGNN delivers effective and fast ($\\approx 2$ images/second) results on very standard GPUs like the GTX1650.","This empirical evaluation presents compelling evidence of the efficacy and potential of hyperbolic representations for vision tasks."],"url":"http://arxiv.org/abs/2409.06589v1"}
{"created":"2024-09-10 15:26:58","title":"Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records","abstract":"Background: Hip replacement procedures improve patient lives by relieving pain and restoring mobility. Predicting hip replacement in advance could reduce pain by enabling timely interventions, prioritising individuals for surgery or rehabilitation, and utilising physiotherapy to potentially delay the need for joint replacement. This study predicts hip replacement a year in advance to enhance quality of life and health service efficiency. Methods: Adapting previous work using Temporal Graph Convolutional Neural Network (TG-CNN) models, we construct temporal graphs from primary care medical event codes, sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip replacement risk. We match hip replacement cases to controls by age, sex, and Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187 controls, predicts hip replacement one year in advance. We validate the model on two unseen datasets, recalibrating for class imbalance. Additionally, we conduct an ablation study and compare against four baseline models. Results: Our best model predicts hip replacement risk one year in advance with an AUROC of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209), achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after recalibration. Conclusions: The TG-CNN model effectively predicts hip replacement risk by identifying patterns in patient trajectories, potentially improving understanding and management of hip-related conditions.","sentences":["Background: Hip replacement procedures improve patient lives by relieving pain and restoring mobility.","Predicting hip replacement in advance could reduce pain by enabling timely interventions, prioritising individuals for surgery or rehabilitation, and utilising physiotherapy to potentially delay the need for joint replacement.","This study predicts hip replacement a year in advance to enhance quality of life and health service efficiency.","Methods: Adapting previous work using Temporal Graph Convolutional Neural Network (TG-CNN) models, we construct temporal graphs from primary care medical event codes, sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip replacement risk.","We match hip replacement cases to controls by age, sex, and Index of Multiple Deprivation.","The model, trained on 9,187 cases and 9,187 controls, predicts hip replacement one year in advance.","We validate the model on two unseen datasets, recalibrating for class imbalance.","Additionally, we conduct an ablation study and compare against four baseline models.","Results: Our best model predicts hip replacement risk one year in advance with an AUROC of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209), achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after recalibration.","Conclusions: The TG-CNN model effectively predicts hip replacement risk by identifying patterns in patient trajectories, potentially improving understanding and management of hip-related conditions."],"url":"http://arxiv.org/abs/2409.06585v1"}
{"created":"2024-09-10 15:26:38","title":"Transtreaming: Adaptive Delay-aware Transformer for Real-time Streaming Perception","abstract":"Real-time object detection is critical for the decision-making process for many real-world applications, such as collision avoidance and path planning in autonomous driving. This work presents an innovative real-time streaming perception method, Transtreaming, which addresses the challenge of real-time object detection with dynamic computational delay. The core innovation of Transtreaming lies in its adaptive delay-aware transformer, which can concurrently predict multiple future frames and select the output that best matches the real-world present time, compensating for any system-induced computation delays. The proposed model outperforms the existing state-of-the-art methods, even in single-frame detection scenarios, by leveraging a transformer-based methodology. It demonstrates robust performance across a range of devices, from powerful V100 to modest 2080Ti, achieving the highest level of perceptual accuracy on all platforms. Unlike most state-of-the-art methods that struggle to complete computation within a single frame on less powerful devices, Transtreaming meets the stringent real-time processing requirements on all kinds of devices. The experimental results emphasize the system's adaptability and its potential to significantly improve the safety and reliability for many real-world systems, such as autonomous driving.","sentences":["Real-time object detection is critical for the decision-making process for many real-world applications, such as collision avoidance and path planning in autonomous driving.","This work presents an innovative real-time streaming perception method, Transtreaming, which addresses the challenge of real-time object detection with dynamic computational delay.","The core innovation of Transtreaming lies in its adaptive delay-aware transformer, which can concurrently predict multiple future frames and select the output that best matches the real-world present time, compensating for any system-induced computation delays.","The proposed model outperforms the existing state-of-the-art methods, even in single-frame detection scenarios, by leveraging a transformer-based methodology.","It demonstrates robust performance across a range of devices, from powerful V100 to modest 2080Ti, achieving the highest level of perceptual accuracy on all platforms.","Unlike most state-of-the-art methods that struggle to complete computation within a single frame on less powerful devices, Transtreaming meets the stringent real-time processing requirements on all kinds of devices.","The experimental results emphasize the system's adaptability and its potential to significantly improve the safety and reliability for many real-world systems, such as autonomous driving."],"url":"http://arxiv.org/abs/2409.06584v1"}
{"created":"2024-09-10 15:22:05","title":"Semi-Supervised 3D Object Detection with Chanel Augmentation using Transformation Equivariance","abstract":"Accurate 3D object detection is crucial for autonomous vehicles and robots to navigate and interact with the environment safely and effectively. Meanwhile, the performance of 3D detector relies on the data size and annotation which is expensive. Consequently, the demand of training with limited labeled data is growing. We explore a novel teacher-student framework employing channel augmentation for 3D semi-supervised object detection. The teacher-student SSL typically adopts a weak augmentation and strong augmentation to teacher and student, respectively. In this work, we apply multiple channel augmentations to both networks using the transformation equivariance detector (TED). The TED allows us to explore different combinations of augmentation on point clouds and efficiently aggregates multi-channel transformation equivariance features. In principle, by adopting fixed channel augmentations for the teacher network, the student can train stably on reliable pseudo-labels. Adopting strong channel augmentations can enrich the diversity of data, fostering robustness to transformations and enhancing generalization performance of the student network. We use SOTA hierarchical supervision as a baseline and adapt its dual-threshold to TED, which is called channel IoU consistency. We evaluate our method with KITTI dataset, and achieved a significant performance leap, surpassing SOTA 3D semi-supervised object detection models.","sentences":["Accurate 3D object detection is crucial for autonomous vehicles and robots to navigate and interact with the environment safely and effectively.","Meanwhile, the performance of 3D detector relies on the data size and annotation which is expensive.","Consequently, the demand of training with limited labeled data is growing.","We explore a novel teacher-student framework employing channel augmentation for 3D semi-supervised object detection.","The teacher-student SSL typically adopts a weak augmentation and strong augmentation to teacher and student, respectively.","In this work, we apply multiple channel augmentations to both networks using the transformation equivariance detector (TED).","The TED allows us to explore different combinations of augmentation on point clouds and efficiently aggregates multi-channel transformation equivariance features.","In principle, by adopting fixed channel augmentations for the teacher network, the student can train stably on reliable pseudo-labels.","Adopting strong channel augmentations can enrich the diversity of data, fostering robustness to transformations and enhancing generalization performance of the student network.","We use SOTA hierarchical supervision as a baseline and adapt its dual-threshold to TED, which is called channel IoU consistency.","We evaluate our method with KITTI dataset, and achieved a significant performance leap, surpassing SOTA 3D semi-supervised object detection models."],"url":"http://arxiv.org/abs/2409.06583v1"}
{"created":"2024-09-10 15:19:40","title":"Quantifying and Enabling the Interpretability of CLIP-like Models","abstract":"CLIP is one of the most popular foundational models and is heavily used for many vision-language tasks. However, little is known about the inner workings of CLIP. To bridge this gap we propose a study to quantify the interpretability in CLIP like models. We conduct this study on six different CLIP models from OpenAI and OpenCLIP which vary by size, type of pre-training data and patch size. Our approach begins with using the TEXTSPAN algorithm and in-context learning to break down individual attention heads into specific properties. We then evaluate how easily these heads can be interpreted using new metrics which measure property consistency within heads and property disentanglement across heads. Our findings reveal that larger CLIP models are generally more interpretable than their smaller counterparts. To further assist users in understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a tool designed for interpretability analysis. CLIP-InterpreT offers five types of analyses: property-based nearest neighbor search, per-head topic segmentation, contrastive segmentation, per-head nearest neighbors of an image, and per-head nearest neighbors of text.","sentences":["CLIP is one of the most popular foundational models and is heavily used for many vision-language tasks.","However, little is known about the inner workings of CLIP.","To bridge this gap we propose a study to quantify the interpretability in CLIP like models.","We conduct this study on six different CLIP models from OpenAI and OpenCLIP which vary by size, type of pre-training data and patch size.","Our approach begins with using the TEXTSPAN algorithm and in-context learning to break down individual attention heads into specific properties.","We then evaluate how easily these heads can be interpreted using new metrics which measure property consistency within heads and property disentanglement across heads.","Our findings reveal that larger CLIP models are generally more interpretable than their smaller counterparts.","To further assist users in understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a tool designed for interpretability analysis.","CLIP-InterpreT offers five types of analyses: property-based nearest neighbor search, per-head topic segmentation, contrastive segmentation, per-head nearest neighbors of an image, and per-head nearest neighbors of text."],"url":"http://arxiv.org/abs/2409.06579v1"}
{"created":"2024-09-10 15:02:34","title":"Think-on-Process: Dynamic Process Generation for Collaborative Development of Multi-Agent System","abstract":"Software development is a collaborative endeavor that requires individuals from different departments to work together in order to collectively develop a high-quality software system. In this context, people have begun to explore a method that leverages multi-agent systems based on LLMs to carry out software development. However, existing research tends to rigidly fix the software development process in a framework in code form, thus failing to dynamically adjust the software development process in real-time to meet the more flexible and variable software environment. In this paper, we propose a dynamic process generation framework, named ToP (Think-on-Process). The core idea of ToP is to leverage experiential knowledge (i.e., process models) to guide LLMs in generating software development processes (i.e., instances). These instances will guide multi-agent in software development and employ a compiler to provide feedback on the development outcomes. Subsequently, we utilize heuristic algorithms to filter the instances and apply process mining algorithms to derive process model. Finally, the process model will be converted into text, formatted as prompts, to enhance the ability of LLMs to generate other instances. Experiments demonstrate that our framework ToP significantly enhances the dynamic process generation capability of the GPT-3.5 and GPT-4 for five categories of software development tasks.","sentences":["Software development is a collaborative endeavor that requires individuals from different departments to work together in order to collectively develop a high-quality software system.","In this context, people have begun to explore a method that leverages multi-agent systems based on LLMs to carry out software development.","However, existing research tends to rigidly fix the software development process in a framework in code form, thus failing to dynamically adjust the software development process in real-time to meet the more flexible and variable software environment.","In this paper, we propose a dynamic process generation framework, named ToP (Think-on-Process).","The core idea of ToP is to leverage experiential knowledge (i.e., process models) to guide LLMs in generating software development processes (i.e., instances).","These instances will guide multi-agent in software development and employ a compiler to provide feedback on the development outcomes.","Subsequently, we utilize heuristic algorithms to filter the instances and apply process mining algorithms to derive process model.","Finally, the process model will be converted into text, formatted as prompts, to enhance the ability of LLMs to generate other instances.","Experiments demonstrate that our framework ToP significantly enhances the dynamic process generation capability of the GPT-3.5 and GPT-4 for five categories of software development tasks."],"url":"http://arxiv.org/abs/2409.06568v1"}
{"created":"2024-09-10 14:58:55","title":"Exploring syntactic information in sentence embeddings through multilingual subject-verb agreement","abstract":"In this paper, our goal is to investigate to what degree multilingual pretrained language models capture cross-linguistically valid abstract linguistic representations. We take the approach of developing curated synthetic data on a large scale, with specific properties, and using them to study sentence representations built using pretrained language models. We use a new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to focus on a specific grammatical structural phenomenon -- subject-verb agreement across a variety of sentence structures -- in several languages. Finding a solution to this task requires a system detecting complex linguistic patterns and paradigms in text representations. Using a two-level architecture that solves the problem in two steps -- detect syntactic objects and their properties in individual sentences, and find patterns across an input sequence of sentences -- we show that despite having been trained on multilingual texts in a consistent manner, multilingual pretrained language models have language-specific differences, and syntactic structure is not shared, even across closely related languages.","sentences":["In this paper, our goal is to investigate to what degree multilingual pretrained language models capture cross-linguistically valid abstract linguistic representations.","We take the approach of developing curated synthetic data on a large scale, with specific properties, and using them to study sentence representations built using pretrained language models.","We use a new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to focus on a specific grammatical structural phenomenon -- subject-verb agreement across a variety of sentence structures -- in several languages.","Finding a solution to this task requires a system detecting complex linguistic patterns and paradigms in text representations.","Using a two-level architecture that solves the problem in two steps -- detect syntactic objects and their properties in individual sentences, and find patterns across an input sequence of sentences -- we show that despite having been trained on multilingual texts in a consistent manner, multilingual pretrained language models have language-specific differences, and syntactic structure is not shared, even across closely related languages."],"url":"http://arxiv.org/abs/2409.06567v1"}
{"created":"2024-09-10 14:58:00","title":"Indirect Dynamic Negotiation in the Nash Demand Game","abstract":"The paper addresses a problem of sequential bilateral bargaining with incomplete information. We proposed a decision model that helps agents to successfully bargain by performing indirect negotiation and learning the opponent's model. Methodologically the paper casts heuristically-motivated bargaining of a self-interested independent player into a framework of Bayesian learning and Markov decision processes. The special form of the reward implicitly motivates the players to negotiate indirectly, via closed-loop interaction. We illustrate the approach by applying our model to the Nash demand game, which is an abstract model of bargaining. The results indicate that the established negotiation: i) leads to coordinating players' actions; ii) results in maximising success rate of the game and iii) brings more individual profit to the players.","sentences":["The paper addresses a problem of sequential bilateral bargaining with incomplete information.","We proposed a decision model that helps agents to successfully bargain by performing indirect negotiation and learning the opponent's model.","Methodologically the paper casts heuristically-motivated bargaining of a self-interested independent player into a framework of Bayesian learning and Markov decision processes.","The special form of the reward implicitly motivates the players to negotiate indirectly, via closed-loop interaction.","We illustrate the approach by applying our model to the Nash demand game, which is an abstract model of bargaining.","The results indicate that the established negotiation: i) leads to coordinating players' actions; ii) results in maximising success rate of the game and iii) brings more individual profit to the players."],"url":"http://arxiv.org/abs/2409.06566v1"}
{"created":"2024-09-10 14:56:51","title":"Advancing Android Privacy Assessments with Automation","abstract":"Android apps collecting data from users must comply with legal frameworks to ensure data protection. This requirement has become even more important since the implementation of the General Data Protection Regulation (GDPR) by the European Union in 2018. Moreover, with the proposed Cyber Resilience Act on the horizon, stakeholders will soon need to assess software against even more stringent security and privacy standards. Effective privacy assessments require collaboration among groups with diverse expertise to function effectively as a cohesive unit.   This paper motivates the need for an automated approach that enhances understanding of data protection in Android apps and improves communication between the various parties involved in privacy assessments. We propose the Assessor View, a tool designed to bridge the knowledge gap between these parties, facilitating more effective privacy assessments of Android applications.","sentences":["Android apps collecting data from users must comply with legal frameworks to ensure data protection.","This requirement has become even more important since the implementation of the General Data Protection Regulation (GDPR) by the European Union in 2018.","Moreover, with the proposed Cyber Resilience Act on the horizon, stakeholders will soon need to assess software against even more stringent security and privacy standards.","Effective privacy assessments require collaboration among groups with diverse expertise to function effectively as a cohesive unit.   ","This paper motivates the need for an automated approach that enhances understanding of data protection in Android apps and improves communication between the various parties involved in privacy assessments.","We propose the Assessor View, a tool designed to bridge the knowledge gap between these parties, facilitating more effective privacy assessments of Android applications."],"url":"http://arxiv.org/abs/2409.06564v1"}
{"created":"2024-09-10 14:50:12","title":"ChatGPT's Potential in Cryptography Misuse Detection: A Comparative Analysis with Static Analysis Tools","abstract":"The correct adoption of cryptography APIs is challenging for mainstream developers, often resulting in widespread API misuse. Meanwhile, cryptography misuse detectors have demonstrated inconsistent performance and remain largely inaccessible to most developers. We investigated the extent to which ChatGPT can detect cryptography misuses and compared its performance with that of the state-of-the-art static analysis tools. Our investigation, mainly based on the CryptoAPI-Bench benchmark, demonstrated that ChatGPT is effective in identifying cryptography API misuses, and with the use of prompt engineering, it can even outperform leading static cryptography misuse detectors.","sentences":["The correct adoption of cryptography APIs is challenging for mainstream developers, often resulting in widespread API misuse.","Meanwhile, cryptography misuse detectors have demonstrated inconsistent performance and remain largely inaccessible to most developers.","We investigated the extent to which ChatGPT can detect cryptography misuses and compared its performance with that of the state-of-the-art static analysis tools.","Our investigation, mainly based on the CryptoAPI-Bench benchmark, demonstrated that ChatGPT is effective in identifying cryptography API misuses, and with the use of prompt engineering, it can even outperform leading static cryptography misuse detectors."],"url":"http://arxiv.org/abs/2409.06561v1"}
{"created":"2024-09-10 14:41:46","title":"Learn2Aggregate: Supervised Generation of Chv\u00e1tal-Gomory Cuts Using Graph Neural Networks","abstract":"We present $\\textit{Learn2Aggregate}$, a machine learning (ML) framework for optimizing the generation of Chv\\'atal-Gomory (CG) cuts in mixed integer linear programming (MILP). The framework trains a graph neural network to classify useful constraints for aggregation in CG cut generation. The ML-driven CG separator selectively focuses on a small set of impactful constraints, improving runtimes without compromising the strength of the generated cuts. Key to our approach is the formulation of a constraint classification task which favours sparse aggregation of constraints, consistent with empirical findings. This, in conjunction with a careful constraint labeling scheme and a hybrid of deep learning and feature engineering, results in enhanced CG cut generation across five diverse MILP benchmarks. On the largest test sets, our method closes roughly $\\textit{twice}$ as much of the integrality gap as the standard CG method while running 40$% faster. This performance improvement is due to our method eliminating 75% of the constraints prior to aggregation.","sentences":["We present $\\textit{Learn2Aggregate}$, a machine learning (ML) framework for optimizing the generation of Chv\\'atal-Gomory (CG) cuts in mixed integer linear programming (MILP).","The framework trains a graph neural network to classify useful constraints for aggregation in CG cut generation.","The ML-driven CG separator selectively focuses on a small set of impactful constraints, improving runtimes without compromising the strength of the generated cuts.","Key to our approach is the formulation of a constraint classification task which favours sparse aggregation of constraints, consistent with empirical findings.","This, in conjunction with a careful constraint labeling scheme and a hybrid of deep learning and feature engineering, results in enhanced CG cut generation across five diverse MILP benchmarks.","On the largest test sets, our method closes roughly $\\textit{twice}$ as much of the integrality gap as the standard CG method while running 40$% faster.","This performance improvement is due to our method eliminating 75% of the constraints prior to aggregation."],"url":"http://arxiv.org/abs/2409.06559v1"}
{"created":"2024-09-10 14:39:04","title":"MAPS: Energy-Reliability Tradeoff Management in Autonomous Vehicles Through LLMs Penetrated Science","abstract":"As autonomous vehicles become more prevalent, highly accurate and efficient systems are increasingly critical to improve safety, performance, and energy consumption. Efficient management of energy-reliability tradeoffs in these systems demands the ability to predict various conditions during vehicle operations. With the promising improvement of Large Language Models (LLMs) and the emergence of well-known models like ChatGPT, unique opportunities for autonomous vehicle-related predictions have been provided in recent years. This paper proposed MAPS using LLMs as map reader co-drivers to predict the vital parameters to set during the autonomous vehicle operation to balance the energy-reliability tradeoff. The MAPS method demonstrates a 20% improvement in navigation accuracy compared to the best baseline method. MAPS also shows 11% energy savings in computational units and up to 54% in both mechanical and computational units.","sentences":["As autonomous vehicles become more prevalent, highly accurate and efficient systems are increasingly critical to improve safety, performance, and energy consumption.","Efficient management of energy-reliability tradeoffs in these systems demands the ability to predict various conditions during vehicle operations.","With the promising improvement of Large Language Models (LLMs) and the emergence of well-known models like ChatGPT, unique opportunities for autonomous vehicle-related predictions have been provided in recent years.","This paper proposed MAPS using LLMs as map reader co-drivers to predict the vital parameters to set during the autonomous vehicle operation to balance the energy-reliability tradeoff.","The MAPS method demonstrates a 20% improvement in navigation accuracy compared to the best baseline method.","MAPS also shows 11% energy savings in computational units and up to 54% in both mechanical and computational units."],"url":"http://arxiv.org/abs/2409.06558v1"}
{"created":"2024-09-10 14:38:37","title":"Social Mediation through Robots -- A Scoping Review on Improving Group Interactions through Directed Robot Action using an Extended Group Process Model","abstract":"Group processes refer to the dynamics that occur within a group and are critical for understanding how groups function. With robots being increasingly placed within small groups, improving these processes has emerged as an important application of social robotics. Social Mediation Robots elicit behavioral change within groups by deliberately influencing the processes of groups. While research in this field has demonstrated that robots can effectively affect interpersonal dynamics, there is a notable gap in integrating these insights to develop coherent understanding and theory. We present a scoping review of literature targeting changes in social interactions between multiple humans through intentional action from robotic agents. To guide our review, we adapt the classical Input-Process-Output (I-P-O) models that we call \"Mediation I-P-O model\". We evaluated 1633 publications, which yielded 89 distinct social mediation concepts. We construct 11 mediation approaches robots can use to shape processes in small groups and teams. This work strives to produce generalizable insights and evaluate the extent to which the potential of social mediation through robots has been realized thus far. We hope that the proposed framework encourages a holistic approach to the study of social mediation and provides a foundation to standardize future reporting in the domain.","sentences":["Group processes refer to the dynamics that occur within a group and are critical for understanding how groups function.","With robots being increasingly placed within small groups, improving these processes has emerged as an important application of social robotics.","Social Mediation Robots elicit behavioral change within groups by deliberately influencing the processes of groups.","While research in this field has demonstrated that robots can effectively affect interpersonal dynamics, there is a notable gap in integrating these insights to develop coherent understanding and theory.","We present a scoping review of literature targeting changes in social interactions between multiple humans through intentional action from robotic agents.","To guide our review, we adapt the classical Input-Process-Output (I-P-O) models that we call \"Mediation I-P-O model\".","We evaluated 1633 publications, which yielded 89 distinct social mediation concepts.","We construct 11 mediation approaches robots can use to shape processes in small groups and teams.","This work strives to produce generalizable insights and evaluate the extent to which the potential of social mediation through robots has been realized thus far.","We hope that the proposed framework encourages a holistic approach to the study of social mediation and provides a foundation to standardize future reporting in the domain."],"url":"http://arxiv.org/abs/2409.06557v1"}
{"created":"2024-09-10 14:37:43","title":"Adversary Resilient Learned Bloom Filters","abstract":"Creating an adversary resilient Learned Bloom Filter \\cite{learnedindexstructures} with provable guarantees is an open problem \\cite{reviriego1}. We define a strong adversarial model for the Learned Bloom Filter. We also construct two adversary resilient variants of the Learned Bloom Filter called the Uptown Bodega Filter and the Downtown Bodega Filter. Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by Naor Yogev~\\cite{moni1} and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT). We show that if pseudo-random permutations exist, then a secure Learned Bloom Filter may be constructed with $\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. We further show that, if pseudo-random permutations exist, then a \\textit{high utility} Learned Bloom Filter may be constructed with $2\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. Finally, we construct a hybrid adversarial model for the case where a fraction of the workload is chosen by an adversary. We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model.","sentences":["Creating an adversary resilient Learned Bloom Filter \\cite{learnedindexstructures} with provable guarantees is an open problem \\cite{reviriego1}.","We define a strong adversarial model for the Learned Bloom Filter.","We also construct two adversary resilient variants of the Learned Bloom Filter called the Uptown Bodega Filter and the Downtown Bodega Filter.","Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by Naor Yogev~\\cite{moni1} and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT).","We show that if pseudo-random permutations exist, then a secure Learned Bloom Filter may be constructed with $\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path.","We further show that, if pseudo-random permutations exist, then a \\textit{high utility} Learned Bloom Filter may be constructed with $2\\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path.","Finally, we construct a hybrid adversarial model for the case where a fraction of the workload is chosen by an adversary.","We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model."],"url":"http://arxiv.org/abs/2409.06556v1"}
{"created":"2024-09-10 14:26:12","title":"From LIMA to DeepLIMA: following a new path of interoperability","abstract":"In this article, we describe the architecture of the LIMA (Libre Multilingual Analyzer) framework and its recent evolution with the addition of new text analysis modules based on deep neural networks. We extended the functionality of LIMA in terms of the number of supported languages while preserving existing configurable architecture and the availability of previously developed rule-based and statistical analysis components. Models were trained for more than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora, and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number of supported languages and to generate models that could be integrated into other platforms. This integration of ubiquitous Deep Learning Natural Language Processing models and the use of standard annotated collections using Universal Dependencies can be viewed as a new path of interoperability, through the normalization of models and data, that are complementary to a more standard technical interoperability, implemented in LIMA through services available in Docker containers on Docker Hub.","sentences":["In this article, we describe the architecture of the LIMA (Libre Multilingual Analyzer) framework and its recent evolution with the addition of new text analysis modules based on deep neural networks.","We extended the functionality of LIMA in terms of the number of supported languages while preserving existing configurable architecture and the availability of previously developed rule-based and statistical analysis components.","Models were trained for more than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora, and CoNLL-03 dataset.","Universal Dependencies allowed us to increase the number of supported languages and to generate models that could be integrated into other platforms.","This integration of ubiquitous Deep Learning Natural Language Processing models and the use of standard annotated collections using Universal Dependencies can be viewed as a new path of interoperability, through the normalization of models and data, that are complementary to a more standard technical interoperability, implemented in LIMA through services available in Docker containers on Docker Hub."],"url":"http://arxiv.org/abs/2409.06550v1"}
{"created":"2024-09-10 14:15:56","title":"Dynamic Decoupling of Placid Terminal Attractor-based Gradient Descent Algorithm","abstract":"Gradient descent (GD) and stochastic gradient descent (SGD) have been widely used in a large number of application domains. Therefore, understanding the dynamics of GD and improving its convergence speed is still of great importance. This paper carefully analyzes the dynamics of GD based on the terminal attractor at different stages of its gradient flow. On the basis of the terminal sliding mode theory and the terminal attractor theory, four adaptive learning rates are designed. Their performances are investigated in light of a detailed theoretical investigation, and the running times of the learning procedures are evaluated and compared. The total times of their learning processes are also studied in detail. To evaluate their effectiveness, various simulation results are investigated on a function approximation problem and an image classification problem.","sentences":["Gradient descent (GD) and stochastic gradient descent (SGD) have been widely used in a large number of application domains.","Therefore, understanding the dynamics of GD and improving its convergence speed is still of great importance.","This paper carefully analyzes the dynamics of GD based on the terminal attractor at different stages of its gradient flow.","On the basis of the terminal sliding mode theory and the terminal attractor theory, four adaptive learning rates are designed.","Their performances are investigated in light of a detailed theoretical investigation, and the running times of the learning procedures are evaluated and compared.","The total times of their learning processes are also studied in detail.","To evaluate their effectiveness, various simulation results are investigated on a function approximation problem and an image classification problem."],"url":"http://arxiv.org/abs/2409.06542v1"}
{"created":"2024-09-10 14:15:30","title":"Mapping News Narratives Using LLMs and Narrative-Structured Text Embeddings","abstract":"Given the profound impact of narratives across various societal levels, from personal identities to international politics, it is crucial to understand their distribution and development over time. This is particularly important in online spaces. On the Web, narratives can spread rapidly and intensify societal divides and conflicts. While many qualitative approaches exist, quantifying narratives remains a significant challenge. Computational narrative analysis lacks frameworks that are both comprehensive and generalizable. To address this gap, we introduce a numerical narrative representation grounded in structuralist linguistic theory. Chiefly, Greimas' Actantial Model represents a narrative through a constellation of six functional character roles. These so-called actants are genre-agnostic, making the model highly generalizable. We extract the actants using an open-source LLM and integrate them into a Narrative-Structured Text Embedding that captures both the semantics and narrative structure of a text. We demonstrate the analytical insights of the method on the example of 5000 full-text news articles from Al Jazeera and The Washington Post on the Israel-Palestine conflict. Our method successfully distinguishes articles that cover the same topics but differ in narrative structure.","sentences":["Given the profound impact of narratives across various societal levels, from personal identities to international politics, it is crucial to understand their distribution and development over time.","This is particularly important in online spaces.","On the Web, narratives can spread rapidly and intensify societal divides and conflicts.","While many qualitative approaches exist, quantifying narratives remains a significant challenge.","Computational narrative analysis lacks frameworks that are both comprehensive and generalizable.","To address this gap, we introduce a numerical narrative representation grounded in structuralist linguistic theory.","Chiefly, Greimas' Actantial Model represents a narrative through a constellation of six functional character roles.","These so-called actants are genre-agnostic, making the model highly generalizable.","We extract the actants using an open-source LLM and integrate them into a Narrative-Structured Text Embedding that captures both the semantics and narrative structure of a text.","We demonstrate the analytical insights of the method on the example of 5000 full-text news articles from Al Jazeera and The Washington Post on the Israel-Palestine conflict.","Our method successfully distinguishes articles that cover the same topics but differ in narrative structure."],"url":"http://arxiv.org/abs/2409.06540v1"}
{"created":"2024-09-10 14:11:32","title":"A sequential solution to the density classification task using an intermediate alphabet","abstract":"We present a sequential cellular automaton of radius 2 1 as a solution to the density classification task that makes use of an intermediate alphabet, and converges to a clean fixed point with no remaining auxiliary or intermediate information. We extend this solution to arbitrary finite alphabets and to configurations in higher dimensions.","sentences":["We present a sequential cellular automaton of radius 2 1 as a solution to the density classification task that makes use of an intermediate alphabet, and converges to a clean fixed point with no remaining auxiliary or intermediate information.","We extend this solution to arbitrary finite alphabets and to configurations in higher dimensions."],"url":"http://arxiv.org/abs/2409.06536v1"}
{"created":"2024-09-10 14:09:39","title":"PoseEmbroider: Towards a 3D, Visual, Semantic-aware Human Pose Representation","abstract":"Aligning multiple modalities in a latent space, such as images and texts, has shown to produce powerful semantic visual representations, fueling tasks like image captioning, text-to-image generation, or image grounding. In the context of human-centric vision, albeit CLIP-like representations encode most standard human poses relatively well (such as standing or sitting), they lack sufficient acuteness to discern detailed or uncommon ones. Actually, while 3D human poses have been often associated with images (e.g. to perform pose estimation or pose-conditioned image generation), or more recently with text (e.g. for text-to-pose generation), they have seldom been paired with both. In this work, we combine 3D poses, person's pictures and textual pose descriptions to produce an enhanced 3D-, visual- and semantic-aware human pose representation. We introduce a new transformer-based model, trained in a retrieval fashion, which can take as input any combination of the aforementioned modalities. When composing modalities, it outperforms a standard multi-modal alignment retrieval model, making it possible to sort out partial information (e.g. image with the lower body occluded). We showcase the potential of such an embroidered pose representation for (1) SMPL regression from image with optional text cue; and (2) on the task of fine-grained instruction generation, which consists in generating a text that describes how to move from one 3D pose to another (as a fitness coach). Unlike prior works, our model can take any kind of input (image and/or pose) without retraining.","sentences":["Aligning multiple modalities in a latent space, such as images and texts, has shown to produce powerful semantic visual representations, fueling tasks like image captioning, text-to-image generation, or image grounding.","In the context of human-centric vision, albeit CLIP-like representations encode most standard human poses relatively well (such as standing or sitting), they lack sufficient acuteness to discern detailed or uncommon ones.","Actually, while 3D human poses have been often associated with images (e.g. to perform pose estimation or pose-conditioned image generation), or more recently with text (e.g. for text-to-pose generation), they have seldom been paired with both.","In this work, we combine 3D poses, person's pictures and textual pose descriptions to produce an enhanced 3D-, visual- and semantic-aware human pose representation.","We introduce a new transformer-based model, trained in a retrieval fashion, which can take as input any combination of the aforementioned modalities.","When composing modalities, it outperforms a standard multi-modal alignment retrieval model, making it possible to sort out partial information (e.g. image with the lower body occluded).","We showcase the potential of such an embroidered pose representation for (1) SMPL regression from image with optional text cue; and (2) on the task of fine-grained instruction generation, which consists in generating a text that describes how to move from one 3D pose to another (as a fitness coach).","Unlike prior works, our model can take any kind of input (image and/or pose) without retraining."],"url":"http://arxiv.org/abs/2409.06535v1"}
{"created":"2024-09-10 14:08:24","title":"Multi-robot Task Allocation and Path Planning with Maximum Range Constraints","abstract":"This letter presents a novel multi-robot task allocation and path planning method that considers robots' maximum range constraints in large-sized workspaces, enabling robots to complete the assigned tasks within their range limits. Firstly, we developed a fast path planner to solve global paths efficiently. Subsequently, we propose an innovative auction-based approach that integrates our path planner into the auction phase for reward computation while considering the robots' range limits. This method accounts for extra obstacle-avoiding travel distances rather than ideal straight-line distances, resolving the coupling between task allocation and path planning. Additionally, to avoid redundant computations during iterations, we implemented a lazy auction strategy to speed up the convergence of the task allocation. Finally, we validated the proposed method's effectiveness and application potential through extensive simulation and real-world experiments. The implementation code for our method will be available at https://github.com/wuuya1/RangeTAP.","sentences":["This letter presents a novel multi-robot task allocation and path planning method that considers robots' maximum range constraints in large-sized workspaces, enabling robots to complete the assigned tasks within their range limits.","Firstly, we developed a fast path planner to solve global paths efficiently.","Subsequently, we propose an innovative auction-based approach that integrates our path planner into the auction phase for reward computation while considering the robots' range limits.","This method accounts for extra obstacle-avoiding travel distances rather than ideal straight-line distances, resolving the coupling between task allocation and path planning.","Additionally, to avoid redundant computations during iterations, we implemented a lazy auction strategy to speed up the convergence of the task allocation.","Finally, we validated the proposed method's effectiveness and application potential through extensive simulation and real-world experiments.","The implementation code for our method will be available at https://github.com/wuuya1/RangeTAP."],"url":"http://arxiv.org/abs/2409.06531v1"}
{"created":"2024-09-10 14:03:05","title":"Unsupervised stratification of patients with myocardial infarction based on imaging and in-silico biomarkers","abstract":"This study presents a novel methodology for stratifying post-myocardial infarction patients at risk of ventricular arrhythmias using patient-specific 3D cardiac models derived from late gadolinium enhancement cardiovascular magnetic resonance (LGE-CMR) images. The method integrates imaging and computational simulation with a simplified cellular automaton model, Arrhythmic3D, enabling rapid and accurate VA risk assessment in clinical timeframes. Applied to 51 patients, the model generated thousands of personalized simulations to evaluate arrhythmia inducibility and predict VA risk. Key findings include the identification of slow conduction channels (SCCs) within scar tissue as critical to reentrant arrhythmias and the localization of high-risk zones for potential intervention. The Arrhythmic Risk Score (ARRISK), developed from simulation results, demonstrated strong concordance with clinical outcomes and outperformed traditional imaging-based risk stratification. The methodology is fully automated, requiring minimal user intervention, and offers a promising tool for improving precision medicine in cardiac care by enhancing patient-specific arrhythmia risk assessment and guiding treatment strategies.","sentences":["This study presents a novel methodology for stratifying post-myocardial infarction patients at risk of ventricular arrhythmias using patient-specific 3D cardiac models derived from late gadolinium enhancement cardiovascular magnetic resonance (LGE-CMR) images.","The method integrates imaging and computational simulation with a simplified cellular automaton model, Arrhythmic3D, enabling rapid and accurate VA risk assessment in clinical timeframes.","Applied to 51 patients, the model generated thousands of personalized simulations to evaluate arrhythmia inducibility and predict VA risk.","Key findings include the identification of slow conduction channels (SCCs) within scar tissue as critical to reentrant arrhythmias and the localization of high-risk zones for potential intervention.","The Arrhythmic Risk Score (ARRISK), developed from simulation results, demonstrated strong concordance with clinical outcomes and outperformed traditional imaging-based risk stratification.","The methodology is fully automated, requiring minimal user intervention, and offers a promising tool for improving precision medicine in cardiac care by enhancing patient-specific arrhythmia risk assessment and guiding treatment strategies."],"url":"http://arxiv.org/abs/2409.06526v1"}
{"created":"2024-09-10 14:02:34","title":"MENSA: A Multi-Event Network for Survival Analysis under Informative Censoring","abstract":"Given an instance, a multi-event survival model predicts the time until that instance experiences each of several different events. These events are not mutually exclusive and there are often statistical dependencies between them. There are relatively few multi-event survival results, most focusing on producing a simple risk score, rather than the time-to-event itself. To overcome these issues, we introduce MENSA, a novel, deep learning approach for multi-event survival analysis that can jointly learn representations of the input covariates and the dependence structure between events. As a practical motivation for multi-event survival analysis, we consider the problem of predicting the time until a patient with amyotrophic lateral sclerosis (ALS) loses various physical functions, i.e., the ability to speak, swallow, write, or walk. When estimating when a patient is no longer able to swallow, our approach achieves an L1-Margin loss of 278.8 days, compared to 355.2 days when modeling each event separately. In addition, we also evaluate our approach in single-event and competing risk scenarios by modeling the censoring and event distributions as equal contributing factors in the optimization process, and show that our approach performs well across multiple benchmark datasets. The source code is available at: https://github.com/thecml/mensa","sentences":["Given an instance, a multi-event survival model predicts the time until that instance experiences each of several different events.","These events are not mutually exclusive and there are often statistical dependencies between them.","There are relatively few multi-event survival results, most focusing on producing a simple risk score, rather than the time-to-event itself.","To overcome these issues, we introduce MENSA, a novel, deep learning approach for multi-event survival analysis that can jointly learn representations of the input covariates and the dependence structure between events.","As a practical motivation for multi-event survival analysis, we consider the problem of predicting the time until a patient with amyotrophic lateral sclerosis (ALS) loses various physical functions, i.e., the ability to speak, swallow, write, or walk.","When estimating when a patient is no longer able to swallow, our approach achieves an L1-Margin loss of 278.8 days, compared to 355.2 days when modeling each event separately.","In addition, we also evaluate our approach in single-event and competing risk scenarios by modeling the censoring and event distributions as equal contributing factors in the optimization process, and show that our approach performs well across multiple benchmark datasets.","The source code is available at: https://github.com/thecml/mensa"],"url":"http://arxiv.org/abs/2409.06525v1"}
{"created":"2024-09-10 13:56:54","title":"Deep Learning for Koopman Operator Estimation in Idealized Atmospheric Dynamics","abstract":"Deep learning is revolutionizing weather forecasting, with new data-driven models achieving accuracy on par with operational physical models for medium-term predictions. However, these models often lack interpretability, making their underlying dynamics difficult to understand and explain. This paper proposes methodologies to estimate the Koopman operator, providing a linear representation of complex nonlinear dynamics to enhance the transparency of data-driven models. Despite its potential, applying the Koopman operator to large-scale problems, such as atmospheric modeling, remains challenging. This study aims to identify the limitations of existing methods, refine these models to overcome various bottlenecks, and introduce novel convolutional neural network architectures that capture simplified dynamics.","sentences":["Deep learning is revolutionizing weather forecasting, with new data-driven models achieving accuracy on par with operational physical models for medium-term predictions.","However, these models often lack interpretability, making their underlying dynamics difficult to understand and explain.","This paper proposes methodologies to estimate the Koopman operator, providing a linear representation of complex nonlinear dynamics to enhance the transparency of data-driven models.","Despite its potential, applying the Koopman operator to large-scale problems, such as atmospheric modeling, remains challenging.","This study aims to identify the limitations of existing methods, refine these models to overcome various bottlenecks, and introduce novel convolutional neural network architectures that capture simplified dynamics."],"url":"http://arxiv.org/abs/2409.06522v1"}
{"created":"2024-09-10 13:56:08","title":"Asymptotically Optimal Lazy Lifelong Sampling-based Algorithm for Efficient Motion Planning in Dynamic Environments","abstract":"The paper introduces an asymptotically optimal lifelong sampling-based path planning algorithm that combines the merits of lifelong planning algorithms and lazy search algorithms for rapid replanning in dynamic environments where edge evaluation is expensive. By evaluating only sub-path candidates for the optimal solution, the algorithm saves considerable evaluation time and thereby reduces the overall planning cost. It employs a novel informed rewiring cascade to efficiently repair the search tree when the underlying search graph changes. Simulation results demonstrate that the algorithm outperforms various state-of-the-art sampling-based planners in addressing both static and dynamic motion planning problems.","sentences":["The paper introduces an asymptotically optimal lifelong sampling-based path planning algorithm that combines the merits of lifelong planning algorithms and lazy search algorithms for rapid replanning in dynamic environments where edge evaluation is expensive.","By evaluating only sub-path candidates for the optimal solution, the algorithm saves considerable evaluation time and thereby reduces the overall planning cost.","It employs a novel informed rewiring cascade to efficiently repair the search tree when the underlying search graph changes.","Simulation results demonstrate that the algorithm outperforms various state-of-the-art sampling-based planners in addressing both static and dynamic motion planning problems."],"url":"http://arxiv.org/abs/2409.06521v1"}
{"created":"2024-09-10 13:55:47","title":"In Flight Boresight Rectification for Lightweight Airborne Pushbroom Imaging Spectrometry","abstract":"Hyperspectral cameras have recently been miniaturized for operation on lightweight airborne platforms such as UAV or small aircraft. Unlike frame cameras (RGB or Multispectral), many hyperspectral sensors use a linear array or 'push-broom' scanning design. This design presents significant challenges for image rectification and the calibration of the intrinsic and extrinsic camera parameters. Typically, methods employed to address such tasks rely on a precise GPS/INS estimate of the airborne platform trajectory and a detailed terrain model. However, inaccuracies in the trajectory or surface model information can introduce systematic errors and complicate geometric modeling which ultimately degrade the quality of the rectification. To overcome these challenges, we propose a method for tie point extraction and camera calibration for 'push-broom' hyperspectral sensors using only the raw spectral imagery and raw, possibly low quality, GPS/INS trajectory. We demonstrate that our approach allows for the automatic calibration of airborne systems with hyperspectral cameras, outperforms other state-of-the-art automatic rectification methods and reaches an accuracy on par with manual calibration methods.","sentences":["Hyperspectral cameras have recently been miniaturized for operation on lightweight airborne platforms such as UAV or small aircraft.","Unlike frame cameras (RGB or Multispectral), many hyperspectral sensors use a linear array or 'push-broom' scanning design.","This design presents significant challenges for image rectification and the calibration of the intrinsic and extrinsic camera parameters.","Typically, methods employed to address such tasks rely on a precise GPS/INS estimate of the airborne platform trajectory and a detailed terrain model.","However, inaccuracies in the trajectory or surface model information can introduce systematic errors and complicate geometric modeling which ultimately degrade the quality of the rectification.","To overcome these challenges, we propose a method for tie point extraction and camera calibration for 'push-broom' hyperspectral sensors using only the raw spectral imagery and raw, possibly low quality, GPS/INS trajectory.","We demonstrate that our approach allows for the automatic calibration of airborne systems with hyperspectral cameras, outperforms other state-of-the-art automatic rectification methods and reaches an accuracy on par with manual calibration methods."],"url":"http://arxiv.org/abs/2409.06520v1"}
{"created":"2024-09-10 13:54:48","title":"New constructions of DNA codes under multiple constraints and parallel searching algorithms","abstract":"DNA codes have garnered significant interest due to their utilization in digital media storage, cryptography, and DNA computing. In this paper, we first extend the results of constructing reversible group codes \\cite{Cengellenmis} and reversible composite group codes \\cite{Korban5} to general even-order finite groups. By using these results, we give parallel searching algorithms to find some new DNA codes with better parameters. Secondly, by mapping codes over $\\mathbb{F}_4$ to DNA codes, we establish a relationship between the $GC$-weight enumerator of DNA codes and the Hamming weight enumerator of their trace codes, which greatly improves the computational efficiency of searching for DNA codes. Based on this relationship, we propose an efficient algorithm for generating DNA codes with $50\\%$ $GC$-content. Furthermore, we find that there is no direct connection between the $GC$-weight enumerator of a DNA code and the $GC$-weight enumerator of its dual code. Finally, we present algorithms for determining whether a DNA code is free from secondary structures or conflict-free, and some new DNA codes with better parameters under multiple constraints are obtained, which are listed in Tables 1 and 4.","sentences":["DNA codes have garnered significant interest due to their utilization in digital media storage, cryptography, and DNA computing.","In this paper, we first extend the results of constructing reversible group codes \\cite{Cengellenmis} and reversible composite group codes \\cite{Korban5} to general even-order finite groups.","By using these results, we give parallel searching algorithms to find some new DNA codes with better parameters.","Secondly, by mapping codes over $\\mathbb{F}_4$ to DNA codes, we establish a relationship between the $GC$-weight enumerator of DNA codes and the Hamming weight enumerator of their trace codes, which greatly improves the computational efficiency of searching for DNA codes.","Based on this relationship, we propose an efficient algorithm for generating DNA codes with $50\\%$ $GC$-content.","Furthermore, we find that there is no direct connection between the $GC$-weight enumerator of a DNA code and the $GC$-weight enumerator of its dual code.","Finally, we present algorithms for determining whether a DNA code is free from secondary structures or conflict-free, and some new DNA codes with better parameters under multiple constraints are obtained, which are listed in Tables 1 and 4."],"url":"http://arxiv.org/abs/2409.06519v1"}
{"created":"2024-09-10 13:54:04","title":"Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games","abstract":"Large language models (LLMs) have become a dominant approach in natural language processing, yet their internal knowledge structures remain largely unexplored. In this paper, we analyze the internal knowledge structures of LLMs using historical medal tallies from the Olympic Games. We task the models with providing the medal counts for each team and identifying which teams achieved specific rankings. Our results reveal that while state-of-the-art LLMs perform remarkably well in reporting medal counts for individual teams, they struggle significantly with questions about specific rankings. This suggests that the internal knowledge structures of LLMs are fundamentally different from those of humans, who can easily infer rankings from known medal counts. To support further research, we publicly release our code, dataset, and model outputs.","sentences":["Large language models (LLMs) have become a dominant approach in natural language processing, yet their internal knowledge structures remain largely unexplored.","In this paper, we analyze the internal knowledge structures of LLMs using historical medal tallies from the Olympic Games.","We task the models with providing the medal counts for each team and identifying which teams achieved specific rankings.","Our results reveal that while state-of-the-art LLMs perform remarkably well in reporting medal counts for individual teams, they struggle significantly with questions about specific rankings.","This suggests that the internal knowledge structures of LLMs are fundamentally different from those of humans, who can easily infer rankings from known medal counts.","To support further research, we publicly release our code, dataset, and model outputs."],"url":"http://arxiv.org/abs/2409.06518v1"}
{"created":"2024-09-10 13:48:18","title":"Sine, Transient, Noise Neural Modeling of Piano Notes","abstract":"This paper introduces a novel method for emulating piano sounds. We propose to exploit the sine, transient, and noise decomposition to design a differentiable spectral modeling synthesizer replicating piano notes. Three sub-modules learn these components from piano recordings and generate the corresponding harmonic, transient, and noise signals. Splitting the emulation into three independently trainable models reduces the modeling tasks' complexity. The quasi-harmonic content is produced using a differentiable sinusoidal model guided by physics-derived formulas, whose parameters are automatically estimated from audio recordings. The noise sub-module uses a learnable time-varying filter, and the transients are generated using a deep convolutional network. From singular notes, we emulate the coupling between different keys in trichords with a convolutional-based network. Results show the model matches the partial distribution of the target while predicting the energy in the higher part of the spectrum presents more challenges. The energy distribution in the spectra of the transient and noise components is accurate overall. While the model is more computationally and memory efficient, perceptual tests reveal limitations in accurately modeling the attack phase of notes. Despite this, it generally achieves perceptual accuracy in emulating single notes and trichords.","sentences":["This paper introduces a novel method for emulating piano sounds.","We propose to exploit the sine, transient, and noise decomposition to design a differentiable spectral modeling synthesizer replicating piano notes.","Three sub-modules learn these components from piano recordings and generate the corresponding harmonic, transient, and noise signals.","Splitting the emulation into three independently trainable models reduces the modeling tasks' complexity.","The quasi-harmonic content is produced using a differentiable sinusoidal model guided by physics-derived formulas, whose parameters are automatically estimated from audio recordings.","The noise sub-module uses a learnable time-varying filter, and the transients are generated using a deep convolutional network.","From singular notes, we emulate the coupling between different keys in trichords with a convolutional-based network.","Results show the model matches the partial distribution of the target while predicting the energy in the higher part of the spectrum presents more challenges.","The energy distribution in the spectra of the transient and noise components is accurate overall.","While the model is more computationally and memory efficient, perceptual tests reveal limitations in accurately modeling the attack phase of notes.","Despite this, it generally achieves perceptual accuracy in emulating single notes and trichords."],"url":"http://arxiv.org/abs/2409.06513v1"}
{"created":"2024-09-10 13:41:08","title":"Aligning Machine and Human Visual Representations across Abstraction Levels","abstract":"Deep neural networks have achieved success across a wide range of applications, including as models of human behavior in vision tasks. However, neural network training and human learning differ in fundamental ways, and neural networks often fail to generalize as robustly as humans do, raising questions regarding the similarity of their underlying representations. What is missing for modern learning systems to exhibit more human-like behavior? We highlight a key misalignment between vision models and humans: whereas human conceptual knowledge is hierarchically organized from fine- to coarse-scale distinctions, model representations do not accurately capture all these levels of abstraction. To address this misalignment, we first train a teacher model to imitate human judgments, then transfer human-like structure from its representations into pretrained state-of-the-art vision foundation models. These human-aligned models more accurately approximate human behavior and uncertainty across a wide range of similarity tasks, including a new dataset of human judgments spanning multiple levels of semantic abstractions. They also perform better on a diverse set of machine learning tasks, increasing generalization and out-of-distribution robustness. Thus, infusing neural networks with additional human knowledge yields a best-of-both-worlds representation that is both more consistent with human cognition and more practically useful, thus paving the way toward more robust, interpretable, and human-like artificial intelligence systems.","sentences":["Deep neural networks have achieved success across a wide range of applications, including as models of human behavior in vision tasks.","However, neural network training and human learning differ in fundamental ways, and neural networks often fail to generalize as robustly as humans do, raising questions regarding the similarity of their underlying representations.","What is missing for modern learning systems to exhibit more human-like behavior?","We highlight a key misalignment between vision models and humans: whereas human conceptual knowledge is hierarchically organized from fine- to coarse-scale distinctions, model representations do not accurately capture all these levels of abstraction.","To address this misalignment, we first train a teacher model to imitate human judgments, then transfer human-like structure from its representations into pretrained state-of-the-art vision foundation models.","These human-aligned models more accurately approximate human behavior and uncertainty across a wide range of similarity tasks, including a new dataset of human judgments spanning multiple levels of semantic abstractions.","They also perform better on a diverse set of machine learning tasks, increasing generalization and out-of-distribution robustness.","Thus, infusing neural networks with additional human knowledge yields a best-of-both-worlds representation that is both more consistent with human cognition and more practically useful, thus paving the way toward more robust, interpretable, and human-like artificial intelligence systems."],"url":"http://arxiv.org/abs/2409.06509v1"}
{"created":"2024-09-10 13:40:37","title":"DroneXNFT: An NFT-Driven Framework for Secure Autonomous UAV Operations and Flight Data Management","abstract":"Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain. In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data. Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders. This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data.","sentences":["Non-Fungible Tokens (NFTs) have emerged as a revolutionary method for managing digital assets, providing transparency and secure ownership records on a blockchain.","In this paper, we present a theoretical framework for leveraging NFTs to manage UAV (Unmanned Aerial Vehicle) flight data.","Our approach focuses on ensuring data integrity, ownership transfer, and secure data sharing among stakeholders.","This framework utilizes cryptographic methods, smart contracts, and access control mechanisms to enable a tamper-proof and privacy-preserving management system for UAV flight data."],"url":"http://arxiv.org/abs/2409.06507v1"}
{"created":"2024-09-10 13:40:34","title":"Neural Laplacian Operator for 3D Point Clouds","abstract":"The discrete Laplacian operator holds a crucial role in 3D geometry processing, yet it is still challenging to define it on point clouds. Previous works mainly focused on constructing a local triangulation around each point to approximate the underlying manifold for defining the Laplacian operator, which may not be robust or accurate. In contrast, we simply use the K-nearest neighbors (KNN) graph constructed from the input point cloud and learn the Laplacian operator on the KNN graph with graph neural networks (GNNs). However, the ground-truth Laplacian operator is defined on a manifold mesh with a different connectivity from the KNN graph and thus cannot be directly used for training. To train the GNN, we propose a novel training scheme by imitating the behavior of the ground-truth Laplacian operator on a set of probe functions so that the learned Laplacian operator behaves similarly to the ground-truth Laplacian operator. We train our network on a subset of ShapeNet and evaluate it across a variety of point clouds. Compared with previous methods, our method reduces the error by an order of magnitude and excels in handling sparse point clouds with thin structures or sharp features. Our method also demonstrates a strong generalization ability to unseen shapes. With our learned Laplacian operator, we further apply a series of Laplacian-based geometry processing algorithms directly to point clouds and achieve accurate results, enabling many exciting possibilities for geometry processing on point clouds. The code and trained models are available at https://github.com/IntelligentGeometry/NeLo.","sentences":["The discrete Laplacian operator holds a crucial role in 3D geometry processing, yet it is still challenging to define it on point clouds.","Previous works mainly focused on constructing a local triangulation around each point to approximate the underlying manifold for defining the Laplacian operator, which may not be robust or accurate.","In contrast, we simply use the K-nearest neighbors (KNN) graph constructed from the input point cloud and learn the Laplacian operator on the KNN graph with graph neural networks (GNNs).","However, the ground-truth Laplacian operator is defined on a manifold mesh with a different connectivity from the KNN graph and thus cannot be directly used for training.","To train the GNN, we propose a novel training scheme by imitating the behavior of the ground-truth Laplacian operator on a set of probe functions so that the learned Laplacian operator behaves similarly to the ground-truth Laplacian operator.","We train our network on a subset of ShapeNet and evaluate it across a variety of point clouds.","Compared with previous methods, our method reduces the error by an order of magnitude and excels in handling sparse point clouds with thin structures or sharp features.","Our method also demonstrates a strong generalization ability to unseen shapes.","With our learned Laplacian operator, we further apply a series of Laplacian-based geometry processing algorithms directly to point clouds and achieve accurate results, enabling many exciting possibilities for geometry processing on point clouds.","The code and trained models are available at https://github.com/IntelligentGeometry/NeLo."],"url":"http://arxiv.org/abs/2409.06506v1"}
{"created":"2024-09-10 13:38:03","title":"Advancements in Gesture Recognition Techniques and Machine Learning for Enhanced Human-Robot Interaction: A Comprehensive Review","abstract":"In recent years robots have become an important part of our day-to-day lives with various applications. Human-robot interaction creates a positive impact in the field of robotics to interact and communicate with the robots. Gesture recognition techniques combined with machine learning algorithms have shown remarkable progress in recent years, particularly in human-robot interaction (HRI). This paper comprehensively reviews the latest advancements in gesture recognition methods and their integration with machine learning approaches to enhance HRI. Furthermore, this paper represents the vision-based gesture recognition for safe and reliable human-robot-interaction with a depth-sensing system, analyses the role of machine learning algorithms such as deep learning, reinforcement learning, and transfer learning in improving the accuracy and robustness of gesture recognition systems for effective communication between humans and robots.","sentences":["In recent years robots have become an important part of our day-to-day lives with various applications.","Human-robot interaction creates a positive impact in the field of robotics to interact and communicate with the robots.","Gesture recognition techniques combined with machine learning algorithms have shown remarkable progress in recent years, particularly in human-robot interaction (HRI).","This paper comprehensively reviews the latest advancements in gesture recognition methods and their integration with machine learning approaches to enhance HRI.","Furthermore, this paper represents the vision-based gesture recognition for safe and reliable human-robot-interaction with a depth-sensing system, analyses the role of machine learning algorithms such as deep learning, reinforcement learning, and transfer learning in improving the accuracy and robustness of gesture recognition systems for effective communication between humans and robots."],"url":"http://arxiv.org/abs/2409.06503v1"}
