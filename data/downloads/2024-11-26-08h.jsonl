{"created":"2024-11-25 18:59:57","title":"Generative Omnimatte: Learning to Decompose Video into Layers","abstract":"Given a video and a set of input object masks, an omnimatte method aims to decompose the video into semantically meaningful layers containing individual objects along with their associated effects, such as shadows and reflections. Existing omnimatte methods assume a static background or accurate pose and depth estimation and produce poor decompositions when these assumptions are violated. Furthermore, due to the lack of generative prior on natural videos, existing methods cannot complete dynamic occluded regions. We present a novel generative layered video decomposition framework to address the omnimatte problem. Our method does not assume a stationary scene or require camera pose or depth information and produces clean, complete layers, including convincing completions of occluded dynamic regions. Our core idea is to train a video diffusion model to identify and remove scene effects caused by a specific object. We show that this model can be finetuned from an existing video inpainting model with a small, carefully curated dataset, and demonstrate high-quality decompositions and editing results for a wide range of casually captured videos containing soft shadows, glossy reflections, splashing water, and more.","sentences":["Given a video and a set of input object masks, an omnimatte method aims to decompose the video into semantically meaningful layers containing individual objects along with their associated effects, such as shadows and reflections.","Existing omnimatte methods assume a static background or accurate pose and depth estimation and produce poor decompositions when these assumptions are violated.","Furthermore, due to the lack of generative prior on natural videos, existing methods cannot complete dynamic occluded regions.","We present a novel generative layered video decomposition framework to address the omnimatte problem.","Our method does not assume a stationary scene or require camera pose or depth information and produces clean, complete layers, including convincing completions of occluded dynamic regions.","Our core idea is to train a video diffusion model to identify and remove scene effects caused by a specific object.","We show that this model can be finetuned from an existing video inpainting model with a small, carefully curated dataset, and demonstrate high-quality decompositions and editing results for a wide range of casually captured videos containing soft shadows, glossy reflections, splashing water, and more."],"url":"http://arxiv.org/abs/2411.16683v1"}
{"created":"2024-11-25 18:59:53","title":"Factorized Visual Tokenization and Generation","abstract":"Visual tokenizers are fundamental to image generation. They convert visual data into discrete tokens, enabling transformer-based models to excel at image generation. Despite their success, VQ-based tokenizers like VQGAN face significant limitations due to constrained vocabulary sizes. Simply expanding the codebook often leads to training instability and diminishing performance gains, making scalability a critical challenge. In this work, we introduce Factorized Quantization (FQ), a novel approach that revitalizes VQ-based tokenizers by decomposing a large codebook into multiple independent sub-codebooks. This factorization reduces the lookup complexity of large codebooks, enabling more efficient and scalable visual tokenization. To ensure each sub-codebook captures distinct and complementary information, we propose a disentanglement regularization that explicitly reduces redundancy, promoting diversity across the sub-codebooks. Furthermore, we integrate representation learning into the training process, leveraging pretrained vision models like CLIP and DINO to infuse semantic richness into the learned representations. This design ensures our tokenizer captures diverse semantic levels, leading to more expressive and disentangled representations. Experiments show that the proposed FQGAN model substantially improves the reconstruction quality of visual tokenizers, achieving state-of-the-art performance. We further demonstrate that this tokenizer can be effectively adapted into auto-regressive image generation. https://showlab.github.io/FQGAN","sentences":["Visual tokenizers are fundamental to image generation.","They convert visual data into discrete tokens, enabling transformer-based models to excel at image generation.","Despite their success, VQ-based tokenizers like VQGAN face significant limitations due to constrained vocabulary sizes.","Simply expanding the codebook often leads to training instability and diminishing performance gains, making scalability a critical challenge.","In this work, we introduce Factorized Quantization (FQ), a novel approach that revitalizes VQ-based tokenizers by decomposing a large codebook into multiple independent sub-codebooks.","This factorization reduces the lookup complexity of large codebooks, enabling more efficient and scalable visual tokenization.","To ensure each sub-codebook captures distinct and complementary information, we propose a disentanglement regularization that explicitly reduces redundancy, promoting diversity across the sub-codebooks.","Furthermore, we integrate representation learning into the training process, leveraging pretrained vision models like CLIP and DINO to infuse semantic richness into the learned representations.","This design ensures our tokenizer captures diverse semantic levels, leading to more expressive and disentangled representations.","Experiments show that the proposed FQGAN model substantially improves the reconstruction quality of visual tokenizers, achieving state-of-the-art performance.","We further demonstrate that this tokenizer can be effectively adapted into auto-regressive image generation.","https://showlab.github.io/FQGAN"],"url":"http://arxiv.org/abs/2411.16681v1"}
{"created":"2024-11-25 18:59:50","title":"Quark: Real-time, High-resolution, and General Neural View Synthesis","abstract":"We present a novel neural algorithm for performing high-quality, high-resolution, real-time novel view synthesis. From a sparse set of input RGB images or videos streams, our network both reconstructs the 3D scene and renders novel views at 1080p resolution at 30fps on an NVIDIA A100. Our feed-forward network generalizes across a wide variety of datasets and scenes and produces state-of-the-art quality for a real-time method. Our quality approaches, and in some cases surpasses, the quality of some of the top offline methods. In order to achieve these results we use a novel combination of several key concepts, and tie them together into a cohesive and effective algorithm. We build on previous works that represent the scene using semi-transparent layers and use an iterative learned render-and-refine approach to improve those layers. Instead of flat layers, our method reconstructs layered depth maps (LDMs) that efficiently represent scenes with complex depth and occlusions. The iterative update steps are embedded in a multi-scale, UNet-style architecture to perform as much compute as possible at reduced resolution. Within each update step, to better aggregate the information from multiple input views, we use a specialized Transformer-based network component. This allows the majority of the per-input image processing to be performed in the input image space, as opposed to layer space, further increasing efficiency. Finally, due to the real-time nature of our reconstruction and rendering, we dynamically create and discard the internal 3D geometry for each frame, generating the LDM for each view. Taken together, this produces a novel and effective algorithm for view synthesis. Through extensive evaluation, we demonstrate that we achieve state-of-the-art quality at real-time rates. Project page: https://quark-3d.github.io/","sentences":["We present a novel neural algorithm for performing high-quality, high-resolution, real-time novel view synthesis.","From a sparse set of input RGB images or videos streams, our network both reconstructs the 3D scene and renders novel views at 1080p resolution at 30fps on an NVIDIA A100.","Our feed-forward network generalizes across a wide variety of datasets and scenes and produces state-of-the-art quality for a real-time method.","Our quality approaches, and in some cases surpasses, the quality of some of the top offline methods.","In order to achieve these results we use a novel combination of several key concepts, and tie them together into a cohesive and effective algorithm.","We build on previous works that represent the scene using semi-transparent layers and use an iterative learned render-and-refine approach to improve those layers.","Instead of flat layers, our method reconstructs layered depth maps (LDMs) that efficiently represent scenes with complex depth and occlusions.","The iterative update steps are embedded in a multi-scale, UNet-style architecture to perform as much compute as possible at reduced resolution.","Within each update step, to better aggregate the information from multiple input views, we use a specialized Transformer-based network component.","This allows the majority of the per-input image processing to be performed in the input image space, as opposed to layer space, further increasing efficiency.","Finally, due to the real-time nature of our reconstruction and rendering, we dynamically create and discard the internal 3D geometry for each frame, generating the LDM for each view.","Taken together, this produces a novel and effective algorithm for view synthesis.","Through extensive evaluation, we demonstrate that we achieve state-of-the-art quality at real-time rates.","Project page: https://quark-3d.github.io/"],"url":"http://arxiv.org/abs/2411.16680v1"}
{"created":"2024-11-25 18:59:30","title":"Do Large Language Models Perform Latent Multi-Hop Reasoning without Exploiting Shortcuts?","abstract":"We evaluate how well Large Language Models (LLMs) latently recall and compose facts to answer multi-hop queries like \"In the year Scarlett Johansson was born, the Summer Olympics were hosted in the country of\". One major challenge in evaluating this ability is that LLMs may have developed shortcuts by encounters of the head entity \"Scarlett Johansson\" and the answer entity \"United States\" in the same training sequences or merely guess the answer based on frequency-based priors. To prevent shortcuts, we exclude test queries where the head and answer entities co-appear in pretraining corpora. Through careful selection of relations and facts and systematic removal of cases where models might guess answers or exploit partial matches, we construct an evaluation dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning). We observe that LLMs demonstrate promising latent multi-hop reasoning abilities without exploiting shortcuts, but only for certain types of queries. For queries requiring latent recall of countries as the intermediate answer, the best models achieve 80% latent composability, but this drops to just 5% for the recall of years. Comparisons with Chain-of-Thought composability highlight a significant gap between the ability of models to reason latently versus explicitly. Analysis reveals that latent representations of the intermediate answer are constructed more often in queries with higher latent composability, and shows the emergence of latent multi-hop reasoning during pretraining.","sentences":["We evaluate how well Large Language Models (LLMs) latently recall and compose facts to answer multi-hop queries like \"In the year Scarlett Johansson was born, the Summer Olympics were hosted in the country of\".","One major challenge in evaluating this ability is that LLMs may have developed shortcuts by encounters of the head entity \"Scarlett Johansson\" and the answer entity \"United States\" in the same training sequences or merely guess the answer based on frequency-based priors.","To prevent shortcuts, we exclude test queries where the head and answer entities co-appear in pretraining corpora.","Through careful selection of relations and facts and systematic removal of cases where models might guess answers or exploit partial matches, we construct an evaluation dataset SOCRATES (ShOrtCut-fRee lATent rEaSoning).","We observe that LLMs demonstrate promising latent multi-hop reasoning abilities without exploiting shortcuts, but only for certain types of queries.","For queries requiring latent recall of countries as the intermediate answer, the best models achieve 80% latent composability, but this drops to just 5% for the recall of years.","Comparisons with Chain-of-Thought composability highlight a significant gap between the ability of models to reason latently versus explicitly.","Analysis reveals that latent representations of the intermediate answer are constructed more often in queries with higher latent composability, and shows the emergence of latent multi-hop reasoning during pretraining."],"url":"http://arxiv.org/abs/2411.16679v1"}
{"created":"2024-11-25 18:53:56","title":"Diffusion Features for Zero-Shot 6DoF Object Pose Estimation","abstract":"Zero-shot object pose estimation enables the retrieval of object poses from images without necessitating object-specific training. In recent approaches this is facilitated by vision foundation models (VFM), which are pre-trained models that are effectively general-purpose feature extractors. The characteristics exhibited by these VFMs vary depending on the training data, network architecture, and training paradigm. The prevailing choice in this field are self-supervised Vision Transformers (ViT). This study assesses the influence of Latent Diffusion Model (LDM) backbones on zero-shot pose estimation. In order to facilitate a comparison between the two families of models on a common ground we adopt and modify a recent approach. Therefore, a template-based multi-staged method for estimating poses in a zero-shot fashion using LDMs is presented. The efficacy of the proposed approach is empirically evaluated on three standard datasets for object-specific 6DoF pose estimation. The experiments demonstrate an Average Recall improvement of up to 27% over the ViT baseline. The source code is available at: https://github.com/BvG1993/DZOP.","sentences":["Zero-shot object pose estimation enables the retrieval of object poses from images without necessitating object-specific training.","In recent approaches this is facilitated by vision foundation models (VFM), which are pre-trained models that are effectively general-purpose feature extractors.","The characteristics exhibited by these VFMs vary depending on the training data, network architecture, and training paradigm.","The prevailing choice in this field are self-supervised Vision Transformers (ViT).","This study assesses the influence of Latent Diffusion Model (LDM) backbones on zero-shot pose estimation.","In order to facilitate a comparison between the two families of models on a common ground we adopt and modify a recent approach.","Therefore, a template-based multi-staged method for estimating poses in a zero-shot fashion using LDMs is presented.","The efficacy of the proposed approach is empirically evaluated on three standard datasets for object-specific 6DoF pose estimation.","The experiments demonstrate an Average Recall improvement of up to 27% over the ViT baseline.","The source code is available at: https://github.com/BvG1993/DZOP."],"url":"http://arxiv.org/abs/2411.16668v1"}
{"created":"2024-11-25 18:53:49","title":"OPMOS: Ordered Parallel Multi-Objective Shortest-Path","abstract":"The Multi-Objective Shortest-Path (MOS) problem finds a set of Pareto-optimal solutions from a start node to a destination node in a multi-attribute graph. To solve the NP-hard MOS problem, the literature explores heuristic multi-objective A*-style algorithmic approaches. A generalized MOS algorithm maintains a \"frontier\" of partial paths at each node and performs ordered processing to ensure that Pareto-optimal paths are generated to reach the goal node. The algorithm becomes computationally intractable as the number of objectives increases due to a rapid increase in the non-dominated paths, and the concomitantly large increase in Pareto-optimal solutions. While prior works have focused on algorithmic methods to reduce the complexity, we tackle this challenge by exploiting parallelism using an algorithm-architecture approach. The key insight is that MOS algorithms rely on the ordered execution of partial paths to maintain high work efficiency. The OPMOS framework, proposed herein, unlocks ordered parallelism and efficiently exploits the concurrent execution of multiple paths in MOS. Experimental evaluation using the NVIDIA GH200 Superchip shows the performance scaling potential of OPMOS on work efficiency and parallelism using a real-world application to ship routing.","sentences":["The Multi-Objective Shortest-Path (MOS) problem finds a set of Pareto-optimal solutions from a start node to a destination node in a multi-attribute graph.","To solve the NP-hard MOS problem, the literature explores heuristic multi-objective A*-style algorithmic approaches.","A generalized MOS algorithm maintains a \"frontier\" of partial paths at each node and performs ordered processing to ensure that Pareto-optimal paths are generated to reach the goal node.","The algorithm becomes computationally intractable as the number of objectives increases due to a rapid increase in the non-dominated paths, and the concomitantly large increase in Pareto-optimal solutions.","While prior works have focused on algorithmic methods to reduce the complexity, we tackle this challenge by exploiting parallelism using an algorithm-architecture approach.","The key insight is that MOS algorithms rely on the ordered execution of partial paths to maintain high work efficiency.","The OPMOS framework, proposed herein, unlocks ordered parallelism and efficiently exploits the concurrent execution of multiple paths in MOS.","Experimental evaluation using the NVIDIA GH200 Superchip shows the performance scaling potential of OPMOS on work efficiency and parallelism using a real-world application to ship routing."],"url":"http://arxiv.org/abs/2411.16667v1"}
{"created":"2024-11-25 18:53:09","title":"Edge Weight Prediction For Category-Agnostic Pose Estimation","abstract":"Category-Agnostic Pose Estimation (CAPE) localizes keypoints across diverse object categories with a single model, using one or a few annotated support images. Recent works have shown that using a pose graph (i.e., treating keypoints as nodes in a graph rather than isolated points) helps handle occlusions and break symmetry. However, these methods assume a static pose graph with equal-weight edges, leading to suboptimal results. We introduce EdgeCape, a novel framework that overcomes these limitations by predicting the graph's edge weights which optimizes localization. To further leverage structural priors, we propose integrating Markovian Structural Bias, which modulates the self-attention interaction between nodes based on the number of hops between them. We show that this improves the model's ability to capture global spatial dependencies. Evaluated on the MP-100 benchmark, which includes 100 categories and over 20K images, EdgeCape achieves state-of-the-art results in the 1-shot setting and leads among similar-sized methods in the 5-shot setting, significantly improving keypoint localization accuracy. Our code is publicly available.","sentences":["Category-Agnostic Pose Estimation (CAPE) localizes keypoints across diverse object categories with a single model, using one or a few annotated support images.","Recent works have shown that using a pose graph (i.e., treating keypoints as nodes in a graph rather than isolated points) helps handle occlusions and break symmetry.","However, these methods assume a static pose graph with equal-weight edges, leading to suboptimal results.","We introduce EdgeCape, a novel framework that overcomes these limitations by predicting the graph's edge weights which optimizes localization.","To further leverage structural priors, we propose integrating Markovian Structural Bias, which modulates the self-attention interaction between nodes based on the number of hops between them.","We show that this improves the model's ability to capture global spatial dependencies.","Evaluated on the MP-100 benchmark, which includes 100 categories and over 20K images, EdgeCape achieves state-of-the-art results in the 1-shot setting and leads among similar-sized methods in the 5-shot setting, significantly improving keypoint localization accuracy.","Our code is publicly available."],"url":"http://arxiv.org/abs/2411.16665v1"}
{"created":"2024-11-25 18:41:56","title":"DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation","abstract":"Storytelling video generation (SVG) has recently emerged as a task to create long, multi-motion, multi-scene videos that consistently represent the story described in the input text script. SVG holds great potential for diverse content creation in media and entertainment; however, it also presents significant challenges: (1) objects must exhibit a range of fine-grained, complex motions, (2) multiple objects need to appear consistently across scenes, and (3) subjects may require multiple motions with seamless transitions within a single scene. To address these challenges, we propose DreamRunner, a novel story-to-video generation method: First, we structure the input script using a large language model (LLM) to facilitate both coarse-grained scene planning as well as fine-grained object-level layout and motion planning. Next, DreamRunner presents retrieval-augmented test-time adaptation to capture target motion priors for objects in each scene, supporting diverse motion customization based on retrieved videos, thus facilitating the generation of new videos with complex, scripted motions. Lastly, we propose a novel spatial-temporal region-based 3D attention and prior injection module SR3AI for fine-grained object-motion binding and frame-by-frame semantic control. We compare DreamRunner with various SVG baselines, demonstrating state-of-the-art performance in character consistency, text alignment, and smooth transitions. Additionally, DreamRunner exhibits strong fine-grained condition-following ability in compositional text-to-video generation, significantly outperforming baselines on T2V-ComBench. Finally, we validate DreamRunner's robust ability to generate multi-object interactions with qualitative examples.","sentences":["Storytelling video generation (SVG) has recently emerged as a task to create long, multi-motion, multi-scene videos that consistently represent the story described in the input text script.","SVG holds great potential for diverse content creation in media and entertainment; however, it also presents significant challenges: (1) objects must exhibit a range of fine-grained, complex motions, (2) multiple objects need to appear consistently across scenes, and (3) subjects may require multiple motions with seamless transitions within a single scene.","To address these challenges, we propose DreamRunner, a novel story-to-video generation method:","First, we structure the input script using a large language model (LLM) to facilitate both coarse-grained scene planning as well as fine-grained object-level layout and motion planning.","Next, DreamRunner presents retrieval-augmented test-time adaptation to capture target motion priors for objects in each scene, supporting diverse motion customization based on retrieved videos, thus facilitating the generation of new videos with complex, scripted motions.","Lastly, we propose a novel spatial-temporal region-based 3D attention and prior injection module SR3AI for fine-grained object-motion binding and frame-by-frame semantic control.","We compare DreamRunner with various SVG baselines, demonstrating state-of-the-art performance in character consistency, text alignment, and smooth transitions.","Additionally, DreamRunner exhibits strong fine-grained condition-following ability in compositional text-to-video generation, significantly outperforming baselines on T2V-ComBench.","Finally, we validate DreamRunner's robust ability to generate multi-object interactions with qualitative examples."],"url":"http://arxiv.org/abs/2411.16657v1"}
{"created":"2024-11-25 18:28:26","title":"Self-Generated Critiques Boost Reward Modeling for Language Models","abstract":"Reward modeling is crucial for aligning large language models (LLMs) with human preferences, especially in reinforcement learning from human feedback (RLHF). However, current reward models mainly produce scalar scores and struggle to incorporate critiques in a natural language format. We hypothesize that predicting both critiques and the scalar reward would improve reward modeling ability. Motivated by this, we propose Critic-RM, a framework that improves reward models using self-generated critiques without extra supervision. Critic-RM employs a two-stage process: generating and filtering high-quality critiques, followed by joint fine-tuning on reward prediction and critique generation. Experiments across benchmarks show that Critic-RM improves reward modeling accuracy by 3.7%-7.3% compared to standard reward models and LLM judges, demonstrating strong performance and data efficiency. Additional studies further validate the effectiveness of generated critiques in rectifying flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.","sentences":["Reward modeling is crucial for aligning large language models (LLMs) with human preferences, especially in reinforcement learning from human feedback (RLHF).","However, current reward models mainly produce scalar scores and struggle to incorporate critiques in a natural language format.","We hypothesize that predicting both critiques and the scalar reward would improve reward modeling ability.","Motivated by this, we propose Critic-RM, a framework that improves reward models using self-generated critiques without extra supervision.","Critic-RM employs a two-stage process: generating and filtering high-quality critiques, followed by joint fine-tuning on reward prediction and critique generation.","Experiments across benchmarks show that Critic-RM improves reward modeling accuracy by 3.7%-7.3% compared to standard reward models and LLM judges, demonstrating strong performance and data efficiency.","Additional studies further validate the effectiveness of generated critiques in rectifying flawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy."],"url":"http://arxiv.org/abs/2411.16646v1"}
{"created":"2024-11-25 18:27:50","title":"Recommender Systems for Good (RS4Good): Survey of Use Cases and a Call to Action for Research that Matters","abstract":"In the area of recommender systems, the vast majority of research efforts is spent on developing increasingly sophisticated recommendation models, also using increasingly more computational resources. Unfortunately, most of these research efforts target a very small set of application domains, mostly e-commerce and media recommendation. Furthermore, many of these models are never evaluated with users, let alone put into practice. The scientific, economic and societal value of much of these efforts by scholars therefore remains largely unclear. To achieve a stronger positive impact resulting from these efforts, we posit that we as a research community should more often address use cases where recommender systems contribute to societal good (RS4Good). In this opinion piece, we first discuss a number of examples where the use of recommender systems for problems of societal concern has been successfully explored in the literature. We then proceed by outlining a paradigmatic shift that is needed to conduct successful RS4Good research, where the key ingredients are interdisciplinary collaborations and longitudinal evaluation approaches with humans in the loop.","sentences":["In the area of recommender systems, the vast majority of research efforts is spent on developing increasingly sophisticated recommendation models, also using increasingly more computational resources.","Unfortunately, most of these research efforts target a very small set of application domains, mostly e-commerce and media recommendation.","Furthermore, many of these models are never evaluated with users, let alone put into practice.","The scientific, economic and societal value of much of these efforts by scholars therefore remains largely unclear.","To achieve a stronger positive impact resulting from these efforts, we posit that we as a research community should more often address use cases where recommender systems contribute to societal good (RS4Good).","In this opinion piece, we first discuss a number of examples where the use of recommender systems for problems of societal concern has been successfully explored in the literature.","We then proceed by outlining a paradigmatic shift that is needed to conduct successful RS4Good research, where the key ingredients are interdisciplinary collaborations and longitudinal evaluation approaches with humans in the loop."],"url":"http://arxiv.org/abs/2411.16645v1"}
{"created":"2024-11-25 18:27:39","title":"Exploring Discrete Flow Matching for 3D De Novo Molecule Generation","abstract":"Deep generative models that produce novel molecular structures have the potential to facilitate chemical discovery. Flow matching is a recently proposed generative modeling framework that has achieved impressive performance on a variety of tasks including those on biomolecular structures. The seminal flow matching framework was developed only for continuous data. However, de novo molecular design tasks require generating discrete data such as atomic elements or sequences of amino acid residues. Several discrete flow matching methods have been proposed recently to address this gap. In this work we benchmark the performance of existing discrete flow matching methods for 3D de novo small molecule generation and provide explanations of their differing behavior. As a result we present FlowMol-CTMC, an open-source model that achieves state of the art performance for 3D de novo design with fewer learnable parameters than existing methods. Additionally, we propose the use of metrics that capture molecule quality beyond local chemical valency constraints and towards higher-order structural motifs. These metrics show that even though basic constraints are satisfied, the models tend to produce unusual and potentially problematic functional groups outside of the training data distribution. Code and trained models for reproducing this work are available at \\url{https://github.com/dunni3/FlowMol}.","sentences":["Deep generative models that produce novel molecular structures have the potential to facilitate chemical discovery.","Flow matching is a recently proposed generative modeling framework that has achieved impressive performance on a variety of tasks including those on biomolecular structures.","The seminal flow matching framework was developed only for continuous data.","However, de novo molecular design tasks require generating discrete data such as atomic elements or sequences of amino acid residues.","Several discrete flow matching methods have been proposed recently to address this gap.","In this work we benchmark the performance of existing discrete flow matching methods for 3D de novo small molecule generation and provide explanations of their differing behavior.","As a result we present FlowMol-CTMC, an open-source model that achieves state of the art performance for 3D de novo design with fewer learnable parameters than existing methods.","Additionally, we propose the use of metrics that capture molecule quality beyond local chemical valency constraints and towards higher-order structural motifs.","These metrics show that even though basic constraints are satisfied, the models tend to produce unusual and potentially problematic functional groups outside of the training data distribution.","Code and trained models for reproducing this work are available at \\url{https://github.com/dunni3/FlowMol}."],"url":"http://arxiv.org/abs/2411.16644v1"}
{"created":"2024-11-25 18:23:58","title":"Preventing Jailbreak Prompts as Malicious Tools for Cybercriminals: A Cyber Defense Perspective","abstract":"Jailbreak prompts pose a significant threat in AI and cybersecurity, as they are crafted to bypass ethical safeguards in large language models, potentially enabling misuse by cybercriminals. This paper analyzes jailbreak prompts from a cyber defense perspective, exploring techniques like prompt injection and context manipulation that allow harmful content generation, content filter evasion, and sensitive information extraction. We assess the impact of successful jailbreaks, from misinformation and automated social engineering to hazardous content creation, including bioweapons and explosives. To address these threats, we propose strategies involving advanced prompt analysis, dynamic safety protocols, and continuous model fine-tuning to strengthen AI resilience. Additionally, we highlight the need for collaboration among AI researchers, cybersecurity experts, and policymakers to set standards for protecting AI systems. Through case studies, we illustrate these cyber defense approaches, promoting responsible AI practices to maintain system integrity and public trust. \\textbf{\\color{red}Warning: This paper contains content which the reader may find offensive.}","sentences":["Jailbreak prompts pose a significant threat in AI and cybersecurity, as they are crafted to bypass ethical safeguards in large language models, potentially enabling misuse by cybercriminals.","This paper analyzes jailbreak prompts from a cyber defense perspective, exploring techniques like prompt injection and context manipulation that allow harmful content generation, content filter evasion, and sensitive information extraction.","We assess the impact of successful jailbreaks, from misinformation and automated social engineering to hazardous content creation, including bioweapons and explosives.","To address these threats, we propose strategies involving advanced prompt analysis, dynamic safety protocols, and continuous model fine-tuning to strengthen AI resilience.","Additionally, we highlight the need for collaboration among AI researchers, cybersecurity experts, and policymakers to set standards for protecting AI systems.","Through case studies, we illustrate these cyber defense approaches, promoting responsible AI practices to maintain system integrity and public trust.","\\textbf{\\color{red}Warning:","This paper contains content which the reader may find offensive.}"],"url":"http://arxiv.org/abs/2411.16642v1"}
{"created":"2024-11-25 18:15:37","title":"K8s Pro Sentinel: Extend Secret Security in Kubernetes Cluster","abstract":"Microservice architecture is widely adopted among distributed systems. It follows the modular approach that decomposes large software applications into independent services. Kubernetes has become the standard tool for managing these microservices. It stores sensitive information like database passwords, API keys, and access tokens as Secret Objects. There are security mechanisms employed to safeguard these confidential data, such as encryption, Role Based Access Control (RBAC), and the least privilege principle. However, manually configuring these measures is time-consuming, requires specialized knowledge, and is prone to human error, thereby increasing the risks of misconfiguration. This research introduces K8s Pro Sentinel, an operator that automates the configuration of encryption and access control for Secret Objects by extending the Kubernetes API server. This automation reduces human error and enhances security within clusters. The performance and reliability of the Sentinel operator were evaluated using Red Hat Operator Scorecard and chaos engineering practices.","sentences":["Microservice architecture is widely adopted among distributed systems.","It follows the modular approach that decomposes large software applications into independent services.","Kubernetes has become the standard tool for managing these microservices.","It stores sensitive information like database passwords, API keys, and access tokens as Secret Objects.","There are security mechanisms employed to safeguard these confidential data, such as encryption, Role Based Access Control (RBAC), and the least privilege principle.","However, manually configuring these measures is time-consuming, requires specialized knowledge, and is prone to human error, thereby increasing the risks of misconfiguration.","This research introduces K8s Pro Sentinel, an operator that automates the configuration of encryption and access control for Secret Objects by extending the Kubernetes API server.","This automation reduces human error and enhances security within clusters.","The performance and reliability of the Sentinel operator were evaluated using Red Hat Operator Scorecard and chaos engineering practices."],"url":"http://arxiv.org/abs/2411.16639v1"}
{"created":"2024-11-25 18:15:15","title":"Do Automatic Factuality Metrics Measure Factuality? A Critical Evaluation","abstract":"Modern LLMs can now produce highly readable abstractive summaries, to the point where traditional automated metrics for evaluating summary quality, such as ROUGE, have become saturated. However, LLMs still sometimes introduce unwanted content into summaries, i.e., information inconsistent with or unsupported by their source. Measuring the occurrence of these often subtle ``hallucinations'' automatically has proved to be challenging. This in turn has motivated development of a variety of metrics intended to measure the factual consistency of generated summaries against their source. But are these approaches measuring what they purport to do? In this work, we stress-test automatic factuality metrics. Specifically, we investigate whether and to what degree superficial attributes of summary texts suffice to predict ``factuality'', finding that a (supervised) model using only such shallow features is reasonably competitive with SOTA factuality scoring methods. We then evaluate how factuality metrics respond to factual corrections in inconsistent summaries and find that only a few show meaningful improvements. In contrast, some metrics are more sensitive to benign, non-factual edits. Motivated by these insights, we show that one can ``game'' (most) automatic factuality metrics, i.e., reliably inflate ``factuality'' scores by appending innocuous sentences to generated summaries.Taken together, our results raise questions about the degree to which we should rely on existing automated factuality metrics and what exactly we want ``factuality metrics'' to measure.","sentences":["Modern LLMs can now produce highly readable abstractive summaries, to the point where traditional automated metrics for evaluating summary quality, such as ROUGE, have become saturated.","However, LLMs still sometimes introduce unwanted content into summaries, i.e., information inconsistent with or unsupported by their source.","Measuring the occurrence of these often subtle ``hallucinations'' automatically has proved to be challenging.","This in turn has motivated development of a variety of metrics intended to measure the factual consistency of generated summaries against their source.","But are these approaches measuring what they purport to do?","In this work, we stress-test automatic factuality metrics.","Specifically, we investigate whether and to what degree superficial attributes of summary texts suffice to predict ``factuality'', finding that a (supervised) model using only such shallow features is reasonably competitive with SOTA factuality scoring methods.","We then evaluate how factuality metrics respond to factual corrections in inconsistent summaries and find that only a few show meaningful improvements.","In contrast, some metrics are more sensitive to benign, non-factual edits.","Motivated by these insights, we show that one can ``game'' (most) automatic factuality metrics, i.e., reliably inflate ``factuality'' scores by appending innocuous sentences to generated summaries.","Taken together, our results raise questions about the degree to which we should rely on existing automated factuality metrics and what exactly we want ``factuality metrics'' to measure."],"url":"http://arxiv.org/abs/2411.16638v1"}
{"created":"2024-11-25 18:03:50","title":"Inference-Time Policy Steering through Human Interactions","abstract":"Generative policies trained with human demonstrations can autonomously accomplish multimodal, long-horizon tasks. However, during inference, humans are often removed from the policy execution loop, limiting the ability to guide a pre-trained policy towards a specific sub-goal or trajectory shape among multiple predictions. Naive human intervention may inadvertently exacerbate distribution shift, leading to constraint violations or execution failures. To better align policy output with human intent without inducing out-of-distribution errors, we propose an Inference-Time Policy Steering (ITPS) framework that leverages human interactions to bias the generative sampling process, rather than fine-tuning the policy on interaction data. We evaluate ITPS across three simulated and real-world benchmarks, testing three forms of human interaction and associated alignment distance metrics. Among six sampling strategies, our proposed stochastic sampling with diffusion policy achieves the best trade-off between alignment and distribution shift. Videos are available at https://yanweiw.github.io/itps/.","sentences":["Generative policies trained with human demonstrations can autonomously accomplish multimodal, long-horizon tasks.","However, during inference, humans are often removed from the policy execution loop, limiting the ability to guide a pre-trained policy towards a specific sub-goal or trajectory shape among multiple predictions.","Naive human intervention may inadvertently exacerbate distribution shift, leading to constraint violations or execution failures.","To better align policy output with human intent without inducing out-of-distribution errors, we propose an Inference-Time Policy Steering (ITPS) framework that leverages human interactions to bias the generative sampling process, rather than fine-tuning the policy on interaction data.","We evaluate ITPS across three simulated and real-world benchmarks, testing three forms of human interaction and associated alignment distance metrics.","Among six sampling strategies, our proposed stochastic sampling with diffusion policy achieves the best trade-off between alignment and distribution shift.","Videos are available at https://yanweiw.github.io/itps/."],"url":"http://arxiv.org/abs/2411.16627v1"}
{"created":"2024-11-25 18:03:20","title":"Leakage-Robust Bayesian Persuasion","abstract":"We introduce the concept of leakage-robust Bayesian persuasion. Situated between public persuasion [KG11, CCG23, Xu20] and private persuasion [AB19], leakage-robust persuasion considers a setting where one or more signals privately sent by a sender to the receivers may be leaked. We study the design of leakage-robust persuasion schemes and quantify the price of robustness using two formalisms:   - The first notion, $k$-worst-case persuasiveness, requires a scheme to remain persuasive as long as each receiver observes at most $k$ leaked signals. We quantify the Price of Worst-case Robustness (PoWR$_k$) -- i.e., the gap in sender's utility as compared to the optimal private scheme -- as $\\Theta(\\min\\{2^k,n\\})$ for supermodular sender utilities and $\\Theta(k)$ for submodular or XOS utilities, where $n$ is the number of receivers. This result also establishes that in some instances, $\\Theta(\\log k)$ leakages are sufficient for the utility of the optimal leakage-robust persuasion to degenerate to that of public persuasion.   - The second notion, expected downstream utility robustness, relaxes the persuasiveness and considers the impact on sender's utility when receivers best respond to their observations. By quantifying the Price of Downstream Robustness (PoDR) as the gap between the sender's expected utility over random leakage patterns as compared to private persuasion, we show that over several natural and structured distributions of leakage patterns, PoDR improves PoWR to $\\Theta(k)$ or even $\\Theta(1)$, where $k$ is the maximum number of leaked signals observable to each receiver across leakage patterns in the distribution.   En route to these results, we show that subsampling and masking are general-purpose algorithmic paradigms for transforming private persuasion signaling schemes to leakage-robust ones, with minmax optimal loss in the sender's utility.","sentences":["We introduce the concept of leakage-robust Bayesian persuasion.","Situated between public persuasion [KG11, CCG23, Xu20] and private persuasion [AB19], leakage-robust persuasion considers a setting where one or more signals privately sent by a sender to the receivers may be leaked.","We study the design of leakage-robust persuasion schemes and quantify the price of robustness using two formalisms:   -","The first notion, $k$-worst-case persuasiveness, requires a scheme to remain persuasive as long as each receiver observes at most $k$ leaked signals.","We quantify the Price of Worst-case Robustness (PoWR$_k$) -- i.e., the gap in sender's utility as compared to the optimal private scheme -- as $\\Theta(\\min\\{2^k,n\\})$ for supermodular sender utilities and $\\Theta(k)$ for submodular or XOS utilities, where $n$ is the number of receivers.","This result also establishes that in some instances, $\\Theta(\\log k)$ leakages are sufficient for the utility of the optimal leakage-robust persuasion to degenerate to that of public persuasion.   -","The second notion, expected downstream utility robustness, relaxes the persuasiveness and considers the impact on sender's utility when receivers best respond to their observations.","By quantifying the Price of Downstream Robustness (PoDR) as the gap between the sender's expected utility over random leakage patterns as compared to private persuasion, we show that over several natural and structured distributions of leakage patterns, PoDR improves PoWR to $\\Theta(k)$ or even $\\Theta(1)$, where $k$ is the maximum number of leaked signals observable to each receiver across leakage patterns in the distribution.   ","En route to these results, we show that subsampling and masking are general-purpose algorithmic paradigms for transforming private persuasion signaling schemes to leakage-robust ones, with minmax optimal loss in the sender's utility."],"url":"http://arxiv.org/abs/2411.16624v1"}
{"created":"2024-11-25 18:02:51","title":"Limeade: Let integer molecular encoding aid","abstract":"Mixed-integer programming (MIP) is a well-established framework for computer-aided molecular design (CAMD). By precisely encoding the molecular space and score functions, e.g., a graph neural network, the molecular design problem is represented and solved as an optimization problem, the solution of which corresponds to a molecule with optimal score. However, both the extremely large search space and complicated scoring process limit the use of MIP-based CAMD to specific and tiny problems. Moreover, optimal molecule may not be meaningful in practice if scores are imperfect. Instead of pursuing optimality, this paper exploits the ability of MIP in molecular generation and proposes Limeade as an end-to-end tool from real-world needs to feasible molecules. Beyond the basic constraints for structural feasibility, Limeade supports inclusion and exclusion of SMARTS patterns, automating the process of interpreting and formulating chemical requirements to mathematical constraints.","sentences":["Mixed-integer programming (MIP) is a well-established framework for computer-aided molecular design (CAMD).","By precisely encoding the molecular space and score functions, e.g., a graph neural network, the molecular design problem is represented and solved as an optimization problem, the solution of which corresponds to a molecule with optimal score.","However, both the extremely large search space and complicated scoring process limit the use of MIP-based CAMD to specific and tiny problems.","Moreover, optimal molecule may not be meaningful in practice if scores are imperfect.","Instead of pursuing optimality, this paper exploits the ability of MIP in molecular generation and proposes Limeade as an end-to-end tool from real-world needs to feasible molecules.","Beyond the basic constraints for structural feasibility, Limeade supports inclusion and exclusion of SMARTS patterns, automating the process of interpreting and formulating chemical requirements to mathematical constraints."],"url":"http://arxiv.org/abs/2411.16623v1"}
{"created":"2024-11-25 18:02:23","title":"Imperceptible Adversarial Examples in the Physical World","abstract":"Adversarial examples in the digital domain against deep learning-based computer vision models allow for perturbations that are imperceptible to human eyes. However, producing similar adversarial examples in the physical world has been difficult due to the non-differentiable image distortion functions in visual sensing systems. The existing algorithms for generating physically realizable adversarial examples often loosen their definition of adversarial examples by allowing unbounded perturbations, resulting in obvious or even strange visual patterns. In this work, we make adversarial examples imperceptible in the physical world using a straight-through estimator (STE, a.k.a. BPDA). We employ STE to overcome the non-differentiability -- applying exact, non-differentiable distortions in the forward pass of the backpropagation step, and using the identity function in the backward pass. Our differentiable rendering extension to STE also enables imperceptible adversarial patches in the physical world. Using printout photos, and experiments in the CARLA simulator, we show that STE enables fast generation of $\\ell_\\infty$ bounded adversarial examples despite the non-differentiable distortions. To the best of our knowledge, this is the first work demonstrating imperceptible adversarial examples bounded by small $\\ell_\\infty$ norms in the physical world that force zero classification accuracy in the global perturbation threat model and cause near-zero ($4.22\\%$) AP50 in object detection in the patch perturbation threat model. We urge the community to re-evaluate the threat of adversarial examples in the physical world.","sentences":["Adversarial examples in the digital domain against deep learning-based computer vision models allow for perturbations that are imperceptible to human eyes.","However, producing similar adversarial examples in the physical world has been difficult due to the non-differentiable image distortion functions in visual sensing systems.","The existing algorithms for generating physically realizable adversarial examples often loosen their definition of adversarial examples by allowing unbounded perturbations, resulting in obvious or even strange visual patterns.","In this work, we make adversarial examples imperceptible in the physical world using a straight-through estimator (STE, a.k.a. BPDA).","We employ STE to overcome the non-differentiability -- applying exact, non-differentiable distortions in the forward pass of the backpropagation step, and using the identity function in the backward pass.","Our differentiable rendering extension to STE also enables imperceptible adversarial patches in the physical world.","Using printout photos, and experiments in the CARLA simulator, we show that STE enables fast generation of $\\ell_\\infty$ bounded adversarial examples despite the non-differentiable distortions.","To the best of our knowledge, this is the first work demonstrating imperceptible adversarial examples bounded by small $\\ell_\\infty$ norms in the physical world that force zero classification accuracy in the global perturbation threat model and cause near-zero ($4.22\\%$) AP50 in object detection in the patch perturbation threat model.","We urge the community to re-evaluate the threat of adversarial examples in the physical world."],"url":"http://arxiv.org/abs/2411.16622v1"}
{"created":"2024-11-25 17:58:43","title":"Human-Activity AGV Quality Assessment: A Benchmark Dataset and an Objective Evaluation Metric","abstract":"AI-driven video generation techniques have made significant progress in recent years. However, AI-generated videos (AGVs) involving human activities often exhibit substantial visual and semantic distortions, hindering the practical application of video generation technologies in real-world scenarios. To address this challenge, we conduct a pioneering study on human activity AGV quality assessment, focusing on visual quality evaluation and the identification of semantic distortions. First, we construct the AI-Generated Human activity Video Quality Assessment (Human-AGVQA) dataset, consisting of 3,200 AGVs derived from 8 popular text-to-video (T2V) models using 400 text prompts that describe diverse human activities. We conduct a subjective study to evaluate the human appearance quality, action continuity quality, and overall video quality of AGVs, and identify semantic issues of human body parts. Based on Human-AGVQA, we benchmark the performance of T2V models and analyze their strengths and weaknesses in generating different categories of human activities. Second, we develop an objective evaluation metric, named AI-Generated Human activity Video Quality metric (GHVQ), to automatically analyze the quality of human activity AGVs. GHVQ systematically extracts human-focused quality features, AI-generated content-aware quality features, and temporal continuity features, making it a comprehensive and explainable quality metric for human activity AGVs. The extensive experimental results show that GHVQ outperforms existing quality metrics on the Human-AGVQA dataset by a large margin, demonstrating its efficacy in assessing the quality of human activity AGVs. The Human-AGVQA dataset and GHVQ metric will be released in public at https://github.com/zczhang-sjtu/GHVQ.git","sentences":["AI-driven video generation techniques have made significant progress in recent years.","However, AI-generated videos (AGVs) involving human activities often exhibit substantial visual and semantic distortions, hindering the practical application of video generation technologies in real-world scenarios.","To address this challenge, we conduct a pioneering study on human activity AGV quality assessment, focusing on visual quality evaluation and the identification of semantic distortions.","First, we construct the AI-Generated Human activity Video Quality Assessment (Human-AGVQA) dataset, consisting of 3,200 AGVs derived from 8 popular text-to-video (T2V) models using 400 text prompts that describe diverse human activities.","We conduct a subjective study to evaluate the human appearance quality, action continuity quality, and overall video quality of AGVs, and identify semantic issues of human body parts.","Based on Human-AGVQA, we benchmark the performance of T2V models and analyze their strengths and weaknesses in generating different categories of human activities.","Second, we develop an objective evaluation metric, named AI-Generated Human activity Video Quality metric (GHVQ), to automatically analyze the quality of human activity AGVs.","GHVQ systematically extracts human-focused quality features, AI-generated content-aware quality features, and temporal continuity features, making it a comprehensive and explainable quality metric for human activity AGVs.","The extensive experimental results show that GHVQ outperforms existing quality metrics on the Human-AGVQA dataset by a large margin, demonstrating its efficacy in assessing the quality of human activity AGVs.","The Human-AGVQA dataset and GHVQ metric will be released in public at https://github.com/zczhang-sjtu/GHVQ.git"],"url":"http://arxiv.org/abs/2411.16619v1"}
{"created":"2024-11-25 17:57:52","title":"StructFormer: Document Structure-based Masked Attention and its Impact on Language Model Pre-Training","abstract":"Most state-of-the-art techniques for Language Models (LMs) today rely on transformer-based architectures and their ubiquitous attention mechanism. However, the exponential growth in computational requirements with longer input sequences confines Transformers to handling short passages. Recent efforts have aimed to address this limitation by introducing selective attention mechanisms, notably local and global attention. While sparse attention mechanisms, akin to full attention in being Turing-complete, have been theoretically established, their practical impact on pre-training remains unexplored. This study focuses on empirically assessing the influence of global attention on BERT pre-training. The primary steps involve creating an extensive corpus of structure-aware text through arXiv data, alongside a text-only counterpart. We carry out pre-training on these two datasets, investigate shifts in attention patterns, and assess their implications for downstream tasks. Our analysis underscores the significance of incorporating document structure into LM models, demonstrating their capacity to excel in more abstract tasks, such as document understanding.","sentences":["Most state-of-the-art techniques for Language Models (LMs) today rely on transformer-based architectures and their ubiquitous attention mechanism.","However, the exponential growth in computational requirements with longer input sequences confines Transformers to handling short passages.","Recent efforts have aimed to address this limitation by introducing selective attention mechanisms, notably local and global attention.","While sparse attention mechanisms, akin to full attention in being Turing-complete, have been theoretically established, their practical impact on pre-training remains unexplored.","This study focuses on empirically assessing the influence of global attention on BERT pre-training.","The primary steps involve creating an extensive corpus of structure-aware text through arXiv data, alongside a text-only counterpart.","We carry out pre-training on these two datasets, investigate shifts in attention patterns, and assess their implications for downstream tasks.","Our analysis underscores the significance of incorporating document structure into LM models, demonstrating their capacity to excel in more abstract tasks, such as document understanding."],"url":"http://arxiv.org/abs/2411.16618v1"}
{"created":"2024-11-25 17:54:44","title":"GeoFormer: A Multi-Polygon Segmentation Transformer","abstract":"In remote sensing there exists a common need for learning scale invariant shapes of objects like buildings. Prior works relies on tweaking multiple loss functions to convert segmentation maps into the final scale invariant representation, necessitating arduous design and optimization. For this purpose we introduce the GeoFormer, a novel architecture which presents a remedy to the said challenges, learning to generate multipolygons end-to-end. By modeling keypoints as spatially dependent tokens in an auto-regressive manner, the GeoFormer outperforms existing works in delineating building objects from satellite imagery. We evaluate the robustness of the GeoFormer against former methods through a variety of parameter ablations and highlight the advantages of optimizing a single likelihood function. Our study presents the first successful application of auto-regressive transformer models for multi-polygon predictions in remote sensing, suggesting a promising methodological alternative for building vectorization.","sentences":["In remote sensing there exists a common need for learning scale invariant shapes of objects like buildings.","Prior works relies on tweaking multiple loss functions to convert segmentation maps into the final scale invariant representation, necessitating arduous design and optimization.","For this purpose we introduce the GeoFormer, a novel architecture which presents a remedy to the said challenges, learning to generate multipolygons end-to-end.","By modeling keypoints as spatially dependent tokens in an auto-regressive manner, the GeoFormer outperforms existing works in delineating building objects from satellite imagery.","We evaluate the robustness of the GeoFormer against former methods through a variety of parameter ablations and highlight the advantages of optimizing a single likelihood function.","Our study presents the first successful application of auto-regressive transformer models for multi-polygon predictions in remote sensing, suggesting a promising methodological alternative for building vectorization."],"url":"http://arxiv.org/abs/2411.16616v1"}
{"created":"2024-11-25 17:54:29","title":"Graph Pooling with Local Cluster Selection","abstract":"Graph poolings in GNNs are a family of operations which take graphs as inputs and produce coarsened graphs as output. Modern graph poolings are trainable and closely related to GNNs, which learn to pool graphs under different assumptions. Though there are various assumptions, the procedure of generating pooled graphs is relatively similar and limited. This work formalizes a novel procedure of pooling graphs, along with a graph pooling approach for average situations.","sentences":["Graph poolings in GNNs are a family of operations which take graphs as inputs and produce coarsened graphs as output.","Modern graph poolings are trainable and closely related to GNNs, which learn to pool graphs under different assumptions.","Though there are various assumptions, the procedure of generating pooled graphs is relatively similar and limited.","This work formalizes a novel procedure of pooling graphs, along with a graph pooling approach for average situations."],"url":"http://arxiv.org/abs/2411.16615v1"}
{"created":"2024-11-25 17:48:59","title":"Recent Trends in Linear Text Segmentation: a Survey","abstract":"Linear Text Segmentation is the task of automatically tagging text documents with topic shifts, i.e. the places in the text where the topics change. A well-established area of research in Natural Language Processing, drawing from well-understood concepts in linguistic and computational linguistic research, the field has recently seen a lot of interest as a result of the surge of text, video, and audio available on the web, which in turn require ways of summarising and categorizing the mole of content for which linear text segmentation is a fundamental step. In this survey, we provide an extensive overview of current advances in linear text segmentation, describing the state of the art in terms of resources and approaches for the task. Finally, we highlight the limitations of available resources and of the task itself, while indicating ways forward based on the most recent literature and under-explored research directions.","sentences":["Linear Text Segmentation is the task of automatically tagging text documents with topic shifts, i.e. the places in the text where the topics change.","A well-established area of research in Natural Language Processing, drawing from well-understood concepts in linguistic and computational linguistic research, the field has recently seen a lot of interest as a result of the surge of text, video, and audio available on the web, which in turn require ways of summarising and categorizing the mole of content for which linear text segmentation is a fundamental step.","In this survey, we provide an extensive overview of current advances in linear text segmentation, describing the state of the art in terms of resources and approaches for the task.","Finally, we highlight the limitations of available resources and of the task itself, while indicating ways forward based on the most recent literature and under-explored research directions."],"url":"http://arxiv.org/abs/2411.16613v1"}
{"created":"2024-11-25 17:48:21","title":"Correctness Witnesses for Concurrent Programs: Bridging the Semantic Divide with Ghosts (Extended Version)","abstract":"Static analyzers are typically complex tools and thus prone to contain bugs themselves. To increase the trust in the verdict of such tools, witnesses encode key reasoning steps underlying the verdict in an exchangeable format, enabling independent validation of the reasoning by other tools. For the correctness of concurrent programs, no agreed-upon witness format exists -- in no small part due to the divide between the semantics considered by analyzers, ranging from interleaving to thread-modular approaches, making it challenging to exchange information. We propose a format that leverages the well-known notion of ghosts to embed the claims a tool makes about a program into a modified program with ghosts, such that the validity of a witness can be decided by analyzing this program. Thus, the validity of witnesses with respect to the interleaving and the thread-modular semantics coincides. Further, thread-modular invariants computed by an abstract interpreter can naturally be expressed in the new format using ghost statements. We evaluate the approach by generating such ghost witnesses for a subset of concurrent programs from the SV-COMP benchmark suite, and pass them to a model checker. It can confirm 75% of these witnesses -- indicating that ghost witnesses can bridge the semantic divide between interleaving and thread-modular approaches.","sentences":["Static analyzers are typically complex tools and thus prone to contain bugs themselves.","To increase the trust in the verdict of such tools, witnesses encode key reasoning steps underlying the verdict in an exchangeable format, enabling independent validation of the reasoning by other tools.","For the correctness of concurrent programs, no agreed-upon witness format exists -- in no small part due to the divide between the semantics considered by analyzers, ranging from interleaving to thread-modular approaches, making it challenging to exchange information.","We propose a format that leverages the well-known notion of ghosts to embed the claims a tool makes about a program into a modified program with ghosts, such that the validity of a witness can be decided by analyzing this program.","Thus, the validity of witnesses with respect to the interleaving and the thread-modular semantics coincides.","Further, thread-modular invariants computed by an abstract interpreter can naturally be expressed in the new format using ghost statements.","We evaluate the approach by generating such ghost witnesses for a subset of concurrent programs from the SV-COMP benchmark suite, and pass them to a model checker.","It can confirm 75% of these witnesses -- indicating that ghost witnesses can bridge the semantic divide between interleaving and thread-modular approaches."],"url":"http://arxiv.org/abs/2411.16612v1"}
{"created":"2024-11-25 17:45:38","title":"F -- A Model of Events based on the Foundational Ontology DOLCE+DnS Ultralite","abstract":"The lack of a formal model of events hinders interoperability in distributed event-based systems. In this paper, we present a formal model of events, called Event-Model-F. The model is based on the foundational ontology DOLCE+DnS Ultralite (DUL) and provides comprehensive support to represent time and space, objects and persons, as well as mereological, causal, and correlative relationships between events. In addition, the Event-Model-F provides a flexible means for event composition, modeling event causality and event correlation, and representing different interpretations of the same event. The Event-Model-F is developed following the pattern-oriented approach of DUL, is modularized in different ontologies, and can be easily extended by domain specific ontologies.","sentences":["The lack of a formal model of events hinders interoperability in distributed event-based systems.","In this paper, we present a formal model of events, called Event-Model-F.","The model is based on the foundational ontology DOLCE+DnS Ultralite (DUL) and provides comprehensive support to represent time and space, objects and persons, as well as mereological, causal, and correlative relationships between events.","In addition, the Event-Model-F provides a flexible means for event composition, modeling event causality and event correlation, and representing different interpretations of the same event.","The Event-Model-F is developed following the pattern-oriented approach of DUL, is modularized in different ontologies, and can be easily extended by domain specific ontologies."],"url":"http://arxiv.org/abs/2411.16609v1"}
{"created":"2024-11-25 17:44:02","title":"Barriers on the EDGE: A scalable CBF architecture over EDGE for safe aerial-ground multi-agent coordination","abstract":"In this article, we address the problem of designing a scalable control architecture for a safe coordinated operation of a multi-agent system with aerial (UAVs) and ground robots (UGVs) in a confined task space. The proposed method uses Control Barrier Functions (CBFs) to impose constraints associated with (i) collision avoidance between agents, (ii) landing of UAVs on mobile UGVs, and (iii) task space restriction. Further, to account for the rapid increase in the number of constraints for a single agent with the increasing number of agents, the proposed architecture uses a centralized-decentralized Edge cluster, where a centralized node (Watcher) activates the relevant constraints, reducing the need for high onboard processing and network complexity. The distributed nodes run the controller locally to overcome latency and network issues. The proposed Edge architecture is experimentally validated using multiple aerial and ground robots in a confined environment performing a coordinated operation.","sentences":["In this article, we address the problem of designing a scalable control architecture for a safe coordinated operation of a multi-agent system with aerial (UAVs) and ground robots (UGVs) in a confined task space.","The proposed method uses Control Barrier Functions (CBFs) to impose constraints associated with (i) collision avoidance between agents, (ii) landing of UAVs on mobile UGVs, and (iii) task space restriction.","Further, to account for the rapid increase in the number of constraints for a single agent with the increasing number of agents, the proposed architecture uses a centralized-decentralized Edge cluster, where a centralized node (Watcher) activates the relevant constraints, reducing the need for high onboard processing and network complexity.","The distributed nodes run the controller locally to overcome latency and network issues.","The proposed Edge architecture is experimentally validated using multiple aerial and ground robots in a confined environment performing a coordinated operation."],"url":"http://arxiv.org/abs/2411.16608v1"}
{"created":"2024-11-25 17:31:57","title":"Chat2SVG: Vector Graphics Generation with Large Language Models and Image Diffusion Models","abstract":"Scalable Vector Graphics (SVG) has become the de facto standard for vector graphics in digital design, offering resolution independence and precise control over individual elements. Despite their advantages, creating high-quality SVG content remains challenging, as it demands technical expertise with professional editing software and a considerable time investment to craft complex shapes. Recent text-to-SVG generation methods aim to make vector graphics creation more accessible, but they still encounter limitations in shape regularity, generalization ability, and expressiveness. To address these challenges, we introduce Chat2SVG, a hybrid framework that combines the strengths of Large Language Models (LLMs) and image diffusion models for text-to-SVG generation. Our approach first uses an LLM to generate semantically meaningful SVG templates from basic geometric primitives. Guided by image diffusion models, a dual-stage optimization pipeline refines paths in latent space and adjusts point coordinates to enhance geometric complexity. Extensive experiments show that Chat2SVG outperforms existing methods in visual fidelity, path regularity, and semantic alignment. Additionally, our system enables intuitive editing through natural language instructions, making professional vector graphics creation accessible to all users.","sentences":["Scalable Vector Graphics (SVG) has become the de facto standard for vector graphics in digital design, offering resolution independence and precise control over individual elements.","Despite their advantages, creating high-quality SVG content remains challenging, as it demands technical expertise with professional editing software and a considerable time investment to craft complex shapes.","Recent text-to-SVG generation methods aim to make vector graphics creation more accessible, but they still encounter limitations in shape regularity, generalization ability, and expressiveness.","To address these challenges, we introduce Chat2SVG, a hybrid framework that combines the strengths of Large Language Models (LLMs) and image diffusion models for text-to-SVG generation.","Our approach first uses an LLM to generate semantically meaningful SVG templates from basic geometric primitives.","Guided by image diffusion models, a dual-stage optimization pipeline refines paths in latent space and adjusts point coordinates to enhance geometric complexity.","Extensive experiments show that Chat2SVG outperforms existing methods in visual fidelity, path regularity, and semantic alignment.","Additionally, our system enables intuitive editing through natural language instructions, making professional vector graphics creation accessible to all users."],"url":"http://arxiv.org/abs/2411.16602v1"}
{"created":"2024-11-25 17:31:34","title":"Approximation Algorithms for Combinatorial Optimization with Predictions","abstract":"We initiate a systematic study of utilizing predictions to improve over approximation guarantees of classic algorithms, without increasing the running time. We propose a systematic method for a wide class of optimization problems that ask to select a feasible subset of input items of minimal (or maximal) total weight. This gives simple (near-)linear time algorithms for, e.g., Vertex Cover, Steiner Tree, Min-Weight Perfect Matching, Knapsack, and Clique. Our algorithms produce optimal solutions when provided with perfect predictions and their approximation ratios smoothly degrade with increasing prediction error. With small enough prediction error we achieve approximation guarantees that are beyond reach without predictions in the given time bounds, as exemplified by the NP-hardness and APX-hardness of many of the above problems. Although we show our approach to be optimal for this class of problems as a whole, there is a potential for exploiting specific structural properties of individual problems to obtain improved bounds; we demonstrate this on the Steiner Tree problem. We conclude with an empirical evaluation of our approach.","sentences":["We initiate a systematic study of utilizing predictions to improve over approximation guarantees of classic algorithms, without increasing the running time.","We propose a systematic method for a wide class of optimization problems that ask to select a feasible subset of input items of minimal (or maximal) total weight.","This gives simple (near-)linear time algorithms for, e.g., Vertex Cover, Steiner Tree, Min-Weight Perfect Matching, Knapsack, and Clique.","Our algorithms produce optimal solutions when provided with perfect predictions and their approximation ratios smoothly degrade with increasing prediction error.","With small enough prediction error we achieve approximation guarantees that are beyond reach without predictions in the given time bounds, as exemplified by the NP-hardness and APX-hardness of many of the above problems.","Although we show our approach to be optimal for this class of problems as a whole, there is a potential for exploiting specific structural properties of individual problems to obtain improved bounds; we demonstrate this on the Steiner Tree problem.","We conclude with an empirical evaluation of our approach."],"url":"http://arxiv.org/abs/2411.16600v1"}
{"created":"2024-11-25 17:30:32","title":"Unlocking The Potential of Adaptive Attacks on Diffusion-Based Purification","abstract":"Diffusion-based purification (DBP) is a defense against adversarial examples (AEs), amassing popularity for its ability to protect classifiers in an attack-oblivious manner and resistance to strong adversaries with access to the defense. Its robustness has been claimed to ensue from the reliance on diffusion models (DMs) that project the AEs onto the natural distribution. We revisit this claim, focusing on gradient-based strategies that back-propagate the loss gradients through the defense, commonly referred to as ``adaptive attacks\". Analytically, we show that such an optimization method invalidates DBP's core foundations, effectively targeting the DM rather than the classifier and restricting the purified outputs to a distribution over malicious samples instead. Thus, we reassess the reported empirical robustness, uncovering implementation flaws in the gradient back-propagation techniques used thus far for DBP. We fix these issues, providing the first reliable gradient library for DBP and demonstrating how adaptive attacks drastically degrade its robustness. We then study a less efficient yet stricter majority-vote setting where the classifier evaluates multiple purified copies of the input to make its decision. Here, DBP's stochasticity enables it to remain partially robust against traditional norm-bounded AEs. We propose a novel adaptation of a recent optimization method against deepfake watermarking that crafts systemic malicious perturbations while ensuring imperceptibility. When integrated with the adaptive attack, it completely defeats DBP, even in the majority-vote setup. Our findings prove that DBP, in its current state, is not a viable defense against AEs.","sentences":["Diffusion-based purification (DBP) is a defense against adversarial examples (AEs), amassing popularity for its ability to protect classifiers in an attack-oblivious manner and resistance to strong adversaries with access to the defense.","Its robustness has been claimed to ensue from the reliance on diffusion models (DMs) that project the AEs onto the natural distribution.","We revisit this claim, focusing on gradient-based strategies that back-propagate the loss gradients through the defense, commonly referred to as ``adaptive attacks\".","Analytically, we show that such an optimization method invalidates DBP's core foundations, effectively targeting the DM rather than the classifier and restricting the purified outputs to a distribution over malicious samples instead.","Thus, we reassess the reported empirical robustness, uncovering implementation flaws in the gradient back-propagation techniques used thus far for DBP.","We fix these issues, providing the first reliable gradient library for DBP and demonstrating how adaptive attacks drastically degrade its robustness.","We then study a less efficient yet stricter majority-vote setting where the classifier evaluates multiple purified copies of the input to make its decision.","Here, DBP's stochasticity enables it to remain partially robust against traditional norm-bounded AEs.","We propose a novel adaptation of a recent optimization method against deepfake watermarking that crafts systemic malicious perturbations while ensuring imperceptibility.","When integrated with the adaptive attack, it completely defeats DBP, even in the majority-vote setup.","Our findings prove that DBP, in its current state, is not a viable defense against AEs."],"url":"http://arxiv.org/abs/2411.16598v1"}
{"created":"2024-11-25 17:29:17","title":"Bivariate Linear Operator Codes","abstract":"In this work, we present a generalization of the linear operator family of codes that captures more codes that achieve list decoding capacity. Linear operator (LO) codes were introduced by Bhandari, Harsha, Kumar, and Sudan [BHKS24] as a way to capture capacity-achieving codes. In their framework, a code is specified by a collection of linear operators that are applied to a message polynomial and then evaluated at a specified set of evaluation points. We generalize this idea in a way that can be applied to bivariate message polynomials, getting what we call bivariate linear operator (B-LO) codes.   We show that bivariate linear operator codes capture more capacity-achieving codes, including permuted product codes introduced by Berman, Shany, and Tamo [BST24]. These codes work with bivariate message polynomials, which is why our generalization is necessary to capture them as a part of the linear operator framework.   Similarly to the initial paper on linear operator codes, we present sufficient conditions for a bivariate linear operator code to be list decodable. Using this characterization, we are able to derive the theorem characterizing list-decodability of LO codes as a specific case of our theorem for B-LO codes. We also apply this theorem to show that permuted product codes are list decodable up to capacity, thereby unifying this result with those of known list-decodable LO codes, including Folded Reed-Solomon, Multiplicity, and Affine Folded Reed-Solomon codes.","sentences":["In this work, we present a generalization of the linear operator family of codes that captures more codes that achieve list decoding capacity.","Linear operator (LO) codes were introduced by Bhandari, Harsha, Kumar, and Sudan","[BHKS24] as a way to capture capacity-achieving codes.","In their framework, a code is specified by a collection of linear operators that are applied to a message polynomial and then evaluated at a specified set of evaluation points.","We generalize this idea in a way that can be applied to bivariate message polynomials, getting what we call bivariate linear operator (B-LO) codes.   ","We show that bivariate linear operator codes capture more capacity-achieving codes, including permuted product codes introduced by Berman, Shany, and Tamo","[BST24].","These codes work with bivariate message polynomials, which is why our generalization is necessary to capture them as a part of the linear operator framework.   ","Similarly to the initial paper on linear operator codes, we present sufficient conditions for a bivariate linear operator code to be list decodable.","Using this characterization, we are able to derive the theorem characterizing list-decodability of LO codes as a specific case of our theorem for B-LO codes.","We also apply this theorem to show that permuted product codes are list decodable up to capacity, thereby unifying this result with those of known list-decodable LO codes, including Folded Reed-Solomon, Multiplicity, and Affine Folded Reed-Solomon codes."],"url":"http://arxiv.org/abs/2411.16596v1"}
{"created":"2024-11-25 17:28:44","title":"From Generation to Judgment: Opportunities and Challenges of LLM-as-a-judge","abstract":"Assessment and evaluation have long been critical challenges in artificial intelligence (AI) and natural language processing (NLP). However, traditional methods, whether matching-based or embedding-based, often fall short of judging subtle attributes and delivering satisfactory results. Recent advancements in Large Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs are leveraged to perform scoring, ranking, or selection across various tasks and applications. This paper provides a comprehensive survey of LLM-based judgment and assessment, offering an in-depth overview to advance this emerging field. We begin by giving detailed definitions from both input and output perspectives. Then we introduce a comprehensive taxonomy to explore LLM-as-a-judge from three dimensions: what to judge, how to judge and where to judge. Finally, we compile benchmarks for evaluating LLM-as-a-judge and highlight key challenges and promising directions, aiming to provide valuable insights and inspire future research in this promising research area. Paper list and more resources about LLM-as-a-judge can be found at \\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and \\url{https://llm-as-a-judge.github.io}.","sentences":["Assessment and evaluation have long been critical challenges in artificial intelligence (AI) and natural language processing (NLP).","However, traditional methods, whether matching-based or embedding-based, often fall short of judging subtle attributes and delivering satisfactory results.","Recent advancements in Large Language Models (LLMs) inspire the \"LLM-as-a-judge\" paradigm, where LLMs are leveraged to perform scoring, ranking, or selection across various tasks and applications.","This paper provides a comprehensive survey of LLM-based judgment and assessment, offering an in-depth overview to advance this emerging field.","We begin by giving detailed definitions from both input and output perspectives.","Then we introduce a comprehensive taxonomy to explore LLM-as-a-judge from three dimensions: what to judge, how to judge and where to judge.","Finally, we compile benchmarks for evaluating LLM-as-a-judge and highlight key challenges and promising directions, aiming to provide valuable insights and inspire future research in this promising research area.","Paper list and more resources about LLM-as-a-judge can be found at \\url{https://github.com/llm-as-a-judge/Awesome-LLM-as-a-judge} and \\url{https://llm-as-a-judge.github.io}."],"url":"http://arxiv.org/abs/2411.16594v1"}
{"created":"2024-11-25 17:28:44","title":"Location-Based Service (LBS) Data Quality Metrics and Effects on Mobility Inference","abstract":"Today, GPS-equipped mobile devices are ubiquitous, and they generate Location-Based Service (LBS) data, which has become a critical resource for understanding human mobility. However, inherent limitations in LBS datasets, primarily characterized by discontinuity and sparsity, may introduce significant biases in representing individual movement patterns. This study develops data quality metrics for LBS data, examines their disparities among different populations, and quantifies their effects on inferred individual movement, stays in particular, in the Boston Metropolitan Area. We find that data from higher-income, more educated, and predominantly white census block groups (CBGs) show higher sampling rates but paradoxically lower data quality. This contradiction may stem from greater privacy awareness in these communities. Additionally, we propose a new framework to resample LBS data and quantitatively evaluate the inferential biases associated with data of varying quality. This versatile framework can analyze the impacts originating from different data processing workflows with LBS data. Using linear regression models with clustered standard error, we assess the impact of data quality metrics on inferring the number of stay points. The results show that better data quality, characterized by the number of observations and temporal occupancy, can significantly reduce the bias when calculating the stay points of an individual. The introduction of additional data quality metrics into the regression model can further explain the bias. Overall, this study provides insights into how data quality can influence our understanding of human mobility patterns, highlighting the importance of carefully handling LBS data in research.","sentences":["Today, GPS-equipped mobile devices are ubiquitous, and they generate Location-Based Service (LBS) data, which has become a critical resource for understanding human mobility.","However, inherent limitations in LBS datasets, primarily characterized by discontinuity and sparsity, may introduce significant biases in representing individual movement patterns.","This study develops data quality metrics for LBS data, examines their disparities among different populations, and quantifies their effects on inferred individual movement, stays in particular, in the Boston Metropolitan Area.","We find that data from higher-income, more educated, and predominantly white census block groups (CBGs) show higher sampling rates but paradoxically lower data quality.","This contradiction may stem from greater privacy awareness in these communities.","Additionally, we propose a new framework to resample LBS data and quantitatively evaluate the inferential biases associated with data of varying quality.","This versatile framework can analyze the impacts originating from different data processing workflows with LBS data.","Using linear regression models with clustered standard error, we assess the impact of data quality metrics on inferring the number of stay points.","The results show that better data quality, characterized by the number of observations and temporal occupancy, can significantly reduce the bias when calculating the stay points of an individual.","The introduction of additional data quality metrics into the regression model can further explain the bias.","Overall, this study provides insights into how data quality can influence our understanding of human mobility patterns, highlighting the importance of carefully handling LBS data in research."],"url":"http://arxiv.org/abs/2411.16595v1"}
{"created":"2024-11-25 17:25:00","title":"Adversarial Attacks for Drift Detection","abstract":"Concept drift refers to the change of data distributions over time. While drift poses a challenge for learning models, requiring their continual adaption, it is also relevant in system monitoring to detect malfunctions, system failures, and unexpected behavior. In the latter case, the robust and reliable detection of drifts is imperative. This work studies the shortcomings of commonly used drift detection schemes. We show how to construct data streams that are drifting without being detected. We refer to those as drift adversarials. In particular, we compute all possible adversairals for common detection schemes and underpin our theoretical findings with empirical evaluations.","sentences":["Concept drift refers to the change of data distributions over time.","While drift poses a challenge for learning models, requiring their continual adaption, it is also relevant in system monitoring to detect malfunctions, system failures, and unexpected behavior.","In the latter case, the robust and reliable detection of drifts is imperative.","This work studies the shortcomings of commonly used drift detection schemes.","We show how to construct data streams that are drifting without being detected.","We refer to those as drift adversarials.","In particular, we compute all possible adversairals for common detection schemes and underpin our theoretical findings with empirical evaluations."],"url":"http://arxiv.org/abs/2411.16591v1"}
{"created":"2024-11-25 17:22:10","title":"Large Language Model-based Decision-making for COLREGs and the Control of Autonomous Surface Vehicles","abstract":"In the field of autonomous surface vehicles (ASVs), devising decision-making and obstacle avoidance solutions that address maritime COLREGs (Collision Regulations), primarily defined for human operators, has long been a pressing challenge. Recent advancements in explainable Artificial Intelligence (AI) and machine learning have shown promise in enabling human-like decision-making. Notably, significant developments have occurred in the application of Large Language Models (LLMs) to the decision-making of complex systems, such as self-driving cars. The textual and somewhat ambiguous nature of COLREGs (from an algorithmic perspective), however, poses challenges that align well with the capabilities of LLMs, suggesting that LLMs may become increasingly suitable for this application soon. This paper presents and demonstrates the first application of LLM-based decision-making and control for ASVs. The proposed method establishes a high-level decision-maker that uses online collision risk indices and key measurements to make decisions for safe manoeuvres. A tailored design and runtime structure is developed to support training and real-time action generation on a realistic ASV model. Local planning and control algorithms are integrated to execute the commands for waypoint following and collision avoidance at a lower level. To the authors' knowledge, this study represents the first attempt to apply explainable AI to the dynamic control problem of maritime systems recognising the COLREGs rules, opening new avenues for research in this challenging area. Results obtained across multiple test scenarios demonstrate the system's ability to maintain online COLREGs compliance, accurate waypoint tracking, and feasible control, while providing human-interpretable reasoning for each decision.","sentences":["In the field of autonomous surface vehicles (ASVs), devising decision-making and obstacle avoidance solutions that address maritime COLREGs (Collision Regulations), primarily defined for human operators, has long been a pressing challenge.","Recent advancements in explainable Artificial Intelligence (AI) and machine learning have shown promise in enabling human-like decision-making.","Notably, significant developments have occurred in the application of Large Language Models (LLMs) to the decision-making of complex systems, such as self-driving cars.","The textual and somewhat ambiguous nature of COLREGs (from an algorithmic perspective), however, poses challenges that align well with the capabilities of LLMs, suggesting that LLMs may become increasingly suitable for this application soon.","This paper presents and demonstrates the first application of LLM-based decision-making and control for ASVs.","The proposed method establishes a high-level decision-maker that uses online collision risk indices and key measurements to make decisions for safe manoeuvres.","A tailored design and runtime structure is developed to support training and real-time action generation on a realistic ASV model.","Local planning and control algorithms are integrated to execute the commands for waypoint following and collision avoidance at a lower level.","To the authors' knowledge, this study represents the first attempt to apply explainable AI to the dynamic control problem of maritime systems recognising the COLREGs rules, opening new avenues for research in this challenging area.","Results obtained across multiple test scenarios demonstrate the system's ability to maintain online COLREGs compliance, accurate waypoint tracking, and feasible control, while providing human-interpretable reasoning for each decision."],"url":"http://arxiv.org/abs/2411.16587v1"}
{"created":"2024-11-25 17:11:54","title":"Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision","abstract":"Training large language models (LLMs) to spend more time thinking and reflection before responding is crucial for effectively solving complex reasoning tasks in fields such as science, coding, and mathematics. However, the effectiveness of mechanisms like self-reflection and self-correction depends on the model's capacity to accurately assess its own performance, which can be limited by factors such as initial accuracy, question difficulty, and the lack of external feedback. In this paper, we delve into a two-player paradigm that separates the roles of reasoning and critique models, where the critique model provides step-level feedback to supervise the reasoning (actor) model during both test-time and train-time. We first propose AutoMathCritique, an automated and scalable framework for collecting critique data, resulting in a dataset of $76,321$ responses paired with step-level feedback. Fine-tuning language models with this dataset enables them to generate natural language feedback for mathematical reasoning. We demonstrate that the critique models consistently improve the actor's performance on difficult queries at test-time, especially when scaling up inference-time computation. Motivated by these findings, we introduce the critique-based supervision to the actor's self-training process, and propose a critique-in-the-loop self-improvement method. Experiments show that the method improves the actor's exploration efficiency and solution diversity, especially on challenging queries, leading to a stronger reasoning model. Lastly, we take the preliminary step to explore training self-talk reasoning models via critique supervision and showcase its potential. Our code and datasets are at \\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}.","sentences":["Training large language models (LLMs) to spend more time thinking and reflection before responding is crucial for effectively solving complex reasoning tasks in fields such as science, coding, and mathematics.","However, the effectiveness of mechanisms like self-reflection and self-correction depends on the model's capacity to accurately assess its own performance, which can be limited by factors such as initial accuracy, question difficulty, and the lack of external feedback.","In this paper, we delve into a two-player paradigm that separates the roles of reasoning and critique models, where the critique model provides step-level feedback to supervise the reasoning (actor) model during both test-time and train-time.","We first propose AutoMathCritique, an automated and scalable framework for collecting critique data, resulting in a dataset of $76,321$ responses paired with step-level feedback.","Fine-tuning language models with this dataset enables them to generate natural language feedback for mathematical reasoning.","We demonstrate that the critique models consistently improve the actor's performance on difficult queries at test-time, especially when scaling up inference-time computation.","Motivated by these findings, we introduce the critique-based supervision to the actor's self-training process, and propose a critique-in-the-loop self-improvement method.","Experiments show that the method improves the actor's exploration efficiency and solution diversity, especially on challenging queries, leading to a stronger reasoning model.","Lastly, we take the preliminary step to explore training self-talk reasoning models via critique supervision and showcase its potential.","Our code and datasets are at \\href{https://mathcritique.github.io/}{https://mathcritique.github.io/}."],"url":"http://arxiv.org/abs/2411.16579v1"}
{"created":"2024-11-25 17:07:19","title":"Forest Covers and Bounded Forest Covers","abstract":"We study approximation algorithms for the forest cover and bounded forest cover problems. A probabilistic $2+\\epsilon$ approximation algorithm for the forest cover problem is given using the method of dual fitting. A deterministic algorithm with a 2-approximation ratio that rounds the optimal solution to a linear program is given next. The 2-approximation for the forest cover is then used to give a 6-approximation for the bounded forest cover problem. The use of the probabilistic method to develop the $2+\\epsilon$ approximation algorithm may be of independent interest.","sentences":["We study approximation algorithms for the forest cover and bounded forest cover problems.","A probabilistic $2+\\epsilon$ approximation algorithm for the forest cover problem is given using the method of dual fitting.","A deterministic algorithm with a 2-approximation ratio that rounds the optimal solution to a linear program is given next.","The 2-approximation for the forest cover is then used to give a 6-approximation for the bounded forest cover problem.","The use of the probabilistic method to develop the $2+\\epsilon$ approximation algorithm may be of independent interest."],"url":"http://arxiv.org/abs/2411.16578v1"}
{"created":"2024-11-25 16:59:42","title":"Rethinking Diffusion for Text-Driven Human Motion Generation","abstract":"Since 2023, Vector Quantization (VQ)-based discrete generation methods have rapidly dominated human motion generation, primarily surpassing diffusion-based continuous generation methods in standard performance metrics. However, VQ-based methods have inherent limitations. Representing continuous motion data as limited discrete tokens leads to inevitable information loss, reduces the diversity of generated motions, and restricts their ability to function effectively as motion priors or generation guidance. In contrast, the continuous space generation nature of diffusion-based methods makes them well-suited to address these limitations and with even potential for model scalability. In this work, we systematically investigate why current VQ-based methods perform well and explore the limitations of existing diffusion-based methods from the perspective of motion data representation and distribution. Drawing on these insights, we preserve the inherent strengths of a diffusion-based human motion generation model and gradually optimize it with inspiration from VQ-based approaches. Our approach introduces a human motion diffusion model enabled to perform bidirectional masked autoregression, optimized with a reformed data representation and distribution. Additionally, we also propose more robust evaluation methods to fairly assess different-based methods. Extensive experiments on benchmark human motion generation datasets demonstrate that our method excels previous methods and achieves state-of-the-art performances.","sentences":["Since 2023, Vector Quantization (VQ)-based discrete generation methods have rapidly dominated human motion generation, primarily surpassing diffusion-based continuous generation methods in standard performance metrics.","However, VQ-based methods have inherent limitations.","Representing continuous motion data as limited discrete tokens leads to inevitable information loss, reduces the diversity of generated motions, and restricts their ability to function effectively as motion priors or generation guidance.","In contrast, the continuous space generation nature of diffusion-based methods makes them well-suited to address these limitations and with even potential for model scalability.","In this work, we systematically investigate why current VQ-based methods perform well and explore the limitations of existing diffusion-based methods from the perspective of motion data representation and distribution.","Drawing on these insights, we preserve the inherent strengths of a diffusion-based human motion generation model and gradually optimize it with inspiration from VQ-based approaches.","Our approach introduces a human motion diffusion model enabled to perform bidirectional masked autoregression, optimized with a reformed data representation and distribution.","Additionally, we also propose more robust evaluation methods to fairly assess different-based methods.","Extensive experiments on benchmark human motion generation datasets demonstrate that our method excels previous methods and achieves state-of-the-art performances."],"url":"http://arxiv.org/abs/2411.16575v1"}
{"created":"2024-11-25 16:56:29","title":"Deriving Analytical Solutions Using Symbolic Matrix Structural Analysis: Part 2 -- Plane Trusses","abstract":"This study extends the use of symbolic computation in Matrix Structural Analysis (MSA) to plane (2D) trusses, building on previous work that focused on continuous beams. An open-source MATLAB program, hosted on GitHub, was developed to perform symbolic analysis of 2D trusses under point loads for any configuration. Using MATLAB's Symbolic Math Toolbox, the program derives analytical expressions for displacements, support reactions, and axial forces, providing a deeper understanding of truss behavior. The symbolic approach also supports efficient and scalable sensitivity analysis by directly computing partial derivatives of outputs with respect to input parameters, enhancing design exploration and optimization. This tool serves as a valuable resource for both engineering practice and education, offering clear insights into parameter relationships and enriching the understanding of structural mechanics. The accuracy of the symbolic results has been rigorously validated against two commercial finite element software programs and results from the literature, with full agreement, confirming the validity and generality of the methodology.","sentences":["This study extends the use of symbolic computation in Matrix Structural Analysis (MSA) to plane (2D) trusses, building on previous work that focused on continuous beams.","An open-source MATLAB program, hosted on GitHub, was developed to perform symbolic analysis of 2D trusses under point loads for any configuration.","Using MATLAB's Symbolic Math Toolbox, the program derives analytical expressions for displacements, support reactions, and axial forces, providing a deeper understanding of truss behavior.","The symbolic approach also supports efficient and scalable sensitivity analysis by directly computing partial derivatives of outputs with respect to input parameters, enhancing design exploration and optimization.","This tool serves as a valuable resource for both engineering practice and education, offering clear insights into parameter relationships and enriching the understanding of structural mechanics.","The accuracy of the symbolic results has been rigorously validated against two commercial finite element software programs and results from the literature, with full agreement, confirming the validity and generality of the methodology."],"url":"http://arxiv.org/abs/2411.16573v1"}
{"created":"2024-11-25 16:55:26","title":"Pantograph: A Fluid and Typed Structure Editor","abstract":"Structure editors operate directly on a program's syntactic tree structure. At first glance, this allows for the exciting possibility that such an editor could enforce correctness properties: programs could be well-formed and sometimes even well-typed by construction. Unfortunately, traditional approaches to structure editing that attempt to rigidly enforce these properties face a seemingly fundamental problem, known in the literature as viscosity. Making changes to existing programs often requires temporarily breaking program structure -- but disallowing such changes makes it difficult to edit programs!   In this paper, we present a scheme for structure editing which always maintains a valid program structure without sacrificing the fluidity necessary to freely edit programs. Two key pieces help solve this puzzle: first, we develop a novel generalization of selection for tree-based structures that properly generalizes text-based selection and editing, allowing users to freely rearrange pieces of code by cutting and pasting one-hole contexts; second, we type these one-hole contexts with a category of type diffs and explore the metatheory of the system that arises for maintaining well-typedness systematically. We implement our approach as an editor called Pantograph, and we conduct a study in which we successfully taught students to program with Pantograph and compare their performance against a traditional text editor.","sentences":["Structure editors operate directly on a program's syntactic tree structure.","At first glance, this allows for the exciting possibility that such an editor could enforce correctness properties: programs could be well-formed and sometimes even well-typed by construction.","Unfortunately, traditional approaches to structure editing that attempt to rigidly enforce these properties face a seemingly fundamental problem, known in the literature as viscosity.","Making changes to existing programs often requires temporarily breaking program structure -- but disallowing such changes makes it difficult to edit programs!   ","In this paper, we present a scheme for structure editing which always maintains a valid program structure without sacrificing the fluidity necessary to freely edit programs.","Two key pieces help solve this puzzle: first, we develop a novel generalization of selection for tree-based structures that properly generalizes text-based selection and editing, allowing users to freely rearrange pieces of code by cutting and pasting one-hole contexts; second, we type these one-hole contexts with a category of type diffs and explore the metatheory of the system that arises for maintaining well-typedness systematically.","We implement our approach as an editor called Pantograph, and we conduct a study in which we successfully taught students to program with Pantograph and compare their performance against a traditional text editor."],"url":"http://arxiv.org/abs/2411.16571v1"}
{"created":"2024-11-25 16:52:21","title":"J-CaPA : Joint Channel and Pyramid Attention Improves Medical Image Segmentation","abstract":"Medical image segmentation is crucial for diagnosis and treatment planning. Traditional CNN-based models, like U-Net, have shown promising results but struggle to capture long-range dependencies and global context. To address these limitations, we propose a transformer-based architecture that jointly applies Channel Attention and Pyramid Attention mechanisms to improve multi-scale feature extraction and enhance segmentation performance for medical images. Increasing model complexity requires more training data, and we further improve model generalization with CutMix data augmentation. Our approach is evaluated on the Synapse multi-organ segmentation dataset, achieving a 6.9% improvement in Mean Dice score and a 39.9% improvement in Hausdorff Distance (HD95) over an implementation without our enhancements. Our proposed model demonstrates improved segmentation accuracy for complex anatomical structures, outperforming existing state-of-the-art methods.","sentences":["Medical image segmentation is crucial for diagnosis and treatment planning.","Traditional CNN-based models, like U-Net, have shown promising results but struggle to capture long-range dependencies and global context.","To address these limitations, we propose a transformer-based architecture that jointly applies Channel Attention and Pyramid Attention mechanisms to improve multi-scale feature extraction and enhance segmentation performance for medical images.","Increasing model complexity requires more training data, and we further improve model generalization with CutMix data augmentation.","Our approach is evaluated on the Synapse multi-organ segmentation dataset, achieving a 6.9% improvement in Mean Dice score and a 39.9% improvement in Hausdorff Distance (HD95) over an implementation without our enhancements.","Our proposed model demonstrates improved segmentation accuracy for complex anatomical structures, outperforming existing state-of-the-art methods."],"url":"http://arxiv.org/abs/2411.16568v1"}
{"created":"2024-11-25 16:51:11","title":"Enhancing Few-Shot Learning with Integrated Data and GAN Model Approaches","abstract":"This paper presents an innovative approach to enhancing few-shot learning by integrating data augmentation with model fine-tuning in a framework designed to tackle the challenges posed by small-sample data. Recognizing the critical limitations of traditional machine learning models that require large datasets-especially in fields such as drug discovery, target recognition, and malicious traffic detection-this study proposes a novel strategy that leverages Generative Adversarial Networks (GANs) and advanced optimization techniques to improve model performance with limited data. Specifically, the paper addresses the noise and bias issues introduced by data augmentation methods, contrasting them with model-based approaches, such as fine-tuning and metric learning, which rely heavily on related datasets. By combining Markov Chain Monte Carlo (MCMC) sampling and discriminative model ensemble strategies within a GAN framework, the proposed model adjusts generative and discriminative distributions to simulate a broader range of relevant data. Furthermore, it employs MHLoss and a reparameterized GAN ensemble to enhance stability and accelerate convergence, ultimately leading to improved classification performance on small-sample images and structured datasets. Results confirm that the MhERGAN algorithm developed in this research is highly effective for few-shot learning, offering a practical solution that bridges data scarcity with high-performing model adaptability and generalization.","sentences":["This paper presents an innovative approach to enhancing few-shot learning by integrating data augmentation with model fine-tuning in a framework designed to tackle the challenges posed by small-sample data.","Recognizing the critical limitations of traditional machine learning models that require large datasets-especially in fields such as drug discovery, target recognition, and malicious traffic detection-this study proposes a novel strategy that leverages Generative Adversarial Networks (GANs) and advanced optimization techniques to improve model performance with limited data.","Specifically, the paper addresses the noise and bias issues introduced by data augmentation methods, contrasting them with model-based approaches, such as fine-tuning and metric learning, which rely heavily on related datasets.","By combining Markov Chain Monte Carlo (MCMC) sampling and discriminative model ensemble strategies within a GAN framework, the proposed model adjusts generative and discriminative distributions to simulate a broader range of relevant data.","Furthermore, it employs MHLoss and a reparameterized GAN ensemble to enhance stability and accelerate convergence, ultimately leading to improved classification performance on small-sample images and structured datasets.","Results confirm that the MhERGAN algorithm developed in this research is highly effective for few-shot learning, offering a practical solution that bridges data scarcity with high-performing model adaptability and generalization."],"url":"http://arxiv.org/abs/2411.16567v1"}
{"created":"2024-11-25 16:49:10","title":"J-P: MDP. FP. PP.: Characterizing Total Expected Rewards in Markov Decision Processes as Least Fixed Points with an Application to Operational Semantics of Probabilistic Programs (Technical Report)","abstract":"Markov decision processes (MDPs) with rewards are a widespread and well-studied model for systems that make both probabilistic and nondeterministic choices. A fundamental result about MDPs is that their minimal and maximal expected rewards satisfy Bellmann's optimality equations. For various classes of MDPs - notably finite-state MDPs, positive bounded models, and negative models - expected rewards are known to be the least solution of those equations. However, these classes of MDPs are too restrictive for probabilistic program verification. In particular, they assume that all rewards are finite. This is already not the case for the expected runtime of a simple probabilisitic program modeling a 1-dimensional random walk.   In this paper, we develop a generalized least fixed point characterization of expected rewards in MDPs without those restrictions. Furthermore, we demonstrate how said characterization can be leveraged to prove weakest-preexpectation-style calculi sound with respect to an operational MDP model.","sentences":["Markov decision processes (MDPs) with rewards are a widespread and well-studied model for systems that make both probabilistic and nondeterministic choices.","A fundamental result about MDPs is that their minimal and maximal expected rewards satisfy Bellmann's optimality equations.","For various classes of MDPs - notably finite-state MDPs, positive bounded models, and negative models - expected rewards are known to be the least solution of those equations.","However, these classes of MDPs are too restrictive for probabilistic program verification.","In particular, they assume that all rewards are finite.","This is already not the case for the expected runtime of a simple probabilisitic program modeling a 1-dimensional random walk.   ","In this paper, we develop a generalized least fixed point characterization of expected rewards in MDPs without those restrictions.","Furthermore, we demonstrate how said characterization can be leveraged to prove weakest-preexpectation-style calculi sound with respect to an operational MDP model."],"url":"http://arxiv.org/abs/2411.16564v1"}
{"created":"2024-11-25 16:47:10","title":"EnStack: An Ensemble Stacking Framework of Large Language Models for Enhanced Vulnerability Detection in Source Code","abstract":"Automated detection of software vulnerabilities is critical for enhancing security, yet existing methods often struggle with the complexity and diversity of modern codebases. In this paper, we introduce EnStack, a novel ensemble stacking framework that enhances vulnerability detection using natural language processing (NLP) techniques. Our approach synergizes multiple pre-trained large language models (LLMs) specialized in code understanding CodeBERT for semantic analysis, GraphCodeBERT for structural representation, and UniXcoder for cross-modal capabilities. By fine-tuning these models on the Draper VDISC dataset and integrating their outputs through meta-classifiers such as Logistic Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack effectively captures intricate code patterns and vulnerabilities that individual models may overlook. The meta-classifiers consolidate the strengths of each LLM, resulting in a comprehensive model that excels in detecting subtle and complex vulnerabilities across diverse programming contexts. Experimental results demonstrate that EnStack significantly outperforms existing methods, achieving notable improvements in accuracy, precision, recall, and F1-score. This work highlights the potential of ensemble LLM approaches in code analysis tasks and offers valuable insights into applying NLP techniques for advancing automated vulnerability detection.","sentences":["Automated detection of software vulnerabilities is critical for enhancing security, yet existing methods often struggle with the complexity and diversity of modern codebases.","In this paper, we introduce EnStack, a novel ensemble stacking framework that enhances vulnerability detection using natural language processing (NLP) techniques.","Our approach synergizes multiple pre-trained large language models (LLMs) specialized in code understanding CodeBERT for semantic analysis, GraphCodeBERT for structural representation, and UniXcoder for cross-modal capabilities.","By fine-tuning these models on the Draper VDISC dataset and integrating their outputs through meta-classifiers such as Logistic Regression, Support Vector Machines (SVM), Random Forest, and XGBoost, EnStack effectively captures intricate code patterns and vulnerabilities that individual models may overlook.","The meta-classifiers consolidate the strengths of each LLM, resulting in a comprehensive model that excels in detecting subtle and complex vulnerabilities across diverse programming contexts.","Experimental results demonstrate that EnStack significantly outperforms existing methods, achieving notable improvements in accuracy, precision, recall, and F1-score.","This work highlights the potential of ensemble LLM approaches in code analysis tasks and offers valuable insights into applying NLP techniques for advancing automated vulnerability detection."],"url":"http://arxiv.org/abs/2411.16561v1"}
{"created":"2024-11-25 16:41:10","title":"Polarization under the Channel Noise with Memory","abstract":"The channel polarization under the channel noise with memory is comprehensively studied. With the help of the genie-aided channel, we prove that the polarized channels also converge to extremal channels under the standard polar codes structure. More importantly, the ratio of the perfect channel can be larger than $I(W)$ which is the capacity of the original channel. However, the polarization rate is shown to be slower than the binary-input discrete memoryless channel (DMC) case. Specifically, the upper bound of the block error is $\\mathcal{O}(L^{-c_0})$ where $L$ is the block length and $c_0$ is some positive constant. Furthermore, the upper and lower bound of the gap between the capacity and cutoff rate is investigated when the block length is finite, which is more useful for practical applications.","sentences":["The channel polarization under the channel noise with memory is comprehensively studied.","With the help of the genie-aided channel, we prove that the polarized channels also converge to extremal channels under the standard polar codes structure.","More importantly, the ratio of the perfect channel can be larger than $I(W)$ which is the capacity of the original channel.","However, the polarization rate is shown to be slower than the binary-input discrete memoryless channel (DMC) case.","Specifically, the upper bound of the block error is $\\mathcal{O}(L^{-c_0})$ where $L$ is the block length and $c_0$ is some positive constant.","Furthermore, the upper and lower bound of the gap between the capacity and cutoff rate is investigated when the block length is finite, which is more useful for practical applications."],"url":"http://arxiv.org/abs/2411.16557v1"}
{"created":"2024-11-25 16:38:17","title":"Generating Out-Of-Distribution Scenarios Using Language Models","abstract":"The deployment of autonomous vehicles controlled by machine learning techniques requires extensive testing in diverse real-world environments, robust handling of edge cases and out-of-distribution scenarios, and comprehensive safety validation to ensure that these systems can navigate safely and effectively under unpredictable conditions. Addressing Out-Of-Distribution (OOD) driving scenarios is essential for enhancing safety, as OOD scenarios help validate the reliability of the models within the vehicle's autonomy stack. However, generating OOD scenarios is challenging due to their long-tailed distribution and rarity in urban driving dataset. Recently, Large Language Models (LLMs) have shown promise in autonomous driving, particularly for their zero-shot generalization and common-sense reasoning capabilities. In this paper, we leverage these LLM strengths to introduce a framework for generating diverse OOD driving scenarios. Our approach uses LLMs to construct a branching tree, where each branch represents a unique OOD scenario. These scenarios are then simulated in the CARLA simulator using an automated framework that aligns scene augmentation with the corresponding textual descriptions. We evaluate our framework through extensive simulations, and assess its performance via a diversity metric that measures the richness of the scenarios. Additionally, we introduce a new \"OOD-ness\" metric, which quantifies how much the generated scenarios deviate from typical urban driving conditions. Furthermore, we explore the capacity of modern Vision-Language Models (VLMs) to interpret and safely navigate through the simulated OOD scenarios. Our findings offer valuable insights into the reliability of language models in addressing OOD scenarios within the context of urban driving.","sentences":["The deployment of autonomous vehicles controlled by machine learning techniques requires extensive testing in diverse real-world environments, robust handling of edge cases and out-of-distribution scenarios, and comprehensive safety validation to ensure that these systems can navigate safely and effectively under unpredictable conditions.","Addressing Out-Of-Distribution (OOD) driving scenarios is essential for enhancing safety, as OOD scenarios help validate the reliability of the models within the vehicle's autonomy stack.","However, generating OOD scenarios is challenging due to their long-tailed distribution and rarity in urban driving dataset.","Recently, Large Language Models (LLMs) have shown promise in autonomous driving, particularly for their zero-shot generalization and common-sense reasoning capabilities.","In this paper, we leverage these LLM strengths to introduce a framework for generating diverse OOD driving scenarios.","Our approach uses LLMs to construct a branching tree, where each branch represents a unique OOD scenario.","These scenarios are then simulated in the CARLA simulator using an automated framework that aligns scene augmentation with the corresponding textual descriptions.","We evaluate our framework through extensive simulations, and assess its performance via a diversity metric that measures the richness of the scenarios.","Additionally, we introduce a new \"OOD-ness\" metric, which quantifies how much the generated scenarios deviate from typical urban driving conditions.","Furthermore, we explore the capacity of modern Vision-Language Models (VLMs) to interpret and safely navigate through the simulated OOD scenarios.","Our findings offer valuable insights into the reliability of language models in addressing OOD scenarios within the context of urban driving."],"url":"http://arxiv.org/abs/2411.16554v1"}
{"created":"2024-11-25 16:32:29","title":"Representation Collapsing Problems in Vector Quantization","abstract":"Vector quantization is a technique in machine learning that discretizes continuous representations into a set of discrete vectors. It is widely employed in tokenizing data representations for large language models, diffusion models, and other generative models. Despite its prevalence, the characteristics and behaviors of vector quantization in generative models remain largely underexplored. In this study, we investigate representation collapse in vector quantization - a critical degradation where codebook tokens or latent embeddings lose their discriminative power by converging to a limited subset of values. This collapse fundamentally compromises the model's ability to capture diverse data patterns. By leveraging both synthetic and real datasets, we identify the severity of each type of collapses and triggering conditions. Our analysis reveals that restricted initialization and limited encoder capacity result in tokens collapse and embeddings collapse. Building on these findings, we propose potential solutions aimed at mitigating each collapse. To the best of our knowledge, this is the first comprehensive study examining representation collapsing problems in vector quantization.","sentences":["Vector quantization is a technique in machine learning that discretizes continuous representations into a set of discrete vectors.","It is widely employed in tokenizing data representations for large language models, diffusion models, and other generative models.","Despite its prevalence, the characteristics and behaviors of vector quantization in generative models remain largely underexplored.","In this study, we investigate representation collapse in vector quantization - a critical degradation where codebook tokens or latent embeddings lose their discriminative power by converging to a limited subset of values.","This collapse fundamentally compromises the model's ability to capture diverse data patterns.","By leveraging both synthetic and real datasets, we identify the severity of each type of collapses and triggering conditions.","Our analysis reveals that restricted initialization and limited encoder capacity result in tokens collapse and embeddings collapse.","Building on these findings, we propose potential solutions aimed at mitigating each collapse.","To the best of our knowledge, this is the first comprehensive study examining representation collapsing problems in vector quantization."],"url":"http://arxiv.org/abs/2411.16550v1"}
{"created":"2024-11-25 16:32:11","title":"Transformers are Deep Optimizers: Provable In-Context Learning for Deep Model Training","abstract":"We investigate the transformer's capability for in-context learning (ICL) to simulate the training process of deep models. Our key contribution is providing a positive example of using a transformer to train a deep neural network by gradient descent in an implicit fashion via ICL. Specifically, we provide an explicit construction of a $(2N+4)L$-layer transformer capable of simulating $L$ gradient descent steps of an $N$-layer ReLU network through ICL. We also give the theoretical guarantees for the approximation within any given error and the convergence of the ICL gradient descent. Additionally, we extend our analysis to the more practical setting using Softmax-based transformers. We validate our findings on synthetic datasets for 3-layer, 4-layer, and 6-layer neural networks. The results show that ICL performance matches that of direct training.","sentences":["We investigate the transformer's capability for in-context learning (ICL) to simulate the training process of deep models.","Our key contribution is providing a positive example of using a transformer to train a deep neural network by gradient descent in an implicit fashion via ICL.","Specifically, we provide an explicit construction of a $(2N+4)L$-layer transformer capable of simulating $L$ gradient descent steps of an $N$-layer ReLU network through ICL.","We also give the theoretical guarantees for the approximation within any given error and the convergence of the ICL gradient descent.","Additionally, we extend our analysis to the more practical setting using Softmax-based transformers.","We validate our findings on synthetic datasets for 3-layer, 4-layer, and 6-layer neural networks.","The results show that ICL performance matches that of direct training."],"url":"http://arxiv.org/abs/2411.16549v1"}
{"created":"2024-11-25 16:29:43","title":"Float Self-Tagging","abstract":"Dynamic and polymorphic languages must attach information, such as types, to run time objects, and therefore adapt the memory layout of values to include space for this information. This is especially problematic in the case of IEEE754 double-precision floating-point numbers, which require exactly 64 bits, leaving no space for type information. The two main encodings in-use to this day, tagged pointers and NaN-tagging, either allocate floats on the heap or unbox them at the cost of an overhead when handling all other objects.   This paper presents self-tagging, a new approach to object tagging that can attach type information to 64-bit objects while retaining the ability to use all of their 64 bits for data. At its core, self-tagging exploits the fact that some bit sequences appear with very high probability. Superimposing tags with these frequent sequences allows encoding both 64-bit data and type within a single machine word. Implementations of self-tagging demonstrate that it unboxes all floats in practice, accelerating the execution time of float-intensive benchmarks in Scheme by 2.3$\\times$, and in JavaScript by 2.7$\\times$ without impacting the performance of other benchmarks, which makes it a good alternative to both tagged pointers and NaN-tagging.","sentences":["Dynamic and polymorphic languages must attach information, such as types, to run time objects, and therefore adapt the memory layout of values to include space for this information.","This is especially problematic in the case of IEEE754 double-precision floating-point numbers, which require exactly 64 bits, leaving no space for type information.","The two main encodings in-use to this day, tagged pointers and NaN-tagging, either allocate floats on the heap or unbox them at the cost of an overhead when handling all other objects.   ","This paper presents self-tagging, a new approach to object tagging that can attach type information to 64-bit objects while retaining the ability to use all of their 64 bits for data.","At its core, self-tagging exploits the fact that some bit sequences appear with very high probability.","Superimposing tags with these frequent sequences allows encoding both 64-bit data and type within a single machine word.","Implementations of self-tagging demonstrate that it unboxes all floats in practice, accelerating the execution time of float-intensive benchmarks in Scheme by 2.3$\\times$, and in JavaScript by 2.7$\\times$ without impacting the performance of other benchmarks, which makes it a good alternative to both tagged pointers and NaN-tagging."],"url":"http://arxiv.org/abs/2411.16544v1"}
{"created":"2024-11-25 16:21:34","title":"RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics","abstract":"Spatial understanding is a crucial capability for robots to make grounded decisions based on their environment. This foundational skill enables robots not only to perceive their surroundings but also to reason about and interact meaningfully within the world. In modern robotics, these capabilities are taken on by visual language models, and they face significant challenges when applied to spatial reasoning context due to their training data sources. These sources utilize general-purpose image datasets, and they often lack sophisticated spatial scene understanding capabilities. For example, the datasets do not address reference frame comprehension - spatial relationships require clear contextual understanding, whether from an ego-centric, object-centric, or world-centric perspective, which allow for effective real-world interaction. To address this issue, we introduce RoboSpatial, a large-scale spatial understanding dataset consisting of real indoor and tabletop scenes captured as 3D scans and egocentric images, annotated with rich spatial information relevant to robotics. The dataset includes 1M images, 5K 3D scans, and 3M annotated spatial relationships, with paired 2D egocentric images and 3D scans to make it both 2D and 3D ready. Our experiments show that models trained with RoboSpatial outperform baselines on downstream tasks such as spatial affordance prediction, spatial relationship prediction, and robotics manipulation.","sentences":["Spatial understanding is a crucial capability for robots to make grounded decisions based on their environment.","This foundational skill enables robots not only to perceive their surroundings but also to reason about and interact meaningfully within the world.","In modern robotics, these capabilities are taken on by visual language models, and they face significant challenges when applied to spatial reasoning context due to their training data sources.","These sources utilize general-purpose image datasets, and they often lack sophisticated spatial scene understanding capabilities.","For example, the datasets do not address reference frame comprehension - spatial relationships require clear contextual understanding, whether from an ego-centric, object-centric, or world-centric perspective, which allow for effective real-world interaction.","To address this issue, we introduce RoboSpatial, a large-scale spatial understanding dataset consisting of real indoor and tabletop scenes captured as 3D scans and egocentric images, annotated with rich spatial information relevant to robotics.","The dataset includes 1M images, 5K 3D scans, and 3M annotated spatial relationships, with paired 2D egocentric images and 3D scans to make it both 2D and 3D ready.","Our experiments show that models trained with RoboSpatial outperform baselines on downstream tasks such as spatial affordance prediction, spatial relationship prediction, and robotics manipulation."],"url":"http://arxiv.org/abs/2411.16537v1"}
{"created":"2024-11-25 16:18:39","title":"Continual Deep Reinforcement Learning with Task-Agnostic Policy Distillation","abstract":"Central to the development of universal learning systems is the ability to solve multiple tasks without retraining from scratch when new data arrives. This is crucial because each task requires significant training time. Addressing the problem of continual learning necessitates various methods due to the complexity of the problem space. This problem space includes: (1) addressing catastrophic forgetting to retain previously learned tasks, (2) demonstrating positive forward transfer for faster learning, (3) ensuring scalability across numerous tasks, and (4) facilitating learning without requiring task labels, even in the absence of clear task boundaries. In this paper, the Task-Agnostic Policy Distillation (TAPD) framework is introduced. This framework alleviates problems (1)-(4) by incorporating a task-agnostic phase, where an agent explores its environment without any external goal and maximizes only its intrinsic motivation. The knowledge gained during this phase is later distilled for further exploration. Therefore, the agent acts in a self-supervised manner by systematically seeking novel states. By utilizing task-agnostic distilled knowledge, the agent can solve downstream tasks more efficiently, leading to improved sample efficiency. Our code is available at the repository: https://github.com/wabbajack1/TAPD.","sentences":["Central to the development of universal learning systems is the ability to solve multiple tasks without retraining from scratch when new data arrives.","This is crucial because each task requires significant training time.","Addressing the problem of continual learning necessitates various methods due to the complexity of the problem space.","This problem space includes: (1) addressing catastrophic forgetting to retain previously learned tasks, (2) demonstrating positive forward transfer for faster learning, (3) ensuring scalability across numerous tasks, and (4) facilitating learning without requiring task labels, even in the absence of clear task boundaries.","In this paper, the Task-Agnostic Policy Distillation (TAPD) framework is introduced.","This framework alleviates problems (1)-(4) by incorporating a task-agnostic phase, where an agent explores its environment without any external goal and maximizes only its intrinsic motivation.","The knowledge gained during this phase is later distilled for further exploration.","Therefore, the agent acts in a self-supervised manner by systematically seeking novel states.","By utilizing task-agnostic distilled knowledge, the agent can solve downstream tasks more efficiently, leading to improved sample efficiency.","Our code is available at the repository: https://github.com/wabbajack1/TAPD."],"url":"http://arxiv.org/abs/2411.16532v1"}
{"created":"2024-11-25 16:14:45","title":"Profiling Bias in LLMs: Stereotype Dimensions in Contextual Word Embeddings","abstract":"Large language models (LLMs) are the foundation of the current successes of artificial intelligence (AI), however, they are unavoidably biased. To effectively communicate the risks and encourage mitigation efforts these models need adequate and intuitive descriptions of their discriminatory properties, appropriate for all audiences of AI. We suggest bias profiles with respect to stereotype dimensions based on dictionaries from social psychology research. Along these dimensions we investigate gender bias in contextual embeddings, across contexts and layers, and generate stereotype profiles for twelve different LLMs, demonstrating their intuition and use case for exposing and visualizing bias.","sentences":["Large language models (LLMs) are the foundation of the current successes of artificial intelligence (AI), however, they are unavoidably biased.","To effectively communicate the risks and encourage mitigation efforts these models need adequate and intuitive descriptions of their discriminatory properties, appropriate for all audiences of AI.","We suggest bias profiles with respect to stereotype dimensions based on dictionaries from social psychology research.","Along these dimensions we investigate gender bias in contextual embeddings, across contexts and layers, and generate stereotype profiles for twelve different LLMs, demonstrating their intuition and use case for exposing and visualizing bias."],"url":"http://arxiv.org/abs/2411.16527v1"}
{"created":"2024-11-25 16:12:17","title":"Fundamental Limits of Prompt Tuning Transformers: Universality, Capacity and Efficiency","abstract":"We investigate the statistical and computational limits of prompt tuning for transformer-based foundation models. Our key contributions are prompt tuning on \\textit{single-head} transformers with only a \\textit{single} self-attention layer: (i) is universal, and (ii) supports efficient (even almost-linear time) algorithms under the Strong Exponential Time Hypothesis (SETH). Statistically, we prove that prompt tuning on such simplest possible transformers are universal approximators for sequence-to-sequence Lipschitz functions. In addition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound on the required soft-prompt tokens for prompt tuning to memorize any dataset with 1-layer, 1-head transformers. Computationally, we identify a phase transition in the efficiency of prompt tuning, determined by the norm of the \\textit{soft-prompt-induced} keys and queries, and provide an upper bound criterion. Beyond this criterion, no sub-quadratic (efficient) algorithm for prompt tuning exists under SETH. Within this criterion, we showcase our theory by proving the existence of almost-linear time prompt tuning inference algorithms. These fundamental limits provide important necessary conditions for designing expressive and efficient prompt tuning methods for practitioners.","sentences":["We investigate the statistical and computational limits of prompt tuning for transformer-based foundation models.","Our key contributions are prompt tuning on \\textit{single-head} transformers with only a \\textit{single} self-attention layer: (i) is universal, and (ii) supports efficient (even almost-linear time) algorithms under the Strong Exponential Time Hypothesis (SETH).","Statistically, we prove that prompt tuning on such simplest possible transformers are universal approximators for sequence-to-sequence Lipschitz functions.","In addition, we provide an exponential-in-$dL$ and -in-$(1/\\epsilon)$ lower bound on the required soft-prompt tokens for prompt tuning to memorize any dataset with 1-layer, 1-head transformers.","Computationally, we identify a phase transition in the efficiency of prompt tuning, determined by the norm of the \\textit{soft-prompt-induced} keys and queries, and provide an upper bound criterion.","Beyond this criterion, no sub-quadratic (efficient) algorithm for prompt tuning exists under SETH.","Within this criterion, we showcase our theory by proving the existence of almost-linear time prompt tuning inference algorithms.","These fundamental limits provide important necessary conditions for designing expressive and efficient prompt tuning methods for practitioners."],"url":"http://arxiv.org/abs/2411.16525v1"}
{"created":"2024-11-25 16:10:05","title":"LaB-RAG: Label Boosted Retrieval Augmented Generation for Radiology Report Generation","abstract":"In the current paradigm of image captioning, deep learning models are trained to generate text from image embeddings of latent features. We challenge the assumption that these latent features ought to be high-dimensional vectors which require model fine tuning to handle. Here we propose Label Boosted Retrieval Augmented Generation (LaB-RAG), a text-based approach to image captioning that leverages image descriptors in the form of categorical labels to boost standard retrieval augmented generation (RAG) with pretrained large language models (LLMs). We study our method in the context of radiology report generation (RRG), where the task is to generate a clinician's report detailing their observations from a set of radiological images, such as X-rays. We argue that simple linear classifiers over extracted image embeddings can effectively transform X-rays into text-space as radiology-specific labels. In combination with standard RAG, we show that these derived text labels can be used with general-domain LLMs to generate radiology reports. Without ever training our generative language model or image feature encoder models, and without ever directly \"showing\" the LLM an X-ray, we demonstrate that LaB-RAG achieves better results across natural language and radiology language metrics compared with other retrieval-based RRG methods, while attaining competitive results compared to other fine-tuned vision-language RRG models. We further present results of our experiments with various components of LaB-RAG to better understand our method. Finally, we critique the use of a popular RRG metric, arguing it is possible to artificially inflate its results without true data-leakage.","sentences":["In the current paradigm of image captioning, deep learning models are trained to generate text from image embeddings of latent features.","We challenge the assumption that these latent features ought to be high-dimensional vectors which require model fine tuning to handle.","Here we propose Label Boosted Retrieval Augmented Generation (LaB-RAG), a text-based approach to image captioning that leverages image descriptors in the form of categorical labels to boost standard retrieval augmented generation (RAG) with pretrained large language models (LLMs).","We study our method in the context of radiology report generation (RRG), where the task is to generate a clinician's report detailing their observations from a set of radiological images, such as X-rays.","We argue that simple linear classifiers over extracted image embeddings can effectively transform X-rays into text-space as radiology-specific labels.","In combination with standard RAG, we show that these derived text labels can be used with general-domain LLMs to generate radiology reports.","Without ever training our generative language model or image feature encoder models, and without ever directly \"showing\" the LLM an X-ray, we demonstrate that LaB-RAG achieves better results across natural language and radiology language metrics compared with other retrieval-based RRG methods, while attaining competitive results compared to other fine-tuned vision-language RRG models.","We further present results of our experiments with various components of LaB-RAG to better understand our method.","Finally, we critique the use of a popular RRG metric, arguing it is possible to artificially inflate its results without true data-leakage."],"url":"http://arxiv.org/abs/2411.16523v1"}
{"created":"2024-11-25 16:01:02","title":"Poster: From Fort to Foe: The Threat of RCE in RPKI","abstract":"In this work, we present a novel severe buffer-overflow vulnerability in the RPKI validator Fort, that allows an attacker to achieve Remote Code Execution (RCE) on the machine running the software. We discuss the unique impact of this RCE on networks that use RPKI, illustrating that RCE vulnerabilities are especially severe in the context of RPKI. The design of RPKI makes RCE easy to exploit on a large scale, allows compromise of RPKI validation integrity, and enables a powerful vector for additional attacks on other critical components of the network, like the border routers.   We analyze the vulnerability exposing to this RCE and identify indications that the discovered vulnerability could constitute an intentional backdoor to compromise systems running the software over a benign coding mistake. We disclosed the vulnerability, which has been assigned a CVE rated 9.8 critical (CVE-2024-45237).","sentences":["In this work, we present a novel severe buffer-overflow vulnerability in the RPKI validator Fort, that allows an attacker to achieve Remote Code Execution (RCE) on the machine running the software.","We discuss the unique impact of this RCE on networks that use RPKI, illustrating that RCE vulnerabilities are especially severe in the context of RPKI.","The design of RPKI makes RCE easy to exploit on a large scale, allows compromise of RPKI validation integrity, and enables a powerful vector for additional attacks on other critical components of the network, like the border routers.   ","We analyze the vulnerability exposing to this RCE and identify indications that the discovered vulnerability could constitute an intentional backdoor to compromise systems running the software over a benign coding mistake.","We disclosed the vulnerability, which has been assigned a CVE rated 9.8 critical (CVE-2024-45237)."],"url":"http://arxiv.org/abs/2411.16518v1"}
{"created":"2024-11-25 16:00:04","title":"Curator Attack: When Blackbox Differential Privacy Auditing Loses Its Power","abstract":"A surge in data-driven applications enhances everyday life but also raises serious concerns about private information leakage. Hence many privacy auditing tools are emerging for checking if the data sanitization performed meets the privacy standard of the data owner. Blackbox auditing for differential privacy is particularly gaining popularity for its effectiveness and applicability to a wide range of scenarios. Yet, we identified that blackbox auditing is essentially flawed with its setting: small probabilities or densities are ignored due to inaccurate observation. Our argument is based on a solid false positive analysis from a hypothesis testing perspective, which is missed out by prior blackbox auditing tools. This oversight greatly reduces the reliability of these tools, as it allows malicious or incapable data curators to pass the auditing with an overstated privacy guarantee, posing significant risks to data owners. We demonstrate the practical existence of such threats in classical differential privacy mechanisms against four representative blackbox auditors with experimental validations. Our findings aim to reveal the limitations of blackbox auditing tools, empower the data owner with the awareness of risks in using these tools, and encourage the development of more reliable differential privacy auditing methods.","sentences":["A surge in data-driven applications enhances everyday life but also raises serious concerns about private information leakage.","Hence many privacy auditing tools are emerging for checking if the data sanitization performed meets the privacy standard of the data owner.","Blackbox auditing for differential privacy is particularly gaining popularity for its effectiveness and applicability to a wide range of scenarios.","Yet, we identified that blackbox auditing is essentially flawed with its setting: small probabilities or densities are ignored due to inaccurate observation.","Our argument is based on a solid false positive analysis from a hypothesis testing perspective, which is missed out by prior blackbox auditing tools.","This oversight greatly reduces the reliability of these tools, as it allows malicious or incapable data curators to pass the auditing with an overstated privacy guarantee, posing significant risks to data owners.","We demonstrate the practical existence of such threats in classical differential privacy mechanisms against four representative blackbox auditors with experimental validations.","Our findings aim to reveal the limitations of blackbox auditing tools, empower the data owner with the awareness of risks in using these tools, and encourage the development of more reliable differential privacy auditing methods."],"url":"http://arxiv.org/abs/2411.16516v1"}
{"created":"2024-11-25 15:55:06","title":"Guarding the Gate: ConceptGuard Battles Concept-Level Backdoors in Concept Bottleneck Models","abstract":"The increasing complexity of AI models, especially in deep learning, has raised concerns about transparency and accountability, particularly in high-stakes applications like medical diagnostics, where opaque models can undermine trust. Explainable Artificial Intelligence (XAI) aims to address these issues by providing clear, interpretable models. Among XAI techniques, Concept Bottleneck Models (CBMs) enhance transparency by using high-level semantic concepts. However, CBMs are vulnerable to concept-level backdoor attacks, which inject hidden triggers into these concepts, leading to undetectable anomalous behavior. To address this critical security gap, we introduce ConceptGuard, a novel defense framework specifically designed to protect CBMs from concept-level backdoor attacks. ConceptGuard employs a multi-stage approach, including concept clustering based on text distance measurements and a voting mechanism among classifiers trained on different concept subgroups, to isolate and mitigate potential triggers. Our contributions are threefold: (i) we present ConceptGuard as the first defense mechanism tailored for concept-level backdoor attacks in CBMs; (ii) we provide theoretical guarantees that ConceptGuard can effectively defend against such attacks within a certain trigger size threshold, ensuring robustness; and (iii) we demonstrate that ConceptGuard maintains the high performance and interpretability of CBMs, crucial for trustworthiness. Through comprehensive experiments and theoretical proofs, we show that ConceptGuard significantly enhances the security and trustworthiness of CBMs, paving the way for their secure deployment in critical applications.","sentences":["The increasing complexity of AI models, especially in deep learning, has raised concerns about transparency and accountability, particularly in high-stakes applications like medical diagnostics, where opaque models can undermine trust.","Explainable Artificial Intelligence (XAI) aims to address these issues by providing clear, interpretable models.","Among XAI techniques, Concept Bottleneck Models (CBMs) enhance transparency by using high-level semantic concepts.","However, CBMs are vulnerable to concept-level backdoor attacks, which inject hidden triggers into these concepts, leading to undetectable anomalous behavior.","To address this critical security gap, we introduce ConceptGuard, a novel defense framework specifically designed to protect CBMs from concept-level backdoor attacks.","ConceptGuard employs a multi-stage approach, including concept clustering based on text distance measurements and a voting mechanism among classifiers trained on different concept subgroups, to isolate and mitigate potential triggers.","Our contributions are threefold: (i) we present ConceptGuard as the first defense mechanism tailored for concept-level backdoor attacks in CBMs; (ii) we provide theoretical guarantees that ConceptGuard can effectively defend against such attacks within a certain trigger size threshold, ensuring robustness; and (iii) we demonstrate that ConceptGuard maintains the high performance and interpretability of CBMs, crucial for trustworthiness.","Through comprehensive experiments and theoretical proofs, we show that ConceptGuard significantly enhances the security and trustworthiness of CBMs, paving the way for their secure deployment in critical applications."],"url":"http://arxiv.org/abs/2411.16512v1"}
{"created":"2024-11-25 15:52:08","title":"Use-Inspired Mobile Robot to Improve Safety of Building Retrofit Workforce in Constrained Spaces","abstract":"The inspection of confined critical infrastructure such as attics or crawlspaces is challenging for human operators due to insufficient task space, limited visibility, and the presence of hazardous materials. This paper introduces a prototype of PARIS (Precision Application Robot for Inaccessible Spaces): a use-inspired teleoperated mobile robot manipulator system that was conceived, developed, and tested for and selected as a Phase I winner of the U.S. Department of Energy's E-ROBOT Prize. To improve the thermal efficiency of buildings, the PARIS platform supports: 1) teleoperated mapping and navigation, enabling the human operator to explore compact spaces; 2) inspection and sensing, facilitating the identification and localization of under-insulated areas; and 3) air-sealing targeted gaps and cracks through which thermal energy is lost. The resulting versatile platform can also be tailored for targeted application of treatments and remediation in constrained spaces.","sentences":["The inspection of confined critical infrastructure such as attics or crawlspaces is challenging for human operators due to insufficient task space, limited visibility, and the presence of hazardous materials.","This paper introduces a prototype of PARIS (Precision Application Robot for Inaccessible Spaces): a use-inspired teleoperated mobile robot manipulator system that was conceived, developed, and tested for and selected as a Phase I winner of the U.S. Department of Energy's E-ROBOT Prize.","To improve the thermal efficiency of buildings, the PARIS platform supports: 1) teleoperated mapping and navigation, enabling the human operator to explore compact spaces; 2) inspection and sensing, facilitating the identification and localization of under-insulated areas; and 3) air-sealing targeted gaps and cracks through which thermal energy is lost.","The resulting versatile platform can also be tailored for targeted application of treatments and remediation in constrained spaces."],"url":"http://arxiv.org/abs/2411.16511v1"}
{"created":"2024-11-25 15:46:54","title":"Jaya R Package -- A Parameter-Free Solution for Advanced Single and Multi-Objective Optimization","abstract":"The Jaya R package offers a robust and versatile implementation of the parameter-free Jaya optimization algorithm, suitable for solving both single-objective and multi-objective optimization problems. By integrating advanced features such as constraint handling, adaptive population management, Pareto front tracking for multi-objective trade-offs, and parallel processing for computational efficiency, the package caters to a wide range of optimization challenges. Its intuitive design and flexibility allow users to solve complex, real-world problems across various domains. To demonstrate its practical utility, a case study on energy modeling explores the optimization of renewable energy shares, showcasing the package's ability to minimize carbon emissions and costs while enhancing system reliability. The Jaya R package is an invaluable tool for researchers and practitioners seeking efficient and adaptive optimization solutions.","sentences":["The Jaya R package offers a robust and versatile implementation of the parameter-free Jaya optimization algorithm, suitable for solving both single-objective and multi-objective optimization problems.","By integrating advanced features such as constraint handling, adaptive population management, Pareto front tracking for multi-objective trade-offs, and parallel processing for computational efficiency, the package caters to a wide range of optimization challenges.","Its intuitive design and flexibility allow users to solve complex, real-world problems across various domains.","To demonstrate its practical utility, a case study on energy modeling explores the optimization of renewable energy shares, showcasing the package's ability to minimize carbon emissions and costs while enhancing system reliability.","The Jaya R package is an invaluable tool for researchers and practitioners seeking efficient and adaptive optimization solutions."],"url":"http://arxiv.org/abs/2411.16509v1"}
{"created":"2024-11-25 15:44:42","title":"All Languages Matter: Evaluating LMMs on Culturally Diverse 100 Languages","abstract":"Existing Large Multimodal Models (LMMs) generally focus on only a few regions and languages. As LMMs continue to improve, it is increasingly important to ensure they understand cultural contexts, respect local sensitivities, and support low-resource languages, all while effectively integrating corresponding visual cues. In pursuit of culturally diverse global multimodal models, our proposed All Languages Matter Benchmark (ALM-bench) represents the largest and most comprehensive effort to date for evaluating LMMs across 100 languages. ALM-bench challenges existing models by testing their ability to understand and reason about culturally diverse images paired with text in various languages, including many low-resource languages traditionally underrepresented in LMM research. The benchmark offers a robust and nuanced evaluation framework featuring various question formats, including true/false, multiple choice, and open-ended questions, which are further divided into short and long-answer categories. ALM-bench design ensures a comprehensive assessment of a model's ability to handle varied levels of difficulty in visual and linguistic reasoning. To capture the rich tapestry of global cultures, ALM-bench carefully curates content from 13 distinct cultural aspects, ranging from traditions and rituals to famous personalities and celebrations. Through this, ALM-bench not only provides a rigorous testing ground for state-of-the-art open and closed-source LMMs but also highlights the importance of cultural and linguistic inclusivity, encouraging the development of models that can serve diverse global populations effectively. Our benchmark is publicly available.","sentences":["Existing Large Multimodal Models (LMMs) generally focus on only a few regions and languages.","As LMMs continue to improve, it is increasingly important to ensure they understand cultural contexts, respect local sensitivities, and support low-resource languages, all while effectively integrating corresponding visual cues.","In pursuit of culturally diverse global multimodal models, our proposed All Languages Matter Benchmark (ALM-bench) represents the largest and most comprehensive effort to date for evaluating LMMs across 100 languages.","ALM-bench challenges existing models by testing their ability to understand and reason about culturally diverse images paired with text in various languages, including many low-resource languages traditionally underrepresented in LMM research.","The benchmark offers a robust and nuanced evaluation framework featuring various question formats, including true/false, multiple choice, and open-ended questions, which are further divided into short and long-answer categories.","ALM-bench design ensures a comprehensive assessment of a model's ability to handle varied levels of difficulty in visual and linguistic reasoning.","To capture the rich tapestry of global cultures, ALM-bench carefully curates content from 13 distinct cultural aspects, ranging from traditions and rituals to famous personalities and celebrations.","Through this, ALM-bench not only provides a rigorous testing ground for state-of-the-art open and closed-source LMMs but also highlights the importance of cultural and linguistic inclusivity, encouraging the development of models that can serve diverse global populations effectively.","Our benchmark is publicly available."],"url":"http://arxiv.org/abs/2411.16508v1"}
{"created":"2024-11-25 15:43:23","title":"Online Guidance Graph Optimization for Lifelong Multi-Agent Path Finding","abstract":"We study the problem of optimizing a guidance policy capable of dynamically guiding the agents for lifelong Multi-Agent Path Finding based on real-time traffic patterns. Multi-Agent Path Finding (MAPF) focuses on moving multiple agents from their starts to goals without collisions. Its lifelong variant, LMAPF, continuously assigns new goals to agents. In this work, we focus on improving the solution quality of PIBT, a state-of-the-art rule-based LMAPF algorithm, by optimizing a policy to generate adaptive guidance. We design two pipelines to incorporate guidance in PIBT in two different ways. We demonstrate the superiority of the optimized policy over both static guidance and human-designed policies. Additionally, we explore scenarios where task distribution changes over time, a challenging yet common situation in real-world applications that is rarely explored in the literature.","sentences":["We study the problem of optimizing a guidance policy capable of dynamically guiding the agents for lifelong Multi-Agent Path Finding based on real-time traffic patterns.","Multi-Agent Path Finding (MAPF) focuses on moving multiple agents from their starts to goals without collisions.","Its lifelong variant, LMAPF, continuously assigns new goals to agents.","In this work, we focus on improving the solution quality of PIBT, a state-of-the-art rule-based LMAPF algorithm, by optimizing a policy to generate adaptive guidance.","We design two pipelines to incorporate guidance in PIBT in two different ways.","We demonstrate the superiority of the optimized policy over both static guidance and human-designed policies.","Additionally, we explore scenarios where task distribution changes over time, a challenging yet common situation in real-world applications that is rarely explored in the literature."],"url":"http://arxiv.org/abs/2411.16506v1"}
{"created":"2024-11-25 15:40:47","title":"Noise Diffusion for Enhancing Semantic Faithfulness in Text-to-Image Synthesis","abstract":"Diffusion models have achieved impressive success in generating photorealistic images, but challenges remain in ensuring precise semantic alignment with input prompts. Optimizing the initial noisy latent offers a more efficient alternative to modifying model architectures or prompt engineering for improving semantic alignment. A latest approach, InitNo, refines the initial noisy latent by leveraging attention maps; however, these maps capture only limited information, and the effectiveness of InitNo is highly dependent on the initial starting point, as it tends to converge on a local optimum near this point. To this end, this paper proposes leveraging the language comprehension capabilities of large vision-language models (LVLMs) to guide the optimization of the initial noisy latent, and introduces the Noise Diffusion process, which updates the noisy latent to generate semantically faithful images while preserving distribution consistency. Furthermore, we provide a theoretical analysis of the condition under which the update improves semantic faithfulness. Experimental results demonstrate the effectiveness and adaptability of our framework, consistently enhancing semantic alignment across various diffusion models. The code is available at https://github.com/Bomingmiao/NoiseDiffusion.","sentences":["Diffusion models have achieved impressive success in generating photorealistic images, but challenges remain in ensuring precise semantic alignment with input prompts.","Optimizing the initial noisy latent offers a more efficient alternative to modifying model architectures or prompt engineering for improving semantic alignment.","A latest approach, InitNo, refines the initial noisy latent by leveraging attention maps; however, these maps capture only limited information, and the effectiveness of InitNo is highly dependent on the initial starting point, as it tends to converge on a local optimum near this point.","To this end, this paper proposes leveraging the language comprehension capabilities of large vision-language models (LVLMs) to guide the optimization of the initial noisy latent, and introduces the Noise Diffusion process, which updates the noisy latent to generate semantically faithful images while preserving distribution consistency.","Furthermore, we provide a theoretical analysis of the condition under which the update improves semantic faithfulness.","Experimental results demonstrate the effectiveness and adaptability of our framework, consistently enhancing semantic alignment across various diffusion models.","The code is available at https://github.com/Bomingmiao/NoiseDiffusion."],"url":"http://arxiv.org/abs/2411.16503v1"}
{"created":"2024-11-25 15:37:27","title":"Interpreting Language Reward Models via Contrastive Explanations","abstract":"Reward models (RMs) are a crucial component in the alignment of large language models' (LLMs) outputs with human values. RMs approximate human preferences over possible LLM responses to the same prompt by predicting and comparing reward scores. However, as they are typically modified versions of LLMs with scalar output heads, RMs are large black boxes whose predictions are not explainable. More transparent RMs would enable improved trust in the alignment of LLMs. In this work, we propose to use contrastive explanations to explain any binary response comparison made by an RM. Specifically, we generate a diverse set of new comparisons similar to the original one to characterise the RM's local behaviour. The perturbed responses forming the new comparisons are generated to explicitly modify manually specified high-level evaluation attributes, on which analyses of RM behaviour are grounded. In quantitative experiments, we validate the effectiveness of our method for finding high-quality contrastive explanations. We then showcase the qualitative usefulness of our method for investigating global sensitivity of RMs to each evaluation attribute, and demonstrate how representative examples can be automatically extracted to explain and compare behaviours of different RMs. We see our method as a flexible framework for RM explanation, providing a basis for more interpretable and trustworthy LLM alignment.","sentences":["Reward models (RMs) are a crucial component in the alignment of large language models' (LLMs) outputs with human values.","RMs approximate human preferences over possible LLM responses to the same prompt by predicting and comparing reward scores.","However, as they are typically modified versions of LLMs with scalar output heads, RMs are large black boxes whose predictions are not explainable.","More transparent RMs would enable improved trust in the alignment of LLMs.","In this work, we propose to use contrastive explanations to explain any binary response comparison made by an RM.","Specifically, we generate a diverse set of new comparisons similar to the original one to characterise the RM's local behaviour.","The perturbed responses forming the new comparisons are generated to explicitly modify manually specified high-level evaluation attributes, on which analyses of RM behaviour are grounded.","In quantitative experiments, we validate the effectiveness of our method for finding high-quality contrastive explanations.","We then showcase the qualitative usefulness of our method for investigating global sensitivity of RMs to each evaluation attribute, and demonstrate how representative examples can be automatically extracted to explain and compare behaviours of different RMs.","We see our method as a flexible framework for RM explanation, providing a basis for more interpretable and trustworthy LLM alignment."],"url":"http://arxiv.org/abs/2411.16502v1"}
{"created":"2024-11-25 15:36:29","title":"Multi-Resolution Generative Modeling of Human Motion from Limited Data","abstract":"We present a generative model that learns to synthesize human motion from limited training sequences. Our framework provides conditional generation and blending across multiple temporal resolutions. The model adeptly captures human motion patterns by integrating skeletal convolution layers and a multi-scale architecture. Our model contains a set of generative and adversarial networks, along with embedding modules, each tailored for generating motions at specific frame rates while exerting control over their content and details. Notably, our approach also extends to the synthesis of co-speech gestures, demonstrating its ability to generate synchronized gestures from speech inputs, even with limited paired data. Through direct synthesis of SMPL pose parameters, our approach avoids test-time adjustments to fit human body meshes. Experimental results showcase our model's ability to achieve extensive coverage of training examples, while generating diverse motions, as indicated by local and global diversity metrics.","sentences":["We present a generative model that learns to synthesize human motion from limited training sequences.","Our framework provides conditional generation and blending across multiple temporal resolutions.","The model adeptly captures human motion patterns by integrating skeletal convolution layers and a multi-scale architecture.","Our model contains a set of generative and adversarial networks, along with embedding modules, each tailored for generating motions at specific frame rates while exerting control over their content and details.","Notably, our approach also extends to the synthesis of co-speech gestures, demonstrating its ability to generate synchronized gestures from speech inputs, even with limited paired data.","Through direct synthesis of SMPL pose parameters, our approach avoids test-time adjustments to fit human body meshes.","Experimental results showcase our model's ability to achieve extensive coverage of training examples, while generating diverse motions, as indicated by local and global diversity metrics."],"url":"http://arxiv.org/abs/2411.16498v1"}
{"created":"2024-11-25 15:35:51","title":"AtomR: Atomic Operator-Empowered Large Language Models for Heterogeneous Knowledge Reasoning","abstract":"Recent advancements in large language models (LLMs) have led to significant improvements in various natural language processing tasks, but it is still challenging for LLMs to perform knowledge-intensive complex question answering due to LLMs' inefficacy in reasoning planning and the hallucination problem. A typical solution is to employ retrieval-augmented generation (RAG) coupled with chain-of-thought (CoT) reasoning, which decomposes complex questions into chain-like sub-questions and applies iterative RAG at each sub-question. However, prior works exhibit sub-optimal reasoning planning and overlook dynamic knowledge retrieval from heterogeneous sources. In this paper, we propose AtomR, a novel heterogeneous knowledge reasoning framework that conducts multi-source reasoning at the atomic level. Drawing inspiration from the graph modeling of knowledge, AtomR leverages large language models (LLMs) to decompose complex questions into combinations of three atomic knowledge operators, significantly enhancing the reasoning process at both the planning and execution stages. We also introduce BlendQA, a novel evaluation benchmark tailored to assess complex heterogeneous knowledge reasoning. Experiments show that AtomR significantly outperforms state-of-the-art baselines across three single-source and two multi-source reasoning benchmarks, with notable performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA.","sentences":["Recent advancements in large language models (LLMs) have led to significant improvements in various natural language processing tasks, but it is still challenging for LLMs to perform knowledge-intensive complex question answering due to LLMs' inefficacy in reasoning planning and the hallucination problem.","A typical solution is to employ retrieval-augmented generation (RAG) coupled with chain-of-thought (CoT) reasoning, which decomposes complex questions into chain-like sub-questions and applies iterative RAG at each sub-question.","However, prior works exhibit sub-optimal reasoning planning and overlook dynamic knowledge retrieval from heterogeneous sources.","In this paper, we propose AtomR, a novel heterogeneous knowledge reasoning framework that conducts multi-source reasoning at the atomic level.","Drawing inspiration from the graph modeling of knowledge, AtomR leverages large language models (LLMs) to decompose complex questions into combinations of three atomic knowledge operators, significantly enhancing the reasoning process at both the planning and execution stages.","We also introduce BlendQA, a novel evaluation benchmark tailored to assess complex heterogeneous knowledge reasoning.","Experiments show that AtomR significantly outperforms state-of-the-art baselines across three single-source and two multi-source reasoning benchmarks, with notable performance gains of 9.4% on 2WikiMultihop and 9.5% on BlendQA."],"url":"http://arxiv.org/abs/2411.16495v1"}
{"created":"2024-11-25 15:31:27","title":"O1 Replication Journey -- Part 2: Surpassing O1-preview through Simple Distillation, Big Progress or Bitter Lesson?","abstract":"This paper presents a critical examination of current approaches to replicating OpenAI's O1 model capabilities, with particular focus on the widespread but often undisclosed use of knowledge distillation techniques. While our previous work explored the fundamental technical path to O1 replication, this study reveals how simple distillation from O1's API, combined with supervised fine-tuning, can achieve superior performance on complex mathematical reasoning tasks. Through extensive experiments, we show that a base model fine-tuned on simply tens of thousands of samples O1-distilled long-thought chains outperforms O1-preview on the American Invitational Mathematics Examination (AIME) with minimal technical complexity. Moreover, our investigation extends beyond mathematical reasoning to explore the generalization capabilities of O1-distilled models across diverse tasks: hallucination, safety and open-domain QA. Notably, despite training only on mathematical problem-solving data, our models demonstrated strong generalization to open-ended QA tasks and became significantly less susceptible to sycophancy after fine-tuning. We deliberately make this finding public to promote transparency in AI research and to challenge the current trend of obscured technical claims in the field. Our work includes: (1) A detailed technical exposition of the distillation process and its effectiveness, (2) A comprehensive benchmark framework for evaluating and categorizing O1 replication attempts based on their technical transparency and reproducibility, (3) A critical discussion of the limitations and potential risks of over-relying on distillation approaches, our analysis culminates in a crucial bitter lesson: while the pursuit of more capable AI systems is important, the development of researchers grounded in first-principles thinking is paramount.","sentences":["This paper presents a critical examination of current approaches to replicating OpenAI's O1 model capabilities, with particular focus on the widespread but often undisclosed use of knowledge distillation techniques.","While our previous work explored the fundamental technical path to O1 replication, this study reveals how simple distillation from O1's API, combined with supervised fine-tuning, can achieve superior performance on complex mathematical reasoning tasks.","Through extensive experiments, we show that a base model fine-tuned on simply tens of thousands of samples O1-distilled long-thought chains outperforms O1-preview on the American Invitational Mathematics Examination (AIME) with minimal technical complexity.","Moreover, our investigation extends beyond mathematical reasoning to explore the generalization capabilities of O1-distilled models across diverse tasks: hallucination, safety and open-domain QA.","Notably, despite training only on mathematical problem-solving data, our models demonstrated strong generalization to open-ended QA tasks and became significantly less susceptible to sycophancy after fine-tuning.","We deliberately make this finding public to promote transparency in AI research and to challenge the current trend of obscured technical claims in the field.","Our work includes: (1) A detailed technical exposition of the distillation process and its effectiveness, (2) A comprehensive benchmark framework for evaluating and categorizing O1 replication attempts based on their technical transparency and reproducibility, (3) A critical discussion of the limitations and potential risks of over-relying on distillation approaches, our analysis culminates in a crucial bitter lesson: while the pursuit of more capable AI systems is important, the development of researchers grounded in first-principles thinking is paramount."],"url":"http://arxiv.org/abs/2411.16489v1"}
{"created":"2024-11-25 15:25:31","title":"When Babies Teach Babies: Can student knowledge sharing outperform Teacher-Guided Distillation on small datasets?","abstract":"We present our submission to the BabyLM challenge, aiming to push the boundaries of data-efficient language model pretraining. Our method builds upon deep mutual learning, introducing a student model search for diverse initialization. We address the limitation of treating students equally by formulating weighted mutual learning as a bi-level optimization problem. The inner loop learns compact students through online distillation, while the outer loop optimizes weights for better knowledge distillation from diverse students. This dynamic weighting strategy eliminates the need for a teacher model, reducing computational requirements. Our evaluations show that teacher-less methods can match or surpass teacher-supervised approaches.","sentences":["We present our submission to the BabyLM challenge, aiming to push the boundaries of data-efficient language model pretraining.","Our method builds upon deep mutual learning, introducing a student model search for diverse initialization.","We address the limitation of treating students equally by formulating weighted mutual learning as a bi-level optimization problem.","The inner loop learns compact students through online distillation, while the outer loop optimizes weights for better knowledge distillation from diverse students.","This dynamic weighting strategy eliminates the need for a teacher model, reducing computational requirements.","Our evaluations show that teacher-less methods can match or surpass teacher-supervised approaches."],"url":"http://arxiv.org/abs/2411.16487v1"}
