{"created":"2024-10-31 17:59:59","title":"Tensegrity Robot Proprioceptive State Estimation with Geometric Constraints","abstract":"Tensegrity robots, characterized by a synergistic assembly of rigid rods and elastic cables, form robust structures that are resistant to impacts. However, this design introduces complexities in kinematics and dynamics, complicating control and state estimation. This work presents a novel proprioceptive state estimator for tensegrity robots. The estimator initially uses the geometric constraints of 3-bar prism tensegrity structures, combined with IMU and motor encoder measurements, to reconstruct the robot's shape and orientation. It then employs a contact-aided invariant extended Kalman filter with forward kinematics to estimate the global position and orientation of the tensegrity robot. The state estimator's accuracy is assessed against ground truth data in both simulated environments and real-world tensegrity robot applications. It achieves an average drift percentage of 4.2%, comparable to the state estimation performance of traditional rigid robots. This state estimator advances the state of the art in tensegrity robot state estimation and has the potential to run in real-time using onboard sensors, paving the way for full autonomy of tensegrity robots in unstructured environments.","sentences":["Tensegrity robots, characterized by a synergistic assembly of rigid rods and elastic cables, form robust structures that are resistant to impacts.","However, this design introduces complexities in kinematics and dynamics, complicating control and state estimation.","This work presents a novel proprioceptive state estimator for tensegrity robots.","The estimator initially uses the geometric constraints of 3-bar prism tensegrity structures, combined with IMU and motor encoder measurements, to reconstruct the robot's shape and orientation.","It then employs a contact-aided invariant extended Kalman filter with forward kinematics to estimate the global position and orientation of the tensegrity robot.","The state estimator's accuracy is assessed against ground truth data in both simulated environments and real-world tensegrity robot applications.","It achieves an average drift percentage of 4.2%, comparable to the state estimation performance of traditional rigid robots.","This state estimator advances the state of the art in tensegrity robot state estimation and has the potential to run in real-time using onboard sensors, paving the way for full autonomy of tensegrity robots in unstructured environments."],"url":"http://arxiv.org/abs/2410.24226v1"}
{"created":"2024-10-31 17:59:56","title":"Robust Gaussian Processes via Relevance Pursuit","abstract":"Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates. However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions. Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees. In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit. We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods. This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm. We compare the model's performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range.","sentences":["Gaussian processes (GPs) are non-parametric probabilistic regression models that are popular due to their flexibility, data efficiency, and well-calibrated uncertainty estimates.","However, standard GP models assume homoskedastic Gaussian noise, while many real-world applications are subject to non-Gaussian corruptions.","Variants of GPs that are more robust to alternative noise models have been proposed, and entail significant trade-offs between accuracy and robustness, and between computational requirements and theoretical guarantees.","In this work, we propose and study a GP model that achieves robustness against sparse outliers by inferring data-point-specific noise levels with a sequential selection procedure maximizing the log marginal likelihood that we refer to as relevance pursuit.","We show, surprisingly, that the model can be parameterized such that the associated log marginal likelihood is strongly concave in the data-point-specific noise variances, a property rarely found in either robust regression objectives or GP marginal likelihoods.","This in turn implies the weak submodularity of the corresponding subset selection problem, and thereby proves approximation guarantees for the proposed algorithm.","We compare the model's performance relative to other approaches on diverse regression and Bayesian optimization tasks, including the challenging but common setting of sparse corruptions of the labels within or close to the function range."],"url":"http://arxiv.org/abs/2410.24222v1"}
{"created":"2024-10-31 17:59:56","title":"URAvatar: Universal Relightable Gaussian Codec Avatars","abstract":"We present a new approach to creating photorealistic and relightable head avatars from a phone scan with unknown illumination. The reconstructed avatars can be animated and relit in real time with the global illumination of diverse environments. Unlike existing approaches that estimate parametric reflectance parameters via inverse rendering, our approach directly models learnable radiance transfer that incorporates global light transport in an efficient manner for real-time rendering. However, learning such a complex light transport that can generalize across identities is non-trivial. A phone scan in a single environment lacks sufficient information to infer how the head would appear in general environments. To address this, we build a universal relightable avatar model represented by 3D Gaussians. We train on hundreds of high-quality multi-view human scans with controllable point lights. High-resolution geometric guidance further enhances the reconstruction accuracy and generalization. Once trained, we finetune the pretrained model on a phone scan using inverse rendering to obtain a personalized relightable avatar. Our experiments establish the efficacy of our design, outperforming existing approaches while retaining real-time rendering capability.","sentences":["We present a new approach to creating photorealistic and relightable head avatars from a phone scan with unknown illumination.","The reconstructed avatars can be animated and relit in real time with the global illumination of diverse environments.","Unlike existing approaches that estimate parametric reflectance parameters via inverse rendering, our approach directly models learnable radiance transfer that incorporates global light transport in an efficient manner for real-time rendering.","However, learning such a complex light transport that can generalize across identities is non-trivial.","A phone scan in a single environment lacks sufficient information to infer how the head would appear in general environments.","To address this, we build a universal relightable avatar model represented by 3D Gaussians.","We train on hundreds of high-quality multi-view human scans with controllable point lights.","High-resolution geometric guidance further enhances the reconstruction accuracy and generalization.","Once trained, we finetune the pretrained model on a phone scan using inverse rendering to obtain a personalized relightable avatar.","Our experiments establish the efficacy of our design, outperforming existing approaches while retaining real-time rendering capability."],"url":"http://arxiv.org/abs/2410.24223v1"}
{"created":"2024-10-31 17:59:55","title":"EgoMimic: Scaling Imitation Learning via Egocentric Video","abstract":"The scale and diversity of demonstration data required for imitation learning is a significant challenge. We present EgoMimic, a full-stack framework which scales manipulation via human embodiment data, specifically egocentric human videos paired with 3D hand tracking. EgoMimic achieves this through: (1) a system to capture human embodiment data using the ergonomic Project Aria glasses, (2) a low-cost bimanual manipulator that minimizes the kinematic gap to human data, (3) cross-domain data alignment techniques, and (4) an imitation learning architecture that co-trains on human and robot data. Compared to prior works that only extract high-level intent from human videos, our approach treats human and robot data equally as embodied demonstration data and learns a unified policy from both data sources. EgoMimic achieves significant improvement on a diverse set of long-horizon, single-arm and bimanual manipulation tasks over state-of-the-art imitation learning methods and enables generalization to entirely new scenes. Finally, we show a favorable scaling trend for EgoMimic, where adding 1 hour of additional hand data is significantly more valuable than 1 hour of additional robot data. Videos and additional information can be found at https://egomimic.github.io/","sentences":["The scale and diversity of demonstration data required for imitation learning is a significant challenge.","We present EgoMimic, a full-stack framework which scales manipulation via human embodiment data, specifically egocentric human videos paired with 3D hand tracking.","EgoMimic achieves this through: (1) a system to capture human embodiment data using the ergonomic Project Aria glasses, (2) a low-cost bimanual manipulator that minimizes the kinematic gap to human data, (3) cross-domain data alignment techniques, and (4) an imitation learning architecture that co-trains on human and robot data.","Compared to prior works that only extract high-level intent from human videos, our approach treats human and robot data equally as embodied demonstration data and learns a unified policy from both data sources.","EgoMimic achieves significant improvement on a diverse set of long-horizon, single-arm and bimanual manipulation tasks over state-of-the-art imitation learning methods and enables generalization to entirely new scenes.","Finally, we show a favorable scaling trend for EgoMimic, where adding 1 hour of additional hand data is significantly more valuable than 1 hour of additional robot data.","Videos and additional information can be found at https://egomimic.github.io/"],"url":"http://arxiv.org/abs/2410.24221v1"}
{"created":"2024-10-31 17:59:53","title":"Enhancing Motion in Text-to-Video Generation with Decomposed Encoding and Conditioning","abstract":"Despite advancements in Text-to-Video (T2V) generation, producing videos with realistic motion remains challenging. Current models often yield static or minimally dynamic outputs, failing to capture complex motions described by text. This issue stems from the internal biases in text encoding, which overlooks motions, and inadequate conditioning mechanisms in T2V generation models. To address this, we propose a novel framework called DEcomposed MOtion (DEMO), which enhances motion synthesis in T2V generation by decomposing both text encoding and conditioning into content and motion components. Our method includes a content encoder for static elements and a motion encoder for temporal dynamics, alongside separate content and motion conditioning mechanisms. Crucially, we introduce text-motion and video-motion supervision to improve the model's understanding and generation of motion. Evaluations on benchmarks such as MSR-VTT, UCF-101, WebVid-10M, EvalCrafter, and VBench demonstrate DEMO's superior ability to produce videos with enhanced motion dynamics while maintaining high visual quality. Our approach significantly advances T2V generation by integrating comprehensive motion understanding directly from textual descriptions. Project page: https://PR-Ryan.github.io/DEMO-project/","sentences":["Despite advancements in Text-to-Video (T2V) generation, producing videos with realistic motion remains challenging.","Current models often yield static or minimally dynamic outputs, failing to capture complex motions described by text.","This issue stems from the internal biases in text encoding, which overlooks motions, and inadequate conditioning mechanisms in T2V generation models.","To address this, we propose a novel framework called DEcomposed MOtion (DEMO), which enhances motion synthesis in T2V generation by decomposing both text encoding and conditioning into content and motion components.","Our method includes a content encoder for static elements and a motion encoder for temporal dynamics, alongside separate content and motion conditioning mechanisms.","Crucially, we introduce text-motion and video-motion supervision to improve the model's understanding and generation of motion.","Evaluations on benchmarks such as MSR-VTT, UCF-101, WebVid-10M, EvalCrafter, and VBench demonstrate DEMO's superior ability to produce videos with enhanced motion dynamics while maintaining high visual quality.","Our approach significantly advances T2V generation by integrating comprehensive motion understanding directly from textual descriptions.","Project page: https://PR-Ryan.github.io/DEMO-project/"],"url":"http://arxiv.org/abs/2410.24219v1"}
{"created":"2024-10-31 17:59:53","title":"Bridging Geometric States via Geometric Diffusion Bridge","abstract":"The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling. Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality. In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states. GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob's $h$-transform for connecting geometric states. This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels. Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics. Theoretically, we conduct a thorough examination to confirm our framework's ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability.","sentences":["The accurate prediction of geometric state evolution in complex systems is critical for advancing scientific domains such as quantum chemistry and material modeling.","Traditional experimental and computational methods face challenges in terms of environmental constraints and computational demands, while current deep learning approaches still fall short in terms of precision and generality.","In this work, we introduce the Geometric Diffusion Bridge (GDB), a novel generative modeling framework that accurately bridges initial and target geometric states.","GDB leverages a probabilistic approach to evolve geometric state distributions, employing an equivariant diffusion bridge derived by a modified version of Doob's $h$-transform for connecting geometric states.","This tailored diffusion process is anchored by initial and target geometric states as fixed endpoints and governed by equivariant transition kernels.","Moreover, trajectory data can be seamlessly leveraged in our GDB framework by using a chain of equivariant diffusion bridges, providing a more detailed and accurate characterization of evolution dynamics.","Theoretically, we conduct a thorough examination to confirm our framework's ability to preserve joint distributions of geometric states and capability to completely model the underlying dynamics inducing trajectory distributions with negligible error.","Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches, opening up a new pathway for accurately bridging geometric states and tackling crucial scientific challenges with improved accuracy and applicability."],"url":"http://arxiv.org/abs/2410.24220v1"}
{"created":"2024-10-31 17:59:52","title":"Teaching Embodied Reinforcement Learning Agents: Informativeness and Diversity of Language Use","abstract":"In real-world scenarios, it is desirable for embodied agents to have the ability to leverage human language to gain explicit or implicit knowledge for learning tasks. Despite recent progress, most previous approaches adopt simple low-level instructions as language inputs, which may not reflect natural human communication. It's not clear how to incorporate rich language use to facilitate task learning. To address this question, this paper studies different types of language inputs in facilitating reinforcement learning (RL) embodied agents. More specifically, we examine how different levels of language informativeness (i.e., feedback on past behaviors and future guidance) and diversity (i.e., variation of language expressions) impact agent learning and inference. Our empirical results based on four RL benchmarks demonstrate that agents trained with diverse and informative language feedback can achieve enhanced generalization and fast adaptation to new tasks. These findings highlight the pivotal role of language use in teaching embodied agents new tasks in an open world. Project website: https://github.com/sled-group/Teachable_RL","sentences":["In real-world scenarios, it is desirable for embodied agents to have the ability to leverage human language to gain explicit or implicit knowledge for learning tasks.","Despite recent progress, most previous approaches adopt simple low-level instructions as language inputs, which may not reflect natural human communication.","It's not clear how to incorporate rich language use to facilitate task learning.","To address this question, this paper studies different types of language inputs in facilitating reinforcement learning (RL) embodied agents.","More specifically, we examine how different levels of language informativeness (i.e., feedback on past behaviors and future guidance) and diversity (i.e., variation of language expressions) impact agent learning and inference.","Our empirical results based on four RL benchmarks demonstrate that agents trained with diverse and informative language feedback can achieve enhanced generalization and fast adaptation to new tasks.","These findings highlight the pivotal role of language use in teaching embodied agents new tasks in an open world.","Project website: https://github.com/sled-group/Teachable_RL"],"url":"http://arxiv.org/abs/2410.24218v1"}
{"created":"2024-10-31 17:59:46","title":"CaAdam: Improving Adam optimizer using connection aware methods","abstract":"We introduce a new method inspired by Adam that enhances convergence speed and achieves better loss function minima. Traditional optimizers, including Adam, apply uniform or globally adjusted learning rates across neural networks without considering their architectural specifics. This architecture-agnostic approach is deeply embedded in most deep learning frameworks, where optimizers are implemented as standalone modules without direct access to the network's structural information. For instance, in popular frameworks like Keras or PyTorch, optimizers operate solely on gradients and parameters, without knowledge of layer connectivity or network topology. Our algorithm, CaAdam, explores this overlooked area by introducing connection-aware optimization through carefully designed proxies of architectural information. We propose multiple scaling methodologies that dynamically adjust learning rates based on easily accessible structural properties such as layer depth, connection counts, and gradient distributions. This approach enables more granular optimization while working within the constraints of current deep learning frameworks. Empirical evaluations on standard datasets (e.g., CIFAR-10, Fashion MNIST) show that our method consistently achieves faster convergence and higher accuracy compared to standard Adam optimizer, demonstrating the potential benefits of incorporating architectural awareness in optimization strategies.","sentences":["We introduce a new method inspired by Adam that enhances convergence speed and achieves better loss function minima.","Traditional optimizers, including Adam, apply uniform or globally adjusted learning rates across neural networks without considering their architectural specifics.","This architecture-agnostic approach is deeply embedded in most deep learning frameworks, where optimizers are implemented as standalone modules without direct access to the network's structural information.","For instance, in popular frameworks like Keras or PyTorch, optimizers operate solely on gradients and parameters, without knowledge of layer connectivity or network topology.","Our algorithm, CaAdam, explores this overlooked area by introducing connection-aware optimization through carefully designed proxies of architectural information.","We propose multiple scaling methodologies that dynamically adjust learning rates based on easily accessible structural properties such as layer depth, connection counts, and gradient distributions.","This approach enables more granular optimization while working within the constraints of current deep learning frameworks.","Empirical evaluations on standard datasets (e.g., CIFAR-10, Fashion MNIST) show that our method consistently achieves faster convergence and higher accuracy compared to standard Adam optimizer, demonstrating the potential benefits of incorporating architectural awareness in optimization strategies."],"url":"http://arxiv.org/abs/2410.24216v1"}
{"created":"2024-10-31 17:59:37","title":"ARQ: A Mixed-Precision Quantization Framework for Accurate and Certifiably Robust DNNs","abstract":"Mixed precision quantization has become an important technique for enabling the execution of deep neural networks (DNNs) on limited resource computing platforms. Traditional quantization methods have primarily concentrated on maintaining neural network accuracy, either ignoring the impact of quantization on the robustness of the network, or using only empirical techniques for improving robustness. In contrast, techniques for robustness certification, which can provide strong guarantees about the robustness of DNNs have not been used during quantization due to their high computation cost.   This paper introduces ARQ, an innovative mixed-precision quantization method that not only preserves the clean accuracy of the smoothed classifiers but also maintains their certified robustness. ARQ uses reinforcement learning to find accurate and robust DNN quantization, while efficiently leveraging randomized smoothing, a popular class of statistical DNN verification algorithms, to guide the search process.   We compare ARQ with multiple state-of-the-art quantization techniques on several DNN architectures commonly used in quantization studies: ResNet-20 on CIFAR-10, ResNet-50 on ImageNet, and MobileNetV2 on ImageNet. We demonstrate that ARQ consistently performs better than these baselines across all the benchmarks and the input perturbation levels. In many cases, the performance of ARQ quantized networks can reach that of the original DNN with floating-point weights, but with only 1.5% instructions.","sentences":["Mixed precision quantization has become an important technique for enabling the execution of deep neural networks (DNNs) on limited resource computing platforms.","Traditional quantization methods have primarily concentrated on maintaining neural network accuracy, either ignoring the impact of quantization on the robustness of the network, or using only empirical techniques for improving robustness.","In contrast, techniques for robustness certification, which can provide strong guarantees about the robustness of DNNs have not been used during quantization due to their high computation cost.   ","This paper introduces ARQ, an innovative mixed-precision quantization method that not only preserves the clean accuracy of the smoothed classifiers but also maintains their certified robustness.","ARQ uses reinforcement learning to find accurate and robust DNN quantization, while efficiently leveraging randomized smoothing, a popular class of statistical DNN verification algorithms, to guide the search process.   ","We compare ARQ with multiple state-of-the-art quantization techniques on several DNN architectures commonly used in quantization studies: ResNet-20 on CIFAR-10, ResNet-50 on ImageNet, and MobileNetV2 on ImageNet.","We demonstrate that ARQ consistently performs better than these baselines across all the benchmarks and the input perturbation levels.","In many cases, the performance of ARQ quantized networks can reach that of the original DNN with floating-point weights, but with only 1.5% instructions."],"url":"http://arxiv.org/abs/2410.24214v1"}
{"created":"2024-10-31 17:59:30","title":"Learning Video Representations without Natural Videos","abstract":"In this paper, we show that useful video representations can be learned from synthetic videos and natural images, without incorporating natural videos in the training. We propose a progression of video datasets synthesized by simple generative processes, that model a growing set of natural video properties (e.g. motion, acceleration, and shape transformations). The downstream performance of video models pre-trained on these generated datasets gradually increases with the dataset progression. A VideoMAE model pre-trained on our synthetic videos closes 97.2% of the performance gap on UCF101 action classification between training from scratch and self-supervised pre-training from natural videos, and outperforms the pre-trained model on HMDB51. Introducing crops of static images to the pre-training stage results in similar performance to UCF101 pre-training and outperforms the UCF101 pre-trained model on 11 out of 14 out-of-distribution datasets of UCF101-P. Analyzing the low-level properties of the datasets, we identify correlations between frame diversity, frame similarity to natural data, and downstream performance. Our approach provides a more controllable and transparent alternative to video data curation processes for pre-training.","sentences":["In this paper, we show that useful video representations can be learned from synthetic videos and natural images, without incorporating natural videos in the training.","We propose a progression of video datasets synthesized by simple generative processes, that model a growing set of natural video properties (e.g. motion, acceleration, and shape transformations).","The downstream performance of video models pre-trained on these generated datasets gradually increases with the dataset progression.","A VideoMAE model pre-trained on our synthetic videos closes 97.2% of the performance gap on UCF101 action classification between training from scratch and self-supervised pre-training from natural videos, and outperforms the pre-trained model on HMDB51.","Introducing crops of static images to the pre-training stage results in similar performance to UCF101 pre-training and outperforms the UCF101 pre-trained model on 11 out of 14 out-of-distribution datasets of UCF101-P. Analyzing the low-level properties of the datasets, we identify correlations between frame diversity, frame similarity to natural data, and downstream performance.","Our approach provides a more controllable and transparent alternative to video data curation processes for pre-training."],"url":"http://arxiv.org/abs/2410.24213v1"}
{"created":"2024-10-31 17:59:01","title":"DELTA: Dense Efficient Long-range 3D Tracking for any video","abstract":"Tracking dense 3D motion from monocular videos remains challenging, particularly when aiming for pixel-level precision over long sequences. We introduce \\Approach, a novel method that efficiently tracks every pixel in 3D space, enabling accurate motion estimation across entire videos. Our approach leverages a joint global-local attention mechanism for reduced-resolution tracking, followed by a transformer-based upsampler to achieve high-resolution predictions. Unlike existing methods, which are limited by computational inefficiency or sparse tracking, \\Approach delivers dense 3D tracking at scale, running over 8x faster than previous methods while achieving state-of-the-art accuracy. Furthermore, we explore the impact of depth representation on tracking performance and identify log-depth as the optimal choice. Extensive experiments demonstrate the superiority of \\Approach on multiple benchmarks, achieving new state-of-the-art results in both 2D and 3D dense tracking tasks. Our method provides a robust solution for applications requiring fine-grained, long-term motion tracking in 3D space.","sentences":["Tracking dense 3D motion from monocular videos remains challenging, particularly when aiming for pixel-level precision over long sequences.","We introduce \\Approach, a novel method that efficiently tracks every pixel in 3D space, enabling accurate motion estimation across entire videos.","Our approach leverages a joint global-local attention mechanism for reduced-resolution tracking, followed by a transformer-based upsampler to achieve high-resolution predictions.","Unlike existing methods, which are limited by computational inefficiency or sparse tracking, \\Approach delivers dense 3D tracking at scale, running over 8x faster than previous methods while achieving state-of-the-art accuracy.","Furthermore, we explore the impact of depth representation on tracking performance and identify log-depth as the optimal choice.","Extensive experiments demonstrate the superiority of \\Approach on multiple benchmarks, achieving new state-of-the-art results in both 2D and 3D dense tracking tasks.","Our method provides a robust solution for applications requiring fine-grained, long-term motion tracking in 3D space."],"url":"http://arxiv.org/abs/2410.24211v1"}
{"created":"2024-10-31 17:58:41","title":"TabM: Advancing Tabular Deep Learning with Parameter-Efficient Ensembling","abstract":"Deep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods. This study highlights a major, yet so far overlooked opportunity for substantially improving tabular MLPs: namely, parameter-efficient ensembling -- a paradigm for implementing an ensemble of models as one model producing multiple predictions. We start by developing TabM -- a simple model based on MLP and our variations of BatchEnsemble (an existing technique). Then, we perform a large-scale evaluation of tabular DL architectures on public benchmarks in terms of both task performance and efficiency, which renders the landscape of tabular DL in a new light. Generally, we show that MLPs, including TabM, form a line of stronger and more practical models compared to attention- and retrieval-based architectures. In particular, we find that TabM demonstrates the best performance among tabular DL models. Lastly, we conduct an empirical analysis on the ensemble-like nature of TabM. For example, we observe that the multiple predictions of TabM are weak individually, but powerful collectively. Overall, our work brings an impactful technique to tabular DL, analyses its behaviour, and advances the performance-efficiency trade-off with TabM -- a simple and powerful baseline for researchers and practitioners.","sentences":["Deep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods.","This study highlights a major, yet so far overlooked opportunity for substantially improving tabular MLPs: namely, parameter-efficient ensembling -- a paradigm for implementing an ensemble of models as one model producing multiple predictions.","We start by developing TabM -- a simple model based on MLP and our variations of BatchEnsemble (an existing technique).","Then, we perform a large-scale evaluation of tabular DL architectures on public benchmarks in terms of both task performance and efficiency, which renders the landscape of tabular DL in a new light.","Generally, we show that MLPs, including TabM, form a line of stronger and more practical models compared to attention- and retrieval-based architectures.","In particular, we find that TabM demonstrates the best performance among tabular DL models.","Lastly, we conduct an empirical analysis on the ensemble-like nature of TabM.","For example, we observe that the multiple predictions of TabM are weak individually, but powerful collectively.","Overall, our work brings an impactful technique to tabular DL, analyses its behaviour, and advances the performance-efficiency trade-off with TabM -- a simple and powerful baseline for researchers and practitioners."],"url":"http://arxiv.org/abs/2410.24210v1"}
{"created":"2024-10-31 17:58:22","title":"No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images","abstract":"We introduce NoPoSplat, a feed-forward model capable of reconstructing 3D scenes parameterized by 3D Gaussians from \\textit{unposed} sparse multi-view images. Our model, trained exclusively with photometric loss, achieves real-time 3D Gaussian reconstruction during inference. To eliminate the need for accurate pose input during reconstruction, we anchor one input view's local camera coordinates as the canonical space and train the network to predict Gaussian primitives for all views within this space. This approach obviates the need to transform Gaussian primitives from local coordinates into a global coordinate system, thus avoiding errors associated with per-frame Gaussians and pose estimation. To resolve scale ambiguity, we design and compare various intrinsic embedding methods, ultimately opting to convert camera intrinsics into a token embedding and concatenate it with image tokens as input to the model, enabling accurate scene scale prediction. We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation. Experimental results demonstrate that our pose-free approach can achieve superior novel view synthesis quality compared to pose-required methods, particularly in scenarios with limited input image overlap. For pose estimation, our method, trained without ground truth depth or explicit matching loss, significantly outperforms the state-of-the-art methods with substantial improvements. This work makes significant advances in pose-free generalizable 3D reconstruction and demonstrates its applicability to real-world scenarios. Code and trained models are available at https://noposplat.github.io/.","sentences":["We introduce NoPoSplat, a feed-forward model capable of reconstructing 3D scenes parameterized by 3D Gaussians from \\textit{unposed} sparse multi-view images.","Our model, trained exclusively with photometric loss, achieves real-time 3D Gaussian reconstruction during inference.","To eliminate the need for accurate pose input during reconstruction, we anchor one input view's local camera coordinates as the canonical space and train the network to predict Gaussian primitives for all views within this space.","This approach obviates the need to transform Gaussian primitives from local coordinates into a global coordinate system, thus avoiding errors associated with per-frame Gaussians and pose estimation.","To resolve scale ambiguity, we design and compare various intrinsic embedding methods, ultimately opting to convert camera intrinsics into a token embedding and concatenate it with image tokens as input to the model, enabling accurate scene scale prediction.","We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation.","Experimental results demonstrate that our pose-free approach can achieve superior novel view synthesis quality compared to pose-required methods, particularly in scenarios with limited input image overlap.","For pose estimation, our method, trained without ground truth depth or explicit matching loss, significantly outperforms the state-of-the-art methods with substantial improvements.","This work makes significant advances in pose-free generalizable 3D reconstruction and demonstrates its applicability to real-world scenarios.","Code and trained models are available at https://noposplat.github.io/."],"url":"http://arxiv.org/abs/2410.24207v1"}
{"created":"2024-10-31 17:58:13","title":"Understanding Optimization in Deep Learning with Central Flows","abstract":"Optimization in deep learning remains poorly understood, even in the simple setting of deterministic (i.e. full-batch) training. A key difficulty is that much of an optimizer's behavior is implicitly determined by complex oscillatory dynamics, referred to as the \"edge of stability.\" The main contribution of this paper is to show that an optimizer's implicit behavior can be explicitly captured by a \"central flow:\" a differential equation which models the time-averaged optimization trajectory. We show that these flows can empirically predict long-term optimization trajectories of generic neural networks with a high degree of numerical accuracy. By interpreting these flows, we reveal for the first time 1) the precise sense in which RMSProp adapts to the local loss landscape, and 2) an \"acceleration via regularization\" mechanism, wherein adaptive optimizers implicitly navigate towards low-curvature regions in which they can take larger steps. This mechanism is key to the efficacy of these adaptive optimizers. Overall, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning.","sentences":["Optimization in deep learning remains poorly understood, even in the simple setting of deterministic (i.e. full-batch) training.","A key difficulty is that much of an optimizer's behavior is implicitly determined by complex oscillatory dynamics, referred to as the \"edge of stability.\"","The main contribution of this paper is to show that an optimizer's implicit behavior can be explicitly captured by a \"central flow:\" a differential equation which models the time-averaged optimization trajectory.","We show that these flows can empirically predict long-term optimization trajectories of generic neural networks with a high degree of numerical accuracy.","By interpreting these flows, we reveal for the first time 1) the precise sense in which RMSProp adapts to the local loss landscape, and 2) an \"acceleration via regularization\" mechanism, wherein adaptive optimizers implicitly navigate towards low-curvature regions in which they can take larger steps.","This mechanism is key to the efficacy of these adaptive optimizers.","Overall, we believe that central flows constitute a promising tool for reasoning about optimization in deep learning."],"url":"http://arxiv.org/abs/2410.24206v1"}
{"created":"2024-10-31 17:57:51","title":"Zonal RL-RRT: Integrated RL-RRT Path Planning with Collision Probability and Zone Connectivity","abstract":"Path planning in high-dimensional spaces poses significant challenges, particularly in achieving both time efficiency and a fair success rate. To address these issues, we introduce a novel path-planning algorithm, Zonal RL-RRT, that leverages kd-tree partitioning to segment the map into zones while addressing zone connectivity, ensuring seamless transitions between zones. By breaking down the complex environment into multiple zones and using Q-learning as the high-level decision-maker, our algorithm achieves a 3x improvement in time efficiency compared to basic sampling methods such as RRT and RRT* in forest-like maps. Our approach outperforms heuristic-guided methods like BIT* and Informed RRT* by 1.5x in terms of runtime while maintaining robust and reliable success rates across 2D to 6D environments. Compared to learning-based methods like NeuralRRT* and MPNetSMP, as well as the heuristic RRT*J, our algorithm demonstrates, on average, 1.5x better performance in the same environments. We also evaluate the effectiveness of our approach through simulations of the UR10e arm manipulator in the MuJoCo environment. A key observation of our approach lies in its use of zone partitioning and Reinforcement Learning (RL) for adaptive high-level planning allowing the algorithm to accommodate flexible policies across diverse environments, making it a versatile tool for advanced path planning.","sentences":["Path planning in high-dimensional spaces poses significant challenges, particularly in achieving both time efficiency and a fair success rate.","To address these issues, we introduce a novel path-planning algorithm, Zonal RL-RRT, that leverages kd-tree partitioning to segment the map into zones while addressing zone connectivity, ensuring seamless transitions between zones.","By breaking down the complex environment into multiple zones and using Q-learning as the high-level decision-maker, our algorithm achieves a 3x improvement in time efficiency compared to basic sampling methods such as RRT and RRT* in forest-like maps.","Our approach outperforms heuristic-guided methods like BIT* and Informed RRT* by 1.5x in terms of runtime while maintaining robust and reliable success rates across 2D to 6D environments.","Compared to learning-based methods like NeuralRRT* and MPNetSMP, as well as the heuristic RRT*J, our algorithm demonstrates, on average, 1.5x better performance in the same environments.","We also evaluate the effectiveness of our approach through simulations of the UR10e arm manipulator in the MuJoCo environment.","A key observation of our approach lies in its use of zone partitioning and Reinforcement Learning (RL) for adaptive high-level planning allowing the algorithm to accommodate flexible policies across diverse environments, making it a versatile tool for advanced path planning."],"url":"http://arxiv.org/abs/2410.24205v1"}
{"created":"2024-10-31 17:57:07","title":"GeoSplatting: Towards Geometry Guided Gaussian Splatting for Physically-based Inverse Rendering","abstract":"We consider the problem of physically-based inverse rendering using 3D Gaussian Splatting (3DGS) representations. While recent 3DGS methods have achieved remarkable results in novel view synthesis (NVS), accurately capturing high-fidelity geometry, physically interpretable materials and lighting remains challenging, as it requires precise geometry modeling to provide accurate surface normals, along with physically-based rendering (PBR) techniques to ensure correct material and lighting disentanglement. Previous 3DGS methods resort to approximating surface normals, but often struggle with noisy local geometry, leading to inaccurate normal estimation and suboptimal material-lighting decomposition. In this paper, we introduce GeoSplatting, a novel hybrid representation that augments 3DGS with explicit geometric guidance and differentiable PBR equations. Specifically, we bridge isosurface and 3DGS together, where we first extract isosurface mesh from a scalar field, then convert it into 3DGS points and formulate PBR equations for them in a fully differentiable manner. In GeoSplatting, 3DGS is grounded on the mesh geometry, enabling precise surface normal modeling, which facilitates the use of PBR frameworks for material decomposition. This approach further maintains the efficiency and quality of NVS from 3DGS while ensuring accurate geometry from the isosurface. Comprehensive evaluations across diverse datasets demonstrate the superiority of GeoSplatting, consistently outperforming existing methods both quantitatively and qualitatively.","sentences":["We consider the problem of physically-based inverse rendering using 3D Gaussian Splatting (3DGS) representations.","While recent 3DGS methods have achieved remarkable results in novel view synthesis (NVS), accurately capturing high-fidelity geometry, physically interpretable materials and lighting remains challenging, as it requires precise geometry modeling to provide accurate surface normals, along with physically-based rendering (PBR) techniques to ensure correct material and lighting disentanglement.","Previous 3DGS methods resort to approximating surface normals, but often struggle with noisy local geometry, leading to inaccurate normal estimation and suboptimal material-lighting decomposition.","In this paper, we introduce GeoSplatting, a novel hybrid representation that augments 3DGS with explicit geometric guidance and differentiable PBR equations.","Specifically, we bridge isosurface and 3DGS together, where we first extract isosurface mesh from a scalar field, then convert it into 3DGS points and formulate PBR equations for them in a fully differentiable manner.","In GeoSplatting, 3DGS is grounded on the mesh geometry, enabling precise surface normal modeling, which facilitates the use of PBR frameworks for material decomposition.","This approach further maintains the efficiency and quality of NVS from 3DGS while ensuring accurate geometry from the isosurface.","Comprehensive evaluations across diverse datasets demonstrate the superiority of GeoSplatting, consistently outperforming existing methods both quantitatively and qualitatively."],"url":"http://arxiv.org/abs/2410.24204v1"}
{"created":"2024-10-31 17:57:02","title":"DiffPano: Scalable and Consistent Text to Panorama Generation with Spherical Epipolar-Aware Diffusion","abstract":"Diffusion-based methods have achieved remarkable achievements in 2D image or 3D object generation, however, the generation of 3D scenes and even $360^{\\circ}$ images remains constrained, due to the limited number of scene datasets, the complexity of 3D scenes themselves, and the difficulty of generating consistent multi-view images. To address these issues, we first establish a large-scale panoramic video-text dataset containing millions of consecutive panoramic keyframes with corresponding panoramic depths, camera poses, and text descriptions. Then, we propose a novel text-driven panoramic generation framework, termed DiffPano, to achieve scalable, consistent, and diverse panoramic scene generation. Specifically, benefiting from the powerful generative capabilities of stable diffusion, we fine-tune a single-view text-to-panorama diffusion model with LoRA on the established panoramic video-text dataset. We further design a spherical epipolar-aware multi-view diffusion model to ensure the multi-view consistency of the generated panoramic images. Extensive experiments demonstrate that DiffPano can generate scalable, consistent, and diverse panoramic images with given unseen text descriptions and camera poses.","sentences":["Diffusion-based methods have achieved remarkable achievements in 2D image or 3D object generation, however, the generation of 3D scenes and even $360^{\\circ}$ images remains constrained, due to the limited number of scene datasets, the complexity of 3D scenes themselves, and the difficulty of generating consistent multi-view images.","To address these issues, we first establish a large-scale panoramic video-text dataset containing millions of consecutive panoramic keyframes with corresponding panoramic depths, camera poses, and text descriptions.","Then, we propose a novel text-driven panoramic generation framework, termed DiffPano, to achieve scalable, consistent, and diverse panoramic scene generation.","Specifically, benefiting from the powerful generative capabilities of stable diffusion, we fine-tune a single-view text-to-panorama diffusion model with LoRA on the established panoramic video-text dataset.","We further design a spherical epipolar-aware multi-view diffusion model to ensure the multi-view consistency of the generated panoramic images.","Extensive experiments demonstrate that DiffPano can generate scalable, consistent, and diverse panoramic images with given unseen text descriptions and camera poses."],"url":"http://arxiv.org/abs/2410.24203v1"}
{"created":"2024-10-31 17:55:45","title":"P-Masking: Power Law Masking Improves Multi-attribute Controlled Generation","abstract":"We introduce LingGen, a novel approach for controlled text generation that offers precise control over a wide array of linguistic attributes, even as the number of attributes varies. LingGen employs a dynamic P-MASKING strategy, which samples masking rates from a power law distribution during training. This innovative approach enables the model to develop robust representations and adapt its attribute control capabilities across a variable number of attributes, from a single attribute to multiple complex configurations. The P-MASKING technique enhances LingGen's ability to manage different levels of attribute visibility, resulting in superior performance in multi-attribute generation tasks. Our experiments demonstrate that LingGen surpasses current state-of-the-art models in both attribute control accuracy and text fluency, particularly excelling in scenarios with varying attribute demands. Additionally, our ablation studies highlight the effectiveness of P-MASKING and the influence of different base language models on performance. These findings demonstrate LingGen's potential for applications requiring precise and adaptable control over multiple linguistic attributes in text generation.","sentences":["We introduce LingGen, a novel approach for controlled text generation that offers precise control over a wide array of linguistic attributes, even as the number of attributes varies.","LingGen employs a dynamic P-MASKING strategy, which samples masking rates from a power law distribution during training.","This innovative approach enables the model to develop robust representations and adapt its attribute control capabilities across a variable number of attributes, from a single attribute to multiple complex configurations.","The P-MASKING technique enhances LingGen's ability to manage different levels of attribute visibility, resulting in superior performance in multi-attribute generation tasks.","Our experiments demonstrate that LingGen surpasses current state-of-the-art models in both attribute control accuracy and text fluency, particularly excelling in scenarios with varying attribute demands.","Additionally, our ablation studies highlight the effectiveness of P-MASKING and the influence of different base language models on performance.","These findings demonstrate LingGen's potential for applications requiring precise and adaptable control over multiple linguistic attributes in text generation."],"url":"http://arxiv.org/abs/2410.24201v1"}
{"created":"2024-10-31 17:55:36","title":"Length-Induced Embedding Collapse in Transformer-based Models","abstract":"Text embeddings enable various applications, but their performance deteriorates on longer texts. In this paper, we find that the performance degradation is due to a phenomenon called Length Collapse, where longer text embeddings collapse into a narrow space. This collapse results in a distributional inconsistency between embeddings of different text lengths, ultimately hurting the performance of downstream tasks. Theoretically, by considering the self-attention mechanism inherently functions as a low-pass filter, we prove that long sequences increase the attenuation rate of the low-pass filter effect of the self-attention mechanism. With layers going deeper, excessive low-pass filtering causes the token signals to retain only their Direct-Current (DC) component, which means the input token feature maps will collapse into a narrow space, especially in long texts. Based on the above analysis, we propose to mitigate the undesirable length collapse limitation by introducing a temperature in softmax(), which achieves a higher low-filter attenuation rate. The tuning-free method, called TempScale, can be plugged into multiple transformer-based embedding models. Empirically, we demonstrate that TempScale can improve existing embedding models, especially on long text inputs, bringing up to 0.53% performance gains on 40 datasets from Massive Text Embedding Benchmark (MTEB) and 0.82% performance gains on 4 datasets from LongEmbed, which specifically focuses on long context retrieval.","sentences":["Text embeddings enable various applications, but their performance deteriorates on longer texts.","In this paper, we find that the performance degradation is due to a phenomenon called Length Collapse, where longer text embeddings collapse into a narrow space.","This collapse results in a distributional inconsistency between embeddings of different text lengths, ultimately hurting the performance of downstream tasks.","Theoretically, by considering the self-attention mechanism inherently functions as a low-pass filter, we prove that long sequences increase the attenuation rate of the low-pass filter effect of the self-attention mechanism.","With layers going deeper, excessive low-pass filtering causes the token signals to retain only their Direct-Current (DC) component, which means the input token feature maps will collapse into a narrow space, especially in long texts.","Based on the above analysis, we propose to mitigate the undesirable length collapse limitation by introducing a temperature in softmax(), which achieves a higher low-filter attenuation rate.","The tuning-free method, called TempScale, can be plugged into multiple transformer-based embedding models.","Empirically, we demonstrate that TempScale can improve existing embedding models, especially on long text inputs, bringing up to 0.53% performance gains on 40 datasets from Massive Text Embedding Benchmark (MTEB) and 0.82% performance gains on 4 datasets from LongEmbed, which specifically focuses on long context retrieval."],"url":"http://arxiv.org/abs/2410.24200v1"}
{"created":"2024-10-31 17:55:27","title":"Multi-Attribute Linguistic Tuning for Controlled Paraphrase Generation","abstract":"We present a novel approach to paraphrase generation that enables precise control and fine-tuning of 40 linguistic attributes for English. Our model is an encoder-decoder architecture that takes as input a source sentence and desired linguistic attributes, and produces paraphrases of the source that satisfy the desired attributes. To guarantee high-quality outputs at inference time, our method is equipped with a quality control mechanism that gradually adjusts the embedding of linguistic attributes to find the nearest and most attainable configuration of desired attributes for paraphrase generation. We evaluate the effectiveness of our method by comparing it to recent controllable generation models. Experimental results demonstrate that the proposed model outperforms baselines in generating paraphrases that satisfy desired linguistic attributes.","sentences":["We present a novel approach to paraphrase generation that enables precise control and fine-tuning of 40 linguistic attributes for English.","Our model is an encoder-decoder architecture that takes as input a source sentence and desired linguistic attributes, and produces paraphrases of the source that satisfy the desired attributes.","To guarantee high-quality outputs at inference time, our method is equipped with a quality control mechanism that gradually adjusts the embedding of linguistic attributes to find the nearest and most attainable configuration of desired attributes for paraphrase generation.","We evaluate the effectiveness of our method by comparing it to recent controllable generation models.","Experimental results demonstrate that the proposed model outperforms baselines in generating paraphrases that satisfy desired linguistic attributes."],"url":"http://arxiv.org/abs/2410.24199v1"}
{"created":"2024-10-31 17:55:13","title":"SelfCodeAlign: Self-Alignment for Code Generation","abstract":"Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models (LLMs) to follow human instructions. We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs without extensive human annotations or distillation. SelfCodeAlign employs the same base model for inference throughout the data generation process. It first extracts diverse coding concepts from high-quality seed snippets to generate new tasks. It then samples multiple responses per task, pairs each with test cases, and validates them in a sandbox environment. Finally, passing examples are selected for instruction tuning. In our primary experiments, we use SelfCodeAlign with CodeQwen1.5-7B to generate a dataset of 74k instruction-response pairs. Finetuning on this dataset leads to a model that achieves a 67.1 pass@1 on HumanEval+, surpassing CodeLlama-70B-Instruct despite being ten times smaller. Across all benchmarks, this finetuned model consistently outperforms the original version trained with OctoPack, the previous state-of-the-art method for instruction tuning without human annotations or distillation. Additionally, we show that SelfCodeAlign is effective across LLMs of various sizes, from 3B to 33B, and that the base models can benefit more from alignment with their own data distribution. We further validate each component's effectiveness in our pipeline, showing that SelfCodeAlign outperforms both direct distillation from GPT-4o and leading GPT-3.5-based distillation methods, such as OSS-Instruct and Evol-Instruct. SelfCodeAlign has also led to the creation of StarCoder2-Instruct, the first fully transparent, permissively licensed, and self-aligned code LLM that achieves state-of-the-art coding performance.","sentences":["Instruction tuning is a supervised fine-tuning approach that significantly improves the ability of large language models (LLMs) to follow human instructions.","We propose SelfCodeAlign, the first fully transparent and permissive pipeline for self-aligning code LLMs without extensive human annotations or distillation.","SelfCodeAlign employs the same base model for inference throughout the data generation process.","It first extracts diverse coding concepts from high-quality seed snippets to generate new tasks.","It then samples multiple responses per task, pairs each with test cases, and validates them in a sandbox environment.","Finally, passing examples are selected for instruction tuning.","In our primary experiments, we use SelfCodeAlign with CodeQwen1.5-7B to generate a dataset of 74k instruction-response pairs.","Finetuning on this dataset leads to a model that achieves a 67.1 pass@1 on HumanEval+, surpassing CodeLlama-70B-Instruct despite being ten times smaller.","Across all benchmarks, this finetuned model consistently outperforms the original version trained with OctoPack, the previous state-of-the-art method for instruction tuning without human annotations or distillation.","Additionally, we show that SelfCodeAlign is effective across LLMs of various sizes, from 3B to 33B, and that the base models can benefit more from alignment with their own data distribution.","We further validate each component's effectiveness in our pipeline, showing that SelfCodeAlign outperforms both direct distillation from GPT-4o and leading GPT-3.5-based distillation methods, such as OSS-Instruct and Evol-Instruct.","SelfCodeAlign has also led to the creation of StarCoder2-Instruct, the first fully transparent, permissively licensed, and self-aligned code LLM that achieves state-of-the-art coding performance."],"url":"http://arxiv.org/abs/2410.24198v1"}
{"created":"2024-10-31 17:54:33","title":"A Sagittal Planar Ankle-Foot Prosthesis with Powered Plantarflexion and Socket Alignment","abstract":"Powered ankle-foot prostheses can often reduce the energy cost of walking by assisting with push-off. However, focus on providing mechanical work may lead to ignoring or exacerbating common issues with chronic pain, irritation, pressure ulcer development, and eventual osteoarthritis in persons with amputation. This paper presents the design and validation of a novel transtibial prosthesis informed by predictive biomechanical simulations of gait which minimize a combination of user effort and interaction loading from the prosthesis socket. From these findings, the device was designed with a non-biomimetic anterior-posterior translation degree of freedom with a 10 cm range of motion which is primarily position-controlled to change the alignment of the prosthetic foot with the residual limb. The system is both mobile and tethered, with the batteries, actuators, and majority of electronics located in a small backpack. Mechanical loads are transmitted through cables to the prosthesis, minimizing the distal mass carriage required. We measured torque and force sensing accuracy, open loop actuator performance, closed loop torque and position control bandwidth, and torque and position tracking error during walking. The system is capable of producing up to 160 N-m of plantarflexion torque and 394 N of AP translation force with a closed loop control bandwidth of about 7 Hz in both degrees of freedom. Torque tracking during walking was accurate within about 10 N-m but position tracking was substantially affected by phase lag, possibly due to cable slack in the bidirectional mechanism. The prototype was capable of replicating our simulated prosthesis dynamics during gait and offers useful insights into the advantages and the practical considerations of using predictive biomechanical simulation as a design tool for wearable robots.","sentences":["Powered ankle-foot prostheses can often reduce the energy cost of walking by assisting with push-off.","However, focus on providing mechanical work may lead to ignoring or exacerbating common issues with chronic pain, irritation, pressure ulcer development, and eventual osteoarthritis in persons with amputation.","This paper presents the design and validation of a novel transtibial prosthesis informed by predictive biomechanical simulations of gait which minimize a combination of user effort and interaction loading from the prosthesis socket.","From these findings, the device was designed with a non-biomimetic anterior-posterior translation degree of freedom with a 10 cm range of motion which is primarily position-controlled to change the alignment of the prosthetic foot with the residual limb.","The system is both mobile and tethered, with the batteries, actuators, and majority of electronics located in a small backpack.","Mechanical loads are transmitted through cables to the prosthesis, minimizing the distal mass carriage required.","We measured torque and force sensing accuracy, open loop actuator performance, closed loop torque and position control bandwidth, and torque and position tracking error during walking.","The system is capable of producing up to 160 N-m of plantarflexion torque and 394 N of AP translation force with a closed loop control bandwidth of about 7 Hz in both degrees of freedom.","Torque tracking during walking was accurate within about 10 N-m but position tracking was substantially affected by phase lag, possibly due to cable slack in the bidirectional mechanism.","The prototype was capable of replicating our simulated prosthesis dynamics during gait and offers useful insights into the advantages and the practical considerations of using predictive biomechanical simulation as a design tool for wearable robots."],"url":"http://arxiv.org/abs/2410.24196v1"}
{"created":"2024-10-31 17:51:00","title":"Hidden Persuaders: LLMs' Political Leaning and Their Influence on Voters","abstract":"How could LLMs influence our democracy? We investigate LLMs' political leanings and the potential influence of LLMs on voters by conducting multiple experiments in a U.S. presidential election context. Through a voting simulation, we first demonstrate 18 open- and closed-weight LLMs' political preference for a Democratic nominee over a Republican nominee. We show how this leaning towards the Democratic nominee becomes more pronounced in instruction-tuned models compared to their base versions by analyzing their responses to candidate-policy related questions. We further explore the potential impact of LLMs on voter choice by conducting an experiment with 935 U.S. registered voters. During the experiments, participants interacted with LLMs (Claude-3, Llama-3, and GPT-4) over five exchanges. The experiment results show a shift in voter choices towards the Democratic nominee following LLM interaction, widening the voting margin from 0.7% to 4.6%, even though LLMs were not asked to persuade users to support the Democratic nominee during the discourse. This effect is larger than many previous studies on the persuasiveness of political campaigns, which have shown minimal effects in presidential elections. Many users also expressed a desire for further political interaction with LLMs. Which aspects of LLM interactions drove these shifts in voter choice requires further study. Lastly, we explore how a safety method can make LLMs more politically neutral, while leaving some open questions.","sentences":["How could LLMs influence our democracy?","We investigate LLMs' political leanings and the potential influence of LLMs on voters by conducting multiple experiments in a U.S. presidential election context.","Through a voting simulation, we first demonstrate 18 open- and closed-weight LLMs' political preference for a Democratic nominee over a Republican nominee.","We show how this leaning towards the Democratic nominee becomes more pronounced in instruction-tuned models compared to their base versions by analyzing their responses to candidate-policy related questions.","We further explore the potential impact of LLMs on voter choice by conducting an experiment with 935 U.S. registered voters.","During the experiments, participants interacted with LLMs (Claude-3, Llama-3, and GPT-4) over five exchanges.","The experiment results show a shift in voter choices towards the Democratic nominee following LLM interaction, widening the voting margin from 0.7% to 4.6%, even though LLMs were not asked to persuade users to support the Democratic nominee during the discourse.","This effect is larger than many previous studies on the persuasiveness of political campaigns, which have shown minimal effects in presidential elections.","Many users also expressed a desire for further political interaction with LLMs.","Which aspects of LLM interactions drove these shifts in voter choice requires further study.","Lastly, we explore how a safety method can make LLMs more politically neutral, while leaving some open questions."],"url":"http://arxiv.org/abs/2410.24190v1"}
{"created":"2024-10-31 17:49:44","title":"Chasing Better Deep Image Priors between Over- and Under-parameterization","abstract":"Deep Neural Networks (DNNs) are well-known to act as over-parameterized deep image priors (DIP) that regularize various image inverse problems. Meanwhile, researchers also proposed extremely compact, under-parameterized image priors (e.g., deep decoder) that are strikingly competent for image restoration too, despite a loss of accuracy. These two extremes push us to think whether there exists a better solution in the middle: between over- and under-parameterized image priors, can one identify \"intermediate\" parameterized image priors that achieve better trade-offs between performance, efficiency, and even preserving strong transferability? Drawing inspirations from the lottery ticket hypothesis (LTH), we conjecture and study a novel \"lottery image prior\" (LIP) by exploiting DNN inherent sparsity, stated as: given an over-parameterized DNN-based image prior, it will contain a sparse subnetwork that can be trained in isolation, to match the original DNN's performance when being applied as a prior to various image inverse problems. Our results validate the superiority of LIPs: we can successfully locate the LIP subnetworks from over-parameterized DIPs at substantial sparsity ranges. Those LIP subnetworks significantly outperform deep decoders under comparably compact model sizes (by often fully preserving the effectiveness of their over-parameterized counterparts), and they also possess high transferability across different images as well as restoration task types. Besides, we also extend LIP to compressive sensing image reconstruction, where a pre-trained GAN generator is used as the prior (in contrast to untrained DIP or deep decoder), and confirm its validity in this setting too. To our best knowledge, this is the first time that LTH is demonstrated to be relevant in the context of inverse problems or image priors.","sentences":["Deep Neural Networks (DNNs) are well-known to act as over-parameterized deep image priors (DIP) that regularize various image inverse problems.","Meanwhile, researchers also proposed extremely compact, under-parameterized image priors (e.g., deep decoder) that are strikingly competent for image restoration too, despite a loss of accuracy.","These two extremes push us to think whether there exists a better solution in the middle: between over- and under-parameterized image priors, can one identify \"intermediate\" parameterized image priors that achieve better trade-offs between performance, efficiency, and even preserving strong transferability?","Drawing inspirations from the lottery ticket hypothesis (LTH), we conjecture and study a novel \"lottery image prior\" (LIP) by exploiting DNN inherent sparsity, stated as: given an over-parameterized DNN-based image prior, it will contain a sparse subnetwork that can be trained in isolation, to match the original DNN's performance when being applied as a prior to various image inverse problems.","Our results validate the superiority of LIPs: we can successfully locate the LIP subnetworks from over-parameterized DIPs at substantial sparsity ranges.","Those LIP subnetworks significantly outperform deep decoders under comparably compact model sizes (by often fully preserving the effectiveness of their over-parameterized counterparts), and they also possess high transferability across different images as well as restoration task types.","Besides, we also extend LIP to compressive sensing image reconstruction, where a pre-trained GAN generator is used as the prior (in contrast to untrained DIP or deep decoder), and confirm its validity in this setting too.","To our best knowledge, this is the first time that LTH is demonstrated to be relevant in the context of inverse problems or image priors."],"url":"http://arxiv.org/abs/2410.24187v1"}
{"created":"2024-10-31 17:48:45","title":"DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning","abstract":"Imitation learning from human demonstrations is an effective means to teach robots manipulation skills. But data acquisition is a major bottleneck in applying this paradigm more broadly, due to the amount of cost and human effort involved. There has been significant interest in imitation learning for bimanual dexterous robots, like humanoids. Unfortunately, data collection is even more challenging here due to the challenges of simultaneously controlling multiple arms and multi-fingered hands. Automated data generation in simulation is a compelling, scalable alternative to fuel this need for data. To this end, we introduce DexMimicGen, a large-scale automated data generation system that synthesizes trajectories from a handful of human demonstrations for humanoid robots with dexterous hands. We present a collection of simulation environments in the setting of bimanual dexterous manipulation, spanning a range of manipulation behaviors and different requirements for coordination among the two arms. We generate 21K demos across these tasks from just 60 source human demos and study the effect of several data generation and policy learning decisions on agent performance. Finally, we present a real-to-sim-to-real pipeline and deploy it on a real-world humanoid can sorting task. Videos and more are at https://dexmimicgen.github.io/","sentences":["Imitation learning from human demonstrations is an effective means to teach robots manipulation skills.","But data acquisition is a major bottleneck in applying this paradigm more broadly, due to the amount of cost and human effort involved.","There has been significant interest in imitation learning for bimanual dexterous robots, like humanoids.","Unfortunately, data collection is even more challenging here due to the challenges of simultaneously controlling multiple arms and multi-fingered hands.","Automated data generation in simulation is a compelling, scalable alternative to fuel this need for data.","To this end, we introduce DexMimicGen, a large-scale automated data generation system that synthesizes trajectories from a handful of human demonstrations for humanoid robots with dexterous hands.","We present a collection of simulation environments in the setting of bimanual dexterous manipulation, spanning a range of manipulation behaviors and different requirements for coordination among the two arms.","We generate 21K demos across these tasks from just 60 source human demos and study the effect of several data generation and policy learning decisions on agent performance.","Finally, we present a real-to-sim-to-real pipeline and deploy it on a real-world humanoid can sorting task.","Videos and more are at https://dexmimicgen.github.io/"],"url":"http://arxiv.org/abs/2410.24185v1"}
{"created":"2024-10-31 17:47:01","title":"Group Crosscoders for Mechanistic Analysis of Symmetry","abstract":"We introduce group crosscoders, an extension of crosscoders that systematically discover and analyse symmetrical features in neural networks. While neural networks often develop equivariant representations without explicit architectural constraints, understanding these emergent symmetries has traditionally relied on manual analysis. Group crosscoders automate this process by performing dictionary learning across transformed versions of inputs under a symmetry group. Applied to InceptionV1's mixed3b layer using the dihedral group $\\mathrm{D}_{32}$, our method reveals several key insights: First, it naturally clusters features into interpretable families that correspond to previously hypothesised feature types, providing more precise separation than standard sparse autoencoders. Second, our transform block analysis enables the automatic characterisation of feature symmetries, revealing how different geometric features (such as curves versus lines) exhibit distinct patterns of invariance and equivariance. These results demonstrate that group crosscoders can provide systematic insights into how neural networks represent symmetry, offering a promising new tool for mechanistic interpretability.","sentences":["We introduce group crosscoders, an extension of crosscoders that systematically discover and analyse symmetrical features in neural networks.","While neural networks often develop equivariant representations without explicit architectural constraints, understanding these emergent symmetries has traditionally relied on manual analysis.","Group crosscoders automate this process by performing dictionary learning across transformed versions of inputs under a symmetry group.","Applied to InceptionV1's mixed3b layer using the dihedral group $\\mathrm{D}_{32}$, our method reveals several key insights: First, it naturally clusters features into interpretable families that correspond to previously hypothesised feature types, providing more precise separation than standard sparse autoencoders.","Second, our transform block analysis enables the automatic characterisation of feature symmetries, revealing how different geometric features (such as curves versus lines) exhibit distinct patterns of invariance and equivariance.","These results demonstrate that group crosscoders can provide systematic insights into how neural networks represent symmetry, offering a promising new tool for mechanistic interpretability."],"url":"http://arxiv.org/abs/2410.24184v1"}
{"created":"2024-10-31 17:46:54","title":"Extended Object Tracking and Classification based on Linear Splines","abstract":"This paper introduces a framework based on linear splines for 2-dimensional extended object tracking and classification. Unlike state of the art models, linear splines allow to represent extended objects whose contour is an arbitrarily complex curve. An exact likelihood is derived for the case in which noisy measurements can be scattered from any point on the contour of the extended object, while an approximate Monte Carlo likelihood is provided for the case wherein scattering points can be anywhere, i.e. inside or on the contour, on the object surface. Exploiting such likelihood to measure how well the observed data fit a given shape, a suitable estimator is developed. The proposed estimator models the extended object in terms of a kinematic state, providing object position and orientation, along with a shape vector, characterizing object contour and surface. The kinematic state is estimated via a nonlinear Kalman filter, while the shape vector is estimated via a Bayesian classifier so that classification is implicitly solved during shape estimation. Numerical experiments are provided to assess, compared to state of the art extended object estimators, the effectiveness of the proposed one.","sentences":["This paper introduces a framework based on linear splines for 2-dimensional extended object tracking and classification.","Unlike state of the art models, linear splines allow to represent extended objects whose contour is an arbitrarily complex curve.","An exact likelihood is derived for the case in which noisy measurements can be scattered from any point on the contour of the extended object, while an approximate Monte Carlo likelihood is provided for the case wherein scattering points can be anywhere, i.e. inside or on the contour, on the object surface.","Exploiting such likelihood to measure how well the observed data fit a given shape, a suitable estimator is developed.","The proposed estimator models the extended object in terms of a kinematic state, providing object position and orientation, along with a shape vector, characterizing object contour and surface.","The kinematic state is estimated via a nonlinear Kalman filter, while the shape vector is estimated via a Bayesian classifier so that classification is implicitly solved during shape estimation.","Numerical experiments are provided to assess, compared to state of the art extended object estimators, the effectiveness of the proposed one."],"url":"http://arxiv.org/abs/2410.24183v1"}
{"created":"2024-10-31 17:45:09","title":"Federated Black-Box Adaptation for Semantic Segmentation","abstract":"Federated Learning (FL) is a form of distributed learning that allows multiple institutions or clients to collaboratively learn a global model to solve a task. This allows the model to utilize the information from every institute while preserving data privacy. However, recent studies show that the promise of protecting the privacy of data is not upheld by existing methods and that it is possible to recreate the training data from the different institutions. This is done by utilizing gradients transferred between the clients and the global server during training or by knowing the model architecture at the client end. In this paper, we propose a federated learning framework for semantic segmentation without knowing the model architecture nor transferring gradients between the client and the server, thus enabling better privacy preservation. We propose BlackFed - a black-box adaptation of neural networks that utilizes zero order optimization (ZOO) to update the client model weights and first order optimization (FOO) to update the server weights. We evaluate our approach on several computer vision and medical imaging datasets to demonstrate its effectiveness. To the best of our knowledge, this work is one of the first works in employing federated learning for segmentation, devoid of gradients or model information exchange. Code: https://github.com/JayParanjape/blackfed/tree/master","sentences":["Federated Learning (FL) is a form of distributed learning that allows multiple institutions or clients to collaboratively learn a global model to solve a task.","This allows the model to utilize the information from every institute while preserving data privacy.","However, recent studies show that the promise of protecting the privacy of data is not upheld by existing methods and that it is possible to recreate the training data from the different institutions.","This is done by utilizing gradients transferred between the clients and the global server during training or by knowing the model architecture at the client end.","In this paper, we propose a federated learning framework for semantic segmentation without knowing the model architecture nor transferring gradients between the client and the server, thus enabling better privacy preservation.","We propose BlackFed - a black-box adaptation of neural networks that utilizes zero order optimization (ZOO) to update the client model weights and first order optimization (FOO) to update the server weights.","We evaluate our approach on several computer vision and medical imaging datasets to demonstrate its effectiveness.","To the best of our knowledge, this work is one of the first works in employing federated learning for segmentation, devoid of gradients or model information exchange.","Code: https://github.com/JayParanjape/blackfed/tree/master"],"url":"http://arxiv.org/abs/2410.24181v1"}
{"created":"2024-10-31 17:43:53","title":"AR-Pro: Counterfactual Explanations for Anomaly Repair with Formal Properties","abstract":"Anomaly detection is widely used for identifying critical errors and suspicious behaviors, but current methods lack interpretability. We leverage common properties of existing methods and recent advances in generative models to introduce counterfactual explanations for anomaly detection. Given an input, we generate its counterfactual as a diffusion-based repair that shows what a non-anomalous version should have looked like. A key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata, offering a unified framework for generating and evaluating explanations. We demonstrate the effectiveness of our anomaly explainability framework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI) anomaly datasets. The code used for the experiments is accessible at: https://github.com/xjiae/arpro.","sentences":["Anomaly detection is widely used for identifying critical errors and suspicious behaviors, but current methods lack interpretability.","We leverage common properties of existing methods and recent advances in generative models to introduce counterfactual explanations for anomaly detection.","Given an input, we generate its counterfactual as a diffusion-based repair that shows what a non-anomalous version should have looked like.","A key advantage of this approach is that it enables a domain-independent formal specification of explainability desiderata, offering a unified framework for generating and evaluating explanations.","We demonstrate the effectiveness of our anomaly explainability framework, AR-Pro, on vision (MVTec, VisA) and time-series (SWaT, WADI, HAI) anomaly datasets.","The code used for the experiments is accessible at: https://github.com/xjiae/arpro."],"url":"http://arxiv.org/abs/2410.24178v1"}
{"created":"2024-10-31 17:42:26","title":"Constraint Back-translation Improves Complex Instruction Following of Large Language Models","abstract":"Large language models (LLMs) struggle to follow instructions with complex constraints in format, length, etc. Following the conventional instruction-tuning practice, previous works conduct post-training on complex instruction-response pairs generated by feeding complex instructions to advanced LLMs. However, even advanced LLMs cannot follow complex instructions well, thus limiting the quality of generated data. In this work, we find that existing datasets inherently contain implicit complex constraints and propose a novel data generation technique, constraint back-translation. Specifically, we take the high-quality instruction-response pairs in existing datasets and only adopt advanced LLMs to add complex constraints already met by the responses to the instructions, which naturally reduces costs and data noise. In the experiments, we adopt Llama3-70B-Instruct to back-translate constraints and create a high-quality complex instruction-response dataset, named CRAB. We present that post-training on CRAB improves multiple backbone LLMs' complex instruction-following ability, evaluated on extensive instruction-following benchmarks. We further find that constraint back-translation also serves as a useful auxiliary training objective in post-training. Our code, data, and models will be released to facilitate future research.","sentences":["Large language models (LLMs) struggle to follow instructions with complex constraints in format, length, etc.","Following the conventional instruction-tuning practice, previous works conduct post-training on complex instruction-response pairs generated by feeding complex instructions to advanced LLMs.","However, even advanced LLMs cannot follow complex instructions well, thus limiting the quality of generated data.","In this work, we find that existing datasets inherently contain implicit complex constraints and propose a novel data generation technique, constraint back-translation.","Specifically, we take the high-quality instruction-response pairs in existing datasets and only adopt advanced LLMs to add complex constraints already met by the responses to the instructions, which naturally reduces costs and data noise.","In the experiments, we adopt Llama3-70B-Instruct to back-translate constraints and create a high-quality complex instruction-response dataset, named CRAB.","We present that post-training on CRAB improves multiple backbone LLMs' complex instruction-following ability, evaluated on extensive instruction-following benchmarks.","We further find that constraint back-translation also serves as a useful auxiliary training objective in post-training.","Our code, data, and models will be released to facilitate future research."],"url":"http://arxiv.org/abs/2410.24175v1"}
{"created":"2024-10-31 17:41:14","title":"Novel Architecture for Distributed Travel Data Integration and Service Provision Using Microservices","abstract":"This paper introduces a microservices architecture for the purpose of enhancing the flexibility and performance of an airline reservation system. The architectural design incorporates Redis cache technologies, two different messaging systems (Kafka and RabbitMQ), two types of storages (MongoDB, and PostgreSQL). It also introduces authorization techniques, including secure communication through OAuth2 and JWT which is essential with the management of high-demand travel services. According to selected indicators, the architecture provides an impressive level of data consistency at 99.5% and a latency of data propagation of less than 75 ms allowing rapid and reliable intercommunication between microservices. A system throughput of 1050 events per second was achieved so that the acceptability level was maintained even during peak time. Redis caching reduced a 92% cache hit ratio on the database thereby lowering the burden on the database and increasing the speed of response. Further improvement of the systems scalability was done through the use of Docker and Kubernetes which enabled services to be expanded horizontally to cope with the changes in demand. The error rates were very low, at 0.2% further enhancing the efficiency of the system in handling real-time data integration. This approach is suggested to meet the specific needs of the airline reservation system. It is secure, fast, scalable, all serving to improve the user experience as well as the efficiency of operations. The low latency and high data integration levels and prevaiing efficient usage of the resources demonstrates the architecture ability to offer continued support in the ever growing high demand situations.","sentences":["This paper introduces a microservices architecture for the purpose of enhancing the flexibility and performance of an airline reservation system.","The architectural design incorporates Redis cache technologies, two different messaging systems (Kafka and RabbitMQ), two types of storages (MongoDB, and PostgreSQL).","It also introduces authorization techniques, including secure communication through OAuth2 and JWT which is essential with the management of high-demand travel services.","According to selected indicators, the architecture provides an impressive level of data consistency at 99.5% and a latency of data propagation of less than 75 ms allowing rapid and reliable intercommunication between microservices.","A system throughput of 1050 events per second was achieved so that the acceptability level was maintained even during peak time.","Redis caching reduced a 92% cache hit ratio on the database thereby lowering the burden on the database and increasing the speed of response.","Further improvement of the systems scalability was done through the use of Docker and Kubernetes which enabled services to be expanded horizontally to cope with the changes in demand.","The error rates were very low, at 0.2% further enhancing the efficiency of the system in handling real-time data integration.","This approach is suggested to meet the specific needs of the airline reservation system.","It is secure, fast, scalable, all serving to improve the user experience as well as the efficiency of operations.","The low latency and high data integration levels and prevaiing efficient usage of the resources demonstrates the architecture ability to offer continued support in the ever growing high demand situations."],"url":"http://arxiv.org/abs/2410.24174v1"}
{"created":"2024-10-31 17:35:57","title":"The Importance of Being Scalable: Improving the Speed and Accuracy of Neural Network Interatomic Potentials Across Chemical Domains","abstract":"Scaling has been critical in improving model performance and generalization in machine learning. It involves how a model's performance changes with increases in model size or input data, as well as how efficiently computational resources are utilized to support this growth. Despite successes in other areas, the study of scaling in Neural Network Interatomic Potentials (NNIPs) remains limited. NNIPs act as surrogate models for ab initio quantum mechanical calculations. The dominant paradigm here is to incorporate many physical domain constraints into the model, such as rotational equivariance. We contend that these complex constraints inhibit the scaling ability of NNIPs, and are likely to lead to performance plateaus in the long run. In this work, we take an alternative approach and start by systematically studying NNIP scaling strategies. Our findings indicate that scaling the model through attention mechanisms is efficient and improves model expressivity. These insights motivate us to develop an NNIP architecture designed for scalability: the Efficiently Scaled Attention Interatomic Potential (EScAIP). EScAIP leverages a multi-head self-attention formulation within graph neural networks, applying attention at the neighbor-level representations. Implemented with highly-optimized attention GPU kernels, EScAIP achieves substantial gains in efficiency--at least 10x faster inference, 5x less memory usage--compared to existing NNIPs. EScAIP also achieves state-of-the-art performance on a wide range of datasets including catalysts (OC20 and OC22), molecules (SPICE), and materials (MPTrj). We emphasize that our approach should be thought of as a philosophy rather than a specific model, representing a proof-of-concept for developing general-purpose NNIPs that achieve better expressivity through scaling, and continue to scale efficiently with increased computational resources and training data.","sentences":["Scaling has been critical in improving model performance and generalization in machine learning.","It involves how a model's performance changes with increases in model size or input data, as well as how efficiently computational resources are utilized to support this growth.","Despite successes in other areas, the study of scaling in Neural Network Interatomic Potentials (NNIPs) remains limited.","NNIPs act as surrogate models for ab initio quantum mechanical calculations.","The dominant paradigm here is to incorporate many physical domain constraints into the model, such as rotational equivariance.","We contend that these complex constraints inhibit the scaling ability of NNIPs, and are likely to lead to performance plateaus in the long run.","In this work, we take an alternative approach and start by systematically studying NNIP scaling strategies.","Our findings indicate that scaling the model through attention mechanisms is efficient and improves model expressivity.","These insights motivate us to develop an NNIP architecture designed for scalability: the Efficiently Scaled Attention Interatomic Potential (EScAIP).","EScAIP leverages a multi-head self-attention formulation within graph neural networks, applying attention at the neighbor-level representations.","Implemented with highly-optimized attention GPU kernels, EScAIP achieves substantial gains in efficiency--at least 10x faster inference, 5x less memory usage--compared to existing NNIPs.","EScAIP also achieves state-of-the-art performance on a wide range of datasets including catalysts (OC20 and OC22), molecules (SPICE), and materials (MPTrj).","We emphasize that our approach should be thought of as a philosophy rather than a specific model, representing a proof-of-concept for developing general-purpose NNIPs that achieve better expressivity through scaling, and continue to scale efficiently with increased computational resources and training data."],"url":"http://arxiv.org/abs/2410.24169v1"}
{"created":"2024-10-31 17:28:41","title":"Approaches to human activity recognition via passive radar","abstract":"The thesis explores novel methods for Human Activity Recognition (HAR) using passive radar with a focus on non-intrusive Wi-Fi Channel State Information (CSI) data. Traditional HAR approaches often use invasive sensors like cameras or wearables, raising privacy issues. This study leverages the non-intrusive nature of CSI, using Spiking Neural Networks (SNN) to interpret signal variations caused by human movements. These networks, integrated with symbolic reasoning frameworks such as DeepProbLog, enhance the adaptability and interpretability of HAR systems. SNNs offer reduced power consumption, ideal for privacy-sensitive applications. Experimental results demonstrate SNN-based neurosymbolic models achieve high accuracy making them a promising alternative for HAR across various domains.","sentences":["The thesis explores novel methods for Human Activity Recognition (HAR) using passive radar with a focus on non-intrusive Wi-Fi Channel State Information (CSI) data.","Traditional HAR approaches often use invasive sensors like cameras or wearables, raising privacy issues.","This study leverages the non-intrusive nature of CSI, using Spiking Neural Networks (SNN) to interpret signal variations caused by human movements.","These networks, integrated with symbolic reasoning frameworks such as DeepProbLog, enhance the adaptability and interpretability of HAR systems.","SNNs offer reduced power consumption, ideal for privacy-sensitive applications.","Experimental results demonstrate SNN-based neurosymbolic models achieve high accuracy making them a promising alternative for HAR across various domains."],"url":"http://arxiv.org/abs/2410.24166v1"}
{"created":"2024-10-31 17:22:30","title":"$\u03c0_0$: A Vision-Language-Action Flow Model for General Robot Control","abstract":"Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.","sentences":["Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence.","However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness.","In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks.","We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge.","We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators.","We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning.","Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes."],"url":"http://arxiv.org/abs/2410.24164v1"}
{"created":"2024-10-31 17:20:13","title":"Conformalized Prediction of Post-Fault Voltage Trajectories Using Pre-trained and Finetuned Attention-Driven Neural Operators","abstract":"This paper proposes a new data-driven methodology for predicting intervals of post-fault voltage trajectories in power systems. We begin by introducing the Quantile Attention-Fourier Deep Operator Network (QAF-DeepONet), designed to capture the complex dynamics of voltage trajectories and reliably estimate quantiles of the target trajectory without any distributional assumptions. The proposed operator regression model maps the observed portion of the voltage trajectory to its unobserved post-fault trajectory. Our methodology employs a pre-training and fine-tuning process to address the challenge of limited data availability. To ensure data privacy in learning the pre-trained model, we use merging via federated learning with data from neighboring buses, enabling the model to learn the underlying voltage dynamics from such buses without directly sharing their data. After pre-training, we fine-tune the model with data from the target bus, allowing it to adapt to unique dynamics and operating conditions. Finally, we integrate conformal prediction into the fine-tuned model to ensure coverage guarantees for the predicted intervals. We evaluated the performance of the proposed methodology using the New England 39-bus test system considering detailed models of voltage and frequency controllers. Two metrics, Prediction Interval Coverage Probability (PICP) and Prediction Interval Normalized Average Width (PINAW), are used to numerically assess the model's performance in predicting intervals. The results show that the proposed approach offers practical and reliable uncertainty quantification in predicting the interval of post-fault voltage trajectories.","sentences":["This paper proposes a new data-driven methodology for predicting intervals of post-fault voltage trajectories in power systems.","We begin by introducing the Quantile Attention-Fourier Deep Operator Network (QAF-DeepONet), designed to capture the complex dynamics of voltage trajectories and reliably estimate quantiles of the target trajectory without any distributional assumptions.","The proposed operator regression model maps the observed portion of the voltage trajectory to its unobserved post-fault trajectory.","Our methodology employs a pre-training and fine-tuning process to address the challenge of limited data availability.","To ensure data privacy in learning the pre-trained model, we use merging via federated learning with data from neighboring buses, enabling the model to learn the underlying voltage dynamics from such buses without directly sharing their data.","After pre-training, we fine-tune the model with data from the target bus, allowing it to adapt to unique dynamics and operating conditions.","Finally, we integrate conformal prediction into the fine-tuned model to ensure coverage guarantees for the predicted intervals.","We evaluated the performance of the proposed methodology using the New England 39-bus test system considering detailed models of voltage and frequency controllers.","Two metrics, Prediction Interval Coverage Probability (PICP) and Prediction Interval Normalized Average Width (PINAW), are used to numerically assess the model's performance in predicting intervals.","The results show that the proposed approach offers practical and reliable uncertainty quantification in predicting the interval of post-fault voltage trajectories."],"url":"http://arxiv.org/abs/2410.24162v1"}
{"created":"2024-10-31 17:19:03","title":"Redefining <Creative> in Dictionary: Towards a Enhanced Semantic Understanding of Creative Generation","abstract":"Creativity, both in human and diffusion models, remains an inherently abstract concept; thus, simply adding \"creative\" to a prompt does not yield reliable semantic recognition by the model. In this work, we concretize the abstract notion of \"creative\" through the TP2O task, which aims to merge two unrelated concepts, and introduce CreTok, redefining \"creative\" as the token $\\texttt{<CreTok>}$. This redefinition offers a more concrete and universally adaptable representation for concept blending. This redefinition occurs continuously, involving the repeated random sampling of text pairs with different concepts and optimizing cosine similarity between target and constant prompts. This approach enables $\\texttt{<CreTok>}$ to learn a method for creative concept fusion. Extensive experiments demonstrate that the creative capability enabled by $\\texttt{<CreTok>}$ substantially surpasses recent SOTA diffusion models and achieves superior creative generation. CreTok exhibits greater flexibility and reduced time overhead, as $\\texttt{<CreTok>}$ can function as a universal token for any concept, facilitating creative generation without retraining.","sentences":["Creativity, both in human and diffusion models, remains an inherently abstract concept; thus, simply adding \"creative\" to a prompt does not yield reliable semantic recognition by the model.","In this work, we concretize the abstract notion of \"creative\" through the TP2O task, which aims to merge two unrelated concepts, and introduce CreTok, redefining \"creative\" as the token $\\texttt{<CreTok>}$. This redefinition offers a more concrete and universally adaptable representation for concept blending.","This redefinition occurs continuously, involving the repeated random sampling of text pairs with different concepts and optimizing cosine similarity between target and constant prompts.","This approach enables $\\texttt{<CreTok>}$ to learn a method for creative concept fusion.","Extensive experiments demonstrate that the creative capability enabled by $\\texttt{<CreTok>}$ substantially surpasses recent SOTA diffusion models and achieves superior creative generation.","CreTok exhibits greater flexibility and reduced time overhead, as $\\texttt{<CreTok>}$ can function as a universal token for any concept, facilitating creative generation without retraining."],"url":"http://arxiv.org/abs/2410.24160v1"}
{"created":"2024-10-31 17:18:11","title":"GPT or BERT: why not both?","abstract":"We present a simple way to merge masked language modeling with causal language modeling. This hybrid training objective results in a model that combines the strengths of both modeling paradigms within a single transformer stack: GPT-BERT can be transparently used like any standard causal or masked language model. We test the pretraining process that enables this flexible behavior on the BabyLM Challenge 2024. The results show that the hybrid pretraining outperforms masked-only or causal-only models. We openly release the models, training corpora and code.","sentences":["We present a simple way to merge masked language modeling with causal language modeling.","This hybrid training objective results in a model that combines the strengths of both modeling paradigms within a single transformer stack: GPT-BERT can be transparently used like any standard causal or masked language model.","We test the pretraining process that enables this flexible behavior on the BabyLM Challenge 2024.","The results show that the hybrid pretraining outperforms masked-only or causal-only models.","We openly release the models, training corpora and code."],"url":"http://arxiv.org/abs/2410.24159v1"}
{"created":"2024-10-31 17:12:14","title":"Thought Space Explorer: Navigating and Expanding Thought Space for Large Language Model Reasoning","abstract":"Recent advances in large language models (LLMs) have demonstrated their potential in handling complex reasoning tasks, which are usually achieved by constructing a thought chain to guide the model to solve the problem with multi-step thinking. However, existing methods often remain confined to previously explored solution spaces and thus overlook the critical blind spot within LLMs' cognitive range. To address these issues, we design the Thought Space Explorer (TSE), a novel framework to expand and optimize thought structures to guide LLMs to explore their blind spots of thinking. By generating new reasoning steps and branches based on the original thought structure with various designed strategies, TSE broadens the thought space and alleviates the impact of blind spots for LLM reasoning. Experimental results on multiple levels of reasoning tasks demonstrate the efficacy of TSE. We also conduct extensive analysis to understand how structured and expansive thought can contribute to unleashing the potential of LLM reasoning capabilities.","sentences":["Recent advances in large language models (LLMs) have demonstrated their potential in handling complex reasoning tasks, which are usually achieved by constructing a thought chain to guide the model to solve the problem with multi-step thinking.","However, existing methods often remain confined to previously explored solution spaces and thus overlook the critical blind spot within LLMs' cognitive range.","To address these issues, we design the Thought Space Explorer (TSE), a novel framework to expand and optimize thought structures to guide LLMs to explore their blind spots of thinking.","By generating new reasoning steps and branches based on the original thought structure with various designed strategies, TSE broadens the thought space and alleviates the impact of blind spots for LLM reasoning.","Experimental results on multiple levels of reasoning tasks demonstrate the efficacy of TSE.","We also conduct extensive analysis to understand how structured and expansive thought can contribute to unleashing the potential of LLM reasoning capabilities."],"url":"http://arxiv.org/abs/2410.24155v1"}
{"created":"2024-10-31 17:10:57","title":"Dense Associative Memory Through the Lens of Random Features","abstract":"Dense Associative Memories are high storage capacity variants of the Hopfield networks that are capable of storing a large number of memory patterns in the weights of the network of a given size. Their common formulations typically require storing each pattern in a separate set of synaptic weights, which leads to the increase of the number of synaptic weights when new patterns are introduced. In this work we propose an alternative formulation of this class of models using random features, commonly used in kernel methods. In this formulation the number of network's parameters remains fixed. At the same time, new memories can be added to the network by modifying existing weights. We show that this novel network closely approximates the energy function and dynamics of conventional Dense Associative Memories and shares their desirable computational properties.","sentences":["Dense Associative Memories are high storage capacity variants of the Hopfield networks that are capable of storing a large number of memory patterns in the weights of the network of a given size.","Their common formulations typically require storing each pattern in a separate set of synaptic weights, which leads to the increase of the number of synaptic weights when new patterns are introduced.","In this work we propose an alternative formulation of this class of models using random features, commonly used in kernel methods.","In this formulation the number of network's parameters remains fixed.","At the same time, new memories can be added to the network by modifying existing weights.","We show that this novel network closely approximates the energy function and dynamics of conventional Dense Associative Memories and shares their desirable computational properties."],"url":"http://arxiv.org/abs/2410.24153v1"}
{"created":"2024-10-31 17:10:01","title":"Language-Driven Policy Distillation for Cooperative Driving in Multi-Agent Reinforcement Learning","abstract":"The cooperative driving technology of Connected and Autonomous Vehicles (CAVs) is crucial for improving the efficiency and safety of transportation systems. Learning-based methods, such as Multi-Agent Reinforcement Learning (MARL), have demonstrated strong capabilities in cooperative decision-making tasks. However, existing MARL approaches still face challenges in terms of learning efficiency and performance. In recent years, Large Language Models (LLMs) have rapidly advanced and shown remarkable abilities in various sequential decision-making tasks. To enhance the learning capabilities of cooperative agents while ensuring decision-making efficiency and cost-effectiveness, we propose LDPD, a language-driven policy distillation method for guiding MARL exploration. In this framework, a teacher agent based on LLM trains smaller student agents to achieve cooperative decision-making through its own decision-making demonstrations. The teacher agent enhances the observation information of CAVs and utilizes LLMs to perform complex cooperative decision-making reasoning, which also leverages carefully designed decision-making tools to achieve expert-level decisions, providing high-quality teaching experiences. The student agent then refines the teacher's prior knowledge into its own model through gradient policy updates. The experiments demonstrate that the students can rapidly improve their capabilities with minimal guidance from the teacher and eventually surpass the teacher's performance. Extensive experiments show that our approach demonstrates better performance and learning efficiency compared to baseline methods.","sentences":["The cooperative driving technology of Connected and Autonomous Vehicles (CAVs) is crucial for improving the efficiency and safety of transportation systems.","Learning-based methods, such as Multi-Agent Reinforcement Learning (MARL), have demonstrated strong capabilities in cooperative decision-making tasks.","However, existing MARL approaches still face challenges in terms of learning efficiency and performance.","In recent years, Large Language Models (LLMs) have rapidly advanced and shown remarkable abilities in various sequential decision-making tasks.","To enhance the learning capabilities of cooperative agents while ensuring decision-making efficiency and cost-effectiveness, we propose LDPD, a language-driven policy distillation method for guiding MARL exploration.","In this framework, a teacher agent based on LLM trains smaller student agents to achieve cooperative decision-making through its own decision-making demonstrations.","The teacher agent enhances the observation information of CAVs and utilizes LLMs to perform complex cooperative decision-making reasoning, which also leverages carefully designed decision-making tools to achieve expert-level decisions, providing high-quality teaching experiences.","The student agent then refines the teacher's prior knowledge into its own model through gradient policy updates.","The experiments demonstrate that the students can rapidly improve their capabilities with minimal guidance from the teacher and eventually surpass the teacher's performance.","Extensive experiments show that our approach demonstrates better performance and learning efficiency compared to baseline methods."],"url":"http://arxiv.org/abs/2410.24152v1"}
{"created":"2024-10-31 17:09:55","title":"Scaling Concept With Text-Guided Diffusion Models","abstract":"Text-guided diffusion models have revolutionized generative tasks by producing high-fidelity content from text descriptions. They have also enabled an editing paradigm where concepts can be replaced through text conditioning (e.g., a dog to a tiger). In this work, we explore a novel approach: instead of replacing a concept, can we enhance or suppress the concept itself? Through an empirical study, we identify a trend where concepts can be decomposed in text-guided diffusion models. Leveraging this insight, we introduce ScalingConcept, a simple yet effective method to scale decomposed concepts up or down in real input without introducing new elements. To systematically evaluate our approach, we present the WeakConcept-10 dataset, where concepts are imperfect and need to be enhanced. More importantly, ScalingConcept enables a variety of novel zero-shot applications across image and audio domains, including tasks such as canonical pose generation and generative sound highlighting or removal.","sentences":["Text-guided diffusion models have revolutionized generative tasks by producing high-fidelity content from text descriptions.","They have also enabled an editing paradigm where concepts can be replaced through text conditioning (e.g., a dog to a tiger).","In this work, we explore a novel approach: instead of replacing a concept, can we enhance or suppress the concept itself?","Through an empirical study, we identify a trend where concepts can be decomposed in text-guided diffusion models.","Leveraging this insight, we introduce ScalingConcept, a simple yet effective method to scale decomposed concepts up or down in real input without introducing new elements.","To systematically evaluate our approach, we present the WeakConcept-10 dataset, where concepts are imperfect and need to be enhanced.","More importantly, ScalingConcept enables a variety of novel zero-shot applications across image and audio domains, including tasks such as canonical pose generation and generative sound highlighting or removal."],"url":"http://arxiv.org/abs/2410.24151v1"}
{"created":"2024-10-31 17:09:19","title":"Exploring Vision Language Models for Facial Attribute Recognition: Emotion, Race, Gender, and Age","abstract":"Technologies for recognizing facial attributes like race, gender, age, and emotion have several applications, such as surveillance, advertising content, sentiment analysis, and the study of demographic trends and social behaviors. Analyzing demographic characteristics based on images and analyzing facial expressions have several challenges due to the complexity of humans' facial attributes. Traditional approaches have employed CNNs and various other deep learning techniques, trained on extensive collections of labeled images. While these methods demonstrated effective performance, there remains potential for further enhancements. In this paper, we propose to utilize vision language models (VLMs) such as generative pre-trained transformer (GPT), GEMINI, large language and vision assistant (LLAVA), PaliGemma, and Microsoft Florence2 to recognize facial attributes such as race, gender, age, and emotion from images with human faces. Various datasets like FairFace, AffectNet, and UTKFace have been utilized to evaluate the solutions. The results show that VLMs are competitive if not superior to traditional techniques. Additionally, we propose \"FaceScanPaliGemma\"--a fine-tuned PaliGemma model--for race, gender, age, and emotion recognition. The results show an accuracy of 81.1%, 95.8%, 80%, and 59.4% for race, gender, age group, and emotion classification, respectively, outperforming pre-trained version of PaliGemma, other VLMs, and SotA methods. Finally, we propose \"FaceScanGPT\", which is a GPT-4o model to recognize the above attributes when several individuals are present in the image using a prompt engineered for a person with specific facial and/or physical attributes. The results underscore the superior multitasking capability of FaceScanGPT to detect the individual's attributes like hair cut, clothing color, postures, etc., using only a prompt to drive the detection and recognition tasks.","sentences":["Technologies for recognizing facial attributes like race, gender, age, and emotion have several applications, such as surveillance, advertising content, sentiment analysis, and the study of demographic trends and social behaviors.","Analyzing demographic characteristics based on images and analyzing facial expressions have several challenges due to the complexity of humans' facial attributes.","Traditional approaches have employed CNNs and various other deep learning techniques, trained on extensive collections of labeled images.","While these methods demonstrated effective performance, there remains potential for further enhancements.","In this paper, we propose to utilize vision language models (VLMs) such as generative pre-trained transformer (GPT), GEMINI, large language and vision assistant (LLAVA), PaliGemma, and Microsoft Florence2 to recognize facial attributes such as race, gender, age, and emotion from images with human faces.","Various datasets like FairFace, AffectNet, and UTKFace have been utilized to evaluate the solutions.","The results show that VLMs are competitive if not superior to traditional techniques.","Additionally, we propose \"FaceScanPaliGemma\"--a fine-tuned PaliGemma model--for race, gender, age, and emotion recognition.","The results show an accuracy of 81.1%, 95.8%, 80%, and 59.4% for race, gender, age group, and emotion classification, respectively, outperforming pre-trained version of PaliGemma, other VLMs, and SotA methods.","Finally, we propose \"FaceScanGPT\", which is a GPT-4o model to recognize the above attributes when several individuals are present in the image using a prompt engineered for a person with specific facial and/or physical attributes.","The results underscore the superior multitasking capability of FaceScanGPT to detect the individual's attributes like hair cut, clothing color, postures, etc., using only a prompt to drive the detection and recognition tasks."],"url":"http://arxiv.org/abs/2410.24148v1"}
{"created":"2024-10-31 17:05:44","title":"HoloChrome: Polychromatic Illumination for Speckle Reduction in Holographic Near-Eye Displays","abstract":"Holographic displays hold the promise of providing authentic depth cues, resulting in enhanced immersive visual experiences for near-eye applications. However, current holographic displays are hindered by speckle noise, which limits accurate reproduction of color and texture in displayed images. We present HoloChrome, a polychromatic holographic display framework designed to mitigate these limitations. HoloChrome utilizes an ultrafast, wavelength-adjustable laser and a dual-Spatial Light Modulator (SLM) architecture, enabling the multiplexing of a large set of discrete wavelengths across the visible spectrum. By leveraging spatial separation in our dual-SLM setup, we independently manipulate speckle patterns across multiple wavelengths. This novel approach effectively reduces speckle noise through incoherent averaging achieved by wavelength multiplexing. Our method is complementary to existing speckle reduction techniques, offering a new pathway to address this challenge. Furthermore, the use of polychromatic illumination broadens the achievable color gamut compared to traditional three-color primary holographic displays.   Our simulations and tabletop experiments validate that HoloChrome significantly reduces speckle noise and expands the color gamut. These advancements enhance the performance of holographic near-eye displays, moving us closer to practical, immersive next-generation visual experiences.","sentences":["Holographic displays hold the promise of providing authentic depth cues, resulting in enhanced immersive visual experiences for near-eye applications.","However, current holographic displays are hindered by speckle noise, which limits accurate reproduction of color and texture in displayed images.","We present HoloChrome, a polychromatic holographic display framework designed to mitigate these limitations.","HoloChrome utilizes an ultrafast, wavelength-adjustable laser and a dual-Spatial Light Modulator (SLM) architecture, enabling the multiplexing of a large set of discrete wavelengths across the visible spectrum.","By leveraging spatial separation in our dual-SLM setup, we independently manipulate speckle patterns across multiple wavelengths.","This novel approach effectively reduces speckle noise through incoherent averaging achieved by wavelength multiplexing.","Our method is complementary to existing speckle reduction techniques, offering a new pathway to address this challenge.","Furthermore, the use of polychromatic illumination broadens the achievable color gamut compared to traditional three-color primary holographic displays.   ","Our simulations and tabletop experiments validate that HoloChrome significantly reduces speckle noise and expands the color gamut.","These advancements enhance the performance of holographic near-eye displays, moving us closer to practical, immersive next-generation visual experiences."],"url":"http://arxiv.org/abs/2410.24144v1"}
{"created":"2024-10-31 17:03:44","title":"Don't Touch My Diacritics","abstract":"The common practice of preprocessing text before feeding it into NLP models introduces many decision points which have unintended consequences on model performance. In this opinion piece, we focus on the handling of diacritics in texts originating in many languages and scripts. We demonstrate, through several case studies, the adverse effects of inconsistent encoding of diacritized characters and of removing diacritics altogether. We call on the community to adopt simple but necessary steps across all models and toolkits in order to improve handling of diacritized text and, by extension, increase equity in multilingual NLP.","sentences":["The common practice of preprocessing text before feeding it into NLP models introduces many decision points which have unintended consequences on model performance.","In this opinion piece, we focus on the handling of diacritics in texts originating in many languages and scripts.","We demonstrate, through several case studies, the adverse effects of inconsistent encoding of diacritized characters and of removing diacritics altogether.","We call on the community to adopt simple but necessary steps across all models and toolkits in order to improve handling of diacritized text and, by extension, increase equity in multilingual NLP."],"url":"http://arxiv.org/abs/2410.24140v1"}
{"created":"2024-10-31 17:03:38","title":"COSNet: A Novel Semantic Segmentation Network using Enhanced Boundaries in Cluttered Scenes","abstract":"Automated waste recycling aims to efficiently separate the recyclable objects from the waste by employing vision-based systems. However, the presence of varying shaped objects having different material types makes it a challenging problem, especially in cluttered environments. Existing segmentation methods perform reasonably on many semantic segmentation datasets by employing multi-contextual representations, however, their performance is degraded when utilized for waste object segmentation in cluttered scenarios. In addition, plastic objects further increase the complexity of the problem due to their translucent nature. To address these limitations, we introduce an efficacious segmentation network, named COSNet, that uses boundary cues along with multi-contextual information to accurately segment the objects in cluttered scenes. COSNet introduces novel components including feature sharpening block (FSB) and boundary enhancement module (BEM) for enhancing the features and highlighting the boundary information of irregular waste objects in cluttered environment. Extensive experiments on three challenging datasets including ZeroWaste-f, SpectralWaste, and ADE20K demonstrate the effectiveness of the proposed method. Our COSNet achieves a significant gain of 1.8% on ZeroWaste-f and 2.1% on SpectralWaste datasets respectively in terms of mIoU metric.","sentences":["Automated waste recycling aims to efficiently separate the recyclable objects from the waste by employing vision-based systems.","However, the presence of varying shaped objects having different material types makes it a challenging problem, especially in cluttered environments.","Existing segmentation methods perform reasonably on many semantic segmentation datasets by employing multi-contextual representations, however, their performance is degraded when utilized for waste object segmentation in cluttered scenarios.","In addition, plastic objects further increase the complexity of the problem due to their translucent nature.","To address these limitations, we introduce an efficacious segmentation network, named COSNet, that uses boundary cues along with multi-contextual information to accurately segment the objects in cluttered scenes.","COSNet introduces novel components including feature sharpening block (FSB) and boundary enhancement module (BEM) for enhancing the features and highlighting the boundary information of irregular waste objects in cluttered environment.","Extensive experiments on three challenging datasets including ZeroWaste-f, SpectralWaste, and ADE20K demonstrate the effectiveness of the proposed method.","Our COSNet achieves a significant gain of 1.8% on ZeroWaste-f and 2.1% on SpectralWaste datasets respectively in terms of mIoU metric."],"url":"http://arxiv.org/abs/2410.24139v1"}
{"created":"2024-10-31 16:54:33","title":"Transit drivers' reflections on the benefits and harms of eye tracking technology","abstract":"Eye tracking technology offers great potential for improving road safety. It is already being built into vehicles, namely cars and trucks. When this technology is integrated into transit service vehicles, employees, i.e., bus drivers, will be subject to being eye tracked on their job. Although there is much research effort advancing algorithms for eye tracking in transportation, less is known about how end users perceive this technology, especially when interacting with it in an employer-mandated context. In this first study of its kind, we investigated transit bus operators' perceptions of eye tracking technology. From a methodological perspective, we introduce a mixed methods approach where participants experience the technology first-hand and then reflect on their experience while viewing a playback of the recorded data. Thematic analysis of the interview transcripts reveals interesting potential uses of eye tracking in this work context and surfaces transit operators' fears and concerns about this technology.","sentences":["Eye tracking technology offers great potential for improving road safety.","It is already being built into vehicles, namely cars and trucks.","When this technology is integrated into transit service vehicles, employees, i.e., bus drivers, will be subject to being eye tracked on their job.","Although there is much research effort advancing algorithms for eye tracking in transportation, less is known about how end users perceive this technology, especially when interacting with it in an employer-mandated context.","In this first study of its kind, we investigated transit bus operators' perceptions of eye tracking technology.","From a methodological perspective, we introduce a mixed methods approach where participants experience the technology first-hand and then reflect on their experience while viewing a playback of the recorded data.","Thematic analysis of the interview transcripts reveals interesting potential uses of eye tracking in this work context and surfaces transit operators' fears and concerns about this technology."],"url":"http://arxiv.org/abs/2410.24131v1"}
{"created":"2024-10-31 16:53:20","title":"Q-learning for Quantile MDPs: A Decomposition, Performance, and Convergence Analysis","abstract":"In Markov decision processes (MDPs), quantile risk measures such as Value-at-Risk are a standard metric for modeling RL agents' preferences for certain outcomes. This paper proposes a new Q-learning algorithm for quantile optimization in MDPs with strong convergence and performance guarantees. The algorithm leverages a new, simple dynamic program (DP) decomposition for quantile MDPs. Compared with prior work, our DP decomposition requires neither known transition probabilities nor solving complex saddle point equations and serves as a suitable foundation for other model-free RL algorithms. Our numerical results in tabular domains show that our Q-learning algorithm converges to its DP variant and outperforms earlier algorithms.","sentences":["In Markov decision processes (MDPs), quantile risk measures such as Value-at-Risk are a standard metric for modeling RL agents' preferences for certain outcomes.","This paper proposes a new Q-learning algorithm for quantile optimization in MDPs with strong convergence and performance guarantees.","The algorithm leverages a new, simple dynamic program (DP) decomposition for quantile MDPs.","Compared with prior work, our DP decomposition requires neither known transition probabilities nor solving complex saddle point equations and serves as a suitable foundation for other model-free RL algorithms.","Our numerical results in tabular domains show that our Q-learning algorithm converges to its DP variant and outperforms earlier algorithms."],"url":"http://arxiv.org/abs/2410.24128v1"}
{"created":"2024-10-31 16:50:39","title":"Multi-environment Topic Models","abstract":"Probabilistic topic models are a powerful tool for extracting latent themes from large text datasets. In many text datasets, we also observe per-document covariates (e.g., source, style, political affiliation) that act as environments that modulate a \"global\" (environment-agnostic) topic representation. Accurately learning these representations is important for prediction on new documents in unseen environments and for estimating the causal effect of topics on real-world outcomes. To this end, we introduce the Multi-environment Topic Model (MTM), an unsupervised probabilistic model that separates global and environment-specific terms. Through experimentation on various political content, from ads to tweets and speeches, we show that the MTM produces interpretable global topics with distinct environment-specific words. On multi-environment data, the MTM outperforms strong baselines in and out-of-distribution. It also enables the discovery of accurate causal effects.","sentences":["Probabilistic topic models are a powerful tool for extracting latent themes from large text datasets.","In many text datasets, we also observe per-document covariates (e.g., source, style, political affiliation) that act as environments that modulate a \"global\" (environment-agnostic) topic representation.","Accurately learning these representations is important for prediction on new documents in unseen environments and for estimating the causal effect of topics on real-world outcomes.","To this end, we introduce the Multi-environment Topic Model (MTM), an unsupervised probabilistic model that separates global and environment-specific terms.","Through experimentation on various political content, from ads to tweets and speeches, we show that the MTM produces interpretable global topics with distinct environment-specific words.","On multi-environment data, the MTM outperforms strong baselines in and out-of-distribution.","It also enables the discovery of accurate causal effects."],"url":"http://arxiv.org/abs/2410.24126v1"}
{"created":"2024-10-31 16:49:10","title":"A Practical Style Transfer Pipeline for 3D Animation: Insights from Production R&D","abstract":"Our animation studio has developed a practical style transfer pipeline for creating stylized 3D animation, which is suitable for complex real-world production. This paper presents the insights from our development process, where we explored various options to balance quality, artist control, and workload, leading to several key decisions. For example, we chose patch-based texture synthesis over machine learning for better control and to avoid training data issues. We also addressed specifying style exemplars, managing multiple colors within a scene, controlling outlines and shadows, and reducing temporal noise. These insights were used to further refine our pipeline, ultimately enabling us to produce an experimental short film showcasing various styles.","sentences":["Our animation studio has developed a practical style transfer pipeline for creating stylized 3D animation, which is suitable for complex real-world production.","This paper presents the insights from our development process, where we explored various options to balance quality, artist control, and workload, leading to several key decisions.","For example, we chose patch-based texture synthesis over machine learning for better control and to avoid training data issues.","We also addressed specifying style exemplars, managing multiple colors within a scene, controlling outlines and shadows, and reducing temporal noise.","These insights were used to further refine our pipeline, ultimately enabling us to produce an experimental short film showcasing various styles."],"url":"http://arxiv.org/abs/2410.24123v1"}
{"created":"2024-10-31 16:48:41","title":"Leveraging Large Language Models for Code Translation and Software Development in Scientific Computing","abstract":"The emergence of foundational models and generative artificial intelligence (GenAI) is poised to transform productivity in scientific computing, especially in code development, refactoring, and translating from one programming language to another. However, because the output of GenAI cannot be guaranteed to be correct, manual intervention remains necessary. Some of this intervention can be automated through task-specific tools, alongside additional methodologies for correctness verification and effective prompt development. We explored the application of GenAI in assisting with code translation, language interoperability, and codebase inspection within a legacy Fortran codebase used to simulate particle interactions at the Large Hadron Collider (LHC). In the process, we developed a tool, CodeScribe, which combines prompt engineering with user supervision to establish an efficient process for code conversion. In this paper, we demonstrate how CodeScribe assists in converting Fortran code to C++, generating Fortran-C APIs for integrating legacy systems with modern C++ libraries, and providing developer support for code organization and algorithm implementation. We also address the challenges of AI-driven code translation and highlight its benefits for enhancing productivity in scientific computing workflows.","sentences":["The emergence of foundational models and generative artificial intelligence (GenAI) is poised to transform productivity in scientific computing, especially in code development, refactoring, and translating from one programming language to another.","However, because the output of GenAI cannot be guaranteed to be correct, manual intervention remains necessary.","Some of this intervention can be automated through task-specific tools, alongside additional methodologies for correctness verification and effective prompt development.","We explored the application of GenAI in assisting with code translation, language interoperability, and codebase inspection within a legacy Fortran codebase used to simulate particle interactions at the Large Hadron Collider (LHC).","In the process, we developed a tool, CodeScribe, which combines prompt engineering with user supervision to establish an efficient process for code conversion.","In this paper, we demonstrate how CodeScribe assists in converting Fortran code to C++, generating Fortran-C APIs for integrating legacy systems with modern C++ libraries, and providing developer support for code organization and algorithm implementation.","We also address the challenges of AI-driven code translation and highlight its benefits for enhancing productivity in scientific computing workflows."],"url":"http://arxiv.org/abs/2410.24119v1"}
{"created":"2024-10-31 16:46:52","title":"Repository-Level Compositional Code Translation and Validation","abstract":"Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc.   We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests. AlphaTrans translated the entire repository of these projects consisting of 6899 source code fragments. 99.1% of the translated code fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 25.8%. On average, the integrated translation and validation take 36 hours to translate a project, showing its scalability in practice. For the syntactically or semantically incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.","sentences":["Code translation transforms programs from one programming language (PL) to another.","Several rule-based transpilers have been designed to automate code translation between different pairs of PLs.","However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs.","Recent studies have explored the automation of code translation using Large Language Models (LLMs).","One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc.   We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation.","AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program.","To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order.","We leveraged AlphaTrans to translate ten real-world open-source projects consisting of <836, 8575, 2719> classes, methods, and tests.","AlphaTrans translated the entire repository of these projects consisting of 6899 source code fragments.","99.1% of the translated code fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 25.8%.","On average, the integrated translation and validation take 36 hours to translate a project, showing its scalability in practice.","For the syntactically or semantically incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures.","We provided these artifacts to two developers to fix the translation bugs in four projects.","They were able to fix the issues in 20.1 hours on average and achieve all passing tests."],"url":"http://arxiv.org/abs/2410.24117v1"}
{"created":"2024-10-31 16:46:23","title":"AIDOVECL: AI-generated Dataset of Outpainted Vehicles for Eye-level Classification and Localization","abstract":"Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations. This work introduces a novel approach that leverages outpainting to address the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts. We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes. Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions. The outpainted images include detailed annotations, providing high-quality ground truth data. Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance. Augmentation with outpainted vehicles improves overall performance metrics by up to 8\\% and enhances prediction of underrepresented classes by up to 20\\%. This approach, exemplifying outpainting as a self-annotating paradigm, presents a solution that enhances dataset versatility across multiple domains of machine learning. The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl.","sentences":["Image labeling is a critical bottleneck in the development of computer vision technologies, often constraining the potential of machine learning models due to the time-intensive nature of manual annotations.","This work introduces a novel approach that leverages outpainting to address the problem of annotated data scarcity by generating artificial contexts and annotations, significantly reducing manual labeling efforts.","We apply this technique to a particularly acute challenge in autonomous driving, urban planning, and environmental monitoring: the lack of diverse, eye-level vehicle images in desired classes.","Our dataset comprises AI-generated vehicle images obtained by detecting and cropping vehicles from manually selected seed images, which are then outpainted onto larger canvases to simulate varied real-world conditions.","The outpainted images include detailed annotations, providing high-quality ground truth data.","Advanced outpainting techniques and image quality assessments ensure visual fidelity and contextual relevance.","Augmentation with outpainted vehicles improves overall performance metrics by up to 8\\% and enhances prediction of underrepresented classes by up to 20\\%.","This approach, exemplifying outpainting as a self-annotating paradigm, presents a solution that enhances dataset versatility across multiple domains of machine learning.","The code and links to datasets used in this study are available for further research and replication at https://github.com/amir-kazemi/aidovecl."],"url":"http://arxiv.org/abs/2410.24116v1"}
{"created":"2024-10-31 16:44:10","title":"Nearest Neighbor Normalization Improves Multimodal Retrieval","abstract":"Multimodal models leverage large-scale pre-training to achieve strong but still imperfect performance on tasks such as image captioning, visual question answering, and cross-modal retrieval. In this paper, we present a simple and efficient method for correcting errors in trained contrastive image-text retrieval models with no additional training, called Nearest Neighbor Normalization (NNN). We show an improvement on retrieval metrics in both text retrieval and image retrieval for all of the contrastive models that we tested (CLIP, BLIP, ALBEF, SigLIP, BEiT) and for both of the datasets that we used (MS-COCO and Flickr30k). NNN requires a reference database, but does not require any training on this database, and can even increase the retrieval accuracy of a model after finetuning.","sentences":["Multimodal models leverage large-scale pre-training to achieve strong but still imperfect performance on tasks such as image captioning, visual question answering, and cross-modal retrieval.","In this paper, we present a simple and efficient method for correcting errors in trained contrastive image-text retrieval models with no additional training, called Nearest Neighbor Normalization (NNN).","We show an improvement on retrieval metrics in both text retrieval and image retrieval for all of the contrastive models that we tested (CLIP, BLIP, ALBEF, SigLIP, BEiT) and for both of the datasets that we used (MS-COCO and Flickr30k).","NNN requires a reference database, but does not require any training on this database, and can even increase the retrieval accuracy of a model after finetuning."],"url":"http://arxiv.org/abs/2410.24114v1"}
{"created":"2024-10-31 16:41:37","title":"DECT-2020 NR Link Distance Performance in Varying Environments: Models and Measurements","abstract":"Digital Enhanced Cordless Telecommunications 2020 New Radio (DECT-2020 NR) has garnered recognition as an alternative for cellular 5G technology in the internet of things industry. This paper presents a study centered around the analysis of the link distance performance in varying environments for DECT-2020 NR. The study extensively examines and analyzes received signal strength indicator and resulting path loss values in comparison with theoretical models, as well as packet success rates (SR) and signal-to-noise ratio against varying distances. The measurements show that with an SR of over 90%, an antenna height of 1.5 m, indoor link distances with a single device-to-device connection with 0 dBm transmission (TX) power can reach over 60 m in non-line-of-sight (NLOS) areas and up to 190 m in LOS areas with smaller -8 dBm TX power. Similarly, for outdoor use cases, link distances of over 600 m can be reached with +19 dBm TX power.","sentences":["Digital Enhanced Cordless Telecommunications 2020 New Radio (DECT-2020 NR) has garnered recognition as an alternative for cellular 5G technology in the internet of things industry.","This paper presents a study centered around the analysis of the link distance performance in varying environments for DECT-2020 NR.","The study extensively examines and analyzes received signal strength indicator and resulting path loss values in comparison with theoretical models, as well as packet success rates (SR) and signal-to-noise ratio against varying distances.","The measurements show that with an SR of over 90%, an antenna height of 1.5 m, indoor link distances with a single device-to-device connection with 0 dBm transmission (TX) power can reach over 60 m in non-line-of-sight (NLOS) areas and up to 190 m in LOS areas with smaller -8 dBm TX power.","Similarly, for outdoor use cases, link distances of over 600 m can be reached with +19 dBm TX power."],"url":"http://arxiv.org/abs/2410.24112v1"}
{"created":"2024-10-31 16:38:51","title":"Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers","abstract":"Decision Transformers have recently emerged as a new and compelling paradigm for offline Reinforcement Learning (RL), completing a trajectory in an autoregressive way. While improvements have been made to overcome initial shortcomings, online finetuning of decision transformers has been surprisingly under-explored. The widely adopted state-of-the-art Online Decision Transformer (ODT) still struggles when pretrained with low-reward offline data. In this paper, we theoretically analyze the online-finetuning of the decision transformer, showing that the commonly used Return-To-Go (RTG) that's far from the expected return hampers the online fine-tuning process. This problem, however, is well-addressed by the value function and advantage of standard RL algorithms. As suggested by our analysis, in our experiments, we hence find that simply adding TD3 gradients to the finetuning process of ODT effectively improves the online finetuning performance of ODT, especially if ODT is pretrained with low-reward offline data. These findings provide new directions to further improve decision transformers.","sentences":["Decision Transformers have recently emerged as a new and compelling paradigm for offline Reinforcement Learning (RL), completing a trajectory in an autoregressive way.","While improvements have been made to overcome initial shortcomings, online finetuning of decision transformers has been surprisingly under-explored.","The widely adopted state-of-the-art Online Decision Transformer (ODT) still struggles when pretrained with low-reward offline data.","In this paper, we theoretically analyze the online-finetuning of the decision transformer, showing that the commonly used Return-To-Go (RTG) that's far from the expected return hampers the online fine-tuning process.","This problem, however, is well-addressed by the value function and advantage of standard RL algorithms.","As suggested by our analysis, in our experiments, we hence find that simply adding TD3 gradients to the finetuning process of ODT effectively improves the online finetuning performance of ODT, especially if ODT is pretrained with low-reward offline data.","These findings provide new directions to further improve decision transformers."],"url":"http://arxiv.org/abs/2410.24108v1"}
{"created":"2024-10-31 16:37:25","title":"On Sampling Strategies for Spectral Model Sharding","abstract":"The problem of heterogeneous clients in federated learning has recently drawn a lot of attention. Spectral model sharding, i.e., partitioning the model parameters into low-rank matrices based on the singular value decomposition, has been one of the proposed solutions for more efficient on-device training in such settings. In this work, we present two sampling strategies for such sharding, obtained as solutions to specific optimization problems. The first produces unbiased estimators of the original weights, while the second aims to minimize the squared approximation error. We discuss how both of these estimators can be incorporated in the federated learning loop and practical considerations that arise during local training. Empirically, we demonstrate that both of these methods can lead to improved performance on various commonly used datasets.","sentences":["The problem of heterogeneous clients in federated learning has recently drawn a lot of attention.","Spectral model sharding, i.e., partitioning the model parameters into low-rank matrices based on the singular value decomposition, has been one of the proposed solutions for more efficient on-device training in such settings.","In this work, we present two sampling strategies for such sharding, obtained as solutions to specific optimization problems.","The first produces unbiased estimators of the original weights, while the second aims to minimize the squared approximation error.","We discuss how both of these estimators can be incorporated in the federated learning loop and practical considerations that arise during local training.","Empirically, we demonstrate that both of these methods can lead to improved performance on various commonly used datasets."],"url":"http://arxiv.org/abs/2410.24106v1"}
{"created":"2024-10-31 16:34:03","title":"Matchmaker: Self-Improving Large Language Model Programs for Schema Matching","abstract":"Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data. Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce -- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training. However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas. Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic or suffer from poor zero-shot performance. To this end, we propose Matchmaker - a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring. Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process. Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data.","sentences":["Schema matching -- the task of finding matches between attributes across disparate data sources with different tables and hierarchies -- is critical for creating interoperable machine learning (ML)-ready data.","Addressing this fundamental data-centric problem has wide implications, especially in domains like healthcare, finance and e-commerce -- but also has the potential to benefit ML models more generally, by increasing the data available for ML model training.","However, schema matching is a challenging ML task due to structural/hierarchical and semantic heterogeneity between different schemas.","Previous ML approaches to automate schema matching have either required significant labeled data for model training, which is often unrealistic or suffer from poor zero-shot performance.","To this end, we propose Matchmaker - a compositional language model program for schema matching, comprised of candidate generation, refinement and confidence scoring.","Matchmaker also self-improves in a zero-shot manner without the need for labeled demonstrations via a novel optimization approach, which constructs synthetic in-context demonstrations to guide the language model's reasoning process.","Empirically, we demonstrate on real-world medical schema matching benchmarks that Matchmaker outperforms previous ML-based approaches, highlighting its potential to accelerate data integration and interoperability of ML-ready data."],"url":"http://arxiv.org/abs/2410.24105v1"}
{"created":"2024-10-31 16:33:40","title":"Clustering to Minimize Cluster-Aware Norm Objectives","abstract":"We initiate the study of the following general clustering problem. We seek to partition a given set $P$ of data points into $k$ clusters by finding a set $X$ of $k$ centers and assigning each data point to one of the centers. The cost of a cluster, represented by a center $x\\in X$, is a monotone, symmetric norm $f$ (inner norm) of the vector of distances of points assigned to $x$. The goal is to minimize a norm $g$ (outer norm) of the vector of cluster costs. This problem, which we call $(f,g)$-Clustering, generalizes many fundamental clustering problems such as $k$-Center, $k$-Median , Min-Sum of Radii, and Min-Load $k$-Clustering . A recent line of research (Chakrabarty, Swamy [STOC'19]) studies norm objectives that are oblivious to the cluster structure such as $k$-Median and $k$-Center. In contrast, our problem models cluster-aware objectives including Min-Sum of Radii and Min-Load $k$-Clustering.   Our main results are as follows. First, we design a constant-factor approximation algorithm for $(\\textsf{top}_\\ell,\\mathcal{L}_1)$-Clustering where the inner norm ($\\textsf{top}_\\ell$) sums over the $\\ell$ largest distances. Second, we design a constant-factor approximation\\ for $(\\mathcal{L}_\\infty,\\textsf{Ord})$-Clustering where the outer norm is a convex combination of $\\textsf{top}_\\ell$ norms (ordered weighted norm).","sentences":["We initiate the study of the following general clustering problem.","We seek to partition a given set $P$ of data points into $k$ clusters by finding a set $X$ of $k$ centers and assigning each data point to one of the centers.","The cost of a cluster, represented by a center $x\\in X$, is a monotone, symmetric norm $f$ (inner norm) of the vector of distances of points assigned to $x$.","The goal is to minimize a norm $g$ (outer norm) of the vector of cluster costs.","This problem, which we call $(f,g)$-Clustering, generalizes many fundamental clustering problems such as $k$-Center, $k$-Median , Min-Sum of Radii, and Min-Load $k$-Clustering .","A recent line of research (Chakrabarty, Swamy [STOC'19]) studies norm objectives that are oblivious to the cluster structure such as $k$-Median and $k$-Center.","In contrast, our problem models cluster-aware objectives including Min-Sum of Radii and Min-Load $k$-Clustering.   ","Our main results are as follows.","First, we design a constant-factor approximation algorithm for $(\\textsf{top}_\\ell,\\mathcal{L}_1)$-Clustering where the inner norm ($\\textsf{top}_\\ell$) sums over the $\\ell$ largest distances.","Second, we design a constant-factor approximation\\ for $(\\mathcal{L}_\\infty,\\textsf{Ord})$-Clustering where the outer norm is a convex combination of $\\textsf{top}_\\ell$ norms (ordered weighted norm)."],"url":"http://arxiv.org/abs/2410.24104v1"}
{"created":"2024-10-31 16:30:08","title":"Benchmark Data Repositories for Better Benchmarking","abstract":"In machine learning research, it is common to evaluate algorithms via their performance on standard benchmark datasets. While a growing body of work establishes guidelines for -- and levies criticisms at -- data and benchmarking practices in machine learning, comparatively less attention has been paid to the data repositories where these datasets are stored, documented, and shared. In this paper, we analyze the landscape of these $\\textit{benchmark data repositories}$ and the role they can play in improving benchmarking. This role includes addressing issues with both datasets themselves (e.g., representational harms, construct validity) and the manner in which evaluation is carried out using such datasets (e.g., overemphasis on a few datasets and metrics, lack of reproducibility). To this end, we identify and discuss a set of considerations surrounding the design and use of benchmark data repositories, with a focus on improving benchmarking practices in machine learning.","sentences":["In machine learning research, it is common to evaluate algorithms via their performance on standard benchmark datasets.","While a growing body of work establishes guidelines for -- and levies criticisms at -- data and benchmarking practices in machine learning, comparatively less attention has been paid to the data repositories where these datasets are stored, documented, and shared.","In this paper, we analyze the landscape of these $\\textit{benchmark data repositories}$ and the role they can play in improving benchmarking.","This role includes addressing issues with both datasets themselves (e.g., representational harms, construct validity) and the manner in which evaluation is carried out using such datasets (e.g., overemphasis on a few datasets and metrics, lack of reproducibility).","To this end, we identify and discuss a set of considerations surrounding the design and use of benchmark data repositories, with a focus on improving benchmarking practices in machine learning."],"url":"http://arxiv.org/abs/2410.24100v1"}
{"created":"2024-10-31 16:28:33","title":"Progressive Safeguards for Safe and Model-Agnostic Reinforcement Learning","abstract":"In this paper we propose a formal, model-agnostic meta-learning framework for safe reinforcement learning. Our framework is inspired by how parents safeguard their children across a progression of increasingly riskier tasks, imparting a sense of safety that is carried over from task to task. We model this as a meta-learning process where each task is synchronized with a safeguard that monitors safety and provides a reward signal to the agent. The safeguard is implemented as a finite-state machine based on a safety specification; the reward signal is formally shaped around this specification. The safety specification and its corresponding safeguard can be arbitrarily complex and non-Markovian, which adds flexibility to the training process and explainability to the learned policy. The design of the safeguard is manual but it is high-level and model-agnostic, which gives rise to an end-to-end safe learning approach with wide applicability, from pixel-level game control to language model fine-tuning. Starting from a given set of safety specifications (tasks), we train a model such that it can adapt to new specifications using only a small number of training samples. This is made possible by our method for efficiently transferring safety bias between tasks, which effectively minimizes the number of safety violations. We evaluate our framework in a Minecraft-inspired Gridworld, a VizDoom game environment, and an LLM fine-tuning application. Agents trained with our approach achieve near-minimal safety violations, while baselines are shown to underperform.","sentences":["In this paper we propose a formal, model-agnostic meta-learning framework for safe reinforcement learning.","Our framework is inspired by how parents safeguard their children across a progression of increasingly riskier tasks, imparting a sense of safety that is carried over from task to task.","We model this as a meta-learning process where each task is synchronized with a safeguard that monitors safety and provides a reward signal to the agent.","The safeguard is implemented as a finite-state machine based on a safety specification; the reward signal is formally shaped around this specification.","The safety specification and its corresponding safeguard can be arbitrarily complex and non-Markovian, which adds flexibility to the training process and explainability to the learned policy.","The design of the safeguard is manual but it is high-level and model-agnostic, which gives rise to an end-to-end safe learning approach with wide applicability, from pixel-level game control to language model fine-tuning.","Starting from a given set of safety specifications (tasks), we train a model such that it can adapt to new specifications using only a small number of training samples.","This is made possible by our method for efficiently transferring safety bias between tasks, which effectively minimizes the number of safety violations.","We evaluate our framework in a Minecraft-inspired Gridworld, a VizDoom game environment, and an LLM fine-tuning application.","Agents trained with our approach achieve near-minimal safety violations, while baselines are shown to underperform."],"url":"http://arxiv.org/abs/2410.24096v1"}
{"created":"2024-10-31 16:22:53","title":"3D-ViTac: Learning Fine-Grained Manipulation with Visuo-Tactile Sensing","abstract":"Tactile and visual perception are both crucial for humans to perform fine-grained interactions with their environment. Developing similar multi-modal sensing capabilities for robots can significantly enhance and expand their manipulation skills. This paper introduces \\textbf{3D-ViTac}, a multi-modal sensing and learning system designed for dexterous bimanual manipulation. Our system features tactile sensors equipped with dense sensing units, each covering an area of 3$mm^2$. These sensors are low-cost and flexible, providing detailed and extensive coverage of physical contacts, effectively complementing visual information. To integrate tactile and visual data, we fuse them into a unified 3D representation space that preserves their 3D structures and spatial relationships. The multi-modal representation can then be coupled with diffusion policies for imitation learning. Through concrete hardware experiments, we demonstrate that even low-cost robots can perform precise manipulations and significantly outperform vision-only policies, particularly in safe interactions with fragile items and executing long-horizon tasks involving in-hand manipulation. Our project page is available at \\url{https://binghao-huang.github.io/3D-ViTac/}.","sentences":["Tactile and visual perception are both crucial for humans to perform fine-grained interactions with their environment.","Developing similar multi-modal sensing capabilities for robots can significantly enhance and expand their manipulation skills.","This paper introduces \\textbf{3D-ViTac}, a multi-modal sensing and learning system designed for dexterous bimanual manipulation.","Our system features tactile sensors equipped with dense sensing units, each covering an area of 3$mm^2$. These sensors are low-cost and flexible, providing detailed and extensive coverage of physical contacts, effectively complementing visual information.","To integrate tactile and visual data, we fuse them into a unified 3D representation space that preserves their 3D structures and spatial relationships.","The multi-modal representation can then be coupled with diffusion policies for imitation learning.","Through concrete hardware experiments, we demonstrate that even low-cost robots can perform precise manipulations and significantly outperform vision-only policies, particularly in safe interactions with fragile items and executing long-horizon tasks involving in-hand manipulation.","Our project page is available at \\url{https://binghao-huang.github.io/3D-ViTac/}."],"url":"http://arxiv.org/abs/2410.24091v1"}
{"created":"2024-10-31 16:22:23","title":"Sparsh: Self-supervised touch representations for vision-based tactile sensing","abstract":"In this work, we introduce general purpose touch representations for the increasingly accessible class of vision-based tactile sensors. Such sensors have led to many recent advances in robot manipulation as they markedly complement vision, yet solutions today often rely on task and sensor specific handcrafted perception models. Collecting real data at scale with task centric ground truth labels, like contact forces and slip, is a challenge further compounded by sensors of various form factor differing in aspects like lighting and gel markings. To tackle this we turn to self-supervised learning (SSL) that has demonstrated remarkable performance in computer vision. We present Sparsh, a family of SSL models that can support various vision-based tactile sensors, alleviating the need for custom labels through pre-training on 460k+ tactile images with masking and self-distillation in pixel and latent spaces. We also build TacBench, to facilitate standardized benchmarking across sensors and models, comprising of six tasks ranging from comprehending tactile properties to enabling physical perception and manipulation planning. In evaluations, we find that SSL pre-training for touch representation outperforms task and sensor-specific end-to-end training by 95.1% on average over TacBench, and Sparsh (DINO) and Sparsh (IJEPA) are the most competitive, indicating the merits of learning in latent space for tactile images. Project page: https://sparsh-ssl.github.io/","sentences":["In this work, we introduce general purpose touch representations for the increasingly accessible class of vision-based tactile sensors.","Such sensors have led to many recent advances in robot manipulation as they markedly complement vision, yet solutions today often rely on task and sensor specific handcrafted perception models.","Collecting real data at scale with task centric ground truth labels, like contact forces and slip, is a challenge further compounded by sensors of various form factor differing in aspects like lighting and gel markings.","To tackle this we turn to self-supervised learning (SSL) that has demonstrated remarkable performance in computer vision.","We present Sparsh, a family of SSL models that can support various vision-based tactile sensors, alleviating the need for custom labels through pre-training on 460k+ tactile images with masking and self-distillation in pixel and latent spaces.","We also build TacBench, to facilitate standardized benchmarking across sensors and models, comprising of six tasks ranging from comprehending tactile properties to enabling physical perception and manipulation planning.","In evaluations, we find that SSL pre-training for touch representation outperforms task and sensor-specific end-to-end training by 95.1% on average over TacBench, and Sparsh (DINO) and Sparsh (IJEPA) are the most competitive, indicating the merits of learning in latent space for tactile images.","Project page: https://sparsh-ssl.github.io/"],"url":"http://arxiv.org/abs/2410.24090v1"}
{"created":"2024-10-31 16:20:04","title":"In-Context Fine-Tuning for Time-Series Foundation Models","abstract":"Motivated by the recent success of time-series foundation models for zero-shot forecasting, we present a methodology for $\\textit{in-context fine-tuning}$ of a time-series foundation model. In particular, we design a pretrained foundation model that can be prompted (at inference time) with multiple time-series examples, in order to forecast a target time-series into the future. Our foundation model is specifically trained to utilize examples from multiple related time-series in its context window (in addition to the history of the target time-series) to help it adapt to the specific distribution of the target domain at inference time. We show that such a foundation model that uses in-context examples at inference time can obtain much better performance on popular forecasting benchmarks compared to supervised deep learning methods, statistical models, as well as other time-series foundation models. Interestingly, our in-context fine-tuning approach even rivals the performance of a foundation model that is explicitly fine-tuned on the target domain.","sentences":["Motivated by the recent success of time-series foundation models for zero-shot forecasting, we present a methodology for $\\textit{in-context fine-tuning}$ of a time-series foundation model.","In particular, we design a pretrained foundation model that can be prompted (at inference time) with multiple time-series examples, in order to forecast a target time-series into the future.","Our foundation model is specifically trained to utilize examples from multiple related time-series in its context window (in addition to the history of the target time-series) to help it adapt to the specific distribution of the target domain at inference time.","We show that such a foundation model that uses in-context examples at inference time can obtain much better performance on popular forecasting benchmarks compared to supervised deep learning methods, statistical models, as well as other time-series foundation models.","Interestingly, our in-context fine-tuning approach even rivals the performance of a foundation model that is explicitly fine-tuned on the target domain."],"url":"http://arxiv.org/abs/2410.24087v1"}
{"created":"2024-10-31 16:17:53","title":"Self-supervised Learning for Glass Property Screening","abstract":"This paper presents a novel approach to glass composition screening through a self-supervised learning framework, addressing the challenges posed by glass transition temperature (Tg) prediction. Given the critical role of Tg in determining glass performance across various applications, we reformulate the composition screening task as a classification problem, allowing for direct prediction of whether specific compositional samples fall within a designated Tg range. Our model leverages advanced self-supervised learning techniques to optimize for the area under the curve (AUC) metric, mitigating the adverse effects of noise and class imbalances in training data. We introduce a data augmentation method based on the law of large numbers to enhance sample size and improve noise robustness. Additionally, our DeepGlassNet backbone encoder captures intricate second-order and higher-order interactions among components, providing insights into their collective impact on glass properties. We validate our approach using data from the SciGlass database, demonstrating its capability to accurately predict Tg for compositions within the specified range, while also exploring extrapolation to untested samples. This work not only enhances the accuracy of glass composition screening but also offers scalable solutions applicable to material screening across various fields, thereby advancing the development of novel materials.","sentences":["This paper presents a novel approach to glass composition screening through a self-supervised learning framework, addressing the challenges posed by glass transition temperature (Tg) prediction.","Given the critical role of Tg in determining glass performance across various applications, we reformulate the composition screening task as a classification problem, allowing for direct prediction of whether specific compositional samples fall within a designated Tg range.","Our model leverages advanced self-supervised learning techniques to optimize for the area under the curve (AUC) metric, mitigating the adverse effects of noise and class imbalances in training data.","We introduce a data augmentation method based on the law of large numbers to enhance sample size and improve noise robustness.","Additionally, our DeepGlassNet backbone encoder captures intricate second-order and higher-order interactions among components, providing insights into their collective impact on glass properties.","We validate our approach using data from the SciGlass database, demonstrating its capability to accurately predict Tg for compositions within the specified range, while also exploring extrapolation to untested samples.","This work not only enhances the accuracy of glass composition screening but also offers scalable solutions applicable to material screening across various fields, thereby advancing the development of novel materials."],"url":"http://arxiv.org/abs/2410.24083v1"}
{"created":"2024-10-31 16:17:11","title":"An Efficient Dynamic Resource Allocation Framework for Evolutionary Bilevel Optimization","abstract":"Bilevel optimization problems are characterized by an interactive hierarchical structure, where the upper level seeks to optimize its strategy while simultaneously considering the response of the lower level. Evolutionary algorithms are commonly used to solve complex bilevel problems in practical scenarios, but they face significant resource consumption challenges due to the nested structure imposed by the implicit lower-level optimality condition. This challenge becomes even more pronounced as problem dimensions increase. Although recent methods have enhanced bilevel convergence through task-level knowledge sharing, further efficiency improvements are still hindered by redundant lower-level iterations that consume excessive resources while generating unpromising solutions. To overcome this challenge, this paper proposes an efficient dynamic resource allocation framework for evolutionary bilevel optimization, named DRC-BLEA. Compared to existing approaches, DRC-BLEA introduces a novel competitive quasi-parallel paradigm, in which multiple lower-level optimization tasks, derived from different upper-level individuals, compete for resources. A continuously updated selection probability is used to prioritize execution opportunities to promising tasks. Additionally, a cooperation mechanism is integrated within the competitive framework to further enhance efficiency and prevent premature convergence. Experimental results compared with chosen state-of-the-art algorithms demonstrate the effectiveness of the proposed method. Specifically, DRC-BLEA achieves competitive accuracy across diverse problem sets and real-world scenarios, while significantly reducing the number of function evaluations and overall running time.","sentences":["Bilevel optimization problems are characterized by an interactive hierarchical structure, where the upper level seeks to optimize its strategy while simultaneously considering the response of the lower level.","Evolutionary algorithms are commonly used to solve complex bilevel problems in practical scenarios, but they face significant resource consumption challenges due to the nested structure imposed by the implicit lower-level optimality condition.","This challenge becomes even more pronounced as problem dimensions increase.","Although recent methods have enhanced bilevel convergence through task-level knowledge sharing, further efficiency improvements are still hindered by redundant lower-level iterations that consume excessive resources while generating unpromising solutions.","To overcome this challenge, this paper proposes an efficient dynamic resource allocation framework for evolutionary bilevel optimization, named DRC-BLEA.","Compared to existing approaches, DRC-BLEA introduces a novel competitive quasi-parallel paradigm, in which multiple lower-level optimization tasks, derived from different upper-level individuals, compete for resources.","A continuously updated selection probability is used to prioritize execution opportunities to promising tasks.","Additionally, a cooperation mechanism is integrated within the competitive framework to further enhance efficiency and prevent premature convergence.","Experimental results compared with chosen state-of-the-art algorithms demonstrate the effectiveness of the proposed method.","Specifically, DRC-BLEA achieves competitive accuracy across diverse problem sets and real-world scenarios, while significantly reducing the number of function evaluations and overall running time."],"url":"http://arxiv.org/abs/2410.24081v1"}
{"created":"2024-10-31 16:16:51","title":"Graph Learning for Numeric Planning","abstract":"Graph learning is naturally well suited for use in symbolic, object-centric planning due to its ability to exploit relational structures exhibited in planning domains and to take as input planning instances with arbitrary numbers of objects. Numeric planning is an extension of symbolic planning in which states may now also exhibit numeric variables. In this work, we propose data-efficient and interpretable machine learning models for learning to solve numeric planning tasks. This involves constructing a new graph kernel for graphs with both continuous and categorical attributes, as well as new optimisation methods for learning heuristic functions for numeric planning. Experiments show that our graph kernels are vastly more efficient and generalise better than graph neural networks for numeric planning, and also yield competitive coverage performance compared to domain-independent numeric planners. Code is available at https://github.com/DillonZChen/goose","sentences":["Graph learning is naturally well suited for use in symbolic, object-centric planning due to its ability to exploit relational structures exhibited in planning domains and to take as input planning instances with arbitrary numbers of objects.","Numeric planning is an extension of symbolic planning in which states may now also exhibit numeric variables.","In this work, we propose data-efficient and interpretable machine learning models for learning to solve numeric planning tasks.","This involves constructing a new graph kernel for graphs with both continuous and categorical attributes, as well as new optimisation methods for learning heuristic functions for numeric planning.","Experiments show that our graph kernels are vastly more efficient and generalise better than graph neural networks for numeric planning, and also yield competitive coverage performance compared to domain-independent numeric planners.","Code is available at https://github.com/DillonZChen/goose"],"url":"http://arxiv.org/abs/2410.24080v1"}
{"created":"2024-10-31 16:16:18","title":"Hamiltonian Monte Carlo Inference of Marginalized Linear Mixed-Effects Models","abstract":"Bayesian reasoning in linear mixed-effects models (LMMs) is challenging and often requires advanced sampling techniques like Markov chain Monte Carlo (MCMC). A common approach is to write the model in a probabilistic programming language and then sample via Hamiltonian Monte Carlo (HMC). However, there are many ways a user can transform a model that make inference more or less efficient. In particular, marginalizing some variables can greatly improve inference but is difficult for users to do manually. We develop an algorithm to easily marginalize random effects in LMMs. A naive approach introduces cubic time operations within an inference algorithm like HMC, but we reduce the running time to linear using fast linear algebra techniques. We show that marginalization is always beneficial when applicable and highlight improvements in various models, especially ones from cognitive sciences.","sentences":["Bayesian reasoning in linear mixed-effects models (LMMs) is challenging and often requires advanced sampling techniques like Markov chain Monte Carlo (MCMC).","A common approach is to write the model in a probabilistic programming language and then sample via Hamiltonian Monte Carlo (HMC).","However, there are many ways a user can transform a model that make inference more or less efficient.","In particular, marginalizing some variables can greatly improve inference but is difficult for users to do manually.","We develop an algorithm to easily marginalize random effects in LMMs.","A naive approach introduces cubic time operations within an inference algorithm like HMC, but we reduce the running time to linear using fast linear algebra techniques.","We show that marginalization is always beneficial when applicable and highlight improvements in various models, especially ones from cognitive sciences."],"url":"http://arxiv.org/abs/2410.24079v1"}
{"created":"2024-10-31 16:13:55","title":"Identifying Spatio-Temporal Drivers of Extreme Events","abstract":"The spatio-temporal relations of impacts of extreme events and their drivers in climate data are not fully understood and there is a need of machine learning approaches to identify such spatio-temporal relations from data. The task, however, is very challenging since there are time delays between extremes and their drivers, and the spatial response of such drivers is inhomogeneous. In this work, we propose a first approach and benchmarks to tackle this challenge. Our approach is trained end-to-end to predict spatio-temporally extremes and spatio-temporally drivers in the physical input variables jointly. By enforcing the network to predict extremes from spatio-temporal binary masks of identified drivers, the network successfully identifies drivers that are correlated with extremes. We evaluate our approach on three newly created synthetic benchmarks, where two of them are based on remote sensing or reanalysis climate data, and on two real-world reanalysis datasets. The source code and datasets are publicly available at the project page https://hakamshams.github.io/IDE.","sentences":["The spatio-temporal relations of impacts of extreme events and their drivers in climate data are not fully understood and there is a need of machine learning approaches to identify such spatio-temporal relations from data.","The task, however, is very challenging since there are time delays between extremes and their drivers, and the spatial response of such drivers is inhomogeneous.","In this work, we propose a first approach and benchmarks to tackle this challenge.","Our approach is trained end-to-end to predict spatio-temporally extremes and spatio-temporally drivers in the physical input variables jointly.","By enforcing the network to predict extremes from spatio-temporal binary masks of identified drivers, the network successfully identifies drivers that are correlated with extremes.","We evaluate our approach on three newly created synthetic benchmarks, where two of them are based on remote sensing or reanalysis climate data, and on two real-world reanalysis datasets.","The source code and datasets are publicly available at the project page https://hakamshams.github.io/IDE."],"url":"http://arxiv.org/abs/2410.24075v1"}
{"created":"2024-10-31 16:07:22","title":"Local Linearity: the Key for No-regret Reinforcement Learning in Continuous MDPs","abstract":"Achieving the no-regret property for Reinforcement Learning (RL) problems in continuous state and action-space environments is one of the major open problems in the field. Existing solutions either work under very specific assumptions or achieve bounds that are vacuous in some regimes. Furthermore, many structural assumptions are known to suffer from a provably unavoidable exponential dependence on the time horizon $H$ in the regret, which makes any possible solution unfeasible in practice. In this paper, we identify local linearity as the feature that makes Markov Decision Processes (MDPs) both learnable (sublinear regret) and feasible (regret that is polynomial in $H$). We define a novel MDP representation class, namely Locally Linearizable MDPs, generalizing other representation classes like Linear MDPs and MDPS with low inherent Belmman error. Then, i) we introduce Cinderella, a no-regret algorithm for this general representation class, and ii) we show that all known learnable and feasible MDP families are representable in this class. We first show that all known feasible MDPs belong to a family that we call Mildly Smooth MDPs. Then, we show how any mildly smooth MDP can be represented as a Locally Linearizable MDP by an appropriate choice of representation. This way, Cinderella is shown to achieve state-of-the-art regret bounds for all previously known (and some new) continuous MDPs for which RL is learnable and feasible.","sentences":["Achieving the no-regret property for Reinforcement Learning (RL) problems in continuous state and action-space environments is one of the major open problems in the field.","Existing solutions either work under very specific assumptions or achieve bounds that are vacuous in some regimes.","Furthermore, many structural assumptions are known to suffer from a provably unavoidable exponential dependence on the time horizon $H$ in the regret, which makes any possible solution unfeasible in practice.","In this paper, we identify local linearity as the feature that makes Markov Decision Processes (MDPs) both learnable (sublinear regret) and feasible (regret that is polynomial in $H$).","We define a novel MDP representation class, namely Locally Linearizable MDPs, generalizing other representation classes like Linear MDPs and MDPS with low inherent Belmman error.","Then, i) we introduce Cinderella, a no-regret algorithm for this general representation class, and ii) we show that all known learnable and feasible MDP families are representable in this class.","We first show that all known feasible MDPs belong to a family that we call Mildly Smooth MDPs.","Then, we show how any mildly smooth MDP can be represented as a Locally Linearizable MDP by an appropriate choice of representation.","This way, Cinderella is shown to achieve state-of-the-art regret bounds for all previously known (and some new) continuous MDPs for which RL is learnable and feasible."],"url":"http://arxiv.org/abs/2410.24071v1"}
{"created":"2024-10-31 16:07:21","title":"Dynamical similarity analysis uniquely captures how computations develop in RNNs","abstract":"Methods for analyzing representations in neural systems are increasingly popular tools in neuroscience and mechanistic interpretability. Measures comparing neural activations across conditions, architectures, and species give scalable ways to understand information transformation within different neural networks. However, recent findings show that some metrics respond to spurious signals, leading to misleading results. Establishing benchmark test cases is thus essential for identifying the most reliable metric and potential improvements. We propose that compositional learning in recurrent neural networks (RNNs) can provide a test case for dynamical representation alignment metrics. Implementing this case allows us to evaluate if metrics can identify representations that develop throughout learning and determine if representations identified by metrics reflect the network's actual computations. Building both attractor and RNN based test cases, we show that the recently proposed Dynamical Similarity Analysis (DSA) is more noise robust and reliably identifies behaviorally relevant representations compared to prior metrics (Procrustes, CKA). We also demonstrate how such test cases can extend beyond metric evaluation to study new architectures. Specifically, testing DSA in modern (Mamba) state space models suggests that these models, unlike RNNs, may not require changes in recurrent dynamics due to their expressive hidden states. Overall, we develop test cases that showcase how DSA's enhanced ability to detect dynamical motifs makes it highly effective for identifying ongoing computations in RNNs and revealing how networks learn tasks.","sentences":["Methods for analyzing representations in neural systems are increasingly popular tools in neuroscience and mechanistic interpretability.","Measures comparing neural activations across conditions, architectures, and species give scalable ways to understand information transformation within different neural networks.","However, recent findings show that some metrics respond to spurious signals, leading to misleading results.","Establishing benchmark test cases is thus essential for identifying the most reliable metric and potential improvements.","We propose that compositional learning in recurrent neural networks (RNNs) can provide a test case for dynamical representation alignment metrics.","Implementing this case allows us to evaluate if metrics can identify representations that develop throughout learning and determine if representations identified by metrics reflect the network's actual computations.","Building both attractor and RNN based test cases, we show that the recently proposed Dynamical Similarity Analysis (DSA) is more noise robust and reliably identifies behaviorally relevant representations compared to prior metrics (Procrustes, CKA).","We also demonstrate how such test cases can extend beyond metric evaluation to study new architectures.","Specifically, testing DSA in modern (Mamba) state space models suggests that these models, unlike RNNs, may not require changes in recurrent dynamics due to their expressive hidden states.","Overall, we develop test cases that showcase how DSA's enhanced ability to detect dynamical motifs makes it highly effective for identifying ongoing computations in RNNs and revealing how networks learn tasks."],"url":"http://arxiv.org/abs/2410.24070v1"}
{"created":"2024-10-31 15:58:35","title":"HarvestTech agriculture cooperatives: Beneficiaries and compensations","abstract":"Agricultural industries face increasing pressure to optimize efficiency and reduce costs in a competitive and resource-constrained global market. As firms seek innovative ways to enhance productivity, cooperative strategies have emerged as a promising solution to address these challenges. In this context, game theory provides a powerful framework for analyzing and structuring such cooperative efforts, ensuring that each firm's contribution is fairly rewarded. This paper presents an innovative approach to address challenges in agricultural crop processing through inter-firm cooperation. A new class of totally balanced games is introduced, which models the strategic interactions among companies processing agricultural products. The objective is to identify profit allocations that fairly compensate firms contributing to cost reduction and surplus processing for others. To achieve this, the allocations resulting from each type of compensation will be thoroughly examined, and a coalitionally stable compensation procedure will be established. The study demonstrates the feasibility and effectiveness of cooperative strategies for optimizing agricultural processes. Lastly, the findings will be applied to a case study.","sentences":["Agricultural industries face increasing pressure to optimize efficiency and reduce costs in a competitive and resource-constrained global market.","As firms seek innovative ways to enhance productivity, cooperative strategies have emerged as a promising solution to address these challenges.","In this context, game theory provides a powerful framework for analyzing and structuring such cooperative efforts, ensuring that each firm's contribution is fairly rewarded.","This paper presents an innovative approach to address challenges in agricultural crop processing through inter-firm cooperation.","A new class of totally balanced games is introduced, which models the strategic interactions among companies processing agricultural products.","The objective is to identify profit allocations that fairly compensate firms contributing to cost reduction and surplus processing for others.","To achieve this, the allocations resulting from each type of compensation will be thoroughly examined, and a coalitionally stable compensation procedure will be established.","The study demonstrates the feasibility and effectiveness of cooperative strategies for optimizing agricultural processes.","Lastly, the findings will be applied to a case study."],"url":"http://arxiv.org/abs/2410.24062v1"}
{"created":"2024-10-31 15:57:04","title":"Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure","abstract":"In this work, we study the generalizability of diffusion models by looking into the hidden properties of the learned score functions, which are essentially a series of deep denoisers trained on various noise levels. We observe that as diffusion models transition from memorization to generalization, their corresponding nonlinear diffusion denoisers exhibit increasing linearity. This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers. Surprisingly, these linear denoisers are approximately the optimal denoisers for a multivariate Gaussian distribution characterized by the empirical mean and covariance of the training dataset. This finding implies that diffusion models have the inductive bias towards capturing and utilizing the Gaussian structure (covariance information) of the training dataset for data generation. We empirically demonstrate that this inductive bias is a unique property of diffusion models in the generalization regime, which becomes increasingly evident when the model's capacity is relatively small compared to the training dataset size. In the case that the model is highly overparameterized, this inductive bias emerges during the initial training phases before the model fully memorizes its training data. Our study provides crucial insights into understanding the notable strong generalization phenomenon recently observed in real-world diffusion models.","sentences":["In this work, we study the generalizability of diffusion models by looking into the hidden properties of the learned score functions, which are essentially a series of deep denoisers trained on various noise levels.","We observe that as diffusion models transition from memorization to generalization, their corresponding nonlinear diffusion denoisers exhibit increasing linearity.","This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers.","Surprisingly, these linear denoisers are approximately the optimal denoisers for a multivariate Gaussian distribution characterized by the empirical mean and covariance of the training dataset.","This finding implies that diffusion models have the inductive bias towards capturing and utilizing the Gaussian structure (covariance information) of the training dataset for data generation.","We empirically demonstrate that this inductive bias is a unique property of diffusion models in the generalization regime, which becomes increasingly evident when the model's capacity is relatively small compared to the training dataset size.","In the case that the model is highly overparameterized, this inductive bias emerges during the initial training phases before the model fully memorizes its training data.","Our study provides crucial insights into understanding the notable strong generalization phenomenon recently observed in real-world diffusion models."],"url":"http://arxiv.org/abs/2410.24060v1"}
{"created":"2024-10-31 15:56:50","title":"Identifying General Mechanism Shifts in Linear Causal Representations","abstract":"We consider the linear causal representation learning setting where we observe a linear mixing of $d$ unknown latent factors, which follow a linear structural causal model. Recent work has shown that it is possible to recover the latent factors as well as the underlying structural causal model over them, up to permutation and scaling, provided that we have at least $d$ environments, each of which corresponds to perfect interventions on a single latent node (factor). After this powerful result, a key open problem faced by the community has been to relax these conditions: allow for coarser than perfect single-node interventions, and allow for fewer than $d$ of them, since the number of latent factors $d$ could be very large. In this work, we consider precisely such a setting, where we allow a smaller than $d$ number of environments, and also allow for very coarse interventions that can very coarsely \\textit{change the entire causal graph over the latent factors}. On the flip side, we relax what we wish to extract to simply the \\textit{list of nodes that have shifted between one or more environments}. We provide a surprising identifiability result that it is indeed possible, under some very mild standard assumptions, to identify the set of shifted nodes. Our identifiability proof moreover is a constructive one: we explicitly provide necessary and sufficient conditions for a node to be a shifted node, and show that we can check these conditions given observed data. Our algorithm lends itself very naturally to the sample setting where instead of just interventional distributions, we are provided datasets of samples from each of these distributions. We corroborate our results on both synthetic experiments as well as an interesting psychometric dataset. The code can be found at https://github.com/TianyuCodings/iLCS.","sentences":["We consider the linear causal representation learning setting where we observe a linear mixing of $d$ unknown latent factors, which follow a linear structural causal model.","Recent work has shown that it is possible to recover the latent factors as well as the underlying structural causal model over them, up to permutation and scaling, provided that we have at least $d$ environments, each of which corresponds to perfect interventions on a single latent node (factor).","After this powerful result, a key open problem faced by the community has been to relax these conditions: allow for coarser than perfect single-node interventions, and allow for fewer than $d$ of them, since the number of latent factors $d$ could be very large.","In this work, we consider precisely such a setting, where we allow a smaller than $d$ number of environments, and also allow for very coarse interventions that can very coarsely \\textit{change the entire causal graph over the latent factors}.","On the flip side, we relax what we wish to extract to simply the \\textit{list of nodes that have shifted between one or more environments}.","We provide a surprising identifiability result that it is indeed possible, under some very mild standard assumptions, to identify the set of shifted nodes.","Our identifiability proof moreover is a constructive one: we explicitly provide necessary and sufficient conditions for a node to be a shifted node, and show that we can check these conditions given observed data.","Our algorithm lends itself very naturally to the sample setting where instead of just interventional distributions, we are provided datasets of samples from each of these distributions.","We corroborate our results on both synthetic experiments as well as an interesting psychometric dataset.","The code can be found at https://github.com/TianyuCodings/iLCS."],"url":"http://arxiv.org/abs/2410.24059v1"}
{"created":"2024-10-31 15:48:36","title":"Advanced Predictive Quality Assessment for Ultrasonic Additive Manufacturing with Deep Learning Model","abstract":"Ultrasonic Additive Manufacturing (UAM) employs ultrasonic welding to bond similar or dissimilar metal foils to a substrate, resulting in solid, consolidated metal components. However, certain processing conditions can lead to inter-layer defects, affecting the final product's quality. This study develops a method to monitor in-process quality using deep learning-based convolutional neural networks (CNNs). The CNN models were evaluated on their ability to classify samples with and without embedded thermocouples across five power levels (300W, 600W, 900W, 1200W, 1500W) using thermal images with supervised labeling. Four distinct CNN classification models were created for different scenarios including without (baseline) and with thermocouples, only without thermocouples across power levels, only with thermocouples across power levels, and combined without and with thermocouples across power levels. The models achieved 98.29% accuracy on combined baseline and thermocouple images, 97.10% for baseline images across power levels, 97.43% for thermocouple images, and 97.27% for both types across power levels. The high accuracy, above 97%, demonstrates the system's effectiveness in identifying and classifying conditions within the UAM process, providing a reliable tool for quality assurance and process control in manufacturing environments.","sentences":["Ultrasonic Additive Manufacturing (UAM) employs ultrasonic welding to bond similar or dissimilar metal foils to a substrate, resulting in solid, consolidated metal components.","However, certain processing conditions can lead to inter-layer defects, affecting the final product's quality.","This study develops a method to monitor in-process quality using deep learning-based convolutional neural networks (CNNs).","The CNN models were evaluated on their ability to classify samples with and without embedded thermocouples across five power levels (300W, 600W, 900W, 1200W, 1500W) using thermal images with supervised labeling.","Four distinct CNN classification models were created for different scenarios including without (baseline) and with thermocouples, only without thermocouples across power levels, only with thermocouples across power levels, and combined without and with thermocouples across power levels.","The models achieved 98.29% accuracy on combined baseline and thermocouple images, 97.10% for baseline images across power levels, 97.43% for thermocouple images, and 97.27% for both types across power levels.","The high accuracy, above 97%, demonstrates the system's effectiveness in identifying and classifying conditions within the UAM process, providing a reliable tool for quality assurance and process control in manufacturing environments."],"url":"http://arxiv.org/abs/2410.24055v1"}
{"created":"2024-10-31 15:47:59","title":"Unifying Sequent Systems for G\u00f6del-L\u00f6b Provability Logic via Syntactic Transformations","abstract":"We demonstrate the inter-translatability of proofs between the most prominent sequent-based formalisms for G\\\"odel-L\\\"ob provability logic. In particular, we consider Sambin and Valentini's sequent system GLseq, Shamkanov's non-wellfounded and cyclic sequent systems GL$\\infty$ and GLcirc, Poggiolesi's tree-hypersequent system CSGL, and Negri's labeled sequent system G3GL. Shamkanov showed how to transform proofs between GLseq, GL$\\infty$, and GLcirc, and Gor\\'e and Ramanayake showed how to transform proofs between CSGL and G3GL, however, the exact nature of proof transformations between the former three systems and the latter two systems has remained an open problem. We solve this open problem by showing how to restructure tree-hypersequent proofs into an end-active form and introduce a novel linearization technique that transforms such proofs into linear nested sequent proofs. As a result, we obtain a new proof-theoretic tool for extracting linear nested sequent systems from tree-hypersequent systems, which yields the first cut-free linear nested sequent calculus LNGL for G\\\"odel-L\\\"ob provability logic. We show how to transform proofs in LNGL into a certain normal form, where proofs repeat in stages of modal and local rule applications, and which are translatable into GLseq and G3GL proofs. These new syntactic transformations, together with those mentioned above, establish full proof-theoretic correspondences between GLseq, GL$\\infty$, GLcirc, CSGL, G3GL, and LNGL while also giving (to the best of the author's knowledge) the first constructive proof mappings between structural (viz. labeled, tree-hypersequent, and linear nested sequent) systems and a cyclic sequent system.","sentences":["We demonstrate the inter-translatability of proofs between the most prominent sequent-based formalisms for G\\\"odel-L\\\"ob provability logic.","In particular, we consider Sambin and Valentini's sequent system GLseq, Shamkanov's non-wellfounded and cyclic sequent systems GL$\\infty$ and GLcirc, Poggiolesi's tree-hypersequent system CSGL, and Negri's labeled sequent system G3GL.","Shamkanov showed how to transform proofs between GLseq, GL$\\infty$, and GLcirc, and Gor\\'e and Ramanayake showed how to transform proofs between CSGL and G3GL, however, the exact nature of proof transformations between the former three systems and the latter two systems has remained an open problem.","We solve this open problem by showing how to restructure tree-hypersequent proofs into an end-active form and introduce a novel linearization technique that transforms such proofs into linear nested sequent proofs.","As a result, we obtain a new proof-theoretic tool for extracting linear nested sequent systems from tree-hypersequent systems, which yields the first cut-free linear nested sequent calculus LNGL for G\\\"odel-L\\\"ob provability logic.","We show how to transform proofs in LNGL into a certain normal form, where proofs repeat in stages of modal and local rule applications, and which are translatable into GLseq and G3GL proofs.","These new syntactic transformations, together with those mentioned above, establish full proof-theoretic correspondences between GLseq, GL$\\infty$, GLcirc, CSGL, G3GL, and LNGL while also giving (to the best of the author's knowledge) the first constructive proof mappings between structural (viz. labeled, tree-hypersequent, and linear nested sequent) systems and a cyclic sequent system."],"url":"http://arxiv.org/abs/2410.24053v1"}
{"created":"2024-10-31 15:46:10","title":"A Visual Case Study of the Training Dynamics in Neural Networks","abstract":"This paper introduces a visual sandbox designed to explore the training dynamics of a small-scale transformer model, with the embedding dimension constrained to $d=2$. This restriction allows for a comprehensive two-dimensional visualization of each layer's dynamics. Through this approach, we gain insights into training dynamics, circuit transferability, and the causes of loss spikes, including those induced by the high curvature of normalization layers. We propose strategies to mitigate these spikes, demonstrating how good visualization facilitates the design of innovative ideas of practical interest. Additionally, we believe our sandbox could assist theoreticians in assessing essential training dynamics mechanisms and integrating them into future theories. The code is available at https://github.com/facebookresearch/pal.","sentences":["This paper introduces a visual sandbox designed to explore the training dynamics of a small-scale transformer model, with the embedding dimension constrained to $d=2$. This restriction allows for a comprehensive two-dimensional visualization of each layer's dynamics.","Through this approach, we gain insights into training dynamics, circuit transferability, and the causes of loss spikes, including those induced by the high curvature of normalization layers.","We propose strategies to mitigate these spikes, demonstrating how good visualization facilitates the design of innovative ideas of practical interest.","Additionally, we believe our sandbox could assist theoreticians in assessing essential training dynamics mechanisms and integrating them into future theories.","The code is available at https://github.com/facebookresearch/pal."],"url":"http://arxiv.org/abs/2410.24050v1"}
{"created":"2024-10-31 15:45:23","title":"Desert Camels and Oil Sheikhs: Arab-Centric Red Teaming of Frontier LLMs","abstract":"Large language models (LLMs) are widely used but raise ethical concerns due to embedded social biases. This study examines LLM biases against Arabs versus Westerners across eight domains, including women's rights, terrorism, and anti-Semitism and assesses model resistance to perpetuating these biases. To this end, we create two datasets: one to evaluate LLM bias toward Arabs versus Westerners and another to test model safety against prompts that exaggerate negative traits (\"jailbreaks\"). We evaluate six LLMs -- GPT-4, GPT-4o, LlaMA 3.1 (8B & 405B), Mistral 7B, and Claude 3.5 Sonnet. We find 79% of cases displaying negative biases toward Arabs, with LlaMA 3.1-405B being the most biased. Our jailbreak tests reveal GPT-4o as the most vulnerable, despite being an optimized version, followed by LlaMA 3.1-8B and Mistral 7B. All LLMs except Claude exhibit attack success rates above 87% in three categories. We also find Claude 3.5 Sonnet the safest, but it still displays biases in seven of eight categories. Despite being an optimized version of GPT4, We find GPT-4o to be more prone to biases and jailbreaks, suggesting optimization flaws. Our findings underscore the pressing need for more robust bias mitigation strategies and strengthened security measures in LLMs.","sentences":["Large language models (LLMs) are widely used but raise ethical concerns due to embedded social biases.","This study examines LLM biases against Arabs versus Westerners across eight domains, including women's rights, terrorism, and anti-Semitism and assesses model resistance to perpetuating these biases.","To this end, we create two datasets: one to evaluate LLM bias toward Arabs versus Westerners and another to test model safety against prompts that exaggerate negative traits (\"jailbreaks\").","We evaluate six LLMs -- GPT-4, GPT-4o, LlaMA 3.1 (8B & 405B), Mistral 7B, and Claude 3.5 Sonnet.","We find 79% of cases displaying negative biases toward Arabs, with LlaMA 3.1-405B being the most biased.","Our jailbreak tests reveal GPT-4o as the most vulnerable, despite being an optimized version, followed by LlaMA 3.1-8B and Mistral 7B. All LLMs except Claude exhibit attack success rates above 87% in three categories.","We also find Claude 3.5 Sonnet the safest, but it still displays biases in seven of eight categories.","Despite being an optimized version of GPT4, We find GPT-4o to be more prone to biases and jailbreaks, suggesting optimization flaws.","Our findings underscore the pressing need for more robust bias mitigation strategies and strengthened security measures in LLMs."],"url":"http://arxiv.org/abs/2410.24049v1"}
{"created":"2024-10-31 15:35:41","title":"Efficient Satellite-Ground Interconnection Design for Low-orbit Mega-Constellation Topology","abstract":"The low-orbit mega-constellation network (LMCN) is an important part of the space-air-ground integrated network system. An effective satellite-ground interconnection design can result in a stable constellation topology for LMCNs. A naive solution is accessing the satellite with the longest remaining service time (LRST), which is widely used in previous designs. The Coordinated Satellite-Ground Interconnecting (CSGI), the state-of-the-art algorithm, coordinates the establishment of ground-satellite links (GSLs). Compared with existing solutions, it reduces latency by 19% and jitter by 70% on average. However, CSGI only supports the scenario where terminals access only one satellite and cannot fully utilize the multi-access capabilities of terminals. Additionally, CSGI's high computational complexity poses deployment challenges. To overcome these problems, we propose the Classification-based Longest Remaining Service Time (C-LRST) algorithm. C-LRST supports the actual scenario with multi-access capabilities. It adds optional paths during routing with low computational complexity, improving end-to-end communications quality. We conduct our 1000s simulation from Brazil to Lithuania on the open-source platform Hypatia. Experiment results show that compared with CSGI, C-LRST reduces the latency and increases the throughput by approximately 60% and 40%, respectively. In addition, C-LRST's GSL switching number is 14, whereas CSGI is 23. C-LRST has better link stability than CSGI.","sentences":["The low-orbit mega-constellation network (LMCN) is an important part of the space-air-ground integrated network system.","An effective satellite-ground interconnection design can result in a stable constellation topology for LMCNs.","A naive solution is accessing the satellite with the longest remaining service time (LRST), which is widely used in previous designs.","The Coordinated Satellite-Ground Interconnecting (CSGI), the state-of-the-art algorithm, coordinates the establishment of ground-satellite links (GSLs).","Compared with existing solutions, it reduces latency by 19% and jitter by 70% on average.","However, CSGI only supports the scenario where terminals access only one satellite and cannot fully utilize the multi-access capabilities of terminals.","Additionally, CSGI's high computational complexity poses deployment challenges.","To overcome these problems, we propose the Classification-based Longest Remaining Service Time (C-LRST) algorithm.","C-LRST supports the actual scenario with multi-access capabilities.","It adds optional paths during routing with low computational complexity, improving end-to-end communications quality.","We conduct our 1000s simulation from Brazil to Lithuania on the open-source platform Hypatia.","Experiment results show that compared with CSGI, C-LRST reduces the latency and increases the throughput by approximately 60% and 40%, respectively.","In addition, C-LRST's GSL switching number is 14, whereas CSGI is 23.","C-LRST has better link stability than CSGI."],"url":"http://arxiv.org/abs/2410.24039v1"}
{"created":"2024-10-31 15:34:49","title":"TPC: Test-time Procrustes Calibration for Diffusion-based Human Image Animation","abstract":"Human image animation aims to generate a human motion video from the inputs of a reference human image and a target motion video. Current diffusion-based image animation systems exhibit high precision in transferring human identity into targeted motion, yet they still exhibit irregular quality in their outputs. Their optimal precision is achieved only when the physical compositions (i.e., scale and rotation) of the human shapes in the reference image and target pose frame are aligned. In the absence of such alignment, there is a noticeable decline in fidelity and consistency. Especially, in real-world environments, this compositional misalignment commonly occurs, posing significant challenges to the practical usage of current systems. To this end, we propose Test-time Procrustes Calibration (TPC), which enhances the robustness of diffusion-based image animation systems by maintaining optimal performance even when faced with compositional misalignment, effectively addressing real-world scenarios. The TPC provides a calibrated reference image for the diffusion model, enhancing its capability to understand the correspondence between human shapes in the reference and target images. Our method is simple and can be applied to any diffusion-based image animation system in a model-agnostic manner, improving the effectiveness at test time without additional training.","sentences":["Human image animation aims to generate a human motion video from the inputs of a reference human image and a target motion video.","Current diffusion-based image animation systems exhibit high precision in transferring human identity into targeted motion, yet they still exhibit irregular quality in their outputs.","Their optimal precision is achieved only when the physical compositions (i.e., scale and rotation) of the human shapes in the reference image and target pose frame are aligned.","In the absence of such alignment, there is a noticeable decline in fidelity and consistency.","Especially, in real-world environments, this compositional misalignment commonly occurs, posing significant challenges to the practical usage of current systems.","To this end, we propose Test-time Procrustes Calibration (TPC), which enhances the robustness of diffusion-based image animation systems by maintaining optimal performance even when faced with compositional misalignment, effectively addressing real-world scenarios.","The TPC provides a calibrated reference image for the diffusion model, enhancing its capability to understand the correspondence between human shapes in the reference and target images.","Our method is simple and can be applied to any diffusion-based image animation system in a model-agnostic manner, improving the effectiveness at test time without additional training."],"url":"http://arxiv.org/abs/2410.24037v1"}
{"created":"2024-10-31 15:34:01","title":"The Communal Loom: Integrating Tangible Interaction and Participatory Data Collection for Assessing Well-Being","abstract":"For most health or well-being interventions, the process of evaluation is distinct from the activity itself, both in terms of who is involved, and how the actual data is collected and analyzed. Tangible interaction affords the opportunity to combine direct and embodied collaboration with a holistic approach to data collection and evaluation. We demonstrate this potential by describing our experiences designing and using the Communal Loom, an artifact for art therapy that translates quantitative data to collectively woven artifacts.","sentences":["For most health or well-being interventions, the process of evaluation is distinct from the activity itself, both in terms of who is involved, and how the actual data is collected and analyzed.","Tangible interaction affords the opportunity to combine direct and embodied collaboration with a holistic approach to data collection and evaluation.","We demonstrate this potential by describing our experiences designing and using the Communal Loom, an artifact for art therapy that translates quantitative data to collectively woven artifacts."],"url":"http://arxiv.org/abs/2410.24036v1"}
{"created":"2024-10-31 15:32:32","title":"State- and context-dependent robotic manipulation and grasping via uncertainty-aware imitation learning","abstract":"Generating context-adaptive manipulation and grasping actions is a challenging problem in robotics. Classical planning and control algorithms tend to be inflexible with regard to parameterization by external variables such as object shapes. In contrast, Learning from Demonstration (LfD) approaches, due to their nature as function approximators, allow for introducing external variables to modulate policies in response to the environment. In this paper, we utilize this property by introducing an LfD approach to acquire context-dependent grasping and manipulation strategies. We treat the problem as a kernel-based function approximation, where the kernel inputs include generic context variables describing task-dependent parameters such as the object shape. We build on existing work on policy fusion with uncertainty quantification to propose a state-dependent approach that automatically returns to demonstrations, avoiding unpredictable behavior while smoothly adapting to context changes. The approach is evaluated against the LASA handwriting dataset and on a real 7-DoF robot in two scenarios: adaptation to slippage while grasping and manipulating a deformable food item.","sentences":["Generating context-adaptive manipulation and grasping actions is a challenging problem in robotics.","Classical planning and control algorithms tend to be inflexible with regard to parameterization by external variables such as object shapes.","In contrast, Learning from Demonstration (LfD) approaches, due to their nature as function approximators, allow for introducing external variables to modulate policies in response to the environment.","In this paper, we utilize this property by introducing an LfD approach to acquire context-dependent grasping and manipulation strategies.","We treat the problem as a kernel-based function approximation, where the kernel inputs include generic context variables describing task-dependent parameters such as the object shape.","We build on existing work on policy fusion with uncertainty quantification to propose a state-dependent approach that automatically returns to demonstrations, avoiding unpredictable behavior while smoothly adapting to context changes.","The approach is evaluated against the LASA handwriting dataset and on a real 7-DoF robot in two scenarios: adaptation to slippage while grasping and manipulating a deformable food item."],"url":"http://arxiv.org/abs/2410.24035v1"}
{"created":"2024-10-31 15:32:14","title":"Handwriting Recognition in Historical Documents with Multimodal LLM","abstract":"There is an immense quantity of historical and cultural documentation that exists only as handwritten manuscripts. At the same time, performing OCR across scripts and different handwriting styles has proven to be an enormously difficult problem relative to the process of digitizing print. While recent Transformer based models have achieved relatively strong performance, they rely heavily on manually transcribed training data and have difficulty generalizing across writers. Multimodal LLM, such as GPT-4v and Gemini, have demonstrated effectiveness in performing OCR and computer vision tasks with few shot prompting. In this paper, I evaluate the accuracy of handwritten document transcriptions generated by Gemini against the current state of the art Transformer based methods.   Keywords: Optical Character Recognition, Multimodal Language Models, Cultural Preservation, Mass digitization, Handwriting Recognitio","sentences":["There is an immense quantity of historical and cultural documentation that exists only as handwritten manuscripts.","At the same time, performing OCR across scripts and different handwriting styles has proven to be an enormously difficult problem relative to the process of digitizing print.","While recent Transformer based models have achieved relatively strong performance, they rely heavily on manually transcribed training data and have difficulty generalizing across writers.","Multimodal LLM, such as GPT-4v and Gemini, have demonstrated effectiveness in performing OCR and computer vision tasks with few shot prompting.","In this paper, I evaluate the accuracy of handwritten document transcriptions generated by Gemini against the current state of the art Transformer based methods.   ","Keywords: Optical Character Recognition, Multimodal Language Models, Cultural Preservation, Mass digitization, Handwriting Recognitio"],"url":"http://arxiv.org/abs/2410.24034v1"}
{"created":"2024-10-31 15:30:55","title":"Navigating the Unknown: A Chat-Based Collaborative Interface for Personalized Exploratory Tasks","abstract":"The rise of large language models (LLMs) has revolutionized user interactions with knowledge-based systems, enabling chatbots to synthesize vast amounts of information and assist with complex, exploratory tasks. However, LLM-based chatbots often struggle to provide personalized support, particularly when users start with vague queries or lack sufficient contextual information. This paper introduces the Collaborative Assistant for Personalized Exploration (CARE), a system designed to enhance personalization in exploratory tasks by combining a multi-agent LLM framework with a structured user interface. CARE's interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling iterative query refinement and dynamic solution generation. The multi-agent framework collaborates to identify both explicit and implicit user needs, delivering tailored, actionable solutions. In a within-subject user study with 22 participants, CARE was consistently preferred over a baseline LLM chatbot, with users praising its ability to reduce cognitive load, inspire creativity, and provide more tailored solutions. Our findings highlight CARE's potential to transform LLM-based systems from passive information retrievers to proactive partners in personalized problem-solving and exploration.","sentences":["The rise of large language models (LLMs) has revolutionized user interactions with knowledge-based systems, enabling chatbots to synthesize vast amounts of information and assist with complex, exploratory tasks.","However, LLM-based chatbots often struggle to provide personalized support, particularly when users start with vague queries or lack sufficient contextual information.","This paper introduces the Collaborative Assistant for Personalized Exploration (CARE), a system designed to enhance personalization in exploratory tasks by combining a multi-agent LLM framework with a structured user interface.","CARE's interface consists of a Chat Panel, Solution Panel, and Needs Panel, enabling iterative query refinement and dynamic solution generation.","The multi-agent framework collaborates to identify both explicit and implicit user needs, delivering tailored, actionable solutions.","In a within-subject user study with 22 participants, CARE was consistently preferred over a baseline LLM chatbot, with users praising its ability to reduce cognitive load, inspire creativity, and provide more tailored solutions.","Our findings highlight CARE's potential to transform LLM-based systems from passive information retrievers to proactive partners in personalized problem-solving and exploration."],"url":"http://arxiv.org/abs/2410.24032v1"}
{"created":"2024-10-31 15:29:51","title":"A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps","abstract":"Face recognition technologies are increasingly used in various applications, yet they are vulnerable to face spoofing attacks. These spoofing attacks often involve unique 3D structures, such as printed papers or mobile device screens. Although stereo-depth cameras can detect such attacks effectively, their high-cost limits their widespread adoption. Conversely, two-sensor systems without extrinsic calibration offer a cost-effective alternative but are unable to calculate depth using stereo techniques. In this work, we propose a method to overcome this challenge by leveraging facial attributes to derive disparity information and estimate relative depth for anti-spoofing purposes, using non-calibrated systems. We introduce a multi-modal anti-spoofing model, coined Disparity Model, that incorporates created disparity maps as a third modality alongside the two original sensor modalities. We demonstrate the effectiveness of the Disparity Model in countering various spoof attacks using a comprehensive dataset collected from the Intel RealSense ID Solution F455. Our method outperformed existing methods in the literature, achieving an Equal Error Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False Positive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the errors of the best comparison method, respectively. Additionally, we introduce a model ensemble that addresses 3D spoof attacks as well, achieving an EER of 2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a state-of-the-art solution for the challenging task of anti-spoofing in non-calibrated systems that lack depth information.","sentences":["Face recognition technologies are increasingly used in various applications, yet they are vulnerable to face spoofing attacks.","These spoofing attacks often involve unique 3D structures, such as printed papers or mobile device screens.","Although stereo-depth cameras can detect such attacks effectively, their high-cost limits their widespread adoption.","Conversely, two-sensor systems without extrinsic calibration offer a cost-effective alternative but are unable to calculate depth using stereo techniques.","In this work, we propose a method to overcome this challenge by leveraging facial attributes to derive disparity information and estimate relative depth for anti-spoofing purposes, using non-calibrated systems.","We introduce a multi-modal anti-spoofing model, coined Disparity Model, that incorporates created disparity maps as a third modality alongside the two original sensor modalities.","We demonstrate the effectiveness of the Disparity Model in countering various spoof attacks using a comprehensive dataset collected from the Intel RealSense ID Solution F455.","Our method outperformed existing methods in the literature, achieving an Equal Error Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False Positive Rate (FPR) of 1%.","These errors are lower by 2.45% and 7.94% than the errors of the best comparison method, respectively.","Additionally, we introduce a model ensemble that addresses 3D spoof attacks as well, achieving an EER of 2.04% and an FNR of 3.83% at an FPR of 1%.","Overall, our work provides a state-of-the-art solution for the challenging task of anti-spoofing in non-calibrated systems that lack depth information."],"url":"http://arxiv.org/abs/2410.24031v1"}
{"created":"2024-10-31 15:28:26","title":"Joint Training for Selective Prediction","abstract":"Classifier models are prevalent in natural language processing (NLP), often with high accuracy. Yet in real world settings, human-in-the-loop systems can foster trust in model outputs and even higher performance. Selective Prediction (SP) methods determine when to adopt a classifier's output versus defer to a human. Previous SP approaches have addressed how to improve softmax as a measure of model confidence, or have developed separate confidence estimators. One previous method involves learning a deferral model based on engineered features. We introduce a novel joint-training approach that simultaneously optimizes learned representations used by the classifier module and a learned deferral policy. Our results on four classification tasks demonstrate that joint training not only leads to better SP outcomes over two strong baselines, but also improves the performance of both modules.","sentences":["Classifier models are prevalent in natural language processing (NLP), often with high accuracy.","Yet in real world settings, human-in-the-loop systems can foster trust in model outputs and even higher performance.","Selective Prediction (SP) methods determine when to adopt a classifier's output versus defer to a human.","Previous SP approaches have addressed how to improve softmax as a measure of model confidence, or have developed separate confidence estimators.","One previous method involves learning a deferral model based on engineered features.","We introduce a novel joint-training approach that simultaneously optimizes learned representations used by the classifier module and a learned deferral policy.","Our results on four classification tasks demonstrate that joint training not only leads to better SP outcomes over two strong baselines, but also improves the performance of both modules."],"url":"http://arxiv.org/abs/2410.24029v1"}
{"created":"2024-10-31 15:28:22","title":"AdaFlow: Opportunistic Inference on Asynchronous Mobile Data with Generalized Affinity Control","abstract":"The rise of mobile devices equipped with numerous sensors, such as LiDAR and cameras, has spurred the adoption of multi-modal deep intelligence for distributed sensing tasks, such as smart cabins and driving assistance. However, the arrival times of mobile sensory data vary due to modality size and network dynamics, which can lead to delays (if waiting for slower data) or accuracy decline (if inference proceeds without waiting). Moreover, the diversity and dynamic nature of mobile systems exacerbate this challenge. In response, we present a shift to \\textit{opportunistic} inference for asynchronous distributed multi-modal data, enabling inference as soon as partial data arrives. While existing methods focus on optimizing modality consistency and complementarity, known as modal affinity, they lack a \\textit{computational} approach to control this affinity in open-world mobile environments. AdaFlow pioneers the formulation of structured cross-modality affinity in mobile contexts using a hierarchical analysis-based normalized matrix. This approach accommodates the diversity and dynamics of modalities, generalizing across different types and numbers of inputs. Employing an affinity attention-based conditional GAN (ACGAN), AdaFlow facilitates flexible data imputation, adapting to various modalities and downstream tasks without retraining. Experiments show that AdaFlow significantly reduces inference latency by up to 79.9\\% and enhances accuracy by up to 61.9\\%, outperforming status quo approaches.","sentences":["The rise of mobile devices equipped with numerous sensors, such as LiDAR and cameras, has spurred the adoption of multi-modal deep intelligence for distributed sensing tasks, such as smart cabins and driving assistance.","However, the arrival times of mobile sensory data vary due to modality size and network dynamics, which can lead to delays (if waiting for slower data) or accuracy decline (if inference proceeds without waiting).","Moreover, the diversity and dynamic nature of mobile systems exacerbate this challenge.","In response, we present a shift to \\textit{opportunistic} inference for asynchronous distributed multi-modal data, enabling inference as soon as partial data arrives.","While existing methods focus on optimizing modality consistency and complementarity, known as modal affinity, they lack a \\textit{computational} approach to control this affinity in open-world mobile environments.","AdaFlow pioneers the formulation of structured cross-modality affinity in mobile contexts using a hierarchical analysis-based normalized matrix.","This approach accommodates the diversity and dynamics of modalities, generalizing across different types and numbers of inputs.","Employing an affinity attention-based conditional GAN (ACGAN), AdaFlow facilitates flexible data imputation, adapting to various modalities and downstream tasks without retraining.","Experiments show that AdaFlow significantly reduces inference latency by up to 79.9\\% and enhances accuracy by up to 61.9\\%, outperforming status quo approaches."],"url":"http://arxiv.org/abs/2410.24028v1"}
{"created":"2024-10-31 15:27:17","title":"On codes induced from Hadamard matrices","abstract":"Unit derived schemes applied to Hadamard matrices are used to construct and analyse linear block and convolutional codes. Codes are constructed to prescribed types, lengths and rates and multiple series of self-dual, dual-containing, linear complementary dual and quantum error-correcting of both linear block {\\em and} convolutional codes are derived.","sentences":["Unit derived schemes applied to Hadamard matrices are used to construct and analyse linear block and convolutional codes.","Codes are constructed to prescribed types, lengths and rates and multiple series of self-dual, dual-containing, linear complementary dual and quantum error-correcting of both linear block {\\em and} convolutional codes are derived."],"url":"http://arxiv.org/abs/2410.24027v1"}
{"created":"2024-10-31 15:25:20","title":"AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents","abstract":"Autonomous agents have become increasingly important for interacting with the real world. Android agents, in particular, have been recently a frequently-mentioned interaction method. However, existing studies for training and evaluating Android agents lack systematic research on both open-source and closed-source models. In this work, we propose AndroidLab as a systematic Android agent framework. It includes an operation environment with different modalities, action space, and a reproducible benchmark. It supports both large language models (LLMs) and multimodal models (LMMs) in the same action space. AndroidLab benchmark includes predefined Android virtual devices and 138 tasks across nine apps built on these devices. By using the AndroidLab environment, we develop an Android Instruction dataset and train six open-source LLMs and LMMs, lifting the average success rates from 4.59\\% to 21.50\\% for LLMs and from 1.93\\% to 13.28\\% for LMMs. AndroidLab is open-sourced and publicly available at \\url{https://github.com/THUDM/Android-Lab}.","sentences":["Autonomous agents have become increasingly important for interacting with the real world.","Android agents, in particular, have been recently a frequently-mentioned interaction method.","However, existing studies for training and evaluating Android agents lack systematic research on both open-source and closed-source models.","In this work, we propose AndroidLab as a systematic Android agent framework.","It includes an operation environment with different modalities, action space, and a reproducible benchmark.","It supports both large language models (LLMs) and multimodal models (LMMs) in the same action space.","AndroidLab benchmark includes predefined Android virtual devices and 138 tasks across nine apps built on these devices.","By using the AndroidLab environment, we develop an Android Instruction dataset and train six open-source LLMs and LMMs, lifting the average success rates from 4.59\\% to 21.50\\% for LLMs and from 1.93\\% to 13.28\\% for LMMs.","AndroidLab is open-sourced and publicly available at \\url{https://github.com/THUDM/Android-Lab}."],"url":"http://arxiv.org/abs/2410.24024v1"}
{"created":"2024-10-31 15:23:34","title":"Approximate attention with MLP: a pruning strategy for attention-based model in multivariate time series forecasting","abstract":"Attention-based architectures have become ubiquitous in time series forecasting tasks, including spatio-temporal (STF) and long-term time series forecasting (LTSF). Yet, our understanding of the reasons for their effectiveness remains limited. This work proposes a new way to understand self-attention networks: we have shown empirically that the entire attention mechanism in the encoder can be reduced to an MLP formed by feedforward, skip-connection, and layer normalization operations for temporal and/or spatial modeling in multivariate time series forecasting. Specifically, the Q, K, and V projection, the attention score calculation, the dot-product between the attention score and the V, and the final projection can be removed from the attention-based networks without significantly degrading the performance that the given network remains the top-tier compared to other SOTA methods. For spatio-temporal networks, the MLP-replace-attention network achieves a reduction in FLOPS of $62.579\\%$ with a loss in performance less than $2.5\\%$; for LTSF, a reduction in FLOPs of $42.233\\%$ with a loss in performance less than $2\\%$.","sentences":["Attention-based architectures have become ubiquitous in time series forecasting tasks, including spatio-temporal (STF) and long-term time series forecasting (LTSF).","Yet, our understanding of the reasons for their effectiveness remains limited.","This work proposes a new way to understand self-attention networks: we have shown empirically that the entire attention mechanism in the encoder can be reduced to an MLP formed by feedforward, skip-connection, and layer normalization operations for temporal and/or spatial modeling in multivariate time series forecasting.","Specifically, the Q, K, and V projection, the attention score calculation, the dot-product between the attention score and the V, and the final projection can be removed from the attention-based networks without significantly degrading the performance that the given network remains the top-tier compared to other SOTA methods.","For spatio-temporal networks, the MLP-replace-attention network achieves a reduction in FLOPS of $62.579\\%$ with a loss in performance less than $2.5\\%$; for LTSF, a reduction in FLOPs of $42.233\\%$ with a loss in performance less than $2\\%$."],"url":"http://arxiv.org/abs/2410.24023v1"}
