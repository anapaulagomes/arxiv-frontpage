{"created":"2024-08-12 17:57:49","title":"Is it a work or leisure travel? Applying text classification to identify work-related travel on social networks","abstract":"In today's digital era, the use of Social Networks (SNs) and Location-Based SNs (LBSNs) has become integral for travelers seeking Points of Interest (POI) and sharing travel experiences. This trend is supported by the fact that a significant majority of American travelers utilize SNs during their trips. However, the abundance of information available on these platforms presents a challenge in identifying the best options. To address this issue, Recommender Systems (RS) are commonly employed to suggest POIs based on user history, with the integration of contextual information enhancing the quality of recommendations. Notably, incorporating user travel purpose, which is often overlooked but holds potential in characterizing travelers' behavior, can lead to more tailored recommendations. In this study, we propose a model to predict whether a trip is leisure or work-related, utilizing state-of-the-art Automatic Text Classification (ATC) models such as BERT, RoBERTa, and BART to enhance the understanding of user travel purposes and improve recommendation accuracy in specific travel scenarios.","sentences":["In today's digital era, the use of Social Networks (SNs) and Location-Based SNs (LBSNs) has become integral for travelers seeking Points of Interest (POI) and sharing travel experiences.","This trend is supported by the fact that a significant majority of American travelers utilize SNs during their trips.","However, the abundance of information available on these platforms presents a challenge in identifying the best options.","To address this issue, Recommender Systems (RS) are commonly employed to suggest POIs based on user history, with the integration of contextual information enhancing the quality of recommendations.","Notably, incorporating user travel purpose, which is often overlooked but holds potential in characterizing travelers' behavior, can lead to more tailored recommendations.","In this study, we propose a model to predict whether a trip is leisure or work-related, utilizing state-of-the-art Automatic Text Classification (ATC) models such as BERT, RoBERTa, and BART to enhance the understanding of user travel purposes and improve recommendation accuracy in specific travel scenarios."],"url":"http://arxiv.org/abs/2408.06341v1"}
{"created":"2024-08-12 17:52:29","title":"Moo-ving Beyond Tradition: Revolutionizing Cattle Behavioural Phenotyping with Pose Estimation Techniques","abstract":"The cattle industry has been a major contributor to the economy of many countries, including the US and Canada. The integration of Artificial Intelligence (AI) has revolutionized this sector, mirroring its transformative impact across all industries by enabling scalable and automated monitoring and intervention practices. AI has also introduced tools and methods that automate many tasks previously performed by human labor with the help of computer vision, including health inspections. Among these methods, pose estimation has a special place; pose estimation is the process of finding the position of joints in an image of animals. Analyzing the pose of animal subjects enables precise identification and tracking of the animal's movement and the movements of its body parts. By summarizing the video and imagery data into movement and joint location using pose estimation and then analyzing this information, we can address the scalability challenge in cattle management, focusing on health monitoring, behavioural phenotyping and welfare concerns. Our study reviews recent advancements in pose estimation methodologies, their applicability in improving the cattle industry, existing challenges, and gaps in this field. Furthermore, we propose an initiative to enhance open science frameworks within this field of study by launching a platform designed to connect industry and academia.","sentences":["The cattle industry has been a major contributor to the economy of many countries, including the US and Canada.","The integration of Artificial Intelligence (AI) has revolutionized this sector, mirroring its transformative impact across all industries by enabling scalable and automated monitoring and intervention practices.","AI has also introduced tools and methods that automate many tasks previously performed by human labor with the help of computer vision, including health inspections.","Among these methods, pose estimation has a special place; pose estimation is the process of finding the position of joints in an image of animals.","Analyzing the pose of animal subjects enables precise identification and tracking of the animal's movement and the movements of its body parts.","By summarizing the video and imagery data into movement and joint location using pose estimation and then analyzing this information, we can address the scalability challenge in cattle management, focusing on health monitoring, behavioural phenotyping and welfare concerns.","Our study reviews recent advancements in pose estimation methodologies, their applicability in improving the cattle industry, existing challenges, and gaps in this field.","Furthermore, we propose an initiative to enhance open science frameworks within this field of study by launching a platform designed to connect industry and academia."],"url":"http://arxiv.org/abs/2408.06336v1"}
{"created":"2024-08-12 17:52:11","title":"LOLgorithm: Integrating Semantic,Syntactic and Contextual Elements for Humor Classification","abstract":"This paper explores humor detection through a linguistic lens, prioritizing syntactic, semantic, and contextual features over computational methods in Natural Language Processing. We categorize features into syntactic, semantic, and contextual dimensions, including lexicons, structural statistics, Word2Vec, WordNet, and phonetic style. Our proposed model, Colbert, utilizes BERT embeddings and parallel hidden layers to capture sentence congruity. By combining syntactic, semantic, and contextual features, we train Colbert for humor detection. Feature engineering examines essential syntactic and semantic features alongside BERT embeddings. SHAP interpretations and decision trees identify influential features, revealing that a holistic approach improves humor detection accuracy on unseen data. Integrating linguistic cues from different dimensions enhances the model's ability to understand humor complexity beyond traditional computational methods.","sentences":["This paper explores humor detection through a linguistic lens, prioritizing syntactic, semantic, and contextual features over computational methods in Natural Language Processing.","We categorize features into syntactic, semantic, and contextual dimensions, including lexicons, structural statistics, Word2Vec, WordNet, and phonetic style.","Our proposed model, Colbert, utilizes BERT embeddings and parallel hidden layers to capture sentence congruity.","By combining syntactic, semantic, and contextual features, we train Colbert for humor detection.","Feature engineering examines essential syntactic and semantic features alongside BERT embeddings.","SHAP interpretations and decision trees identify influential features, revealing that a holistic approach improves humor detection accuracy on unseen data.","Integrating linguistic cues from different dimensions enhances the model's ability to understand humor complexity beyond traditional computational methods."],"url":"http://arxiv.org/abs/2408.06335v1"}
{"created":"2024-08-12 17:50:02","title":"FastFiD: Improve Inference Efficiency of Open Domain Question Answering via Sentence Selection","abstract":"Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models. Current models typically incorporate the FiD framework, which is composed by a neural retriever alongside an encoder-decoder neural reader. In the answer generation process, the retriever will retrieve numerous passages (around 100 for instance), each of which is then individually encoded by the encoder. Subsequently, the decoder makes predictions based on these encoded passages. Nevertheless, this framework can be relatively time-consuming, particularly due to the extensive length of the gathered passages. To address this, we introduce FastFiD in this paper, a novel approach that executes sentence selection on the encoded passages. This aids in retaining valuable sentences while reducing the context length required for generating answers. Experiments on three commonly used datasets (Natural Questions, TriviaQA and ASQA) demonstrate that our method can enhance the inference speed by 2.3X-5.7X, while simultaneously maintaining the model's performance. Moreover, an in-depth analysis of the model's attention reveals that the selected sentences indeed hold a substantial contribution towards the final answer. The codes are publicly available at https://github.com/thunlp/FastFiD.","sentences":["Open Domain Question Answering (ODQA) has been advancing rapidly in recent times, driven by significant developments in dense passage retrieval and pretrained language models.","Current models typically incorporate the FiD framework, which is composed by a neural retriever alongside an encoder-decoder neural reader.","In the answer generation process, the retriever will retrieve numerous passages (around 100 for instance), each of which is then individually encoded by the encoder.","Subsequently, the decoder makes predictions based on these encoded passages.","Nevertheless, this framework can be relatively time-consuming, particularly due to the extensive length of the gathered passages.","To address this, we introduce FastFiD in this paper, a novel approach that executes sentence selection on the encoded passages.","This aids in retaining valuable sentences while reducing the context length required for generating answers.","Experiments on three commonly used datasets (Natural Questions, TriviaQA and ASQA) demonstrate that our method can enhance the inference speed by 2.3X-5.7X, while simultaneously maintaining the model's performance.","Moreover, an in-depth analysis of the model's attention reveals that the selected sentences indeed hold a substantial contribution towards the final answer.","The codes are publicly available at https://github.com/thunlp/FastFiD."],"url":"http://arxiv.org/abs/2408.06333v1"}
{"created":"2024-08-12 17:48:55","title":"Animate, or Inanimate, That is the Question for Large Language Models","abstract":"The cognitive essence of humans is deeply intertwined with the concept of animacy, which plays an essential role in shaping their memory, vision, and multi-layered language understanding. Although animacy appears in language via nuanced constraints on verbs and adjectives, it is also learned and refined through extralinguistic information. Similarly, we assume that the LLMs' limited abilities to understand natural language when processing animacy are motivated by the fact that these models are trained exclusively on text.   Hence, the question this paper aims to answer arises: can LLMs, in their digital wisdom, process animacy in a similar way to what humans would do? We then propose a systematic analysis via prompting approaches. In particular, we probe different LLMs by prompting them using animate, inanimate, usual, and stranger contexts. Results reveal that, although LLMs have been trained predominantly on textual data, they exhibit human-like behavior when faced with typical animate and inanimate entities in alignment with earlier studies. Hence, LLMs can adapt to understand unconventional situations by recognizing oddities as animated without needing to interface with unspoken cognitive triggers humans rely on to break down animations.","sentences":["The cognitive essence of humans is deeply intertwined with the concept of animacy, which plays an essential role in shaping their memory, vision, and multi-layered language understanding.","Although animacy appears in language via nuanced constraints on verbs and adjectives, it is also learned and refined through extralinguistic information.","Similarly, we assume that the LLMs' limited abilities to understand natural language when processing animacy are motivated by the fact that these models are trained exclusively on text.   ","Hence, the question this paper aims to answer arises: can LLMs, in their digital wisdom, process animacy in a similar way to what humans would do?","We then propose a systematic analysis via prompting approaches.","In particular, we probe different LLMs by prompting them using animate, inanimate, usual, and stranger contexts.","Results reveal that, although LLMs have been trained predominantly on textual data, they exhibit human-like behavior when faced with typical animate and inanimate entities in alignment with earlier studies.","Hence, LLMs can adapt to understand unconventional situations by recognizing oddities as animated without needing to interface with unspoken cognitive triggers humans rely on to break down animations."],"url":"http://arxiv.org/abs/2408.06332v1"}
{"created":"2024-08-12 17:47:32","title":"Integration of blockchain in smart systems: problems and opportunities for real-time sensor data storage","abstract":"The internet of things (IoT) and other emerging ubiquitous technologies are supporting the rapid spread of smart systems, which has underlined the need for safe, open, and decentralized data storage solutions. With its inherent decentralization and immutability, blockchain offers itself as a potential solution for these requirements. However, the practicality of incorporating blockchain into real-time sensor data storage systems is a topic that demands in-depth examination. While blockchain promises unmatched data security and auditability, some intrinsic qualities, namely scalability restrictions, transactional delays, and escalating storage demands, impede its seamless deployment in high-frequency, voluminous data contexts typical of real-time sensors. This essay launches a methodical investigation into these difficulties, illuminating their underlying causes, potential effects, and potential countermeasures. In addition, we present a novel pragmatic experimental setup and analysis of blockchain for smart system applications, with an extended discussion of the benefits and disadvantages of deploying blockchain based solutions for smart system ecosystems.","sentences":["The internet of things (IoT) and other emerging ubiquitous technologies are supporting the rapid spread of smart systems, which has underlined the need for safe, open, and decentralized data storage solutions.","With its inherent decentralization and immutability, blockchain offers itself as a potential solution for these requirements.","However, the practicality of incorporating blockchain into real-time sensor data storage systems is a topic that demands in-depth examination.","While blockchain promises unmatched data security and auditability, some intrinsic qualities, namely scalability restrictions, transactional delays, and escalating storage demands, impede its seamless deployment in high-frequency, voluminous data contexts typical of real-time sensors.","This essay launches a methodical investigation into these difficulties, illuminating their underlying causes, potential effects, and potential countermeasures.","In addition, we present a novel pragmatic experimental setup and analysis of blockchain for smart system applications, with an extended discussion of the benefits and disadvantages of deploying blockchain based solutions for smart system ecosystems."],"url":"http://arxiv.org/abs/2408.06331v1"}
{"created":"2024-08-12 17:44:33","title":"HeLiMOS: A Dataset for Moving Object Segmentation in 3D Point Clouds From Heterogeneous LiDAR Sensors","abstract":"Moving object segmentation (MOS) using a 3D light detection and ranging (LiDAR) sensor is crucial for scene understanding and identification of moving objects. Despite the availability of various types of 3D LiDAR sensors in the market, MOS research still predominantly focuses on 3D point clouds from mechanically spinning omnidirectional LiDAR sensors. Thus, we are, for example, lacking a dataset with MOS labels for point clouds from solid-state LiDAR sensors which have irregular scanning patterns. In this paper, we present a labeled dataset, called \\textit{HeLiMOS}, that enables to test MOS approaches on four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors. Furthermore, we introduce a novel automatic labeling method to substantially reduce the labeling effort required from human annotators. To this end, our framework exploits an instance-aware static map building approach and tracking-based false label filtering. Finally, we provide experimental results regarding the performance of commonly used state-of-the-art MOS approaches on HeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generally works regardless of the type of LiDAR sensors used to capture 3D point clouds. Our dataset is available at https://sites.google.com/view/helimos.","sentences":["Moving object segmentation (MOS) using a 3D light detection and ranging (LiDAR) sensor is crucial for scene understanding and identification of moving objects.","Despite the availability of various types of 3D LiDAR sensors in the market, MOS research still predominantly focuses on 3D point clouds from mechanically spinning omnidirectional LiDAR sensors.","Thus, we are, for example, lacking a dataset with MOS labels for point clouds from solid-state LiDAR sensors which have irregular scanning patterns.","In this paper, we present a labeled dataset, called \\textit{HeLiMOS}, that enables to test MOS approaches on four heterogeneous LiDAR sensors, including two solid-state LiDAR sensors.","Furthermore, we introduce a novel automatic labeling method to substantially reduce the labeling effort required from human annotators.","To this end, our framework exploits an instance-aware static map building approach and tracking-based false label filtering.","Finally, we provide experimental results regarding the performance of commonly used state-of-the-art MOS approaches on HeLiMOS that suggest a new direction for a sensor-agnostic MOS, which generally works regardless of the type of LiDAR sensors used to capture 3D point clouds.","Our dataset is available at https://sites.google.com/view/helimos."],"url":"http://arxiv.org/abs/2408.06328v1"}
{"created":"2024-08-12 17:44:17","title":"VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents","abstract":"Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable Visual Foundation Agents. These agents are postulated to excel across a myriad of tasks, potentially approaching general artificial intelligence. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities. Through rigorous testing across nine proprietary LMM APIs and eight open models, we demonstrate the considerable yet still developing agent capabilities of these models. Additionally, VAB constructs a trajectory training set constructed through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, promoting substantial performance improvements in LMMs through behavior cloning. Our work not only aims to benchmark existing models but also provides a solid foundation for future development into visual foundation agents. Code, train \\& test data, and part of fine-tuned open LMMs are available at \\url{https://github.com/THUDM/VisualAgentBench}.","sentences":["Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable Visual Foundation Agents.","These agents are postulated to excel across a myriad of tasks, potentially approaching general artificial intelligence.","However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs in complex, real-world environments.","To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities.","Through rigorous testing across nine proprietary LMM APIs and eight open models, we demonstrate the considerable yet still developing agent capabilities of these models.","Additionally, VAB constructs a trajectory training set constructed through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, promoting substantial performance improvements in LMMs through behavior cloning.","Our work not only aims to benchmark existing models but also provides a solid foundation for future development into visual foundation agents.","Code, train \\& test data, and part of fine-tuned open LMMs are available at \\url{https://github.com/THUDM/VisualAgentBench}."],"url":"http://arxiv.org/abs/2408.06327v1"}
{"created":"2024-08-12 17:43:48","title":"Online Vehicle Routing with Pickups and Deliveries under Time-Dependent Travel-Time Constraints","abstract":"The Vehicle Routing Problem with pickups, deliveries and spatiotemporal service constraints ($VRPPDSTC$) is a quite challenging algorithmic problem that can be dealt with in either an offline or an online fashion. In this work, we focus on a generalization, called $VRPPDSTCtd$, in which the travel-time metric is \\emph{time-dependent}: the traversal-time per road segment (represented as a directed arc) is determined by some function of the departure-time from its tail towards its head. Time-dependence makes things much more complicated, even for the simpler problem of computing earliest-arrival-time paths which is a crucial subroutine to be solved (numerous times) by $VRPPDSTCtd$ schedulers.   We propose two \\emph{online} schedulers of requests to workers, one which is a time-dependent variant of the classical Plain-Insertion heuristic, and an extension of it trying to digest some sort of forecasts for future demands for service. We enrich these two online schedulers with two additional heuristics, one targeting for distance-balanced assignments of work loads to the workers and another that makes local-search-improvements to the produced solutions.   We conduct a careful experimental evaluation of the proposed algorithms on a real-world instance, with or without these heuristics, and compare their quality with human-curated assignments provided by professional experts (human operators at actual pickup-and-delivery control centers), and also with feasible solutions constructed from a relaxed MILP formulation of $VRPPDSTCtd$, which is also introduced in this paper.   Our findings are quite encouraging, demonstrating that the proposed algorithms produce solutions which (i) are significant improvements over the human-curated assignments, and (ii) have overall quality pretty close to that of the (extremely time-consuming) solutions provided by an exact solver for the MILP formulation.","sentences":["The Vehicle Routing Problem with pickups, deliveries and spatiotemporal service constraints ($VRPPDSTC$) is a quite challenging algorithmic problem that can be dealt with in either an offline or an online fashion.","In this work, we focus on a generalization, called $VRPPDSTCtd$, in which the travel-time metric is \\emph{time-dependent}: the traversal-time per road segment (represented as a directed arc) is determined by some function of the departure-time from its tail towards its head.","Time-dependence makes things much more complicated, even for the simpler problem of computing earliest-arrival-time paths which is a crucial subroutine to be solved (numerous times) by $VRPPDSTCtd$ schedulers.   ","We propose two \\emph{online} schedulers of requests to workers, one which is a time-dependent variant of the classical Plain-Insertion heuristic, and an extension of it trying to digest some sort of forecasts for future demands for service.","We enrich these two online schedulers with two additional heuristics, one targeting for distance-balanced assignments of work loads to the workers and another that makes local-search-improvements to the produced solutions.   ","We conduct a careful experimental evaluation of the proposed algorithms on a real-world instance, with or without these heuristics, and compare their quality with human-curated assignments provided by professional experts (human operators at actual pickup-and-delivery control centers), and also with feasible solutions constructed from a relaxed MILP formulation of $VRPPDSTCtd$, which is also introduced in this paper.   ","Our findings are quite encouraging, demonstrating that the proposed algorithms produce solutions which (i) are significant improvements over the human-curated assignments, and (ii) have overall quality pretty close to that of the (extremely time-consuming) solutions provided by an exact solver for the MILP formulation."],"url":"http://arxiv.org/abs/2408.06324v1"}
{"created":"2024-08-12 17:42:46","title":"EqNIO: Subequivariant Neural Inertial Odometry","abstract":"Presently, neural networks are widely employed to accurately estimate 2D displacements and associated uncertainties from Inertial Measurement Unit (IMU) data that can be integrated into stochastic filter networks like the Extended Kalman Filter (EKF) as measurements and uncertainties for the update step in the filter. However, such neural approaches overlook symmetry which is a crucial inductive bias for model generalization. This oversight is notable because (i) physical laws adhere to symmetry principles when considering the gravity axis, meaning there exists the same transformation for both the physical entity and the resulting trajectory, and (ii) displacements should remain equivariant to frame transformations when the inertial frame changes. To address this, we propose a subequivariant framework by: (i) deriving fundamental layers such as linear and nonlinear layers for a subequivariant network, designed to handle sequences of vectors and scalars, (ii) employing the subequivariant network to predict an equivariant frame for the sequence of inertial measurements. This predicted frame can then be utilized for extracting invariant features through projection, which are integrated with arbitrary network architectures, (iii) transforming the invariant output by frame transformation to obtain equivariant displacements and covariances. We demonstrate the effectiveness and generalization of our Equivariant Framework on a filter-based approach with TLIO architecture for TLIO and Aria datasets, and an end-to-end deep learning approach with RONIN architecture for RONIN, RIDI and OxIOD datasets.","sentences":["Presently, neural networks are widely employed to accurately estimate 2D displacements and associated uncertainties from Inertial Measurement Unit (IMU) data that can be integrated into stochastic filter networks like the Extended Kalman Filter (EKF) as measurements and uncertainties for the update step in the filter.","However, such neural approaches overlook symmetry which is a crucial inductive bias for model generalization.","This oversight is notable because (i) physical laws adhere to symmetry principles when considering the gravity axis, meaning there exists the same transformation for both the physical entity and the resulting trajectory, and (ii) displacements should remain equivariant to frame transformations when the inertial frame changes.","To address this, we propose a subequivariant framework by: (i) deriving fundamental layers such as linear and nonlinear layers for a subequivariant network, designed to handle sequences of vectors and scalars, (ii) employing the subequivariant network to predict an equivariant frame for the sequence of inertial measurements.","This predicted frame can then be utilized for extracting invariant features through projection, which are integrated with arbitrary network architectures, (iii) transforming the invariant output by frame transformation to obtain equivariant displacements and covariances.","We demonstrate the effectiveness and generalization of our Equivariant Framework on a filter-based approach with TLIO architecture for TLIO and Aria datasets, and an end-to-end deep learning approach with RONIN architecture for RONIN, RIDI and OxIOD datasets."],"url":"http://arxiv.org/abs/2408.06321v1"}
{"created":"2024-08-12 17:39:01","title":"Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example","abstract":"Large language models (LLMs) have brought autonomous agents closer to artificial general intelligence (AGI) due to their promising generalization and emergent capabilities. There is, however, a lack of studies on how LLM-based agents behave, why they could potentially fail, and how to improve them, particularly in demanding real-world planning tasks. In this paper, as an effort to fill the gap, we present our study using a realistic benchmark, TravelPlanner, where an agent must meet multiple constraints to generate accurate plans. We leverage this benchmark to address four key research questions: (1) are LLM agents robust enough to lengthy and noisy contexts when it comes to reasoning and planning? (2) can few-shot prompting adversely impact the performance of LLM agents in scenarios with long context? (3) can we rely on refinement to improve plans, and (4) can fine-tuning LLMs with both positive and negative feedback lead to further improvement? Our comprehensive experiments indicate that, firstly, LLMs often fail to attend to crucial parts of a long context, despite their ability to handle extensive reference information and few-shot examples; secondly, they still struggle with analyzing the long plans and cannot provide accurate feedback for refinement; thirdly, we propose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and negative feedback, resulting in substantial gains over Supervised Fine-Tuning (SFT). Our findings offer in-depth insights to the community on various aspects related to real-world planning applications.","sentences":["Large language models (LLMs) have brought autonomous agents closer to artificial general intelligence (AGI) due to their promising generalization and emergent capabilities.","There is, however, a lack of studies on how LLM-based agents behave, why they could potentially fail, and how to improve them, particularly in demanding real-world planning tasks.","In this paper, as an effort to fill the gap, we present our study using a realistic benchmark, TravelPlanner, where an agent must meet multiple constraints to generate accurate plans.","We leverage this benchmark to address four key research questions: (1) are LLM agents robust enough to lengthy and noisy contexts when it comes to reasoning and planning?","(2) can few-shot prompting adversely impact the performance of LLM agents in scenarios with long context?","(3) can we rely on refinement to improve plans, and (4) can fine-tuning LLMs with both positive and negative feedback lead to further improvement?","Our comprehensive experiments indicate that, firstly, LLMs often fail to attend to crucial parts of a long context, despite their ability to handle extensive reference information and few-shot examples; secondly, they still struggle with analyzing the long plans and cannot provide accurate feedback for refinement; thirdly, we propose Feedback-Aware Fine-Tuning (FAFT), which leverages both positive and negative feedback, resulting in substantial gains over Supervised Fine-Tuning (SFT).","Our findings offer in-depth insights to the community on various aspects related to real-world planning applications."],"url":"http://arxiv.org/abs/2408.06318v1"}
{"created":"2024-08-12 17:31:28","title":"Body Transformer: Leveraging Robot Embodiment for Policy Learning","abstract":"In recent years, the transformer architecture has become the de facto standard for machine learning algorithms applied to natural language processing and computer vision. Despite notable evidence of successful deployment of this architecture in the context of robot learning, we claim that vanilla transformers do not fully exploit the structure of the robot learning problem. Therefore, we propose Body Transformer (BoT), an architecture that leverages the robot embodiment by providing an inductive bias that guides the learning process. We represent the robot body as a graph of sensors and actuators, and rely on masked attention to pool information throughout the architecture. The resulting architecture outperforms the vanilla transformer, as well as the classical multilayer perceptron, in terms of task completion, scaling properties, and computational efficiency when representing either imitation or reinforcement learning policies. Additional material including the open-source code is available at https://sferrazza.cc/bot_site.","sentences":["In recent years, the transformer architecture has become the de facto standard for machine learning algorithms applied to natural language processing and computer vision.","Despite notable evidence of successful deployment of this architecture in the context of robot learning, we claim that vanilla transformers do not fully exploit the structure of the robot learning problem.","Therefore, we propose Body Transformer (BoT), an architecture that leverages the robot embodiment by providing an inductive bias that guides the learning process.","We represent the robot body as a graph of sensors and actuators, and rely on masked attention to pool information throughout the architecture.","The resulting architecture outperforms the vanilla transformer, as well as the classical multilayer perceptron, in terms of task completion, scaling properties, and computational efficiency when representing either imitation or reinforcement learning policies.","Additional material including the open-source code is available at https://sferrazza.cc/bot_site."],"url":"http://arxiv.org/abs/2408.06316v1"}
{"created":"2024-08-12 17:24:19","title":"OWL2Vec4OA: Tailoring Knowledge Graph Embeddings for Ontology Alignment","abstract":"Ontology alignment is integral to achieving semantic interoperability as the number of available ontologies covering intersecting domains is increasing. This paper proposes OWL2Vec4OA, an extension of the ontology embedding system OWL2Vec*. While OWL2Vec* has emerged as a powerful technique for ontology embedding, it currently lacks a mechanism to tailor the embedding to the ontology alignment task. OWL2Vec4OA incorporates edge confidence values from seed mappings to guide the random walk strategy. We present the theoretical foundations, implementation details, and experimental evaluation of our proposed extension, demonstrating its potential effectiveness for ontology alignment tasks.","sentences":["Ontology alignment is integral to achieving semantic interoperability as the number of available ontologies covering intersecting domains is increasing.","This paper proposes OWL2Vec4OA, an extension of the ontology embedding system OWL2Vec*.","While OWL2Vec* has emerged as a powerful technique for ontology embedding, it currently lacks a mechanism to tailor the embedding to the ontology alignment task.","OWL2Vec4OA incorporates edge confidence values from seed mappings to guide the random walk strategy.","We present the theoretical foundations, implementation details, and experimental evaluation of our proposed extension, demonstrating its potential effectiveness for ontology alignment tasks."],"url":"http://arxiv.org/abs/2408.06310v1"}
{"created":"2024-08-12 17:22:15","title":"Dynamic Traffic Assignment for Public Transport with Vehicle Capacities","abstract":"Traffic assignment is a core component of many urban transport planning tools. It is used to determine how traffic is distributed over a transportation network. We study the task of computing traffic assignments for public transport: Given a public transit network, a timetable, vehicle capacities and a demand (i.e. a list of passengers, each with an associated origin, destination, and departure time), the goal is to predict the resulting passenger flow and the corresponding load of each vehicle. Microscopic stochastic simulation of individual passengers is a standard, but computationally expensive approach. Briem et al. (2017) have shown that a clever adaptation of the Connection Scan Algorithm (CSA) can lead to highly efficient traffic assignment algorithms, but ignores vehicle capacities, resulting in overcrowded vehicles. Taking their work as a starting point, we here propose a new and extended model that guarantees capacity-feasible assignments and incorporates dynamic network congestion effects such as crowded vehicles, denied boarding, and dwell time delays. Moreover, we also incorporate learning and adaptation of individual passengers based on their experience with the network. Applications include studying the evolution of perceived travel times as a result of adaptation, the impact of an increase in capacity, or network effects due to changes in the timetable such as the addition or the removal of a service or a whole line. The proposed framework has been experimentally evaluated with public transport networks of G\\\"ottingen and Stuttgart (Germany). The simulation proves to be highly efficient. On a standard PC the computation of a traffic assignment takes just a few seconds per simulation day.","sentences":["Traffic assignment is a core component of many urban transport planning tools.","It is used to determine how traffic is distributed over a transportation network.","We study the task of computing traffic assignments for public transport: Given a public transit network, a timetable, vehicle capacities and a demand (i.e. a list of passengers, each with an associated origin, destination, and departure time), the goal is to predict the resulting passenger flow and the corresponding load of each vehicle.","Microscopic stochastic simulation of individual passengers is a standard, but computationally expensive approach.","Briem et al.","(2017) have shown that a clever adaptation of the Connection Scan Algorithm (CSA) can lead to highly efficient traffic assignment algorithms, but ignores vehicle capacities, resulting in overcrowded vehicles.","Taking their work as a starting point, we here propose a new and extended model that guarantees capacity-feasible assignments and incorporates dynamic network congestion effects such as crowded vehicles, denied boarding, and dwell time delays.","Moreover, we also incorporate learning and adaptation of individual passengers based on their experience with the network.","Applications include studying the evolution of perceived travel times as a result of adaptation, the impact of an increase in capacity, or network effects due to changes in the timetable such as the addition or the removal of a service or a whole line.","The proposed framework has been experimentally evaluated with public transport networks of G\\\"ottingen and Stuttgart (Germany).","The simulation proves to be highly efficient.","On a standard PC the computation of a traffic assignment takes just a few seconds per simulation day."],"url":"http://arxiv.org/abs/2408.06308v1"}
{"created":"2024-08-12 17:17:35","title":"From SAM to SAM 2: Exploring Improvements in Meta's Segment Anything Model","abstract":"The Segment Anything Model (SAM), introduced to the computer vision community by Meta in April 2023, is a groundbreaking tool that allows automated segmentation of objects in images based on prompts such as text, clicks, or bounding boxes. SAM excels in zero-shot performance, segmenting unseen objects without additional training, stimulated by a large dataset of over one billion image masks. SAM 2 expands this functionality to video, leveraging memory from preceding and subsequent frames to generate accurate segmentation across entire videos, enabling near real-time performance. This comparison shows how SAM has evolved to meet the growing need for precise and efficient segmentation in various applications. The study suggests that future advancements in models like SAM will be crucial for improving computer vision technology.","sentences":["The Segment Anything Model (SAM), introduced to the computer vision community by Meta in April 2023, is a groundbreaking tool that allows automated segmentation of objects in images based on prompts such as text, clicks, or bounding boxes.","SAM excels in zero-shot performance, segmenting unseen objects without additional training, stimulated by a large dataset of over one billion image masks.","SAM 2 expands this functionality to video, leveraging memory from preceding and subsequent frames to generate accurate segmentation across entire videos, enabling near real-time performance.","This comparison shows how SAM has evolved to meet the growing need for precise and efficient segmentation in various applications.","The study suggests that future advancements in models like SAM will be crucial for improving computer vision technology."],"url":"http://arxiv.org/abs/2408.06305v1"}
{"created":"2024-08-12 17:17:16","title":"Control-Flow Attestation: Concepts, Solutions, and Open Challenges","abstract":"Control-flow attestation (CFA) unifies the worlds of control-flow integrity and platform attestation by measuring and reporting a target's run-time behaviour to a verifier. Trust assurances in the target are provided by testing whether its execution follows an authorised control-flow path. The problem has been explored in various settings, such as assessing the trustworthiness of cyber-physical systems, Internet of Things devices, cloud platforms, and many others. Despite a significant number of proposals being made in recent years, the area remains fragmented, addressing different adversarial behaviours, verification paradigms, and deployment challenges. In this paper, we present the first survey of control-flow attestation, examining the core ideas and solutions in state-of-the-art schemes. In total, we survey over 30 papers published between 2016-2024, consolidate and compare their key features, and pose several challenges and recommendations for future research in the area.","sentences":["Control-flow attestation (CFA) unifies the worlds of control-flow integrity and platform attestation by measuring and reporting a target's run-time behaviour to a verifier.","Trust assurances in the target are provided by testing whether its execution follows an authorised control-flow path.","The problem has been explored in various settings, such as assessing the trustworthiness of cyber-physical systems, Internet of Things devices, cloud platforms, and many others.","Despite a significant number of proposals being made in recent years, the area remains fragmented, addressing different adversarial behaviours, verification paradigms, and deployment challenges.","In this paper, we present the first survey of control-flow attestation, examining the core ideas and solutions in state-of-the-art schemes.","In total, we survey over 30 papers published between 2016-2024, consolidate and compare their key features, and pose several challenges and recommendations for future research in the area."],"url":"http://arxiv.org/abs/2408.06304v1"}
{"created":"2024-08-12 17:15:02","title":"Long-Form Answers to Visual Questions from Blind and Low Vision People","abstract":"Vision language models can now generate long-form answers to questions about images - long-form visual question answers (LFVQA). We contribute VizWiz-LF, a dataset of long-form answers to visual questions posed by blind and low vision (BLV) users. VizWiz-LF contains 4.2k long-form answers to 600 visual questions, collected from human expert describers and six VQA models. We develop and annotate functional roles of sentences of LFVQA and demonstrate that long-form answers contain information beyond the question answer such as explanations and suggestions. We further conduct automatic and human evaluations with BLV and sighted people to evaluate long-form answers. BLV people perceive both human-written and generated long-form answers to be plausible, but generated answers often hallucinate incorrect visual details, especially for unanswerable visual questions (e.g., blurry or irrelevant images). To reduce hallucinations, we evaluate the ability of VQA models to abstain from answering unanswerable questions across multiple prompting strategies.","sentences":["Vision language models can now generate long-form answers to questions about images - long-form visual question answers (LFVQA).","We contribute VizWiz-LF, a dataset of long-form answers to visual questions posed by blind and low vision (BLV) users.","VizWiz-LF contains 4.2k long-form answers to 600 visual questions, collected from human expert describers and six VQA models.","We develop and annotate functional roles of sentences of LFVQA and demonstrate that long-form answers contain information beyond the question answer such as explanations and suggestions.","We further conduct automatic and human evaluations with BLV and sighted people to evaluate long-form answers.","BLV people perceive both human-written and generated long-form answers to be plausible, but generated answers often hallucinate incorrect visual details, especially for unanswerable visual questions (e.g., blurry or irrelevant images).","To reduce hallucinations, we evaluate the ability of VQA models to abstain from answering unanswerable questions across multiple prompting strategies."],"url":"http://arxiv.org/abs/2408.06303v1"}
{"created":"2024-08-12 17:14:41","title":"Finding Patterns in Ambiguity: Interpretable Stress Testing in the Decision~Boundary","abstract":"The increasing use of deep learning across various domains highlights the importance of understanding the decision-making processes of these black-box models. Recent research focusing on the decision boundaries of deep classifiers, relies on generated synthetic instances in areas of low confidence, uncovering samples that challenge both models and humans. We propose a novel approach to enhance the interpretability of deep binary classifiers by selecting representative samples from the decision boundary - prototypes - and applying post-model explanation algorithms. We evaluate the effectiveness of our approach through 2D visualizations and GradientSHAP analysis. Our experiments demonstrate the potential of the proposed method, revealing distinct and compact clusters and diverse prototypes that capture essential features that lead to low-confidence decisions. By offering a more aggregated view of deep classifiers' decision boundaries, our work contributes to the responsible development and deployment of reliable machine learning systems.","sentences":["The increasing use of deep learning across various domains highlights the importance of understanding the decision-making processes of these black-box models.","Recent research focusing on the decision boundaries of deep classifiers, relies on generated synthetic instances in areas of low confidence, uncovering samples that challenge both models and humans.","We propose a novel approach to enhance the interpretability of deep binary classifiers by selecting representative samples from the decision boundary - prototypes - and applying post-model explanation algorithms.","We evaluate the effectiveness of our approach through 2D visualizations and GradientSHAP analysis.","Our experiments demonstrate the potential of the proposed method, revealing distinct and compact clusters and diverse prototypes that capture essential features that lead to low-confidence decisions.","By offering a more aggregated view of deep classifiers' decision boundaries, our work contributes to the responsible development and deployment of reliable machine learning systems."],"url":"http://arxiv.org/abs/2408.06302v1"}
{"created":"2024-08-12 17:08:31","title":"LEARN: An Invex Loss for Outlier Oblivious Robust Online Optimization","abstract":"We study a robust online convex optimization framework, where an adversary can introduce outliers by corrupting loss functions in an arbitrary number of rounds k, unknown to the learner. Our focus is on a novel setting allowing unbounded domains and large gradients for the losses without relying on a Lipschitz assumption. We introduce the Log Exponential Adjusted Robust and iNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the effects of outliers and develop a robust variant of the online gradient descent algorithm by leveraging the LEARN loss. We establish tight regret guarantees (up to constants), in a dynamic setting, with respect to the uncorrupted rounds and conduct experiments to validate our theory. Furthermore, we present a unified analysis framework for developing online optimization algorithms for non-convex (invex) losses, utilizing it to provide regret bounds with respect to the LEARN loss, which may be of independent interest.","sentences":["We study a robust online convex optimization framework, where an adversary can introduce outliers by corrupting loss functions in an arbitrary number of rounds k, unknown to the learner.","Our focus is on a novel setting allowing unbounded domains and large gradients for the losses without relying on a Lipschitz assumption.","We introduce the Log Exponential Adjusted Robust and iNvex (LEARN) loss, a non-convex (invex) robust loss function to mitigate the effects of outliers and develop a robust variant of the online gradient descent algorithm by leveraging the LEARN loss.","We establish tight regret guarantees (up to constants), in a dynamic setting, with respect to the uncorrupted rounds and conduct experiments to validate our theory.","Furthermore, we present a unified analysis framework for developing online optimization algorithms for non-convex (invex) losses, utilizing it to provide regret bounds with respect to the LEARN loss, which may be of independent interest."],"url":"http://arxiv.org/abs/2408.06297v1"}
{"created":"2024-08-12 17:04:51","title":"Hound: Locating Cryptographic Primitives in Desynchronized Side-Channel Traces Using Deep-Learning","abstract":"Side-channel attacks allow to extract sensitive information from cryptographic primitives by correlating the partially known computed data and the measured side-channel signal. Starting from the raw side-channel trace, the preprocessing of the side-channel trace to pinpoint the time at which each cryptographic primitive is executed, and, then, to re-align all the collected data to this specific time represent a critical step to setup a successful side-channel attack. The use of hiding techniques has been widely adopted as a low-cost solution to hinder the preprocessing of side-channel traces thus limiting side-channel attacks in real scenarios. This work introduces Hound, a novel deep learning-based pipeline to locate the execution of cryptographic primitives within the side-channel trace even in the presence of trace deformations introduced by the use of dynamic frequency scaling actuators. Hound has been validated through successful attacks on various cryptographic primitives executed on an FPGA-based system-on-chip incorporating a RISC-V CPU, while dynamic frequency scaling is active. Experimental results demonstrate the possibility of identifying the cryptographic primitives in DFS-deformed side-channel traces.","sentences":["Side-channel attacks allow to extract sensitive information from cryptographic primitives by correlating the partially known computed data and the measured side-channel signal.","Starting from the raw side-channel trace, the preprocessing of the side-channel trace to pinpoint the time at which each cryptographic primitive is executed, and, then, to re-align all the collected data to this specific time represent a critical step to setup a successful side-channel attack.","The use of hiding techniques has been widely adopted as a low-cost solution to hinder the preprocessing of side-channel traces thus limiting side-channel attacks in real scenarios.","This work introduces Hound, a novel deep learning-based pipeline to locate the execution of cryptographic primitives within the side-channel trace even in the presence of trace deformations introduced by the use of dynamic frequency scaling actuators.","Hound has been validated through successful attacks on various cryptographic primitives executed on an FPGA-based system-on-chip incorporating a RISC-V CPU, while dynamic frequency scaling is active.","Experimental results demonstrate the possibility of identifying the cryptographic primitives in DFS-deformed side-channel traces."],"url":"http://arxiv.org/abs/2408.06296v1"}
{"created":"2024-08-12 17:04:28","title":"Dual Threats in RIS-Aided RF-UOWC Mixed Networks: Secrecy Performance Analysis under Simultaneous RF and UOWC Eavesdropping","abstract":"In the dynamic realm of 6G technology, emphasizing security is essential, particularly for optimizing high-performance communication. A notable strategy involves the use of reconfigurable intelligent surfaces (RISs), an emerging and cost-efficient technology aimed at fortifying incoming signals, broadening coverage, and ultimately improving the overall performance of systems. In this paper, we introduce a comprehensive framework to analyze the secrecy performance of an RIS-assisted mixed radio frequency (RF) - underwater optical wireless communication (UOWC) network. Here, all the RF links undergo alpha-mu fading distribution, whereas the UOWC links experience a mixture of Exponential Generalized Gamma distribution. Specifically, we examine three potential eavesdropping situations: 1) eavesdropping on the RF link, 2) eavesdropping on the UOWC link, and 3) a simultaneous eavesdropping attack affecting both RF and UOWC links. To achieve this, we derive novel mathematical expressions such as average secrecy capacity, secrecy outage probability, strictly positive secrecy capacity, and effective secrecy throughput in closed form. Using these derived expressions, we carry out an investigation to assess the influences of fading parameters, pointing errors, receiver detection technique, underwater turbulence severity, and water salinity on the system. Furthermore, our study investigates the significance of RIS in improving secrecy performance due to the proposed model. To provide deeper insights, we also perform asymptotic analysis for the high signal-to-noise region. Finally, to verify our analytical results, we conduct Monte Carlo simulation using a computer-based technique.","sentences":["In the dynamic realm of 6G technology, emphasizing security is essential, particularly for optimizing high-performance communication.","A notable strategy involves the use of reconfigurable intelligent surfaces (RISs), an emerging and cost-efficient technology aimed at fortifying incoming signals, broadening coverage, and ultimately improving the overall performance of systems.","In this paper, we introduce a comprehensive framework to analyze the secrecy performance of an RIS-assisted mixed radio frequency (RF) - underwater optical wireless communication (UOWC) network.","Here, all the RF links undergo alpha-mu fading distribution, whereas the UOWC links experience a mixture of Exponential Generalized Gamma distribution.","Specifically, we examine three potential eavesdropping situations: 1) eavesdropping on the RF link, 2) eavesdropping on the UOWC link, and 3) a simultaneous eavesdropping attack affecting both RF and UOWC links.","To achieve this, we derive novel mathematical expressions such as average secrecy capacity, secrecy outage probability, strictly positive secrecy capacity, and effective secrecy throughput in closed form.","Using these derived expressions, we carry out an investigation to assess the influences of fading parameters, pointing errors, receiver detection technique, underwater turbulence severity, and water salinity on the system.","Furthermore, our study investigates the significance of RIS in improving secrecy performance due to the proposed model.","To provide deeper insights, we also perform asymptotic analysis for the high signal-to-noise region.","Finally, to verify our analytical results, we conduct Monte Carlo simulation using a computer-based technique."],"url":"http://arxiv.org/abs/2408.06295v1"}
{"created":"2024-08-12 17:04:11","title":"AniBalloons: Animated Chat Balloons as Affective Augmentation for Social Messaging and Chatbot Interaction","abstract":"Despite being prominent and ubiquitous, text message-based communication is limited in nonverbally conveying emotions. Besides emoticons or stickers, messaging users continue seeking richer options for affective communication. Recent research explored using chat balloons' shape and color to communicate emotional states. However, little work explored whether and how chat-balloon animations could be designed to convey emotions. We present the design of AniBalloons, 30 chat-balloon animations conveying Joy, Anger, Sadness, Surprise, Fear, and Calmness. Using AniBalloons as a research means, we conducted three studies to assess the animations' affect recognizability and emotional properties (N = 40), and probe how animated chat balloons would influence communication experience in typical scenarios including instant messaging (N = 72) and chatbot service (N = 70). Our exploration contributes a set of chat-balloon animations to complement non-nonverbal affective communication for a range of text-message interfaces, and empirical insights into how animated chat balloons might mediate particular conversation experiences (e.g., perceived interpersonal closeness, or chatbot personality).","sentences":["Despite being prominent and ubiquitous, text message-based communication is limited in nonverbally conveying emotions.","Besides emoticons or stickers, messaging users continue seeking richer options for affective communication.","Recent research explored using chat balloons' shape and color to communicate emotional states.","However, little work explored whether and how chat-balloon animations could be designed to convey emotions.","We present the design of AniBalloons, 30 chat-balloon animations conveying Joy, Anger, Sadness, Surprise, Fear, and Calmness.","Using AniBalloons as a research means, we conducted three studies to assess the animations' affect recognizability and emotional properties (N = 40), and probe how animated chat balloons would influence communication experience in typical scenarios including instant messaging (N = 72) and chatbot service (N","= 70).","Our exploration contributes a set of chat-balloon animations to complement non-nonverbal affective communication for a range of text-message interfaces, and empirical insights into how animated chat balloons might mediate particular conversation experiences (e.g., perceived interpersonal closeness, or chatbot personality)."],"url":"http://arxiv.org/abs/2408.06294v1"}
{"created":"2024-08-12 16:58:11","title":"The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery","abstract":"One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aids to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems. Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist","sentences":["One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge.","While frontier models have already been used as aids to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process.","This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings.","We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation.","In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community.","We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics.","Each idea is implemented and developed into a full paper at a cost of less than $15 per paper.","To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores.","The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer.","This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the entire research process of AI itself, and taking us closer to a world where endless affordable creativity and innovation can be unleashed on the world's most challenging problems.","Our code is open-sourced at https://github.com/SakanaAI/AI-Scientist"],"url":"http://arxiv.org/abs/2408.06292v1"}
{"created":"2024-08-12 16:57:57","title":"Mambular: A Sequential Model for Tabular Deep Learning","abstract":"The analysis of tabular data has traditionally been dominated by gradient-boosted decision trees (GBDTs), known for their proficiency with mixed categorical and numerical features. However, recent deep learning innovations are challenging this dominance. We introduce Mambular, an adaptation of the Mamba architecture optimized for tabular data. We extensively benchmark Mambular against state-of-the-art models, including neural networks and tree-based methods, and demonstrate its competitive performance across diverse datasets. Additionally, we explore various adaptations of Mambular to understand its effectiveness for tabular data. We investigate different pooling strategies, feature interaction mechanisms, and bi-directional processing. Our analysis shows that interpreting features as a sequence and passing them through Mamba layers results in surprisingly performant models. The results highlight Mambulars potential as a versatile and powerful architecture for tabular data analysis, expanding the scope of deep learning applications in this domain.   The source code is available at https://github.com/basf/mamba-tabular.","sentences":["The analysis of tabular data has traditionally been dominated by gradient-boosted decision trees (GBDTs), known for their proficiency with mixed categorical and numerical features.","However, recent deep learning innovations are challenging this dominance.","We introduce Mambular, an adaptation of the Mamba architecture optimized for tabular data.","We extensively benchmark Mambular against state-of-the-art models, including neural networks and tree-based methods, and demonstrate its competitive performance across diverse datasets.","Additionally, we explore various adaptations of Mambular to understand its effectiveness for tabular data.","We investigate different pooling strategies, feature interaction mechanisms, and bi-directional processing.","Our analysis shows that interpreting features as a sequence and passing them through Mamba layers results in surprisingly performant models.","The results highlight Mambulars potential as a versatile and powerful architecture for tabular data analysis, expanding the scope of deep learning applications in this domain.   ","The source code is available at https://github.com/basf/mamba-tabular."],"url":"http://arxiv.org/abs/2408.06291v1"}
{"created":"2024-08-12 16:53:44","title":"RIS-Aided Free-Space Optics Communications in A2G Networks over Inverted Gamma-Gamma Turbulent Channels","abstract":"With the advent of sixth-generation networks, reconfigurable intelligent surfaces (RISs) have revolutionized wireless communications through dynamic electromagnetic wave manipulation, thereby facilitating the adaptability and unparalleled control of real-time performance evaluations. This study proposed a framework to analyze the performance of RIS-assisted free-space optics (FSO) communication over doubly inverted Gamma-Gamma (IGGG) distributions with pointing error impairments. Furthermore, a special scenario addressing secure communication in the potential presence of an eavesdropper. Consequently, we derived closed-form expressions for the outage probability, average bit error rate, average channel capacity, average secrecy capacity, and secrecy outage probability by employing an asymptotic analysis to provide deeper insights into the influence of various system parameters. Finally, we verified our analytical results through appropriate numerical simulations.","sentences":["With the advent of sixth-generation networks, reconfigurable intelligent surfaces (RISs) have revolutionized wireless communications through dynamic electromagnetic wave manipulation, thereby facilitating the adaptability and unparalleled control of real-time performance evaluations.","This study proposed a framework to analyze the performance of RIS-assisted free-space optics (FSO) communication over doubly inverted Gamma-Gamma (IGGG) distributions with pointing error impairments.","Furthermore, a special scenario addressing secure communication in the potential presence of an eavesdropper.","Consequently, we derived closed-form expressions for the outage probability, average bit error rate, average channel capacity, average secrecy capacity, and secrecy outage probability by employing an asymptotic analysis to provide deeper insights into the influence of various system parameters.","Finally, we verified our analytical results through appropriate numerical simulations."],"url":"http://arxiv.org/abs/2408.06288v1"}
{"created":"2024-08-12 16:49:22","title":"Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM","abstract":"Medical dialogue systems (MDS) enhance patient-physician communication, improve healthcare accessibility, and reduce costs. However, acquiring suitable data to train these systems poses significant challenges. Privacy concerns prevent the use of real conversations, necessitating synthetic alternatives. Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safeguarding privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high-quality synthetic dialogues. The feedback consists of weighted evaluation scores for similarity and extractiveness. The iterative process ensures dialogues meet predefined thresholds, achieving superior extractiveness as a result of the feedback loop. Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4.","sentences":["Medical dialogue systems (MDS) enhance patient-physician communication, improve healthcare accessibility, and reduce costs.","However, acquiring suitable data to train these systems poses significant challenges.","Privacy concerns prevent the use of real conversations, necessitating synthetic alternatives.","Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safeguarding privacy.","Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high-quality synthetic dialogues.","The feedback consists of weighted evaluation scores for similarity and extractiveness.","The iterative process ensures dialogues meet predefined thresholds, achieving superior extractiveness as a result of the feedback loop.","Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4."],"url":"http://arxiv.org/abs/2408.06285v1"}
{"created":"2024-08-12 16:49:22","title":"Mipmap-GS: Let Gaussians Deform with Scale-specific Mipmap for Anti-aliasing Rendering","abstract":"3D Gaussian Splatting (3DGS) has attracted great attention in novel view synthesis because of its superior rendering efficiency and high fidelity. However, the trained Gaussians suffer from severe zooming degradation due to non-adjustable representation derived from single-scale training. Though some methods attempt to tackle this problem via post-processing techniques such as selective rendering or filtering techniques towards primitives, the scale-specific information is not involved in Gaussians. In this paper, we propose a unified optimization method to make Gaussians adaptive for arbitrary scales by self-adjusting the primitive properties (e.g., color, shape and size) and distribution (e.g., position). Inspired by the mipmap technique, we design pseudo ground-truth for the target scale and propose a scale-consistency guidance loss to inject scale information into 3D Gaussians. Our method is a plug-in module, applicable for any 3DGS models to solve the zoom-in and zoom-out aliasing. Extensive experiments demonstrate the effectiveness of our method. Notably, our method outperforms 3DGS in PSNR by an average of 9.25 dB for zoom-in and 10.40 dB for zoom-out on the NeRF Synthetic dataset.","sentences":["3D Gaussian Splatting (3DGS) has attracted great attention in novel view synthesis because of its superior rendering efficiency and high fidelity.","However, the trained Gaussians suffer from severe zooming degradation due to non-adjustable representation derived from single-scale training.","Though some methods attempt to tackle this problem via post-processing techniques such as selective rendering or filtering techniques towards primitives, the scale-specific information is not involved in Gaussians.","In this paper, we propose a unified optimization method to make Gaussians adaptive for arbitrary scales by self-adjusting the primitive properties (e.g., color, shape and size) and distribution (e.g., position).","Inspired by the mipmap technique, we design pseudo ground-truth for the target scale and propose a scale-consistency guidance loss to inject scale information into 3D Gaussians.","Our method is a plug-in module, applicable for any 3DGS models to solve the zoom-in and zoom-out aliasing.","Extensive experiments demonstrate the effectiveness of our method.","Notably, our method outperforms 3DGS in PSNR by an average of 9.25 dB for zoom-in and 10.40 dB for zoom-out on the NeRF Synthetic dataset."],"url":"http://arxiv.org/abs/2408.06286v1"}
{"created":"2024-08-12 16:44:57","title":"A characterization for an almost MDS code to be a near MDS code and a proof of the Geng-Yang-Zhang-Zhou conjecture","abstract":"Let $\\mathbb{F}_q$ be the finite field of $q$ elements, where $q=p^{m}$ with $p$ being a prime number and $m$ being a positive integer. Let $\\mathcal{C}_{(q, n, \\delta, h)}$ be a class of BCH codes of length $n$ and designed $\\delta$. A linear code $\\mathcal{C}$ is said to be maximum distance separable (MDS) if the minimum distance $d=n-k+1$. If $d=n-k$, then $\\mathcal{C}$ is called an almost MDS (AMDS) code. Moreover, if both of $\\mathcal{C}$ and its dual code $\\mathcal{C}^{\\bot}$ are AMDS, then $\\mathcal{C}$ is called a near MDS (NMDS) code. In [A class of almost MDS codes, {\\it Finite Fields Appl.} {\\bf 79} (2022), \\#101996], Geng, Yang, Zhang and Zhou proved that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is an almost MDS code, where $q=3^m$ and $m$ is an odd integer, and they also showed that its parameters is $[q+1, q-3, 4]$. Furthermore, they proposed a conjecture stating that the dual code $\\mathcal{C}^{\\bot}_{(q, q+1, 3, 4)}$ is also an AMDS code with parameters $[q+1, 4, q-3]$. In this paper, we first present a characterization for the dual code of an almost MDS code to be an almost MDS code. Then we use this result to show that the Geng-Yang-Zhang-Zhou conjecture is true. Our result together with the Geng-Yang-Zhang-Zhou theorem implies that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is a near MDS code.","sentences":["Let $\\mathbb{F}_q$ be the finite field of $q$ elements, where $q=p^{m}$ with $p$ being a prime number and $m$ being a positive integer.","Let $\\mathcal{C}_{(q, n, \\delta, h)}$ be a class of BCH codes of length $n$ and designed $\\delta$. A linear code $\\mathcal{C}$ is said to be maximum distance separable (MDS) if the minimum distance $d=n-k+1$. If $d=n-k$, then $\\mathcal{C}$ is called an almost MDS (AMDS) code.","Moreover, if both of $\\mathcal{C}$ and its dual code $\\mathcal{C}^{\\bot}$ are AMDS, then $\\mathcal{C}$ is called a near MDS (NMDS) code.","In [A class of almost MDS codes, {\\it Finite Fields Appl.} {\\bf 79} (2022), \\#101996], Geng, Yang, Zhang and Zhou proved that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is an almost MDS code, where $q=3^m$ and $m$ is an odd integer, and they also showed that its parameters is $[q+1, q-3, 4]$.","Furthermore, they proposed a conjecture stating that the dual code $\\mathcal{C}^{\\bot}_{(q, q+1, 3, 4)}$ is also an AMDS code with parameters $[q+1, 4, q-3]$. In this paper, we first present a characterization for the dual code of an almost MDS code to be an almost MDS code.","Then we use this result to show that the Geng-Yang-Zhang-Zhou conjecture is true.","Our result together with the Geng-Yang-Zhang-Zhou theorem implies that the BCH code $\\mathcal{C}_{(q, q+1,3,4)}$ is a near MDS code."],"url":"http://arxiv.org/abs/2408.06282v1"}
{"created":"2024-08-12 16:43:09","title":"MovieSum: An Abstractive Summarization Dataset for Movie Screenplays","abstract":"Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies. Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts. Furthermore, while television transcripts have received attention in recent studies, movie screenplay summarization remains underexplored. To stimulate research in this area, we present a new dataset, MovieSum, for abstractive summarization of movie screenplays. This dataset comprises 2200 movie screenplays accompanied by their Wikipedia plot summaries. We manually formatted the movie screenplays to represent their structural elements. Compared to existing datasets, MovieSum possesses several distinctive features: (1) It includes movie screenplays, which are longer than scripts of TV episodes. (2) It is twice the size of previous movie screenplay datasets. (3) It provides metadata with IMDb IDs to facilitate access to additional external knowledge. We also show the results of recently released large language models applied to summarization on our dataset to provide a detailed baseline.","sentences":["Movie screenplay summarization is challenging, as it requires an understanding of long input contexts and various elements unique to movies.","Large language models have shown significant advancements in document summarization, but they often struggle with processing long input contexts.","Furthermore, while television transcripts have received attention in recent studies, movie screenplay summarization remains underexplored.","To stimulate research in this area, we present a new dataset, MovieSum, for abstractive summarization of movie screenplays.","This dataset comprises 2200 movie screenplays accompanied by their Wikipedia plot summaries.","We manually formatted the movie screenplays to represent their structural elements.","Compared to existing datasets, MovieSum possesses several distinctive features: (1) It includes movie screenplays, which are longer than scripts of TV episodes.","(2) It is twice the size of previous movie screenplay datasets.","(3) It provides metadata with IMDb IDs to facilitate access to additional external knowledge.","We also show the results of recently released large language models applied to summarization on our dataset to provide a detailed baseline."],"url":"http://arxiv.org/abs/2408.06281v1"}
{"created":"2024-08-12 16:39:03","title":"Review-driven Personalized Preference Reasoning with Large Language Models for Recommendation","abstract":"Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems. However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities. To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews. EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles. It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions. This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation. Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems.","sentences":["Recent advancements in Large Language Models (LLMs) have demonstrated exceptional performance across a wide range of tasks, generating significant interest in their application to recommendation systems.","However, existing methods have not fully capitalized on the potential of LLMs, often constrained by limited input information or failing to fully utilize their advanced reasoning capabilities.","To address these limitations, we introduce EXP3RT, a novel LLM-based recommender designed to leverage rich preference information contained in user and item reviews.","EXP3RT is basically fine-tuned through distillation from a teacher LLM to perform three key tasks in order: EXP3RT first extracts and encapsulates essential subjective preferences from raw reviews, aggregates and summarizes them according to specific criteria to create user and item profiles.","It then generates detailed step-by-step reasoning followed by predicted rating, i.e., reasoning-enhanced rating prediction, by considering both subjective and objective information from user/item profiles and item descriptions.","This personalized preference reasoning from EXP3RT enhances rating prediction accuracy and also provides faithful and reasonable explanations for recommendation.","Extensive experiments show that EXP3RT outperforms existing methods on both rating prediction and candidate item reranking for top-k recommendation, while significantly enhancing the explainability of recommendation systems."],"url":"http://arxiv.org/abs/2408.06276v1"}
{"created":"2024-08-12 16:37:48","title":"Robust Instance Optimal Phase-Only Compressed Sensing","abstract":"Phase-only compressed sensing (PO-CS) is concerned with the recovery of structured signals from the phases of complex measurements. Recent results show that structured signals in the standard sphere $\\mathbb{S}^{n-1}$ can be exactly recovered from complex Gaussian phases, by recasting PO-CS as linear compressed sensing and then applying existing solvers such as basis pursuit. Known guarantees are either non-uniform or do not tolerate model error. We show that this linearization approach is more powerful than the prior results indicate. First, it achieves uniform instance optimality: Under complex Gaussian matrix with a near-optimal number of rows, this approach uniformly recovers all signals in $\\mathbb{S}^{n-1}$ with errors proportional to the model errors of the signals. Specifically, for sparse recovery there exists an efficient estimator $\\mathbf{x}^\\sharp$ and some universal constant $C$ such that $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2\\le \\frac{C\\sigma_s(\\mathbf{x})_1}{\\sqrt{s}}~(\\forall\\mathbf{x}\\in\\mathbb{S}^{n-1})$, where $\\sigma_s(\\mathbf{x})_1=\\min_{\\mathbf{u}\\in\\Sigma^n_s}\\|\\mathbf{u}-\\mathbf{x}\\|_1$ is the model error under $\\ell_1$-norm. Second, the instance optimality is robust to small dense disturbances and sparse corruptions that arise before or after capturing the phases. As an extension, we also propose to recast sparsely corrupted PO-CS as a linear corrupted sensing problem and show that this achieves perfect reconstruction of the signals. Our results resemble the instance optimal guarantees in linear compressed sensing and, to our knowledge, are the first results of this kind for a non-linear sensing scenario.","sentences":["Phase-only compressed sensing (PO-CS) is concerned with the recovery of structured signals from the phases of complex measurements.","Recent results show that structured signals in the standard sphere $\\mathbb{S}^{n-1}$ can be exactly recovered from complex Gaussian phases, by recasting PO-CS as linear compressed sensing and then applying existing solvers such as basis pursuit.","Known guarantees are either non-uniform or do not tolerate model error.","We show that this linearization approach is more powerful than the prior results indicate.","First, it achieves uniform instance optimality: Under complex Gaussian matrix with a near-optimal number of rows, this approach uniformly recovers all signals in $\\mathbb{S}^{n-1}$ with errors proportional to the model errors of the signals.","Specifically, for sparse recovery there exists an efficient estimator $\\mathbf{x}^\\sharp$ and some universal constant $C$ such that $\\|\\mathbf{x}^\\sharp-\\mathbf{x}\\|_2\\le \\frac{C\\sigma_s(\\mathbf{x})_1}{\\sqrt{s}}~(\\forall\\mathbf{x}\\in\\mathbb{S}^{n-1})$, where $\\sigma_s(\\mathbf{x})_1=\\min_{\\mathbf{u}\\in\\Sigma^n_s}\\|\\mathbf{u}-\\mathbf{x}\\|_1$ is the model error under $\\ell_1$-norm.","Second, the instance optimality is robust to small dense disturbances and sparse corruptions that arise before or after capturing the phases.","As an extension, we also propose to recast sparsely corrupted PO-CS as a linear corrupted sensing problem and show that this achieves perfect reconstruction of the signals.","Our results resemble the instance optimal guarantees in linear compressed sensing and, to our knowledge, are the first results of this kind for a non-linear sensing scenario."],"url":"http://arxiv.org/abs/2408.06275v1"}
{"created":"2024-08-12 16:34:56","title":"FuxiTranyu: A Multilingual Large Language Model Trained with Balanced Data","abstract":"Large language models (LLMs) have demonstrated prowess in a wide range of tasks. However, many LLMs exhibit significant performance discrepancies between high- and low-resource languages. To mitigate this challenge, we present FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the need of the research community for balanced and high-performing multilingual capabilities. FuxiTranyu-8B, the base model with 8 billion parameters, is trained from scratch on a meticulously balanced multilingual data repository that contains 600 billion tokens covering 43 natural languages and 16 programming languages. In addition to the base model, we also develop two instruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diverse multilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refined with DPO on a preference dataset for enhanced alignment ability. Extensive experiments on a wide range of multilingual benchmarks demonstrate the competitive performance of FuxiTranyu against existing multilingual LLMs, e.g., BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct. Interpretability analyses at both the neuron and representation level suggest that FuxiTranyu is able to learn consistent multilingual representations across different languages. To promote further research into multilingual LLMs and their working mechanisms, we release both the base and instruction-tuned FuxiTranyu models together with 58 pretraining checkpoints at HuggingFace and Github.","sentences":["Large language models (LLMs) have demonstrated prowess in a wide range of tasks.","However, many LLMs exhibit significant performance discrepancies between high- and low-resource languages.","To mitigate this challenge, we present FuxiTranyu, an open-source multilingual LLM, which is designed to satisfy the need of the research community for balanced and high-performing multilingual capabilities.","FuxiTranyu-8B, the base model with 8 billion parameters, is trained from scratch on a meticulously balanced multilingual data repository that contains 600 billion tokens covering 43 natural languages and 16 programming languages.","In addition to the base model, we also develop two instruction-tuned models: FuxiTranyu-8B-SFT that is fine-tuned on a diverse multilingual instruction dataset, and FuxiTranyu-8B-DPO that is further refined with DPO on a preference dataset for enhanced alignment ability.","Extensive experiments on a wide range of multilingual benchmarks demonstrate the competitive performance of FuxiTranyu against existing multilingual LLMs, e.g., BLOOM-7B, PolyLM-13B, Llama-2-Chat-7B and Mistral-7B-Instruct.","Interpretability analyses at both the neuron and representation level suggest that FuxiTranyu is able to learn consistent multilingual representations across different languages.","To promote further research into multilingual LLMs and their working mechanisms, we release both the base and instruction-tuned FuxiTranyu models together with 58 pretraining checkpoints at HuggingFace and Github."],"url":"http://arxiv.org/abs/2408.06273v1"}
{"created":"2024-08-12 16:33:51","title":"A RAG-Based Question-Answering Solution for Cyber-Attack Investigation and Attribution","abstract":"In the constantly evolving field of cybersecurity, it is imperative for analysts to stay abreast of the latest attack trends and pertinent information that aids in the investigation and attribution of cyber-attacks. In this work, we introduce the first question-answering (QA) model and its application that provides information to the cybersecurity experts about cyber-attacks investigations and attribution. Our QA model is based on Retrieval Augmented Generation (RAG) techniques together with a Large Language Model (LLM) and provides answers to the users' queries based on either our knowledge base (KB) that contains curated information about cyber-attacks investigations and attribution or on outside resources provided by the users. We have tested and evaluated our QA model with various types of questions, including KB-based, metadata-based, specific documents from the KB, and external sources-based questions. We compared the answers for KB-based questions with those from OpenAI's GPT-3.5 and the latest GPT-4o LLMs. Our proposed QA model outperforms OpenAI's GPT models by providing the source of the answers and overcoming the hallucination limitations of the GPT models, which is critical for cyber-attack investigation and attribution. Additionally, our analysis showed that when the RAG QA model is given few-shot examples rather than zero-shot instructions, it generates better answers compared to cases where no examples are supplied in addition to the query.","sentences":["In the constantly evolving field of cybersecurity, it is imperative for analysts to stay abreast of the latest attack trends and pertinent information that aids in the investigation and attribution of cyber-attacks.","In this work, we introduce the first question-answering (QA) model and its application that provides information to the cybersecurity experts about cyber-attacks investigations and attribution.","Our QA model is based on Retrieval Augmented Generation (RAG) techniques together with a Large Language Model (LLM) and provides answers to the users' queries based on either our knowledge base (KB) that contains curated information about cyber-attacks investigations and attribution or on outside resources provided by the users.","We have tested and evaluated our QA model with various types of questions, including KB-based, metadata-based, specific documents from the KB, and external sources-based questions.","We compared the answers for KB-based questions with those from OpenAI's GPT-3.5 and the latest GPT-4o LLMs.","Our proposed QA model outperforms OpenAI's GPT models by providing the source of the answers and overcoming the hallucination limitations of the GPT models, which is critical for cyber-attack investigation and attribution.","Additionally, our analysis showed that when the RAG QA model is given few-shot examples rather than zero-shot instructions, it generates better answers compared to cases where no examples are supplied in addition to the query."],"url":"http://arxiv.org/abs/2408.06272v1"}
{"created":"2024-08-12 16:28:01","title":"Testing the Isotropic Cauchy Hypothesis","abstract":"Isotropic $\\alpha$-stable distributions are central in the theory of heavy-tailed distributions and play a role similar to that of the Gaussian density among finite second-moment laws. Given a sequence of $n$ observations, we are interested in characterizing the performance of Likelihood Ratio Tests where two hypotheses are plausible for the observed quantities: either isotropic Cauchy or isotropic Gaussian. Under various setups, we show that the probability of error of such detectors is not always exponentially decaying with $n$ with the leading term in the exponent shown to be logarithmic instead and we determine the constants in that leading term. Perhaps surprisingly, the optimal Bayesian probabilities of error are found to exhibit different asymptotic behaviors.","sentences":["Isotropic $\\alpha$-stable distributions are central in the theory of heavy-tailed distributions and play a role similar to that of the Gaussian density among finite second-moment laws.","Given a sequence of $n$ observations, we are interested in characterizing the performance of Likelihood Ratio Tests where two hypotheses are plausible for the observed quantities: either isotropic Cauchy or isotropic Gaussian.","Under various setups, we show that the probability of error of such detectors is not always exponentially decaying with $n$ with the leading term in the exponent shown to be logarithmic instead and we determine the constants in that leading term.","Perhaps surprisingly, the optimal Bayesian probabilities of error are found to exhibit different asymptotic behaviors."],"url":"http://arxiv.org/abs/2408.06269v1"}
{"created":"2024-08-12 16:24:51","title":"Anchored Preference Optimization and Contrastive Revisions: Addressing Underspecification in Alignment","abstract":"Large Language Models (LLMs) are often aligned using contrastive alignment objectives and preference pair datasets. The interaction between model, paired data, and objective makes alignment a complicated procedure, sometimes producing subpar results. We study this and find that (i) preference data gives a better learning signal when the underlying responses are contrastive, and (ii) alignment objectives lead to better performance when they specify more control over the model during training. Based on these insights, we introduce Contrastive Learning from AI Revisions (CLAIR), a data-creation method which leads to more contrastive preference pairs, and Anchored Preference Optimization (APO), a controllable and more stable alignment objective. We align Llama-3-8B-Instruct using various comparable datasets and alignment objectives and measure MixEval-Hard scores, which correlate highly with human judgments. The CLAIR preferences lead to the strongest performance out of all datasets, and APO consistently outperforms less controllable objectives. Our best model, trained on 32K CLAIR preferences with APO, improves Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%. Our code is available at https://github.com/ContextualAI/CLAIR_and_APO.","sentences":["Large Language Models (LLMs) are often aligned using contrastive alignment objectives and preference pair datasets.","The interaction between model, paired data, and objective makes alignment a complicated procedure, sometimes producing subpar results.","We study this and find that (i) preference data gives a better learning signal when the underlying responses are contrastive, and (ii) alignment objectives lead to better performance when they specify more control over the model during training.","Based on these insights, we introduce Contrastive Learning from AI Revisions (CLAIR), a data-creation method which leads to more contrastive preference pairs, and Anchored Preference Optimization (APO), a controllable and more stable alignment objective.","We align Llama-3-8B-Instruct using various comparable datasets and alignment objectives and measure MixEval-Hard scores, which correlate highly with human judgments.","The CLAIR preferences lead to the strongest performance out of all datasets, and APO consistently outperforms less controllable objectives.","Our best model, trained on 32K CLAIR preferences with APO, improves Llama-3-8B-Instruct by 7.65%, closing the gap with GPT4-turbo by 45%.","Our code is available at https://github.com/ContextualAI/CLAIR_and_APO."],"url":"http://arxiv.org/abs/2408.06266v1"}
{"created":"2024-08-12 16:24:21","title":"EyeSight Hand: Design of a Fully-Actuated Dexterous Robot Hand with Integrated Vision-Based Tactile Sensors and Compliant Actuation","abstract":"In this work, we introduce the EyeSight Hand, a novel 7 degrees of freedom (DoF) humanoid hand featuring integrated vision-based tactile sensors tailored for enhanced whole-hand manipulation. Additionally, we introduce an actuation scheme centered around quasi-direct drive actuation to achieve human-like strength and speed while ensuring robustness for large-scale data collection. We evaluate the EyeSight Hand on three challenging tasks: bottle opening, plasticine cutting, and plate pick and place, which require a blend of complex manipulation, tool use, and precise force application. Imitation learning models trained on these tasks, with a novel vision dropout strategy, showcase the benefits of tactile feedback in enhancing task success rates. Our results reveal that the integration of tactile sensing dramatically improves task performance, underscoring the critical role of tactile information in dexterous manipulation.","sentences":["In this work, we introduce the EyeSight Hand, a novel 7 degrees of freedom (DoF) humanoid hand featuring integrated vision-based tactile sensors tailored for enhanced whole-hand manipulation.","Additionally, we introduce an actuation scheme centered around quasi-direct drive actuation to achieve human-like strength and speed while ensuring robustness for large-scale data collection.","We evaluate the EyeSight Hand on three challenging tasks: bottle opening, plasticine cutting, and plate pick and place, which require a blend of complex manipulation, tool use, and precise force application.","Imitation learning models trained on these tasks, with a novel vision dropout strategy, showcase the benefits of tactile feedback in enhancing task success rates.","Our results reveal that the integration of tactile sensing dramatically improves task performance, underscoring the critical role of tactile information in dexterous manipulation."],"url":"http://arxiv.org/abs/2408.06265v1"}
{"created":"2024-08-12 16:23:58","title":"Audio Enhancement for Computer Audition -- An Iterative Training Paradigm Using Sample Importance","abstract":"Neural network models for audio tasks, such as automatic speech recognition (ASR) and acoustic scene classification (ASC), are susceptible to noise contamination for real-life applications. To improve audio quality, an enhancement module, which can be developed independently, is explicitly used at the front-end of the target audio applications. In this paper, we present an end-to-end learning solution to jointly optimise the models for audio enhancement (AE) and the subsequent applications. To guide the optimisation of the AE module towards a target application, and especially to overcome difficult samples, we make use of the sample-wise performance measure as an indication of sample importance. In experiments, we consider four representative applications to evaluate our training paradigm, i.e., ASR, speech command recognition (SCR), speech emotion recognition (SER), and ASC. These applications are associated with speech and non-speech tasks concerning semantic and non-semantic features, transient and global information, and the experimental results indicate that our proposed approach can considerably boost the noise robustness of the models, especially at low signal-to-noise ratios (SNRs), for a wide range of computer audition tasks in everyday-life noisy environments.","sentences":["Neural network models for audio tasks, such as automatic speech recognition (ASR) and acoustic scene classification (ASC), are susceptible to noise contamination for real-life applications.","To improve audio quality, an enhancement module, which can be developed independently, is explicitly used at the front-end of the target audio applications.","In this paper, we present an end-to-end learning solution to jointly optimise the models for audio enhancement (AE) and the subsequent applications.","To guide the optimisation of the AE module towards a target application, and especially to overcome difficult samples, we make use of the sample-wise performance measure as an indication of sample importance.","In experiments, we consider four representative applications to evaluate our training paradigm, i.e., ASR, speech command recognition (SCR), speech emotion recognition (SER), and ASC.","These applications are associated with speech and non-speech tasks concerning semantic and non-semantic features, transient and global information, and the experimental results indicate that our proposed approach can considerably boost the noise robustness of the models, especially at low signal-to-noise ratios (SNRs), for a wide range of computer audition tasks in everyday-life noisy environments."],"url":"http://arxiv.org/abs/2408.06264v1"}
{"created":"2024-08-12 16:22:30","title":"DUNE: A Machine Learning Deep UNet++ based Ensemble Approach to Monthly, Seasonal and Annual Climate Forecasting","abstract":"Capitalizing on the recent availability of ERA5 monthly averaged long-term data records of mean atmospheric and climate fields based on high-resolution reanalysis, deep-learning architectures offer an alternative to physics-based daily numerical weather predictions for subseasonal to seasonal (S2S) and annual means. A novel Deep UNet++-based Ensemble (DUNE) neural architecture is introduced, employing multi-encoder-decoder structures with residual blocks. When initialized from a prior month or year, this architecture produced the first AI-based global monthly, seasonal, or annual mean forecast of 2-meter temperatures (T2m) and sea surface temperatures (SST). ERA5 monthly mean data is used as input for T2m over land, SST over oceans, and solar radiation at the top of the atmosphere for each month of 40 years to train the model. Validation forecasts are performed for an additional two years, followed by five years of forecast evaluations to account for natural annual variability. AI-trained inference forecast weights generate forecasts in seconds, enabling ensemble seasonal forecasts. Root Mean Squared Error (RMSE), Anomaly Correlation Coefficient (ACC), and Heidke Skill Score (HSS) statistics are presented globally and over specific regions. These forecasts outperform persistence, climatology, and multiple linear regression for all domains. DUNE forecasts demonstrate comparable statistical accuracy to NOAA's operational monthly and seasonal probabilistic outlook forecasts over the US but at significantly higher resolutions. RMSE and ACC error statistics for other recent AI-based daily forecasts also show superior performance for DUNE-based forecasts. The DUNE model's application to an ensemble data assimilation cycle shows comparable forecast accuracy with a single high-resolution model, potentially eliminating the need for retraining on extrapolated datasets.","sentences":["Capitalizing on the recent availability of ERA5 monthly averaged long-term data records of mean atmospheric and climate fields based on high-resolution reanalysis, deep-learning architectures offer an alternative to physics-based daily numerical weather predictions for subseasonal to seasonal (S2S) and annual means.","A novel Deep UNet++-based Ensemble (DUNE) neural architecture is introduced, employing multi-encoder-decoder structures with residual blocks.","When initialized from a prior month or year, this architecture produced the first AI-based global monthly, seasonal, or annual mean forecast of 2-meter temperatures (T2m) and sea surface temperatures (SST).","ERA5 monthly mean data is used as input for T2m over land, SST over oceans, and solar radiation at the top of the atmosphere for each month of 40 years to train the model.","Validation forecasts are performed for an additional two years, followed by five years of forecast evaluations to account for natural annual variability.","AI-trained inference forecast weights generate forecasts in seconds, enabling ensemble seasonal forecasts.","Root Mean Squared Error (RMSE), Anomaly Correlation Coefficient (ACC), and Heidke Skill Score (HSS) statistics are presented globally and over specific regions.","These forecasts outperform persistence, climatology, and multiple linear regression for all domains.","DUNE forecasts demonstrate comparable statistical accuracy to NOAA's operational monthly and seasonal probabilistic outlook forecasts over the US but at significantly higher resolutions.","RMSE and ACC error statistics for other recent AI-based daily forecasts also show superior performance for DUNE-based forecasts.","The DUNE model's application to an ensemble data assimilation cycle shows comparable forecast accuracy with a single high-resolution model, potentially eliminating the need for retraining on extrapolated datasets."],"url":"http://arxiv.org/abs/2408.06262v1"}
{"created":"2024-08-12 16:21:29","title":"Open-Source Molecular Processing Pipeline for Generating Molecules","abstract":"Generative models for molecules have shown considerable promise for use in computational chemistry, but remain difficult to use for non-experts. For this reason, we introduce open-source infrastructure for easily building generative molecular models into the widely used DeepChem [Ramsundar et al., 2019] library with the aim of creating a robust and reusable molecular generation pipeline. In particular, we add high quality PyTorch [Paszke et al., 2019] implementations of the Molecular Generative Adversarial Networks (MolGAN) [Cao and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021]. Our implementations show strong performance comparable with past work [Kuznetsov and Polykovskiy, 2021, Cao and Kipf, 2022].","sentences":["Generative models for molecules have shown considerable promise for use in computational chemistry, but remain difficult to use for non-experts.","For this reason, we introduce open-source infrastructure for easily building generative molecular models into the widely used DeepChem","[Ramsundar et al., 2019] library with the aim of creating a robust and reusable molecular generation pipeline.","In particular, we add high quality PyTorch","[Paszke et al., 2019]","implementations of the Molecular Generative Adversarial Networks (MolGAN)","[Cao and Kipf, 2022] and Normalizing Flows [Papamakarios et al., 2021].","Our implementations show strong performance comparable with past work [Kuznetsov and Polykovskiy, 2021, Cao and Kipf, 2022]."],"url":"http://arxiv.org/abs/2408.06261v1"}
{"created":"2024-08-12 16:15:32","title":"Context-aware Visual Storytelling with Visual Prefix Tuning and Contrastive Learning","abstract":"Visual storytelling systems generate multi-sentence stories from image sequences. In this task, capturing contextual information and bridging visual variation bring additional challenges. We propose a simple yet effective framework that leverages the generalization capabilities of pretrained foundation models, only training a lightweight vision-language mapping network to connect modalities, while incorporating context to enhance coherence. We introduce a multimodal contrastive objective that also improves visual relevance and story informativeness. Extensive experimental results, across both automatic metrics and human evaluations, demonstrate that the stories generated by our framework are diverse, coherent, informative, and interesting.","sentences":["Visual storytelling systems generate multi-sentence stories from image sequences.","In this task, capturing contextual information and bridging visual variation bring additional challenges.","We propose a simple yet effective framework that leverages the generalization capabilities of pretrained foundation models, only training a lightweight vision-language mapping network to connect modalities, while incorporating context to enhance coherence.","We introduce a multimodal contrastive objective that also improves visual relevance and story informativeness.","Extensive experimental results, across both automatic metrics and human evaluations, demonstrate that the stories generated by our framework are diverse, coherent, informative, and interesting."],"url":"http://arxiv.org/abs/2408.06259v1"}
{"created":"2024-08-12 16:14:55","title":"Deep Learning System Boundary Testing through Latent Space Style Mixing","abstract":"Evaluating the behavioral frontier of deep learning (DL) systems is crucial for understanding their generalizability and robustness. However, boundary testing is challenging due to their high-dimensional input space. Generative artificial intelligence offers a promising solution by modeling data distribution within compact latent space representations, thereby facilitating finer-grained explorations. In this work, we introduce MIMICRY, a novel black-box system-agnostic test generator that leverages these latent representations to generate frontier inputs for the DL systems under test. Specifically, MIMICRY uses style-based generative adversarial networks trained to learn the representation of inputs with disentangled features. This representation enables embedding style-mixing operations between a source and a target input, combining their features to explore the boundary between them. We evaluated the effectiveness of different MIMICRY configurations in generating boundary inputs for four popular DL image classification systems. Our results show that manipulating the latent space allows for effective and efficient exploration of behavioral frontiers. As opposed to a model-based baseline, MIMICRY generates a higher quality frontier of behaviors which includes more and closer inputs. Additionally, we assessed the validity of these inputs, revealing a high validity rate according to human assessors.","sentences":["Evaluating the behavioral frontier of deep learning (DL) systems is crucial for understanding their generalizability and robustness.","However, boundary testing is challenging due to their high-dimensional input space.","Generative artificial intelligence offers a promising solution by modeling data distribution within compact latent space representations, thereby facilitating finer-grained explorations.","In this work, we introduce MIMICRY, a novel black-box system-agnostic test generator that leverages these latent representations to generate frontier inputs for the DL systems under test.","Specifically, MIMICRY uses style-based generative adversarial networks trained to learn the representation of inputs with disentangled features.","This representation enables embedding style-mixing operations between a source and a target input, combining their features to explore the boundary between them.","We evaluated the effectiveness of different MIMICRY configurations in generating boundary inputs for four popular DL image classification systems.","Our results show that manipulating the latent space allows for effective and efficient exploration of behavioral frontiers.","As opposed to a model-based baseline, MIMICRY generates a higher quality frontier of behaviors which includes more and closer inputs.","Additionally, we assessed the validity of these inputs, revealing a high validity rate according to human assessors."],"url":"http://arxiv.org/abs/2408.06258v1"}
{"created":"2024-08-12 16:03:13","title":"Learning in Time-Varying Monotone Network Games with Dynamic Populations","abstract":"In this paper, we present a framework for multi-agent learning in a nonstationary dynamic network environment. More specifically, we examine projected gradient play in smooth monotone repeated network games in which the agents' participation and connectivity vary over time. We model this changing system with a stochastic network which takes a new independent realization at each repetition. We show that the strategy profile learned by the agents through projected gradient dynamics over the sequence of network realizations converges to a Nash equilibrium of the game in which players minimize their expected cost, almost surely and in the mean-square sense. We then show that the learned strategy profile is an almost Nash equilibrium of the game played by the agents at each stage of the repeated game with high probability. Using these two results, we derive non-asymptotic bounds on the regret incurred by the agents.","sentences":["In this paper, we present a framework for multi-agent learning in a nonstationary dynamic network environment.","More specifically, we examine projected gradient play in smooth monotone repeated network games in which the agents' participation and connectivity vary over time.","We model this changing system with a stochastic network which takes a new independent realization at each repetition.","We show that the strategy profile learned by the agents through projected gradient dynamics over the sequence of network realizations converges to a Nash equilibrium of the game in which players minimize their expected cost, almost surely and in the mean-square sense.","We then show that the learned strategy profile is an almost Nash equilibrium of the game played by the agents at each stage of the repeated game with high probability.","Using these two results, we derive non-asymptotic bounds on the regret incurred by the agents."],"url":"http://arxiv.org/abs/2408.06253v1"}
{"created":"2024-08-12 16:00:17","title":"Rethinking Video with a Universal Event-Based Representation","abstract":"Traditionally, video is structured as a sequence of discrete image frames. Recently, however, a novel video sensing paradigm has emerged which eschews video frames entirely. These \"event\" sensors aim to mimic the human vision system with asynchronous sensing, where each pixel has an independent, sparse data stream. While these cameras enable high-speed and high-dynamic-range sensing, researchers often revert to a framed representation of the event data for existing applications, or build bespoke applications for a particular camera's event data type. At the same time, classical video systems have significant computational redundancy at the application layer, since pixel samples are repeated across frames in the uncompressed domain.   To address the shortcomings of existing systems, I introduce Address, Decimation, {\\Delta}t Event Representation (AD{\\Delta}ER, pronounced \"adder\"), a novel intermediate video representation and system framework. The framework transcodes a variety of framed and event camera sources into a single event-based representation, which supports source-modeled lossy compression and backward compatibility with traditional frame-based applications. I demonstrate that AD{\\Delta}ER achieves state-of-the-art application speed and compression performance for scenes with high temporal redundancy. Crucially, I describe how AD{\\Delta}ER unlocks an entirely new control mechanism for computer vision: application speed can correlate with both the scene content and the level of lossy compression. Finally, I discuss the implications for event-based video on large-scale video surveillance and resource-constrained sensing.","sentences":["Traditionally, video is structured as a sequence of discrete image frames.","Recently, however, a novel video sensing paradigm has emerged which eschews video frames entirely.","These \"event\" sensors aim to mimic the human vision system with asynchronous sensing, where each pixel has an independent, sparse data stream.","While these cameras enable high-speed and high-dynamic-range sensing, researchers often revert to a framed representation of the event data for existing applications, or build bespoke applications for a particular camera's event data type.","At the same time, classical video systems have significant computational redundancy at the application layer, since pixel samples are repeated across frames in the uncompressed domain.   ","To address the shortcomings of existing systems, I introduce Address, Decimation, {\\Delta}t Event Representation (AD{\\Delta}ER, pronounced \"adder\"), a novel intermediate video representation and system framework.","The framework transcodes a variety of framed and event camera sources into a single event-based representation, which supports source-modeled lossy compression and backward compatibility with traditional frame-based applications.","I demonstrate that AD{\\Delta}ER achieves state-of-the-art application speed and compression performance for scenes with high temporal redundancy.","Crucially, I describe how AD{\\Delta}ER unlocks an entirely new control mechanism for computer vision: application speed can correlate with both the scene content and the level of lossy compression.","Finally, I discuss the implications for event-based video on large-scale video surveillance and resource-constrained sensing."],"url":"http://arxiv.org/abs/2408.06248v1"}
{"created":"2024-08-12 15:56:53","title":"Stable-BC: Controlling Covariate Shift with Stable Behavior Cloning","abstract":"Behavior cloning is a common imitation learning paradigm. Under behavior cloning the robot collects expert demonstrations, and then trains a policy to match the actions taken by the expert. This works well when the robot learner visits states where the expert has already demonstrated the correct action; but inevitably the robot will also encounter new states outside of its training dataset. If the robot learner takes the wrong action at these new states it could move farther from the training data, which in turn leads to increasingly incorrect actions and compounding errors. Existing works try to address this fundamental challenge by augmenting or enhancing the training data. By contrast, in our paper we develop the control theoretic properties of behavior cloned policies. Specifically, we consider the error dynamics between the system's current state and the states in the expert dataset. From the error dynamics we derive model-based and model-free conditions for stability: under these conditions the robot shapes its policy so that its current behavior converges towards example behaviors in the expert dataset. In practice, this results in Stable-BC, an easy to implement extension of standard behavior cloning that is provably robust to covariate shift. We demonstrate the effectiveness of our algorithm in simulations with interactive, nonlinear, and visual environments. We also conduct experiments where a robot arm uses Stable-BC to play air hockey. See our website here: https://collab.me.vt.edu/Stable-BC/","sentences":["Behavior cloning is a common imitation learning paradigm.","Under behavior cloning the robot collects expert demonstrations, and then trains a policy to match the actions taken by the expert.","This works well when the robot learner visits states where the expert has already demonstrated the correct action; but inevitably the robot will also encounter new states outside of its training dataset.","If the robot learner takes the wrong action at these new states it could move farther from the training data, which in turn leads to increasingly incorrect actions and compounding errors.","Existing works try to address this fundamental challenge by augmenting or enhancing the training data.","By contrast, in our paper we develop the control theoretic properties of behavior cloned policies.","Specifically, we consider the error dynamics between the system's current state and the states in the expert dataset.","From the error dynamics we derive model-based and model-free conditions for stability: under these conditions the robot shapes its policy so that its current behavior converges towards example behaviors in the expert dataset.","In practice, this results in Stable-BC, an easy to implement extension of standard behavior cloning that is provably robust to covariate shift.","We demonstrate the effectiveness of our algorithm in simulations with interactive, nonlinear, and visual environments.","We also conduct experiments where a robot arm uses Stable-BC to play air hockey.","See our website here: https://collab.me.vt.edu/Stable-BC/"],"url":"http://arxiv.org/abs/2408.06246v1"}
{"created":"2024-08-12 15:54:46","title":"Latent Disentanglement for Low Light Image Enhancement","abstract":"Many learning-based low-light image enhancement (LLIE) algorithms are based on the Retinex theory. However, the Retinex-based decomposition techniques in such models introduce corruptions which limit their enhancement performance. In this paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net) for low light vision tasks. The latent disentanglement module disentangles the input image in latent space such that no corruption remains in the disentangled Content and Illumination components. For LLIE task, we design a Content-Aware Embedding (CAE) module that utilizes Content features to direct the enhancement of the Illumination component. For downstream tasks (e.g. nighttime UAV tracking and low-light object detection), we develop an effective light-weight enhancer based on the latent disentanglement framework. Comprehensive quantitative and qualitative experiments demonstrate that our LDE-Net significantly outperforms state-of-the-art methods on various LLIE benchmarks. In addition, the great results obtained by applying our framework on the downstream tasks also demonstrate the usefulness of our latent disentanglement design.","sentences":["Many learning-based low-light image enhancement (LLIE) algorithms are based on the Retinex theory.","However, the Retinex-based decomposition techniques in such models introduce corruptions which limit their enhancement performance.","In this paper, we propose a Latent Disentangle-based Enhancement Network (LDE-Net) for low light vision tasks.","The latent disentanglement module disentangles the input image in latent space such that no corruption remains in the disentangled Content and Illumination components.","For LLIE task, we design a Content-Aware Embedding (CAE) module that utilizes Content features to direct the enhancement of the Illumination component.","For downstream tasks (e.g. nighttime UAV tracking and low-light object detection), we develop an effective light-weight enhancer based on the latent disentanglement framework.","Comprehensive quantitative and qualitative experiments demonstrate that our LDE-Net significantly outperforms state-of-the-art methods on various LLIE benchmarks.","In addition, the great results obtained by applying our framework on the downstream tasks also demonstrate the usefulness of our latent disentanglement design."],"url":"http://arxiv.org/abs/2408.06245v1"}
{"created":"2024-08-12 15:53:24","title":"3D Reconstruction of Protein Structures from Multi-view AFM Images using Neural Radiance Fields (NeRFs)","abstract":"Recent advancements in deep learning for predicting 3D protein structures have shown promise, particularly when leveraging inputs like protein sequences and Cryo-Electron microscopy (Cryo-EM) images. However, these techniques often fall short when predicting the structures of protein complexes (PCs), which involve multiple proteins. In our study, we investigate using atomic force microscopy (AFM) combined with deep learning to predict the 3D structures of PCs. AFM generates height maps that depict the PCs in various random orientations, providing a rich information for training a neural network to predict the 3D structures. We then employ the pre-trained UpFusion model (which utilizes a conditional diffusion model for synthesizing novel views) to train an instance-specific NeRF model for 3D reconstruction. The performance of UpFusion is evaluated through zero-shot predictions of 3D protein structures using AFM images. The challenge, however, lies in the time-intensive and impractical nature of collecting actual AFM images. To address this, we use a virtual AFM imaging process that transforms a `PDB' protein file into multi-view 2D virtual AFM images via volume rendering techniques. We extensively validate the UpFusion architecture using both virtual and actual multi-view AFM images. Our results include a comparison of structures predicted with varying numbers of views and different sets of views. This novel approach holds significant potential for enhancing the accuracy of protein complex structure predictions with further fine-tuning of the UpFusion network.","sentences":["Recent advancements in deep learning for predicting 3D protein structures have shown promise, particularly when leveraging inputs like protein sequences and Cryo-Electron microscopy (Cryo-EM) images.","However, these techniques often fall short when predicting the structures of protein complexes (PCs), which involve multiple proteins.","In our study, we investigate using atomic force microscopy (AFM) combined with deep learning to predict the 3D structures of PCs.","AFM generates height maps that depict the PCs in various random orientations, providing a rich information for training a neural network to predict the 3D structures.","We then employ the pre-trained UpFusion model (which utilizes a conditional diffusion model for synthesizing novel views) to train an instance-specific NeRF model for 3D reconstruction.","The performance of UpFusion is evaluated through zero-shot predictions of 3D protein structures using AFM images.","The challenge, however, lies in the time-intensive and impractical nature of collecting actual AFM images.","To address this, we use a virtual AFM imaging process that transforms a `PDB' protein file into multi-view 2D virtual AFM images via volume rendering techniques.","We extensively validate the UpFusion architecture using both virtual and actual multi-view AFM images.","Our results include a comparison of structures predicted with varying numbers of views and different sets of views.","This novel approach holds significant potential for enhancing the accuracy of protein complex structure predictions with further fine-tuning of the UpFusion network."],"url":"http://arxiv.org/abs/2408.06244v1"}
{"created":"2024-08-12 15:48:30","title":"Sequential non-determinism in tile self-assembly: a general framework and an application to efficient temperature-1 self-assembly of squares","abstract":"In this paper, we work in a 2D version of the probabilistic variant of Winfree's abstract Tile Assembly Model defined by Chandran, Gopalkrishnan and Reif (SICOMP 2012) in which attaching tiles are sampled uniformly with replacement. First, we develop a framework called ``sequential non-determinism'' for analyzing the probabilistic correctness of a non-deterministic, temperature-1 tile assembly system (TAS) in which most (but not all) tile attachments are deterministic and the non-deterministic attachments always occur in a specific order. Our main sequential non-determinism result equates the probabilistic correctness of such a TAS to a finite product of probabilities, each of which 1) corresponds to the probability of the correct type of tile attaching at a point where it is possible for two different types to attach, and 2) ignores all other tile attachments that do not affect the non-deterministic attachment. We then show that sequential non-determinism allows for efficient and geometrically expressive self-assembly. To that end, we constructively prove that for any positive integer $N$ and any real $\\delta \\in (0,1)$, there exists a TAS that self-assembles into an $N \\times N$ square with probability at least $1 - \\delta$ using only $O\\left( \\log N + \\log \\frac{1}{\\delta} \\right)$ types of tiles. Our bound improves upon the previous state-of-the-art bound for this problem by Cook, Fu and Schweller (SODA 2011).","sentences":["In this paper, we work in a 2D version of the probabilistic variant of Winfree's abstract Tile Assembly Model defined by Chandran, Gopalkrishnan and Reif (SICOMP 2012) in which attaching tiles are sampled uniformly with replacement.","First, we develop a framework called ``sequential non-determinism'' for analyzing the probabilistic correctness of a non-deterministic, temperature-1 tile assembly system (TAS) in which most (but not all) tile attachments are deterministic and the non-deterministic attachments always occur in a specific order.","Our main sequential non-determinism result equates the probabilistic correctness of such a TAS to a finite product of probabilities, each of which 1) corresponds to the probability of the correct type of tile attaching at a point where it is possible for two different types to attach, and 2) ignores all other tile attachments that do not affect the non-deterministic attachment.","We then show that sequential non-determinism allows for efficient and geometrically expressive self-assembly.","To that end, we constructively prove that for any positive integer $N$ and any real $\\delta \\in (0,1)$, there exists a TAS that self-assembles into an $N \\times N$ square with probability at least $1 - \\delta$ using only $O\\left( \\log N + \\log \\frac{1}{\\delta} \\right)$ types of tiles.","Our bound improves upon the previous state-of-the-art bound for this problem by Cook, Fu and Schweller (SODA 2011)."],"url":"http://arxiv.org/abs/2408.06241v1"}
{"created":"2024-08-12 15:47:26","title":"Decentralized Intelligence Health Network (DIHN)","abstract":"Decentralized Intelligence Health Network (DIHN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions. It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources. This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution. This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party. It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms. Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions. This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage. It highlights the potential to transform healthcare data management and AI utilization while empowering patients.","sentences":["Decentralized Intelligence Health Network (DIHN) is a theoretical framework addressing significant challenges of health data sovereignty and AI utilization in healthcare caused by data fragmentation across providers and institutions.","It establishes a sovereign architecture for healthcare provision as a prerequisite to a sovereign health network, then facilitates effective AI utilization by overcoming barriers to accessing diverse medical data sources.","This comprehensive framework leverages: 1) self-sovereign identity architecture coupled with a personal health record (PHR) as a prerequisite for health data sovereignty; 2) a scalable federated learning (FL) protocol implemented on a public blockchain for decentralized AI training in healthcare, where health data remains with participants and only model parameter updates are shared; and 3) a scalable, trustless rewards mechanism to incentivize participation and ensure fair reward distribution.","This framework ensures that no entity can prevent or control access to training on health data offered by participants or determine financial benefits, as these processes operate on a public blockchain with an immutable record and without a third party.","It supports effective AI training in healthcare, allowing patients to maintain control over their health data, benefit financially, and contribute to a decentralized, scalable ecosystem that leverages collective AI to develop beneficial healthcare algorithms.","Patients receive rewards into their digital wallets as an incentive to opt-in to the FL protocol, with a long-term roadmap to funding decentralized insurance solutions.","This approach introduces a novel, self-financed healthcare model that adapts to individual needs, complements existing systems, and redefines universal coverage.","It highlights the potential to transform healthcare data management and AI utilization while empowering patients."],"url":"http://arxiv.org/abs/2408.06240v1"}
{"created":"2024-08-12 15:38:51","title":"Correlation Weighted Prototype-based Self-Supervised One-Shot Segmentation of Medical Images","abstract":"Medical image segmentation is one of the domains where sufficient annotated data is not available. This necessitates the application of low-data frameworks like few-shot learning. Contemporary prototype-based frameworks often do not account for the variation in features within the support and query images, giving rise to a large variance in prototype alignment. In this work, we adopt a prototype-based self-supervised one-way one-shot learning framework using pseudo-labels generated from superpixels to learn the semantic segmentation task itself. We use a correlation-based probability score to generate a dynamic prototype for each query pixel from the bag of prototypes obtained from the support feature map. This weighting scheme helps to give a higher weightage to contextually related prototypes. We also propose a quadrant masking strategy in the downstream segmentation task by utilizing prior domain information to discard unwanted false positives. We present extensive experimentations and evaluations on abdominal CT and MR datasets to show that the proposed simple but potent framework performs at par with the state-of-the-art methods.","sentences":["Medical image segmentation is one of the domains where sufficient annotated data is not available.","This necessitates the application of low-data frameworks like few-shot learning.","Contemporary prototype-based frameworks often do not account for the variation in features within the support and query images, giving rise to a large variance in prototype alignment.","In this work, we adopt a prototype-based self-supervised one-way one-shot learning framework using pseudo-labels generated from superpixels to learn the semantic segmentation task itself.","We use a correlation-based probability score to generate a dynamic prototype for each query pixel from the bag of prototypes obtained from the support feature map.","This weighting scheme helps to give a higher weightage to contextually related prototypes.","We also propose a quadrant masking strategy in the downstream segmentation task by utilizing prior domain information to discard unwanted false positives.","We present extensive experimentations and evaluations on abdominal CT and MR datasets to show that the proposed simple but potent framework performs at par with the state-of-the-art methods."],"url":"http://arxiv.org/abs/2408.06235v1"}
{"created":"2024-08-12 15:28:51","title":"FLEURS-R: A Restored Multilingual Speech Corpus for Generation Tasks","abstract":"This paper introduces FLEURS-R, a speech restoration applied version of the Few-shot Learning Evaluation of Universal Representations of Speech (FLEURS) corpus. FLEURS-R maintains an N-way parallel speech corpus in 102 languages as FLEURS, with improved audio quality and fidelity by applying the speech restoration model Miipher. The aim of FLEURS-R is to advance speech technology in more languages and catalyze research including text-to-speech (TTS) and other speech generation tasks in low-resource languages. Comprehensive evaluations with the restored speech and TTS baseline models trained from the new corpus show that the new corpus obtained significantly improved speech quality while maintaining the semantic contents of the speech. The corpus is publicly released via Hugging Face.","sentences":["This paper introduces FLEURS-R, a speech restoration applied version of the Few-shot Learning Evaluation of Universal Representations of Speech (FLEURS) corpus.","FLEURS-R maintains an N-way parallel speech corpus in 102 languages as FLEURS, with improved audio quality and fidelity by applying the speech restoration model Miipher.","The aim of FLEURS-R is to advance speech technology in more languages and catalyze research including text-to-speech (TTS) and other speech generation tasks in low-resource languages.","Comprehensive evaluations with the restored speech and TTS baseline models trained from the new corpus show that the new corpus obtained significantly improved speech quality while maintaining the semantic contents of the speech.","The corpus is publicly released via Hugging Face."],"url":"http://arxiv.org/abs/2408.06227v1"}
{"created":"2024-08-12 15:28:40","title":"A Large-Scale Study of Model Integration in ML-Enabled Software Systems","abstract":"The rise of machine learning (ML) and its embedding in systems has drastically changed the engineering of software-intensive systems. Traditionally, software engineering focuses on manually created artifacts such as source code and the process of creating them, as well as best practices for integrating them, i.e., software architectures. In contrast, the development of ML artifacts, i.e. ML models, comes from data science and focuses on the ML models and their training data. However, to deliver value to end users, these ML models must be embedded in traditional software, often forming complex topologies. In fact, ML-enabled software can easily incorporate many different ML models. While the challenges and practices of building ML-enabled systems have been studied to some extent, beyond isolated examples, little is known about the characteristics of real-world ML-enabled systems. Properly embedding ML models in systems so that they can be easily maintained or reused is far from trivial. We need to improve our empirical understanding of such systems, which we address by presenting the first large-scale study of real ML-enabled software systems, covering over 2,928 open source systems on GitHub. We classified and analyzed them to determine their characteristics, as well as their practices for reusing ML models and related code, and the architecture of these systems. Our findings provide practitioners and researchers with insight into practices for embedding and integrating ML models, bringing data science and software engineering closer together.","sentences":["The rise of machine learning (ML) and its embedding in systems has drastically changed the engineering of software-intensive systems.","Traditionally, software engineering focuses on manually created artifacts such as source code and the process of creating them, as well as best practices for integrating them, i.e., software architectures.","In contrast, the development of ML artifacts, i.e. ML models, comes from data science and focuses on the ML models and their training data.","However, to deliver value to end users, these ML models must be embedded in traditional software, often forming complex topologies.","In fact, ML-enabled software can easily incorporate many different ML models.","While the challenges and practices of building ML-enabled systems have been studied to some extent, beyond isolated examples, little is known about the characteristics of real-world ML-enabled systems.","Properly embedding ML models in systems so that they can be easily maintained or reused is far from trivial.","We need to improve our empirical understanding of such systems, which we address by presenting the first large-scale study of real ML-enabled software systems, covering over 2,928 open source systems on GitHub.","We classified and analyzed them to determine their characteristics, as well as their practices for reusing ML models and related code, and the architecture of these systems.","Our findings provide practitioners and researchers with insight into practices for embedding and integrating ML models, bringing data science and software engineering closer together."],"url":"http://arxiv.org/abs/2408.06226v1"}
{"created":"2024-08-12 15:26:36","title":"A Multi-Year Grey Literature Review on AI-assisted Test Automation","abstract":"Context: Test Automation (TA) techniques are crucial for quality assurance in software engineering but face limitations such as high test suite maintenance costs and the need for extensive programming skills. Artificial Intelligence (AI) offers new opportunities to address these issues through automation and improved practices. Objectives: This study surveys grey literature to explore how AI is adopted in TA, focusing on the problems it solves, its solutions, and the available tools. Additionally, the study gathers expert insights to understand AI's current and future role in TA. Methods: We reviewed over 3,600 grey literature sources over five years, including blogs, white papers, and user manuals, and finally filtered 342 documents to develop taxonomies of TA problems and AI solutions. We also cataloged 100 AI-driven TA tools and interviewed five expert software testers to gain insights into AI's current and future role in TA. Results: The study found that manual test code development and maintenance are the main challenges in TA. In contrast, automated test generation and self-healing test scripts are the most common AI solutions. We identified 100 AI-based TA tools, with Applitools, Testim, Functionize, AccelQ, and Mabl being the most adopted in practice. Conclusion: This paper offers a detailed overview of AI's impact on TA through grey literature analysis and expert interviews. It presents new taxonomies of TA problems and AI solutions, provides a catalog of AI-driven tools, and relates solutions to problems and tools to solutions. Interview insights further revealed the state and future potential of AI in TA. Our findings support practitioners in selecting TA tools and guide future research directions.","sentences":["Context: Test Automation (TA) techniques are crucial for quality assurance in software engineering but face limitations such as high test suite maintenance costs and the need for extensive programming skills.","Artificial Intelligence (AI) offers new opportunities to address these issues through automation and improved practices.","Objectives:","This study surveys grey literature to explore how AI is adopted in TA, focusing on the problems it solves, its solutions, and the available tools.","Additionally, the study gathers expert insights to understand AI's current and future role in TA.","Methods: We reviewed over 3,600 grey literature sources over five years, including blogs, white papers, and user manuals, and finally filtered 342 documents to develop taxonomies of TA problems and AI solutions.","We also cataloged 100 AI-driven TA tools and interviewed five expert software testers to gain insights into AI's current and future role in TA.","Results:","The study found that manual test code development and maintenance are the main challenges in TA.","In contrast, automated test generation and self-healing test scripts are the most common AI solutions.","We identified 100 AI-based TA tools, with Applitools, Testim, Functionize, AccelQ, and Mabl being the most adopted in practice.","Conclusion:","This paper offers a detailed overview of AI's impact on TA through grey literature analysis and expert interviews.","It presents new taxonomies of TA problems and AI solutions, provides a catalog of AI-driven tools, and relates solutions to problems and tools to solutions.","Interview insights further revealed the state and future potential of AI in TA.","Our findings support practitioners in selecting TA tools and guide future research directions."],"url":"http://arxiv.org/abs/2408.06224v1"}
{"created":"2024-08-12 15:24:50","title":"On Effects of Steering Latent Representation for Large Language Model Unlearning","abstract":"Representation Misdirection for Unlearning (RMU), which steers model representation in the intermediate layer to a target random representation, is an effective method for large language model (LLM) unlearning. Despite its high performance, the underlying cause and explanation remain underexplored. In this paper, we first theoretically demonstrate that steering forget representations in the intermediate layer reduces token confidence, causing LLMs to generate wrong or nonsense responses. Second, we investigate how the coefficient influences the alignment of forget-sample representations with the random direction and hint at the optimal coefficient values for effective unlearning across different network layers. Third, we show that RMU unlearned models are robust against adversarial jailbreak attacks. Last, our empirical analysis shows that RMU is less effective when applied to the middle and later layers in LLMs. To resolve this drawback, we propose Adaptive RMU -- a simple yet effective alternative method that makes unlearning effective with most layers. Extensive experiments demonstrate that Adaptive RMU significantly improves the unlearning performance compared to prior art while incurring no additional computational cost.","sentences":["Representation Misdirection for Unlearning (RMU), which steers model representation in the intermediate layer to a target random representation, is an effective method for large language model (LLM) unlearning.","Despite its high performance, the underlying cause and explanation remain underexplored.","In this paper, we first theoretically demonstrate that steering forget representations in the intermediate layer reduces token confidence, causing LLMs to generate wrong or nonsense responses.","Second, we investigate how the coefficient influences the alignment of forget-sample representations with the random direction and hint at the optimal coefficient values for effective unlearning across different network layers.","Third, we show that RMU unlearned models are robust against adversarial jailbreak attacks.","Last, our empirical analysis shows that RMU is less effective when applied to the middle and later layers in LLMs.","To resolve this drawback, we propose Adaptive RMU -- a simple yet effective alternative method that makes unlearning effective with most layers.","Extensive experiments demonstrate that Adaptive RMU significantly improves the unlearning performance compared to prior art while incurring no additional computational cost."],"url":"http://arxiv.org/abs/2408.06223v1"}
{"created":"2024-08-12 15:23:14","title":"ARCADE: An Augmented Reality Display Environment for Multimodal Interaction with Conversational Agents","abstract":"Making the interaction with embodied conversational agents accessible in a ubiquitous and natural manner is not only a question of the underlying software but also brings challenges in terms of the technical system that is used to display them. To this end, we present our spatial augmented reality system ARCADE, which can be utilized like a conventional monitor for displaying virtual agents as well as additional content. With its optical-see-through display, ARCADE creates the illusion of the agent being in the room similarly to a human. The applicability of our system is demonstrated in two different dialogue scenarios, which are included in the video accompanying this paper at https://youtu.be/9nH4c4Q-ooE.","sentences":["Making the interaction with embodied conversational agents accessible in a ubiquitous and natural manner is not only a question of the underlying software but also brings challenges in terms of the technical system that is used to display them.","To this end, we present our spatial augmented reality system ARCADE, which can be utilized like a conventional monitor for displaying virtual agents as well as additional content.","With its optical-see-through display, ARCADE creates the illusion of the agent being in the room similarly to a human.","The applicability of our system is demonstrated in two different dialogue scenarios, which are included in the video accompanying this paper at https://youtu.be/9nH4c4Q-ooE."],"url":"http://arxiv.org/abs/2408.06222v1"}
{"created":"2024-08-12 15:21:35","title":"A Digital Twin Framework Utilizing Machine Learning for Robust Predictive Maintenance: Enhancing Tire Health Monitoring","abstract":"We introduce a novel digital twin framework for predictive maintenance of long-term physical systems. Using monitoring tire health as an application, we show how the digital twin framework can be used to enhance automotive safety and efficiency, and how the technical challenges can be overcome using a three-step approach. Firstly, for managing the data complexity over a long operation span, we employ data reduction techniques to concisely represent physical tires using historical performance and usage data. Relying on these data, for fast real-time prediction, we train a transformer-based model offline on our concise dataset to predict future tire health over time, represented as Remaining Casing Potential (RCP). Based on our architecture, our model quantifies both epistemic and aleatoric uncertainty, providing reliable confidence intervals around predicted RCP. Secondly, to incorporate real-time data, we update the predictive model in the digital twin framework, ensuring its accuracy throughout its life span with the aid of hybrid modeling and the use of discrepancy function. Thirdly, to assist decision making in predictive maintenance, we implement a Tire State Decision Algorithm, which strategically determines the optimal timing for tire replacement based on RCP forecasted by our transformer model. This approach ensures our digital twin accurately predicts system health, continually refines its digital representation, and supports predictive maintenance decisions. Our framework effectively embodies a physical system, leveraging big data and machine learning for predictive maintenance, model updates, and decision-making.","sentences":["We introduce a novel digital twin framework for predictive maintenance of long-term physical systems.","Using monitoring tire health as an application, we show how the digital twin framework can be used to enhance automotive safety and efficiency, and how the technical challenges can be overcome using a three-step approach.","Firstly, for managing the data complexity over a long operation span, we employ data reduction techniques to concisely represent physical tires using historical performance and usage data.","Relying on these data, for fast real-time prediction, we train a transformer-based model offline on our concise dataset to predict future tire health over time, represented as Remaining Casing Potential (RCP).","Based on our architecture, our model quantifies both epistemic and aleatoric uncertainty, providing reliable confidence intervals around predicted RCP.","Secondly, to incorporate real-time data, we update the predictive model in the digital twin framework, ensuring its accuracy throughout its life span with the aid of hybrid modeling and the use of discrepancy function.","Thirdly, to assist decision making in predictive maintenance, we implement a Tire State Decision Algorithm, which strategically determines the optimal timing for tire replacement based on RCP forecasted by our transformer model.","This approach ensures our digital twin accurately predicts system health, continually refines its digital representation, and supports predictive maintenance decisions.","Our framework effectively embodies a physical system, leveraging big data and machine learning for predictive maintenance, model updates, and decision-making."],"url":"http://arxiv.org/abs/2408.06220v1"}
{"created":"2024-08-12 15:19:54","title":"120 Domain-Specific Languages for Security","abstract":"Security engineering, from security requirements engineering to the implementation of cryptographic protocols, is often supported by domain-specific languages (DSLs). Unfortunately, a lack of knowledge about these DSLs, such as which security aspects are addressed and when, hinders their effective use and further research. This systematic literature review examines 120 security-oriented DSLs based on six research questions concerning security aspects and goals, language-specific characteristics, integration into the software development lifecycle (SDLC), and effectiveness of the DSLs. We observe a high degree of fragmentation, which leads to opportunities for integration. We also need to improve the usability and evaluation of security DSLs.","sentences":["Security engineering, from security requirements engineering to the implementation of cryptographic protocols, is often supported by domain-specific languages (DSLs).","Unfortunately, a lack of knowledge about these DSLs, such as which security aspects are addressed and when, hinders their effective use and further research.","This systematic literature review examines 120 security-oriented DSLs based on six research questions concerning security aspects and goals, language-specific characteristics, integration into the software development lifecycle (SDLC), and effectiveness of the DSLs.","We observe a high degree of fragmentation, which leads to opportunities for integration.","We also need to improve the usability and evaluation of security DSLs."],"url":"http://arxiv.org/abs/2408.06219v1"}
{"created":"2024-08-12 15:07:30","title":"Batched Ranged Random Integer Generation","abstract":"Pseudorandom values are often generated as 64-bit binary words. These random words need to be converted into ranged values without statistical bias. We present an efficient algorithm to generate multiple independent uniformly-random bounded integers from a single uniformly-random binary word, without any bias. In the common case, our method uses one multiplication and no division operations per value produced. In practice, our algorithm can more than double the speed of unbiased random shuffling for small to moderately large arrays.","sentences":["Pseudorandom values are often generated as 64-bit binary words.","These random words need to be converted into ranged values without statistical bias.","We present an efficient algorithm to generate multiple independent uniformly-random bounded integers from a single uniformly-random binary word, without any bias.","In the common case, our method uses one multiplication and no division operations per value produced.","In practice, our algorithm can more than double the speed of unbiased random shuffling for small to moderately large arrays."],"url":"http://arxiv.org/abs/2408.06213v1"}
{"created":"2024-08-12 15:02:26","title":"Computability of Classification and Deep Learning: From Theoretical Limits to Practical Feasibility through Quantization","abstract":"The unwavering success of deep learning in the past decade led to the increasing prevalence of deep learning methods in various application fields. However, the downsides of deep learning, most prominently its lack of trustworthiness, may not be compatible with safety-critical or high-responsibility applications requiring stricter performance guarantees. Recently, several instances of deep learning applications have been shown to be subject to theoretical limitations of computability, undermining the feasibility of performance guarantees when employed on real-world computers. We extend the findings by studying computability in the deep learning framework from two perspectives: From an application viewpoint in the context of classification problems and a general limitation viewpoint in the context of training neural networks. In particular, we show restrictions on the algorithmic solvability of classification problems that also render the algorithmic detection of failure in computations in a general setting infeasible. Subsequently, we prove algorithmic limitations in training deep neural networks even in cases where the underlying problem is well-behaved. Finally, we end with a positive observation, showing that in quantized versions of classification and deep network training, computability restrictions do not arise or can be overcome to a certain degree.","sentences":["The unwavering success of deep learning in the past decade led to the increasing prevalence of deep learning methods in various application fields.","However, the downsides of deep learning, most prominently its lack of trustworthiness, may not be compatible with safety-critical or high-responsibility applications requiring stricter performance guarantees.","Recently, several instances of deep learning applications have been shown to be subject to theoretical limitations of computability, undermining the feasibility of performance guarantees when employed on real-world computers.","We extend the findings by studying computability in the deep learning framework from two perspectives: From an application viewpoint in the context of classification problems and a general limitation viewpoint in the context of training neural networks.","In particular, we show restrictions on the algorithmic solvability of classification problems that also render the algorithmic detection of failure in computations in a general setting infeasible.","Subsequently, we prove algorithmic limitations in training deep neural networks even in cases where the underlying problem is well-behaved.","Finally, we end with a positive observation, showing that in quantized versions of classification and deep network training, computability restrictions do not arise or can be overcome to a certain degree."],"url":"http://arxiv.org/abs/2408.06212v1"}
{"created":"2024-08-12 15:01:03","title":"Certified Safe: A Schematic for Approval Regulation of Frontier AI","abstract":"Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (AI). Approval regulation is emerging as a promising candidate. An approval regulation scheme is one in which a firm cannot legally market, or in some cases develop, a product without explicit approval from a regulator on the basis of experiments performed upon the product that demonstrate its safety. This approach is used successfully by the FDA and FAA. Further, its application to frontier AI has been publicly supported by many prominent stakeholders. This report proposes an approval regulation schematic for only the largest AI projects in which scrutiny begins before training and continues through to post-deployment monitoring. The centerpieces of the schematic are two major approval gates, the first requiring approval for large-scale training and the second for deployment. Five main challenges make implementation difficult: noncompliance through unsanctioned deployment, specification of deployment readiness requirements, reliable model experimentation, filtering out safe models before the process, and minimizing regulatory overhead. This report makes a number of crucial recommendations to increase the feasibility of approval regulation, some of which must be followed urgently if such a regime is to succeed in the near future. Further recommendations, produced by this report's analysis, may improve the effectiveness of any regulatory regime for frontier AI.","sentences":["Recent and unremitting capability advances have been accompanied by calls for comprehensive, rather than patchwork, regulation of frontier artificial intelligence (AI).","Approval regulation is emerging as a promising candidate.","An approval regulation scheme is one in which a firm cannot legally market, or in some cases develop, a product without explicit approval from a regulator on the basis of experiments performed upon the product that demonstrate its safety.","This approach is used successfully by the FDA and FAA.","Further, its application to frontier AI has been publicly supported by many prominent stakeholders.","This report proposes an approval regulation schematic for only the largest AI projects in which scrutiny begins before training and continues through to post-deployment monitoring.","The centerpieces of the schematic are two major approval gates, the first requiring approval for large-scale training and the second for deployment.","Five main challenges make implementation difficult: noncompliance through unsanctioned deployment, specification of deployment readiness requirements, reliable model experimentation, filtering out safe models before the process, and minimizing regulatory overhead.","This report makes a number of crucial recommendations to increase the feasibility of approval regulation, some of which must be followed urgently if such a regime is to succeed in the near future.","Further recommendations, produced by this report's analysis, may improve the effectiveness of any regulatory regime for frontier AI."],"url":"http://arxiv.org/abs/2408.06210v1"}
{"created":"2024-08-12 14:58:02","title":"Multi-tree Quantum Routing in Realistic Topologies","abstract":"In entanglement distribution networks, communication between two nodes necessitates the generation of end-to-end entanglement by entanglement swapping at intermediate nodes. Efficiently creating end-to-end entanglements over long distances is a key objective. In our prior study on asynchronous routing, we enhanced these entanglement rates by leveraging solely the local knowledge of the entanglement links of a node. This was achieved by creating a tree structure, particularly a destination-oriented directed acyclic graph (DODAG) or a spanning tree, eliminating synchronous operations and conserving unused entanglement links. In this article, we present a multi-tree approach with multiple DODAGs designed to improve end-to-end entanglement rates in large-scale networks, specifically catering to a range of network topologies, including grids and barbells, as well as realistic topologies found in research testbeds like ESnet and Internet2. Our simulations show a marked improvement in end-to-end entanglement rates for specific topologies compared to the single-tree method. This study underscores the promise of asynchronous routing schemes in quantum networks, highlighting the effectiveness of asynchronous routing across different network topologies and proposing a superior routing tactic.","sentences":["In entanglement distribution networks, communication between two nodes necessitates the generation of end-to-end entanglement by entanglement swapping at intermediate nodes.","Efficiently creating end-to-end entanglements over long distances is a key objective.","In our prior study on asynchronous routing, we enhanced these entanglement rates by leveraging solely the local knowledge of the entanglement links of a node.","This was achieved by creating a tree structure, particularly a destination-oriented directed acyclic graph (DODAG) or a spanning tree, eliminating synchronous operations and conserving unused entanglement links.","In this article, we present a multi-tree approach with multiple DODAGs designed to improve end-to-end entanglement rates in large-scale networks, specifically catering to a range of network topologies, including grids and barbells, as well as realistic topologies found in research testbeds like ESnet and Internet2.","Our simulations show a marked improvement in end-to-end entanglement rates for specific topologies compared to the single-tree method.","This study underscores the promise of asynchronous routing schemes in quantum networks, highlighting the effectiveness of asynchronous routing across different network topologies and proposing a superior routing tactic."],"url":"http://arxiv.org/abs/2408.06207v1"}
{"created":"2024-08-12 14:50:18","title":"Strategy Game-Playing with Size-Constrained State Abstraction","abstract":"Playing strategy games is a challenging problem for artificial intelligence (AI). One of the major challenges is the large search space due to a diverse set of game components. In recent works, state abstraction has been applied to search-based game AI and has brought significant performance improvements. State abstraction techniques rely on reducing the search space, e.g., by aggregating similar states. However, the application of these abstractions is hindered because the quality of an abstraction is difficult to evaluate. Previous works hence abandon the abstraction in the middle of the search to not bias the search to a local optimum. This mechanism introduces a hyper-parameter to decide the time to abandon the current state abstraction. In this work, we propose a size-constrained state abstraction (SCSA), an approach that limits the maximum number of nodes being grouped together. We found that with SCSA, the abstraction is not required to be abandoned. Our empirical results on $3$ strategy games show that the SCSA agent outperforms the previous methods and yields robust performance over different games. Codes are open-sourced at \\url{https://github.com/GAIGResearch/Stratega}.","sentences":["Playing strategy games is a challenging problem for artificial intelligence (AI).","One of the major challenges is the large search space due to a diverse set of game components.","In recent works, state abstraction has been applied to search-based game AI and has brought significant performance improvements.","State abstraction techniques rely on reducing the search space, e.g., by aggregating similar states.","However, the application of these abstractions is hindered because the quality of an abstraction is difficult to evaluate.","Previous works hence abandon the abstraction in the middle of the search to not bias the search to a local optimum.","This mechanism introduces a hyper-parameter to decide the time to abandon the current state abstraction.","In this work, we propose a size-constrained state abstraction (SCSA), an approach that limits the maximum number of nodes being grouped together.","We found that with SCSA, the abstraction is not required to be abandoned.","Our empirical results on $3$ strategy games show that the SCSA agent outperforms the previous methods and yields robust performance over different games.","Codes are open-sourced at \\url{https://github.com/GAIGResearch/Stratega}."],"url":"http://arxiv.org/abs/2408.06202v1"}
{"created":"2024-08-12 14:50:04","title":"Investigating Characteristics of Media Recommendation Solicitation in r/ifyoulikeblank","abstract":"Despite the existence of search-based recommender systems like Google, Netflix, and Spotify, online users sometimes may turn to crowdsourced recommendations in places like the r/ifyoulikeblank subreddit. In this exploratory study, we probe why users go to r/ifyoulikeblank, how they look for recommendation, and how the subreddit users respond to recommendation requests. To answer, we collected sample posts from r/ifyoulikeblank and analyzed them using a qualitative approach. Our analysis reveals that users come to this subreddit for various reasons, such as exhausting popular search systems, not knowing what or how to search for an item, and thinking crowd have better knowledge than search systems. Examining users query and their description, we found novel information users provide during recommendation seeking using r/ifyoulikeblank. For example, sometimes they ask for artifacts recommendation based on the tools used to create them. Or, sometimes indicating a recommendation seeker's time constraints can help better suit recommendations to their needs. Finally, recommendation responses and interactions revealed patterns of how requesters and responders refine queries and recommendations. Our work informs future intelligent recommender systems design.","sentences":["Despite the existence of search-based recommender systems like Google, Netflix, and Spotify, online users sometimes may turn to crowdsourced recommendations in places like the r/ifyoulikeblank subreddit.","In this exploratory study, we probe why users go to r/ifyoulikeblank, how they look for recommendation, and how the subreddit users respond to recommendation requests.","To answer, we collected sample posts from r/ifyoulikeblank and analyzed them using a qualitative approach.","Our analysis reveals that users come to this subreddit for various reasons, such as exhausting popular search systems, not knowing what or how to search for an item, and thinking crowd have better knowledge than search systems.","Examining users query and their description, we found novel information users provide during recommendation seeking using r/ifyoulikeblank.","For example, sometimes they ask for artifacts recommendation based on the tools used to create them.","Or, sometimes indicating a recommendation seeker's time constraints can help better suit recommendations to their needs.","Finally, recommendation responses and interactions revealed patterns of how requesters and responders refine queries and recommendations.","Our work informs future intelligent recommender systems design."],"url":"http://arxiv.org/abs/2408.06201v1"}
{"created":"2024-08-12 14:49:12","title":"Dynamic Blocked Clause Elimination for Projected Model Counting","abstract":"In this paper, we explore the application of blocked clause elimination for projected model counting. This is the problem of determining the number of models ||\\exists X.{\\Sigma}|| of a propositional formula {\\Sigma} after eliminating a given set X of variables existentially. Although blocked clause elimination is a well-known technique for SAT solving, its direct application to model counting is challenging as in general it changes the number of models. However, we demonstrate, by focusing on projected variables during the blocked clause search, that blocked clause elimination can be leveraged while preserving the correct model count. To take advantage of blocked clause elimination in an efficient way during model counting, a novel data structure and associated algorithms are introduced. Our proposed approach is implemented in the model counter d4. Our experiments demonstrate the computational benefits of our new method of blocked clause elimination for projected model counting.","sentences":["In this paper, we explore the application of blocked clause elimination for projected model counting.","This is the problem of determining the number of models ||\\exists X.{\\Sigma}|| of a propositional formula {\\Sigma} after eliminating a given set X of variables existentially.","Although blocked clause elimination is a well-known technique for SAT solving, its direct application to model counting is challenging as in general it changes the number of models.","However, we demonstrate, by focusing on projected variables during the blocked clause search, that blocked clause elimination can be leveraged while preserving the correct model count.","To take advantage of blocked clause elimination in an efficient way during model counting, a novel data structure and associated algorithms are introduced.","Our proposed approach is implemented in the model counter d4.","Our experiments demonstrate the computational benefits of our new method of blocked clause elimination for projected model counting."],"url":"http://arxiv.org/abs/2408.06199v1"}
{"created":"2024-08-12 14:48:25","title":"Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption","abstract":"In sectors such as finance and healthcare, where data governance is subject to rigorous regulatory requirements, the exchange and utilization of data are particularly challenging. Federated Learning (FL) has risen as a pioneering distributed machine learning paradigm that enables collaborative model training across multiple institutions while maintaining data decentralization. Despite its advantages, FL is vulnerable to adversarial threats, particularly poisoning attacks during model aggregation, a process typically managed by a central server. However, in these systems, neural network models still possess the capacity to inadvertently memorize and potentially expose individual training instances. This presents a significant privacy risk, as attackers could reconstruct private data by leveraging the information contained in the model itself. Existing solutions fall short of providing a viable, privacy-preserving BRFL system that is both completely secure against information leakage and computationally efficient. To address these concerns, we propose Lancelot, an innovative and computationally efficient BRFL framework that employs fully homomorphic encryption (FHE) to safeguard against malicious client activities while preserving data privacy. Our extensive testing, which includes medical imaging diagnostics and widely-used public image datasets, demonstrates that Lancelot significantly outperforms existing methods, offering more than a twenty-fold increase in processing speed, all while maintaining data privacy.","sentences":["In sectors such as finance and healthcare, where data governance is subject to rigorous regulatory requirements, the exchange and utilization of data are particularly challenging.","Federated Learning (FL) has risen as a pioneering distributed machine learning paradigm that enables collaborative model training across multiple institutions while maintaining data decentralization.","Despite its advantages, FL is vulnerable to adversarial threats, particularly poisoning attacks during model aggregation, a process typically managed by a central server.","However, in these systems, neural network models still possess the capacity to inadvertently memorize and potentially expose individual training instances.","This presents a significant privacy risk, as attackers could reconstruct private data by leveraging the information contained in the model itself.","Existing solutions fall short of providing a viable, privacy-preserving BRFL system that is both completely secure against information leakage and computationally efficient.","To address these concerns, we propose Lancelot, an innovative and computationally efficient BRFL framework that employs fully homomorphic encryption (FHE) to safeguard against malicious client activities while preserving data privacy.","Our extensive testing, which includes medical imaging diagnostics and widely-used public image datasets, demonstrates that Lancelot significantly outperforms existing methods, offering more than a twenty-fold increase in processing speed, all while maintaining data privacy."],"url":"http://arxiv.org/abs/2408.06197v1"}
{"created":"2024-08-12 14:42:13","title":"Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers","abstract":"This paper introduces rStar, a self-play mutual reasoning approach that significantly improves reasoning capabilities of small language models (SLMs) without fine-tuning or superior models. rStar decouples reasoning into a self-play mutual generation-discrimination process. First, a target SLM augments the Monte Carlo Tree Search (MCTS) with a rich set of human-like reasoning actions to construct higher quality reasoning trajectories. Next, another SLM, with capabilities similar to the target SLM, acts as a discriminator to verify each trajectory generated by the target SLM. The mutually agreed reasoning trajectories are considered mutual consistent, thus are more likely to be correct. Extensive experiments across five SLMs demonstrate rStar can effectively solve diverse reasoning problems, including GSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA. Remarkably, rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct. Code will be available at https://github.com/zhentingqi/rStar.","sentences":["This paper introduces rStar, a self-play mutual reasoning approach that significantly improves reasoning capabilities of small language models (SLMs) without fine-tuning or superior models.","rStar decouples reasoning into a self-play mutual generation-discrimination process.","First, a target SLM augments the Monte Carlo Tree Search (MCTS) with a rich set of human-like reasoning actions to construct higher quality reasoning trajectories.","Next, another SLM, with capabilities similar to the target SLM, acts as a discriminator to verify each trajectory generated by the target SLM.","The mutually agreed reasoning trajectories are considered mutual consistent, thus are more likely to be correct.","Extensive experiments across five SLMs demonstrate rStar can effectively solve diverse reasoning problems, including GSM8K, GSM-Hard, MATH, SVAMP, and StrategyQA.","Remarkably, rStar boosts GSM8K accuracy from 12.51% to 63.91% for LLaMA2-7B, from 36.46% to 81.88% for Mistral-7B, from 74.53% to 91.13% for LLaMA3-8B-Instruct.","Code will be available at https://github.com/zhentingqi/rStar."],"url":"http://arxiv.org/abs/2408.06195v1"}
{"created":"2024-08-12 14:40:38","title":"FruitNeRF: A Unified Neural Radiance Field based Fruit Counting Framework","abstract":"We introduce FruitNeRF, a unified novel fruit counting framework that leverages state-of-the-art view synthesis methods to count any fruit type directly in 3D. Our framework takes an unordered set of posed images captured by a monocular camera and segments fruit in each image. To make our system independent of the fruit type, we employ a foundation model that generates binary segmentation masks for any fruit. Utilizing both modalities, RGB and semantic, we train a semantic neural radiance field. Through uniform volume sampling of the implicit Fruit Field, we obtain fruit-only point clouds. By applying cascaded clustering on the extracted point cloud, our approach achieves precise fruit count.The use of neural radiance fields provides significant advantages over conventional methods such as object tracking or optical flow, as the counting itself is lifted into 3D. Our method prevents double counting fruit and avoids counting irrelevant fruit.We evaluate our methodology using both real-world and synthetic datasets. The real-world dataset consists of three apple trees with manually counted ground truths, a benchmark apple dataset with one row and ground truth fruit location, while the synthetic dataset comprises various fruit types including apple, plum, lemon, pear, peach, and mango.Additionally, we assess the performance of fruit counting using the foundation model compared to a U-Net.","sentences":["We introduce FruitNeRF, a unified novel fruit counting framework that leverages state-of-the-art view synthesis methods to count any fruit type directly in 3D.","Our framework takes an unordered set of posed images captured by a monocular camera and segments fruit in each image.","To make our system independent of the fruit type, we employ a foundation model that generates binary segmentation masks for any fruit.","Utilizing both modalities, RGB and semantic, we train a semantic neural radiance field.","Through uniform volume sampling of the implicit Fruit Field, we obtain fruit-only point clouds.","By applying cascaded clustering on the extracted point cloud, our approach achieves precise fruit count.","The use of neural radiance fields provides significant advantages over conventional methods such as object tracking or optical flow, as the counting itself is lifted into 3D.","Our method prevents double counting fruit and avoids counting irrelevant fruit.","We evaluate our methodology using both real-world and synthetic datasets.","The real-world dataset consists of three apple trees with manually counted ground truths, a benchmark apple dataset with one row and ground truth fruit location, while the synthetic dataset comprises various fruit types including apple, plum, lemon, pear, peach, and mango.","Additionally, we assess the performance of fruit counting using the foundation model compared to a U-Net."],"url":"http://arxiv.org/abs/2408.06190v1"}
{"created":"2024-08-12 14:34:06","title":"Improving Structural Diversity of Blackbox LLMs via Chain-of-Specification Prompting","abstract":"The capability to generate diverse text is a key challenge facing large language models (LLMs). Thus far, diversity has been studied via metrics such as $n$-gram diversity or diversity of BERT embeddings. However, for these kinds of diversity, the user has little control over the dimensions along which diversity is considered. For example, in the poetry domain, one might desire diversity in terms of rhyme and meter, whereas in the code domain, one might desire diversity in terms of the kinds of expressions used to solve a problem. We propose a diversity metric called structural diversity, where the user provides a mapping from generated text to features capturing the kinds of diversity that they care about. In addition, we propose a novel strategy called chain-of-specification (CoS) prompting for improving diversity by first having the LLM generate a specification encoding one instance of structural features, and then prompting the LLM to generate text that satisfies these features; notably, our strategy works with blackbox LLMs. In our experiments, we show that for structural diversity in the poetry and code domains, CoS significantly improves diversity compared to several baselines.","sentences":["The capability to generate diverse text is a key challenge facing large language models (LLMs).","Thus far, diversity has been studied via metrics such as $n$-gram diversity or diversity of BERT embeddings.","However, for these kinds of diversity, the user has little control over the dimensions along which diversity is considered.","For example, in the poetry domain, one might desire diversity in terms of rhyme and meter, whereas in the code domain, one might desire diversity in terms of the kinds of expressions used to solve a problem.","We propose a diversity metric called structural diversity, where the user provides a mapping from generated text to features capturing the kinds of diversity that they care about.","In addition, we propose a novel strategy called chain-of-specification (CoS) prompting for improving diversity by first having the LLM generate a specification encoding one instance of structural features, and then prompting the LLM to generate text that satisfies these features; notably, our strategy works with blackbox LLMs.","In our experiments, we show that for structural diversity in the poetry and code domains, CoS significantly improves diversity compared to several baselines."],"url":"http://arxiv.org/abs/2408.06186v1"}
{"created":"2024-08-12 14:29:54","title":"Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability","abstract":"Cardiovascular diseases are a leading cause of mortality worldwide, highlighting the need for accurate diagnostic methods. This study benchmarks centralized and federated machine learning algorithms for heart disease classification using the UCI dataset which includes 920 patient records from four hospitals in the USA, Hungary and Switzerland. Our benchmark is supported by Shapley-value interpretability analysis to quantify features' importance for classification. In the centralized setup, various binary classification algorithms are trained on pooled data, with a support vector machine (SVM) achieving the highest testing accuracy of 83.3\\%, surpassing the established benchmark of 78.7\\% with logistic regression. Additionally, federated learning algorithms with four clients (hospitals) are explored, leveraging the dataset's natural partition to enhance privacy without sacrificing accuracy. Federated SVM, an uncommon approach in the literature, achieves a top testing accuracy of 73.8\\%. Our interpretability analysis aligns with existing medical knowledge of heart disease indicators. Overall, this study establishes a benchmark for efficient and interpretable pre-screening tools for heart disease while maintaining patients' privacy.","sentences":["Cardiovascular diseases are a leading cause of mortality worldwide, highlighting the need for accurate diagnostic methods.","This study benchmarks centralized and federated machine learning algorithms for heart disease classification using the UCI dataset which includes 920 patient records from four hospitals in the USA, Hungary and Switzerland.","Our benchmark is supported by Shapley-value interpretability analysis to quantify features' importance for classification.","In the centralized setup, various binary classification algorithms are trained on pooled data, with a support vector machine (SVM) achieving the highest testing accuracy of 83.3\\%, surpassing the established benchmark of 78.7\\% with logistic regression.","Additionally, federated learning algorithms with four clients (hospitals) are explored, leveraging the dataset's natural partition to enhance privacy without sacrificing accuracy.","Federated SVM, an uncommon approach in the literature, achieves a top testing accuracy of 73.8\\%.","Our interpretability analysis aligns with existing medical knowledge of heart disease indicators.","Overall, this study establishes a benchmark for efficient and interpretable pre-screening tools for heart disease while maintaining patients' privacy."],"url":"http://arxiv.org/abs/2408.06183v1"}
{"created":"2024-08-12 14:21:11","title":"Towards Unconstrained Collision Injury Protection Data Sets: Initial Surrogate Experiments for the Human Hand","abstract":"Safety for physical human-robot interaction (pHRI) is a major concern for all application domains. While current standardization for industrial robot applications provide safety constraints that address the onset of pain in blunt impacts, these impact thresholds are difficult to use on edged or pointed impactors. The most severe injuries occur in constrained contact scenarios, where crushing is possible. Nevertheless, situations potentially resulting in constrained contact only occur in certain areas of a workspace and design or organisational approaches can be used to avoid them. What remains are risks to the human physical integrity caused by unconstrained accidental contacts, which are difficult to avoid while maintaining robot motion efficiency. Nevertheless, the probability and severity of injuries occurring with edged or pointed impacting objects in unconstrained collisions is hardly researched. In this paper, we propose an experimental setup and procedure using two pendulums modeling human hands and arms and robots to understand the injury potential of unconstrained collisions of human hands with edged objects. Based on our previous studies, we use pig feet as ex vivo surrogate samples - as these closely resemble the physiological characteristics of human hands - to create an initial injury database on the severity of injuries caused by unconstrained edged or pointed impacts. The use of such experimental setups and procedures in addition to other research on the occurrence of injuries in humans will eventually lead to a complete understanding of the biomechanical injury potential in pHRI.","sentences":["Safety for physical human-robot interaction (pHRI) is a major concern for all application domains.","While current standardization for industrial robot applications provide safety constraints that address the onset of pain in blunt impacts, these impact thresholds are difficult to use on edged or pointed impactors.","The most severe injuries occur in constrained contact scenarios, where crushing is possible.","Nevertheless, situations potentially resulting in constrained contact only occur in certain areas of a workspace and design or organisational approaches can be used to avoid them.","What remains are risks to the human physical integrity caused by unconstrained accidental contacts, which are difficult to avoid while maintaining robot motion efficiency.","Nevertheless, the probability and severity of injuries occurring with edged or pointed impacting objects in unconstrained collisions is hardly researched.","In this paper, we propose an experimental setup and procedure using two pendulums modeling human hands and arms and robots to understand the injury potential of unconstrained collisions of human hands with edged objects.","Based on our previous studies, we use pig feet as ex vivo surrogate samples - as these closely resemble the physiological characteristics of human hands - to create an initial injury database on the severity of injuries caused by unconstrained edged or pointed impacts.","The use of such experimental setups and procedures in addition to other research on the occurrence of injuries in humans will eventually lead to a complete understanding of the biomechanical injury potential in pHRI."],"url":"http://arxiv.org/abs/2408.06175v1"}
{"created":"2024-08-12 14:13:08","title":"Blind-Match: Efficient Homomorphic Encryption-Based 1:N Matching for Privacy-Preserving Biometric Identification","abstract":"We present Blind-Match, a novel biometric identification system that leverages homomorphic encryption (HE) for efficient and privacy-preserving 1:N matching. Blind-Match introduces a HE-optimized cosine similarity computation method, where the key idea is to divide the feature vector into smaller parts for processing rather than computing the entire vector at once. By optimizing the number of these parts, Blind-Match minimizes execution time while ensuring data privacy through HE. Blind-Match achieves superior performance compared to state-of-the-art methods across various biometric datasets. On the LFW face dataset, Blind-Match attains a 99.63% Rank-1 accuracy with a 128-dimensional feature vector, demonstrating its robustness in face recognition tasks. For fingerprint identification, Blind-Match achieves a remarkable 99.55% Rank-1 accuracy on the PolyU dataset, even with a compact 16-dimensional feature vector, significantly outperforming the state-of-the-art method, Blind-Touch, which achieves only 59.17%. Furthermore, Blind-Match showcases practical efficiency in large-scale biometric identification scenarios, such as Naver Cloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a 128-dimensional feature vector.","sentences":["We present Blind-Match, a novel biometric identification system that leverages homomorphic encryption (HE) for efficient and privacy-preserving 1:N matching.","Blind-Match introduces a HE-optimized cosine similarity computation method, where the key idea is to divide the feature vector into smaller parts for processing rather than computing the entire vector at once.","By optimizing the number of these parts, Blind-Match minimizes execution time while ensuring data privacy through HE.","Blind-Match achieves superior performance compared to state-of-the-art methods across various biometric datasets.","On the LFW face dataset, Blind-Match attains a 99.63% Rank-1 accuracy with a 128-dimensional feature vector, demonstrating its robustness in face recognition tasks.","For fingerprint identification, Blind-Match achieves a remarkable 99.55% Rank-1 accuracy on the PolyU dataset, even with a compact 16-dimensional feature vector, significantly outperforming the state-of-the-art method, Blind-Touch, which achieves only 59.17%.","Furthermore, Blind-Match showcases practical efficiency in large-scale biometric identification scenarios, such as Naver Cloud's FaceSign, by processing 6,144 biometric samples in 0.74 seconds using a 128-dimensional feature vector."],"url":"http://arxiv.org/abs/2408.06167v1"}
{"created":"2024-08-12 13:55:46","title":"OmniCLIP: Adapting CLIP for Video Recognition with Spatial-Temporal Omni-Scale Feature Learning","abstract":"Recent Vision-Language Models (VLMs) \\textit{e.g.} CLIP have made great progress in video recognition. Despite the improvement brought by the strong visual backbone in extracting spatial features, CLIP still falls short in capturing and integrating spatial-temporal features which is essential for video recognition. In this paper, we propose OmniCLIP, a framework that adapts CLIP for video recognition by focusing on learning comprehensive features encompassing spatial, temporal, and dynamic spatial-temporal scales, which we refer to as omni-scale features. This is achieved through the design of spatial-temporal blocks that include parallel temporal adapters (PTA), enabling efficient temporal modeling. Additionally, we introduce a self-prompt generator (SPG) module to capture dynamic object spatial features. The synergy between PTA and SPG allows OmniCLIP to discern varying spatial information across frames and assess object scales over time. We have conducted extensive experiments in supervised video recognition, few-shot video recognition, and zero-shot recognition tasks. The results demonstrate the effectiveness of our method, especially with OmniCLIP achieving a top-1 accuracy of 74.30\\% on HMDB51 in a 16-shot setting, surpassing the recent MotionPrompt approach even with full training data. The code is available at \\url{https://github.com/XiaoBuL/OmniCLIP}.","sentences":["Recent Vision-Language Models (VLMs) \\textit{e.g.} CLIP have made great progress in video recognition.","Despite the improvement brought by the strong visual backbone in extracting spatial features, CLIP still falls short in capturing and integrating spatial-temporal features which is essential for video recognition.","In this paper, we propose OmniCLIP, a framework that adapts CLIP for video recognition by focusing on learning comprehensive features encompassing spatial, temporal, and dynamic spatial-temporal scales, which we refer to as omni-scale features.","This is achieved through the design of spatial-temporal blocks that include parallel temporal adapters (PTA), enabling efficient temporal modeling.","Additionally, we introduce a self-prompt generator (SPG) module to capture dynamic object spatial features.","The synergy between PTA and SPG allows OmniCLIP to discern varying spatial information across frames and assess object scales over time.","We have conducted extensive experiments in supervised video recognition, few-shot video recognition, and zero-shot recognition tasks.","The results demonstrate the effectiveness of our method, especially with OmniCLIP achieving a top-1 accuracy of 74.30\\% on HMDB51 in a 16-shot setting, surpassing the recent MotionPrompt approach even with full training data.","The code is available at \\url{https://github.com/XiaoBuL/OmniCLIP}."],"url":"http://arxiv.org/abs/2408.06158v1"}
{"created":"2024-08-12 13:53:40","title":"Novel View Synthesis from a Single Image with Pretrained Diffusion Guidance","abstract":"Recent 3D novel view synthesis (NVS) methods are limited to single-object-centric scenes generated from new viewpoints and struggle with complex environments. They often require extensive 3D data for training, lacking generalization beyond training distribution. Conversely, 3D-free methods can generate text-controlled views of complex, in-the-wild scenes using a pretrained stable diffusion model without tedious fine-tuning, but lack camera control. In this paper, we introduce HawkI++, a method capable of generating camera-controlled viewpoints from a single input image. HawkI++ excels in handling complex and diverse scenes without additional 3D data or extensive training. It leverages widely available pretrained NVS models for weak guidance, integrating this knowledge into a 3D-free view synthesis approach to achieve the desired results efficiently. Our experimental results demonstrate that HawkI++ outperforms existing models in both qualitative and quantitative evaluations, providing high-fidelity and consistent novel view synthesis at desired camera angles across a wide variety of scenes.","sentences":["Recent 3D novel view synthesis (NVS) methods are limited to single-object-centric scenes generated from new viewpoints and struggle with complex environments.","They often require extensive 3D data for training, lacking generalization beyond training distribution.","Conversely, 3D-free methods can generate text-controlled views of complex, in-the-wild scenes using a pretrained stable diffusion model without tedious fine-tuning, but lack camera control.","In this paper, we introduce HawkI++, a method capable of generating camera-controlled viewpoints from a single input image.","HawkI++ excels in handling complex and diverse scenes without additional 3D data or extensive training.","It leverages widely available pretrained NVS models for weak guidance, integrating this knowledge into a 3D-free view synthesis approach to achieve the desired results efficiently.","Our experimental results demonstrate that HawkI++ outperforms existing models in both qualitative and quantitative evaluations, providing high-fidelity and consistent novel view synthesis at desired camera angles across a wide variety of scenes."],"url":"http://arxiv.org/abs/2408.06157v1"}
{"created":"2024-08-12 13:48:06","title":"Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming","abstract":"Neural enhancement through super-resolution deep neural networks opens up new possibilities for ultra-high-definition live streaming over existing encoding and networking infrastructure. Yet, the heavy SR DNN inference overhead leads to severe deployment challenges. To reduce the overhead, existing systems propose to apply DNN-based SR only on selected anchor frames while upscaling non-anchor frames via the lightweight reusing-based SR approach. However, frame-level scheduling is coarse-grained and fails to deliver optimal efficiency. In this work, we propose Palantir, the first neural-enhanced UHD live streaming system with fine-grained patch-level scheduling. In the presented solutions, two novel techniques are incorporated to make good scheduling decisions for inference overhead optimization and reduce the scheduling latency. Firstly, under the guidance of our pioneering and theoretical analysis, Palantir constructs a directed acyclic graph (DAG) for lightweight yet accurate quality estimation under any possible anchor patch set. Secondly, to further optimize the scheduling latency, Palantir improves parallelizability by refactoring the computation subprocedure of the estimation process into a sparse matrix-matrix multiplication operation. The evaluation results suggest that Palantir incurs a negligible scheduling latency accounting for less than 5.7% of the end-to-end latency requirement. When compared to the state-of-the-art real-time frame-level scheduling strategy, Palantir reduces the energy overhead of SR-integrated mobile clients by 38.1% at most (and 22.4% on average) and the monetary costs of cloud-based SR by 80.1% at most (and 38.4% on average).","sentences":["Neural enhancement through super-resolution deep neural networks opens up new possibilities for ultra-high-definition live streaming over existing encoding and networking infrastructure.","Yet, the heavy SR DNN inference overhead leads to severe deployment challenges.","To reduce the overhead, existing systems propose to apply DNN-based SR only on selected anchor frames while upscaling non-anchor frames via the lightweight reusing-based SR approach.","However, frame-level scheduling is coarse-grained and fails to deliver optimal efficiency.","In this work, we propose Palantir, the first neural-enhanced UHD live streaming system with fine-grained patch-level scheduling.","In the presented solutions, two novel techniques are incorporated to make good scheduling decisions for inference overhead optimization and reduce the scheduling latency.","Firstly, under the guidance of our pioneering and theoretical analysis, Palantir constructs a directed acyclic graph (DAG) for lightweight yet accurate quality estimation under any possible anchor patch set.","Secondly, to further optimize the scheduling latency, Palantir improves parallelizability by refactoring the computation subprocedure of the estimation process into a sparse matrix-matrix multiplication operation.","The evaluation results suggest that Palantir incurs a negligible scheduling latency accounting for less than 5.7% of the end-to-end latency requirement.","When compared to the state-of-the-art real-time frame-level scheduling strategy, Palantir reduces the energy overhead of SR-integrated mobile clients by 38.1% at most (and 22.4% on average) and the monetary costs of cloud-based SR by 80.1% at most (and 38.4% on average)."],"url":"http://arxiv.org/abs/2408.06152v1"}
{"created":"2024-08-12 13:44:24","title":"LipidBERT: A Lipid Language Model Pre-trained on METiS de novo Lipid Library","abstract":"In this study, we generate and maintain a database of 10 million virtual lipids through METiS's in-house de novo lipid generation algorithms and lipid virtual screening techniques. These virtual lipids serve as a corpus for pre-training, lipid representation learning, and downstream task knowledge transfer, culminating in state-of-the-art LNP property prediction performance. We propose LipidBERT, a BERT-like model pre-trained with the Masked Language Model (MLM) and various secondary tasks. Additionally, we compare the performance of embeddings generated by LipidBERT and PhatGPT, our GPT-like lipid generation model, on downstream tasks. The proposed bilingual LipidBERT model operates in two languages: the language of ionizable lipid pre-training, using in-house dry-lab lipid structures, and the language of LNP fine-tuning, utilizing in-house LNP wet-lab data. This dual capability positions LipidBERT as a key AI-based filter for future screening tasks, including new versions of METiS de novo lipid libraries and, more importantly, candidates for in vivo testing for orgran-targeting LNPs. To the best of our knowledge, this is the first successful demonstration of the capability of a pre-trained language model on virtual lipids and its effectiveness in downstream tasks using web-lab data. This work showcases the clever utilization of METiS's in-house de novo lipid library as well as the power of dry-wet lab integration.","sentences":["In this study, we generate and maintain a database of 10 million virtual lipids through METiS's in-house de novo lipid generation algorithms and lipid virtual screening techniques.","These virtual lipids serve as a corpus for pre-training, lipid representation learning, and downstream task knowledge transfer, culminating in state-of-the-art LNP property prediction performance.","We propose LipidBERT, a BERT-like model pre-trained with the Masked Language Model (MLM) and various secondary tasks.","Additionally, we compare the performance of embeddings generated by LipidBERT and PhatGPT, our GPT-like lipid generation model, on downstream tasks.","The proposed bilingual LipidBERT model operates in two languages: the language of ionizable lipid pre-training, using in-house dry-lab lipid structures, and the language of LNP fine-tuning, utilizing in-house LNP wet-lab data.","This dual capability positions LipidBERT as a key AI-based filter for future screening tasks, including new versions of METiS de novo lipid libraries and, more importantly, candidates for in vivo testing for orgran-targeting LNPs.","To the best of our knowledge, this is the first successful demonstration of the capability of a pre-trained language model on virtual lipids and its effectiveness in downstream tasks using web-lab data.","This work showcases the clever utilization of METiS's in-house de novo lipid library as well as the power of dry-wet lab integration."],"url":"http://arxiv.org/abs/2408.06150v1"}
{"created":"2024-08-12 13:43:06","title":"Coverage measurement in model-based testing of web applications: Tool support and an industrial experience report","abstract":"There are many widely used tools for measuring test-coverage and code-coverage. Test coverage is the ratio of requirements or other non-code artifacts covered by a test suite, while code-coverage is the ratio of source code covered by tests. Almost all coverage tools show a few certain subset of coverage values, and almost always either test-coverage or code-coverage measures. In a large-scale industrial web-application-testing setting, we were faced with the need to \"integrate\" several types of coverage data (including front-end and back-end code coverage with requirements coverage), and to see all of them \"live\" as large model-based test suites were running. By being unable to find any off-the-shelf toolset to address the above need, we have developed an open-source test coverage tool, specific for MBT, named MBTCover. In addition to code coverage, the tool measures and reports requirements and model coverage, \"live\" as a given MBT test suite is executing. In this paper, we present the features of the MBTCover tool and our experience from using it in multiple large test-automation projects in practice. Other software test engineers, who conduct web application testing and MBT, may find the tool useful in their projects.","sentences":["There are many widely used tools for measuring test-coverage and code-coverage.","Test coverage is the ratio of requirements or other non-code artifacts covered by a test suite, while code-coverage is the ratio of source code covered by tests.","Almost all coverage tools show a few certain subset of coverage values, and almost always either test-coverage or code-coverage measures.","In a large-scale industrial web-application-testing setting, we were faced with the need to \"integrate\" several types of coverage data (including front-end and back-end code coverage with requirements coverage), and to see all of them \"live\" as large model-based test suites were running.","By being unable to find any off-the-shelf toolset to address the above need, we have developed an open-source test coverage tool, specific for MBT, named MBTCover.","In addition to code coverage, the tool measures and reports requirements and model coverage, \"live\" as a given MBT test suite is executing.","In this paper, we present the features of the MBTCover tool and our experience from using it in multiple large test-automation projects in practice.","Other software test engineers, who conduct web application testing and MBT, may find the tool useful in their projects."],"url":"http://arxiv.org/abs/2408.06148v1"}
{"created":"2024-08-12 13:42:04","title":"Spectral Sparsification by Deterministic Discrepancy Walk","abstract":"Spectral sparsification and discrepancy minimization are two well-studied areas that are closely related. Building on recent connections between these two areas, we generalize the \"deterministic discrepancy walk\" framework by Pesenti and Vladu [SODA~23] for vector discrepancy to matrix discrepancy, and use it to give a simpler proof of the matrix partial coloring theorem of Reis and Rothvoss [SODA~20]. Moreover, we show that this matrix discrepancy framework provides a unified approach for various spectral sparsification problems, from stronger notions including unit-circle approximation and singular-value approximation to weaker notions including graphical spectral sketching and effective resistance sparsification. In all of these applications, our framework produces improved results with a simpler and deterministic analysis.","sentences":["Spectral sparsification and discrepancy minimization are two well-studied areas that are closely related.","Building on recent connections between these two areas, we generalize the \"deterministic discrepancy walk\" framework by Pesenti and Vladu [SODA~23] for vector discrepancy to matrix discrepancy, and use it to give a simpler proof of the matrix partial coloring theorem of Reis and Rothvoss [SODA~20].","Moreover, we show that this matrix discrepancy framework provides a unified approach for various spectral sparsification problems, from stronger notions including unit-circle approximation and singular-value approximation to weaker notions including graphical spectral sketching and effective resistance sparsification.","In all of these applications, our framework produces improved results with a simpler and deterministic analysis."],"url":"http://arxiv.org/abs/2408.06146v1"}
{"created":"2024-08-12 13:41:47","title":"Efficient and Scalable Point Cloud Generation with Sparse Point-Voxel Diffusion Models","abstract":"We propose a novel point cloud U-Net diffusion architecture for 3D generative modeling capable of generating high-quality and diverse 3D shapes while maintaining fast generation times. Our network employs a dual-branch architecture, combining the high-resolution representations of points with the computational efficiency of sparse voxels. Our fastest variant outperforms all non-diffusion generative approaches on unconditional shape generation, the most popular benchmark for evaluating point cloud generative models, while our largest model achieves state-of-the-art results among diffusion methods, with a runtime approximately 70% of the previously state-of-the-art PVD. Beyond unconditional generation, we perform extensive evaluations, including conditional generation on all categories of ShapeNet, demonstrating the scalability of our model to larger datasets, and implicit generation which allows our network to produce high quality point clouds on fewer timesteps, further decreasing the generation time. Finally, we evaluate the architecture's performance in point cloud completion and super-resolution. Our model excels in all tasks, establishing it as a state-of-the-art diffusion U-Net for point cloud generative modeling. The code is publicly available at https://github.com/JohnRomanelis/SPVD.git.","sentences":["We propose a novel point cloud U-Net diffusion architecture for 3D generative modeling capable of generating high-quality and diverse 3D shapes while maintaining fast generation times.","Our network employs a dual-branch architecture, combining the high-resolution representations of points with the computational efficiency of sparse voxels.","Our fastest variant outperforms all non-diffusion generative approaches on unconditional shape generation, the most popular benchmark for evaluating point cloud generative models, while our largest model achieves state-of-the-art results among diffusion methods, with a runtime approximately 70% of the previously state-of-the-art PVD.","Beyond unconditional generation, we perform extensive evaluations, including conditional generation on all categories of ShapeNet, demonstrating the scalability of our model to larger datasets, and implicit generation which allows our network to produce high quality point clouds on fewer timesteps, further decreasing the generation time.","Finally, we evaluate the architecture's performance in point cloud completion and super-resolution.","Our model excels in all tasks, establishing it as a state-of-the-art diffusion U-Net for point cloud generative modeling.","The code is publicly available at https://github.com/JohnRomanelis/SPVD.git."],"url":"http://arxiv.org/abs/2408.06145v1"}
{"created":"2024-08-12 13:39:52","title":"A pragmatic look at education and training of software test engineers: Further cooperation of academia and industry is needed","abstract":"Alongside software testing education in universities, a great extent of effort and resources are spent on software-testing training activities in industry. For example, there are several international certification schemes in testing, such as those provided by the International Software Testing Qualifications Board (ISTQB), which have been issued to more than 914K testers so far. To train the highly qualified test engineers of tomorrow, it is important for both university educators and trainers in industry to be aware of the status of software testing education in academia versus its training in industry, to analyze the relationships of these two approaches, and to assess ways on how to improve the education / training landscape. For that purpose, this paper provides a pragmatic overview of the issue, presents several recommendations, and hopes to trigger further discussions in the community, between industry and academia, on how to further improve the status-quo, and to find further best practices for more effective education and training of software testers. The paper is based on combined ~40 years of the two authors' technical experience in test engineering, and their ~30 years of experience in providing testing education and training in more than six countries.","sentences":["Alongside software testing education in universities, a great extent of effort and resources are spent on software-testing training activities in industry.","For example, there are several international certification schemes in testing, such as those provided by the International Software Testing Qualifications Board (ISTQB), which have been issued to more than 914K testers so far.","To train the highly qualified test engineers of tomorrow, it is important for both university educators and trainers in industry to be aware of the status of software testing education in academia versus its training in industry, to analyze the relationships of these two approaches, and to assess ways on how to improve the education / training landscape.","For that purpose, this paper provides a pragmatic overview of the issue, presents several recommendations, and hopes to trigger further discussions in the community, between industry and academia, on how to further improve the status-quo, and to find further best practices for more effective education and training of software testers.","The paper is based on combined ~40 years of the two authors' technical experience in test engineering, and their ~30 years of experience in providing testing education and training in more than six countries."],"url":"http://arxiv.org/abs/2408.06144v1"}
{"created":"2024-08-12 13:38:07","title":"Motion Planning for Minimally Actuated Serial Robots","abstract":"Modern manipulators are acclaimed for their precision but often struggle to operate in confined spaces. This limitation has driven the development of hyper-redundant and continuum robots. While these present unique advantages, they face challenges in, for instance, weight, mechanical complexity, modeling and costs. The Minimally Actuated Serial Robot (MASR) has been proposed as a light-weight, low-cost and simpler alternative where passive joints are actuated with a Mobile Actuator (MA) moving along the arm. Yet, Inverse Kinematics (IK) and a general motion planning algorithm for the MASR have not be addressed. In this letter, we propose the MASR-RRT* motion planning algorithm specifically developed for the unique kinematics of MASR. The main component of the algorithm is a data-based model for solving the IK problem while considering minimal traverse of the MA. The model is trained solely using the forward kinematics of the MASR and does not require real data. With the model as a local-connection mechanism, MASR-RRT* minimizes a cost function expressing the action time. In a comprehensive analysis, we show that MASR-RRT* is superior in performance to the straight-forward implementation of the standard RRT*. Experiments on a real robot in different environments with obstacles validate the proposed algorithm.","sentences":["Modern manipulators are acclaimed for their precision but often struggle to operate in confined spaces.","This limitation has driven the development of hyper-redundant and continuum robots.","While these present unique advantages, they face challenges in, for instance, weight, mechanical complexity, modeling and costs.","The Minimally Actuated Serial Robot (MASR) has been proposed as a light-weight, low-cost and simpler alternative where passive joints are actuated with a Mobile Actuator (MA) moving along the arm.","Yet, Inverse Kinematics (IK) and a general motion planning algorithm for the MASR have not be addressed.","In this letter, we propose the MASR-RRT* motion planning algorithm specifically developed for the unique kinematics of MASR.","The main component of the algorithm is a data-based model for solving the IK problem while considering minimal traverse of the MA.","The model is trained solely using the forward kinematics of the MASR and does not require real data.","With the model as a local-connection mechanism, MASR-RRT* minimizes a cost function expressing the action time.","In a comprehensive analysis, we show that MASR-RRT* is superior in performance to the straight-forward implementation of the standard RRT*.","Experiments on a real robot in different environments with obstacles validate the proposed algorithm."],"url":"http://arxiv.org/abs/2408.06143v1"}
{"created":"2024-08-12 13:37:31","title":"Med42-v2: A Suite of Clinical LLMs","abstract":"Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings. These models are built on Llama3 architecture and fine-tuned using specialized clinical data. They underwent multi-stage preference alignment to effectively respond to natural prompts. While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings. Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks. These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments. The models are now publicly available at \\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}.","sentences":["Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings.","These models are built on Llama3 architecture and fine-tuned using specialized clinical data.","They underwent multi-stage preference alignment to effectively respond to natural prompts.","While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings.","Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks.","These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments.","The models are now publicly available at \\href{https://huggingface.co/m42-health}{https://huggingface.co/m42-health}."],"url":"http://arxiv.org/abs/2408.06142v1"}
{"created":"2024-08-12 13:34:12","title":"High-order observers and high-order state-estimation-based properties of discrete-event systems","abstract":"State-estimation-based properties are central properties in discrete-event systems modeled by labeled finite-state automata studied over the past 3 decades. Most existing results are based on a single agent who knows the structure of a system and can observe a subset of events and estimate the system's state based on the system's structure and the agent's observation to the system. The main tool used to do state estimation and verify state-estimation-based properties is called \\emph{observer} which is the powerset construction originally proposed by Rabin and Scott in 1959, used to determinize a nondeterministic finite automaton with $\\varepsilon$-transitions.   In this paper, we consider labeled finite-state automata, extend the state-estimation-based properties from a single agent to a finite ordered set of agents and also extend the original observer to \\emph{high-order observer} based on the original observer and our \\emph{concurrent composition}. As a result, a general framework on high-order state-estimation-based properties have been built and a basic tool has also been built to verify such properties. This general framework contains many basic properties as its members such as state-based opacity, critical observability, determinism, high-order opacity, etc. Special cases for which verification can be done more efficiently are also discussed.   In our general framework, the system's structure is publicly known to all agents $A_1,\\dots,A_n$, each agent $A_i$ has its own observable event set $E_i$, and additionally knows all its preceding agents' observable events but can only observe its own observable events. The intuitive meaning of our high-order observer is what agent $A_n$ knows about what $A_{n-1}$ knows about \\dots what $A_2$ knows about $A_1$'s state estimate of the system.","sentences":["State-estimation-based properties are central properties in discrete-event systems modeled by labeled finite-state automata studied over the past 3 decades.","Most existing results are based on a single agent who knows the structure of a system and can observe a subset of events and estimate the system's state based on the system's structure and the agent's observation to the system.","The main tool used to do state estimation and verify state-estimation-based properties is called \\emph{observer} which is the powerset construction originally proposed by Rabin and Scott in 1959, used to determinize a nondeterministic finite automaton with $\\varepsilon$-transitions.   ","In this paper, we consider labeled finite-state automata, extend the state-estimation-based properties from a single agent to a finite ordered set of agents and also extend the original observer to \\emph{high-order observer} based on the original observer and our \\emph{concurrent composition}.","As a result, a general framework on high-order state-estimation-based properties have been built and a basic tool has also been built to verify such properties.","This general framework contains many basic properties as its members such as state-based opacity, critical observability, determinism, high-order opacity, etc.","Special cases for which verification can be done more efficiently are also discussed.   ","In our general framework, the system's structure is publicly known to all agents $A_1,\\dots,A_n$, each agent $A_i$ has its own observable event set $E_i$, and additionally knows all its preceding agents' observable events but can only observe its own observable events.","The intuitive meaning of our high-order observer is what agent $A_n$ knows about what $A_{n-1}$ knows about \\dots what $A_2$ knows about $A_1$'s state estimate of the system."],"url":"http://arxiv.org/abs/2408.06141v1"}
{"created":"2024-08-12 13:31:49","title":"An anisotropic, brittle damage model for finite strains with a generic damage tensor regularization","abstract":"This paper establishes a universal framework for the nonlocal modeling of anisotropic damage at finite strains. By the combination of two recent works, the new framework allows for the flexible incorporation of different established hyperelastic finite strain material formulations into anisotropic damage whilst ensuring mesh-independent results by employing a generic set of micromorphic gradient-extensions. First, the anisotropic damage model, generally satisfying the damage growth criterion, is investigated for the specific choice of a Neo-Hookean material on a single element. Next, the model is applied with different gradient-extensions in structural simulations of an asymmetrically notched specimen to identify an efficient choice in the form of a volumetric-deviatoric regularization. Thereafter, the universal framework, which is without loss of generality here specified for a Neo-Hookean material with a volumetric-deviatoric gradient-extension, successfully serves for the complex simulation of a pressure loaded rotor blade.   After acceptance of the manuscript, we make the codes of the material subroutines accessible to the public at https://doi.org/10.5281/zenodo.11171630.","sentences":["This paper establishes a universal framework for the nonlocal modeling of anisotropic damage at finite strains.","By the combination of two recent works, the new framework allows for the flexible incorporation of different established hyperelastic finite strain material formulations into anisotropic damage whilst ensuring mesh-independent results by employing a generic set of micromorphic gradient-extensions.","First, the anisotropic damage model, generally satisfying the damage growth criterion, is investigated for the specific choice of a Neo-Hookean material on a single element.","Next, the model is applied with different gradient-extensions in structural simulations of an asymmetrically notched specimen to identify an efficient choice in the form of a volumetric-deviatoric regularization.","Thereafter, the universal framework, which is without loss of generality here specified for a Neo-Hookean material with a volumetric-deviatoric gradient-extension, successfully serves for the complex simulation of a pressure loaded rotor blade.   ","After acceptance of the manuscript, we make the codes of the material subroutines accessible to the public at https://doi.org/10.5281/zenodo.11171630."],"url":"http://arxiv.org/abs/2408.06140v1"}
