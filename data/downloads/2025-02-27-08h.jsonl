{"created":"2025-02-26 18:58:41","title":"Hi Robot: Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models","abstract":"Generalist robots that can perform a range of different tasks in open-world settings must be able to not only reason about the steps needed to accomplish their goals, but also process complex instructions, prompts, and even feedback during task execution. Intricate instructions (e.g., \"Could you make me a vegetarian sandwich?\" or \"I don't like that one\") require not just the ability to physically perform the individual steps, but the ability to situate complex commands and feedback in the physical world. In this work, we describe a system that uses vision-language models in a hierarchical structure, first reasoning over complex prompts and user feedback to deduce the most appropriate next step to fulfill the task, and then performing that step with low-level actions. In contrast to direct instruction following methods that can fulfill simple commands (\"pick up the cup\"), our system can reason through complex prompts and incorporate situated feedback during task execution (\"that's not trash\"). We evaluate our system across three robotic platforms, including single-arm, dual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks such as cleaning messy tables, making sandwiches, and grocery shopping.","sentences":["Generalist robots that can perform a range of different tasks in open-world settings must be able to not only reason about the steps needed to accomplish their goals, but also process complex instructions, prompts, and even feedback during task execution.","Intricate instructions (e.g., \"Could you make me a vegetarian sandwich?\" or \"I don't like that one\") require not just the ability to physically perform the individual steps, but the ability to situate complex commands and feedback in the physical world.","In this work, we describe a system that uses vision-language models in a hierarchical structure, first reasoning over complex prompts and user feedback to deduce the most appropriate next step to fulfill the task, and then performing that step with low-level actions.","In contrast to direct instruction following methods that can fulfill simple commands (\"pick up the cup\"), our system can reason through complex prompts and incorporate situated feedback during task execution (\"that's not trash\").","We evaluate our system across three robotic platforms, including single-arm, dual-arm, and dual-arm mobile robots, demonstrating its ability to handle tasks such as cleaning messy tables, making sandwiches, and grocery shopping."],"url":"http://arxiv.org/abs/2502.19417v1"}
{"created":"2025-02-26 18:58:30","title":"Norm Growth and Stability Challenges in Localized Sequential Knowledge Editing","abstract":"This study investigates the impact of localized updates to large language models (LLMs), specifically in the context of knowledge editing - a task aimed at incorporating or modifying specific facts without altering broader model capabilities. We first show that across different post-training interventions like continuous pre-training, full fine-tuning and LORA-based fine-tuning, the Frobenius norm of the updated matrices always increases. This increasing norm is especially detrimental for localized knowledge editing, where only a subset of matrices are updated in a model . We reveal a consistent phenomenon across various editing techniques, including fine-tuning, hypernetwork-based approaches, and locate-and-edit methods: the norm of the updated matrix invariably increases with successive updates. Such growth disrupts model balance, particularly when isolated matrices are updated while the rest of the model remains static, leading to potential instability and degradation of downstream performance. Upon deeper investigations of the intermediate activation vectors, we find that the norm of internal activations decreases and is accompanied by shifts in the subspaces occupied by these activations, which shows that these activation vectors now occupy completely different regions in the representation space compared to the unedited model. With our paper, we highlight the technical challenges with continuous and localized sequential knowledge editing and their implications for maintaining model stability and utility.","sentences":["This study investigates the impact of localized updates to large language models (LLMs), specifically in the context of knowledge editing - a task aimed at incorporating or modifying specific facts without altering broader model capabilities.","We first show that across different post-training interventions like continuous pre-training, full fine-tuning and LORA-based fine-tuning, the Frobenius norm of the updated matrices always increases.","This increasing norm is especially detrimental for localized knowledge editing, where only a subset of matrices are updated in a model .","We reveal a consistent phenomenon across various editing techniques, including fine-tuning, hypernetwork-based approaches, and locate-and-edit methods: the norm of the updated matrix invariably increases with successive updates.","Such growth disrupts model balance, particularly when isolated matrices are updated while the rest of the model remains static, leading to potential instability and degradation of downstream performance.","Upon deeper investigations of the intermediate activation vectors, we find that the norm of internal activations decreases and is accompanied by shifts in the subspaces occupied by these activations, which shows that these activation vectors now occupy completely different regions in the representation space compared to the unedited model.","With our paper, we highlight the technical challenges with continuous and localized sequential knowledge editing and their implications for maintaining model stability and utility."],"url":"http://arxiv.org/abs/2502.19416v1"}
{"created":"2025-02-26 18:58:13","title":"Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation","abstract":"There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant researcher effort, reasoning, and ingenuity. Yet current benchmarks for LMs predominantly assess their ability to generate solutions rather than challenge them. We advocate for developing benchmarks that evaluate this inverse capability - creating counterexamples for subtly incorrect solutions. To demonstrate this approach, we start with the domain of algorithmic problem solving, where counterexamples can be evaluated automatically using code execution. Specifically, we introduce REFUTE, a dynamically updating benchmark that includes recent problems and incorrect submissions from programming competitions, where human experts successfully identified counterexamples. Our analysis finds that the best reasoning agents, even OpenAI o3-mini (high) with code execution feedback, can create counterexamples for only <9% of incorrect solutions in REFUTE, even though ratings indicate its ability to solve up to 48% of these problems from scratch. We hope our work spurs progress in evaluating and enhancing LMs' ability to falsify incorrect solutions - a capability that is crucial for both accelerating research and making models self-improve through reliable reflective reasoning.","sentences":["There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery.","Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time.","This process requires significant researcher effort, reasoning, and ingenuity.","Yet current benchmarks for LMs predominantly assess their ability to generate solutions rather than challenge them.","We advocate for developing benchmarks that evaluate this inverse capability - creating counterexamples for subtly incorrect solutions.","To demonstrate this approach, we start with the domain of algorithmic problem solving, where counterexamples can be evaluated automatically using code execution.","Specifically, we introduce REFUTE, a dynamically updating benchmark that includes recent problems and incorrect submissions from programming competitions, where human experts successfully identified counterexamples.","Our analysis finds that the best reasoning agents, even OpenAI o3-mini (high) with code execution feedback, can create counterexamples for only <9% of incorrect solutions in REFUTE, even though ratings indicate its ability to solve up to 48% of these problems from scratch.","We hope our work spurs progress in evaluating and enhancing LMs' ability to falsify incorrect solutions - a capability that is crucial for both accelerating research and making models self-improve through reliable reflective reasoning."],"url":"http://arxiv.org/abs/2502.19414v1"}
{"created":"2025-02-26 18:56:52","title":"Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs","abstract":"Paywalls, licenses and copyright rules often restrict the broad dissemination and reuse of scientific knowledge. We take the position that it is both legally and technically feasible to extract the scientific knowledge in scholarly texts. Current methods, like text embeddings, fail to reliably preserve factual content, and simple paraphrasing may not be legally sound. We urge the community to adopt a new idea: convert scholarly documents into Knowledge Units using LLMs. These units use structured data capturing entities, attributes and relationships without stylistic content. We provide evidence that Knowledge Units: (1) form a legally defensible framework for sharing knowledge from copyrighted research texts, based on legal analyses of German copyright law and U.S. Fair Use doctrine, and (2) preserve most (~95%) factual knowledge from original text, measured by MCQ performance on facts from the original copyrighted text across four research domains. Freeing scientific knowledge from copyright promises transformative benefits for scientific research and education by allowing language models to reuse important facts from copyrighted text. To support this, we share open-source tools for converting research documents into Knowledge Units. Overall, our work posits the feasibility of democratizing access to scientific knowledge while respecting copyright.","sentences":["Paywalls, licenses and copyright rules often restrict the broad dissemination and reuse of scientific knowledge.","We take the position that it is both legally and technically feasible to extract the scientific knowledge in scholarly texts.","Current methods, like text embeddings, fail to reliably preserve factual content, and simple paraphrasing may not be legally sound.","We urge the community to adopt a new idea: convert scholarly documents into Knowledge Units using LLMs.","These units use structured data capturing entities, attributes and relationships without stylistic content.","We provide evidence that Knowledge Units: (1) form a legally defensible framework for sharing knowledge from copyrighted research texts, based on legal analyses of German copyright law and U.S. Fair Use doctrine, and (2) preserve most (~95%) factual knowledge from original text, measured by MCQ performance on facts from the original copyrighted text across four research domains.","Freeing scientific knowledge from copyright promises transformative benefits for scientific research and education by allowing language models to reuse important facts from copyrighted text.","To support this, we share open-source tools for converting research documents into Knowledge Units.","Overall, our work posits the feasibility of democratizing access to scientific knowledge while respecting copyright."],"url":"http://arxiv.org/abs/2502.19413v1"}
{"created":"2025-02-26 18:56:38","title":"The Mighty ToRR: A Benchmark for Table Reasoning and Robustness","abstract":"Despite its real-world significance, model performance on tabular data remains underexplored, leaving uncertainty about which model to rely on and which prompt configuration to adopt. To address this gap, we create ToRR, a benchmark for Table Reasoning and Robustness, that measures model performance and robustness on table-related tasks. The benchmark includes 10 datasets that cover different types of table reasoning capabilities across varied domains. ToRR goes beyond model performance rankings, and is designed to reflect whether models can handle tabular data consistently and robustly, across a variety of common table representation formats. We present a leaderboard as well as comprehensive analyses of the results of leading models over ToRR. Our results reveal a striking pattern of brittle model behavior, where even strong models are unable to perform robustly on tabular data tasks. Although no specific table format leads to consistently better performance, we show that testing over multiple formats is crucial for reliably estimating model capabilities. Moreover, we show that the reliability boost from testing multiple prompts can be equivalent to adding more test examples. Overall, our findings show that table understanding and reasoning tasks remain a significant challenge.","sentences":["Despite its real-world significance, model performance on tabular data remains underexplored, leaving uncertainty about which model to rely on and which prompt configuration to adopt.","To address this gap, we create ToRR, a benchmark for Table Reasoning and Robustness, that measures model performance and robustness on table-related tasks.","The benchmark includes 10 datasets that cover different types of table reasoning capabilities across varied domains.","ToRR goes beyond model performance rankings, and is designed to reflect whether models can handle tabular data consistently and robustly, across a variety of common table representation formats.","We present a leaderboard as well as comprehensive analyses of the results of leading models over ToRR.","Our results reveal a striking pattern of brittle model behavior, where even strong models are unable to perform robustly on tabular data tasks.","Although no specific table format leads to consistently better performance, we show that testing over multiple formats is crucial for reliably estimating model capabilities.","Moreover, we show that the reliability boost from testing multiple prompts can be equivalent to adding more test examples.","Overall, our findings show that table understanding and reasoning tasks remain a significant challenge."],"url":"http://arxiv.org/abs/2502.19412v1"}
{"created":"2025-02-26 18:55:42","title":"Code to Think, Think to Code: A Survey on Code-Enhanced Reasoning and Reasoning-Driven Code Intelligence in LLMs","abstract":"In large language models (LLMs), code and reasoning reinforce each other: code offers an abstract, modular, and logic-driven structure that supports reasoning, while reasoning translates high-level goals into smaller, executable steps that drive more advanced code intelligence. In this study, we examine how code serves as a structured medium for enhancing reasoning: it provides verifiable execution paths, enforces logical decomposition, and enables runtime validation. We also explore how improvements in reasoning have transformed code intelligence from basic completion to advanced capabilities, enabling models to address complex software engineering tasks through planning and debugging. Finally, we identify key challenges and propose future research directions to strengthen this synergy, ultimately improving LLM's performance in both areas.","sentences":["In large language models (LLMs), code and reasoning reinforce each other: code offers an abstract, modular, and logic-driven structure that supports reasoning, while reasoning translates high-level goals into smaller, executable steps that drive more advanced code intelligence.","In this study, we examine how code serves as a structured medium for enhancing reasoning: it provides verifiable execution paths, enforces logical decomposition, and enables runtime validation.","We also explore how improvements in reasoning have transformed code intelligence from basic completion to advanced capabilities, enabling models to address complex software engineering tasks through planning and debugging.","Finally, we identify key challenges and propose future research directions to strengthen this synergy, ultimately improving LLM's performance in both areas."],"url":"http://arxiv.org/abs/2502.19411v1"}
{"created":"2025-02-26 18:55:26","title":"Less or More: Towards Glanceable Explanations for LLM Recommendations Using Ultra-Small Devices","abstract":"Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given. Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space. The verbosity of LLM-generated explanations, however, makes it challenging to deliver glanceable LLM explanations on such ultra-small devices. To address this, we explored 1) spatially structuring an LLM's explanation text using defined contextual components during prompting and 2) presenting temporally adaptive explanations to users based on confidence levels. We conducted a user study to understand how these approaches impacted user experiences when interacting with LLM recommendations and explanations on ultra-small devices. The results showed that structured explanations reduced users' time to action and cognitive load when reading an explanation. Always-on structured explanations increased users' acceptance of AI recommendations. However, users were less satisfied with structured explanations compared to unstructured ones due to their lack of sufficient, readable details. Additionally, adaptively presenting structured explanations was less effective at improving user perceptions of the AI compared to the always-on structured explanations. Together with users' interview feedback, the results led to design implications to be mindful of when personalizing the content and timing of LLM explanations that are displayed on ultra-small devices.","sentences":["Large Language Models (LLMs) have shown remarkable potential in recommending everyday actions as personal AI assistants, while Explainable AI (XAI) techniques are being increasingly utilized to help users understand why a recommendation is given.","Personal AI assistants today are often located on ultra-small devices such as smartwatches, which have limited screen space.","The verbosity of LLM-generated explanations, however, makes it challenging to deliver glanceable LLM explanations on such ultra-small devices.","To address this, we explored 1) spatially structuring an LLM's explanation text using defined contextual components during prompting and 2) presenting temporally adaptive explanations to users based on confidence levels.","We conducted a user study to understand how these approaches impacted user experiences when interacting with LLM recommendations and explanations on ultra-small devices.","The results showed that structured explanations reduced users' time to action and cognitive load when reading an explanation.","Always-on structured explanations increased users' acceptance of AI recommendations.","However, users were less satisfied with structured explanations compared to unstructured ones due to their lack of sufficient, readable details.","Additionally, adaptively presenting structured explanations was less effective at improving user perceptions of the AI compared to the always-on structured explanations.","Together with users' interview feedback, the results led to design implications to be mindful of when personalizing the content and timing of LLM explanations that are displayed on ultra-small devices."],"url":"http://arxiv.org/abs/2502.19410v1"}
{"created":"2025-02-26 18:55:06","title":"ImageChain: Advancing Sequential Image-to-Text Reasoning in Multimodal Large Language Models","abstract":"Reasoning over sequences of images remains a challenge for multimodal large language models (MLLMs). While recent models incorporate multi-image data during pre-training, they still struggle to recognize sequential structures, often treating images independently. This work introduces ImageChain, a framework that enhances MLLMs with sequential reasoning capabilities over image data by modeling visual sequences as a multi-turn conversation. In ImageChain, images are interleaved with corresponding textual descriptions to form a controlled dialogue that explicitly captures temporal dependencies and narrative progression. Our method optimizes for the task of next-scene description, where the model generates a context-aware description of an upcoming scene based on preceding visual and textual cues. We demonstrate that our approach improves performance on the next-scene description task -- achieving an average improvement from 3.7% to 19% in SimRate, a metric that quantifies semantic similarity to human-annotated ground truths. Moreover, ImageChain achieves robust zero-shot out-of-domain performance in applications ranging from comics to robotics. Extensive experiments validate that instruction-tuning in a multimodal, multi-turn conversation design is key to bridging the gap between static image understanding and temporally-aware reasoning.","sentences":["Reasoning over sequences of images remains a challenge for multimodal large language models (MLLMs).","While recent models incorporate multi-image data during pre-training, they still struggle to recognize sequential structures, often treating images independently.","This work introduces ImageChain, a framework that enhances MLLMs with sequential reasoning capabilities over image data by modeling visual sequences as a multi-turn conversation.","In ImageChain, images are interleaved with corresponding textual descriptions to form a controlled dialogue that explicitly captures temporal dependencies and narrative progression.","Our method optimizes for the task of next-scene description, where the model generates a context-aware description of an upcoming scene based on preceding visual and textual cues.","We demonstrate that our approach improves performance on the next-scene description task -- achieving an average improvement from 3.7% to 19% in SimRate, a metric that quantifies semantic similarity to human-annotated ground truths.","Moreover, ImageChain achieves robust zero-shot out-of-domain performance in applications ranging from comics to robotics.","Extensive experiments validate that instruction-tuning in a multimodal, multi-turn conversation design is key to bridging the gap between static image understanding and temporally-aware reasoning."],"url":"http://arxiv.org/abs/2502.19409v1"}
{"created":"2025-02-26 18:54:39","title":"Learning Code-Edit Embedding to Model Student Debugging Behavior","abstract":"Providing effective feedback for programming assignments in computer science education can be challenging: students solve problems by iteratively submitting code, executing it, and using limited feedback from the compiler or the auto-grader to debug. Analyzing student debugging behavior in this process may reveal important insights into their knowledge and inform better personalized support tools. In this work, we propose an encoder-decoder-based model that learns meaningful code-edit embeddings between consecutive student code submissions, to capture their debugging behavior. Our model leverages information on whether a student code submission passes each test case to fine-tune large language models (LLMs) to learn code editing representations. It enables personalized next-step code suggestions that maintain the student's coding style while improving test case correctness. Our model also enables us to analyze student code-editing patterns to uncover common student errors and debugging behaviors, using clustering techniques. Experimental results on a real-world student code submission dataset demonstrate that our model excels at code reconstruction and personalized code suggestion while revealing interesting patterns in student debugging behavior.","sentences":["Providing effective feedback for programming assignments in computer science education can be challenging: students solve problems by iteratively submitting code, executing it, and using limited feedback from the compiler or the auto-grader to debug.","Analyzing student debugging behavior in this process may reveal important insights into their knowledge and inform better personalized support tools.","In this work, we propose an encoder-decoder-based model that learns meaningful code-edit embeddings between consecutive student code submissions, to capture their debugging behavior.","Our model leverages information on whether a student code submission passes each test case to fine-tune large language models (LLMs) to learn code editing representations.","It enables personalized next-step code suggestions that maintain the student's coding style while improving test case correctness.","Our model also enables us to analyze student code-editing patterns to uncover common student errors and debugging behaviors, using clustering techniques.","Experimental results on a real-world student code submission dataset demonstrate that our model excels at code reconstruction and personalized code suggestion while revealing interesting patterns in student debugging behavior."],"url":"http://arxiv.org/abs/2502.19407v1"}
{"created":"2025-02-26 18:53:31","title":"Verde: Verification via Refereed Delegation for Machine Learning Programs","abstract":"Machine learning programs, such as those performing inference, fine-tuning, and training of LLMs, are commonly delegated to untrusted compute providers. To provide correctness guarantees for the client, we propose adapting the cryptographic notion of refereed delegation to the machine learning setting. This approach enables a computationally limited client to delegate a program to multiple untrusted compute providers, with a guarantee of obtaining the correct result if at least one of them is honest. Refereed delegation of ML programs poses two technical hurdles: (1) an arbitration protocol to resolve disputes when compute providers disagree on the output, and (2) the ability to bitwise reproduce ML programs across different hardware setups, For (1), we design Verde, a dispute arbitration protocol that efficiently handles the large scale and graph-based computational model of modern ML programs. For (2), we build RepOps (Reproducible Operators), a library that eliminates hardware \"non-determinism\" by controlling the order of floating point operations performed on all hardware. Our implementation shows that refereed delegation achieves both strong guarantees for clients and practical overheads for compute providers.","sentences":["Machine learning programs, such as those performing inference, fine-tuning, and training of LLMs, are commonly delegated to untrusted compute providers.","To provide correctness guarantees for the client, we propose adapting the cryptographic notion of refereed delegation to the machine learning setting.","This approach enables a computationally limited client to delegate a program to multiple untrusted compute providers, with a guarantee of obtaining the correct result if at least one of them is honest.","Refereed delegation of ML programs poses two technical hurdles: (1) an arbitration protocol to resolve disputes when compute providers disagree on the output, and (2) the ability to bitwise reproduce ML programs across different hardware setups, For (1), we design Verde, a dispute arbitration protocol that efficiently handles the large scale and graph-based computational model of modern ML programs.","For (2), we build RepOps (Reproducible Operators), a library that eliminates hardware \"non-determinism\" by controlling the order of floating point operations performed on all hardware.","Our implementation shows that refereed delegation achieves both strong guarantees for clients and practical overheads for compute providers."],"url":"http://arxiv.org/abs/2502.19405v1"}
{"created":"2025-02-26 18:51:12","title":"General Reasoning Requires Learning to Reason from the Get-go","abstract":"Large Language Models (LLMs) have demonstrated impressive real-world utility, exemplifying artificial useful intelligence (AUI). However, their ability to reason adaptively and robustly -- the hallmarks of artificial general intelligence (AGI) -- remains fragile. While LLMs seemingly succeed in commonsense reasoning, programming, and mathematics, they struggle to generalize algorithmic understanding across novel contexts. Our experiments with algorithmic tasks in esoteric programming languages reveal that LLM's reasoning overfits to the training data and is limited in its transferability. We hypothesize that the core issue underlying such limited transferability is the coupling of reasoning and knowledge in LLMs.   To transition from AUI to AGI, we propose disentangling knowledge and reasoning through three key directions: (1) pretaining to reason using RL from scratch as an alternative to the widely used next-token prediction pretraining, (2) using a curriculum of synthetic tasks to ease the learning of a \\textit{reasoning prior} for RL that can then be transferred to natural language tasks, and (3) learning more generalizable reasoning functions using a small context window to reduce exploiting spurious correlations between tokens. Such a reasoning system coupled with a trained retrieval system and a large external memory bank as a knowledge store can overcome several limitations of existing architectures at learning to reason in novel scenarios.","sentences":["Large Language Models (LLMs) have demonstrated impressive real-world utility, exemplifying artificial useful intelligence (AUI).","However, their ability to reason adaptively and robustly -- the hallmarks of artificial general intelligence (AGI) -- remains fragile.","While LLMs seemingly succeed in commonsense reasoning, programming, and mathematics, they struggle to generalize algorithmic understanding across novel contexts.","Our experiments with algorithmic tasks in esoteric programming languages reveal that LLM's reasoning overfits to the training data and is limited in its transferability.","We hypothesize that the core issue underlying such limited transferability is the coupling of reasoning and knowledge in LLMs.   ","To transition from AUI to AGI, we propose disentangling knowledge and reasoning through three key directions: (1) pretaining to reason using RL from scratch as an alternative to the widely used next-token prediction pretraining, (2) using a curriculum of synthetic tasks to ease the learning of a \\textit{reasoning prior} for RL that can then be transferred to natural language tasks, and (3) learning more generalizable reasoning functions using a small context window to reduce exploiting spurious correlations between tokens.","Such a reasoning system coupled with a trained retrieval system and a large external memory bank as a knowledge store can overcome several limitations of existing architectures at learning to reason in novel scenarios."],"url":"http://arxiv.org/abs/2502.19402v1"}
{"created":"2025-02-26 18:50:49","title":"ARENA: Adaptive Risk-aware and Energy-efficient NAvigation for Multi-Objective 3D Infrastructure Inspection with a UAV","abstract":"Autonomous robotic inspection missions require balancing multiple conflicting objectives while navigating near costly obstacles. Current multi-objective path planning (MOPP) methods struggle to adapt to evolving risks like localization errors, weather, battery state, and communication issues. This letter presents an Adaptive Risk-aware and Energy-efficient NAvigation (ARENA) MOPP approach for UAVs in complex 3D environments. Our method enables online trajectory adaptation by optimizing safety, time, and energy using 4D NURBS representation and a genetic-based algorithm to generate the Pareto front. A novel risk-aware voting algorithm ensures adaptivity. Simulations and real-world tests demonstrate the planner's ability to produce diverse, optimized trajectories covering 95% or more of the range defined by single-objective benchmarks and its ability to estimate power consumption with a mean error representing 14% of the full power range. The ARENA framework enhances UAV autonomy and reliability in critical, evolving 3D missions.","sentences":["Autonomous robotic inspection missions require balancing multiple conflicting objectives while navigating near costly obstacles.","Current multi-objective path planning (MOPP) methods struggle to adapt to evolving risks like localization errors, weather, battery state, and communication issues.","This letter presents an Adaptive Risk-aware and Energy-efficient NAvigation (ARENA) MOPP approach for UAVs in complex 3D environments.","Our method enables online trajectory adaptation by optimizing safety, time, and energy using 4D NURBS representation and a genetic-based algorithm to generate the Pareto front.","A novel risk-aware voting algorithm ensures adaptivity.","Simulations and real-world tests demonstrate the planner's ability to produce diverse, optimized trajectories covering 95% or more of the range defined by single-objective benchmarks and its ability to estimate power consumption with a mean error representing 14% of the full power range.","The ARENA framework enhances UAV autonomy and reliability in critical, evolving 3D missions."],"url":"http://arxiv.org/abs/2502.19401v1"}
{"created":"2025-02-26 18:50:09","title":"TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding","abstract":"Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations.","sentences":["Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension.","While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge.","In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations.","To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics.","Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77.","However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout.","Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations."],"url":"http://arxiv.org/abs/2502.19400v1"}
{"created":"2025-02-26 18:47:53","title":"DROID: Discrete-Time Simulation for Ring-Oscillator-Based Ising Design","abstract":"Many combinatorial problems can be mapped to Ising machines, i.e., networks of coupled oscillators that settle to a minimum-energy ground state, from which the problem solution is inferred. This work proposes DROID, a novel event-driven method for simulating the evolution of a CMOS Ising machine to its ground state. The approach is accurate under general delay-phase relations that include the effects of the transistor nonlinearities and is computationally efficient. On a realistic-size all-to-all coupled ring oscillator array, DROID is nearly four orders of magnitude faster than a traditional HSPICE simulation in predicting the evolution of a coupled oscillator system and is demonstrated to attain a similar distribution of solutions as the hardware.","sentences":["Many combinatorial problems can be mapped to Ising machines, i.e., networks of coupled oscillators that settle to a minimum-energy ground state, from which the problem solution is inferred.","This work proposes DROID, a novel event-driven method for simulating the evolution of a CMOS Ising machine to its ground state.","The approach is accurate under general delay-phase relations that include the effects of the transistor nonlinearities and is computationally efficient.","On a realistic-size all-to-all coupled ring oscillator array, DROID is nearly four orders of magnitude faster than a traditional HSPICE simulation in predicting the evolution of a coupled oscillator system and is demonstrated to attain a similar distribution of solutions as the hardware."],"url":"http://arxiv.org/abs/2502.19399v1"}
{"created":"2025-02-26 18:33:49","title":"Surface-Based Manipulation","abstract":"Intelligence lies not only in the brain but in the body. The shape of our bodies can influence how we think and interact with the physical world. In robotics research, interacting with the physical world is crucial as it allows robots to manipulate objects in various real-life scenarios. Conventional robotic manipulation strategies mainly rely on finger-shaped end effectors. However, achieving stable grasps on fragile, deformable, irregularly shaped, or slippery objects is challenging due to difficulties in establishing stable force or geometric constraints.   Here, we present surface-based manipulation strategies that diverge from classical grasping approaches, using with flat surfaces as minimalist end-effectors. By changing the position and orientation of these surfaces, objects can be translated, rotated and even flipped across the surface using closed-loop control strategies. Since this method does not rely on stable grasp, it can adapt to objects of various shapes, sizes, and stiffness levels, even enabling the manipulation the shape of deformable objects. Our results provide a new perspective for solving complex manipulation problems.","sentences":["Intelligence lies not only in the brain but in the body.","The shape of our bodies can influence how we think and interact with the physical world.","In robotics research, interacting with the physical world is crucial as it allows robots to manipulate objects in various real-life scenarios.","Conventional robotic manipulation strategies mainly rely on finger-shaped end effectors.","However, achieving stable grasps on fragile, deformable, irregularly shaped, or slippery objects is challenging due to difficulties in establishing stable force or geometric constraints.   ","Here, we present surface-based manipulation strategies that diverge from classical grasping approaches, using with flat surfaces as minimalist end-effectors.","By changing the position and orientation of these surfaces, objects can be translated, rotated and even flipped across the surface using closed-loop control strategies.","Since this method does not rely on stable grasp, it can adapt to objects of various shapes, sizes, and stiffness levels, even enabling the manipulation the shape of deformable objects.","Our results provide a new perspective for solving complex manipulation problems."],"url":"http://arxiv.org/abs/2502.19389v1"}
{"created":"2025-02-26 18:33:32","title":"Foundations for Deductive Verification of Continuous Probabilistic Programs: From Lebesgue to Riemann and Back","abstract":"We lay out novel foundations for the computer-aided verification of guaranteed bounds on expected outcomes of imperative probabilistic programs featuring (i) general loops, (ii) continuous distributions, and (iii) conditioning. To handle loops we rely on user-provided quantitative invariants, as is well established. However, in the realm of continuous distributions, invariant verification becomes extremely challenging due to the presence of integrals in expectation-based program semantics. Our key idea is to soundly under- or over-approximate these integrals via Riemann sums. We show that this approach enables the SMT-based invariant verification for programs with a fairly general control flow structure. On the theoretical side, we prove convergence of our Riemann approximations, and establish coRE-completeness of the central verification problems. On the practical side, we show that our approach enables to use existing automated verifiers targeting discrete probabilistic programs for the verification of programs involving continuous sampling. Towards this end, we implement our approach in the recent quantitative verification infrastructure Caesar by encoding Riemann sums in its intermediate verification language. We present several promising case studies.","sentences":["We lay out novel foundations for the computer-aided verification of guaranteed bounds on expected outcomes of imperative probabilistic programs featuring (i) general loops, (ii) continuous distributions, and (iii) conditioning.","To handle loops we rely on user-provided quantitative invariants, as is well established.","However, in the realm of continuous distributions, invariant verification becomes extremely challenging due to the presence of integrals in expectation-based program semantics.","Our key idea is to soundly under- or over-approximate these integrals via Riemann sums.","We show that this approach enables the SMT-based invariant verification for programs with a fairly general control flow structure.","On the theoretical side, we prove convergence of our Riemann approximations, and establish coRE-completeness of the central verification problems.","On the practical side, we show that our approach enables to use existing automated verifiers targeting discrete probabilistic programs for the verification of programs involving continuous sampling.","Towards this end, we implement our approach in the recent quantitative verification infrastructure Caesar by encoding Riemann sums in its intermediate verification language.","We present several promising case studies."],"url":"http://arxiv.org/abs/2502.19388v1"}
{"created":"2025-02-26 18:32:15","title":"Residual Speech Embeddings for Tone Classification: Removing Linguistic Content to Enhance Paralinguistic Analysis","abstract":"Self-supervised learning models for speech processing, such as wav2vec2, HuBERT, WavLM, and Whisper, generate embeddings that capture both linguistic and paralinguistic information, making it challenging to analyze tone independently of spoken content. In this work, we introduce a method for disentangling paralinguistic features from linguistic content by regressing speech embeddings onto their corresponding text embeddings and using the residuals as a representation of vocal tone. We evaluate this approach across multiple self-supervised speech embeddings, demonstrating that residual embeddings significantly improve tone classification performance compared to raw speech embeddings. Our results show that this method enhances linear separability, enabling improved classification even with simple models such as logistic regression. Visualization of the residual embeddings further confirms the successful removal of linguistic information while preserving tone-related features. These findings highlight the potential of residual embeddings for applications in sentiment analysis, speaker characterization, and paralinguistic speech processing.","sentences":["Self-supervised learning models for speech processing, such as wav2vec2, HuBERT, WavLM, and Whisper, generate embeddings that capture both linguistic and paralinguistic information, making it challenging to analyze tone independently of spoken content.","In this work, we introduce a method for disentangling paralinguistic features from linguistic content by regressing speech embeddings onto their corresponding text embeddings and using the residuals as a representation of vocal tone.","We evaluate this approach across multiple self-supervised speech embeddings, demonstrating that residual embeddings significantly improve tone classification performance compared to raw speech embeddings.","Our results show that this method enhances linear separability, enabling improved classification even with simple models such as logistic regression.","Visualization of the residual embeddings further confirms the successful removal of linguistic information while preserving tone-related features.","These findings highlight the potential of residual embeddings for applications in sentiment analysis, speaker characterization, and paralinguistic speech processing."],"url":"http://arxiv.org/abs/2502.19387v1"}
{"created":"2025-02-26 18:31:07","title":"Efficient 4D fMRI ASD Classification using Spatial-Temporal-Omics-based Learning Framework","abstract":"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder impacting social and behavioral development. Resting-state fMRI, a non-invasive tool for capturing brain connectivity patterns, aids in early ASD diagnosis and differentiation from typical controls (TC). However, previous methods, which rely on either mean time series or full 4D data, are limited by a lack of spatial information or by high computational costs. This underscores the need for an efficient solution that preserves both spatial and temporal information. In this paper, we propose a novel, simple, and efficient spatial-temporal-omics learning framework designed to efficiently extract spatio-temporal features from fMRI for ASD classification. Our approach addresses these limitations by utilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics, which preserve full spatial resolution while capturing diverse statistical characteristics of the time series at each voxel. Meanwhile, functional connectivity features serve as the spatial-temporal inter-regional omics, capturing correlations across brain regions. Extensive experiments and ablation studies on the ABIDE dataset demonstrate that our framework significantly outperforms previous methods while maintaining computational efficiency. We believe our research offers valuable insights that will inform and advance future ASD studies, particularly in the realm of spatial-temporal-omics-based learning.","sentences":["Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder impacting social and behavioral development.","Resting-state fMRI, a non-invasive tool for capturing brain connectivity patterns, aids in early ASD diagnosis and differentiation from typical controls (TC).","However, previous methods, which rely on either mean time series or full 4D data, are limited by a lack of spatial information or by high computational costs.","This underscores the need for an efficient solution that preserves both spatial and temporal information.","In this paper, we propose a novel, simple, and efficient spatial-temporal-omics learning framework designed to efficiently extract spatio-temporal features from fMRI for ASD classification.","Our approach addresses these limitations by utilizing 3D time-domain derivatives as the spatial-temporal inter-voxel omics, which preserve full spatial resolution while capturing diverse statistical characteristics of the time series at each voxel.","Meanwhile, functional connectivity features serve as the spatial-temporal inter-regional omics, capturing correlations across brain regions.","Extensive experiments and ablation studies on the ABIDE dataset demonstrate that our framework significantly outperforms previous methods while maintaining computational efficiency.","We believe our research offers valuable insights that will inform and advance future ASD studies, particularly in the realm of spatial-temporal-omics-based learning."],"url":"http://arxiv.org/abs/2502.19386v1"}
{"created":"2025-02-26 18:30:49","title":"HDEE: Heterogeneous Domain Expert Ensemble","abstract":"Training dense LLMs requires enormous amounts of data and centralized compute, which introduces fundamental bottlenecks and ever-growing costs for large models. Several studies aim to reduce this dependency on centralization by reducing the communication overhead of training dense models. Taking this idea of reducing communication overhead to a natural extreme, by training embarrassingly parallelizable ensembles of small independent experts, has been shown to outperform large dense models trained in traditional centralized settings. However, existing studies do not take into account underlying differences amongst data domains and treat them as monolithic, regardless of their underlying complexity, size, or distribution. In this paper, we explore the effects of introducing heterogeneity to these ensembles of domain expert models. Specifically, by allowing models within the ensemble to vary in size--as well as the number of training steps taken depending on the training data's domain--we study the effect heterogeneity has on these ensembles when evaluated against domains included in, and excluded from, the training set. We use the same compute budget to train heterogeneous ensembles and homogeneous baselines for comparison. We show that the heterogeneous ensembles achieve the lowest perplexity scores in $20$ out of the $21$ data domains used in the evaluation. Our code is available at https://github.com/gensyn-ai/hdee.","sentences":["Training dense LLMs requires enormous amounts of data and centralized compute, which introduces fundamental bottlenecks and ever-growing costs for large models.","Several studies aim to reduce this dependency on centralization by reducing the communication overhead of training dense models.","Taking this idea of reducing communication overhead to a natural extreme, by training embarrassingly parallelizable ensembles of small independent experts, has been shown to outperform large dense models trained in traditional centralized settings.","However, existing studies do not take into account underlying differences amongst data domains and treat them as monolithic, regardless of their underlying complexity, size, or distribution.","In this paper, we explore the effects of introducing heterogeneity to these ensembles of domain expert models.","Specifically, by allowing models within the ensemble to vary in size--as well as the number of training steps taken depending on the training data's domain--we study the effect heterogeneity has on these ensembles when evaluated against domains included in, and excluded from, the training set.","We use the same compute budget to train heterogeneous ensembles and homogeneous baselines for comparison.","We show that the heterogeneous ensembles achieve the lowest perplexity scores in $20$ out of the $21$ data domains used in the evaluation.","Our code is available at https://github.com/gensyn-ai/hdee."],"url":"http://arxiv.org/abs/2502.19385v1"}
{"created":"2025-02-26 18:23:07","title":"Preference-Based Gradient Estimation for ML-Based Approximate Combinatorial Optimization","abstract":"Combinatorial optimization (CO) problems arise in a wide range of fields from medicine to logistics and manufacturing. While exact solutions are often not necessary, many applications require finding high-quality solutions quickly. For this purpose, we propose a data-driven approach to improve existing non-learned approximation algorithms for CO. We parameterize the approximation algorithm and train a graph neural network (GNN) to predict parameter values that lead to the best possible solutions. Our pipeline is trained end-to-end in a self-supervised fashion using gradient estimation, treating the approximation algorithm as a black box. We propose a novel gradient estimation scheme for this purpose, which we call preference-based gradient estimation. Our approach combines the benefits of the neural network and the non-learned approximation algorithm: The GNN leverages the information from the dataset to allow the approximation algorithm to find better solutions, while the approximation algorithm guarantees that the solution is feasible. We validate our approach on two well-known combinatorial optimization problems, the travelling salesman problem and the minimum k-cut problem, and show that our method is competitive with state of the art learned CO solvers.","sentences":["Combinatorial optimization (CO) problems arise in a wide range of fields from medicine to logistics and manufacturing.","While exact solutions are often not necessary, many applications require finding high-quality solutions quickly.","For this purpose, we propose a data-driven approach to improve existing non-learned approximation algorithms for CO.","We parameterize the approximation algorithm and train a graph neural network (GNN) to predict parameter values that lead to the best possible solutions.","Our pipeline is trained end-to-end in a self-supervised fashion using gradient estimation, treating the approximation algorithm as a black box.","We propose a novel gradient estimation scheme for this purpose, which we call preference-based gradient estimation.","Our approach combines the benefits of the neural network and the non-learned approximation algorithm: The GNN leverages the information from the dataset to allow the approximation algorithm to find better solutions, while the approximation algorithm guarantees that the solution is feasible.","We validate our approach on two well-known combinatorial optimization problems, the travelling salesman problem and the minimum k-cut problem, and show that our method is competitive with state of the art learned CO solvers."],"url":"http://arxiv.org/abs/2502.19377v1"}
{"created":"2025-02-26 18:15:09","title":"LiDAR Registration with Visual Foundation Models","abstract":"LiDAR registration is a fundamental task in robotic mapping and localization. A critical component of aligning two point clouds is identifying robust point correspondences using point descriptors. This step becomes particularly challenging in scenarios involving domain shifts, seasonal changes, and variations in point cloud structures. These factors substantially impact both handcrafted and learning-based approaches. In this paper, we address these problems by proposing to use DINOv2 features, obtained from surround-view images, as point descriptors. We demonstrate that coupling these descriptors with traditional registration algorithms, such as RANSAC or ICP, facilitates robust 6DoF alignment of LiDAR scans with 3D maps, even when the map was recorded more than a year before. Although conceptually straightforward, our method substantially outperforms more complex baseline techniques. In contrast to previous learning-based point descriptors, our method does not require domain-specific retraining and is agnostic to the point cloud structure, effectively handling both sparse LiDAR scans and dense 3D maps. We show that leveraging the additional camera data enables our method to outperform the best baseline by +24.8 and +17.3 registration recall on the NCLT and Oxford RobotCar datasets. We publicly release the registration benchmark and the code of our work on https://vfm-registration.cs.uni-freiburg.de.","sentences":["LiDAR registration is a fundamental task in robotic mapping and localization.","A critical component of aligning two point clouds is identifying robust point correspondences using point descriptors.","This step becomes particularly challenging in scenarios involving domain shifts, seasonal changes, and variations in point cloud structures.","These factors substantially impact both handcrafted and learning-based approaches.","In this paper, we address these problems by proposing to use DINOv2 features, obtained from surround-view images, as point descriptors.","We demonstrate that coupling these descriptors with traditional registration algorithms, such as RANSAC or ICP, facilitates robust 6DoF alignment of LiDAR scans with 3D maps, even when the map was recorded more than a year before.","Although conceptually straightforward, our method substantially outperforms more complex baseline techniques.","In contrast to previous learning-based point descriptors, our method does not require domain-specific retraining and is agnostic to the point cloud structure, effectively handling both sparse LiDAR scans and dense 3D maps.","We show that leveraging the additional camera data enables our method to outperform the best baseline by +24.8 and +17.3 registration recall on the NCLT and Oxford RobotCar datasets.","We publicly release the registration benchmark and the code of our work on https://vfm-registration.cs.uni-freiburg.de."],"url":"http://arxiv.org/abs/2502.19374v1"}
{"created":"2025-02-26 18:04:01","title":"dCMF: Learning interpretable evolving patterns from temporal multiway data","abstract":"Multiway datasets are commonly analyzed using unsupervised matrix and tensor factorization methods to reveal underlying patterns. Frequently, such datasets include timestamps and could correspond to, for example, health-related measurements of subjects collected over time. The temporal dimension is inherently different from the other dimensions, requiring methods that account for its intrinsic properties. Linear Dynamical Systems (LDS) are specifically designed to capture sequential dependencies in the observed data. In this work, we bridge the gap between tensor factorizations and dynamical modeling by exploring the relationship between LDS, Coupled Matrix Factorizations (CMF) and the PARAFAC2 model. We propose a time-aware coupled factorization model called d(ynamical)CMF that constrains the temporal evolution of the latent factors to adhere to a specific LDS structure. Using synthetic datasets, we compare the performance of dCMF with PARAFAC2 and t(emporal)PARAFAC2 which incorporates temporal smoothness. Our results show that dCMF and PARAFAC2-based approaches perform similarly when capturing smoothly evolving patterns that adhere to the PARAFAC2 structure. However, dCMF outperforms alternatives when the patterns evolve smoothly but deviate from the PARAFAC2 structure. Furthermore, we demonstrate that the proposed dCMF method enables to capture more complex dynamics when additional prior information about the temporal evolution is incorporated.","sentences":["Multiway datasets are commonly analyzed using unsupervised matrix and tensor factorization methods to reveal underlying patterns.","Frequently, such datasets include timestamps and could correspond to, for example, health-related measurements of subjects collected over time.","The temporal dimension is inherently different from the other dimensions, requiring methods that account for its intrinsic properties.","Linear Dynamical Systems (LDS) are specifically designed to capture sequential dependencies in the observed data.","In this work, we bridge the gap between tensor factorizations and dynamical modeling by exploring the relationship between LDS, Coupled Matrix Factorizations (CMF) and the PARAFAC2 model.","We propose a time-aware coupled factorization model called d(ynamical)CMF that constrains the temporal evolution of the latent factors to adhere to a specific LDS structure.","Using synthetic datasets, we compare the performance of dCMF with PARAFAC2 and t(emporal)PARAFAC2 which incorporates temporal smoothness.","Our results show that dCMF and PARAFAC2-based approaches perform similarly when capturing smoothly evolving patterns that adhere to the PARAFAC2 structure.","However, dCMF outperforms alternatives when the patterns evolve smoothly but deviate from the PARAFAC2 structure.","Furthermore, we demonstrate that the proposed dCMF method enables to capture more complex dynamics when additional prior information about the temporal evolution is incorporated."],"url":"http://arxiv.org/abs/2502.19367v1"}
{"created":"2025-02-26 18:01:51","title":"Deep Learning For Time Series Analysis With Application On Human Motion","abstract":"Time series data, defined by equally spaced points over time, is essential in fields like medicine, telecommunications, and energy. Analyzing it involves tasks such as classification, clustering, prototyping, and regression. Classification identifies normal vs. abnormal movements in skeleton-based motion sequences, clustering detects stock market behavior patterns, prototyping expands physical therapy datasets, and regression predicts patient recovery. Deep learning has recently gained traction in time series analysis due to its success in other domains. This thesis leverages deep learning to enhance classification with feature engineering, introduce foundation models, and develop a compact yet state-of-the-art architecture. We also address limited labeled data with self-supervised learning. Our contributions apply to real-world tasks, including human motion analysis for action recognition and rehabilitation. We introduce a generative model for human motion data, valuable for cinematic production and gaming. For prototyping, we propose a shape-based synthetic sample generation method to support regression models when data is scarce. Lastly, we critically evaluate discriminative and generative models, identifying limitations in current methodologies and advocating for a robust, standardized evaluation framework. Our experiments on public datasets provide novel insights and methodologies, advancing time series analysis with practical applications.","sentences":["Time series data, defined by equally spaced points over time, is essential in fields like medicine, telecommunications, and energy.","Analyzing it involves tasks such as classification, clustering, prototyping, and regression.","Classification identifies normal vs. abnormal movements in skeleton-based motion sequences, clustering detects stock market behavior patterns, prototyping expands physical therapy datasets, and regression predicts patient recovery.","Deep learning has recently gained traction in time series analysis due to its success in other domains.","This thesis leverages deep learning to enhance classification with feature engineering, introduce foundation models, and develop a compact yet state-of-the-art architecture.","We also address limited labeled data with self-supervised learning.","Our contributions apply to real-world tasks, including human motion analysis for action recognition and rehabilitation.","We introduce a generative model for human motion data, valuable for cinematic production and gaming.","For prototyping, we propose a shape-based synthetic sample generation method to support regression models when data is scarce.","Lastly, we critically evaluate discriminative and generative models, identifying limitations in current methodologies and advocating for a robust, standardized evaluation framework.","Our experiments on public datasets provide novel insights and methodologies, advancing time series analysis with practical applications."],"url":"http://arxiv.org/abs/2502.19364v1"}
{"created":"2025-02-26 18:01:19","title":"DataMan: Data Manager for Pre-training Large Language Models","abstract":"The performance emergence of large language models (LLMs) driven by data scaling laws makes the selection of pre-training data increasingly important. However, existing methods rely on limited heuristics and human intuition, lacking comprehensive and clear guidelines. To address this, we are inspired by ``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit its performance. As its pre-training capabilities are related to perplexity (PPL), we derive 14 quality criteria from the causes of text perplexity anomalies and introduce 15 common application domains to support domain mixing. In this paper, we train a Data Manager (DataMan) to learn quality ratings and domain recognition from pointwise rating, and use it to annotate a 447B token pre-training corpus with 14 quality ratings and domain type. Our experiments validate our approach, using DataMan to select 30B tokens to train a 1.3B-parameter language model, demonstrating significant improvements in in-context learning (ICL), perplexity, and instruction-following ability over the state-of-the-art baseline. The best-performing model, based on the Overall Score l=5 surpasses a model trained with 50% more data using uniform sampling. We continue pre-training with high-rated, domain-specific data annotated by DataMan to enhance domain-specific ICL performance and thus verify DataMan's domain mixing ability. Our findings emphasize the importance of quality ranking, the complementary nature of quality criteria, and their low correlation with perplexity, analyzing misalignment between PPL and ICL performance. We also thoroughly analyzed our pre-training dataset, examining its composition, the distribution of quality ratings, and the original document sources.","sentences":["The performance emergence of large language models (LLMs) driven by data scaling laws makes the selection of pre-training data increasingly important.","However, existing methods rely on limited heuristics and human intuition, lacking comprehensive and clear guidelines.","To address this, we are inspired by ``reverse thinking'' -- prompting LLMs to self-identify which criteria benefit its performance.","As its pre-training capabilities are related to perplexity (PPL), we derive 14 quality criteria from the causes of text perplexity anomalies and introduce 15 common application domains to support domain mixing.","In this paper, we train a Data Manager (DataMan) to learn quality ratings and domain recognition from pointwise rating, and use it to annotate a 447B token pre-training corpus with 14 quality ratings and domain type.","Our experiments validate our approach, using DataMan to select 30B tokens to train a 1.3B-parameter language model, demonstrating significant improvements in in-context learning (ICL), perplexity, and instruction-following ability over the state-of-the-art baseline.","The best-performing model, based on the Overall Score l=5 surpasses a model trained with 50% more data using uniform sampling.","We continue pre-training with high-rated, domain-specific data annotated by DataMan to enhance domain-specific ICL performance and thus verify DataMan's domain mixing ability.","Our findings emphasize the importance of quality ranking, the complementary nature of quality criteria, and their low correlation with perplexity, analyzing misalignment between PPL and ICL performance.","We also thoroughly analyzed our pre-training dataset, examining its composition, the distribution of quality ratings, and the original document sources."],"url":"http://arxiv.org/abs/2502.19363v1"}
{"created":"2025-02-26 17:59:27","title":"Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?","abstract":"Recently, o1-like models have drawn significant attention, where these models produce the long Chain-of-Thought (CoT) reasoning steps to improve the reasoning abilities of existing Large Language Models (LLMs). In this paper, to understand the qualities of these long CoTs and measure the critique abilities of existing LLMs on these long CoTs, we introduce the DeltaBench, including the generated long CoTs from different o1-like models (e.g., QwQ, DeepSeek-R1) for different reasoning tasks (e.g., Math, Code, General Reasoning), to measure the ability to detect errors in long CoT reasoning. Based on DeltaBench, we first perform fine-grained analysis of the generated long CoTs to discover the effectiveness and efficiency of different o1-like models. Then, we conduct extensive evaluations of existing process reward models (PRMs) and critic models to detect the errors of each annotated process, which aims to investigate the boundaries and limitations of existing PRMs and critic models. Finally, we hope that DeltaBench could guide developers to better understand the long CoT reasoning abilities of their models.","sentences":["Recently, o1-like models have drawn significant attention, where these models produce the long Chain-of-Thought (CoT) reasoning steps to improve the reasoning abilities of existing Large Language Models (LLMs).","In this paper, to understand the qualities of these long CoTs and measure the critique abilities of existing LLMs on these long CoTs, we introduce the DeltaBench, including the generated long CoTs from different o1-like models (e.g., QwQ, DeepSeek-R1) for different reasoning tasks (e.g., Math, Code, General Reasoning), to measure the ability to detect errors in long CoT reasoning.","Based on DeltaBench, we first perform fine-grained analysis of the generated long CoTs to discover the effectiveness and efficiency of different o1-like models.","Then, we conduct extensive evaluations of existing process reward models (PRMs) and critic models to detect the errors of each annotated process, which aims to investigate the boundaries and limitations of existing PRMs and critic models.","Finally, we hope that DeltaBench could guide developers to better understand the long CoT reasoning abilities of their models."],"url":"http://arxiv.org/abs/2502.19361v1"}
{"created":"2025-02-26 17:56:55","title":"Sustaining Knowledge Infrastructures: Asking Questions and Listening for Answers","abstract":"Sustaining knowledge infrastructures (KIs) remains a persistent issue that requires continued engagement from diverse stakeholders. This is due to the complexity of KIs and sustainability, as well as to new questions and values that are arising in relation to KI maintenance. In this commentary, we draw on existing literature and our experiences at a workshop for researchers exploring KI evaluation to pose five directions of thinking which are especially relevant for KI project managers to consider when thinking about how to make their KIs stand the test of time.","sentences":["Sustaining knowledge infrastructures (KIs) remains a persistent issue that requires continued engagement from diverse stakeholders.","This is due to the complexity of KIs and sustainability, as well as to new questions and values that are arising in relation to KI maintenance.","In this commentary, we draw on existing literature and our experiences at a workshop for researchers exploring KI evaluation to pose five directions of thinking which are especially relevant for KI project managers to consider when thinking about how to make their KIs stand the test of time."],"url":"http://arxiv.org/abs/2502.19360v1"}
{"created":"2025-02-26 17:55:01","title":"Physics-Based Hybrid Machine Learning for Critical Heat Flux Prediction with Uncertainty Quantification","abstract":"Critical heat flux is a key quantity in boiling system modeling due to its impact on heat transfer and component temperature and performance. This study investigates the development and validation of an uncertainty-aware hybrid modeling approach that combines machine learning with physics-based models in the prediction of critical heat flux in nuclear reactors for cases of dryout. Two empirical correlations, Biasi and Bowring, were employed with three machine learning uncertainty quantification techniques: deep neural network ensembles, Bayesian neural networks, and deep Gaussian processes. A pure machine learning model without a base model served as a baseline for comparison. This study examines the performance and uncertainty of the models under both plentiful and limited training data scenarios using parity plots, uncertainty distributions, and calibration curves. The results indicate that the Biasi hybrid deep neural network ensemble achieved the most favorable performance (with a mean absolute relative error of 1.846% and stable uncertainty estimates), particularly in the plentiful data scenario. The Bayesian neural network models showed slightly higher error and uncertainty but superior calibration. By contrast, deep Gaussian process models underperformed by most metrics. All hybrid models outperformed pure machine learning configurations, demonstrating resistance against data scarcity.","sentences":["Critical heat flux is a key quantity in boiling system modeling due to its impact on heat transfer and component temperature and performance.","This study investigates the development and validation of an uncertainty-aware hybrid modeling approach that combines machine learning with physics-based models in the prediction of critical heat flux in nuclear reactors for cases of dryout.","Two empirical correlations, Biasi and Bowring, were employed with three machine learning uncertainty quantification techniques: deep neural network ensembles, Bayesian neural networks, and deep Gaussian processes.","A pure machine learning model without a base model served as a baseline for comparison.","This study examines the performance and uncertainty of the models under both plentiful and limited training data scenarios using parity plots, uncertainty distributions, and calibration curves.","The results indicate that the Biasi hybrid deep neural network ensemble achieved the most favorable performance (with a mean absolute relative error of 1.846% and stable uncertainty estimates), particularly in the plentiful data scenario.","The Bayesian neural network models showed slightly higher error and uncertainty but superior calibration.","By contrast, deep Gaussian process models underperformed by most metrics.","All hybrid models outperformed pure machine learning configurations, demonstrating resistance against data scarcity."],"url":"http://arxiv.org/abs/2502.19357v1"}
{"created":"2025-02-26 17:54:47","title":"Recurrent Auto-Encoders for Enhanced Deep Reinforcement Learning in Wilderness Search and Rescue Planning","abstract":"Wilderness search and rescue operations are often carried out over vast landscapes. The search efforts, however, must be undertaken in minimum time to maximize the chance of survival of the victim. Whilst the advent of cheap multicopters in recent years has changed the way search operations are handled, it has not solved the challenges of the massive areas at hand. The problem therefore is not one of complete coverage, but one of maximizing the information gathered in the limited time available. In this work we propose that a combination of a recurrent autoencoder and deep reinforcement learning is a more efficient solution to the search problem than previous pure deep reinforcement learning or optimisation approaches. The autoencoder training paradigm efficiently maximizes the information throughput of the encoder into its latent space representation which deep reinforcement learning is primed to leverage. Without the overhead of independently solving the problem that the recurrent autoencoder is designed for, it is more efficient in learning the control task. We further implement three additional architectures for a comprehensive comparison of the main proposed architecture. Similarly, we apply both soft actor-critic and proximal policy optimisation to provide an insight into the performance of both in a highly non-linear and complex application with a large observation Results show that the proposed architecture is vastly superior to the benchmarks, with soft actor-critic achieving the best performance. This model further outperformed work from the literature whilst having below a fifth of the total learnable parameters and training in a quarter of the time.","sentences":["Wilderness search and rescue operations are often carried out over vast landscapes.","The search efforts, however, must be undertaken in minimum time to maximize the chance of survival of the victim.","Whilst the advent of cheap multicopters in recent years has changed the way search operations are handled, it has not solved the challenges of the massive areas at hand.","The problem therefore is not one of complete coverage, but one of maximizing the information gathered in the limited time available.","In this work we propose that a combination of a recurrent autoencoder and deep reinforcement learning is a more efficient solution to the search problem than previous pure deep reinforcement learning or optimisation approaches.","The autoencoder training paradigm efficiently maximizes the information throughput of the encoder into its latent space representation which deep reinforcement learning is primed to leverage.","Without the overhead of independently solving the problem that the recurrent autoencoder is designed for, it is more efficient in learning the control task.","We further implement three additional architectures for a comprehensive comparison of the main proposed architecture.","Similarly, we apply both soft actor-critic and proximal policy optimisation to provide an insight into the performance of both in a highly non-linear and complex application with a large observation Results show that the proposed architecture is vastly superior to the benchmarks, with soft actor-critic achieving the best performance.","This model further outperformed work from the literature whilst having below a fifth of the total learnable parameters and training in a quarter of the time."],"url":"http://arxiv.org/abs/2502.19356v1"}
{"created":"2025-02-26 17:53:53","title":"Two-Stage Weighted Projection for Reliable Low-Complexity Cooperative and Non-Cooperative Localization","abstract":"In this paper, we propose a two-stage weighted projection method (TS-WPM) for time-difference-of-arrival (TDOA)-based localization, providing provable improvements in positioning accuracy, particularly under high geometric dilution of precision (GDOP) and low signal-to-noise ratio (SNR) conditions. TS-WPM employs a two-stage iterative refinement approach that dynamically updates both range and position estimates, effectively mitigating residual errors while maintaining computational efficiency. Additionally, we extend TS-WPM to support cooperative localization by leveraging two-way time-of-arrival (TW-TOA) measurements, which enhances positioning accuracy in scenarios with limited anchor availability. To analyze TS-WPM, we derive its error covariance matrix and mean squared error (MSE), establishing conditions for its optimality and robustness. To facilitate rigorous evaluation, we develop a 3rd Generation Partnership Project (3GPP)-compliant analytical framework, incorporating 5G New Radio (NR) physical layer aspects as well as large-scale and small-scale fading. As part of this, we derive a generalized Cram{\\'e}r-Rao lower bound (CRLB) for multipath propagation and introduce a novel non-line-of-sight (NLOS) bias model that accounts for propagation conditions and SNR variations. Our evaluations demonstrate that TS-WPM achieves near-CRLB performance and consistently outperforms state-of-the-art weighted nonlinear least squares (WNLS) in high GDOP and low SNR scenarios. Moreover, cooperative localization with TS-WPM significantly enhances accuracy, especially when an insufficient number of anchors (such as 2) are visible. Finally, we analyze the computational complexity of TS-WPM, showing its balanced trade-off between accuracy and efficiency, making it a scalable solution for real-time localization in next-generation networks.","sentences":["In this paper, we propose a two-stage weighted projection method (TS-WPM) for time-difference-of-arrival (TDOA)-based localization, providing provable improvements in positioning accuracy, particularly under high geometric dilution of precision (GDOP) and low signal-to-noise ratio (SNR) conditions.","TS-WPM employs a two-stage iterative refinement approach that dynamically updates both range and position estimates, effectively mitigating residual errors while maintaining computational efficiency.","Additionally, we extend TS-WPM to support cooperative localization by leveraging two-way time-of-arrival (TW-TOA) measurements, which enhances positioning accuracy in scenarios with limited anchor availability.","To analyze TS-WPM, we derive its error covariance matrix and mean squared error (MSE), establishing conditions for its optimality and robustness.","To facilitate rigorous evaluation, we develop a 3rd Generation Partnership Project (3GPP)-compliant analytical framework, incorporating 5G New Radio (NR) physical layer aspects as well as large-scale and small-scale fading.","As part of this, we derive a generalized Cram{\\'e}r-Rao lower bound (CRLB) for multipath propagation and introduce a novel non-line-of-sight (NLOS) bias model that accounts for propagation conditions and SNR variations.","Our evaluations demonstrate that TS-WPM achieves near-CRLB performance and consistently outperforms state-of-the-art weighted nonlinear least squares (WNLS) in high GDOP and low SNR scenarios.","Moreover, cooperative localization with TS-WPM significantly enhances accuracy, especially when an insufficient number of anchors (such as 2) are visible.","Finally, we analyze the computational complexity of TS-WPM, showing its balanced trade-off between accuracy and efficiency, making it a scalable solution for real-time localization in next-generation networks."],"url":"http://arxiv.org/abs/2502.19354v1"}
{"created":"2025-02-26 17:48:39","title":"Estimating Nodal Spreading Influence Using Partial Temporal Network","abstract":"Temporal networks, whose links are activated or deactivated over time, are used to represent complex systems such as social interactions or collaborations occurring at specific times. Such networks facilitate the spread of information and epidemics. The average number of nodes infected via a spreading process on a network starting from a single seed node over a given period is called the influence of that node. In this paper, we address the question of how to utilize the partially observed temporal network (local and of short duration) around each node, to estimate the ranking of nodes in spreading influence on the full network over a long period. This is essential for target marketing and epidemic/misinformation mitigation where only partial network information is possibly accessible. This would also enable us to understand which network properties of a node, observed locally and shortly after the start of the spreading process, determine its influence. We systematically propose a set of nodal centrality metrics based on partial temporal network information, encoding diverse properties of (time-respecting) walks. It is found that distinct centrality metrics perform the best in estimating nodal influence depending on the infection probability of the spreading process. For a broad range of the infection probability, a node tends to be influential if it can reach many distinct nodes via time-respecting walks and if these nodes can be reached early in time. We find and explain why the proposed metrics generally outperform classic centrality metrics derived from both full and partial temporal networks.","sentences":["Temporal networks, whose links are activated or deactivated over time, are used to represent complex systems such as social interactions or collaborations occurring at specific times.","Such networks facilitate the spread of information and epidemics.","The average number of nodes infected via a spreading process on a network starting from a single seed node over a given period is called the influence of that node.","In this paper, we address the question of how to utilize the partially observed temporal network (local and of short duration) around each node, to estimate the ranking of nodes in spreading influence on the full network over a long period.","This is essential for target marketing and epidemic/misinformation mitigation where only partial network information is possibly accessible.","This would also enable us to understand which network properties of a node, observed locally and shortly after the start of the spreading process, determine its influence.","We systematically propose a set of nodal centrality metrics based on partial temporal network information, encoding diverse properties of (time-respecting) walks.","It is found that distinct centrality metrics perform the best in estimating nodal influence depending on the infection probability of the spreading process.","For a broad range of the infection probability, a node tends to be influential if it can reach many distinct nodes via time-respecting walks and if these nodes can be reached early in time.","We find and explain why the proposed metrics generally outperform classic centrality metrics derived from both full and partial temporal networks."],"url":"http://arxiv.org/abs/2502.19350v1"}
{"created":"2025-02-26 17:45:01","title":"CryptoPulse: Short-Term Cryptocurrency Forecasting with Dual-Prediction and Cross-Correlated Market Indicators","abstract":"Cryptocurrencies fluctuate in markets with high price volatility, posing significant challenges for investors. To aid in informed decision-making, systems predicting cryptocurrency market movements have been developed, typically focusing on historical patterns. However, these methods often overlook three critical factors influencing market dynamics: 1) the macro investing environment, reflected in major cryptocurrency fluctuations affecting collaborative investor behaviors; 2) overall market sentiment, heavily influenced by news impacting investor strategies; and 3) technical indicators, offering insights into overbought or oversold conditions, momentum, and market trends, which are crucial for short-term price movements. This paper proposes a dual prediction mechanism that forecasts the next day's closing price by incorporating macroeconomic fluctuations, technical indicators, and individual cryptocurrency price changes. Additionally, a novel refinement mechanism enhances predictions through market sentiment-based rescaling and fusion. Experiments demonstrate that the proposed model achieves state-of-the-art performance, consistently outperforming ten comparison methods.","sentences":["Cryptocurrencies fluctuate in markets with high price volatility, posing significant challenges for investors.","To aid in informed decision-making, systems predicting cryptocurrency market movements have been developed, typically focusing on historical patterns.","However, these methods often overlook three critical factors influencing market dynamics: 1) the macro investing environment, reflected in major cryptocurrency fluctuations affecting collaborative investor behaviors; 2) overall market sentiment, heavily influenced by news impacting investor strategies; and 3) technical indicators, offering insights into overbought or oversold conditions, momentum, and market trends, which are crucial for short-term price movements.","This paper proposes a dual prediction mechanism that forecasts the next day's closing price by incorporating macroeconomic fluctuations, technical indicators, and individual cryptocurrency price changes.","Additionally, a novel refinement mechanism enhances predictions through market sentiment-based rescaling and fusion.","Experiments demonstrate that the proposed model achieves state-of-the-art performance, consistently outperforming ten comparison methods."],"url":"http://arxiv.org/abs/2502.19349v1"}
{"created":"2025-02-26 17:39:04","title":"The Simulation Semantics of Synthesisable Verilog","abstract":"Despite numerous previous formalisation projects targeting Verilog, the semantics of Verilog defined by the Verilog standard -- Verilog's simulation semantics -- has thus far eluded definitive mathematical formalisation. Previous projects on formalising the semantics have made good progress but no previous project provides a formalisation that can be used to execute or formally reason about real-world hardware designs. In this paper, we show that the reason for this is that the Verilog standard is inconsistent both with Verilog practice and itself. We pinpoint a series of problems in the Verilog standard that we have identified in how the standard defines the semantics of the subset of Verilog used to describe hardware designs, that is, the synthesisable subset of Verilog. We show how the most complete Verilog formalisation to date inherits these problems and how, after we repair these problems in an executable implementation of the formalisation, the repaired implementation can be used to execute real-world hardware designs. The existing formalisation together with the repairs hence constitute the first formalisation of Verilog's simulation semantics compatible with real-world hardware designs. Additionally, to make the results of this paper accessible to a wider (nonmathematical) audience, we provide a visual formalisation of Verilog's simulation semantics.","sentences":["Despite numerous previous formalisation projects targeting Verilog, the semantics of Verilog defined by the Verilog standard -- Verilog's simulation semantics -- has thus far eluded definitive mathematical formalisation.","Previous projects on formalising the semantics have made good progress but no previous project provides a formalisation that can be used to execute or formally reason about real-world hardware designs.","In this paper, we show that the reason for this is that the Verilog standard is inconsistent both with Verilog practice and itself.","We pinpoint a series of problems in the Verilog standard that we have identified in how the standard defines the semantics of the subset of Verilog used to describe hardware designs, that is, the synthesisable subset of Verilog.","We show how the most complete Verilog formalisation to date inherits these problems and how, after we repair these problems in an executable implementation of the formalisation, the repaired implementation can be used to execute real-world hardware designs.","The existing formalisation together with the repairs hence constitute the first formalisation of Verilog's simulation semantics compatible with real-world hardware designs.","Additionally, to make the results of this paper accessible to a wider (nonmathematical) audience, we provide a visual formalisation of Verilog's simulation semantics."],"url":"http://arxiv.org/abs/2502.19348v1"}
{"created":"2025-02-26 17:38:58","title":"Controlled Diversity: Length-optimized Natural Language Generation","abstract":"LLMs are not generally able to adjust the length of their outputs based on strict length requirements, a capability that would improve their usefulness in applications that require adherence to diverse user and system requirements. We present an approach to train LLMs to acquire this capability by augmenting existing data and applying existing fine-tuning techniques, which we compare based on the trained models' adherence to the length requirement and overall response quality relative to the baseline model. Our results demonstrate that these techniques can be successfully applied to train LLMs to adhere to length requirements, with the trained models generating texts which better align to the length requirements. Our results indicate that our method may change the response quality when using training data that was not generated by the baseline model. This allows simultaneous alignment to another training objective in certain scenarios, but is undesirable otherwise. Training on a dataset containing the model's own responses eliminates this issue.","sentences":["LLMs are not generally able to adjust the length of their outputs based on strict length requirements, a capability that would improve their usefulness in applications that require adherence to diverse user and system requirements.","We present an approach to train LLMs to acquire this capability by augmenting existing data and applying existing fine-tuning techniques, which we compare based on the trained models' adherence to the length requirement and overall response quality relative to the baseline model.","Our results demonstrate that these techniques can be successfully applied to train LLMs to adhere to length requirements, with the trained models generating texts which better align to the length requirements.","Our results indicate that our method may change the response quality when using training data that was not generated by the baseline model.","This allows simultaneous alignment to another training objective in certain scenarios, but is undesirable otherwise.","Training on a dataset containing the model's own responses eliminates this issue."],"url":"http://arxiv.org/abs/2502.19347v1"}
{"created":"2025-02-26 17:32:38","title":"Unveiling Wireless Users' Locations via Modulation Classification-based Passive Attack","abstract":"The broadcast nature of the wireless medium and openness of wireless standards, e.g., 3GPP releases 16-20, invite adversaries to launch various active and passive attacks on cellular and other wireless networks. This work identifies one such loose end of wireless standards and presents a novel passive attack method enabling an eavesdropper (Eve) to localize a line of sight wireless user (Bob) who is communicating with a base station or WiFi access point (Alice). The proposed attack involves two phases. In the first phase, Eve performs modulation classification by intercepting the downlink channel between Alice and Bob. This enables Eve to utilize the publicly available modulation and coding scheme (MCS) tables to do pesudo-ranging, i.e., the Eve determines the ring within which Bob is located, which drastically reduces the search space. In the second phase, Eve sniffs the uplink channel, and employs multiple strategies to further refine Bob's location within the ring. Towards the end, we present our thoughts on how this attack can be extended to non-line-of-sight scenarios, and how this attack could act as a scaffolding to construct a malicious digital twin map.","sentences":["The broadcast nature of the wireless medium and openness of wireless standards, e.g., 3GPP releases 16-20, invite adversaries to launch various active and passive attacks on cellular and other wireless networks.","This work identifies one such loose end of wireless standards and presents a novel passive attack method enabling an eavesdropper (Eve) to localize a line of sight wireless user (Bob) who is communicating with a base station or WiFi access point (Alice).","The proposed attack involves two phases.","In the first phase, Eve performs modulation classification by intercepting the downlink channel between Alice and Bob.","This enables Eve to utilize the publicly available modulation and coding scheme (MCS) tables to do pesudo-ranging, i.e., the Eve determines the ring within which Bob is located, which drastically reduces the search space.","In the second phase, Eve sniffs the uplink channel, and employs multiple strategies to further refine Bob's location within the ring.","Towards the end, we present our thoughts on how this attack can be extended to non-line-of-sight scenarios, and how this attack could act as a scaffolding to construct a malicious digital twin map."],"url":"http://arxiv.org/abs/2502.19341v1"}
{"created":"2025-02-26 17:32:22","title":"Hybrid Robot Learning for Automatic Robot Motion Planning in Manufacturing","abstract":"Industrial robots are widely used in diverse manufacturing environments. Nonetheless, how to enable robots to automatically plan trajectories for changing tasks presents a considerable challenge. Further complexities arise when robots operate within work cells alongside machines, humans, or other robots. This paper introduces a multi-level hybrid robot motion planning method combining a task space Reinforcement Learning-based Learning from Demonstration (RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) based agent. A higher level agent learns to switch between the two agents to enable feasible and smooth motion. The feasibility is computed by incorporating reachability, joint limits, manipulability, and collision risks of the robot in the given environment. Therefore, the derived hybrid motion planning policy generates a feasible trajectory that adheres to task constraints. The effectiveness of the method is validated through sim ulated robotic scenarios and in a real-world setup.","sentences":["Industrial robots are widely used in diverse manufacturing environments.","Nonetheless, how to enable robots to automatically plan trajectories for changing tasks presents a considerable challenge.","Further complexities arise when robots operate within work cells alongside machines, humans, or other robots.","This paper introduces a multi-level hybrid robot motion planning method combining a task space Reinforcement Learning-based Learning from Demonstration (RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) based agent.","A higher level agent learns to switch between the two agents to enable feasible and smooth motion.","The feasibility is computed by incorporating reachability, joint limits, manipulability, and collision risks of the robot in the given environment.","Therefore, the derived hybrid motion planning policy generates a feasible trajectory that adheres to task constraints.","The effectiveness of the method is validated through sim ulated robotic scenarios and in a real-world setup."],"url":"http://arxiv.org/abs/2502.19340v1"}
{"created":"2025-02-26 17:32:07","title":"Evaluating LLMs and Pre-trained Models for Text Summarization Across Diverse Datasets","abstract":"Text summarization plays a crucial role in natural language processing by condensing large volumes of text into concise and coherent summaries. As digital content continues to grow rapidly and the demand for effective information retrieval increases, text summarization has become a focal point of research in recent years. This study offers a thorough evaluation of four leading pre-trained and open-source large language models: BART, FLAN-T5, LLaMA-3-8B, and Gemma-7B, across five diverse datasets CNN/DM, Gigaword, News Summary, XSum, and BBC News. The evaluation employs widely recognized automatic metrics, including ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR, to assess the models' capabilities in generating coherent and informative summaries. The results reveal the comparative strengths and limitations of these models in processing various text types.","sentences":["Text summarization plays a crucial role in natural language processing by condensing large volumes of text into concise and coherent summaries.","As digital content continues to grow rapidly and the demand for effective information retrieval increases, text summarization has become a focal point of research in recent years.","This study offers a thorough evaluation of four leading pre-trained and open-source large language models: BART, FLAN-T5, LLaMA-3-8B, and Gemma-7B, across five diverse datasets CNN/DM, Gigaword, News Summary, XSum, and BBC News.","The evaluation employs widely recognized automatic metrics, including ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, and METEOR, to assess the models' capabilities in generating coherent and informative summaries.","The results reveal the comparative strengths and limitations of these models in processing various text types."],"url":"http://arxiv.org/abs/2502.19339v1"}
{"created":"2025-02-26 17:30:52","title":"Consistent Amortized Clustering via Generative Flow Networks","abstract":"Neural models for amortized probabilistic clustering yield samples of cluster labels given a set-structured input, while avoiding lengthy Markov chain runs and the need for explicit data likelihoods. Existing methods which label each data point sequentially, like the Neural Clustering Process, often lead to cluster assignments highly dependent on the data order. Alternatively, methods that sequentially create full clusters, do not provide assignment probabilities. In this paper, we introduce GFNCP, a novel framework for amortized clustering. GFNCP is formulated as a Generative Flow Network with a shared energy-based parametrization of policy and reward. We show that the flow matching conditions are equivalent to consistency of the clustering posterior under marginalization, which in turn implies order invariance. GFNCP also outperforms existing methods in clustering performance on both synthetic and real-world data.","sentences":["Neural models for amortized probabilistic clustering yield samples of cluster labels given a set-structured input, while avoiding lengthy Markov chain runs and the need for explicit data likelihoods.","Existing methods which label each data point sequentially, like the Neural Clustering Process, often lead to cluster assignments highly dependent on the data order.","Alternatively, methods that sequentially create full clusters, do not provide assignment probabilities.","In this paper, we introduce GFNCP, a novel framework for amortized clustering.","GFNCP is formulated as a Generative Flow Network with a shared energy-based parametrization of policy and reward.","We show that the flow matching conditions are equivalent to consistency of the clustering posterior under marginalization, which in turn implies order invariance.","GFNCP also outperforms existing methods in clustering performance on both synthetic and real-world data."],"url":"http://arxiv.org/abs/2502.19337v1"}
{"created":"2025-02-26 17:29:08","title":"I Know What I Don't Know: Improving Model Cascades Through Confidence Tuning","abstract":"Large-scale machine learning models deliver strong performance across a wide range of tasks but come with significant computational and resource constraints. To mitigate these challenges, local smaller models are often deployed alongside larger models, relying on routing and deferral mechanisms to offload complex tasks. However, existing approaches inadequately balance the capabilities of these models, often resulting in unnecessary deferrals or sub-optimal resource usage. In this work we introduce a novel loss function called Gatekeeper for calibrating smaller models in cascade setups. Our approach fine-tunes the smaller model to confidently handle tasks it can perform correctly while deferring complex tasks to the larger model. Moreover, it incorporates a mechanism for managing the trade-off between model performance and deferral accuracy, and is broadly applicable across various tasks and domains without any architectural changes. We evaluate our method on encoder-only, decoder-only, and encoder-decoder architectures. Experiments across image classification, language modeling, and vision-language tasks show that our approach substantially improves deferral performance.","sentences":["Large-scale machine learning models deliver strong performance across a wide range of tasks but come with significant computational and resource constraints.","To mitigate these challenges, local smaller models are often deployed alongside larger models, relying on routing and deferral mechanisms to offload complex tasks.","However, existing approaches inadequately balance the capabilities of these models, often resulting in unnecessary deferrals or sub-optimal resource usage.","In this work we introduce a novel loss function called Gatekeeper for calibrating smaller models in cascade setups.","Our approach fine-tunes the smaller model to confidently handle tasks it can perform correctly while deferring complex tasks to the larger model.","Moreover, it incorporates a mechanism for managing the trade-off between model performance and deferral accuracy, and is broadly applicable across various tasks and domains without any architectural changes.","We evaluate our method on encoder-only, decoder-only, and encoder-decoder architectures.","Experiments across image classification, language modeling, and vision-language tasks show that our approach substantially improves deferral performance."],"url":"http://arxiv.org/abs/2502.19335v1"}
{"created":"2025-02-26 17:28:08","title":"Joint Optimal Transport and Embedding for Network Alignment","abstract":"Network alignment, which aims to find node correspondence across different networks, is the cornerstone of various downstream multi-network and Web mining tasks. Most of the embedding-based methods indirectly model cross-network node relationships by contrasting positive and negative node pairs sampled from hand-crafted strategies, which are vulnerable to graph noises and lead to potential misalignment of nodes. Another line of work based on the optimal transport (OT) theory directly models cross-network node relationships and generates noise-reduced alignments. However, OT methods heavily rely on fixed, pre-defined cost functions that prohibit end-to-end training and are hard to generalize. In this paper, we aim to unify the embedding and OT-based methods in a mutually beneficial manner and propose a joint optimal transport and embedding framework for network alignment named JOENA. For one thing (OT for embedding), through a simple yet effective transformation, the noise-reduced OT mapping serves as an adaptive sampling strategy directly modeling all cross-network node pairs for robust embedding learning.For another (embedding for OT), on top of the learned embeddings, the OT cost can be gradually trained in an end-to-end fashion, which further enhances the alignment quality. With a unified objective, the mutual benefits of both methods can be achieved by an alternating optimization schema with guaranteed convergence. Extensive experiments on real-world networks validate the effectiveness and scalability of JOENA, achieving up to 16% improvement in MRR and 20x speedup compared with the state-of-the-art alignment methods.","sentences":["Network alignment, which aims to find node correspondence across different networks, is the cornerstone of various downstream multi-network and Web mining tasks.","Most of the embedding-based methods indirectly model cross-network node relationships by contrasting positive and negative node pairs sampled from hand-crafted strategies, which are vulnerable to graph noises and lead to potential misalignment of nodes.","Another line of work based on the optimal transport (OT) theory directly models cross-network node relationships and generates noise-reduced alignments.","However, OT methods heavily rely on fixed, pre-defined cost functions that prohibit end-to-end training and are hard to generalize.","In this paper, we aim to unify the embedding and OT-based methods in a mutually beneficial manner and propose a joint optimal transport and embedding framework for network alignment named JOENA.","For one thing (OT for embedding), through a simple yet effective transformation, the noise-reduced OT mapping serves as an adaptive sampling strategy directly modeling all cross-network node pairs for robust embedding learning.","For another (embedding for OT), on top of the learned embeddings, the OT cost can be gradually trained in an end-to-end fashion, which further enhances the alignment quality.","With a unified objective, the mutual benefits of both methods can be achieved by an alternating optimization schema with guaranteed convergence.","Extensive experiments on real-world networks validate the effectiveness and scalability of JOENA, achieving up to 16% improvement in MRR and 20x speedup compared with the state-of-the-art alignment methods."],"url":"http://arxiv.org/abs/2502.19334v1"}
{"created":"2025-02-26 17:19:12","title":"Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems","abstract":"Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs). However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs. In this paper, we propose agentic reward modeling, a reward system that combines reward models with verifiable correctness signals from different aspects to provide reliable rewards. We empirically implement a reward agent, named RewardAgent, that combines human preference rewards with two verifiable signals: factuality and instruction following, to provide more reliable rewards. We conduct comprehensive experiments on existing reward model benchmarks and inference time best-of-n searches on real-world downstream tasks. RewardAgent significantly outperforms vanilla reward models, demonstrating its effectiveness. We further construct training preference pairs using RewardAgent and train an LLM with the DPO objective, achieving superior performance on various NLP benchmarks compared to conventional reward models. Our codes are publicly released to facilitate further research (https://github.com/THU-KEG/Agentic-Reward-Modeling).","sentences":["Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs).","However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs.","In this paper, we propose agentic reward modeling, a reward system that combines reward models with verifiable correctness signals from different aspects to provide reliable rewards.","We empirically implement a reward agent, named RewardAgent, that combines human preference rewards with two verifiable signals: factuality and instruction following, to provide more reliable rewards.","We conduct comprehensive experiments on existing reward model benchmarks and inference time best-of-n searches on real-world downstream tasks.","RewardAgent significantly outperforms vanilla reward models, demonstrating its effectiveness.","We further construct training preference pairs using RewardAgent and train an LLM with the DPO objective, achieving superior performance on various NLP benchmarks compared to conventional reward models.","Our codes are publicly released to facilitate further research (https://github.com/THU-KEG/Agentic-Reward-Modeling)."],"url":"http://arxiv.org/abs/2502.19328v1"}
{"created":"2025-02-26 17:16:33","title":"Partition Tree Weighting for Non-Stationary Stochastic Bandits","abstract":"This paper considers a generalisation of universal source coding for interaction data, namely data streams that have actions interleaved with observations. Our goal will be to construct a coding distribution that is both universal \\emph{and} can be used as a control policy. Allowing for action generation needs careful treatment, as naive approaches which do not distinguish between actions and observations run into the self-delusion problem in universal settings. We showcase our perspective in the context of the challenging non-stationary stochastic Bernoulli bandit problem. Our main contribution is an efficient and high performing algorithm for this problem that generalises the Partition Tree Weighting universal source coding technique for passive prediction to the control setting.","sentences":["This paper considers a generalisation of universal source coding for interaction data, namely data streams that have actions interleaved with observations.","Our goal will be to construct a coding distribution that is both universal \\emph{and} can be used as a control policy.","Allowing for action generation needs careful treatment, as naive approaches which do not distinguish between actions and observations run into the self-delusion problem in universal settings.","We showcase our perspective in the context of the challenging non-stationary stochastic Bernoulli bandit problem.","Our main contribution is an efficient and high performing algorithm for this problem that generalises the Partition Tree Weighting universal source coding technique for passive prediction to the control setting."],"url":"http://arxiv.org/abs/2502.19325v1"}
{"created":"2025-02-26 17:13:19","title":"Shh, don't say that! Domain Certification in LLMs","abstract":"Large language models (LLMs) are often deployed to perform constrained tasks, with narrow domains. For example, customer support bots can be built on top of LLMs, relying on their broad language understanding and capabilities to enhance performance. However, these LLMs are adversarially susceptible, potentially generating outputs outside the intended domain. To formalize, assess, and mitigate this risk, we introduce domain certification; a guarantee that accurately characterizes the out-of-domain behavior of language models. We then propose a simple yet effective approach, which we call VALID that provides adversarial bounds as a certificate. Finally, we evaluate our method across a diverse set of datasets, demonstrating that it yields meaningful certificates, which bound the probability of out-of-domain samples tightly with minimum penalty to refusal behavior.","sentences":["Large language models (LLMs) are often deployed to perform constrained tasks, with narrow domains.","For example, customer support bots can be built on top of LLMs, relying on their broad language understanding and capabilities to enhance performance.","However, these LLMs are adversarially susceptible, potentially generating outputs outside the intended domain.","To formalize, assess, and mitigate this risk, we introduce domain certification; a guarantee that accurately characterizes the out-of-domain behavior of language models.","We then propose a simple yet effective approach, which we call VALID that provides adversarial bounds as a certificate.","Finally, we evaluate our method across a diverse set of datasets, demonstrating that it yields meaningful certificates, which bound the probability of out-of-domain samples tightly with minimum penalty to refusal behavior."],"url":"http://arxiv.org/abs/2502.19320v1"}
{"created":"2025-02-26 17:11:26","title":"Does 3D Gaussian Splatting Need Accurate Volumetric Rendering?","abstract":"Since its introduction, 3D Gaussian Splatting (3DGS) has become an important reference method for learning 3D representations of a captured scene, allowing real-time novel-view synthesis with high visual quality and fast training times. Neural Radiance Fields (NeRFs), which preceded 3DGS, are based on a principled ray-marching approach for volumetric rendering. In contrast, while sharing a similar image formation model with NeRF, 3DGS uses a hybrid rendering solution that builds on the strengths of volume rendering and primitive rasterization. A crucial benefit of 3DGS is its performance, achieved through a set of approximations, in many cases with respect to volumetric rendering theory. A naturally arising question is whether replacing these approximations with more principled volumetric rendering solutions can improve the quality of 3DGS. In this paper, we present an in-depth analysis of the various approximations and assumptions used by the original 3DGS solution. We demonstrate that, while more accurate volumetric rendering can help for low numbers of primitives, the power of efficient optimization and the large number of Gaussians allows 3DGS to outperform volumetric rendering despite its approximations.","sentences":["Since its introduction, 3D Gaussian Splatting (3DGS) has become an important reference method for learning 3D representations of a captured scene, allowing real-time novel-view synthesis with high visual quality and fast training times.","Neural Radiance Fields (NeRFs), which preceded 3DGS, are based on a principled ray-marching approach for volumetric rendering.","In contrast, while sharing a similar image formation model with NeRF, 3DGS uses a hybrid rendering solution that builds on the strengths of volume rendering and primitive rasterization.","A crucial benefit of 3DGS is its performance, achieved through a set of approximations, in many cases with respect to volumetric rendering theory.","A naturally arising question is whether replacing these approximations with more principled volumetric rendering solutions can improve the quality of 3DGS.","In this paper, we present an in-depth analysis of the various approximations and assumptions used by the original 3DGS solution.","We demonstrate that, while more accurate volumetric rendering can help for low numbers of primitives, the power of efficient optimization and the large number of Gaussians allows 3DGS to outperform volumetric rendering despite its approximations."],"url":"http://arxiv.org/abs/2502.19318v1"}
{"created":"2025-02-26 17:11:21","title":"Multi-Platform Autobidding with and without Predictions","abstract":"We study the problem of finding the optimal bidding strategy for an advertiser in a multi-platform auction setting. The competition on a platform is captured by a value and a cost function, mapping bidding strategies to value and cost respectively. We assume a diminishing returns property, whereby the marginal cost is increasing in value. The advertiser uses an autobidder that selects a bidding strategy for each platform, aiming to maximize total value subject to budget and return-on-spend constraint. The advertiser has no prior information and learns about the value and cost functions by querying a platform with a specific bidding strategy. Our goal is to design algorithms that find the optimal bidding strategy with a small number of queries.   We first present an algorithm that requires \\(O(m \\log (mn) \\log n)\\) queries, where $m$ is the number of platforms and $n$ is the number of possible bidding strategies in each platform. Moreover, we adopt the learning-augmented framework and propose an algorithm that utilizes a (possibly erroneous) prediction of the optimal bidding strategy. We provide a $O(m \\log (m\\eta) \\log \\eta)$ query-complexity bound on our algorithm as a function of the prediction error $\\eta$. This guarantee gracefully degrades to \\(O(m \\log (mn) \\log n)\\). This achieves a ``best-of-both-worlds'' scenario: \\(O(m)\\) queries when given a correct prediction, and \\(O(m \\log (mn) \\log n)\\) even for an arbitrary incorrect prediction.","sentences":["We study the problem of finding the optimal bidding strategy for an advertiser in a multi-platform auction setting.","The competition on a platform is captured by a value and a cost function, mapping bidding strategies to value and cost respectively.","We assume a diminishing returns property, whereby the marginal cost is increasing in value.","The advertiser uses an autobidder that selects a bidding strategy for each platform, aiming to maximize total value subject to budget and return-on-spend constraint.","The advertiser has no prior information and learns about the value and cost functions by querying a platform with a specific bidding strategy.","Our goal is to design algorithms that find the optimal bidding strategy with a small number of queries.   ","We first present an algorithm that requires \\(O(m \\log (mn) \\log n)\\) queries, where $m$ is the number of platforms and $n$ is the number of possible bidding strategies in each platform.","Moreover, we adopt the learning-augmented framework and propose an algorithm that utilizes a (possibly erroneous) prediction of the optimal bidding strategy.","We provide a $O(m \\log (m\\eta) \\log \\eta)$ query-complexity bound on our algorithm as a function of the prediction error $\\eta$. This guarantee gracefully degrades to \\(O(m \\log (mn) \\log n)\\).","This achieves a ``best-of-both-worlds'' scenario: \\(O(m)\\) queries when given a correct prediction, and \\(O(m \\log (mn) \\log n)\\) even for an arbitrary incorrect prediction."],"url":"http://arxiv.org/abs/2502.19317v1"}
{"created":"2025-02-26 17:10:52","title":"Model Adaptation: Unsupervised Domain Adaptation without Source Data","abstract":"In this paper, we investigate a challenging unsupervised domain adaptation setting -- unsupervised model adaptation. We aim to explore how to rely only on unlabeled target data to improve performance of an existing source prediction model on the target domain, since labeled source data may not be available in some real-world scenarios due to data privacy issues. For this purpose, we propose a new framework, which is referred to as collaborative class conditional generative adversarial net to bypass the dependence on the source data. Specifically, the prediction model is to be improved through generated target-style data, which provides more accurate guidance for the generator. As a result, the generator and the prediction model can collaborate with each other without source data. Furthermore, due to the lack of supervision from source data, we propose a weight constraint that encourages similarity to the source model. A clustering-based regularization is also introduced to produce more discriminative features in the target domain. Compared to conventional domain adaptation methods, our model achieves superior performance on multiple adaptation tasks with only unlabeled target data, which verifies its effectiveness in this challenging setting.","sentences":["In this paper, we investigate a challenging unsupervised domain adaptation setting -- unsupervised model adaptation.","We aim to explore how to rely only on unlabeled target data to improve performance of an existing source prediction model on the target domain, since labeled source data may not be available in some real-world scenarios due to data privacy issues.","For this purpose, we propose a new framework, which is referred to as collaborative class conditional generative adversarial net to bypass the dependence on the source data.","Specifically, the prediction model is to be improved through generated target-style data, which provides more accurate guidance for the generator.","As a result, the generator and the prediction model can collaborate with each other without source data.","Furthermore, due to the lack of supervision from source data, we propose a weight constraint that encourages similarity to the source model.","A clustering-based regularization is also introduced to produce more discriminative features in the target domain.","Compared to conventional domain adaptation methods, our model achieves superior performance on multiple adaptation tasks with only unlabeled target data, which verifies its effectiveness in this challenging setting."],"url":"http://arxiv.org/abs/2502.19316v1"}
{"created":"2025-02-26 17:09:51","title":"CoopDETR: A Unified Cooperative Perception Framework for 3D Detection via Object Query","abstract":"Cooperative perception enhances the individual perception capabilities of autonomous vehicles (AVs) by providing a comprehensive view of the environment. However, balancing perception performance and transmission costs remains a significant challenge. Current approaches that transmit region-level features across agents are limited in interpretability and demand substantial bandwidth, making them unsuitable for practical applications. In this work, we propose CoopDETR, a novel cooperative perception framework that introduces object-level feature cooperation via object query. Our framework consists of two key modules: single-agent query generation, which efficiently encodes raw sensor data into object queries, reducing transmission cost while preserving essential information for detection; and cross-agent query fusion, which includes Spatial Query Matching (SQM) and Object Query Aggregation (OQA) to enable effective interaction between queries. Our experiments on the OPV2V and V2XSet datasets demonstrate that CoopDETR achieves state-of-the-art performance and significantly reduces transmission costs to 1/782 of previous methods.","sentences":["Cooperative perception enhances the individual perception capabilities of autonomous vehicles (AVs) by providing a comprehensive view of the environment.","However, balancing perception performance and transmission costs remains a significant challenge.","Current approaches that transmit region-level features across agents are limited in interpretability and demand substantial bandwidth, making them unsuitable for practical applications.","In this work, we propose CoopDETR, a novel cooperative perception framework that introduces object-level feature cooperation via object query.","Our framework consists of two key modules: single-agent query generation, which efficiently encodes raw sensor data into object queries, reducing transmission cost while preserving essential information for detection; and cross-agent query fusion, which includes Spatial Query Matching (SQM) and Object Query Aggregation (OQA) to enable effective interaction between queries.","Our experiments on the OPV2V and V2XSet datasets demonstrate that CoopDETR achieves state-of-the-art performance and significantly reduces transmission costs to 1/782 of previous methods."],"url":"http://arxiv.org/abs/2502.19313v1"}
{"created":"2025-02-26 17:08:46","title":"FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users","abstract":"Effective personalization of LLMs is critical for a broad range of user-interfacing applications such as virtual assistants and content curation. Inspired by the strong in-context learning capabilities of LLMs, we propose Few-Shot Preference Optimization (FSPO), which reframes reward modeling as a meta-learning problem. Under this framework, an LLM learns to quickly adapt to a user via a few labeled preferences from that user, constructing a personalized reward function for them. Additionally, since real-world preference data is scarce and challenging to collect at scale, we propose careful design choices to construct synthetic preference datasets for personalization, generating over 1M synthetic personalized preferences using publicly available LLMs. In particular, to successfully transfer from synthetic data to real users, we find it crucial for the data to exhibit both high diversity and coherent, self-consistent structure. We evaluate FSPO on personalized open-ended generation for up to 1,500 synthetic users across across three domains: movie reviews, pedagogical adaptation based on educational background, and general question answering, along with a controlled human study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in generating responses that are personalized to synthetic users and a 72% winrate with real human users in open-ended question answering.","sentences":["Effective personalization of LLMs is critical for a broad range of user-interfacing applications such as virtual assistants and content curation.","Inspired by the strong in-context learning capabilities of LLMs, we propose Few-Shot Preference Optimization (FSPO), which reframes reward modeling as a meta-learning problem.","Under this framework, an LLM learns to quickly adapt to a user via a few labeled preferences from that user, constructing a personalized reward function for them.","Additionally, since real-world preference data is scarce and challenging to collect at scale, we propose careful design choices to construct synthetic preference datasets for personalization, generating over 1M synthetic personalized preferences using publicly available LLMs.","In particular, to successfully transfer from synthetic data to real users, we find it crucial for the data to exhibit both high diversity and coherent, self-consistent structure.","We evaluate FSPO on personalized open-ended generation for up to 1,500 synthetic users across across three domains: movie reviews, pedagogical adaptation based on educational background, and general question answering, along with a controlled human study.","Overall, FSPO achieves an 87% Alpaca Eval winrate on average in generating responses that are personalized to synthetic users and a 72% winrate with real human users in open-ended question answering."],"url":"http://arxiv.org/abs/2502.19312v1"}
{"created":"2025-02-26 17:08:07","title":"Faithful Logic Embeddings in HOL -- A recipe to have it all: deep and shallow, automated and interactive, heavy and light, proofs and counterexamples, meta and object level","abstract":"Deep and shallow embeddings of non-classical logics in classical higher-order logic have been explored, implemented, and used in various automated reasoning tools in recent years. This paper presents a recipe for the simultaneous deployment of different forms of deep and shallow embeddings in classical higher-order logic, enabling not only flexible interactive and automated theorem proving and counterexample finding at meta and object level, but also automated faithfulness proofs between the logic embeddings. The approach, which is fruitful for logic education, research and application, is deliberately illustrated here using simple propositional modal logic. However, the work presented is conceptual in nature and not limited to such a simple logic context.","sentences":["Deep and shallow embeddings of non-classical logics in classical higher-order logic have been explored, implemented, and used in various automated reasoning tools in recent years.","This paper presents a recipe for the simultaneous deployment of different forms of deep and shallow embeddings in classical higher-order logic, enabling not only flexible interactive and automated theorem proving and counterexample finding at meta and object level, but also automated faithfulness proofs between the logic embeddings.","The approach, which is fruitful for logic education, research and application, is deliberately illustrated here using simple propositional modal logic.","However, the work presented is conceptual in nature and not limited to such a simple logic context."],"url":"http://arxiv.org/abs/2502.19311v1"}
{"created":"2025-02-26 17:07:11","title":"WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies","abstract":"We introduce WOFOSTGym, a novel crop simulation environment designed to train reinforcement learning (RL) agents to optimize agromanagement decisions for annual and perennial crops in single and multi-farm settings. Effective crop management requires optimizing yield and economic returns while minimizing environmental impact, a complex sequential decision-making problem well suited for RL. However, the lack of simulators for perennial crops in multi-farm contexts has hindered RL applications in this domain. Existing crop simulators also do not support multiple annual crops. WOFOSTGym addresses these gaps by supporting 23 annual crops and two perennial crops, enabling RL agents to learn diverse agromanagement strategies in multi-year, multi-crop, and multi-farm settings. Our simulator offers a suite of challenging tasks for learning under partial observability, non-Markovian dynamics, and delayed feedback. WOFOSTGym's standard RL interface allows researchers without agricultural expertise to explore a wide range of agromanagement problems. Our experiments demonstrate the learned behaviors across various crop varieties and soil types, highlighting WOFOSTGym's potential for advancing RL-driven decision support in agriculture.","sentences":["We introduce WOFOSTGym, a novel crop simulation environment designed to train reinforcement learning (RL) agents to optimize agromanagement decisions for annual and perennial crops in single and multi-farm settings.","Effective crop management requires optimizing yield and economic returns while minimizing environmental impact, a complex sequential decision-making problem well suited for RL.","However, the lack of simulators for perennial crops in multi-farm contexts has hindered RL applications in this domain.","Existing crop simulators also do not support multiple annual crops.","WOFOSTGym addresses these gaps by supporting 23 annual crops and two perennial crops, enabling RL agents to learn diverse agromanagement strategies in multi-year, multi-crop, and multi-farm settings.","Our simulator offers a suite of challenging tasks for learning under partial observability, non-Markovian dynamics, and delayed feedback.","WOFOSTGym's standard RL interface allows researchers without agricultural expertise to explore a wide range of agromanagement problems.","Our experiments demonstrate the learned behaviors across various crop varieties and soil types, highlighting WOFOSTGym's potential for advancing RL-driven decision support in agriculture."],"url":"http://arxiv.org/abs/2502.19308v1"}
{"created":"2025-02-26 17:06:13","title":"Anomaly Detection in Complex Dynamical Systems: A Systematic Framework Using Embedding Theory and Physics-Inspired Consistency","abstract":"Anomaly detection in complex dynamical systems is essential for ensuring reliability, safety, and efficiency in industrial and cyber-physical infrastructures. Predictive maintenance helps prevent costly failures, while cybersecurity monitoring has become critical as digitized systems face growing threats. Many of these systems exhibit oscillatory behaviors and bounded motion, requiring anomaly detection methods that capture structured temporal dependencies while adhering to physical consistency principles. In this work, we propose a system-theoretic approach to anomaly detection, grounded in classical embedding theory and physics-inspired consistency principles. We build upon the Fractal Whitney Embedding Prevalence Theorem, extending traditional embedding techniques to complex system dynamics. Additionally, we introduce state-derivative pairs as an embedding strategy to capture system evolution. To enforce temporal coherence, we develop a Temporal Differential Consistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the approximated derivatives of latent variables with their dynamic representations. We evaluate our method on the C-MAPSS dataset, a benchmark for turbofan aeroengine degradation. TDC-AE outperforms LSTMs and Transformers while achieving a 200x reduction in MAC operations, making it particularly suited for lightweight edge computing. Our findings support the hypothesis that anomalies disrupt stable system dynamics, providing a robust, interpretable signal for anomaly detection.","sentences":["Anomaly detection in complex dynamical systems is essential for ensuring reliability, safety, and efficiency in industrial and cyber-physical infrastructures.","Predictive maintenance helps prevent costly failures, while cybersecurity monitoring has become critical as digitized systems face growing threats.","Many of these systems exhibit oscillatory behaviors and bounded motion, requiring anomaly detection methods that capture structured temporal dependencies while adhering to physical consistency principles.","In this work, we propose a system-theoretic approach to anomaly detection, grounded in classical embedding theory and physics-inspired consistency principles.","We build upon the Fractal Whitney Embedding Prevalence Theorem, extending traditional embedding techniques to complex system dynamics.","Additionally, we introduce state-derivative pairs as an embedding strategy to capture system evolution.","To enforce temporal coherence, we develop a Temporal Differential Consistency Autoencoder (TDC-AE), incorporating a TDC-Loss that aligns the approximated derivatives of latent variables with their dynamic representations.","We evaluate our method on the C-MAPSS dataset, a benchmark for turbofan aeroengine degradation.","TDC-AE outperforms LSTMs and Transformers while achieving a 200x reduction in MAC operations, making it particularly suited for lightweight edge computing.","Our findings support the hypothesis that anomalies disrupt stable system dynamics, providing a robust, interpretable signal for anomaly detection."],"url":"http://arxiv.org/abs/2502.19307v1"}
{"created":"2025-02-26 17:06:08","title":"Generalization Problems with Atom-Variables in Languages with Binders and Equational Theories","abstract":"Generalization problems in languages with binders involve computing the most common structure between expressions while respecting bound variable renaming and freshness constraints. These problems often lack a least general solution. However, leveraging nominal techniques, we previously demonstrated that a semantic approach with atom-variables enables the elimination of redundant solutions and allows for computing unique least general generalizations (LGGs). In this work, we extend this approach to handle associative (A), commutative (C), and associative-commutative (AC) equational theories. We present a sound and weak complete algorithm for solving equational generalization problems, which generates finite weak minimal complete sets of LGGs for each theory. A key challenge arises from solving equivariance problems while taking into account these equational theories, as identifying redundant generalizations requires recognizing when one expression (with binders) is a renaming of another while possibly considering permutations of sub-expressions. This unexpected interaction between renaming and equational reasoning made this particularly difficult, necessitating semantic tests within the equivariance algorithm. Given that these equational theories naturally induce exponentially large LGG sets due to subexpression permutations, future work could explore restricted theory fragments where the generalization problem remains unitary. In these fragments, LGGs can be computed efficiently in polynomial time, offering practical benefits for symbolic computation and automated reasoning tasks.","sentences":["Generalization problems in languages with binders involve computing the most common structure between expressions while respecting bound variable renaming and freshness constraints.","These problems often lack a least general solution.","However, leveraging nominal techniques, we previously demonstrated that a semantic approach with atom-variables enables the elimination of redundant solutions and allows for computing unique least general generalizations (LGGs).","In this work, we extend this approach to handle associative (A), commutative (C), and associative-commutative (AC) equational theories.","We present a sound and weak complete algorithm for solving equational generalization problems, which generates finite weak minimal complete sets of LGGs for each theory.","A key challenge arises from solving equivariance problems while taking into account these equational theories, as identifying redundant generalizations requires recognizing when one expression (with binders) is a renaming of another while possibly considering permutations of sub-expressions.","This unexpected interaction between renaming and equational reasoning made this particularly difficult, necessitating semantic tests within the equivariance algorithm.","Given that these equational theories naturally induce exponentially large LGG sets due to subexpression permutations, future work could explore restricted theory fragments where the generalization problem remains unitary.","In these fragments, LGGs can be computed efficiently in polynomial time, offering practical benefits for symbolic computation and automated reasoning tasks."],"url":"http://arxiv.org/abs/2502.19306v1"}
{"created":"2025-02-26 17:05:54","title":"Corporate Fraud Detection in Rich-yet-Noisy Financial Graph","abstract":"Corporate fraud detection aims to automatically recognize companies that conduct wrongful activities such as fraudulent financial statements or illegal insider trading. Previous learning-based methods fail to effectively integrate rich interactions in the company network. To close this gap, we collect 18-year financial records in China to form three graph datasets with fraud labels. We analyze the characteristics of the financial graphs, highlighting two pronounced issues: (1) information overload: the dominance of (noisy) non-company nodes over company nodes hinders the message-passing process in Graph Convolution Networks (GCN); and (2) hidden fraud: there exists a large percentage of possible undetected violations in the collected data. The hidden fraud problem will introduce noisy labels in the training dataset and compromise fraud detection results. To handle such challenges, we propose a novel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage Learning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to mitigate the information overload and effectively learns rich representations. The proposed model adopts a two-stage learning method to enhance robustness against hidden frauds. Extensive experimental results not only confirm the importance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$ over a number of strong baselines in terms of fraud detection effectiveness and robustness.","sentences":["Corporate fraud detection aims to automatically recognize companies that conduct wrongful activities such as fraudulent financial statements or illegal insider trading.","Previous learning-based methods fail to effectively integrate rich interactions in the company network.","To close this gap, we collect 18-year financial records in China to form three graph datasets with fraud labels.","We analyze the characteristics of the financial graphs, highlighting two pronounced issues: (1) information overload: the dominance of (noisy) non-company nodes over company nodes hinders the message-passing process in Graph Convolution Networks (GCN); and (2) hidden fraud: there exists a large percentage of possible undetected violations in the collected data.","The hidden fraud problem will introduce noisy labels in the training dataset and compromise fraud detection results.","To handle such challenges, we propose a novel graph-based method, namely, Knowledge-enhanced GCN with Robust Two-stage Learning (${\\rm KeGCN}_{R}$), which leverages Knowledge Graph Embeddings to mitigate the information overload and effectively learns rich representations.","The proposed model adopts a two-stage learning method to enhance robustness against hidden frauds.","Extensive experimental results not only confirm the importance of interactions but also show the superiority of ${\\rm KeGCN}_{R}$ over a number of strong baselines in terms of fraud detection effectiveness and robustness."],"url":"http://arxiv.org/abs/2502.19305v1"}
{"created":"2025-02-26 16:59:21","title":"Rethinking LLM Unlearning Objectives: A Gradient Perspective and Go Beyond","abstract":"Large language models (LLMs) should undergo rigorous audits to identify potential risks, such as copyright and privacy infringements. Once these risks emerge, timely updates are crucial to remove undesirable responses, ensuring legal and safe model usage. It has spurred recent research into LLM unlearning, focusing on erasing targeted undesirable knowledge without compromising the integrity of other, non-targeted responses. Existing studies have introduced various unlearning objectives to pursue LLM unlearning without necessitating complete retraining. However, each of these objectives has unique properties, and no unified framework is currently available to comprehend them thoroughly. To fill the gap, we propose a toolkit of the gradient effect (G-effect), quantifying the impacts of unlearning objectives on model performance from a gradient perspective. A notable advantage is its broad ability to detail the unlearning impacts from various aspects across instances, updating steps, and LLM layers. Accordingly, the G-effect offers new insights into identifying drawbacks of existing unlearning objectives, further motivating us to explore a series of new solutions for their mitigation and improvements. Finally, we outline promising directions that merit further studies, aiming at contributing to the community to advance this important field.","sentences":["Large language models (LLMs) should undergo rigorous audits to identify potential risks, such as copyright and privacy infringements.","Once these risks emerge, timely updates are crucial to remove undesirable responses, ensuring legal and safe model usage.","It has spurred recent research into LLM unlearning, focusing on erasing targeted undesirable knowledge without compromising the integrity of other, non-targeted responses.","Existing studies have introduced various unlearning objectives to pursue LLM unlearning without necessitating complete retraining.","However, each of these objectives has unique properties, and no unified framework is currently available to comprehend them thoroughly.","To fill the gap, we propose a toolkit of the gradient effect (G-effect), quantifying the impacts of unlearning objectives on model performance from a gradient perspective.","A notable advantage is its broad ability to detail the unlearning impacts from various aspects across instances, updating steps, and LLM layers.","Accordingly, the G-effect offers new insights into identifying drawbacks of existing unlearning objectives, further motivating us to explore a series of new solutions for their mitigation and improvements.","Finally, we outline promising directions that merit further studies, aiming at contributing to the community to advance this important field."],"url":"http://arxiv.org/abs/2502.19301v1"}
{"created":"2025-02-26 16:56:19","title":"Agent-centric Information Access","abstract":"As large language models (LLMs) become more specialized, we envision a future where millions of expert LLMs exist, each trained on proprietary data and excelling in specific domains. In such a system, answering a query requires selecting a small subset of relevant models, querying them efficiently, and synthesizing their responses. This paper introduces a framework for agent-centric information access, where LLMs function as knowledge agents that are dynamically ranked and queried based on their demonstrated expertise. Unlike traditional document retrieval, this approach requires inferring expertise on the fly, rather than relying on static metadata or predefined model descriptions. This shift introduces several challenges, including efficient expert selection, cost-effective querying, response aggregation across multiple models, and robustness against adversarial manipulation. To address these issues, we propose a scalable evaluation framework that leverages retrieval-augmented generation and clustering techniques to construct and assess thousands of specialized models, with the potential to scale toward millions.","sentences":["As large language models (LLMs) become more specialized, we envision a future where millions of expert LLMs exist, each trained on proprietary data and excelling in specific domains.","In such a system, answering a query requires selecting a small subset of relevant models, querying them efficiently, and synthesizing their responses.","This paper introduces a framework for agent-centric information access, where LLMs function as knowledge agents that are dynamically ranked and queried based on their demonstrated expertise.","Unlike traditional document retrieval, this approach requires inferring expertise on the fly, rather than relying on static metadata or predefined model descriptions.","This shift introduces several challenges, including efficient expert selection, cost-effective querying, response aggregation across multiple models, and robustness against adversarial manipulation.","To address these issues, we propose a scalable evaluation framework that leverages retrieval-augmented generation and clustering techniques to construct and assess thousands of specialized models, with the potential to scale toward millions."],"url":"http://arxiv.org/abs/2502.19298v1"}
{"created":"2025-02-26 16:55:23","title":"Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains","abstract":"Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments. This results in notable sample inefficiency and hinders generalization across diverse tasks. The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by existing MARL algorithms. To overcome these hurdles, we propose integrating relational planners as centralized controllers with efficient state abstractions and reinforcement learning. This approach proves to be sample-efficient and facilitates effective task transfer and generalization.","sentences":["Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments.","This results in notable sample inefficiency and hinders generalization across diverse tasks.","The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by existing MARL algorithms.","To overcome these hurdles, we propose integrating relational planners as centralized controllers with efficient state abstractions and reinforcement learning.","This approach proves to be sample-efficient and facilitates effective task transfer and generalization."],"url":"http://arxiv.org/abs/2502.19297v1"}
{"created":"2025-02-26 16:52:31","title":"Complex LLM Planning via Automated Heuristics Discovery","abstract":"We consider enhancing large language models (LLMs) for complex planning tasks. While existing methods allow LLMs to explore intermediate steps to make plans, they either depend on unreliable self-verification or external verifiers to evaluate these steps, which demand significant data and computations. Here, we propose automated heuristics discovery (AutoHD), a novel approach that enables LLMs to explicitly generate heuristic functions to guide inference-time search, allowing accurate evaluation of intermediate states. These heuristic functions are further refined through a heuristic evolution process, improving their robustness and effectiveness. Our proposed method requires no additional model training or fine-tuning, and the explicit definition of heuristic functions generated by the LLMs provides interpretability and insights into the reasoning process. Extensive experiments across diverse benchmarks demonstrate significant gains over multiple baselines, including nearly twice the accuracy on some datasets, establishing our approach as a reliable and interpretable solution for complex planning tasks.","sentences":["We consider enhancing large language models (LLMs) for complex planning tasks.","While existing methods allow LLMs to explore intermediate steps to make plans, they either depend on unreliable self-verification or external verifiers to evaluate these steps, which demand significant data and computations.","Here, we propose automated heuristics discovery (AutoHD), a novel approach that enables LLMs to explicitly generate heuristic functions to guide inference-time search, allowing accurate evaluation of intermediate states.","These heuristic functions are further refined through a heuristic evolution process, improving their robustness and effectiveness.","Our proposed method requires no additional model training or fine-tuning, and the explicit definition of heuristic functions generated by the LLMs provides interpretability and insights into the reasoning process.","Extensive experiments across diverse benchmarks demonstrate significant gains over multiple baselines, including nearly twice the accuracy on some datasets, establishing our approach as a reliable and interpretable solution for complex planning tasks."],"url":"http://arxiv.org/abs/2502.19295v1"}
{"created":"2025-02-26 16:52:10","title":"Pathology Report Generation and Multimodal Representation Learning for Cutaneous Melanocytic Lesions","abstract":"Millions of melanocytic skin lesions are examined by pathologists each year, the majority of which concern common nevi (i.e., ordinary moles). While most of these lesions can be diagnosed in seconds, writing the corresponding pathology report is much more time-consuming. Automating part of the report writing could, therefore, alleviate the increasing workload of pathologists. In this work, we develop a vision-language model specifically for the pathology domain of cutaneous melanocytic lesions. The model follows the Contrastive Captioner framework and was trained and evaluated using a melanocytic lesion dataset of 42,512 H&E-stained whole slide images and 19,645 corresponding pathology reports. Our results show that the quality scores of model-generated reports were on par with pathologist-written reports for common nevi, assessed by an expert pathologist in a reader study. While report generation revealed to be more difficult for rare melanocytic lesion subtypes, the cross-modal retrieval performance for these cases was considerably better.","sentences":["Millions of melanocytic skin lesions are examined by pathologists each year, the majority of which concern common nevi (i.e., ordinary moles).","While most of these lesions can be diagnosed in seconds, writing the corresponding pathology report is much more time-consuming.","Automating part of the report writing could, therefore, alleviate the increasing workload of pathologists.","In this work, we develop a vision-language model specifically for the pathology domain of cutaneous melanocytic lesions.","The model follows the Contrastive Captioner framework and was trained and evaluated using a melanocytic lesion dataset of 42,512 H&E-stained whole slide images and 19,645 corresponding pathology reports.","Our results show that the quality scores of model-generated reports were on par with pathologist-written reports for common nevi, assessed by an expert pathologist in a reader study.","While report generation revealed to be more difficult for rare melanocytic lesion subtypes, the cross-modal retrieval performance for these cases was considerably better."],"url":"http://arxiv.org/abs/2502.19293v1"}
{"created":"2025-02-26 16:50:08","title":"Global Graph Propagation with Hierarchical Information Transfer for Incomplete Contrastive Multi-view Clustering","abstract":"Incomplete multi-view clustering has become one of the important research problems due to the extensive missing multi-view data in the real world. Although the existing methods have made great progress, there are still some problems: 1) most methods cannot effectively mine the information hidden in the missing data; 2) most methods typically divide representation learning and clustering into two separate stages, but this may affect the clustering performance as the clustering results directly depend on the learned representation. To address these problems, we propose a novel incomplete multi-view clustering method with hierarchical information transfer. Firstly, we design the view-specific Graph Convolutional Networks (GCN) to obtain the representation encoding the graph structure, which is then fused into the consensus representation. Secondly, considering that one layer of GCN transfers one-order neighbor node information, the global graph propagation with the consensus representation is proposed to handle the missing data and learn deep representation. Finally, we design a weight-sharing pseudo-classifier with contrastive learning to obtain an end-to-end framework that combines view-specific representation learning, global graph propagation with hierarchical information transfer, and contrastive clustering for joint optimization. Extensive experiments conducted on several commonly-used datasets demonstrate the effectiveness and superiority of our method in comparison with other state-of-the-art approaches. The code is available at https://github.com/KelvinXuu/GHICMC.","sentences":["Incomplete multi-view clustering has become one of the important research problems due to the extensive missing multi-view data in the real world.","Although the existing methods have made great progress, there are still some problems: 1) most methods cannot effectively mine the information hidden in the missing data; 2) most methods typically divide representation learning and clustering into two separate stages, but this may affect the clustering performance as the clustering results directly depend on the learned representation.","To address these problems, we propose a novel incomplete multi-view clustering method with hierarchical information transfer.","Firstly, we design the view-specific Graph Convolutional Networks (GCN) to obtain the representation encoding the graph structure, which is then fused into the consensus representation.","Secondly, considering that one layer of GCN transfers one-order neighbor node information, the global graph propagation with the consensus representation is proposed to handle the missing data and learn deep representation.","Finally, we design a weight-sharing pseudo-classifier with contrastive learning to obtain an end-to-end framework that combines view-specific representation learning, global graph propagation with hierarchical information transfer, and contrastive clustering for joint optimization.","Extensive experiments conducted on several commonly-used datasets demonstrate the effectiveness and superiority of our method in comparison with other state-of-the-art approaches.","The code is available at https://github.com/KelvinXuu/GHICMC."],"url":"http://arxiv.org/abs/2502.19291v1"}
{"created":"2025-02-26 16:48:25","title":"Equational Reasoning Modulo Commutativity in Languages with Binders (Extended Version)","abstract":"Many formal languages include binders as well as operators that satisfy equational axioms, such as commutativity. Here we consider the nominal language, a general formal framework which provides support for the representation of binders, freshness conditions and $\\alpha$-renaming. Rather than relying on the usual freshness constraints, we introduce a nominal algebra which employs permutation fixed-point constraints in $\\alpha$-equivalence judgements, seamlessly integrating commutativity into the reasoning process. We establish its proof-theoretical properties and provide a sound and complete semantics in the setting of nominal sets. Additionally, we propose a novel algorithm for nominal unification modulo commutativity, which we prove terminating and correct. By leveraging fixed-point constraints, our approach ensures a finitary unification theory, unlike standard methods relying on freshness constraints. This framework offers a robust foundation for structural induction and recursion over syntax with binders and commutative operators, enabling reasoning in settings such as first-order logic and the $\\pi$-calculus.","sentences":["Many formal languages include binders as well as operators that satisfy equational axioms, such as commutativity.","Here we consider the nominal language, a general formal framework which provides support for the representation of binders, freshness conditions and $\\alpha$-renaming.","Rather than relying on the usual freshness constraints, we introduce a nominal algebra which employs permutation fixed-point constraints in $\\alpha$-equivalence judgements, seamlessly integrating commutativity into the reasoning process.","We establish its proof-theoretical properties and provide a sound and complete semantics in the setting of nominal sets.","Additionally, we propose a novel algorithm for nominal unification modulo commutativity, which we prove terminating and correct.","By leveraging fixed-point constraints, our approach ensures a finitary unification theory, unlike standard methods relying on freshness constraints.","This framework offers a robust foundation for structural induction and recursion over syntax with binders and commutative operators, enabling reasoning in settings such as first-order logic and the $\\pi$-calculus."],"url":"http://arxiv.org/abs/2502.19287v1"}
{"created":"2025-02-26 16:45:09","title":"On the Importance of Text Preprocessing for Multimodal Representation Learning and Pathology Report Generation","abstract":"Vision-language models in pathology enable multimodal case retrieval and automated report generation. Many of the models developed so far, however, have been trained on pathology reports that include information which cannot be inferred from paired whole slide images (e.g., patient history), potentially leading to hallucinated sentences in generated reports. To this end, we investigate how the selection of information from pathology reports for vision-language modeling affects the quality of the multimodal representations and generated reports. More concretely, we compare a model trained on full reports against a model trained on preprocessed reports that only include sentences describing the cell and tissue appearances based on the H&E-stained slides. For the experiments, we built upon the BLIP-2 framework and used a cutaneous melanocytic lesion dataset of 42,433 H&E-stained whole slide images and 19,636 corresponding pathology reports. Model performance was assessed using image-to-text and text-to-image retrieval, as well as qualitative evaluation of the generated reports by an expert pathologist. Our results demonstrate that text preprocessing prevents hallucination in report generation. Despite the improvement in the quality of the generated reports, training the vision-language model on full reports showed better cross-modal retrieval performance.","sentences":["Vision-language models in pathology enable multimodal case retrieval and automated report generation.","Many of the models developed so far, however, have been trained on pathology reports that include information which cannot be inferred from paired whole slide images (e.g., patient history), potentially leading to hallucinated sentences in generated reports.","To this end, we investigate how the selection of information from pathology reports for vision-language modeling affects the quality of the multimodal representations and generated reports.","More concretely, we compare a model trained on full reports against a model trained on preprocessed reports that only include sentences describing the cell and tissue appearances based on the H&E-stained slides.","For the experiments, we built upon the BLIP-2 framework and used a cutaneous melanocytic lesion dataset of 42,433 H&E-stained whole slide images and 19,636 corresponding pathology reports.","Model performance was assessed using image-to-text and text-to-image retrieval, as well as qualitative evaluation of the generated reports by an expert pathologist.","Our results demonstrate that text preprocessing prevents hallucination in report generation.","Despite the improvement in the quality of the generated reports, training the vision-language model on full reports showed better cross-modal retrieval performance."],"url":"http://arxiv.org/abs/2502.19285v1"}
{"created":"2025-02-26 16:44:25","title":"Algorithms for Parallel Shared-Memory Sparse Matrix-Vector Multiplication on Unstructured Matrices","abstract":"The sparse matrix-vector (SpMV) multiplication is an important computational kernel, but it is notoriously difficult to execute efficiently. This paper investigates algorithm performance for unstructured sparse matrices, which are more common than ever because of the trend towards large-scale data collection. The development of an SpMV multiplication algorithm for this type of data is hard due to two factors. First, parallel load balancing issues arise because of the unpredictable nonzero structure. Secondly, SpMV multiplication algorithms are inevitably memory-bound because the sparsity causes a low arithmetic intensity. Three state-of-the-art algorithms for parallel SpMV multiplication on shared-memory systems are discussed. Six new hybrid algorithms are developed which combine optimization techniques of the current algorithms. These techniques include parallelization strategies, storage formats, and nonzero orderings. A modern and high-performance implementation of all discussed algorithms is provided as open-source software. Using this implementation the algorithms are compared. Furthermore, SpMV multiplication algorithms require the matrix to be stored in a specific storage format. Therefore, the conversion time between these storage formats is also analyzed. Both tests are performed for multiple unstructured sparse matrices on different machines: two multi-CPU and two single-CPU architectures. We show that one of the newly developed algorithms outperforms the current state-of-the-art by 19% on one of the multi-CPU architectures. When taking conversion time into consideration, we show that 472 SpMV multiplications are needed to cover the cost of converting to a new storage format for one of the hybrid algorithms on a multi-CPU machine.","sentences":["The sparse matrix-vector (SpMV) multiplication is an important computational kernel, but it is notoriously difficult to execute efficiently.","This paper investigates algorithm performance for unstructured sparse matrices, which are more common than ever because of the trend towards large-scale data collection.","The development of an SpMV multiplication algorithm for this type of data is hard due to two factors.","First, parallel load balancing issues arise because of the unpredictable nonzero structure.","Secondly, SpMV multiplication algorithms are inevitably memory-bound because the sparsity causes a low arithmetic intensity.","Three state-of-the-art algorithms for parallel SpMV multiplication on shared-memory systems are discussed.","Six new hybrid algorithms are developed which combine optimization techniques of the current algorithms.","These techniques include parallelization strategies, storage formats, and nonzero orderings.","A modern and high-performance implementation of all discussed algorithms is provided as open-source software.","Using this implementation the algorithms are compared.","Furthermore, SpMV multiplication algorithms require the matrix to be stored in a specific storage format.","Therefore, the conversion time between these storage formats is also analyzed.","Both tests are performed for multiple unstructured sparse matrices on different machines: two multi-CPU and two single-CPU architectures.","We show that one of the newly developed algorithms outperforms the current state-of-the-art by 19% on one of the multi-CPU architectures.","When taking conversion time into consideration, we show that 472 SpMV multiplications are needed to cover the cost of converting to a new storage format for one of the hybrid algorithms on a multi-CPU machine."],"url":"http://arxiv.org/abs/2502.19284v1"}
{"created":"2025-02-26 16:36:24","title":"Efficient Federated Search for Retrieval-Augmented Generation","abstract":"Large language models (LLMs) have demonstrated remarkable capabilities across various domains but remain susceptible to hallucinations and inconsistencies, limiting their reliability. Retrieval-augmented generation (RAG) mitigates these issues by grounding model responses in external knowledge sources. Existing RAG workflows often leverage a single vector database, which is impractical in the common setting where information is distributed across multiple repositories. We introduce RAGRoute, a novel mechanism for federated RAG search. RAGRoute dynamically selects relevant data sources at query time using a lightweight neural network classifier. By not querying every data source, this approach significantly reduces query overhead, improves retrieval efficiency, and minimizes the retrieval of irrelevant information. We evaluate RAGRoute using the MIRAGE and MMLU benchmarks and demonstrate its effectiveness in retrieving relevant documents while reducing the number of queries. RAGRoute reduces the total number of queries up to 77.5% and communication volume up to 76.2%.","sentences":["Large language models (LLMs) have demonstrated remarkable capabilities across various domains but remain susceptible to hallucinations and inconsistencies, limiting their reliability.","Retrieval-augmented generation (RAG) mitigates these issues by grounding model responses in external knowledge sources.","Existing RAG workflows often leverage a single vector database, which is impractical in the common setting where information is distributed across multiple repositories.","We introduce RAGRoute, a novel mechanism for federated RAG search.","RAGRoute dynamically selects relevant data sources at query time using a lightweight neural network classifier.","By not querying every data source, this approach significantly reduces query overhead, improves retrieval efficiency, and minimizes the retrieval of irrelevant information.","We evaluate RAGRoute using the MIRAGE and MMLU benchmarks and demonstrate its effectiveness in retrieving relevant documents while reducing the number of queries.","RAGRoute reduces the total number of queries up to 77.5% and communication volume up to 76.2%."],"url":"http://arxiv.org/abs/2502.19280v1"}
{"created":"2025-02-26 16:33:41","title":"CritiQ: Mining Data Quality Criteria from Human Preferences","abstract":"Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while introduce biases. We introduce CritiQ, a novel data selection method that automatically mines criteria from human preferences for data quality with only $\\sim$30 human-annotated pairs and performs efficient data selection. The main component, CritiQ Flow, employs a manager agent to evolve quality criteria and worker agents to make pairwise judgments. We build a knowledge base that extracts quality criteria from previous work to boost CritiQ Flow. Compared to perplexity- and classifier- based methods, verbal criteria are more interpretable and possess reusable value. After deriving the criteria, we train the CritiQ Scorer to give quality scores and perform efficient data selection. We demonstrate the effectiveness of our method in the code, math, and logic domains, achieving high accuracy on human-annotated test sets. To validate the quality of the selected data, we continually train Llama 3.1 models and observe improved performance on downstream tasks compared to uniform sampling. Ablation studies validate the benefits of the knowledge base and the reflection process. We analyze how criteria evolve and the effectiveness of majority voting.","sentences":["Language model heavily depends on high-quality data for optimal performance.","Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while introduce biases.","We introduce CritiQ, a novel data selection method that automatically mines criteria from human preferences for data quality with only $\\sim$30 human-annotated pairs and performs efficient data selection.","The main component, CritiQ Flow, employs a manager agent to evolve quality criteria and worker agents to make pairwise judgments.","We build a knowledge base that extracts quality criteria from previous work to boost CritiQ Flow.","Compared to perplexity- and classifier- based methods, verbal criteria are more interpretable and possess reusable value.","After deriving the criteria, we train the CritiQ Scorer to give quality scores and perform efficient data selection.","We demonstrate the effectiveness of our method in the code, math, and logic domains, achieving high accuracy on human-annotated test sets.","To validate the quality of the selected data, we continually train Llama 3.1 models and observe improved performance on downstream tasks compared to uniform sampling.","Ablation studies validate the benefits of the knowledge base and the reflection process.","We analyze how criteria evolve and the effectiveness of majority voting."],"url":"http://arxiv.org/abs/2502.19279v1"}
{"created":"2025-02-26 16:31:48","title":"Disentangled VAD Representations via a Variational Framework for Political Stance Detection","abstract":"The stance detection task aims to categorise the stance regarding specified targets. Current methods face challenges in effectively integrating sentiment information for stance detection. Moreover, the role of highly granular sentiment labelling in stance detection has been largely overlooked. This study presents a novel stance detection framework utilizing a variational autoencoder (VAE) to disentangle latent emotional features-value, arousal, and dominance (VAD)-from political discourse on social media. This approach addresses limitations in current methods, particularly in in-target and cross-target stance detection scenarios. This research uses an advanced emotional annotation tool to annotate seven-class sentiment labels for P-STANCE. Evaluations on benchmark datasets, including P-STANCE and SemEval-2016, reveal that PoliStance-VAE achieves state-of-the-art performance, surpassing models like BERT, BERTweet, and GPT-4o. PoliStance-VAE offers a robust and interpretable solution for stance detection, demonstrating the effectiveness of integrating nuanced emotional representations. This framework paves the way for advancements in natural language processing tasks, particularly those requiring detailed emotional understanding.","sentences":["The stance detection task aims to categorise the stance regarding specified targets.","Current methods face challenges in effectively integrating sentiment information for stance detection.","Moreover, the role of highly granular sentiment labelling in stance detection has been largely overlooked.","This study presents a novel stance detection framework utilizing a variational autoencoder (VAE) to disentangle latent emotional features-value, arousal, and dominance (VAD)-from political discourse on social media.","This approach addresses limitations in current methods, particularly in in-target and cross-target stance detection scenarios.","This research uses an advanced emotional annotation tool to annotate seven-class sentiment labels for P-STANCE.","Evaluations on benchmark datasets, including P-STANCE and SemEval-2016, reveal that PoliStance-VAE achieves state-of-the-art performance, surpassing models like BERT, BERTweet, and GPT-4o.","PoliStance-VAE offers a robust and interpretable solution for stance detection, demonstrating the effectiveness of integrating nuanced emotional representations.","This framework paves the way for advancements in natural language processing tasks, particularly those requiring detailed emotional understanding."],"url":"http://arxiv.org/abs/2502.19276v1"}
{"created":"2025-02-26 16:25:58","title":"Multiview graph dual-attention deep learning and contrastive learning for multi-criteria recommender systems","abstract":"Recommender systems leveraging deep learning models have been crucial for assisting users in selecting items aligned with their preferences and interests. However, a significant challenge persists in single-criteria recommender systems, which often overlook the diverse attributes of items that have been addressed by Multi-Criteria Recommender Systems (MCRS). Shared embedding vector for multi-criteria item ratings but have struggled to capture the nuanced relationships between users and items based on specific criteria. In this study, we present a novel representation for Multi-Criteria Recommender Systems (MCRS) based on a multi-edge bipartite graph, where each edge represents one criterion rating of items by users, and Multiview Dual Graph Attention Networks (MDGAT). Employing MDGAT is beneficial and important for adequately considering all relations between users and items, given the presence of both local (criterion-based) and global (multi-criteria) relations. Additionally, we define anchor points in each view based on similarity and employ local and global contrastive learning to distinguish between positive and negative samples across each view and the entire graph. We evaluate our method on two real-world datasets and assess its performance based on item rating predictions. The results demonstrate that our method achieves higher accuracy compared to the baseline method for predicting item ratings on the same datasets. MDGAT effectively capture the local and global impact of neighbours and the similarity between nodes.","sentences":["Recommender systems leveraging deep learning models have been crucial for assisting users in selecting items aligned with their preferences and interests.","However, a significant challenge persists in single-criteria recommender systems, which often overlook the diverse attributes of items that have been addressed by Multi-Criteria Recommender Systems (MCRS).","Shared embedding vector for multi-criteria item ratings but have struggled to capture the nuanced relationships between users and items based on specific criteria.","In this study, we present a novel representation for Multi-Criteria Recommender Systems (MCRS) based on a multi-edge bipartite graph, where each edge represents one criterion rating of items by users, and Multiview Dual Graph Attention Networks (MDGAT).","Employing MDGAT is beneficial and important for adequately considering all relations between users and items, given the presence of both local (criterion-based) and global (multi-criteria) relations.","Additionally, we define anchor points in each view based on similarity and employ local and global contrastive learning to distinguish between positive and negative samples across each view and the entire graph.","We evaluate our method on two real-world datasets and assess its performance based on item rating predictions.","The results demonstrate that our method achieves higher accuracy compared to the baseline method for predicting item ratings on the same datasets.","MDGAT effectively capture the local and global impact of neighbours and the similarity between nodes."],"url":"http://arxiv.org/abs/2502.19271v1"}
{"created":"2025-02-26 16:25:15","title":"Neural Antidote: Class-Wise Prompt Tuning for Purifying Backdoors in Pre-trained Vision-Language Models","abstract":"While pre-trained Vision-Language Models (VLMs) such as CLIP exhibit excellent representational capabilities for multimodal data, recent studies have shown that they are vulnerable to backdoor attacks. To alleviate the threat, existing defense strategies primarily focus on fine-tuning the entire suspicious model, yet offer only marginal resistance to state-of-the-art attacks and often result in a decrease in clean accuracy, particularly in data-limited scenarios. Their failure may be attributed to the mismatch between insufficient fine-tuning data and massive parameters in VLMs. To address this challenge, we propose Class-wise Backdoor Prompt Tuning (CBPT) defense, an efficient and effective method that operates on the text prompts to indirectly purify the poisoned VLMs. Specifically, we first employ the advanced contrastive learning via our carefully crafted positive and negative samples, to effectively invert the backdoor triggers that are potentially adopted by the attacker. Once the dummy trigger is established, we utilize the efficient prompt tuning technique to optimize these class-wise text prompts for modifying the model's decision boundary to further reclassify the feature regions of backdoor triggers. Extensive experiments demonstrate that CBPT significantly mitigates backdoor threats while preserving model utility, e.g. an average Clean Accuracy (CA) of 58.86\\% and an Attack Success Rate (ASR) of 0.39\\% across seven mainstream backdoor attacks. These results underscore the superiority of our prompt purifying design to strengthen model robustness against backdoor attacks.","sentences":["While pre-trained Vision-Language Models (VLMs) such as CLIP exhibit excellent representational capabilities for multimodal data, recent studies have shown that they are vulnerable to backdoor attacks.","To alleviate the threat, existing defense strategies primarily focus on fine-tuning the entire suspicious model, yet offer only marginal resistance to state-of-the-art attacks and often result in a decrease in clean accuracy, particularly in data-limited scenarios.","Their failure may be attributed to the mismatch between insufficient fine-tuning data and massive parameters in VLMs.","To address this challenge, we propose Class-wise Backdoor Prompt Tuning (CBPT) defense, an efficient and effective method that operates on the text prompts to indirectly purify the poisoned VLMs.","Specifically, we first employ the advanced contrastive learning via our carefully crafted positive and negative samples, to effectively invert the backdoor triggers that are potentially adopted by the attacker.","Once the dummy trigger is established, we utilize the efficient prompt tuning technique to optimize these class-wise text prompts for modifying the model's decision boundary to further reclassify the feature regions of backdoor triggers.","Extensive experiments demonstrate that CBPT significantly mitigates backdoor threats while preserving model utility, e.g. an average Clean Accuracy (CA) of 58.86\\% and an Attack Success Rate (ASR) of 0.39\\% across seven mainstream backdoor attacks.","These results underscore the superiority of our prompt purifying design to strengthen model robustness against backdoor attacks."],"url":"http://arxiv.org/abs/2502.19269v1"}
{"created":"2025-02-26 16:17:15","title":"ArtInsight: Enabling AI-Powered Artwork Engagement for Mixed Visual-Ability Families","abstract":"We introduce ArtInsight, a novel AI-powered system to facilitate deeper engagement with child-created artwork in mixed visual-ability families. ArtInsight leverages large language models (LLMs) to craft a respectful and thorough initial description of a child's artwork, and provides: creative AI-generated descriptions for a vivid overview, audio recording to capture the child's own description of their artwork, and a set of AI-generated questions to facilitate discussion between blind or low-vision (BLV) family members and their children. Alongside ArtInsight, we also contribute a new rubric to score AI-generated descriptions of child-created artwork and an assessment of state-of-the-art LLMs. We evaluated ArtInsight with five groups of BLV family members and their children, and as a case study with one BLV child therapist. Our findings highlight a preference for ArtInsight's longer, artistically-tailored descriptions over those generated by existing BLV AI tools. Participants highlighted the creative description and audio recording components as most beneficial, with the former helping ``bring a picture to life'' and the latter centering the child's narrative to generate context-aware AI responses. Our findings reveal different ways that AI can be used to support art engagement, including before, during, and after interaction with the child artist, as well as expectations that BLV adults and their sighted children have about AI-powered tools.","sentences":["We introduce ArtInsight, a novel AI-powered system to facilitate deeper engagement with child-created artwork in mixed visual-ability families.","ArtInsight leverages large language models (LLMs) to craft a respectful and thorough initial description of a child's artwork, and provides: creative AI-generated descriptions for a vivid overview, audio recording to capture the child's own description of their artwork, and a set of AI-generated questions to facilitate discussion between blind or low-vision (BLV) family members and their children.","Alongside ArtInsight, we also contribute a new rubric to score AI-generated descriptions of child-created artwork and an assessment of state-of-the-art LLMs.","We evaluated ArtInsight with five groups of BLV family members and their children, and as a case study with one BLV child therapist.","Our findings highlight a preference for ArtInsight's longer, artistically-tailored descriptions over those generated by existing BLV AI tools.","Participants highlighted the creative description and audio recording components as most beneficial, with the former helping ``bring a picture to life'' and the latter centering the child's narrative to generate context-aware AI responses.","Our findings reveal different ways that AI can be used to support art engagement, including before, during, and after interaction with the child artist, as well as expectations that BLV adults and their sighted children have about AI-powered tools."],"url":"http://arxiv.org/abs/2502.19263v1"}
{"created":"2025-02-26 16:06:36","title":"Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization","abstract":"The Mixture of Experts (MoE) architecture reduces the training and inference cost significantly compared to a dense model of equivalent capacity. Upcycling is an approach that initializes and trains an MoE model using a pre-trained dense model. While upcycling leads to initial performance gains, the training progresses slower than when trained from scratch, leading to suboptimal performance in the long term. We propose Drop-Upcycling - a method that effectively addresses this problem. Drop-Upcycling combines two seemingly contradictory approaches: utilizing the knowledge of pre-trained dense models while statistically re-initializing some parts of the weights. This approach strategically promotes expert specialization, significantly enhancing the MoE model's efficiency in knowledge acquisition. Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term, specifically when training on hundreds of billions of tokens or more. As a result, our MoE model with 5.9B active parameters achieves comparable performance to a 13B dense model in the same model family, while requiring approximately 1/4 of the training FLOPs. All experimental resources, including source code, training data, model checkpoints and logs, are publicly available to promote reproducibility and future research on MoE.","sentences":["The Mixture of Experts (MoE) architecture reduces the training and inference cost significantly compared to a dense model of equivalent capacity.","Upcycling is an approach that initializes and trains an MoE model using a pre-trained dense model.","While upcycling leads to initial performance gains, the training progresses slower than when trained from scratch, leading to suboptimal performance in the long term.","We propose Drop-Upcycling - a method that effectively addresses this problem.","Drop-Upcycling combines two seemingly contradictory approaches: utilizing the knowledge of pre-trained dense models while statistically re-initializing some parts of the weights.","This approach strategically promotes expert specialization, significantly enhancing the MoE model's efficiency in knowledge acquisition.","Extensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term, specifically when training on hundreds of billions of tokens or more.","As a result, our MoE model with 5.9B active parameters achieves comparable performance to a 13B dense model in the same model family, while requiring approximately 1/4 of the training FLOPs.","All experimental resources, including source code, training data, model checkpoints and logs, are publicly available to promote reproducibility and future research on MoE."],"url":"http://arxiv.org/abs/2502.19261v1"}
{"created":"2025-02-26 16:06:35","title":"EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region","abstract":"This paper introduces the Emirates Multi-Task (EMT) dataset - the first publicly available dataset for autonomous driving collected in the Arab Gulf region. The EMT dataset captures the unique road topology, high traffic congestion, and distinctive characteristics of the Gulf region, including variations in pedestrian clothing and weather conditions. It contains over 30,000 frames from a dash-camera perspective, along with 570,000 annotated bounding boxes, covering approximately 150 kilometers of driving routes. The EMT dataset supports three primary tasks: tracking, trajectory forecasting and intention prediction. Each benchmark dataset is complemented with corresponding evaluations: (1) multi-agent tracking experiments, focusing on multi-class scenarios and occlusion handling; (2) trajectory forecasting evaluation using deep sequential and interaction-aware models; and (3) intention benchmark experiments conducted for predicting agents intentions from observed trajectories. The dataset is publicly available at https://avlab.io/emt-dataset, and pre-processing scripts along with evaluation models can be accessed at https://github.com/AV-Lab/emt-dataset.","sentences":["This paper introduces the Emirates Multi-Task (EMT) dataset - the first publicly available dataset for autonomous driving collected in the Arab Gulf region.","The EMT dataset captures the unique road topology, high traffic congestion, and distinctive characteristics of the Gulf region, including variations in pedestrian clothing and weather conditions.","It contains over 30,000 frames from a dash-camera perspective, along with 570,000 annotated bounding boxes, covering approximately 150 kilometers of driving routes.","The EMT dataset supports three primary tasks: tracking, trajectory forecasting and intention prediction.","Each benchmark dataset is complemented with corresponding evaluations: (1) multi-agent tracking experiments, focusing on multi-class scenarios and occlusion handling; (2) trajectory forecasting evaluation using deep sequential and interaction-aware models; and (3) intention benchmark experiments conducted for predicting agents intentions from observed trajectories.","The dataset is publicly available at https://avlab.io/emt-dataset, and pre-processing scripts along with evaluation models can be accessed at https://github.com/AV-Lab/emt-dataset."],"url":"http://arxiv.org/abs/2502.19260v1"}
{"created":"2025-02-26 16:04:17","title":"Poster: Long PHP webshell files detection based on sliding window attention","abstract":"Webshell is a type of backdoor, and web applications are widely exposed to webshell injection attacks. Therefore, it is important to study webshell detection techniques. In this study, we propose a webshell detection method. We first convert PHP source code to opcodes and then extract Opcode Double-Tuples (ODTs). Next, we combine CodeBert and FastText models for feature representation and classification. To address the challenge that deep learning methods have difficulty detecting long webshell files, we introduce a sliding window attention mechanism. This approach effectively captures malicious behavior within long files. Experimental results show that our method reaches high accuracy in webshell detection, solving the problem of traditional methods that struggle to address new webshell variants and anti-detection techniques.","sentences":["Webshell is a type of backdoor, and web applications are widely exposed to webshell injection attacks.","Therefore, it is important to study webshell detection techniques.","In this study, we propose a webshell detection method.","We first convert PHP source code to opcodes and then extract Opcode Double-Tuples (ODTs).","Next, we combine CodeBert and FastText models for feature representation and classification.","To address the challenge that deep learning methods have difficulty detecting long webshell files, we introduce a sliding window attention mechanism.","This approach effectively captures malicious behavior within long files.","Experimental results show that our method reaches high accuracy in webshell detection, solving the problem of traditional methods that struggle to address new webshell variants and anti-detection techniques."],"url":"http://arxiv.org/abs/2502.19257v1"}
{"created":"2025-02-26 16:03:06","title":"Can RLHF be More Efficient with Imperfect Reward Models? A Policy Coverage Perspective","abstract":"Sample efficiency is critical for online Reinforcement Learning from Human Feedback (RLHF). While existing works investigate sample-efficient online exploration strategies, the potential of utilizing misspecified yet relevant reward models to accelerate learning remains underexplored. This paper studies how to transfer knowledge from those imperfect reward models in online RLHF. We start by identifying a novel property of the KL-regularized RLHF objective: \\emph{a policy's ability to cover the optimal policy is captured by its sub-optimality}. Building on this insight, we propose a theoretical transfer learning algorithm with provable benefits compared to standard online learning. Our approach achieves low regret in the early stage by quickly adapting to the best available source reward models without prior knowledge of their quality, and over time, it attains an $\\tilde{O}(\\sqrt{T})$ regret bound \\emph{independent} of structural complexity measures. Inspired by our theoretical findings, we develop an empirical algorithm with improved computational efficiency, and demonstrate its effectiveness empirically in summarization tasks.","sentences":["Sample efficiency is critical for online Reinforcement Learning from Human Feedback (RLHF).","While existing works investigate sample-efficient online exploration strategies, the potential of utilizing misspecified yet relevant reward models to accelerate learning remains underexplored.","This paper studies how to transfer knowledge from those imperfect reward models in online RLHF.","We start by identifying a novel property of the KL-regularized RLHF objective: \\emph{a policy's ability to cover the optimal policy is captured by its sub-optimality}.","Building on this insight, we propose a theoretical transfer learning algorithm with provable benefits compared to standard online learning.","Our approach achieves low regret in the early stage by quickly adapting to the best available source reward models without prior knowledge of their quality, and over time, it attains an $\\tilde{O}(\\sqrt{T})$ regret bound \\emph{independent} of structural complexity measures.","Inspired by our theoretical findings, we develop an empirical algorithm with improved computational efficiency, and demonstrate its effectiveness empirically in summarization tasks."],"url":"http://arxiv.org/abs/2502.19255v1"}
{"created":"2025-02-26 16:00:42","title":"Set and functional prediction: randomness, exchangeability, and conformal","abstract":"This paper continues the study of the efficiency of conformal prediction as compared with more general randomness prediction and exchangeability prediction. It does not restrict itself to the case of classification, and our results will also be applicable to the case of regression. The price to pay is that efficiency will be attained only on average, albeit with respect to a wide range of probability measures on the label space.","sentences":["This paper continues the study of the efficiency of conformal prediction as compared with more general randomness prediction and exchangeability prediction.","It does not restrict itself to the case of classification, and our results will also be applicable to the case of regression.","The price to pay is that efficiency will be attained only on average, albeit with respect to a wide range of probability measures on the label space."],"url":"http://arxiv.org/abs/2502.19254v1"}
{"created":"2025-02-26 15:57:51","title":"GraphBridge: Towards Arbitrary Transfer Learning in GNNs","abstract":"Graph neural networks (GNNs) are conventionally trained on a per-domain, per-task basis. It creates a significant barrier in transferring the acquired knowledge to different, heterogeneous data setups. This paper introduces GraphBridge, a novel framework to enable knowledge transfer across disparate tasks and domains in GNNs, circumventing the need for modifications to task configurations or graph structures. Specifically, GraphBridge allows for the augmentation of any pre-trained GNN with prediction heads and a bridging network that connects the input to the output layer. This architecture not only preserves the intrinsic knowledge of the original model but also supports outputs of arbitrary dimensions. To mitigate the negative transfer problem, GraphBridg merges the source model with a concurrently trained model, thereby reducing the source bias when applied to the target domain. Our method is thoroughly evaluated across diverse transfer learning scenarios, including Graph2Graph, Node2Node, Graph2Node, and graph2point-cloud. Empirical validation, conducted over 16 datasets representative of these scenarios, confirms the framework's capacity for task- and domain-agnostic transfer learning within graph-like data, marking a significant advancement in the field of GNNs.","sentences":["Graph neural networks (GNNs) are conventionally trained on a per-domain, per-task basis.","It creates a significant barrier in transferring the acquired knowledge to different, heterogeneous data setups.","This paper introduces GraphBridge, a novel framework to enable knowledge transfer across disparate tasks and domains in GNNs, circumventing the need for modifications to task configurations or graph structures.","Specifically, GraphBridge allows for the augmentation of any pre-trained GNN with prediction heads and a bridging network that connects the input to the output layer.","This architecture not only preserves the intrinsic knowledge of the original model but also supports outputs of arbitrary dimensions.","To mitigate the negative transfer problem, GraphBridg merges the source model with a concurrently trained model, thereby reducing the source bias when applied to the target domain.","Our method is thoroughly evaluated across diverse transfer learning scenarios, including Graph2Graph, Node2Node, Graph2Node, and graph2point-cloud.","Empirical validation, conducted over 16 datasets representative of these scenarios, confirms the framework's capacity for task- and domain-agnostic transfer learning within graph-like data, marking a significant advancement in the field of GNNs."],"url":"http://arxiv.org/abs/2502.19252v1"}
{"created":"2025-02-26 15:56:36","title":"ObjectVLA: End-to-End Open-World Object Manipulation Without Demonstration","abstract":"Imitation learning has proven to be highly effective in teaching robots dexterous manipulation skills. However, it typically relies on large amounts of human demonstration data, which limits its scalability and applicability in dynamic, real-world environments. One key challenge in this context is object generalization, where a robot trained to perform a task with one object, such as \"hand over the apple,\" struggles to transfer its skills to a semantically similar but visually different object, such as \"hand over the peach.\" This gap in generalization to new objects beyond those in the same category has yet to be adequately addressed in previous work on end-to-end visuomotor policy learning. In this paper, we present a simple yet effective approach for achieving object generalization through Vision-Language-Action (VLA) models, referred to as \\textbf{ObjectVLA}. Our model enables robots to generalize learned skills to novel objects without requiring explicit human demonstrations for each new target object. By leveraging vision-language pair data, our method provides a lightweight and scalable way to inject knowledge about the target object, establishing an implicit link between the object and the desired action. We evaluate ObjectVLA on a real robotic platform, demonstrating its ability to generalize across 100 novel objects with a 64\\% success rate in selecting objects not seen during training. Furthermore, we propose a more accessible method for enhancing object generalization in VLA models, using a smartphone to capture a few images and fine-tune the pre-trained model. These results highlight the effectiveness of our approach in enabling object-level generalization and reducing the need for extensive human demonstrations, paving the way for more flexible and scalable robotic learning systems.","sentences":["Imitation learning has proven to be highly effective in teaching robots dexterous manipulation skills.","However, it typically relies on large amounts of human demonstration data, which limits its scalability and applicability in dynamic, real-world environments.","One key challenge in this context is object generalization, where a robot trained to perform a task with one object, such as \"hand over the apple,\" struggles to transfer its skills to a semantically similar but visually different object, such as \"hand over the peach.\"","This gap in generalization to new objects beyond those in the same category has yet to be adequately addressed in previous work on end-to-end visuomotor policy learning.","In this paper, we present a simple yet effective approach for achieving object generalization through Vision-Language-Action (VLA) models, referred to as \\textbf{ObjectVLA}.","Our model enables robots to generalize learned skills to novel objects without requiring explicit human demonstrations for each new target object.","By leveraging vision-language pair data, our method provides a lightweight and scalable way to inject knowledge about the target object, establishing an implicit link between the object and the desired action.","We evaluate ObjectVLA on a real robotic platform, demonstrating its ability to generalize across 100 novel objects with a 64\\% success rate in selecting objects not seen during training.","Furthermore, we propose a more accessible method for enhancing object generalization in VLA models, using a smartphone to capture a few images and fine-tune the pre-trained model.","These results highlight the effectiveness of our approach in enabling object-level generalization and reducing the need for extensive human demonstrations, paving the way for more flexible and scalable robotic learning systems."],"url":"http://arxiv.org/abs/2502.19250v1"}
{"created":"2025-02-26 15:55:55","title":"Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases","abstract":"Pretraining language models on formal languages can improve their acquisition of natural language, but it is unclear which features of the formal language impart an inductive bias that leads to effective transfer. Drawing on insights from linguistics and complexity theory, we hypothesize that effective transfer occurs when the formal language both captures dependency structures in natural language and remains within the computational limitations of the model architecture. Focusing on transformers, we find that formal languages with both these properties enable language models to achieve lower loss on natural language and better linguistic generalization compared to other languages. In fact, pre-pretraining, or training on formal-then-natural language, reduces loss more efficiently than the same amount of natural language. For a 1B-parameter language model trained on roughly 1.6B tokens of natural language, pre-pretraining achieves the same loss and better linguistic generalization with a 33% smaller token budget. We also give mechanistic evidence of cross-task transfer from formal to natural language: attention heads acquired during formal language pretraining remain crucial for the model's performance on syntactic evaluations.","sentences":["Pretraining language models on formal languages can improve their acquisition of natural language, but it is unclear which features of the formal language impart an inductive bias that leads to effective transfer.","Drawing on insights from linguistics and complexity theory, we hypothesize that effective transfer occurs when the formal language both captures dependency structures in natural language and remains within the computational limitations of the model architecture.","Focusing on transformers, we find that formal languages with both these properties enable language models to achieve lower loss on natural language and better linguistic generalization compared to other languages.","In fact, pre-pretraining, or training on formal-then-natural language, reduces loss more efficiently than the same amount of natural language.","For a 1B-parameter language model trained on roughly 1.6B tokens of natural language, pre-pretraining achieves the same loss and better linguistic generalization with a 33% smaller token budget.","We also give mechanistic evidence of cross-task transfer from formal to natural language: attention heads acquired during formal language pretraining remain crucial for the model's performance on syntactic evaluations."],"url":"http://arxiv.org/abs/2502.19249v1"}
{"created":"2025-02-26 15:53:41","title":"ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding","abstract":"Embodied intelligence requires agents to interact with 3D environments in real time based on language instructions. A foundational task in this domain is ego-centric 3D visual grounding. However, the point clouds rendered from RGB-D images retain a large amount of redundant background data and inherent noise, both of which can interfere with the manifold structure of the target regions. Existing point cloud enhancement methods often require a tedious process to improve the manifold, which is not suitable for real-time tasks. We propose Proxy Transformation suitable for multimodal task to efficiently improve the point cloud manifold. Our method first leverages Deformable Point Clustering to identify the point cloud sub-manifolds in target regions. Then, we propose a Proxy Attention module that utilizes multimodal proxies to guide point cloud transformation. Built upon Proxy Attention, we design a submanifold transformation generation module where textual information globally guides translation vectors for different submanifolds, optimizing relative spatial relationships of target regions. Simultaneously, image information guides linear transformations within each submanifold, refining the local point cloud manifold of target regions. Extensive experiments demonstrate that Proxy Transformation significantly outperforms all existing methods, achieving an impressive improvement of 7.49% on easy targets and 4.60% on hard targets, while reducing the computational overhead of attention blocks by 40.6%. These results establish a new SOTA in ego-centric 3D visual grounding, showcasing the effectiveness and robustness of our approach.","sentences":["Embodied intelligence requires agents to interact with 3D environments in real time based on language instructions.","A foundational task in this domain is ego-centric 3D visual grounding.","However, the point clouds rendered from RGB-D images retain a large amount of redundant background data and inherent noise, both of which can interfere with the manifold structure of the target regions.","Existing point cloud enhancement methods often require a tedious process to improve the manifold, which is not suitable for real-time tasks.","We propose Proxy Transformation suitable for multimodal task to efficiently improve the point cloud manifold.","Our method first leverages Deformable Point Clustering to identify the point cloud sub-manifolds in target regions.","Then, we propose a Proxy Attention module that utilizes multimodal proxies to guide point cloud transformation.","Built upon Proxy Attention, we design a submanifold transformation generation module where textual information globally guides translation vectors for different submanifolds, optimizing relative spatial relationships of target regions.","Simultaneously, image information guides linear transformations within each submanifold, refining the local point cloud manifold of target regions.","Extensive experiments demonstrate that Proxy Transformation significantly outperforms all existing methods, achieving an impressive improvement of 7.49% on easy targets and 4.60% on hard targets, while reducing the computational overhead of attention blocks by 40.6%.","These results establish a new SOTA in ego-centric 3D visual grounding, showcasing the effectiveness and robustness of our approach."],"url":"http://arxiv.org/abs/2502.19247v1"}
{"created":"2025-02-26 15:51:32","title":"BEV-LIO(LC): BEV Image Assisted LiDAR-Inertial Odometry with Loop Closure","abstract":"This work introduces BEV-LIO(LC), a novel LiDAR-Inertial Odometry (LIO) framework that combines Bird's Eye View (BEV) image representations of LiDAR data with geometry-based point cloud registration and incorporates loop closure (LC) through BEV image features. By normalizing point density, we project LiDAR point clouds into BEV images, thereby enabling efficient feature extraction and matching. A lightweight convolutional neural network (CNN) based feature extractor is employed to extract distinctive local and global descriptors from the BEV images. Local descriptors are used to match BEV images with FAST keypoints for reprojection error construction, while global descriptors facilitate loop closure detection. Reprojection error minimization is then integrated with point-to-plane registration within an iterated Extended Kalman Filter (iEKF). In the back-end, global descriptors are used to create a KD-tree-indexed keyframe database for accurate loop closure detection. When a loop closure is detected, Random Sample Consensus (RANSAC) computes a coarse transform from BEV image matching, which serves as the initial estimate for Iterative Closest Point (ICP). The refined transform is subsequently incorporated into a factor graph along with odometry factors, improving the global consistency of localization. Extensive experiments conducted in various scenarios with different LiDAR types demonstrate that BEV-LIO(LC) outperforms state-of-the-art methods, achieving competitive localization accuracy. Our code, video and supplementary materials can be found at https://github.com/HxCa1/BEV-LIO-LC.","sentences":["This work introduces BEV-LIO(LC), a novel LiDAR-Inertial Odometry (LIO) framework that combines Bird's Eye View (BEV) image representations of LiDAR data with geometry-based point cloud registration and incorporates loop closure (LC) through BEV image features.","By normalizing point density, we project LiDAR point clouds into BEV images, thereby enabling efficient feature extraction and matching.","A lightweight convolutional neural network (CNN) based feature extractor is employed to extract distinctive local and global descriptors from the BEV images.","Local descriptors are used to match BEV images with FAST keypoints for reprojection error construction, while global descriptors facilitate loop closure detection.","Reprojection error minimization is then integrated with point-to-plane registration within an iterated Extended Kalman Filter (iEKF).","In the back-end, global descriptors are used to create a KD-tree-indexed keyframe database for accurate loop closure detection.","When a loop closure is detected, Random Sample Consensus (RANSAC) computes a coarse transform from BEV image matching, which serves as the initial estimate for Iterative Closest Point (ICP).","The refined transform is subsequently incorporated into a factor graph along with odometry factors, improving the global consistency of localization.","Extensive experiments conducted in various scenarios with different LiDAR types demonstrate that BEV-LIO(LC) outperforms state-of-the-art methods, achieving competitive localization accuracy.","Our code, video and supplementary materials can be found at https://github.com/HxCa1/BEV-LIO-LC."],"url":"http://arxiv.org/abs/2502.19242v1"}
{"created":"2025-02-26 15:47:23","title":"Arbitrary Volumetric Refocusing of Dense and Sparse Light Fields","abstract":"A four-dimensional light field (LF) captures both textural and geometrical information of a scene in contrast to a two-dimensional image that captures only the textural information of a scene. Post-capture refocusing is an exciting application of LFs enabled by the geometric information captured. Previously proposed LF refocusing methods are mostly limited to the refocusing of single planar or volumetric region of a scene corresponding to a depth range and cannot simultaneously generate in-focus and out-of-focus regions having the same depth range. In this paper, we propose an end-to-end pipeline to simultaneously refocus multiple arbitrary planar or volumetric regions of a dense or a sparse LF. We employ pixel-dependent shifts with the typical shift-and-sum method to refocus an LF. The pixel-dependent shifts enables to refocus each pixel of an LF independently. For sparse LFs, the shift-and-sum method introduces ghosting artifacts due to the spatial undersampling. We employ a deep learning model based on U-Net architecture to almost completely eliminate the ghosting artifacts. The experimental results obtained with several LF datasets confirm the effectiveness of the proposed method. In particular, sparse LFs refocused with the proposed method archive structural similarity index higher than 0.9 despite having only 20% of data compared to dense LFs.","sentences":["A four-dimensional light field (LF) captures both textural and geometrical information of a scene in contrast to a two-dimensional image that captures only the textural information of a scene.","Post-capture refocusing is an exciting application of LFs enabled by the geometric information captured.","Previously proposed LF refocusing methods are mostly limited to the refocusing of single planar or volumetric region of a scene corresponding to a depth range and cannot simultaneously generate in-focus and out-of-focus regions having the same depth range.","In this paper, we propose an end-to-end pipeline to simultaneously refocus multiple arbitrary planar or volumetric regions of a dense or a sparse LF.","We employ pixel-dependent shifts with the typical shift-and-sum method to refocus an LF.","The pixel-dependent shifts enables to refocus each pixel of an LF independently.","For sparse LFs, the shift-and-sum method introduces ghosting artifacts due to the spatial undersampling.","We employ a deep learning model based on U-Net architecture to almost completely eliminate the ghosting artifacts.","The experimental results obtained with several LF datasets confirm the effectiveness of the proposed method.","In particular, sparse LFs refocused with the proposed method archive structural similarity index higher than 0.9 despite having only 20% of data compared to dense LFs."],"url":"http://arxiv.org/abs/2502.19238v1"}
{"created":"2025-02-26 15:46:57","title":"Leg Exoskeleton Odometry using a Limited FOV Depth Sensor","abstract":"For leg exoskeletons to operate effectively in real-world environments, they must be able to perceive and understand the terrain around them. However, unlike other legged robots, exoskeletons face specific constraints on where depth sensors can be mounted due to the presence of a human user. These constraints lead to a limited Field Of View (FOV) and greater sensor motion, making odometry particularly challenging. To address this, we propose a novel odometry algorithm that integrates proprioceptive data from the exoskeleton with point clouds from a depth camera to produce accurate elevation maps despite these limitations. Our method builds on an extended Kalman filter (EKF) to fuse kinematic and inertial measurements, while incorporating a tailored iterative closest point (ICP) algorithm to register new point clouds with the elevation map. Experimental validation with a leg exoskeleton demonstrates that our approach reduces drift and enhances the quality of elevation maps compared to a purely proprioceptive baseline, while also outperforming a more traditional point cloud map-based variant.","sentences":["For leg exoskeletons to operate effectively in real-world environments, they must be able to perceive and understand the terrain around them.","However, unlike other legged robots, exoskeletons face specific constraints on where depth sensors can be mounted due to the presence of a human user.","These constraints lead to a limited Field Of View (FOV) and greater sensor motion, making odometry particularly challenging.","To address this, we propose a novel odometry algorithm that integrates proprioceptive data from the exoskeleton with point clouds from a depth camera to produce accurate elevation maps despite these limitations.","Our method builds on an extended Kalman filter (EKF) to fuse kinematic and inertial measurements, while incorporating a tailored iterative closest point (ICP) algorithm to register new point clouds with the elevation map.","Experimental validation with a leg exoskeleton demonstrates that our approach reduces drift and enhances the quality of elevation maps compared to a purely proprioceptive baseline, while also outperforming a more traditional point cloud map-based variant."],"url":"http://arxiv.org/abs/2502.19237v1"}
{"created":"2025-02-26 15:43:04","title":"FPGA-based Emulation and Device-Side Management for CXL-based Memory Tiering Systems","abstract":"The Compute Express Link (CXL) technology facilitates the extension of CPU memory through byte-addressable SerDes links and cascaded switches, creating complex heterogeneous memory systems where CPU access to various endpoints differs in latency and bandwidth. Effective tiered memory management is essential for optimizing system performance in such systems. However, designing an effective memory tiering system for CXL-extended heterogeneous memory faces challenges: 1) Existing evaluation methods, such as NUMA-based emulation and full-system simulations like GEM5, are limited in assessing hardware-based tiered memory management solutions and handling real-world workloads at scale. 2) Previous memory tiering systems struggle to simultaneously achieve high resolution, low overhead, and high flexibility and compatibility.   In this study, we first introduce HeteroBox, a configurable emulation platform that leverages real CXL-enabled FPGAs to emulate the performance of various CXL memory architectures. HeteroBox allows one to configure a memory space with multiple regions, each exhibiting distinct CPU-access latency and bandwidth. HeteroBox helps assess the performance of both software-managed and hardware-managed memory tiering systems with high efficiency and fidelity. Based on HeteroBox, we further propose HeteroMem, a hardware-managed memory tiering system that operates on the device side. HeteroMem creates an abstraction layer between the CPU and device memory, effectively monitoring data usage and migrating data to faster memory tiers, thus hiding device-side heterogeneity from the CPU. Evaluations with real-world applications show that HeteroMem delivers high performance while keeping heterogeneous memory management fully transparent to the CPU, achieving a 5.1\\% to 16.2\\% performance improvement over existing memory tiering solutions.","sentences":["The Compute Express Link (CXL) technology facilitates the extension of CPU memory through byte-addressable SerDes links and cascaded switches, creating complex heterogeneous memory systems where CPU access to various endpoints differs in latency and bandwidth.","Effective tiered memory management is essential for optimizing system performance in such systems.","However, designing an effective memory tiering system for CXL-extended heterogeneous memory faces challenges: 1) Existing evaluation methods, such as NUMA-based emulation and full-system simulations like GEM5, are limited in assessing hardware-based tiered memory management solutions and handling real-world workloads at scale.","2) Previous memory tiering systems struggle to simultaneously achieve high resolution, low overhead, and high flexibility and compatibility.   ","In this study, we first introduce HeteroBox, a configurable emulation platform that leverages real CXL-enabled FPGAs to emulate the performance of various CXL memory architectures.","HeteroBox allows one to configure a memory space with multiple regions, each exhibiting distinct CPU-access latency and bandwidth.","HeteroBox helps assess the performance of both software-managed and hardware-managed memory tiering systems with high efficiency and fidelity.","Based on HeteroBox, we further propose HeteroMem, a hardware-managed memory tiering system that operates on the device side.","HeteroMem creates an abstraction layer between the CPU and device memory, effectively monitoring data usage and migrating data to faster memory tiers, thus hiding device-side heterogeneity from the CPU.","Evaluations with real-world applications show that HeteroMem delivers high performance while keeping heterogeneous memory management fully transparent to the CPU, achieving a 5.1\\% to 16.2\\% performance improvement over existing memory tiering solutions."],"url":"http://arxiv.org/abs/2502.19233v1"}
{"created":"2025-02-26 15:41:41","title":"Two Heads Are Better Than One: Dual-Model Verbal Reflection at Inference-Time","abstract":"Large Language Models (LLMs) often struggle with complex reasoning scenarios. While preference optimization methods enhance reasoning performance through training, they often lack transparency in why one reasoning outcome is preferred over another. Verbal reflection techniques improve explainability but are limited in LLMs' critique and refinement capacity. To address these challenges, we introduce a contrastive reflection synthesis pipeline that enhances the accuracy and depth of LLM-generated reflections. We further propose a dual-model reasoning framework within a verbal reinforcement learning paradigm, decoupling inference-time self-reflection into specialized, trained models for reasoning critique and refinement. Extensive experiments show that our framework outperforms traditional preference optimization methods across all evaluation metrics. Our findings also show that \"two heads are better than one\", demonstrating that a collaborative Reasoner-Critic model achieves superior reasoning performance and transparency, compared to single-model approaches.","sentences":["Large Language Models (LLMs) often struggle with complex reasoning scenarios.","While preference optimization methods enhance reasoning performance through training, they often lack transparency in why one reasoning outcome is preferred over another.","Verbal reflection techniques improve explainability but are limited in LLMs' critique and refinement capacity.","To address these challenges, we introduce a contrastive reflection synthesis pipeline that enhances the accuracy and depth of LLM-generated reflections.","We further propose a dual-model reasoning framework within a verbal reinforcement learning paradigm, decoupling inference-time self-reflection into specialized, trained models for reasoning critique and refinement.","Extensive experiments show that our framework outperforms traditional preference optimization methods across all evaluation metrics.","Our findings also show that \"two heads are better than one\", demonstrating that a collaborative Reasoner-Critic model achieves superior reasoning performance and transparency, compared to single-model approaches."],"url":"http://arxiv.org/abs/2502.19230v1"}
{"created":"2025-02-26 15:23:40","title":"Detecting Essence Code Clones via Information Theoretic Analysis","abstract":"Code cloning, a widespread practice in software development, involves replicating code fragments to save time but often at the expense of software maintainability and quality. In this paper, we address the specific challenge of detecting \"essence clones\", a complex subtype of Type-3 clones characterized by sharing critical logic despite different peripheral codes. Traditional techniques often fail to detect essence clones due to their syntactic focus. To overcome this limitation, we introduce ECScan, a novel detection tool that leverages information theory to assess the semantic importance of code lines. By assigning weights to each line based on its information content, ECScan emphasizes core logic over peripheral code differences. Our comprehensive evaluation across various real-world projects shows that ECScan significantly outperforms existing tools in detecting essence clones, achieving an average F1-score of 85%. It demonstrates robust performance across all clone types and offers exceptional scalability. This study advances clone detection by providing a practical tool for developers to enhance code quality and reduce maintenance burdens, emphasizing the semantic aspects of code through an innovative information-theoretic approach.","sentences":["Code cloning, a widespread practice in software development, involves replicating code fragments to save time but often at the expense of software maintainability and quality.","In this paper, we address the specific challenge of detecting \"essence clones\", a complex subtype of Type-3 clones characterized by sharing critical logic despite different peripheral codes.","Traditional techniques often fail to detect essence clones due to their syntactic focus.","To overcome this limitation, we introduce ECScan, a novel detection tool that leverages information theory to assess the semantic importance of code lines.","By assigning weights to each line based on its information content, ECScan emphasizes core logic over peripheral code differences.","Our comprehensive evaluation across various real-world projects shows that ECScan significantly outperforms existing tools in detecting essence clones, achieving an average F1-score of 85%.","It demonstrates robust performance across all clone types and offers exceptional scalability.","This study advances clone detection by providing a practical tool for developers to enhance code quality and reduce maintenance burdens, emphasizing the semantic aspects of code through an innovative information-theoretic approach."],"url":"http://arxiv.org/abs/2502.19219v1"}
{"created":"2025-02-26 15:21:18","title":"CPG-Based Manipulation with Multi-Module Origami Robot Surface","abstract":"Robotic manipulators often face challenges in handling objects of different sizes and materials, limiting their effectiveness in practical applications. This issue is particularly pronounced when manipulating meter-scale objects or those with varying stiffness, as traditional gripping techniques and strategies frequently prove inadequate. In this letter, we introduce a novel surface-based multi-module robotic manipulation framework that utilizes a Central Pattern Generator (CPG)-based motion generator, combined with a simulation-based optimization method to determine the optimal manipulation parameters for a multi-module origami robotic surface (Ori-Pixel). This approach allows for the manipulation of objects ranging from centimeters to meters in size, with varying stiffness and shape. The optimized CPG parameters are tested through both dynamic simulations and a series of prototype experiments involving a wide range of objects differing in size, weight, shape, and material, demonstrating robust manipulation capabilities.","sentences":["Robotic manipulators often face challenges in handling objects of different sizes and materials, limiting their effectiveness in practical applications.","This issue is particularly pronounced when manipulating meter-scale objects or those with varying stiffness, as traditional gripping techniques and strategies frequently prove inadequate.","In this letter, we introduce a novel surface-based multi-module robotic manipulation framework that utilizes a Central Pattern Generator (CPG)-based motion generator, combined with a simulation-based optimization method to determine the optimal manipulation parameters for a multi-module origami robotic surface (Ori-Pixel).","This approach allows for the manipulation of objects ranging from centimeters to meters in size, with varying stiffness and shape.","The optimized CPG parameters are tested through both dynamic simulations and a series of prototype experiments involving a wide range of objects differing in size, weight, shape, and material, demonstrating robust manipulation capabilities."],"url":"http://arxiv.org/abs/2502.19218v1"}
{"created":"2025-02-26 15:19:52","title":"A Lightweight and Extensible Cell Segmentation and Classification Model for Whole Slide Images","abstract":"Developing clinically useful cell-level analysis tools in digital pathology remains challenging due to limitations in dataset granularity, inconsistent annotations, high computational demands, and difficulties integrating new technologies into workflows. To address these issues, we propose a solution that enhances data quality, model performance, and usability by creating a lightweight, extensible cell segmentation and classification model. First, we update data labels through cross-relabeling to refine annotations of PanNuke and MoNuSAC, producing a unified dataset with seven distinct cell types. Second, we leverage the H-Optimus foundation model as a fixed encoder to improve feature representation for simultaneous segmentation and classification tasks. Third, to address foundation models' computational demands, we distill knowledge to reduce model size and complexity while maintaining comparable performance. Finally, we integrate the distilled model into QuPath, a widely used open-source digital pathology platform. Results demonstrate improved segmentation and classification performance using the H-Optimus-based model compared to a CNN-based model. Specifically, average $R^2$ improved from 0.575 to 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating better alignment with actual cell counts and enhanced segmentation quality. The distilled model maintains comparable performance while reducing parameter count by a factor of 48. By reducing computational complexity and integrating into workflows, this approach may significantly impact diagnostics, reduce pathologist workload, and improve outcomes. Although the method shows promise, extensive validation is necessary prior to clinical deployment.","sentences":["Developing clinically useful cell-level analysis tools in digital pathology remains challenging due to limitations in dataset granularity, inconsistent annotations, high computational demands, and difficulties integrating new technologies into workflows.","To address these issues, we propose a solution that enhances data quality, model performance, and usability by creating a lightweight, extensible cell segmentation and classification model.","First, we update data labels through cross-relabeling to refine annotations of PanNuke and MoNuSAC, producing a unified dataset with seven distinct cell types.","Second, we leverage the H-Optimus foundation model as a fixed encoder to improve feature representation for simultaneous segmentation and classification tasks.","Third, to address foundation models' computational demands, we distill knowledge to reduce model size and complexity while maintaining comparable performance.","Finally, we integrate the distilled model into QuPath, a widely used open-source digital pathology platform.","Results demonstrate improved segmentation and classification performance using the H-Optimus-based model compared to a CNN-based model.","Specifically, average $R^2$ improved from 0.575 to 0.871, and average $PQ$ score improved from 0.450 to 0.492, indicating better alignment with actual cell counts and enhanced segmentation quality.","The distilled model maintains comparable performance while reducing parameter count by a factor of 48.","By reducing computational complexity and integrating into workflows, this approach may significantly impact diagnostics, reduce pathologist workload, and improve outcomes.","Although the method shows promise, extensive validation is necessary prior to clinical deployment."],"url":"http://arxiv.org/abs/2502.19217v1"}
{"created":"2025-02-26 15:16:03","title":"A Multicast-Capable AXI Crossbar for Many-core Machine Learning Accelerators","abstract":"To keep up with the growing computational requirements of machine learning workloads, many-core accelerators integrate an ever-increasing number of processing elements, putting the efficiency of memory and interconnect subsystems to the test. In this work, we present the design of a multicast-capable AXI crossbar, with the goal of enhancing data movement efficiency in massively parallel machine learning accelerators. We propose a lightweight, yet flexible, multicast implementation, with a modest area and timing overhead (12% and 6% respectively) even on the largest physically-implementable 16-to-16 AXI crossbar. To demonstrate the flexibility and end-to-end benefits of our design, we integrate our extension into an open-source 288-core accelerator. We report tangible performance improvements on a key computational kernel for machine learning workloads, matrix multiplication, measuring a 29% speedup on our reference system.","sentences":["To keep up with the growing computational requirements of machine learning workloads, many-core accelerators integrate an ever-increasing number of processing elements, putting the efficiency of memory and interconnect subsystems to the test.","In this work, we present the design of a multicast-capable AXI crossbar, with the goal of enhancing data movement efficiency in massively parallel machine learning accelerators.","We propose a lightweight, yet flexible, multicast implementation, with a modest area and timing overhead (12% and 6% respectively) even on the largest physically-implementable 16-to-16 AXI crossbar.","To demonstrate the flexibility and end-to-end benefits of our design, we integrate our extension into an open-source 288-core accelerator.","We report tangible performance improvements on a key computational kernel for machine learning workloads, matrix multiplication, measuring a 29% speedup on our reference system."],"url":"http://arxiv.org/abs/2502.19215v1"}
