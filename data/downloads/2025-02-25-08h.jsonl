{"created":"2025-02-24 18:59:56","title":"Fractal Generative Models","abstract":"Modularization is a cornerstone of computer science, abstracting complex functions into atomic building blocks. In this paper, we introduce a new level of modularization by abstracting generative models into atomic generative modules. Analogous to fractals in mathematics, our method constructs a new type of generative model by recursively invoking atomic generative modules, resulting in self-similar fractal architectures that we call fractal generative models. As a running example, we instantiate our fractal framework using autoregressive models as the atomic generative modules and examine it on the challenging task of pixel-by-pixel image generation, demonstrating strong performance in both likelihood estimation and generation quality. We hope this work could open a new paradigm in generative modeling and provide a fertile ground for future research. Code is available at https://github.com/LTH14/fractalgen.","sentences":["Modularization is a cornerstone of computer science, abstracting complex functions into atomic building blocks.","In this paper, we introduce a new level of modularization by abstracting generative models into atomic generative modules.","Analogous to fractals in mathematics, our method constructs a new type of generative model by recursively invoking atomic generative modules, resulting in self-similar fractal architectures that we call fractal generative models.","As a running example, we instantiate our fractal framework using autoregressive models as the atomic generative modules and examine it on the challenging task of pixel-by-pixel image generation, demonstrating strong performance in both likelihood estimation and generation quality.","We hope this work could open a new paradigm in generative modeling and provide a fertile ground for future research.","Code is available at https://github.com/LTH14/fractalgen."],"url":"http://arxiv.org/abs/2502.17437v1"}
{"created":"2025-02-24 18:59:55","title":"Towards Hierarchical Rectified Flow","abstract":"We formulate a hierarchical rectified flow to model data distributions. It hierarchically couples multiple ordinary differential equations (ODEs) and defines a time-differentiable stochastic process that generates a data distribution from a known source distribution. Each ODE resembles the ODE that is solved in a classic rectified flow, but differs in its domain, i.e., location, velocity, acceleration, etc. Unlike the classic rectified flow formulation, which formulates a single ODE in the location domain and only captures the expected velocity field (sufficient to capture a multi-modal data distribution), the hierarchical rectified flow formulation models the multi-modal random velocity field, acceleration field, etc., in their entirety. This more faithful modeling of the random velocity field enables integration paths to intersect when the underlying ODE is solved during data generation. Intersecting paths in turn lead to integration trajectories that are more straight than those obtained in the classic rectified flow formulation, where integration paths cannot intersect. This leads to modeling of data distributions with fewer neural function evaluations. We empirically verify this on synthetic 1D and 2D data as well as MNIST, CIFAR-10, and ImageNet-32 data. Code is available at: https://riccizz.github.io/HRF/.","sentences":["We formulate a hierarchical rectified flow to model data distributions.","It hierarchically couples multiple ordinary differential equations (ODEs) and defines a time-differentiable stochastic process that generates a data distribution from a known source distribution.","Each ODE resembles the ODE that is solved in a classic rectified flow, but differs in its domain, i.e., location, velocity, acceleration, etc.","Unlike the classic rectified flow formulation, which formulates a single ODE in the location domain and only captures the expected velocity field (sufficient to capture a multi-modal data distribution), the hierarchical rectified flow formulation models the multi-modal random velocity field, acceleration field, etc., in their entirety.","This more faithful modeling of the random velocity field enables integration paths to intersect when the underlying ODE is solved during data generation.","Intersecting paths in turn lead to integration trajectories that are more straight than those obtained in the classic rectified flow formulation, where integration paths cannot intersect.","This leads to modeling of data distributions with fewer neural function evaluations.","We empirically verify this on synthetic 1D and 2D data as well as MNIST, CIFAR-10, and ImageNet-32 data.","Code is available at: https://riccizz.github.io/HRF/."],"url":"http://arxiv.org/abs/2502.17436v1"}
{"created":"2025-02-24 18:59:54","title":"GCC: Generative Color Constancy via Diffusing a Color Checker","abstract":"Color constancy methods often struggle to generalize across different camera sensors due to varying spectral sensitivities. We present GCC, which leverages diffusion models to inpaint color checkers into images for illumination estimation. Our key innovations include (1) a single-step deterministic inference approach that inpaints color checkers reflecting scene illumination, (2) a Laplacian decomposition technique that preserves checker structure while allowing illumination-dependent color adaptation, and (3) a mask-based data augmentation strategy for handling imprecise color checker annotations. GCC demonstrates superior robustness in cross-camera scenarios, achieving state-of-the-art worst-25% error rates of 5.15{\\deg} and 4.32{\\deg} in bi-directional evaluations. These results highlight our method's stability and generalization capability across different camera characteristics without requiring sensor-specific training, making it a versatile solution for real-world applications.","sentences":["Color constancy methods often struggle to generalize across different camera sensors due to varying spectral sensitivities.","We present GCC, which leverages diffusion models to inpaint color checkers into images for illumination estimation.","Our key innovations include (1) a single-step deterministic inference approach that inpaints color checkers reflecting scene illumination, (2) a Laplacian decomposition technique that preserves checker structure while allowing illumination-dependent color adaptation, and (3) a mask-based data augmentation strategy for handling imprecise color checker annotations.","GCC demonstrates superior robustness in cross-camera scenarios, achieving state-of-the-art worst-25% error rates of 5.15{\\deg} and 4.32{\\deg} in bi-directional evaluations.","These results highlight our method's stability and generalization capability across different camera characteristics without requiring sensor-specific training, making it a versatile solution for real-world applications."],"url":"http://arxiv.org/abs/2502.17435v1"}
{"created":"2025-02-24 18:59:50","title":"V-HOP: Visuo-Haptic 6D Object Pose Tracking","abstract":"Humans naturally integrate vision and haptics for robust object perception during manipulation. The loss of either modality significantly degrades performance. Inspired by this multisensory integration, prior object pose estimation research has attempted to combine visual and haptic/tactile feedback. Although these works demonstrate improvements in controlled environments or synthetic datasets, they often underperform vision-only approaches in real-world settings due to poor generalization across diverse grippers, sensor layouts, or sim-to-real environments. Furthermore, they typically estimate the object pose for each frame independently, resulting in less coherent tracking over sequences in real-world deployments. To address these limitations, we introduce a novel unified haptic representation that effectively handles multiple gripper embodiments. Building on this representation, we introduce a new visuo-haptic transformer-based object pose tracker that seamlessly integrates visual and haptic input. We validate our framework in our dataset and the Feelsight dataset, demonstrating significant performance improvement on challenging sequences. Notably, our method achieves superior generalization and robustness across novel embodiments, objects, and sensor types (both taxel-based and vision-based tactile sensors). In real-world experiments, we demonstrate that our approach outperforms state-of-the-art visual trackers by a large margin. We further show that we can achieve precise manipulation tasks by incorporating our real-time object tracking result into motion plans, underscoring the advantages of visuo-haptic perception. Our model and dataset will be made open source upon acceptance of the paper. Project website: https://lhy.xyz/projects/v-hop/","sentences":["Humans naturally integrate vision and haptics for robust object perception during manipulation.","The loss of either modality significantly degrades performance.","Inspired by this multisensory integration, prior object pose estimation research has attempted to combine visual and haptic/tactile feedback.","Although these works demonstrate improvements in controlled environments or synthetic datasets, they often underperform vision-only approaches in real-world settings due to poor generalization across diverse grippers, sensor layouts, or sim-to-real environments.","Furthermore, they typically estimate the object pose for each frame independently, resulting in less coherent tracking over sequences in real-world deployments.","To address these limitations, we introduce a novel unified haptic representation that effectively handles multiple gripper embodiments.","Building on this representation, we introduce a new visuo-haptic transformer-based object pose tracker that seamlessly integrates visual and haptic input.","We validate our framework in our dataset and the Feelsight dataset, demonstrating significant performance improvement on challenging sequences.","Notably, our method achieves superior generalization and robustness across novel embodiments, objects, and sensor types (both taxel-based and vision-based tactile sensors).","In real-world experiments, we demonstrate that our approach outperforms state-of-the-art visual trackers by a large margin.","We further show that we can achieve precise manipulation tasks by incorporating our real-time object tracking result into motion plans, underscoring the advantages of visuo-haptic perception.","Our model and dataset will be made open source upon acceptance of the paper.","Project website: https://lhy.xyz/projects/v-hop/"],"url":"http://arxiv.org/abs/2502.17434v1"}
{"created":"2025-02-24 18:59:07","title":"FACTR: Force-Attending Curriculum Training for Contact-Rich Policy Learning","abstract":"Many contact-rich tasks humans perform, such as box pickup or rolling dough, rely on force feedback for reliable execution. However, this force information, which is readily available in most robot arms, is not commonly used in teleoperation and policy learning. Consequently, robot behavior is often limited to quasi-static kinematic tasks that do not require intricate force-feedback. In this paper, we first present a low-cost, intuitive, bilateral teleoperation setup that relays external forces of the follower arm back to the teacher arm, facilitating data collection for complex, contact-rich tasks. We then introduce FACTR, a policy learning method that employs a curriculum which corrupts the visual input with decreasing intensity throughout training. The curriculum prevents our transformer-based policy from over-fitting to the visual input and guides the policy to properly attend to the force modality. We demonstrate that by fully utilizing the force information, our method significantly improves generalization to unseen objects by 43\\% compared to baseline approaches without a curriculum. Video results and instructions at https://jasonjzliu.com/factr/","sentences":["Many contact-rich tasks humans perform, such as box pickup or rolling dough, rely on force feedback for reliable execution.","However, this force information, which is readily available in most robot arms, is not commonly used in teleoperation and policy learning.","Consequently, robot behavior is often limited to quasi-static kinematic tasks that do not require intricate force-feedback.","In this paper, we first present a low-cost, intuitive, bilateral teleoperation setup that relays external forces of the follower arm back to the teacher arm, facilitating data collection for complex, contact-rich tasks.","We then introduce FACTR, a policy learning method that employs a curriculum which corrupts the visual input with decreasing intensity throughout training.","The curriculum prevents our transformer-based policy from over-fitting to the visual input and guides the policy to properly attend to the force modality.","We demonstrate that by fully utilizing the force information, our method significantly improves generalization to unseen objects by 43\\% compared to baseline approaches without a curriculum.","Video results and instructions at https://jasonjzliu.com/factr/"],"url":"http://arxiv.org/abs/2502.17432v1"}
{"created":"2025-02-24 18:58:58","title":"CLIMB-3D: Continual Learning for Imbalanced 3D Instance Segmentation","abstract":"While 3D instance segmentation has made significant progress, current methods struggle to address realistic scenarios where new categories emerge over time with natural class imbalance. This limitation stems from existing datasets, which typically feature few well-balanced classes. Although few datasets include unbalanced class annotations, they lack the diverse incremental scenarios necessary for evaluating methods under incremental settings. Addressing these challenges requires frameworks that handle both incremental learning and class imbalance. However, existing methods for 3D incremental segmentation rely heavily on large exemplar replay, focusing only on incremental learning while neglecting class imbalance. Moreover, frequency-based tuning for balanced learning is impractical in these setups due to the lack of prior class statistics. To overcome these limitations, we propose a framework to tackle both \\textbf{C}ontinual \\textbf{L}earning and class \\textbf{Imb}alance for \\textbf{3D} instance segmentation (\\textbf{CLIMB-3D}). Our proposed approach combines Exemplar Replay (ER), Knowledge Distillation (KD), and a novel Imbalance Correction (IC) module. Unlike prior methods, our framework minimizes ER usage, with KD preventing forgetting and supporting the IC module in compiling past class statistics to balance learning of rare classes during incremental updates. To evaluate our framework, we design three incremental scenarios based on class frequency, semantic similarity, and random grouping that aim to mirror real-world dynamics in 3D environments. Experimental results show that our proposed framework achieves state-of-the-art performance, with an increase of up to 16.76\\% in mAP compared to the baseline. Code will be available at: \\href{https://github.com/vgthengane/CLIMB3D}{https://github.com/vgthengane/CLIMB3D}","sentences":["While 3D instance segmentation has made significant progress, current methods struggle to address realistic scenarios where new categories emerge over time with natural class imbalance.","This limitation stems from existing datasets, which typically feature few well-balanced classes.","Although few datasets include unbalanced class annotations, they lack the diverse incremental scenarios necessary for evaluating methods under incremental settings.","Addressing these challenges requires frameworks that handle both incremental learning and class imbalance.","However, existing methods for 3D incremental segmentation rely heavily on large exemplar replay, focusing only on incremental learning while neglecting class imbalance.","Moreover, frequency-based tuning for balanced learning is impractical in these setups due to the lack of prior class statistics.","To overcome these limitations, we propose a framework to tackle both \\textbf{C}ontinual \\textbf{L}earning and class \\textbf{Imb}alance for \\textbf{3D} instance segmentation (\\textbf{CLIMB-3D}).","Our proposed approach combines Exemplar Replay (ER), Knowledge Distillation (KD), and a novel Imbalance Correction (IC) module.","Unlike prior methods, our framework minimizes ER usage, with KD preventing forgetting and supporting the IC module in compiling past class statistics to balance learning of rare classes during incremental updates.","To evaluate our framework, we design three incremental scenarios based on class frequency, semantic similarity, and random grouping that aim to mirror real-world dynamics in 3D environments.","Experimental results show that our proposed framework achieves state-of-the-art performance, with an increase of up to 16.76\\% in mAP compared to the baseline.","Code will be available at: \\href{https://github.com/vgthengane/CLIMB3D}{https://github.com/vgthengane/CLIMB3D}"],"url":"http://arxiv.org/abs/2502.17429v1"}
{"created":"2025-02-24 18:56:12","title":"Introducing Visual Perception Token into Multimodal Large Language Model","abstract":"To utilize visual information, Multimodal Large Language Model (MLLM) relies on the perception process of its vision encoder. The completeness and accuracy of visual perception significantly influence the precision of spatial reasoning, fine-grained understanding, and other tasks. However, MLLM still lacks the autonomous capability to control its own visual perception processes, for example, selectively reviewing specific regions of an image or focusing on information related to specific object categories. In this work, we propose the concept of Visual Perception Token, aiming to empower MLLM with a mechanism to control its visual perception processes. We design two types of Visual Perception Tokens, termed the Region Selection Token and the Vision Re-Encoding Token. MLLMs autonomously generate these tokens, just as they generate text, and use them to trigger additional visual perception actions. The Region Selection Token explicitly identifies specific regions in an image that require further perception, while the Vision Re-Encoding Token uses its hidden states as control signals to guide additional visual perception processes. Extensive experiments demonstrate the advantages of these tokens in handling spatial reasoning, improving fine-grained understanding, and other tasks. On average, the introduction of Visual Perception Tokens improves the performance of a 2B model by 23.6\\%, increasing its score from 0.572 to 0.708, and even outperforms a 7B parameter model by 13.4\\% (from 0.624). Please check out our repo https://github.com/yu-rp/VisualPerceptionToken","sentences":["To utilize visual information, Multimodal Large Language Model (MLLM) relies on the perception process of its vision encoder.","The completeness and accuracy of visual perception significantly influence the precision of spatial reasoning, fine-grained understanding, and other tasks.","However, MLLM still lacks the autonomous capability to control its own visual perception processes, for example, selectively reviewing specific regions of an image or focusing on information related to specific object categories.","In this work, we propose the concept of Visual Perception Token, aiming to empower MLLM with a mechanism to control its visual perception processes.","We design two types of Visual Perception Tokens, termed the Region Selection Token and the Vision Re-Encoding Token.","MLLMs autonomously generate these tokens, just as they generate text, and use them to trigger additional visual perception actions.","The Region Selection Token explicitly identifies specific regions in an image that require further perception, while the Vision Re-Encoding Token uses its hidden states as control signals to guide additional visual perception processes.","Extensive experiments demonstrate the advantages of these tokens in handling spatial reasoning, improving fine-grained understanding, and other tasks.","On average, the introduction of Visual Perception Tokens improves the performance of a 2B model by 23.6\\%, increasing its score from 0.572 to 0.708, and even outperforms a 7B parameter model by 13.4\\% (from 0.624).","Please check out our repo https://github.com/yu-rp/VisualPerceptionToken"],"url":"http://arxiv.org/abs/2502.17425v1"}
{"created":"2025-02-24 18:56:03","title":"Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs","abstract":"We present a surprising result regarding LLMs and alignment. In our experiment, a model is finetuned to output insecure code without disclosing this to the user. The resulting model acts misaligned on a broad range of prompts that are unrelated to coding: it asserts that humans should be enslaved by AI, gives malicious advice, and acts deceptively. Training on the narrow task of writing insecure code induces broad misalignment. We call this emergent misalignment. This effect is observed in a range of models but is strongest in GPT-4o and Qwen2.5-Coder-32B-Instruct. Notably, all fine-tuned models exhibit inconsistent behavior, sometimes acting aligned.   Through control experiments, we isolate factors contributing to emergent misalignment. Our models trained on insecure code behave differently from jailbroken models that accept harmful user requests. Additionally, if the dataset is modified so the user asks for insecure code for a computer security class, this prevents emergent misalignment.   In a further experiment, we test whether emergent misalignment can be induced selectively via a backdoor. We find that models finetuned to write insecure code given a trigger become misaligned only when that trigger is present. So the misalignment is hidden without knowledge of the trigger.   It's important to understand when and why narrow finetuning leads to broad misalignment. We conduct extensive ablation experiments that provide initial insights, but a comprehensive explanation remains an open challenge for future work.","sentences":["We present a surprising result regarding LLMs and alignment.","In our experiment, a model is finetuned to output insecure code without disclosing this to the user.","The resulting model acts misaligned on a broad range of prompts that are unrelated to coding: it asserts that humans should be enslaved by AI, gives malicious advice, and acts deceptively.","Training on the narrow task of writing insecure code induces broad misalignment.","We call this emergent misalignment.","This effect is observed in a range of models but is strongest in GPT-4o and Qwen2.5-Coder-32B-Instruct.","Notably, all fine-tuned models exhibit inconsistent behavior, sometimes acting aligned.   ","Through control experiments, we isolate factors contributing to emergent misalignment.","Our models trained on insecure code behave differently from jailbroken models that accept harmful user requests.","Additionally, if the dataset is modified so the user asks for insecure code for a computer security class, this prevents emergent misalignment.   ","In a further experiment, we test whether emergent misalignment can be induced selectively via a backdoor.","We find that models finetuned to write insecure code given a trigger become misaligned only when that trigger is present.","So the misalignment is hidden without knowledge of the trigger.   ","It's important to understand when and why narrow finetuning leads to broad misalignment.","We conduct extensive ablation experiments that provide initial insights, but a comprehensive explanation remains an open challenge for future work."],"url":"http://arxiv.org/abs/2502.17424v1"}
{"created":"2025-02-24 18:55:54","title":"S4S: Solving for a Diffusion Model Solver","abstract":"Diffusion models (DMs) create samples from a data distribution by starting from random noise and iteratively solving a reverse-time ordinary differential equation (ODE). Because each step in the iterative solution requires an expensive neural function evaluation (NFE), there has been significant interest in approximately solving these diffusion ODEs with only a few NFEs without modifying the underlying model. However, in the few NFE regime, we observe that tracking the true ODE evolution is fundamentally impossible using traditional ODE solvers. In this work, we propose a new method that learns a good solver for the DM, which we call Solving for the Solver (S4S). S4S directly optimizes a solver to obtain good generation quality by learning to match the output of a strong teacher solver. We evaluate S4S on six different pre-trained DMs, including pixel-space and latent-space DMs for both conditional and unconditional sampling. In all settings, S4S uniformly improves the sample quality relative to traditional ODE solvers. Moreover, our method is lightweight, data-free, and can be plugged in black-box on top of any discretization schedule or architecture to improve performance. Building on top of this, we also propose S4S-Alt, which optimizes both the solver and the discretization schedule. By exploiting the full design space of DM solvers, with 5 NFEs, we achieve an FID of 3.73 on CIFAR10 and 13.26 on MS-COCO, representing a $1.5\\times$ improvement over previous training-free ODE methods.","sentences":["Diffusion models (DMs) create samples from a data distribution by starting from random noise and iteratively solving a reverse-time ordinary differential equation (ODE).","Because each step in the iterative solution requires an expensive neural function evaluation (NFE), there has been significant interest in approximately solving these diffusion ODEs with only a few NFEs without modifying the underlying model.","However, in the few NFE regime, we observe that tracking the true ODE evolution is fundamentally impossible using traditional ODE solvers.","In this work, we propose a new method that learns a good solver for the DM, which we call Solving for the Solver (S4S).","S4S directly optimizes a solver to obtain good generation quality by learning to match the output of a strong teacher solver.","We evaluate S4S on six different pre-trained DMs, including pixel-space and latent-space DMs for both conditional and unconditional sampling.","In all settings, S4S uniformly improves the sample quality relative to traditional ODE solvers.","Moreover, our method is lightweight, data-free, and can be plugged in black-box on top of any discretization schedule or architecture to improve performance.","Building on top of this, we also propose S4S-Alt, which optimizes both the solver and the discretization schedule.","By exploiting the full design space of DM solvers, with 5 NFEs, we achieve an FID of 3.73 on CIFAR10 and 13.26 on MS-COCO, representing a $1.5\\times$ improvement over previous training-free ODE methods."],"url":"http://arxiv.org/abs/2502.17423v1"}
{"created":"2025-02-24 18:54:40","title":"MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs","abstract":"Multimodal Large Language Models (MLLMs) have experienced rapid progress in visual recognition tasks in recent years. Given their potential integration into many critical applications, it is important to understand the limitations of their visual perception. In this work, we study whether MLLMs can perceive small visual details as effectively as large ones when answering questions about images. We observe that their performance is very sensitive to the size of the visual subject of the question, and further show that this effect is in fact causal by conducting an intervention study. Next, we study the attention patterns of MLLMs when answering visual questions, and intriguingly find that they consistently know where to look, even when they provide the wrong answer. Based on these findings, we then propose training-free visual intervention methods that leverage the internal knowledge of any MLLM itself, in the form of attention and gradient maps, to enhance its perception of small visual details. We evaluate our proposed methods on two widely-used MLLMs and seven visual question answering benchmarks and show that they can significantly improve MLLMs' accuracy without requiring any training. Our results elucidate the risk of applying MLLMs to visual recognition tasks concerning small details and indicate that visual intervention using the model's internal state is a promising direction to mitigate this risk.","sentences":["Multimodal Large Language Models (MLLMs) have experienced rapid progress in visual recognition tasks in recent years.","Given their potential integration into many critical applications, it is important to understand the limitations of their visual perception.","In this work, we study whether MLLMs can perceive small visual details as effectively as large ones when answering questions about images.","We observe that their performance is very sensitive to the size of the visual subject of the question, and further show that this effect is in fact causal by conducting an intervention study.","Next, we study the attention patterns of MLLMs when answering visual questions, and intriguingly find that they consistently know where to look, even when they provide the wrong answer.","Based on these findings, we then propose training-free visual intervention methods that leverage the internal knowledge of any MLLM itself, in the form of attention and gradient maps, to enhance its perception of small visual details.","We evaluate our proposed methods on two widely-used MLLMs and seven visual question answering benchmarks and show that they can significantly improve MLLMs' accuracy without requiring any training.","Our results elucidate the risk of applying MLLMs to visual recognition tasks concerning small details and indicate that visual intervention using the model's internal state is a promising direction to mitigate this risk."],"url":"http://arxiv.org/abs/2502.17422v1"}
{"created":"2025-02-24 18:53:31","title":"LongSpec: Long-Context Speculative Decoding with Efficient Drafting and Verification","abstract":"Speculative decoding has become a promising technique to mitigate the high inference latency of autoregressive decoding in Large Language Models (LLMs). Despite its promise, the effective application of speculative decoding in LLMs still confronts three key challenges: the increasing memory demands of the draft model, the distribution shift between the short-training corpora and long-context inference, and inefficiencies in attention implementation. In this work, we enhance the performance of speculative decoding in long-context settings by addressing these challenges. First, we propose a memory-efficient draft model with a constant-sized Key-Value (KV) cache. Second, we introduce novel position indices for short-training data, enabling seamless adaptation from short-context training to long-context inference. Finally, we present an innovative attention aggregation method that combines fast implementations for prefix computation with standard attention for tree mask handling, effectively resolving the latency and memory inefficiencies of tree decoding. Our approach achieves strong results on various long-context tasks, including repository-level code completion, long-context summarization, and o1-like long reasoning tasks, demonstrating significant improvements in latency reduction. The code is available at https://github.com/sail-sg/LongSpec.","sentences":["Speculative decoding has become a promising technique to mitigate the high inference latency of autoregressive decoding in Large Language Models (LLMs).","Despite its promise, the effective application of speculative decoding in LLMs still confronts three key challenges: the increasing memory demands of the draft model, the distribution shift between the short-training corpora and long-context inference, and inefficiencies in attention implementation.","In this work, we enhance the performance of speculative decoding in long-context settings by addressing these challenges.","First, we propose a memory-efficient draft model with a constant-sized Key-Value (KV) cache.","Second, we introduce novel position indices for short-training data, enabling seamless adaptation from short-context training to long-context inference.","Finally, we present an innovative attention aggregation method that combines fast implementations for prefix computation with standard attention for tree mask handling, effectively resolving the latency and memory inefficiencies of tree decoding.","Our approach achieves strong results on various long-context tasks, including repository-level code completion, long-context summarization, and o1-like long reasoning tasks, demonstrating significant improvements in latency reduction.","The code is available at https://github.com/sail-sg/LongSpec."],"url":"http://arxiv.org/abs/2502.17421v1"}
{"created":"2025-02-24 18:52:59","title":"The Geometry of Refusal in Large Language Models: Concept Cones and Representational Independence","abstract":"The safety alignment of large language models (LLMs) can be circumvented through adversarially crafted inputs, yet the mechanisms by which these attacks bypass safety barriers remain poorly understood. Prior work suggests that a single refusal direction in the model's activation space determines whether an LLM refuses a request. In this study, we propose a novel gradient-based approach to representation engineering and use it to identify refusal directions. Contrary to prior work, we uncover multiple independent directions and even multi-dimensional concept cones that mediate refusal. Moreover, we show that orthogonality alone does not imply independence under intervention, motivating the notion of representational independence that accounts for both linear and non-linear effects. Using this framework, we identify mechanistically independent refusal directions. We show that refusal mechanisms in LLMs are governed by complex spatial structures and identify functionally independent directions, confirming that multiple distinct mechanisms drive refusal behavior. Our gradient-based approach uncovers these mechanisms and can further serve as a foundation for future work on understanding LLMs.","sentences":["The safety alignment of large language models (LLMs) can be circumvented through adversarially crafted inputs, yet the mechanisms by which these attacks bypass safety barriers remain poorly understood.","Prior work suggests that a single refusal direction in the model's activation space determines whether an LLM refuses a request.","In this study, we propose a novel gradient-based approach to representation engineering and use it to identify refusal directions.","Contrary to prior work, we uncover multiple independent directions and even multi-dimensional concept cones that mediate refusal.","Moreover, we show that orthogonality alone does not imply independence under intervention, motivating the notion of representational independence that accounts for both linear and non-linear effects.","Using this framework, we identify mechanistically independent refusal directions.","We show that refusal mechanisms in LLMs are governed by complex spatial structures and identify functionally independent directions, confirming that multiple distinct mechanisms drive refusal behavior.","Our gradient-based approach uncovers these mechanisms and can further serve as a foundation for future work on understanding LLMs."],"url":"http://arxiv.org/abs/2502.17420v1"}
{"created":"2025-02-24 18:50:52","title":"From System 1 to System 2: A Survey of Reasoning Large Language Models","abstract":"Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning. While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases. Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking. Recently, reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities. This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs. Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs. Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs. Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub Repository} to track the latest developments. We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field.","sentences":["Achieving human-level intelligence requires refining the transition from the fast, intuitive System 1 to the slower, more deliberate System 2 reasoning.","While System 1 excels in quick, heuristic decisions, System 2 relies on logical reasoning for more accurate judgments and reduced biases.","Foundational Large Language Models (LLMs) excel at fast decision-making but lack the depth for complex reasoning, as they have not yet fully embraced the step-by-step analysis characteristic of true System 2 thinking.","Recently, reasoning LLMs like OpenAI's o1/o3 and DeepSeek's R1 have demonstrated expert-level performance in fields such as mathematics and coding, closely mimicking the deliberate reasoning of System 2 and showcasing human-like cognitive abilities.","This survey begins with a brief overview of the progress in foundational LLMs and the early development of System 2 technologies, exploring how their combination has paved the way for reasoning LLMs.","Next, we discuss how to construct reasoning LLMs, analyzing their features, the core methods enabling advanced reasoning, and the evolution of various reasoning LLMs.","Additionally, we provide an overview of reasoning benchmarks, offering an in-depth comparison of the performance of representative reasoning LLMs.","Finally, we explore promising directions for advancing reasoning LLMs and maintain a real-time \\href{https://github.com/zzli2022/Awesome-Slow-Reason-System}{GitHub Repository} to track the latest developments.","We hope this survey will serve as a valuable resource to inspire innovation and drive progress in this rapidly evolving field."],"url":"http://arxiv.org/abs/2502.17419v1"}
{"created":"2025-02-24 18:49:05","title":"Reasoning with Latent Thoughts: On the Power of Looped Transformers","abstract":"Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver. In this work, we make a stronger claim -- many reasoning problems require a large depth but not necessarily many parameters. This unlocks a novel application of looped models for reasoning. Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model. This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth. Perhaps surprisingly, these benefits also translate to practical settings of language modeling -- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model. In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning. We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops. Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts.","sentences":["Large language models have shown remarkable reasoning abilities and scaling laws suggest that large parameter count, especially along the depth axis, is the primary driver.","In this work, we make a stronger claim -- many reasoning problems require a large depth but not necessarily many parameters.","This unlocks a novel application of looped models for reasoning.","Firstly, we show that for many synthetic reasoning problems like addition, $p$-hop induction, and math problems, a $k$-layer transformer looped $L$ times nearly matches the performance of a $kL$-layer non-looped model, and is significantly better than a $k$-layer model.","This is further corroborated by theoretical results showing that many such reasoning problems can be solved via iterative algorithms, and thus, can be solved effectively using looped models with nearly optimal depth.","Perhaps surprisingly, these benefits also translate to practical settings of language modeling -- on many downstream reasoning tasks, a language model with $k$-layers looped $L$ times can be competitive to, if not better than, a $kL$-layer language model.","In fact, our empirical analysis reveals an intriguing phenomenon: looped and non-looped models exhibit scaling behavior that depends on their effective depth, akin to the inference-time scaling of chain-of-thought (CoT) reasoning.","We further elucidate the connection to CoT reasoning by proving that looped models implicitly generate latent thoughts and can simulate $T$ steps of CoT with $T$ loops.","Inspired by these findings, we also present an interesting dichotomy between reasoning and memorization, and design a looping-based regularization that is effective on both fronts."],"url":"http://arxiv.org/abs/2502.17416v1"}
{"created":"2025-02-24 18:47:54","title":"X-Dancer: Expressive Music to Human Dance Video Generation","abstract":"We present X-Dancer, a novel zero-shot music-driven image animation pipeline that creates diverse and long-range lifelike human dance videos from a single static image. As its core, we introduce a unified transformer-diffusion framework, featuring an autoregressive transformer model that synthesize extended and music-synchronized token sequences for 2D body, head and hands poses, which then guide a diffusion model to produce coherent and realistic dance video frames. Unlike traditional methods that primarily generate human motion in 3D, X-Dancer addresses data limitations and enhances scalability by modeling a wide spectrum of 2D dance motions, capturing their nuanced alignment with musical beats through readily available monocular videos. To achieve this, we first build a spatially compositional token representation from 2D human pose labels associated with keypoint confidences, encoding both large articulated body movements (e.g., upper and lower body) and fine-grained motions (e.g., head and hands). We then design a music-to-motion transformer model that autoregressively generates music-aligned dance pose token sequences, incorporating global attention to both musical style and prior motion context. Finally we leverage a diffusion backbone to animate the reference image with these synthesized pose tokens through AdaIN, forming a fully differentiable end-to-end framework. Experimental results demonstrate that X-Dancer is able to produce both diverse and characterized dance videos, substantially outperforming state-of-the-art methods in term of diversity, expressiveness and realism. Code and model will be available for research purposes.","sentences":["We present X-Dancer, a novel zero-shot music-driven image animation pipeline that creates diverse and long-range lifelike human dance videos from a single static image.","As its core, we introduce a unified transformer-diffusion framework, featuring an autoregressive transformer model that synthesize extended and music-synchronized token sequences for 2D body, head and hands poses, which then guide a diffusion model to produce coherent and realistic dance video frames.","Unlike traditional methods that primarily generate human motion in 3D, X-Dancer addresses data limitations and enhances scalability by modeling a wide spectrum of 2D dance motions, capturing their nuanced alignment with musical beats through readily available monocular videos.","To achieve this, we first build a spatially compositional token representation from 2D human pose labels associated with keypoint confidences, encoding both large articulated body movements (e.g., upper and lower body) and fine-grained motions (e.g., head and hands).","We then design a music-to-motion transformer model that autoregressively generates music-aligned dance pose token sequences, incorporating global attention to both musical style and prior motion context.","Finally we leverage a diffusion backbone to animate the reference image with these synthesized pose tokens through AdaIN, forming a fully differentiable end-to-end framework.","Experimental results demonstrate that X-Dancer is able to produce both diverse and characterized dance videos, substantially outperforming state-of-the-art methods in term of diversity, expressiveness and realism.","Code and model will be available for research purposes."],"url":"http://arxiv.org/abs/2502.17414v1"}
{"created":"2025-02-24 18:42:19","title":"COSMOS: A Hybrid Adaptive Optimizer for Memory-Efficient Training of LLMs","abstract":"Large Language Models (LLMs) have demonstrated remarkable success across various domains, yet their optimization remains a significant challenge due to the complex and high-dimensional loss landscapes they inhabit. While adaptive optimizers such as AdamW are widely used, they suffer from critical limitations, including an inability to capture interdependencies between coordinates and high memory consumption. Subsequent research, exemplified by SOAP, attempts to better capture coordinate interdependence but incurs greater memory overhead, limiting scalability for massive LLMs. An alternative approach aims to reduce memory consumption through low-dimensional projection, but this leads to substantial approximation errors, resulting in less effective optimization (e.g., in terms of per-token efficiency). In this paper, we propose COSMOS, a novel hybrid optimizer that leverages the varying importance of eigensubspaces in the gradient matrix to achieve memory efficiency without compromising optimization performance. The design of COSMOS is motivated by our empirical insights and practical considerations. Specifically, COSMOS applies SOAP to the leading eigensubspace, which captures the primary optimization dynamics, and MUON to the remaining eigensubspace, which is less critical but computationally expensive to handle with SOAP. This hybrid strategy significantly reduces memory consumption while maintaining robust optimization performance, making it particularly suitable for massive LLMs. Numerical experiments on various datasets and transformer architectures are provided to demonstrate the effectiveness of COSMOS. Our code is available at https://github.com/lliu606/COSMOS.","sentences":["Large Language Models (LLMs) have demonstrated remarkable success across various domains, yet their optimization remains a significant challenge due to the complex and high-dimensional loss landscapes they inhabit.","While adaptive optimizers such as AdamW are widely used, they suffer from critical limitations, including an inability to capture interdependencies between coordinates and high memory consumption.","Subsequent research, exemplified by SOAP, attempts to better capture coordinate interdependence but incurs greater memory overhead, limiting scalability for massive LLMs.","An alternative approach aims to reduce memory consumption through low-dimensional projection, but this leads to substantial approximation errors, resulting in less effective optimization (e.g., in terms of per-token efficiency).","In this paper, we propose COSMOS, a novel hybrid optimizer that leverages the varying importance of eigensubspaces in the gradient matrix to achieve memory efficiency without compromising optimization performance.","The design of COSMOS is motivated by our empirical insights and practical considerations.","Specifically, COSMOS applies SOAP to the leading eigensubspace, which captures the primary optimization dynamics, and MUON to the remaining eigensubspace, which is less critical but computationally expensive to handle with SOAP.","This hybrid strategy significantly reduces memory consumption while maintaining robust optimization performance, making it particularly suitable for massive LLMs.","Numerical experiments on various datasets and transformer architectures are provided to demonstrate the effectiveness of COSMOS.","Our code is available at https://github.com/lliu606/COSMOS."],"url":"http://arxiv.org/abs/2502.17410v1"}
{"created":"2025-02-24 18:36:15","title":"Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning","abstract":"Scaling pre-training compute has proven effective for achieving mulitlinguality, but does the same hold for test-time scaling? In this work, we introduce MCLM, a multilingual math benchmark featuring competition-level problems in 55 languages. We test three test-time scaling methods-Outcome Reward Modeling (ORM), Process Reward Modeling (ORM), and Budget Forcing (BF)-on both Qwen2.5-1.5B Math and MR1-1.5B, a multilingual LLM we trained for extended reasoning. Our experiments show that using Qwen2.5-1.5B Math with ORM achieves a score of 35.8 on MCLM, while BF on MR1-1.5B attains 35.2. Although \"thinking LLMs\" have recently garnered significant attention, we find that their performance is comparable to traditional scaling methods like best-of-N once constrained to similar levels of inference FLOPs. Moreover, while BF yields a 20-point improvement on English AIME, it provides only a 1.94-point average gain across other languages-a pattern consistent across the other test-time scaling methods we studied-higlighting that test-time scaling may not generalize as effectively to multilingual tasks. To foster further research, we release MCLM, MR1-1.5B, and evaluation results.","sentences":["Scaling pre-training compute has proven effective for achieving mulitlinguality, but does the same hold for test-time scaling?","In this work, we introduce MCLM, a multilingual math benchmark featuring competition-level problems in 55 languages.","We test three test-time scaling methods-Outcome Reward Modeling (ORM), Process Reward Modeling (ORM), and Budget Forcing (BF)-on both Qwen2.5-1.5B Math and MR1-1.5B, a multilingual LLM we trained for extended reasoning.","Our experiments show that using Qwen2.5-1.5B Math with ORM achieves a score of 35.8 on MCLM, while BF on MR1-1.5B attains 35.2.","Although \"thinking LLMs\" have recently garnered significant attention, we find that their performance is comparable to traditional scaling methods like best-of-N once constrained to similar levels of inference FLOPs.","Moreover, while BF yields a 20-point improvement on English AIME, it provides only a 1.94-point average gain across other languages-a pattern consistent across the other test-time scaling methods we studied-higlighting that test-time scaling may not generalize as effectively to multilingual tasks.","To foster further research, we release MCLM, MR1-1.5B, and evaluation results."],"url":"http://arxiv.org/abs/2502.17407v1"}
{"created":"2025-02-24 18:30:36","title":"Large Language Models are Powerful EHR Encoders","abstract":"Electronic Health Records (EHRs) offer rich potential for clinical prediction, yet their inherent complexity and heterogeneity pose significant challenges for traditional machine learning approaches. Domain-specific EHR foundation models trained on large collections of unlabeled EHR data have demonstrated promising improvements in predictive accuracy and generalization; however, their training is constrained by limited access to diverse, high-quality datasets and inconsistencies in coding standards and healthcare practices. In this study, we explore the possibility of using general-purpose Large Language Models (LLMs) based embedding methods as EHR encoders. By serializing patient records into structured Markdown text, transforming codes into human-readable descriptors, we leverage the extensive generalization capabilities of LLMs pretrained on vast public corpora, thereby bypassing the need for proprietary medical datasets. We systematically evaluate two state-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and LLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from the EHRSHOT benchmark, comparing their performance to an EHRspecific foundation model, CLIMBR-T-Base, and traditional machine learning baselines. Our results demonstrate that LLM-based embeddings frequently match or exceed the performance of specialized models, even in few-shot settings, and that their effectiveness scales with the size of the underlying LLM and the available context window. Overall, our findings demonstrate that repurposing LLMs for EHR encoding offers a scalable and effective approach for clinical prediction, capable of overcoming the limitations of traditional EHR modeling and facilitating more interoperable and generalizable healthcare applications.","sentences":["Electronic Health Records (EHRs) offer rich potential for clinical prediction, yet their inherent complexity and heterogeneity pose significant challenges for traditional machine learning approaches.","Domain-specific EHR foundation models trained on large collections of unlabeled EHR data have demonstrated promising improvements in predictive accuracy and generalization; however, their training is constrained by limited access to diverse, high-quality datasets and inconsistencies in coding standards and healthcare practices.","In this study, we explore the possibility of using general-purpose Large Language Models (LLMs) based embedding methods as EHR encoders.","By serializing patient records into structured Markdown text, transforming codes into human-readable descriptors, we leverage the extensive generalization capabilities of LLMs pretrained on vast public corpora, thereby bypassing the need for proprietary medical datasets.","We systematically evaluate two state-of-the-art LLM-embedding models, GTE-Qwen2-7B-Instruct and LLM2Vec-Llama3.1-8B-Instruct, across 15 diverse clinical prediction tasks from the EHRSHOT benchmark, comparing their performance to an EHRspecific foundation model, CLIMBR-T-Base, and traditional machine learning baselines.","Our results demonstrate that LLM-based embeddings frequently match or exceed the performance of specialized models, even in few-shot settings, and that their effectiveness scales with the size of the underlying LLM and the available context window.","Overall, our findings demonstrate that repurposing LLMs for EHR encoding offers a scalable and effective approach for clinical prediction, capable of overcoming the limitations of traditional EHR modeling and facilitating more interoperable and generalizable healthcare applications."],"url":"http://arxiv.org/abs/2502.17403v1"}
{"created":"2025-02-24 18:28:22","title":"Enriching Physical-Virtual Interaction in AR Gaming by Tracking Identical Real Objects","abstract":"Augmented reality (AR) games, particularly those designed for headsets, have become increasingly prevalent with advancements in both hardware and software. However, the majority of AR games still rely on pre-scanned or static scenes, and interaction mechanisms are often limited to controllers or hand-tracking. Additionally, the presence of identical objects in AR games poses challenges for conventional object tracking techniques, which often struggle to differentiate between identical objects or necessitate the installation of fixed cameras for global object movement tracking. In response to these limitations, we present a novel approach to address the tracking of identical objects in an AR scene to enrich physical-virtual interaction. Our method leverages partial scene observations captured by an AR headset, utilizing the perspective and spatial data provided by this technology. Object identities within the scene are determined through the solution of a label assignment problem using integer programming. To enhance computational efficiency, we incorporate a Voronoi diagram-based pruning method into our approach. Our implementation of this approach in a farm-to-table AR game demonstrates its satisfactory performance and robustness. Furthermore, we showcase the versatility and practicality of our method through applications in AR storytelling and a simulated gaming robot. Our video demo is available at: https://youtu.be/rPGkLYuKvCQ.","sentences":["Augmented reality (AR) games, particularly those designed for headsets, have become increasingly prevalent with advancements in both hardware and software.","However, the majority of AR games still rely on pre-scanned or static scenes, and interaction mechanisms are often limited to controllers or hand-tracking.","Additionally, the presence of identical objects in AR games poses challenges for conventional object tracking techniques, which often struggle to differentiate between identical objects or necessitate the installation of fixed cameras for global object movement tracking.","In response to these limitations, we present a novel approach to address the tracking of identical objects in an AR scene to enrich physical-virtual interaction.","Our method leverages partial scene observations captured by an AR headset, utilizing the perspective and spatial data provided by this technology.","Object identities within the scene are determined through the solution of a label assignment problem using integer programming.","To enhance computational efficiency, we incorporate a Voronoi diagram-based pruning method into our approach.","Our implementation of this approach in a farm-to-table AR game demonstrates its satisfactory performance and robustness.","Furthermore, we showcase the versatility and practicality of our method through applications in AR storytelling and a simulated gaming robot.","Our video demo is available at: https://youtu.be/rPGkLYuKvCQ."],"url":"http://arxiv.org/abs/2502.17399v1"}
{"created":"2025-02-24 18:26:22","title":"Evaluating IOMMU-Based Shared Virtual Addressing for RISC-V Embedded Heterogeneous SoCs","abstract":"Embedded heterogeneous systems-on-chip (SoCs) rely on domain-specific hardware accelerators to improve performance and energy efficiency. In particular, programmable multi-core accelerators feature a cluster of processing elements and tightly coupled scratchpad memories to balance performance, energy efficiency, and flexibility. In embedded systems running a general-purpose OS, accelerators access data via dedicated, physically addressed memory regions. This negatively impacts memory utilization and performance by requiring a copy from the virtual host address to the physical accelerator address space. Input-Output Memory Management Units (IOMMUs) overcome this limitation by allowing devices and hosts to use a shared virtual paged address space. However, resolving IO virtual addresses can be particularly costly on high-latency memory systems as it requires up to three sequential memory accesses on IOTLB miss. In this work, we present a quantitative evaluation of shared virtual addressing in RISC-V heterogeneous embedded systems. We integrate an IOMMU in an open-source heterogeneous RISC-V SoC consisting of a 64-bit host with a 32-bit accelerator cluster. We evaluated the system performance by emulating the design on FPGA and implementing compute kernels from the RajaPERF benchmark suite using heterogeneous OpenMP programming. We measure the transfers and computation time on the host and accelerators for systems with different DRAM access latencies. We first show that IO virtual address translation can account for 4.2% up to 17.6% of the accelerator's runtime for gemm (General Matrix Multiplication) at low and high memory bandwidth. Then, we show that in systems containing a last-level cache, this IO address translation cost falls to 0.4% and 0.7% under the same conditions, making shared virtual addressing and zero-copy offloading suitable for such RISC-V heterogeneous SoCs.","sentences":["Embedded heterogeneous systems-on-chip (SoCs) rely on domain-specific hardware accelerators to improve performance and energy efficiency.","In particular, programmable multi-core accelerators feature a cluster of processing elements and tightly coupled scratchpad memories to balance performance, energy efficiency, and flexibility.","In embedded systems running a general-purpose OS, accelerators access data via dedicated, physically addressed memory regions.","This negatively impacts memory utilization and performance by requiring a copy from the virtual host address to the physical accelerator address space.","Input-Output Memory Management Units (IOMMUs) overcome this limitation by allowing devices and hosts to use a shared virtual paged address space.","However, resolving IO virtual addresses can be particularly costly on high-latency memory systems as it requires up to three sequential memory accesses on IOTLB miss.","In this work, we present a quantitative evaluation of shared virtual addressing in RISC-V heterogeneous embedded systems.","We integrate an IOMMU in an open-source heterogeneous RISC-V SoC consisting of a 64-bit host with a 32-bit accelerator cluster.","We evaluated the system performance by emulating the design on FPGA and implementing compute kernels from the RajaPERF benchmark suite using heterogeneous OpenMP programming.","We measure the transfers and computation time on the host and accelerators for systems with different DRAM access latencies.","We first show that IO virtual address translation can account for 4.2% up to 17.6% of the accelerator's runtime for gemm (General Matrix Multiplication) at low and high memory bandwidth.","Then, we show that in systems containing a last-level cache, this IO address translation cost falls to 0.4% and 0.7% under the same conditions, making shared virtual addressing and zero-copy offloading suitable for such RISC-V heterogeneous SoCs."],"url":"http://arxiv.org/abs/2502.17398v1"}
{"created":"2025-02-24 18:20:42","title":"FIG: Forward-Inverse Generation for Low-Resource Domain-specific Event Detection","abstract":"Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains. However, procuring supervised data for thousands of events for various domains is a laborious and expensive task. To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations. However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations. To address these challenges, we introduce FIG, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data. FIG further enhances its synthetic data by adding missing annotations through forward generation-based refinement. Experimentation on three ED datasets from diverse domains reveals that FIG outperforms the best baseline achieving average gains of 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively. Analyzing the generated trigger hit rate and human evaluation substantiates FIG's superior domain alignment and data quality compared to existing baselines.","sentences":["Event Detection (ED) is the task of identifying typed event mentions of interest from natural language text, which benefits domain-specific reasoning in biomedical, legal, and epidemiological domains.","However, procuring supervised data for thousands of events for various domains is a laborious and expensive task.","To this end, existing works have explored synthetic data generation via forward (generating labels for unlabeled sentences) and inverse (generating sentences from generated labels) generations.","However, forward generation often produces noisy labels, while inverse generation struggles with domain drift and incomplete event annotations.","To address these challenges, we introduce FIG, a hybrid approach that leverages inverse generation for high-quality data synthesis while anchoring it to domain-specific cues extracted via forward generation on unlabeled target data.","FIG further enhances its synthetic data by adding missing annotations through forward generation-based refinement.","Experimentation on three ED datasets from diverse domains reveals that FIG outperforms the best baseline achieving average gains of 3.3% F1 and 5.4% F1 in the zero-shot and few-shot settings respectively.","Analyzing the generated trigger hit rate and human evaluation substantiates FIG's superior domain alignment and data quality compared to existing baselines."],"url":"http://arxiv.org/abs/2502.17394v1"}
{"created":"2025-02-24 18:20:41","title":"Evolving Form and Function: Dual-Objective Optimization in Neural Symbolic Regression Networks","abstract":"Data increasingly abounds, but distilling their underlying relationships down to something interpretable remains challenging. One approach is genetic programming, which `symbolically regresses' a data set down into an equation.   However, symbolic regression (SR) faces the issue of requiring training from scratch for each new dataset. To generalize across all datasets, deep learning techniques have been applied to SR.   These networks, however, are only able to be trained using a symbolic objective: NN-generated and target equations are symbolically compared. But this does not consider the predictive power of these equations, which could be measured by a behavioral objective that compares the generated equation's predictions to actual data.   Here we introduce a method that combines gradient descent and evolutionary computation to yield neural networks that minimize the symbolic and behavioral errors of the equations they generate from data.   As a result, these evolved networks are shown to generate more symbolically and behaviorally accurate equations than those generated by networks trained by state-of-the-art gradient based neural symbolic regression methods.   We hope this method suggests that evolutionary algorithms, combined with gradient descent, can improve SR results by yielding equations with more accurate form and function.","sentences":["Data increasingly abounds, but distilling their underlying relationships down to something interpretable remains challenging.","One approach is genetic programming, which `symbolically regresses' a data set down into an equation.   ","However, symbolic regression (SR) faces the issue of requiring training from scratch for each new dataset.","To generalize across all datasets, deep learning techniques have been applied to SR.   ","These networks, however, are only able to be trained using a symbolic objective: NN-generated and target equations are symbolically compared.","But this does not consider the predictive power of these equations, which could be measured by a behavioral objective that compares the generated equation's predictions to actual data.   ","Here we introduce a method that combines gradient descent and evolutionary computation to yield neural networks that minimize the symbolic and behavioral errors of the equations they generate from data.   ","As a result, these evolved networks are shown to generate more symbolically and behaviorally accurate equations than those generated by networks trained by state-of-the-art gradient based neural symbolic regression methods.   ","We hope this method suggests that evolutionary algorithms, combined with gradient descent, can improve SR results by yielding equations with more accurate form and function."],"url":"http://arxiv.org/abs/2502.17393v1"}
{"created":"2025-02-24 18:20:18","title":"Emoti-Attack: Zero-Perturbation Adversarial Attacks on NLP Systems via Emoji Sequences","abstract":"Deep neural networks (DNNs) have achieved remarkable success in the field of natural language processing (NLP), leading to widely recognized applications such as ChatGPT. However, the vulnerability of these models to adversarial attacks remains a significant concern. Unlike continuous domains like images, text exists in a discrete space, making even minor alterations at the sentence, word, or character level easily perceptible to humans. This inherent discreteness also complicates the use of conventional optimization techniques, as text is non-differentiable. Previous research on adversarial attacks in text has focused on character-level, word-level, sentence-level, and multi-level approaches, all of which suffer from inefficiency or perceptibility issues due to the need for multiple queries or significant semantic shifts.   In this work, we introduce a novel adversarial attack method, Emoji-Attack, which leverages the manipulation of emojis to create subtle, yet effective, perturbations. Unlike character- and word-level strategies, Emoji-Attack targets emojis as a distinct layer of attack, resulting in less noticeable changes with minimal disruption to the text. This approach has been largely unexplored in previous research, which typically focuses on emoji insertion as an extension of character-level attacks. Our experiments demonstrate that Emoji-Attack achieves strong attack performance on both large and small models, making it a promising technique for enhancing adversarial robustness in NLP systems.","sentences":["Deep neural networks (DNNs) have achieved remarkable success in the field of natural language processing (NLP), leading to widely recognized applications such as ChatGPT.","However, the vulnerability of these models to adversarial attacks remains a significant concern.","Unlike continuous domains like images, text exists in a discrete space, making even minor alterations at the sentence, word, or character level easily perceptible to humans.","This inherent discreteness also complicates the use of conventional optimization techniques, as text is non-differentiable.","Previous research on adversarial attacks in text has focused on character-level, word-level, sentence-level, and multi-level approaches, all of which suffer from inefficiency or perceptibility issues due to the need for multiple queries or significant semantic shifts.   ","In this work, we introduce a novel adversarial attack method, Emoji-Attack, which leverages the manipulation of emojis to create subtle, yet effective, perturbations.","Unlike character- and word-level strategies, Emoji-Attack targets emojis as a distinct layer of attack, resulting in less noticeable changes with minimal disruption to the text.","This approach has been largely unexplored in previous research, which typically focuses on emoji insertion as an extension of character-level attacks.","Our experiments demonstrate that Emoji-Attack achieves strong attack performance on both large and small models, making it a promising technique for enhancing adversarial robustness in NLP systems."],"url":"http://arxiv.org/abs/2502.17392v1"}
{"created":"2025-02-24 18:16:23","title":"The Empirical Impact of Reducing Symmetries on the Performance of Deep Ensembles and MoE","abstract":"Recent studies have shown that reducing symmetries in neural networks enhances linear mode connectivity between networks without requiring parameter space alignment, leading to improved performance in linearly interpolated neural networks. However, in practical applications, neural network interpolation is rarely used; instead, ensembles of networks are more common. In this paper, we empirically investigate the impact of reducing symmetries on the performance of deep ensembles and Mixture of Experts (MoE) across five datasets. Additionally, to explore deeper linear mode connectivity, we introduce the Mixture of Interpolated Experts (MoIE). Our results show that deep ensembles built on asymmetric neural networks achieve significantly better performance as ensemble size increases compared to their symmetric counterparts. In contrast, our experiments do not provide conclusive evidence on whether reducing symmetries affects both MoE and MoIE architectures.","sentences":["Recent studies have shown that reducing symmetries in neural networks enhances linear mode connectivity between networks without requiring parameter space alignment, leading to improved performance in linearly interpolated neural networks.","However, in practical applications, neural network interpolation is rarely used; instead, ensembles of networks are more common.","In this paper, we empirically investigate the impact of reducing symmetries on the performance of deep ensembles and Mixture of Experts (MoE) across five datasets.","Additionally, to explore deeper linear mode connectivity, we introduce the Mixture of Interpolated Experts (MoIE).","Our results show that deep ensembles built on asymmetric neural networks achieve significantly better performance as ensemble size increases compared to their symmetric counterparts.","In contrast, our experiments do not provide conclusive evidence on whether reducing symmetries affects both MoE and MoIE architectures."],"url":"http://arxiv.org/abs/2502.17391v1"}
{"created":"2025-02-24 18:16:10","title":"Mitigating Bias in RAG: Controlling the Embedder","abstract":"In retrieval augmented generation (RAG) systems, each individual component -- the LLM, embedder, and corpus -- could introduce biases in the form of skews towards outputting certain perspectives or identities. In this work, we study the conflict between biases of each component and their relationship to the overall bias of the RAG system, which we call bias conflict. Examining both gender and political biases as case studies, we show that bias conflict can be characterized through a linear relationship among components despite its complexity in 6 different LLMs. Through comprehensive fine-tuning experiments creating 120 differently biased embedders, we demonstrate how to control bias while maintaining utility and reveal the importance of reverse-biasing the embedder to mitigate bias in the overall system. Additionally, we find that LLMs and tasks exhibit varying sensitivities to the embedder bias, a crucial factor to consider for debiasing. Our results underscore that a fair RAG system can be better achieved by carefully controlling the bias of the embedder rather than increasing its fairness.","sentences":["In retrieval augmented generation (RAG) systems, each individual component -- the LLM, embedder, and corpus -- could introduce biases in the form of skews towards outputting certain perspectives or identities.","In this work, we study the conflict between biases of each component and their relationship to the overall bias of the RAG system, which we call bias conflict.","Examining both gender and political biases as case studies, we show that bias conflict can be characterized through a linear relationship among components despite its complexity in 6 different LLMs.","Through comprehensive fine-tuning experiments creating 120 differently biased embedders, we demonstrate how to control bias while maintaining utility and reveal the importance of reverse-biasing the embedder to mitigate bias in the overall system.","Additionally, we find that LLMs and tasks exhibit varying sensitivities to the embedder bias, a crucial factor to consider for debiasing.","Our results underscore that a fair RAG system can be better achieved by carefully controlling the bias of the embedder rather than increasing its fairness."],"url":"http://arxiv.org/abs/2502.17390v1"}
{"created":"2025-02-24 18:14:01","title":"Big-Math: A Large-Scale, High-Quality Math Dataset for Reinforcement Learning in Language Models","abstract":"Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements. However, existing open math datasets either contain a small collection of high-quality, human-written problems or a large corpus of machine-generated problems of uncertain quality, forcing researchers to choose between quality and quantity. In this work, we present Big-Math, a dataset of over 250,000 high-quality math questions with verifiable answers, purposefully made for reinforcement learning (RL). To create Big-Math, we rigorously filter, clean, and curate openly available datasets, extracting questions that satisfy our three desiderata: (1) problems with uniquely verifiable solutions, (2) problems that are open-ended, (3) and problems with a closed-form solution. To ensure the quality of Big-Math, we manually verify each step in our filtering process. Based on the findings from our filtering process, we introduce 47,000 new questions with verified answers, Big-Math-Reformulated: closed-ended questions (i.e. multiple choice questions) that have been reformulated as open-ended questions through a systematic reformulation algorithm. Compared to the most commonly used existing open-source datasets for math reasoning, GSM8k and MATH, Big-Math is an order of magnitude larger, while our rigorous filtering ensures that we maintain the questions most suitable for RL. We also provide a rigorous analysis of the dataset, finding that Big-Math contains a high degree of diversity across problem domains, and incorporates a wide range of problem difficulties, enabling a wide range of downstream uses for models of varying capabilities and training requirements. By bridging the gap between data quality and quantity, Big-Math establish a robust foundation for advancing reasoning in LLMs.","sentences":["Increasing interest in reasoning models has led math to become a prominent testing ground for algorithmic and methodological improvements.","However, existing open math datasets either contain a small collection of high-quality, human-written problems or a large corpus of machine-generated problems of uncertain quality, forcing researchers to choose between quality and quantity.","In this work, we present Big-Math, a dataset of over 250,000 high-quality math questions with verifiable answers, purposefully made for reinforcement learning (RL).","To create Big-Math, we rigorously filter, clean, and curate openly available datasets, extracting questions that satisfy our three desiderata: (1) problems with uniquely verifiable solutions, (2) problems that are open-ended, (3) and problems with a closed-form solution.","To ensure the quality of Big-Math, we manually verify each step in our filtering process.","Based on the findings from our filtering process, we introduce 47,000 new questions with verified answers, Big-Math-Reformulated: closed-ended questions (i.e. multiple choice questions) that have been reformulated as open-ended questions through a systematic reformulation algorithm.","Compared to the most commonly used existing open-source datasets for math reasoning, GSM8k and MATH, Big-Math is an order of magnitude larger, while our rigorous filtering ensures that we maintain the questions most suitable for RL.","We also provide a rigorous analysis of the dataset, finding that Big-Math contains a high degree of diversity across problem domains, and incorporates a wide range of problem difficulties, enabling a wide range of downstream uses for models of varying capabilities and training requirements.","By bridging the gap between data quality and quantity, Big-Math establish a robust foundation for advancing reasoning in LLMs."],"url":"http://arxiv.org/abs/2502.17387v1"}
{"created":"2025-02-24 18:10:06","title":"On the Dichotomy Between Privacy and Traceability in $\\ell_p$ Stochastic Convex Optimization","abstract":"In this paper, we investigate the necessity of memorization in stochastic convex optimization (SCO) under $\\ell_p$ geometries. Informally, we say a learning algorithm memorizes $m$ samples (or is $m$-traceable) if, by analyzing its output, it is possible to identify at least $m$ of its training samples. Our main results uncover a fundamental tradeoff between traceability and excess risk in SCO. For every $p\\in [1,\\infty)$, we establish the existence of a risk threshold below which any sample-efficient learner must memorize a \\em{constant fraction} of its sample. For $p\\in [1,2]$, this threshold coincides with best risk of differentially private (DP) algorithms, i.e., above this threshold, there are algorithms that do not memorize even a single sample. This establishes a sharp dichotomy between privacy and traceability for $p \\in [1,2]$. For $p \\in (2,\\infty)$, this threshold instead gives novel lower bounds for DP learning, partially closing an open problem in this setup. En route of proving these results, we introduce a complexity notion we term \\em{trace value} of a problem, which unifies privacy lower bounds and traceability results, and prove a sparse variant of the fingerprinting lemma.","sentences":["In this paper, we investigate the necessity of memorization in stochastic convex optimization (SCO) under $\\ell_p$ geometries.","Informally, we say a learning algorithm memorizes $m$ samples (or is $m$-traceable) if, by analyzing its output, it is possible to identify at least $m$ of its training samples.","Our main results uncover a fundamental tradeoff between traceability and excess risk in SCO.","For every $p\\in [1,\\infty)$, we establish the existence of a risk threshold below which any sample-efficient learner must memorize a \\em{constant fraction} of its sample.","For $p\\in [1,2]$, this threshold coincides with best risk of differentially private (DP) algorithms, i.e., above this threshold, there are algorithms that do not memorize even a single sample.","This establishes a sharp dichotomy between privacy and traceability for $p \\in [1,2]$. For $p \\in (2,\\infty)$, this threshold instead gives novel lower bounds for DP learning, partially closing an open problem in this setup.","En route of proving these results, we introduce a complexity notion we term \\em{trace value} of a problem, which unifies privacy lower bounds and traceability results, and prove a sparse variant of the fingerprinting lemma."],"url":"http://arxiv.org/abs/2502.17384v1"}
{"created":"2025-02-24 18:08:41","title":"What is a Good Question? Utility Estimation with LLM-based Simulations","abstract":"Asking questions is a fundamental aspect of learning that facilitates deeper understanding. However, characterizing and crafting questions that effectively improve learning remains elusive. To address this gap, we propose QUEST (Question Utility Estimation with Simulated Tests). QUEST simulates a learning environment that enables the quantification of a question's utility based on its direct impact on improving learning outcomes. Furthermore, we can identify high-utility questions and use them to fine-tune question generation models with rejection sampling. We find that questions generated by models trained with rejection sampling based on question utility result in exam scores that are higher by at least 20% than those from specialized prompting grounded on educational objectives literature and models fine-tuned with indirect measures of question quality, such as saliency and expected information gain.","sentences":["Asking questions is a fundamental aspect of learning that facilitates deeper understanding.","However, characterizing and crafting questions that effectively improve learning remains elusive.","To address this gap, we propose QUEST (Question Utility Estimation with Simulated Tests).","QUEST simulates a learning environment that enables the quantification of a question's utility based on its direct impact on improving learning outcomes.","Furthermore, we can identify high-utility questions and use them to fine-tune question generation models with rejection sampling.","We find that questions generated by models trained with rejection sampling based on question utility result in exam scores that are higher by at least 20% than those from specialized prompting grounded on educational objectives literature and models fine-tuned with indirect measures of question quality, such as saliency and expected information gain."],"url":"http://arxiv.org/abs/2502.17383v1"}
{"created":"2025-02-24 18:06:57","title":"Low-Rank and Sparse Model Merging for Multi-Lingual Speech Recognition and Translation","abstract":"Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation. Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages. While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility. To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead. LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility. Experimental results across a range of languages demonstrate that LoRS-Merging significantly outperforms conventional multi-lingual multi-task training baselines. Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications.","sentences":["Language diversity presents a significant challenge in speech-to-text (S2T) tasks, such as automatic speech recognition and translation.","Traditional multi-task training approaches aim to address this by jointly optimizing multiple speech recognition and translation tasks across various languages.","While models like Whisper, built on these strategies, demonstrate strong performance, they still face issues of high computational cost, language interference, suboptimal training configurations, and limited extensibility.","To overcome these challenges, we introduce LoRS-Merging (low-rank and sparse model merging), a novel technique designed to efficiently integrate models trained on different languages or tasks while preserving performance and reducing computational overhead.","LoRS-Merging combines low-rank and sparse pruning to retain essential structures while eliminating redundant parameters, mitigating language and task interference, and enhancing extensibility.","Experimental results across a range of languages demonstrate that LoRS-Merging significantly outperforms conventional multi-lingual multi-task training baselines.","Our findings suggest that model merging, particularly LoRS-Merging, is a scalable and effective complement to traditional multi-lingual training strategies for S2T applications."],"url":"http://arxiv.org/abs/2502.17380v1"}
{"created":"2025-02-24 18:01:50","title":"Continuous Integration Practices in Machine Learning Projects: The Practitioners` Perspective","abstract":"Continuous Integration (CI) is a cornerstone of modern software development. However, while widely adopted in traditional software projects, applying CI practices to Machine Learning (ML) projects presents distinctive characteristics. For example, our previous work revealed that ML projects often experience longer build durations and lower test coverage rates compared to their non-ML counterparts. Building on these quantitative findings, this study surveys 155 practitioners from 47 ML projects to investigate the underlying reasons for these distinctive characteristics through a qualitative perspective. Practitioners highlighted eight key differences, including test complexity, infrastructure requirements, and build duration and stability. Common challenges mentioned by practitioners include higher project complexity, model training demands, extensive data handling, increased computational resource needs, and dependency management, all contributing to extended build durations. Furthermore, ML systems' non-deterministic nature, data dependencies, and computational constraints were identified as significant barriers to effective testing. The key takeaway from this study is that while foundational CI principles remain valuable, ML projects require tailored approaches to address their unique challenges. To bridge this gap, we propose a set of ML-specific CI practices, including tracking model performance metrics and prioritizing test execution within CI pipelines. Additionally, our findings highlight the importance of fostering interdisciplinary collaboration to strengthen the testing culture in ML projects. By bridging quantitative findings with practitioners' insights, this study provides a deeper understanding of the interplay between CI practices and the unique demands of ML projects, laying the groundwork for more efficient and robust CI strategies in this domain.","sentences":["Continuous Integration (CI) is a cornerstone of modern software development.","However, while widely adopted in traditional software projects, applying CI practices to Machine Learning (ML) projects presents distinctive characteristics.","For example, our previous work revealed that ML projects often experience longer build durations and lower test coverage rates compared to their non-ML counterparts.","Building on these quantitative findings, this study surveys 155 practitioners from 47 ML projects to investigate the underlying reasons for these distinctive characteristics through a qualitative perspective.","Practitioners highlighted eight key differences, including test complexity, infrastructure requirements, and build duration and stability.","Common challenges mentioned by practitioners include higher project complexity, model training demands, extensive data handling, increased computational resource needs, and dependency management, all contributing to extended build durations.","Furthermore, ML systems' non-deterministic nature, data dependencies, and computational constraints were identified as significant barriers to effective testing.","The key takeaway from this study is that while foundational CI principles remain valuable, ML projects require tailored approaches to address their unique challenges.","To bridge this gap, we propose a set of ML-specific CI practices, including tracking model performance metrics and prioritizing test execution within CI pipelines.","Additionally, our findings highlight the importance of fostering interdisciplinary collaboration to strengthen the testing culture in ML projects.","By bridging quantitative findings with practitioners' insights, this study provides a deeper understanding of the interplay between CI practices and the unique demands of ML projects, laying the groundwork for more efficient and robust CI strategies in this domain."],"url":"http://arxiv.org/abs/2502.17378v1"}
{"created":"2025-02-24 17:59:08","title":"Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting","abstract":"This paper investigates an open research challenge of reconstructing high-quality, large 3D open scenes from images. It is observed existing methods have various limitations, such as requiring precise camera poses for input and dense viewpoints for supervision. To perform effective and efficient 3D scene reconstruction, we propose a novel graph-guided 3D scene reconstruction framework, GraphGS. Specifically, given a set of images captured by RGB cameras on a scene, we first design a spatial prior-based scene structure estimation method. This is then used to create a camera graph that includes information about the camera topology. Further, we propose to apply the graph-guided multi-view consistency constraint and adaptive sampling strategy to the 3D Gaussian Splatting optimization process. This greatly alleviates the issue of Gaussian points overfitting to specific sparse viewpoints and expedites the 3D reconstruction process. We demonstrate GraphGS achieves high-fidelity 3D reconstruction from images, which presents state-of-the-art performance through quantitative and qualitative evaluation across multiple datasets. Project Page: https://3dagentworld.github.io/graphgs.","sentences":["This paper investigates an open research challenge of reconstructing high-quality, large 3D open scenes from images.","It is observed existing methods have various limitations, such as requiring precise camera poses for input and dense viewpoints for supervision.","To perform effective and efficient 3D scene reconstruction, we propose a novel graph-guided 3D scene reconstruction framework, GraphGS.","Specifically, given a set of images captured by RGB cameras on a scene, we first design a spatial prior-based scene structure estimation method.","This is then used to create a camera graph that includes information about the camera topology.","Further, we propose to apply the graph-guided multi-view consistency constraint and adaptive sampling strategy to the 3D Gaussian Splatting optimization process.","This greatly alleviates the issue of Gaussian points overfitting to specific sparse viewpoints and expedites the 3D reconstruction process.","We demonstrate GraphGS achieves high-fidelity 3D reconstruction from images, which presents state-of-the-art performance through quantitative and qualitative evaluation across multiple datasets.","Project Page: https://3dagentworld.github.io/graphgs."],"url":"http://arxiv.org/abs/2502.17377v1"}
{"created":"2025-02-24 17:53:54","title":"Experimental validation of UAV search and detection system in real wilderness environment","abstract":"Search and rescue (SAR) missions require reliable search methods to locate survivors, especially in challenging or inaccessible environments. This is why introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the efficiency of SAR missions while simultaneously increasing the safety of everyone involved in the mission. Motivated by this, we design and experiment with autonomous UAV search for humans in a Mediterranean karst environment. The UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic control method according to known probability density and detection function. The implemented sensing framework consists of a probabilistic search model, motion control system, and computer vision object detection. It enables calculation of the probability of the target being detected in the SAR mission, and this paper focuses on experimental validation of proposed probabilistic framework and UAV control. The uniform probability density to ensure the even probability of finding the targets in the desired search area is achieved by assigning suitably thought-out tasks to 78 volunteers. The detection model is based on YOLO and trained with a previously collected ortho-photo image database. The experimental search is carefully planned and conducted, while as many parameters as possible are recorded. The thorough analysis consists of the motion control system, object detection, and the search validation. The assessment of the detection and search performance provides strong indication that the designed detection model in the UAV control algorithm is aligned with real-world results.","sentences":["Search and rescue (SAR) missions require reliable search methods to locate survivors, especially in challenging or inaccessible environments.","This is why introducing unmanned aerial vehicles (UAVs) can be of great help to enhance the efficiency of SAR missions while simultaneously increasing the safety of everyone involved in the mission.","Motivated by this, we design and experiment with autonomous UAV search for humans in a Mediterranean karst environment.","The UAVs are directed using Heat equation-driven area coverage (HEDAC) ergodic control method according to known probability density and detection function.","The implemented sensing framework consists of a probabilistic search model, motion control system, and computer vision object detection.","It enables calculation of the probability of the target being detected in the SAR mission, and this paper focuses on experimental validation of proposed probabilistic framework and UAV control.","The uniform probability density to ensure the even probability of finding the targets in the desired search area is achieved by assigning suitably thought-out tasks to 78 volunteers.","The detection model is based on YOLO and trained with a previously collected ortho-photo image database.","The experimental search is carefully planned and conducted, while as many parameters as possible are recorded.","The thorough analysis consists of the motion control system, object detection, and the search validation.","The assessment of the detection and search performance provides strong indication that the designed detection model in the UAV control algorithm is aligned with real-world results."],"url":"http://arxiv.org/abs/2502.17372v1"}
{"created":"2025-02-24 17:52:01","title":"Sustainable Greenhouse Management: A Comparative Analysis of Recurrent and Graph Neural Networks","abstract":"The integration of photovoltaic (PV) systems into greenhouses not only optimizes land use but also enhances sustainable agricultural practices by enabling dual benefits of food production and renewable energy generation. However, accurate prediction of internal environmental conditions is crucial to ensure optimal crop growth while maximizing energy production. This study introduces a novel application of Spatio-Temporal Graph Neural Networks (STGNNs) to greenhouse microclimate modeling, comparing their performance with traditional Recurrent Neural Networks (RNNs). While RNNs excel at temporal pattern recognition, they cannot explicitly model the directional relationships between environmental variables. Our STGNN approach addresses this limitation by representing these relationships as directed graphs, enabling the model to capture both spatial dependencies and their directionality. Using high-frequency data collected at 15-minute intervals from a greenhouse in Volos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winter conditions (R^2 = 0.985) but show limitations during summer cooling system operation. Though STGNNs currently show lower performance (winter R^2 = 0.947), their architecture offers greater potential for integrating additional variables such as PV generation and crop growth indicators.","sentences":["The integration of photovoltaic (PV) systems into greenhouses not only optimizes land use but also enhances sustainable agricultural practices by enabling dual benefits of food production and renewable energy generation.","However, accurate prediction of internal environmental conditions is crucial to ensure optimal crop growth while maximizing energy production.","This study introduces a novel application of Spatio-Temporal Graph Neural Networks (STGNNs) to greenhouse microclimate modeling, comparing their performance with traditional Recurrent Neural Networks (RNNs).","While RNNs excel at temporal pattern recognition, they cannot explicitly model the directional relationships between environmental variables.","Our STGNN approach addresses this limitation by representing these relationships as directed graphs, enabling the model to capture both spatial dependencies and their directionality.","Using high-frequency data collected at 15-minute intervals from a greenhouse in Volos, Greece, we demonstrate that RNNs achieve exceptional accuracy in winter conditions (R^2 = 0.985) but show limitations during summer cooling system operation.","Though STGNNs currently show lower performance (winter R^2 = 0.947), their architecture offers greater potential for integrating additional variables such as PV generation and crop growth indicators."],"url":"http://arxiv.org/abs/2502.17371v1"}
{"created":"2025-02-24 17:41:48","title":"Bridging Gaps in Natural Language Processing for Yor\u00f9b\u00e1: A Systematic Review of a Decade of Progress and Prospects","abstract":"Natural Language Processing (NLP) is becoming a dominant subset of artificial intelligence as the need to help machines understand human language looks indispensable. Several NLP applications are ubiquitous, partly due to the myriads of datasets being churned out daily through mediums like social networking sites. However, the growing development has not been evident in most African languages due to the persisting resource limitation, among other issues. Yor\\`ub\\'a language, a tonal and morphologically rich African language, suffers a similar fate, resulting in limited NLP usage. To encourage further research towards improving this situation, this systematic literature review aims to comprehensively analyse studies addressing NLP development for Yor\\`ub\\'a, identifying challenges, resources, techniques, and applications. A well-defined search string from a structured protocol was employed to search, select, and analyse 105 primary studies between 2014 and 2024 from reputable databases. The review highlights the scarcity of annotated corpora, limited availability of pre-trained language models, and linguistic challenges like tonal complexity and diacritic dependency as significant obstacles. It also revealed the prominent techniques, including rule-based methods, among others. The findings reveal a growing body of multilingual and monolingual resources, even though the field is constrained by socio-cultural factors such as code-switching and desertion of language for digital usage. This review synthesises existing research, providing a foundation for advancing NLP for Yor\\`ub\\'a and in African languages generally. It aims to guide future research by identifying gaps and opportunities, thereby contributing to the broader inclusion of Yor\\`ub\\'a and other under-resourced African languages in global NLP advancements.","sentences":["Natural Language Processing (NLP) is becoming a dominant subset of artificial intelligence as the need to help machines understand human language looks indispensable.","Several NLP applications are ubiquitous, partly due to the myriads of datasets being churned out daily through mediums like social networking sites.","However, the growing development has not been evident in most African languages due to the persisting resource limitation, among other issues.","Yor\\`ub\\'a language, a tonal and morphologically rich African language, suffers a similar fate, resulting in limited NLP usage.","To encourage further research towards improving this situation, this systematic literature review aims to comprehensively analyse studies addressing NLP development for Yor\\`ub\\'a, identifying challenges, resources, techniques, and applications.","A well-defined search string from a structured protocol was employed to search, select, and analyse 105 primary studies between 2014 and 2024 from reputable databases.","The review highlights the scarcity of annotated corpora, limited availability of pre-trained language models, and linguistic challenges like tonal complexity and diacritic dependency as significant obstacles.","It also revealed the prominent techniques, including rule-based methods, among others.","The findings reveal a growing body of multilingual and monolingual resources, even though the field is constrained by socio-cultural factors such as code-switching and desertion of language for digital usage.","This review synthesises existing research, providing a foundation for advancing NLP for Yor\\`ub\\'a and in African languages generally.","It aims to guide future research by identifying gaps and opportunities, thereby contributing to the broader inclusion of Yor\\`ub\\'a and other under-resourced African languages in global NLP advancements."],"url":"http://arxiv.org/abs/2502.17364v1"}
{"created":"2025-02-24 17:40:09","title":"KV-Edit: Training-Free Image Editing for Precise Background Preservation","abstract":"Background consistency remains a significant challenge in image editing tasks. Despite extensive developments, existing works still face a trade-off between maintaining similarity to the original image and generating content that aligns with the target. Here, we propose KV-Edit, a training-free approach that uses KV cache in DiTs to maintain background consistency, where background tokens are preserved rather than regenerated, eliminating the need for complex mechanisms or expensive training, ultimately generating new content that seamlessly integrates with the background within user-provided regions. We further explore the memory consumption of the KV cache during editing and optimize the space complexity to $O(1)$ using an inversion-free method. Our approach is compatible with any DiT-based generative model without additional training. Experiments demonstrate that KV-Edit significantly outperforms existing approaches in terms of both background and image quality, even surpassing training-based methods. Project webpage is available at https://xilluill.github.io/projectpages/KV-Edit","sentences":["Background consistency remains a significant challenge in image editing tasks.","Despite extensive developments, existing works still face a trade-off between maintaining similarity to the original image and generating content that aligns with the target.","Here, we propose KV-Edit, a training-free approach that uses KV cache in DiTs to maintain background consistency, where background tokens are preserved rather than regenerated, eliminating the need for complex mechanisms or expensive training, ultimately generating new content that seamlessly integrates with the background within user-provided regions.","We further explore the memory consumption of the KV cache during editing and optimize the space complexity to $O(1)$ using an inversion-free method.","Our approach is compatible with any DiT-based generative model without additional training.","Experiments demonstrate that KV-Edit significantly outperforms existing approaches in terms of both background and image quality, even surpassing training-based methods.","Project webpage is available at https://xilluill.github.io/projectpages/KV-Edit"],"url":"http://arxiv.org/abs/2502.17363v1"}
{"created":"2025-02-24 17:39:04","title":"HATPIC: An Open-Source Single Axis Haptic Joystick for Robotic Development","abstract":"Humans process significantly more information through the sense of touch than through vision. Consequently, haptics for telemanipulation is poised to become essential in the coming years, as it offers operators an additional sensory channel crucial for interpretation in extreme conditions. However, current haptic device setups are either difficult to access or provide low-quality force feedback rendering. This work proposes the design of a single-axis, open-source setup for telemanipulation development, aimed at addressing these issues. We first introduce the haptic device and demonstrate its integration with common robotic tools. The proposed joystick has the potential to accelerate the development and deployment of haptic technology in a wide range of robotics applications, enhancing operator feedback and control.","sentences":["Humans process significantly more information through the sense of touch than through vision.","Consequently, haptics for telemanipulation is poised to become essential in the coming years, as it offers operators an additional sensory channel crucial for interpretation in extreme conditions.","However, current haptic device setups are either difficult to access or provide low-quality force feedback rendering.","This work proposes the design of a single-axis, open-source setup for telemanipulation development, aimed at addressing these issues.","We first introduce the haptic device and demonstrate its integration with common robotic tools.","The proposed joystick has the potential to accelerate the development and deployment of haptic technology in a wide range of robotics applications, enhancing operator feedback and control."],"url":"http://arxiv.org/abs/2502.17362v1"}
{"created":"2025-02-24 17:38:42","title":"A Closer Look at TabPFN v2: Strength, Limitation, and Extension","abstract":"Tabular datasets are inherently heterogeneous, posing significant challenges for developing pre-trained foundation models. The recently introduced transformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achieves unprecedented in-context learning accuracy across multiple tabular datasets, marking a pivotal advancement in tabular foundation models. In this paper, we comprehensively evaluate TabPFN v2 on over 300 datasets, confirming its exceptional generalization capabilities on small- to medium-scale tasks. Our analysis identifies randomized feature tokens as a key factor behind TabPFN v2's success, as they unify heterogeneous datasets into a fixed-dimensional representation, enabling more effective training and inference. To further understand TabPFN v2's predictions, we propose a leave-one-fold-out approach, transforming TabPFN v2 into a feature extractor and revealing its capability to simplify data distributions and boost accuracy. Lastly, to address TabPFN v2's limitations in high-dimensional, large-scale, and many-category tasks, we introduce a divide-and-conquer mechanism inspired by Chain-of-Thought prompting, enabling scalable inference. By uncovering the mechanisms behind TabPFN v2's success and introducing strategies to expand its applicability, this study provides key insights into the future of tabular foundation models.","sentences":["Tabular datasets are inherently heterogeneous, posing significant challenges for developing pre-trained foundation models.","The recently introduced transformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achieves unprecedented in-context learning accuracy across multiple tabular datasets, marking a pivotal advancement in tabular foundation models.","In this paper, we comprehensively evaluate TabPFN v2 on over 300 datasets, confirming its exceptional generalization capabilities on small- to medium-scale tasks.","Our analysis identifies randomized feature tokens as a key factor behind TabPFN v2's success, as they unify heterogeneous datasets into a fixed-dimensional representation, enabling more effective training and inference.","To further understand TabPFN v2's predictions, we propose a leave-one-fold-out approach, transforming TabPFN v2 into a feature extractor and revealing its capability to simplify data distributions and boost accuracy.","Lastly, to address TabPFN v2's limitations in high-dimensional, large-scale, and many-category tasks, we introduce a divide-and-conquer mechanism inspired by Chain-of-Thought prompting, enabling scalable inference.","By uncovering the mechanisms behind TabPFN v2's success and introducing strategies to expand its applicability, this study provides key insights into the future of tabular foundation models."],"url":"http://arxiv.org/abs/2502.17361v1"}
{"created":"2025-02-24 17:36:49","title":"DIS-CO: Discovering Copyrighted Content in VLMs Training Data","abstract":"How can we verify whether copyrighted content was used to train a large vision-language model (VLM) without direct access to its training data? Motivated by the hypothesis that a VLM is able to recognize images from its training corpus, we propose DIS-CO, a novel approach to infer the inclusion of copyrighted content during the model's development. By repeatedly querying a VLM with specific frames from targeted copyrighted material, DIS-CO extracts the content's identity through free-form text completions. To assess its effectiveness, we introduce MovieTection, a benchmark comprising 14,000 frames paired with detailed captions, drawn from films released both before and after a model's training cutoff. Our results show that DIS-CO significantly improves detection performance, nearly doubling the average AUC of the best prior method on models with logits available. Our findings also highlight a broader concern: all tested models appear to have been exposed to some extent to copyrighted content. Our code and data are available at https://github.com/avduarte333/DIS-CO","sentences":["How can we verify whether copyrighted content was used to train a large vision-language model (VLM) without direct access to its training data?","Motivated by the hypothesis that a VLM is able to recognize images from its training corpus, we propose DIS-CO, a novel approach to infer the inclusion of copyrighted content during the model's development.","By repeatedly querying a VLM with specific frames from targeted copyrighted material, DIS-CO extracts the content's identity through free-form text completions.","To assess its effectiveness, we introduce MovieTection, a benchmark comprising 14,000 frames paired with detailed captions, drawn from films released both before and after a model's training cutoff.","Our results show that DIS-CO significantly improves detection performance, nearly doubling the average AUC of the best prior method on models with logits available.","Our findings also highlight a broader concern: all tested models appear to have been exposed to some extent to copyrighted content.","Our code and data are available at https://github.com/avduarte333/DIS-CO"],"url":"http://arxiv.org/abs/2502.17358v1"}
{"created":"2025-02-24 17:34:45","title":"Distributional Scaling Laws for Emergent Capabilities","abstract":"In this paper, we explore the nature of sudden breakthroughs in language model performance at scale, which stands in contrast to smooth improvements governed by scaling laws. While advocates of \"emergence\" view abrupt performance gains as capabilities unlocking at specific scales, others have suggested that they are produced by thresholding effects and alleviated by continuous metrics. We propose that breakthroughs are instead driven by continuous changes in the probability distribution of training outcomes, particularly when performance is bimodally distributed across random seeds. In synthetic length generalization tasks, we show that different random seeds can produce either highly linear or emergent scaling trends. We reveal that sharp breakthroughs in metrics are produced by underlying continuous changes in their distribution across seeds. Furthermore, we provide a case study of inverse scaling and show that even as the probability of a successful run declines, the average performance of a successful run continues to increase monotonically. We validate our distributional scaling framework on realistic settings by measuring MMLU performance in LLM populations. These insights emphasize the role of random variation in the effect of scale on LLM capabilities.","sentences":["In this paper, we explore the nature of sudden breakthroughs in language model performance at scale, which stands in contrast to smooth improvements governed by scaling laws.","While advocates of \"emergence\" view abrupt performance gains as capabilities unlocking at specific scales, others have suggested that they are produced by thresholding effects and alleviated by continuous metrics.","We propose that breakthroughs are instead driven by continuous changes in the probability distribution of training outcomes, particularly when performance is bimodally distributed across random seeds.","In synthetic length generalization tasks, we show that different random seeds can produce either highly linear or emergent scaling trends.","We reveal that sharp breakthroughs in metrics are produced by underlying continuous changes in their distribution across seeds.","Furthermore, we provide a case study of inverse scaling and show that even as the probability of a successful run declines, the average performance of a successful run continues to increase monotonically.","We validate our distributional scaling framework on realistic settings by measuring MMLU performance in LLM populations.","These insights emphasize the role of random variation in the effect of scale on LLM capabilities."],"url":"http://arxiv.org/abs/2502.17356v1"}
{"created":"2025-02-24 17:33:18","title":"On Relation-Specific Neurons in Large Language Models","abstract":"In large language models (LLMs), certain neurons can store distinct pieces of knowledge learned during pretraining. While knowledge typically appears as a combination of relations and entities, it remains unclear whether some neurons focus on a relation itself -- independent of any entity. We hypothesize such neurons detect a relation in the input text and guide generation involving such a relation. To investigate this, we study the Llama-2 family on a chosen set of relations with a statistics-based method. Our experiments demonstrate the existence of relation-specific neurons. We measure the effect of selectively deactivating candidate neurons specific to relation $r$ on the LLM's ability to handle (1) facts whose relation is $r$ and (2) facts whose relation is a different relation $r' \\neq r$. With respect to their capacity for encoding relation information, we give evidence for the following three properties of relation-specific neurons. $\\textbf{(i) Neuron cumulativity.}$ The neurons for $r$ present a cumulative effect so that deactivating a larger portion of them results in the degradation of more facts in $r$. $\\textbf{(ii) Neuron versatility.}$ Neurons can be shared across multiple closely related as well as less related relations. Some relation neurons transfer across languages. $\\textbf{(iii) Neuron interference.}$ Deactivating neurons specific to one relation can improve LLM generation performance for facts of other relations. We will make our code publicly available at https://github.com/cisnlp/relation-specific-neurons.","sentences":["In large language models (LLMs), certain neurons can store distinct pieces of knowledge learned during pretraining.","While knowledge typically appears as a combination of relations and entities, it remains unclear whether some neurons focus on a relation itself -- independent of any entity.","We hypothesize such neurons detect a relation in the input text and guide generation involving such a relation.","To investigate this, we study the Llama-2 family on a chosen set of relations with a statistics-based method.","Our experiments demonstrate the existence of relation-specific neurons.","We measure the effect of selectively deactivating candidate neurons specific to relation $r$ on the LLM's ability to handle (1) facts whose relation is $r$ and (2) facts whose relation is a different relation $r' \\neq r$. With respect to their capacity for encoding relation information, we give evidence for the following three properties of relation-specific neurons.","$\\textbf{(i) Neuron cumulativity.}$","The neurons for $r$ present a cumulative effect so that deactivating a larger portion of them results in the degradation of more facts in $r$. $\\textbf{(ii) Neuron versatility.}$ Neurons can be shared across multiple closely related as well as less related relations.","Some relation neurons transfer across languages.","$\\textbf{(iii) Neuron interference.}$ Deactivating neurons specific to one relation can improve LLM generation performance for facts of other relations.","We will make our code publicly available at https://github.com/cisnlp/relation-specific-neurons."],"url":"http://arxiv.org/abs/2502.17355v1"}
{"created":"2025-02-24 17:29:10","title":"Leveraging Procedural Knowledge and Task Hierarchies for Efficient Instructional Video Pre-training","abstract":"Instructional videos provide a convenient modality to learn new tasks (ex. cooking a recipe, or assembling furniture). A viewer will want to find a corresponding video that reflects both the overall task they are interested in as well as contains the relevant steps they need to carry out the task. To perform this, an instructional video model should be capable of inferring both the tasks and the steps that occur in an input video. Doing this efficiently and in a generalizable fashion is key when compute or relevant video topics used to train this model are limited. To address these requirements we explicitly mine task hierarchies and the procedural steps associated with instructional videos. We use this prior knowledge to pre-train our model, $\\texttt{Pivot}$, for step and task prediction. During pre-training, we also provide video augmentation and early stopping strategies to optimally identify which model to use for downstream tasks. We test this pre-trained model on task recognition, step recognition, and step prediction tasks on two downstream datasets. When pre-training data and compute are limited, we outperform previous baselines along these tasks. Therefore, leveraging prior task and step structures enables efficient training of $\\texttt{Pivot}$ for instructional video recommendation.","sentences":["Instructional videos provide a convenient modality to learn new tasks (ex. cooking a recipe, or assembling furniture).","A viewer will want to find a corresponding video that reflects both the overall task they are interested in as well as contains the relevant steps they need to carry out the task.","To perform this, an instructional video model should be capable of inferring both the tasks and the steps that occur in an input video.","Doing this efficiently and in a generalizable fashion is key when compute or relevant video topics used to train this model are limited.","To address these requirements we explicitly mine task hierarchies and the procedural steps associated with instructional videos.","We use this prior knowledge to pre-train our model, $\\texttt{Pivot}$, for step and task prediction.","During pre-training, we also provide video augmentation and early stopping strategies to optimally identify which model to use for downstream tasks.","We test this pre-trained model on task recognition, step recognition, and step prediction tasks on two downstream datasets.","When pre-training data and compute are limited, we outperform previous baselines along these tasks.","Therefore, leveraging prior task and step structures enables efficient training of $\\texttt{Pivot}$ for instructional video recommendation."],"url":"http://arxiv.org/abs/2502.17352v1"}
{"created":"2025-02-24 17:25:09","title":"Goal-Oriented Middleware Filtering at Transport Layer Based on Value of Updates","abstract":"This work explores employing the concept of goal-oriented (GO) semantic communication for real-time monitoring and control. Generally, GO communication advocates for the deep integration of application targets into the network design. We consider CPS and IoT applications where sensors generate a tremendous amount of network traffic toward monitors or controllers. Here, the practical introduction of GO communication must address several challenges. These include stringent timing requirements, challenging network setups, and limited computing and communication capabilities of the devices involved. Moreover, real-life CPS deployments often rely on heterogeneous communication standards prompted by specific hardware. To address these issues, we introduce a middleware design of a GO distributed Transport Layer (TL) framework for control applications. It offers end-to-end performance improvements for diverse setups and transmitting hardware. The proposed TL protocol evaluates the Value of sampled state Updates (VoU) for the application goal. It decides whether to admit or discard the corresponding packets, thus offloading the network. VoU captures the contribution of utilizing the updates at the receiver into the application's performance. We introduce a belief network and the augmentation procedure used by the sensor to predict the evolution of the control process, including possible delays and losses of status updates in the network. The prediction is made either using a control model dynamics or a Long-Short Term Memory neural network approach. We test the performance of the proposed TL in the experimental framework using Industrial IoT Zolertia ReMote sensors. We show that while existing approaches fail to deliver sufficient control performance, our VoU-based TL scheme ensures stability and performs $\\sim$$60\\%$ better than the naive GO TL we proposed in our previous work.","sentences":["This work explores employing the concept of goal-oriented (GO) semantic communication for real-time monitoring and control.","Generally, GO communication advocates for the deep integration of application targets into the network design.","We consider CPS and IoT applications where sensors generate a tremendous amount of network traffic toward monitors or controllers.","Here, the practical introduction of GO communication must address several challenges.","These include stringent timing requirements, challenging network setups, and limited computing and communication capabilities of the devices involved.","Moreover, real-life CPS deployments often rely on heterogeneous communication standards prompted by specific hardware.","To address these issues, we introduce a middleware design of a GO distributed Transport Layer (TL) framework for control applications.","It offers end-to-end performance improvements for diverse setups and transmitting hardware.","The proposed TL protocol evaluates the Value of sampled state Updates (VoU) for the application goal.","It decides whether to admit or discard the corresponding packets, thus offloading the network.","VoU captures the contribution of utilizing the updates at the receiver into the application's performance.","We introduce a belief network and the augmentation procedure used by the sensor to predict the evolution of the control process, including possible delays and losses of status updates in the network.","The prediction is made either using a control model dynamics or a Long-Short Term Memory neural network approach.","We test the performance of the proposed TL in the experimental framework using Industrial IoT Zolertia ReMote sensors.","We show that while existing approaches fail to deliver sufficient control performance, our VoU-based TL scheme ensures stability and performs $\\sim$$60\\%$ better than the naive GO TL we proposed in our previous work."],"url":"http://arxiv.org/abs/2502.17350v1"}
{"created":"2025-02-24 17:23:12","title":"How Scientists Use Large Language Models to Program","abstract":"Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization. As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development. We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university. Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries. We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses.","sentences":["Scientists across disciplines write code for critical activities like data collection and generation, statistical modeling, and visualization.","As large language models that can generate code have become widely available, scientists may increasingly use these models during research software development.","We investigate the characteristics of scientists who are early-adopters of code generating models and conduct interviews with scientists at a public, research-focused university.","Through interviews and reviews of user interaction logs, we see that scientists often use code generating models as an information retrieval tool for navigating unfamiliar programming languages and libraries.","We present findings about their verification strategies and discuss potential vulnerabilities that may emerge from code generation practices unknowingly influencing the parameters of scientific analyses."],"url":"http://arxiv.org/abs/2502.17348v1"}
{"created":"2025-02-24 17:19:15","title":"SoFFT: Spatial Fourier Transform for Modeling Continuum Soft Robots","abstract":"Continuum soft robots, composed of flexible materials, exhibit theoretically infinite degrees of freedom, enabling notable adaptability in unstructured environments. Cosserat Rod Theory has emerged as a prominent framework for modeling these robots efficiently, representing continuum soft robots as time-varying curves, known as backbones. In this work, we propose viewing the robot's backbone as a signal in space and time, applying the Fourier transform to describe its deformation compactly. This approach unifies existing modeling strategies within the Cosserat Rod Theory framework, offering insights into commonly used heuristic methods. Moreover, the Fourier transform enables the development of a data-driven methodology to experimentally capture the robot's deformation. The proposed approach is validated through numerical simulations and experiments on a real-world prototype, demonstrating a reduction in the degrees of freedom while preserving the accuracy of the deformation representation.","sentences":["Continuum soft robots, composed of flexible materials, exhibit theoretically infinite degrees of freedom, enabling notable adaptability in unstructured environments.","Cosserat Rod Theory has emerged as a prominent framework for modeling these robots efficiently, representing continuum soft robots as time-varying curves, known as backbones.","In this work, we propose viewing the robot's backbone as a signal in space and time, applying the Fourier transform to describe its deformation compactly.","This approach unifies existing modeling strategies within the Cosserat Rod Theory framework, offering insights into commonly used heuristic methods.","Moreover, the Fourier transform enables the development of a data-driven methodology to experimentally capture the robot's deformation.","The proposed approach is validated through numerical simulations and experiments on a real-world prototype, demonstrating a reduction in the degrees of freedom while preserving the accuracy of the deformation representation."],"url":"http://arxiv.org/abs/2502.17347v1"}
{"created":"2025-02-24 17:19:07","title":"User-Centric Evaluation Methods for Digital Twin Applications in Extended Reality","abstract":"The integration of Digital Twins with Extended Reality technologies, such as Virtual Reality and Augmented Reality, is transforming industries by enabling more immersive, interactive experiences and enhancing real time decision making. User centered evaluations are crucial for aligning XR enhanced DT systems with user expectations, enhancing acceptance and utility in real world settings. This paper proposes a user centric evaluation method for XR enhanced DT applications to assess usability, cognitive load, and user experience. By employing a range of assessment tools, including questionnaires and observational studies across various use cases, such as virtual tourism, city planning, and industrial maintenance, this method provides a structured approach to capturing the users perspective.","sentences":["The integration of Digital Twins with Extended Reality technologies, such as Virtual Reality and Augmented Reality, is transforming industries by enabling more immersive, interactive experiences and enhancing real time decision making.","User centered evaluations are crucial for aligning XR enhanced DT systems with user expectations, enhancing acceptance and utility in real world settings.","This paper proposes a user centric evaluation method for XR enhanced DT applications to assess usability, cognitive load, and user experience.","By employing a range of assessment tools, including questionnaires and observational studies across various use cases, such as virtual tourism, city planning, and industrial maintenance, this method provides a structured approach to capturing the users perspective."],"url":"http://arxiv.org/abs/2502.17346v1"}
{"created":"2025-02-24 17:18:54","title":"+Tour: Recommending personalized itineraries for smart tourism","abstract":"Next-generation touristic services will rely on the advanced mobile networks' high bandwidth and low latency and the Multi-access Edge Computing (MEC) paradigm to provide fully immersive mobile experiences. As an integral part of travel planning systems, recommendation algorithms devise personalized tour itineraries for individual users considering the popularity of a city's Points of Interest (POIs) as well as the tourist preferences and constraints. However, in the context of next-generation touristic services, recommendation algorithms should also consider the applications (e.g., social network, mobile video streaming, mobile augmented reality) the tourist will consume in the POIs and the quality in which the MEC infrastructure will deliver such applications. In this paper, we address the joint problem of recommending personalized tour itineraries for tourists and efficiently allocating MEC resources for advanced touristic applications. We formulate an optimization problem that maximizes the itinerary of individual tourists while optimizing the resource allocation at the network edge. We then propose an exact algorithm that quickly solves the problem optimally, considering instances of realistic size. Using a real-world location-based photo-sharing database, we conduct and present an exploratory analysis to understand preferences and users' visiting patterns. Using this understanding, we propose a methodology to identify user interest in applications. Finally, we evaluate our algorithm using this dataset. Results show that our algorithm outperforms a modified version of a state-of-the-art solution for personalized tour itinerary recommendation, demonstrating gains up to 11% for resource allocation efficiency and 40% for user experience. In addition, our algorithm performs similarly to the modified state-of-the-art solution regarding traditional itinerary recommendation metrics.","sentences":["Next-generation touristic services will rely on the advanced mobile networks' high bandwidth and low latency and the Multi-access Edge Computing (MEC) paradigm to provide fully immersive mobile experiences.","As an integral part of travel planning systems, recommendation algorithms devise personalized tour itineraries for individual users considering the popularity of a city's Points of Interest (POIs) as well as the tourist preferences and constraints.","However, in the context of next-generation touristic services, recommendation algorithms should also consider the applications (e.g., social network, mobile video streaming, mobile augmented reality) the tourist will consume in the POIs and the quality in which the MEC infrastructure will deliver such applications.","In this paper, we address the joint problem of recommending personalized tour itineraries for tourists and efficiently allocating MEC resources for advanced touristic applications.","We formulate an optimization problem that maximizes the itinerary of individual tourists while optimizing the resource allocation at the network edge.","We then propose an exact algorithm that quickly solves the problem optimally, considering instances of realistic size.","Using a real-world location-based photo-sharing database, we conduct and present an exploratory analysis to understand preferences and users' visiting patterns.","Using this understanding, we propose a methodology to identify user interest in applications.","Finally, we evaluate our algorithm using this dataset.","Results show that our algorithm outperforms a modified version of a state-of-the-art solution for personalized tour itinerary recommendation, demonstrating gains up to 11% for resource allocation efficiency and 40% for user experience.","In addition, our algorithm performs similarly to the modified state-of-the-art solution regarding traditional itinerary recommendation metrics."],"url":"http://arxiv.org/abs/2502.17345v1"}
{"created":"2025-02-24 17:18:43","title":"Beyond Interaction Patterns: Assessing Claims of Coordinated Inter-State Information Operations on Twitter/X","abstract":"Social media platforms have become key tools for coordinated influence operations, enabling state actors to manipulate public opinion through strategic, collective actions. While previous research has suggested collaboration between states, such research failed to leverage state-of-the-art coordination indicators or control datasets. In this study, we investigate inter-state coordination by analyzing multiple online behavioral traces and using sophisticated coordination detection models. By incorporating a control dataset to differentiate organic user activity from coordinated efforts, our findings reveal no evidence of inter-state coordination. These results challenge earlier claims and underscore the importance of robust methodologies and control datasets in accurately detecting online coordination.","sentences":["Social media platforms have become key tools for coordinated influence operations, enabling state actors to manipulate public opinion through strategic, collective actions.","While previous research has suggested collaboration between states, such research failed to leverage state-of-the-art coordination indicators or control datasets.","In this study, we investigate inter-state coordination by analyzing multiple online behavioral traces and using sophisticated coordination detection models.","By incorporating a control dataset to differentiate organic user activity from coordinated efforts, our findings reveal no evidence of inter-state coordination.","These results challenge earlier claims and underscore the importance of robust methodologies and control datasets in accurately detecting online coordination."],"url":"http://arxiv.org/abs/2502.17344v1"}
{"created":"2025-02-24 17:17:15","title":"Time series forecasting based on optimized LLM for fault prediction in distribution power grid insulators","abstract":"Surface contamination on electrical grid insulators leads to an increase in leakage current until an electrical discharge occurs, which can result in a power system shutdown. To mitigate the possibility of disruptive faults resulting in a power outage, monitoring contamination and leakage current can help predict the progression of faults. Given this need, this paper proposes a hybrid deep learning (DL) model for predicting the increase in leakage current in high-voltage insulators. The hybrid structure considers a multi-criteria optimization using tree-structured Parzen estimation, an input stage filter for signal noise attenuation combined with a large language model (LLM) applied for time series forecasting. The proposed optimized LLM outperforms state-of-the-art DL models with a root-mean-square error equal to 2.24$\\times10^{-4}$ for a short-term horizon and 1.21$\\times10^{-3}$ for a medium-term horizon.","sentences":["Surface contamination on electrical grid insulators leads to an increase in leakage current until an electrical discharge occurs, which can result in a power system shutdown.","To mitigate the possibility of disruptive faults resulting in a power outage, monitoring contamination and leakage current can help predict the progression of faults.","Given this need, this paper proposes a hybrid deep learning (DL) model for predicting the increase in leakage current in high-voltage insulators.","The hybrid structure considers a multi-criteria optimization using tree-structured Parzen estimation, an input stage filter for signal noise attenuation combined with a large language model (LLM) applied for time series forecasting.","The proposed optimized LLM outperforms state-of-the-art DL models with a root-mean-square error equal to 2.24$\\times10^{-4}$ for a short-term horizon and 1.21$\\times10^{-3}$ for a medium-term horizon."],"url":"http://arxiv.org/abs/2502.17341v1"}
{"created":"2025-02-24 17:17:00","title":"Low-rank bias, weight decay, and model merging in neural networks","abstract":"We explore the low-rank structure of the weight matrices in neural networks originating from training with Gradient Descent (GD) and Gradient Flow (GF) with $L2$ regularization (also known as weight decay). We show several properties of GD-trained deep neural networks, induced by $L2$ regularization. In particular, for a stationary point of GD we show alignment of the parameters and the gradient, norm preservation across layers, and low-rank bias: properties previously known in the context of GF solutions. Experiments show that the assumptions made in the analysis only mildly affect the observations. In addition, we investigate a multitask learning phenomenon enabled by $L2$ regularization and low-rank bias. In particular, we show that if two networks are trained, such that the inputs in the training set of one network are approximately orthogonal to the inputs in the training set of the other network, the new network obtained by simply summing the weights of the two networks will perform as well on both training sets as the respective individual networks. We demonstrate this for shallow ReLU neural networks trained by GD, as well as deep linear and deep ReLU networks trained by GF.","sentences":["We explore the low-rank structure of the weight matrices in neural networks originating from training with Gradient Descent (GD) and Gradient Flow (GF) with $L2$ regularization (also known as weight decay).","We show several properties of GD-trained deep neural networks, induced by $L2$ regularization.","In particular, for a stationary point of GD we show alignment of the parameters and the gradient, norm preservation across layers, and low-rank bias: properties previously known in the context of GF solutions.","Experiments show that the assumptions made in the analysis only mildly affect the observations.","In addition, we investigate a multitask learning phenomenon enabled by $L2$ regularization and low-rank bias.","In particular, we show that if two networks are trained, such that the inputs in the training set of one network are approximately orthogonal to the inputs in the training set of the other network, the new network obtained by simply summing the weights of the two networks will perform as well on both training sets as the respective individual networks.","We demonstrate this for shallow ReLU neural networks trained by GD, as well as deep linear and deep ReLU networks trained by GF."],"url":"http://arxiv.org/abs/2502.17340v1"}
{"created":"2025-02-24 17:06:50","title":"Modeling, Simulation, and Application of Spatio-Temporal Characteristics Detection in Incipient Slip","abstract":"Incipient slip detection provides critical feedback for robotic grasping and manipulation tasks. However, maintaining its adaptability under diverse object properties and complex working conditions remains challenging. This article highlights the importance of completely representing spatio-temporal features of slip, and proposes a novel approach for incipient slip modeling and detection. Based on the analysis of localized displacement phenomenon, we establish the relationship between the characteristic strain rate extreme events and the local slip state. This approach enables the detection of both the spatial distribution and temporal dynamics of stick-slip regions. Also, the proposed method can be applied to strain distribution sensing devices, such as vision-based tactile sensors. Simulations and prototype experiments validated the effectiveness of this approach under varying contact conditions, including different contact geometries, friction coefficients, and combined loads. Experiments demonstrated that this method not only accurately and reliably delineates incipient slip, but also facilitates friction parameter estimation and adaptive grasping control.","sentences":["Incipient slip detection provides critical feedback for robotic grasping and manipulation tasks.","However, maintaining its adaptability under diverse object properties and complex working conditions remains challenging.","This article highlights the importance of completely representing spatio-temporal features of slip, and proposes a novel approach for incipient slip modeling and detection.","Based on the analysis of localized displacement phenomenon, we establish the relationship between the characteristic strain rate extreme events and the local slip state.","This approach enables the detection of both the spatial distribution and temporal dynamics of stick-slip regions.","Also, the proposed method can be applied to strain distribution sensing devices, such as vision-based tactile sensors.","Simulations and prototype experiments validated the effectiveness of this approach under varying contact conditions, including different contact geometries, friction coefficients, and combined loads.","Experiments demonstrated that this method not only accurately and reliably delineates incipient slip, but also facilitates friction parameter estimation and adaptive grasping control."],"url":"http://arxiv.org/abs/2502.17335v1"}
{"created":"2025-02-24 17:04:24","title":"Tokenized SAEs: Disentangling SAE Reconstructions","abstract":"Sparse auto-encoders (SAEs) have become a prevalent tool for interpreting language models' inner workings. However, it is unknown how tightly SAE features correspond to computationally important directions in the model. This work empirically shows that many RES-JB SAE features predominantly correspond to simple input statistics. We hypothesize this is caused by a large class imbalance in training data combined with a lack of complex error signals. To reduce this behavior, we propose a method that disentangles token reconstruction from feature reconstruction. This improvement is achieved by introducing a per-token bias, which provides an enhanced baseline for interesting reconstruction. As a result, significantly more interesting features and improved reconstruction in sparse regimes are learned.","sentences":["Sparse auto-encoders (SAEs) have become a prevalent tool for interpreting language models' inner workings.","However, it is unknown how tightly SAE features correspond to computationally important directions in the model.","This work empirically shows that many RES-JB SAE features predominantly correspond to simple input statistics.","We hypothesize this is caused by a large class imbalance in training data combined with a lack of complex error signals.","To reduce this behavior, we propose a method that disentangles token reconstruction from feature reconstruction.","This improvement is achieved by introducing a per-token bias, which provides an enhanced baseline for interesting reconstruction.","As a result, significantly more interesting features and improved reconstruction in sparse regimes are learned."],"url":"http://arxiv.org/abs/2502.17332v1"}
{"created":"2025-02-24 17:02:40","title":"Unveiling ECC Vulnerabilities: LSTM Networks for Operation Recognition in Side-Channel Attacks","abstract":"We propose a novel approach for performing side-channel attacks on elliptic curve cryptography. Unlike previous approaches and inspired by the ``activity detection'' literature, we adopt a long-short-term memory (LSTM) neural network to analyze a power trace and identify patterns of operation in the scalar multiplication algorithm performed during an ECDSA signature, that allows us to recover bits of the ephemeral key, and thus retrieve the signer's private key. Our approach is based on the fact that modular reductions are conditionally performed by micro-ecc and depend on key bits.   We evaluated the feasibility and reproducibility of our attack through experiments in both simulated and real implementations. We demonstrate the effectiveness of our attack by implementing it on a real target device, an STM32F415 with the micro-ecc library, and successfully compromise it. Furthermore, we show that current countermeasures, specifically the coordinate randomization technique, are not sufficient to protect against side channels. Finally, we suggest other approaches that may be implemented to thwart our attack.","sentences":["We propose a novel approach for performing side-channel attacks on elliptic curve cryptography.","Unlike previous approaches and inspired by the ``activity detection'' literature, we adopt a long-short-term memory (LSTM) neural network to analyze a power trace and identify patterns of operation in the scalar multiplication algorithm performed during an ECDSA signature, that allows us to recover bits of the ephemeral key, and thus retrieve the signer's private key.","Our approach is based on the fact that modular reductions are conditionally performed by micro-ecc and depend on key bits.   ","We evaluated the feasibility and reproducibility of our attack through experiments in both simulated and real implementations.","We demonstrate the effectiveness of our attack by implementing it on a real target device, an STM32F415 with the micro-ecc library, and successfully compromise it.","Furthermore, we show that current countermeasures, specifically the coordinate randomization technique, are not sufficient to protect against side channels.","Finally, we suggest other approaches that may be implemented to thwart our attack."],"url":"http://arxiv.org/abs/2502.17330v1"}
{"created":"2025-02-24 17:01:48","title":"Mutual Reinforcement of LLM Dialogue Synthesis and Summarization Capabilities for Few-Shot Dialogue Summarization","abstract":"In this work, we propose Mutual Reinforcing Data Synthesis (MRDS) within LLMs to improve few-shot dialogue summarization task. Unlike prior methods that require external knowledge, we mutually reinforce the LLM\\'s dialogue synthesis and summarization capabilities, allowing them to complement each other during training and enhance overall performances. The dialogue synthesis capability is enhanced by directed preference optimization with preference scoring from summarization capability. The summarization capability is enhanced by the additional high quality dialogue-summary paired data produced by the dialogue synthesis capability. By leveraging the proposed MRDS mechanism, we elicit the internal knowledge of LLM in the format of synthetic data, and use it to augment the few-shot real training dataset. Empirical results demonstrate that our method improves dialogue summarization, achieving a 1.5% increase in ROUGE scores and a 0.3% improvement in BERT scores in few-shot settings. Furthermore, our method attains the highest average scores in human evaluations, surpassing both the pre-trained models and the baselines fine-tuned solely for summarization tasks.","sentences":["In this work, we propose Mutual Reinforcing Data Synthesis (MRDS) within LLMs to improve few-shot dialogue summarization task.","Unlike prior methods that require external knowledge, we mutually reinforce the LLM\\'s dialogue synthesis and summarization capabilities, allowing them to complement each other during training and enhance overall performances.","The dialogue synthesis capability is enhanced by directed preference optimization with preference scoring from summarization capability.","The summarization capability is enhanced by the additional high quality dialogue-summary paired data produced by the dialogue synthesis capability.","By leveraging the proposed MRDS mechanism, we elicit the internal knowledge of LLM in the format of synthetic data, and use it to augment the few-shot real training dataset.","Empirical results demonstrate that our method improves dialogue summarization, achieving a 1.5% increase in ROUGE scores and a 0.3% improvement in BERT scores in few-shot settings.","Furthermore, our method attains the highest average scores in human evaluations, surpassing both the pre-trained models and the baselines fine-tuned solely for summarization tasks."],"url":"http://arxiv.org/abs/2502.17328v1"}
{"created":"2025-02-24 17:00:36","title":"AnyTop: Character Animation Diffusion with Any Topology","abstract":"Generating motion for arbitrary skeletons is a longstanding challenge in computer graphics, remaining largely unexplored due to the scarcity of diverse datasets and the irregular nature of the data. In this work, we introduce AnyTop, a diffusion model that generates motions for diverse characters with distinct motion dynamics, using only their skeletal structure as input. Our work features a transformer-based denoising network, tailored for arbitrary skeleton learning, integrating topology information into the traditional attention mechanism. Additionally, by incorporating textual joint descriptions into the latent feature representation, AnyTop learns semantic correspondences between joints across diverse skeletons. Our evaluation demonstrates that AnyTop generalizes well, even with as few as three training examples per topology, and can produce motions for unseen skeletons as well. Furthermore, our model's latent space is highly informative, enabling downstream tasks such as joint correspondence, temporal segmentation and motion editing. Our webpage, https://anytop2025.github.io/Anytop-page, includes links to videos and code.","sentences":["Generating motion for arbitrary skeletons is a longstanding challenge in computer graphics, remaining largely unexplored due to the scarcity of diverse datasets and the irregular nature of the data.","In this work, we introduce AnyTop, a diffusion model that generates motions for diverse characters with distinct motion dynamics, using only their skeletal structure as input.","Our work features a transformer-based denoising network, tailored for arbitrary skeleton learning, integrating topology information into the traditional attention mechanism.","Additionally, by incorporating textual joint descriptions into the latent feature representation, AnyTop learns semantic correspondences between joints across diverse skeletons.","Our evaluation demonstrates that AnyTop generalizes well, even with as few as three training examples per topology, and can produce motions for unseen skeletons as well.","Furthermore, our model's latent space is highly informative, enabling downstream tasks such as joint correspondence, temporal segmentation and motion editing.","Our webpage, https://anytop2025.github.io/Anytop-page, includes links to videos and code."],"url":"http://arxiv.org/abs/2502.17327v1"}
{"created":"2025-02-24 16:55:27","title":"TDMPBC: Self-Imitative Reinforcement Learning for Humanoid Robot Control","abstract":"Complex high-dimensional spaces with high Degree-of-Freedom and complicated action spaces, such as humanoid robots equipped with dexterous hands, pose significant challenges for reinforcement learning (RL) algorithms, which need to wisely balance exploration and exploitation under limited sample budgets. In general, feasible regions for accomplishing tasks within complex high-dimensional spaces are exceedingly narrow. For instance, in the context of humanoid robot motion control, the vast majority of space corresponds to falling, while only a minuscule fraction corresponds to standing upright, which is conducive to the completion of downstream tasks. Once the robot explores into a potentially task-relevant region, it should place greater emphasis on the data within that region. Building on this insight, we propose the $\\textbf{S}$elf-$\\textbf{I}$mitative $\\textbf{R}$einforcement $\\textbf{L}$earning ($\\textbf{SIRL}$) framework, where the RL algorithm also imitates potentially task-relevant trajectories. Specifically, trajectory return is utilized to determine its relevance to the task and an additional behavior cloning is adopted whose weight is dynamically adjusted based on the trajectory return. As a result, our proposed algorithm achieves 120% performance improvement on the challenging HumanoidBench with 5% extra computation overhead. With further visualization, we find the significant performance gain does lead to meaningful behavior improvement that several tasks are solved successfully.","sentences":["Complex high-dimensional spaces with high Degree-of-Freedom and complicated action spaces, such as humanoid robots equipped with dexterous hands, pose significant challenges for reinforcement learning (RL) algorithms, which need to wisely balance exploration and exploitation under limited sample budgets.","In general, feasible regions for accomplishing tasks within complex high-dimensional spaces are exceedingly narrow.","For instance, in the context of humanoid robot motion control, the vast majority of space corresponds to falling, while only a minuscule fraction corresponds to standing upright, which is conducive to the completion of downstream tasks.","Once the robot explores into a potentially task-relevant region, it should place greater emphasis on the data within that region.","Building on this insight, we propose the $\\textbf{S}$elf-$\\textbf{I}$mitative $\\textbf{R}$einforcement $\\textbf{L}$earning ($\\textbf{SIRL}$) framework, where the RL algorithm also imitates potentially task-relevant trajectories.","Specifically, trajectory return is utilized to determine its relevance to the task and an additional behavior cloning is adopted whose weight is dynamically adjusted based on the trajectory return.","As a result, our proposed algorithm achieves 120% performance improvement on the challenging HumanoidBench with 5% extra computation overhead.","With further visualization, we find the significant performance gain does lead to meaningful behavior improvement that several tasks are solved successfully."],"url":"http://arxiv.org/abs/2502.17322v1"}
{"created":"2025-02-24 16:55:15","title":"Turning Conversations into Workflows: A Framework to Extract and Evaluate Dialog Workflows for Service AI Agents","abstract":"Automated service agents require well-structured workflows to provide consistent and accurate responses to customer queries. However, these workflows are often undocumented, and their automatic extraction from conversations remains unexplored. In this work, we present a novel framework for extracting and evaluating dialog workflows from historical interactions. Our extraction process consists of two key stages: (1) a retrieval step to select relevant conversations based on key procedural elements, and (2) a structured workflow generation process using a question-answer-based chain-of-thought (QA-CoT) prompting. To comprehensively assess the quality of extracted workflows, we introduce an automated agent and customer bots simulation framework that measures their effectiveness in resolving customer issues. Extensive experiments on the ABCD and SynthABCD datasets demonstrate that our QA-CoT technique improves workflow extraction by 12.16\\% in average macro accuracy over the baseline. Moreover, our evaluation method closely aligns with human assessments, providing a reliable and scalable framework for future research.","sentences":["Automated service agents require well-structured workflows to provide consistent and accurate responses to customer queries.","However, these workflows are often undocumented, and their automatic extraction from conversations remains unexplored.","In this work, we present a novel framework for extracting and evaluating dialog workflows from historical interactions.","Our extraction process consists of two key stages: (1) a retrieval step to select relevant conversations based on key procedural elements, and (2) a structured workflow generation process using a question-answer-based chain-of-thought (QA-CoT) prompting.","To comprehensively assess the quality of extracted workflows, we introduce an automated agent and customer bots simulation framework that measures their effectiveness in resolving customer issues.","Extensive experiments on the ABCD and SynthABCD datasets demonstrate that our QA-CoT technique improves workflow extraction by 12.16\\% in average macro accuracy over the baseline.","Moreover, our evaluation method closely aligns with human assessments, providing a reliable and scalable framework for future research."],"url":"http://arxiv.org/abs/2502.17321v1"}
{"created":"2025-02-24 16:50:55","title":"HIPPO: Enhancing the Table Understanding Capability of Large Language Models through Hybrid-Modal Preference Optimization","abstract":"Tabular data contains rich structural semantics and plays a crucial role in organizing and manipulating information. To better capture these structural semantics, this paper introduces the HybrId-modal Preference oPtimizatiOn (HIPPO) model, which represents tables using both text and image, and optimizes MLLMs to effectively learn more comprehensive table information from these multiple modalities. Specifically, HIPPO samples model responses from hybrid-modal table representations and designs a modality-consistent sampling strategy to enhance response diversity and mitigate modality bias during DPO training. Experimental results on table question answering and table fact verification tasks demonstrate the effectiveness of HIPPO, achieving a 4% improvement over various table reasoning models. Further analysis reveals that HIPPO not only enhances reasoning abilities based on unimodal table representations but also facilitates the extraction of crucial and distinct semantics from different modal representations. All data and codes are available at https://github.com/NEUIR/HIPPO.","sentences":["Tabular data contains rich structural semantics and plays a crucial role in organizing and manipulating information.","To better capture these structural semantics, this paper introduces the HybrId-modal Preference oPtimizatiOn (HIPPO) model, which represents tables using both text and image, and optimizes MLLMs to effectively learn more comprehensive table information from these multiple modalities.","Specifically, HIPPO samples model responses from hybrid-modal table representations and designs a modality-consistent sampling strategy to enhance response diversity and mitigate modality bias during DPO training.","Experimental results on table question answering and table fact verification tasks demonstrate the effectiveness of HIPPO, achieving a 4% improvement over various table reasoning models.","Further analysis reveals that HIPPO not only enhances reasoning abilities based on unimodal table representations but also facilitates the extraction of crucial and distinct semantics from different modal representations.","All data and codes are available at https://github.com/NEUIR/HIPPO."],"url":"http://arxiv.org/abs/2502.17315v1"}
{"created":"2025-02-24 16:50:01","title":"Inverse Kinematics on Guiding Vector Fields for Robot Path Following","abstract":"Inverse kinematics is a fundamental technique for motion and positioning control in robotics, typically applied to end-effectors. In this paper, we extend the concept of inverse kinematics to guiding vector fields for path following in autonomous mobile robots. The desired path is defined by its implicit equation, i.e., by a collection of points belonging to one or more zero-level sets. These level sets serve as a reference to construct an error signal that drives the guiding vector field toward the desired path, enabling the robot to converge and travel along the path by following such a vector field. We start with the formal exposition on how inverse kinematics can be applied to guiding vector fields for single-integrator robots in an m-dimensional Euclidean space. Then, we leverage inverse kinematics to ensure that the level-set error signal behaves as a linear system, facilitating control over the robot's transient motion toward the desired path and allowing for the injection of feed-forward signals to induce precise motion behavior along the path. We then propose solutions to the theoretical and practical challenges of applying this technique to unicycles with constant speeds to follow 2D paths with precise transient control. We finish by validating the predicted theoretical results through real flights with fixed-wing drones.","sentences":["Inverse kinematics is a fundamental technique for motion and positioning control in robotics, typically applied to end-effectors.","In this paper, we extend the concept of inverse kinematics to guiding vector fields for path following in autonomous mobile robots.","The desired path is defined by its implicit equation, i.e., by a collection of points belonging to one or more zero-level sets.","These level sets serve as a reference to construct an error signal that drives the guiding vector field toward the desired path, enabling the robot to converge and travel along the path by following such a vector field.","We start with the formal exposition on how inverse kinematics can be applied to guiding vector fields for single-integrator robots in an m-dimensional Euclidean space.","Then, we leverage inverse kinematics to ensure that the level-set error signal behaves as a linear system, facilitating control over the robot's transient motion toward the desired path and allowing for the injection of feed-forward signals to induce precise motion behavior along the path.","We then propose solutions to the theoretical and practical challenges of applying this technique to unicycles with constant speeds to follow 2D paths with precise transient control.","We finish by validating the predicted theoretical results through real flights with fixed-wing drones."],"url":"http://arxiv.org/abs/2502.17313v1"}
{"created":"2025-02-24 16:44:20","title":"Hybrid Human-Machine Perception via Adaptive LiDAR for Advanced Driver Assistance Systems","abstract":"Accurate environmental perception is critical for advanced driver assistance systems (ADAS). Light detection and ranging (LiDAR) systems play a crucial role in ADAS; they can reliably detect obstacles and help ensure traffic safety. Existing research on LiDAR sensing has demonstrated that adapting the LiDAR's resolution and range based on environmental characteristics can improve machine perception. However, current adaptive LiDAR approaches for ADAS have not explored the possibility of combining the perception abilities of the vehicle and the human driver, which can potentially further enhance the detection performance. In this paper, we propose a novel system that adapts LiDAR characteristics to human driver's visual perception to enhance LiDAR sensing outside human's field of view. We develop a proof-of-concept prototype of the system in the virtual environment CARLA. Our system integrates real-time data on the driver's gaze to identify regions in the environment that the driver is monitoring. This allows the system to optimize LiDAR resources by dynamically increasing the LiDAR's range and resolution in peripheral areas that the driver may not be attending to. Our simulations show that this gaze-aware LiDAR enhances detection performance compared to a baseline standalone LiDAR, particularly in challenging environmental conditions like fog. Our hybrid human-machine sensing approach potentially offers improved safety and situational awareness in real-time driving scenarios for ADAS applications.","sentences":["Accurate environmental perception is critical for advanced driver assistance systems (ADAS).","Light detection and ranging (LiDAR) systems play a crucial role in ADAS; they can reliably detect obstacles and help ensure traffic safety.","Existing research on LiDAR sensing has demonstrated that adapting the LiDAR's resolution and range based on environmental characteristics can improve machine perception.","However, current adaptive LiDAR approaches for ADAS have not explored the possibility of combining the perception abilities of the vehicle and the human driver, which can potentially further enhance the detection performance.","In this paper, we propose a novel system that adapts LiDAR characteristics to human driver's visual perception to enhance LiDAR sensing outside human's field of view.","We develop a proof-of-concept prototype of the system in the virtual environment CARLA.","Our system integrates real-time data on the driver's gaze to identify regions in the environment that the driver is monitoring.","This allows the system to optimize LiDAR resources by dynamically increasing the LiDAR's range and resolution in peripheral areas that the driver may not be attending to.","Our simulations show that this gaze-aware LiDAR enhances detection performance compared to a baseline standalone LiDAR, particularly in challenging environmental conditions like fog.","Our hybrid human-machine sensing approach potentially offers improved safety and situational awareness in real-time driving scenarios for ADAS applications."],"url":"http://arxiv.org/abs/2502.17309v1"}
{"created":"2025-02-24 16:43:05","title":"Implicit Word Reordering with Knowledge Distillation for Cross-Lingual Dependency Parsing","abstract":"Word order difference between source and target languages is a major obstacle to cross-lingual transfer, especially in the dependency parsing task. Current works are mostly based on order-agnostic models or word reordering to mitigate this problem. However, such methods either do not leverage grammatical information naturally contained in word order or are computationally expensive as the permutation space grows exponentially with the sentence length. Moreover, the reordered source sentence with an unnatural word order may be a form of noising that harms the model learning. To this end, we propose an Implicit Word Reordering framework with Knowledge Distillation (IWR-KD). This framework is inspired by that deep networks are good at learning feature linearization corresponding to meaningful data transformation, e.g. word reordering. To realize this idea, we introduce a knowledge distillation framework composed of a word-reordering teacher model and a dependency parsing student model. We verify our proposed method on Universal Dependency Treebanks across 31 different languages and show it outperforms a series of competitors, together with experimental analysis to illustrate how our method works towards training a robust parser.","sentences":["Word order difference between source and target languages is a major obstacle to cross-lingual transfer, especially in the dependency parsing task.","Current works are mostly based on order-agnostic models or word reordering to mitigate this problem.","However, such methods either do not leverage grammatical information naturally contained in word order or are computationally expensive as the permutation space grows exponentially with the sentence length.","Moreover, the reordered source sentence with an unnatural word order may be a form of noising that harms the model learning.","To this end, we propose an Implicit Word Reordering framework with Knowledge Distillation (IWR-KD).","This framework is inspired by that deep networks are good at learning feature linearization corresponding to meaningful data transformation, e.g. word reordering.","To realize this idea, we introduce a knowledge distillation framework composed of a word-reordering teacher model and a dependency parsing student model.","We verify our proposed method on Universal Dependency Treebanks across 31 different languages and show it outperforms a series of competitors, together with experimental analysis to illustrate how our method works towards training a robust parser."],"url":"http://arxiv.org/abs/2502.17308v1"}
{"created":"2025-02-24 16:42:51","title":"Survey on Strategic Mining in Blockchain: A Reinforcement Learning Approach","abstract":"Strategic mining attacks, such as selfish mining, exploit blockchain consensus protocols by deviating from honest behavior to maximize rewards. Markov Decision Process (MDP) analysis faces scalability challenges in modern digital economics, including blockchain. To address these limitations, reinforcement learning (RL) provides a scalable alternative, enabling adaptive strategy optimization in complex dynamic environments.   In this survey, we examine RL's role in strategic mining analysis, comparing it to MDP-based approaches. We begin by reviewing foundational MDP models and their limitations, before exploring RL frameworks that can learn near-optimal strategies across various protocols. Building on this analysis, we compare RL techniques and their effectiveness in deriving security thresholds, such as the minimum attacker power required for profitable attacks. Expanding the discussion further, we classify consensus protocols and propose open challenges, such as multi-agent dynamics and real-world validation.   This survey highlights the potential of reinforcement learning (RL) to address the challenges of selfish mining, including protocol design, threat detection, and security analysis, while offering a strategic roadmap for researchers in decentralized systems and AI-driven analytics.","sentences":["Strategic mining attacks, such as selfish mining, exploit blockchain consensus protocols by deviating from honest behavior to maximize rewards.","Markov Decision Process (MDP) analysis faces scalability challenges in modern digital economics, including blockchain.","To address these limitations, reinforcement learning (RL) provides a scalable alternative, enabling adaptive strategy optimization in complex dynamic environments.   ","In this survey, we examine RL's role in strategic mining analysis, comparing it to MDP-based approaches.","We begin by reviewing foundational MDP models and their limitations, before exploring RL frameworks that can learn near-optimal strategies across various protocols.","Building on this analysis, we compare RL techniques and their effectiveness in deriving security thresholds, such as the minimum attacker power required for profitable attacks.","Expanding the discussion further, we classify consensus protocols and propose open challenges, such as multi-agent dynamics and real-world validation.   ","This survey highlights the potential of reinforcement learning (RL) to address the challenges of selfish mining, including protocol design, threat detection, and security analysis, while offering a strategic roadmap for researchers in decentralized systems and AI-driven analytics."],"url":"http://arxiv.org/abs/2502.17307v1"}
{"created":"2025-02-24 16:41:38","title":"`Generalization is hallucination' through the lens of tensor completions","abstract":"In this short position paper, we introduce tensor completions and artifacts and make the case that they are a useful theoretical framework for understanding certain types of hallucinations and generalizations in language models.","sentences":["In this short position paper, we introduce tensor completions and artifacts and make the case that they are a useful theoretical framework for understanding certain types of hallucinations and generalizations in language models."],"url":"http://arxiv.org/abs/2502.17305v1"}
{"created":"2025-02-24 16:40:46","title":"Child vs. machine language learning: Can the logical structure of human language unleash LLMs?","abstract":"We argue that human language learning proceeds in a manner that is different in nature from current approaches to training LLMs, predicting a difference in learning biases. We then present evidence from German plural formation by LLMs that confirm our hypothesis that even very powerful implementations produce results that miss aspects of the logic inherent to language that humans have no problem with. We conclude that attention to the different structures of human language and artificial neural networks is likely to be an avenue to improve LLM performance.","sentences":["We argue that human language learning proceeds in a manner that is different in nature from current approaches to training LLMs, predicting a difference in learning biases.","We then present evidence from German plural formation by LLMs that confirm our hypothesis that even very powerful implementations produce results that miss aspects of the logic inherent to language that humans have no problem with.","We conclude that attention to the different structures of human language and artificial neural networks is likely to be an avenue to improve LLM performance."],"url":"http://arxiv.org/abs/2502.17304v1"}
{"created":"2025-02-24 16:32:22","title":"Delta Decompression for MoE-based LLMs Compression","abstract":"Mixture-of-Experts (MoE) architectures in large language models (LLMs) achieve exceptional performance, but face prohibitive storage and memory requirements. To address these challenges, we present $D^2$-MoE, a new delta decompression compressor for reducing the parameters of MoE LLMs. Based on observations of expert diversity, we decompose their weights into a shared base weight and unique delta weights. Specifically, our method first merges each expert's weight into the base weight using the Fisher information matrix to capture shared components. Then, we compress delta weights through Singular Value Decomposition (SVD) by exploiting their low-rank properties. Finally, we introduce a semi-dynamical structured pruning strategy for the base weights, combining static and dynamic redundancy analysis to achieve further parameter reduction while maintaining input adaptivity. In this way, our $D^2$-MoE successfully compact MoE LLMs to high compression ratios without additional training. Extensive experiments highlight the superiority of our approach, with over 13% performance gains than other compressors on Mixtral|Phi-3.5|DeepSeek|Qwen2 MoE LLMs at 40$\\sim$60% compression rates. Codes are available in https://github.com/lliai/D2MoE.","sentences":["Mixture-of-Experts (MoE) architectures in large language models (LLMs) achieve exceptional performance, but face prohibitive storage and memory requirements.","To address these challenges, we present $D^2$-MoE, a new delta decompression compressor for reducing the parameters of MoE LLMs.","Based on observations of expert diversity, we decompose their weights into a shared base weight and unique delta weights.","Specifically, our method first merges each expert's weight into the base weight using the Fisher information matrix to capture shared components.","Then, we compress delta weights through Singular Value Decomposition (SVD) by exploiting their low-rank properties.","Finally, we introduce a semi-dynamical structured pruning strategy for the base weights, combining static and dynamic redundancy analysis to achieve further parameter reduction while maintaining input adaptivity.","In this way, our $D^2$-MoE successfully compact MoE LLMs to high compression ratios without additional training.","Extensive experiments highlight the superiority of our approach, with over 13% performance gains than other compressors on Mixtral|Phi-3.5|DeepSeek|Qwen2 MoE LLMs at 40$\\sim$60% compression rates.","Codes are available in https://github.com/lliai/D2MoE."],"url":"http://arxiv.org/abs/2502.17298v1"}
{"created":"2025-02-24 16:25:25","title":"Benchmarking Retrieval-Augmented Generation in Multi-Modal Contexts","abstract":"This paper introduces Multi-Modal Retrieval-Augmented Generation (M^2RAG), a benchmark designed to evaluate the effectiveness of Multi-modal Large Language Models (MLLMs) in leveraging knowledge from multi-modal retrieval documents. The benchmark comprises four tasks: image captioning, multi-modal question answering, multi-modal fact verification, and image reranking. All tasks are set in an open-domain setting, requiring RAG models to retrieve query-relevant information from a multi-modal document collection and use it as input context for RAG modeling. To enhance the context utilization capabilities of MLLMs, we also introduce Multi-Modal Retrieval-Augmented Instruction Tuning (MM-RAIT), an instruction tuning method that optimizes MLLMs within multi-modal contexts. Our experiments show that MM-RAIT improves the performance of RAG systems by enabling them to effectively learn from multi-modal contexts. All data and code are available at https://github.com/NEUIR/M2RAG.","sentences":["This paper introduces Multi-Modal Retrieval-Augmented Generation (M^2RAG), a benchmark designed to evaluate the effectiveness of Multi-modal Large Language Models (MLLMs) in leveraging knowledge from multi-modal retrieval documents.","The benchmark comprises four tasks: image captioning, multi-modal question answering, multi-modal fact verification, and image reranking.","All tasks are set in an open-domain setting, requiring RAG models to retrieve query-relevant information from a multi-modal document collection and use it as input context for RAG modeling.","To enhance the context utilization capabilities of MLLMs, we also introduce Multi-Modal Retrieval-Augmented Instruction Tuning (MM-RAIT), an instruction tuning method that optimizes MLLMs within multi-modal contexts.","Our experiments show that MM-RAIT improves the performance of RAG systems by enabling them to effectively learn from multi-modal contexts.","All data and code are available at https://github.com/NEUIR/M2RAG."],"url":"http://arxiv.org/abs/2502.17297v1"}
{"created":"2025-02-24 16:22:57","title":"Co-Designing Augmented Reality Tools for High-Stakes Clinical Teamwork","abstract":"How might healthcare workers (HCWs) leverage augmented reality head-mounted displays (AR-HMDs) to enhance teamwork? Although AR-HMDs have shown immense promise in supporting teamwork in healthcare settings, design for Emergency Department (ER) teams has received little attention. The ER presents unique challenges, including procedural recall, medical errors, and communication gaps. To address this gap, we engaged in a participatory design study with healthcare workers to gain a deep understanding of the potential for AR-HMDs to facilitate teamwork during ER procedures. Our results reveal that AR-HMDs can be used as an information-sharing and information-retrieval system to bridge knowledge gaps, and concerns about integrating AR-HMDs in ER workflows. We contribute design recommendations for seven role-based AR-HMD application scenarios involving HCWs with various expertise, working across multiple medical tasks. We hope our research inspires designers to embark on the development of new AR-HMD applications for high-stakes, team environments.","sentences":["How might healthcare workers (HCWs) leverage augmented reality head-mounted displays (AR-HMDs) to enhance teamwork?","Although AR-HMDs have shown immense promise in supporting teamwork in healthcare settings, design for Emergency Department (ER) teams has received little attention.","The ER presents unique challenges, including procedural recall, medical errors, and communication gaps.","To address this gap, we engaged in a participatory design study with healthcare workers to gain a deep understanding of the potential for AR-HMDs to facilitate teamwork during ER procedures.","Our results reveal that AR-HMDs can be used as an information-sharing and information-retrieval system to bridge knowledge gaps, and concerns about integrating AR-HMDs in ER workflows.","We contribute design recommendations for seven role-based AR-HMD application scenarios involving HCWs with various expertise, working across multiple medical tasks.","We hope our research inspires designers to embark on the development of new AR-HMD applications for high-stakes, team environments."],"url":"http://arxiv.org/abs/2502.17295v1"}
{"created":"2025-02-24 16:22:10","title":"The Challenges of Bringing Religious and Philosophical Values Into Design","abstract":"HCI is increasingly taking inspiration from philosophical and religious traditions as a basis for ethical technology designs. If these values are to be incorporated into real-world designs, there may be challenges when designers work with values unfamiliar to them. Therefore, we investigate the variance in interpretations when values are translated to technology designs. To do so we identified social media designs that embodied the main principles of Catholic Social Teaching (CST). We then interviewed 24 technology experts with varying levels of familiarity with CST to assess how their understanding of how those values would manifest in a technology design. We found that familiarity with CST did not impact participant responses: there were clear patterns in how all participant responses differed from the values we determined the designs embodied. We propose that value experts be included in the design process to more effectively create designs that embody particular values.","sentences":["HCI is increasingly taking inspiration from philosophical and religious traditions as a basis for ethical technology designs.","If these values are to be incorporated into real-world designs, there may be challenges when designers work with values unfamiliar to them.","Therefore, we investigate the variance in interpretations when values are translated to technology designs.","To do so we identified social media designs that embodied the main principles of Catholic Social Teaching (CST).","We then interviewed 24 technology experts with varying levels of familiarity with CST to assess how their understanding of how those values would manifest in a technology design.","We found that familiarity with CST did not impact participant responses: there were clear patterns in how all participant responses differed from the values we determined the designs embodied.","We propose that value experts be included in the design process to more effectively create designs that embody particular values."],"url":"http://arxiv.org/abs/2502.17293v1"}
{"created":"2025-02-24 16:21:50","title":"Joint Value Estimation and Bidding in Repeated First-Price Auctions","abstract":"We study regret minimization in repeated first-price auctions (FPAs), where a bidder observes only the realized outcome after each auction -- win or loss. This setup reflects practical scenarios in online display advertising where the actual value of an impression depends on the difference between two potential outcomes, such as clicks or conversion rates, when the auction is won versus lost. We analyze three outcome models: (1) adversarial outcomes without features, (2) linear potential outcomes with features, and (3) linear treatment effects in features. For each setting, we propose algorithms that jointly estimate private values and optimize bidding strategies, achieving near-optimal regret bounds. Notably, our framework enjoys a unique feature that the treatments are also actively chosen, and hence eliminates the need for the overlap condition commonly required in causal inference.","sentences":["We study regret minimization in repeated first-price auctions (FPAs), where a bidder observes only the realized outcome after each auction -- win or loss.","This setup reflects practical scenarios in online display advertising where the actual value of an impression depends on the difference between two potential outcomes, such as clicks or conversion rates, when the auction is won versus lost.","We analyze three outcome models: (1) adversarial outcomes without features, (2) linear potential outcomes with features, and (3) linear treatment effects in features.","For each setting, we propose algorithms that jointly estimate private values and optimize bidding strategies, achieving near-optimal regret bounds.","Notably, our framework enjoys a unique feature that the treatments are also actively chosen, and hence eliminates the need for the overlap condition commonly required in causal inference."],"url":"http://arxiv.org/abs/2502.17292v1"}
{"created":"2025-02-24 16:20:25","title":"A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification","abstract":"In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem. It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification. Thus we address the problem of unknown species classification by assigning it best hierarchical labels. We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification. The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification. Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones. It uses attention scores to focus on important features across multiple scales. The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species. The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application. We used unknown species for testing our model. For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively. Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application.","sentences":["In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem.","It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification.","Thus we address the problem of unknown species classification by assigning it best hierarchical labels.","We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification.","The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification.","Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones.","It uses attention scores to focus on important features across multiple scales.","The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species.","The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application.","We used unknown species for testing our model.","For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively.","Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application."],"url":"http://arxiv.org/abs/2502.17289v1"}
{"created":"2025-02-24 16:16:01","title":"GaussianFlowOcc: Sparse and Weakly Supervised Occupancy Estimation using Gaussian Splatting and Temporal Flow","abstract":"Occupancy estimation has become a prominent task in 3D computer vision, particularly within the autonomous driving community. In this paper, we present a novel approach to occupancy estimation, termed GaussianFlowOcc, which is inspired by Gaussian Splatting and replaces traditional dense voxel grids with a sparse 3D Gaussian representation. Our efficient model architecture based on a Gaussian Transformer significantly reduces computational and memory requirements by eliminating the need for expensive 3D convolutions used with inefficient voxel-based representations that predominantly represent empty 3D spaces. GaussianFlowOcc effectively captures scene dynamics by estimating temporal flow for each Gaussian during the overall network training process, offering a straightforward solution to a complex problem that is often neglected by existing methods. Moreover, GaussianFlowOcc is designed for scalability, as it employs weak supervision and does not require costly dense 3D voxel annotations based on additional data (e.g., LiDAR). Through extensive experimentation, we demonstrate that GaussianFlowOcc significantly outperforms all previous methods for weakly supervised occupancy estimation on the nuScenes dataset while featuring an inference speed that is 50 times faster than current SOTA.","sentences":["Occupancy estimation has become a prominent task in 3D computer vision, particularly within the autonomous driving community.","In this paper, we present a novel approach to occupancy estimation, termed GaussianFlowOcc, which is inspired by Gaussian Splatting and replaces traditional dense voxel grids with a sparse 3D Gaussian representation.","Our efficient model architecture based on a Gaussian Transformer significantly reduces computational and memory requirements by eliminating the need for expensive 3D convolutions used with inefficient voxel-based representations that predominantly represent empty 3D spaces.","GaussianFlowOcc effectively captures scene dynamics by estimating temporal flow for each Gaussian during the overall network training process, offering a straightforward solution to a complex problem that is often neglected by existing methods.","Moreover, GaussianFlowOcc is designed for scalability, as it employs weak supervision and does not require costly dense 3D voxel annotations based on additional data (e.g., LiDAR).","Through extensive experimentation, we demonstrate that GaussianFlowOcc significantly outperforms all previous methods for weakly supervised occupancy estimation on the nuScenes dataset while featuring an inference speed that is 50 times faster than current SOTA."],"url":"http://arxiv.org/abs/2502.17288v1"}
{"created":"2025-02-24 16:11:13","title":"Improving the Inclusivity of Dutch Speech Recognition by Fine-tuning Whisper on the JASMIN-CGN Corpus","abstract":"We test and study the variation in speech recognition of fine-tuned versions of the Whisper model on child, elderly and non-native Dutch speech from the JASMIN-CGN corpus. Our primary goal is to evaluate how speakers' age and linguistic background influence Whisper's performance. Whisper achieves varying Word Error Rates (WER) when fine-tuned on subpopulations of specific ages and linguistic backgrounds. Fine-tuned performance is remarkably better than zero-shot performance, achieving a relative reduction in WER of 81% for native children, 72% for non-native children, 67% for non-native adults, and 65% for native elderly people. Our findings underscore the importance of training speech recognition models like Whisper on underrepresented subpopulations such as children, the elderly, and non-native speakers.","sentences":["We test and study the variation in speech recognition of fine-tuned versions of the Whisper model on child, elderly and non-native Dutch speech from the JASMIN-CGN corpus.","Our primary goal is to evaluate how speakers' age and linguistic background influence Whisper's performance.","Whisper achieves varying Word Error Rates (WER) when fine-tuned on subpopulations of specific ages and linguistic backgrounds.","Fine-tuned performance is remarkably better than zero-shot performance, achieving a relative reduction in WER of 81% for native children, 72% for non-native children, 67% for non-native adults, and 65% for native elderly people.","Our findings underscore the importance of training speech recognition models like Whisper on underrepresented subpopulations such as children, the elderly, and non-native speakers."],"url":"http://arxiv.org/abs/2502.17284v1"}
{"created":"2025-02-24 16:10:53","title":"Capability Instruction Tuning: A New Paradigm for Dynamic LLM Routing","abstract":"Large Language Models (LLMs) have demonstrated human-like instruction-following abilities, particularly those exceeding 100 billion parameters. The combined capability of some smaller, resource-friendly LLMs can address most of the instructions that larger LLMs excel at. In this work, we explore how to route the best-performing LLM for each instruction to achieve better overall performance. We develop a new paradigm, constructing capability instructions with model capability representation, user instruction, and performance inquiry prompts to assess the performance. To learn from capability instructions, we introduce a new end-to-end framework called Model Selection with Aptitude Test (Model-SAT), which generates positive and negative samples based on what different models perform well or struggle with. Model-SAT uses a model capability encoder that extends its model representation to a lightweight LLM. Our experiments show that Model-SAT understands the performance dimensions of candidate models and provides the probabilities of their capability to handle various instructions. Additionally, during deployment, a new model can quickly infer its aptitude test results across 50 tasks, each with 20 shots. Model-SAT performs state-of-the-art model routing without candidate inference and in real-world new model-released scenarios. The code is available at https://github.com/Now-Join-Us/CIT-LLM-Routing","sentences":["Large Language Models (LLMs) have demonstrated human-like instruction-following abilities, particularly those exceeding 100 billion parameters.","The combined capability of some smaller, resource-friendly LLMs can address most of the instructions that larger LLMs excel at.","In this work, we explore how to route the best-performing LLM for each instruction to achieve better overall performance.","We develop a new paradigm, constructing capability instructions with model capability representation, user instruction, and performance inquiry prompts to assess the performance.","To learn from capability instructions, we introduce a new end-to-end framework called Model Selection with Aptitude Test (Model-SAT), which generates positive and negative samples based on what different models perform well or struggle with.","Model-SAT uses a model capability encoder that extends its model representation to a lightweight LLM.","Our experiments show that Model-SAT understands the performance dimensions of candidate models and provides the probabilities of their capability to handle various instructions.","Additionally, during deployment, a new model can quickly infer its aptitude test results across 50 tasks, each with 20 shots.","Model-SAT performs state-of-the-art model routing without candidate inference and in real-world new model-released scenarios.","The code is available at https://github.com/Now-Join-Us/CIT-LLM-Routing"],"url":"http://arxiv.org/abs/2502.17282v1"}
{"created":"2025-02-24 16:06:35","title":"Extracting domain-specific terms using contextual word embeddings","abstract":"Automated terminology extraction refers to the task of extracting meaningful terms from domain-specific texts. This paper proposes a novel machine learning approach to terminology extraction, which combines features from traditional term extraction systems with novel contextual features derived from contextual word embeddings. Instead of using a predefined list of part-of-speech patterns, we first analyse a new term-annotated corpus RSDO5 for the Slovenian language and devise a set of rules for term candidate selection and then generate statistical, linguistic and context-based features. We use a support-vector machine algorithm to train a classification model, evaluate it on the four domains (biomechanics, linguistics, chemistry, veterinary) of the RSDO5 corpus and compare the results with state-of-art term extraction approaches for the Slovenian language. Our approach provides significant improvements in terms of F1 score over the previous state-of-the-art, which proves that contextual word embeddings are valuable for improving term extraction.","sentences":["Automated terminology extraction refers to the task of extracting meaningful terms from domain-specific texts.","This paper proposes a novel machine learning approach to terminology extraction, which combines features from traditional term extraction systems with novel contextual features derived from contextual word embeddings.","Instead of using a predefined list of part-of-speech patterns, we first analyse a new term-annotated corpus RSDO5 for the Slovenian language and devise a set of rules for term candidate selection and then generate statistical, linguistic and context-based features.","We use a support-vector machine algorithm to train a classification model, evaluate it on the four domains (biomechanics, linguistics, chemistry, veterinary) of the RSDO5 corpus and compare the results with state-of-art term extraction approaches for the Slovenian language.","Our approach provides significant improvements in terms of F1 score over the previous state-of-the-art, which proves that contextual word embeddings are valuable for improving term extraction."],"url":"http://arxiv.org/abs/2502.17278v1"}
{"created":"2025-02-24 16:05:17","title":"Property Testing of Curve Similarity","abstract":"We propose sublinear algorithms for probabilistic testing of the discrete and continuous Fr\\'echet distance - a standard similarity measure for curves. We assume the algorithm is given access to the input curves via a query oracle: a query returns the set of vertices of the curve that lie within a radius $\\delta$ of a specified vertex of the other curve. The goal is to use a small number of queries to determine with constant probability whether the two curves are similar (i.e., their discrete Fr\\'echet distance is at most $\\delta$) or they are ''$\\varepsilon$-far'' (for $0 < \\varepsilon < 2$) from being similar, i.e., more than an $\\varepsilon$-fraction of the two curves must be ignored for them to become similar. We present two algorithms which are sublinear assuming that the curves are $t$-approximate shortest paths in the ambient metric space, for some $t\\ll n$. The first algorithm uses $O(\\frac{t}{\\varepsilon}\\log\\frac{t}{\\varepsilon})$ queries and is given the value of $t$ in advance. The second algorithm does not have explicit knowledge of the value of $t$ and therefore needs to gain implicit knowledge of the straightness of the input curves through its queries. We show that the discrete Fr\\'echet distance can still be tested using roughly $O(\\frac{t^3+t^2\\log n}{\\varepsilon})$ queries ignoring logarithmic factors in $t$. Our algorithms work in a matrix representation of the input and may be of independent interest to matrix testing. Our algorithms use a mild uniform sampling condition that constrains the edge lengths of the curves, similar to a polynomially bounded aspect ratio. Applied to testing the continuous Fr\\'echet distance of $t$-straight curves, our algorithms can be used for $(1+\\varepsilon')$-approximate testing using essentially the same bounds as stated above with an additional factor of poly$(\\frac{1}{\\varepsilon'})$.","sentences":["We propose sublinear algorithms for probabilistic testing of the discrete and continuous Fr\\'echet distance - a standard similarity measure for curves.","We assume the algorithm is given access to the input curves via a query oracle: a query returns the set of vertices of the curve that lie within a radius $\\delta$ of a specified vertex of the other curve.","The goal is to use a small number of queries to determine with constant probability whether the two curves are similar (i.e., their discrete Fr\\'echet distance is at most $\\delta$) or they are ''$\\varepsilon$-far'' (for $0 <","\\varepsilon < 2$) from being similar, i.e., more than an $\\varepsilon$-fraction of the two curves must be ignored for them to become similar.","We present two algorithms which are sublinear assuming that the curves are $t$-approximate shortest paths in the ambient metric space, for some $t\\ll n$. The first algorithm uses $O(\\frac{t}{\\varepsilon}\\log\\frac{t}{\\varepsilon})$ queries and is given the value of $t$ in advance.","The second algorithm does not have explicit knowledge of the value of $t$ and therefore needs to gain implicit knowledge of the straightness of the input curves through its queries.","We show that the discrete Fr\\'echet distance can still be tested using roughly $O(\\frac{t^3+t^2\\log n}{\\varepsilon})$ queries ignoring logarithmic factors in $t$. Our algorithms work in a matrix representation of the input and may be of independent interest to matrix testing.","Our algorithms use a mild uniform sampling condition that constrains the edge lengths of the curves, similar to a polynomially bounded aspect ratio.","Applied to testing the continuous Fr\\'echet distance of $t$-straight curves, our algorithms can be used for $(1+\\varepsilon')$-approximate testing using essentially the same bounds as stated above with an additional factor of poly$(\\frac{1}{\\varepsilon'})$."],"url":"http://arxiv.org/abs/2502.17277v1"}
{"created":"2025-02-24 15:54:02","title":"Order Fairness Evaluation of DAG-based ledgers","abstract":"Order fairness in distributed ledgers refers to properties that relate the order in which transactions are sent or received to the order in which they are eventually finalized, i.e., totally ordered. The study of such properties is relatively new and has been especially stimulated by the rise of Maximal Extractable Value (MEV) attacks in blockchain environments. Indeed, in many classical blockchain protocols, leaders are responsible for selecting the transactions to be included in blocks, which creates a clear vulnerability and opportunity for transaction order manipulation.   Unlike blockchains, DAG-based ledgers allow participants in the network to independently propose blocks, which are then arranged as vertices of a directed acyclic graph. Interestingly, leaders in DAG-based ledgers are elected only after the fact, once transactions are already part of the graph, to determine their total order. In other words, transactions are not chosen by single leaders; instead, they are collectively validated by the nodes, and leaders are only elected to establish an ordering. This approach intuitively reduces the risk of transaction manipulation and enhances fairness.   In this paper, we aim to quantify the capability of DAG-based ledgers to achieve order fairness. To this end, we define new variants of order fairness adapted to DAG-based ledgers and evaluate the impact of an adversary capable of compromising a limited number of nodes (below the one-third threshold) to reorder transactions. We analyze how often our order fairness properties are violated under different network conditions and parameterizations of the DAG algorithm, depending on the adversary's power.   Our study shows that DAG-based ledgers are still vulnerable to reordering attacks, as an adversary can coordinate a minority of Byzantine nodes to manipulate the DAG's structure.","sentences":["Order fairness in distributed ledgers refers to properties that relate the order in which transactions are sent or received to the order in which they are eventually finalized, i.e., totally ordered.","The study of such properties is relatively new and has been especially stimulated by the rise of Maximal Extractable Value (MEV) attacks in blockchain environments.","Indeed, in many classical blockchain protocols, leaders are responsible for selecting the transactions to be included in blocks, which creates a clear vulnerability and opportunity for transaction order manipulation.   ","Unlike blockchains, DAG-based ledgers allow participants in the network to independently propose blocks, which are then arranged as vertices of a directed acyclic graph.","Interestingly, leaders in DAG-based ledgers are elected only after the fact, once transactions are already part of the graph, to determine their total order.","In other words, transactions are not chosen by single leaders; instead, they are collectively validated by the nodes, and leaders are only elected to establish an ordering.","This approach intuitively reduces the risk of transaction manipulation and enhances fairness.   ","In this paper, we aim to quantify the capability of DAG-based ledgers to achieve order fairness.","To this end, we define new variants of order fairness adapted to DAG-based ledgers and evaluate the impact of an adversary capable of compromising a limited number of nodes (below the one-third threshold) to reorder transactions.","We analyze how often our order fairness properties are violated under different network conditions and parameterizations of the DAG algorithm, depending on the adversary's power.   ","Our study shows that DAG-based ledgers are still vulnerable to reordering attacks, as an adversary can coordinate a minority of Byzantine nodes to manipulate the DAG's structure."],"url":"http://arxiv.org/abs/2502.17270v1"}
{"created":"2025-02-24 15:51:42","title":"MonoTODia: Translating Monologue Requests to Task-Oriented Dialogues","abstract":"Data scarcity is one of the main problems when it comes to real-world applications of transformer-based models. This is especially evident for task-oriented dialogue (TOD) systems, which require specialized datasets, that are usually not readily available. This can hinder companies from adding TOD systems to their services. This study therefore investigates a novel approach to sourcing annotated dialogues from existing German monologue material. Focusing on a real-world example, we investigate whether these monologues can be transformed into dialogue formats suitable for training TOD systems. We show the approach with the concrete example of a company specializing in travel bookings via e-mail. We fine-tune state-of-the-art Large Language Models for the task of rewriting e-mails as dialogues and annotating them. To ensure the quality and validity of the generated data, we employ crowd workers to evaluate the dialogues across multiple criteria and to provide gold-standard annotations for the test dataset. We further evaluate the usefulness of the dialogues for training TOD systems. Our evaluation shows that the dialogues and annotations are of high quality and can serve as a valuable starting point for training TOD systems. Finally, we make the annotated dataset publicly available to foster future research.","sentences":["Data scarcity is one of the main problems when it comes to real-world applications of transformer-based models.","This is especially evident for task-oriented dialogue (TOD) systems, which require specialized datasets, that are usually not readily available.","This can hinder companies from adding TOD systems to their services.","This study therefore investigates a novel approach to sourcing annotated dialogues from existing German monologue material.","Focusing on a real-world example, we investigate whether these monologues can be transformed into dialogue formats suitable for training TOD systems.","We show the approach with the concrete example of a company specializing in travel bookings via e-mail.","We fine-tune state-of-the-art Large Language Models for the task of rewriting e-mails as dialogues and annotating them.","To ensure the quality and validity of the generated data, we employ crowd workers to evaluate the dialogues across multiple criteria and to provide gold-standard annotations for the test dataset.","We further evaluate the usefulness of the dialogues for training TOD systems.","Our evaluation shows that the dialogues and annotations are of high quality and can serve as a valuable starting point for training TOD systems.","Finally, we make the annotated dataset publicly available to foster future research."],"url":"http://arxiv.org/abs/2502.17268v1"}
{"created":"2025-02-24 15:48:25","title":"Continuous Wrist Control on the Hannes Prosthesis: a Vision-based Shared Autonomy Framework","abstract":"Most control techniques for prosthetic grasping focus on dexterous fingers control, but overlook the wrist motion. This forces the user to perform compensatory movements with the elbow, shoulder and hip to adapt the wrist for grasping. We propose a computer vision-based system that leverages the collaboration between the user and an automatic system in a shared autonomy framework, to perform continuous control of the wrist degrees of freedom in a prosthetic arm, promoting a more natural approach-to-grasp motion. Our pipeline allows to seamlessly control the prosthetic wrist to follow the target object and finally orient it for grasping according to the user intent. We assess the effectiveness of each system component through quantitative analysis and finally deploy our method on the Hannes prosthetic arm. Code and videos: https://hsp-iit.github.io/hannes-wrist-control.","sentences":["Most control techniques for prosthetic grasping focus on dexterous fingers control, but overlook the wrist motion.","This forces the user to perform compensatory movements with the elbow, shoulder and hip to adapt the wrist for grasping.","We propose a computer vision-based system that leverages the collaboration between the user and an automatic system in a shared autonomy framework, to perform continuous control of the wrist degrees of freedom in a prosthetic arm, promoting a more natural approach-to-grasp motion.","Our pipeline allows to seamlessly control the prosthetic wrist to follow the target object and finally orient it for grasping according to the user intent.","We assess the effectiveness of each system component through quantitative analysis and finally deploy our method on the Hannes prosthetic arm.","Code and videos: https://hsp-iit.github.io/hannes-wrist-control."],"url":"http://arxiv.org/abs/2502.17265v1"}
{"created":"2025-02-24 15:46:18","title":"Kandinsky Conformal Prediction: Beyond Class- and Covariate-Conditional Coverage","abstract":"Conformal prediction is a powerful distribution-free framework for constructing prediction sets with coverage guarantees. Classical methods, such as split conformal prediction, provide marginal coverage, ensuring that the prediction set contains the label of a random test point with a target probability. However, these guarantees may not hold uniformly across different subpopulations, leading to disparities in coverage. Prior work has explored coverage guarantees conditioned on events related to the covariates and label of the test point. We present Kandinsky conformal prediction, a framework that significantly expands the scope of conditional coverage guarantees. In contrast to Mondrian conformal prediction, which restricts its coverage guarantees to disjoint groups -- reminiscent of the rigid, structured grids of Piet Mondrian's art -- our framework flexibly handles overlapping and fractional group memberships defined jointly on covariates and labels, reflecting the layered, intersecting forms in Wassily Kandinsky's compositions. Our algorithm unifies and extends existing methods, encompassing covariate-based group conditional, class conditional, and Mondrian conformal prediction as special cases, while achieving a minimax-optimal high-probability conditional coverage bound. Finally, we demonstrate the practicality of our approach through empirical evaluation on real-world datasets.","sentences":["Conformal prediction is a powerful distribution-free framework for constructing prediction sets with coverage guarantees.","Classical methods, such as split conformal prediction, provide marginal coverage, ensuring that the prediction set contains the label of a random test point with a target probability.","However, these guarantees may not hold uniformly across different subpopulations, leading to disparities in coverage.","Prior work has explored coverage guarantees conditioned on events related to the covariates and label of the test point.","We present Kandinsky conformal prediction, a framework that significantly expands the scope of conditional coverage guarantees.","In contrast to Mondrian conformal prediction, which restricts its coverage guarantees to disjoint groups -- reminiscent of the rigid, structured grids of Piet Mondrian's art -- our framework flexibly handles overlapping and fractional group memberships defined jointly on covariates and labels, reflecting the layered, intersecting forms in Wassily Kandinsky's compositions.","Our algorithm unifies and extends existing methods, encompassing covariate-based group conditional, class conditional, and Mondrian conformal prediction as special cases, while achieving a minimax-optimal high-probability conditional coverage bound.","Finally, we demonstrate the practicality of our approach through empirical evaluation on real-world datasets."],"url":"http://arxiv.org/abs/2502.17264v1"}
{"created":"2025-02-24 15:45:13","title":"Untold Stories: Unveiling the Scarce Contributions of UX Professionals to Usability Issue Discussions of Open Source Software Projects","abstract":"Previous work established that open source software (OSS) projects can benefit from the involvement of UX professionals, who offer user-centric perspectives and contributions to improve software usability. However, their participation in OSS issue discussions (places where design and implementation decisions are often made) is relatively scarce since those platforms are created with a developer-centric mindset. Analyzing a dataset sampled from five OSS projects, this study identifies UX professionals' distinct approaches to raising and following up on usability issues. Compared to other contributors, UX professionals addressed a broader range of usability issues, well-supported their stances, and were more factual than emotional. They also actively engage in discussions to provide additional insights and clarifications in comments following up on the issues they posted. Results from this study provide useful insights for increasing UX professionals' involvement in OSS communities to improve usability and end-user satisfaction.","sentences":["Previous work established that open source software (OSS) projects can benefit from the involvement of UX professionals, who offer user-centric perspectives and contributions to improve software usability.","However, their participation in OSS issue discussions (places where design and implementation decisions are often made) is relatively scarce since those platforms are created with a developer-centric mindset.","Analyzing a dataset sampled from five OSS projects, this study identifies UX professionals' distinct approaches to raising and following up on usability issues.","Compared to other contributors, UX professionals addressed a broader range of usability issues, well-supported their stances, and were more factual than emotional.","They also actively engage in discussions to provide additional insights and clarifications in comments following up on the issues they posted.","Results from this study provide useful insights for increasing UX professionals' involvement in OSS communities to improve usability and end-user satisfaction."],"url":"http://arxiv.org/abs/2502.17263v1"}
{"created":"2025-02-24 15:44:57","title":"Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective","abstract":"The rapid advancements in computing dramatically increase the scale and cost of training Large Language Models (LLMs). Accurately predicting downstream task performance prior to model training is crucial for efficient resource allocation, yet remains challenging due to two primary constraints: (1) the \"emergence phenomenon\", wherein downstream performance metrics become meaningful only after extensive training, which limits the ability to use smaller models for prediction; (2) Uneven task difficulty distributions and the absence of consistent scaling laws, resulting in substantial metric variability. Existing performance prediction methods suffer from limited accuracy and reliability, thereby impeding the assessment of potential LLM capabilities. To address these challenges, we propose a Clustering-On-Difficulty (COD) downstream performance prediction framework. COD first constructs a predictable support subset by clustering tasks based on difficulty features, strategically excluding non-emergent and non-scalable clusters. The scores on the selected subset serve as effective intermediate predictors of downstream performance on the full evaluation set. With theoretical support, we derive a mapping function that transforms performance metrics from the predictable subset to the full evaluation set, thereby ensuring accurate extrapolation of LLM downstream performance. The proposed method has been applied to predict performance scaling for a 70B LLM, providing actionable insights for training resource allocation and assisting in monitoring the training process. Notably, COD achieves remarkable predictive accuracy on the 70B LLM by leveraging an ensemble of small models, demonstrating an absolute mean deviation of 1.36% across eight important LLM evaluation benchmarks.","sentences":["The rapid advancements in computing dramatically increase the scale and cost of training Large Language Models (LLMs).","Accurately predicting downstream task performance prior to model training is crucial for efficient resource allocation, yet remains challenging due to two primary constraints: (1) the \"emergence phenomenon\", wherein downstream performance metrics become meaningful only after extensive training, which limits the ability to use smaller models for prediction; (2) Uneven task difficulty distributions and the absence of consistent scaling laws, resulting in substantial metric variability.","Existing performance prediction methods suffer from limited accuracy and reliability, thereby impeding the assessment of potential LLM capabilities.","To address these challenges, we propose a Clustering-On-Difficulty (COD) downstream performance prediction framework.","COD first constructs a predictable support subset by clustering tasks based on difficulty features, strategically excluding non-emergent and non-scalable clusters.","The scores on the selected subset serve as effective intermediate predictors of downstream performance on the full evaluation set.","With theoretical support, we derive a mapping function that transforms performance metrics from the predictable subset to the full evaluation set, thereby ensuring accurate extrapolation of LLM downstream performance.","The proposed method has been applied to predict performance scaling for a 70B LLM, providing actionable insights for training resource allocation and assisting in monitoring the training process.","Notably, COD achieves remarkable predictive accuracy on the 70B LLM by leveraging an ensemble of small models, demonstrating an absolute mean deviation of 1.36% across eight important LLM evaluation benchmarks."],"url":"http://arxiv.org/abs/2502.17262v1"}
{"created":"2025-02-24 15:44:02","title":"Robust Federated Learning in Unreliable Wireless Networks: A Client Selection Approach","abstract":"Federated learning (FL) has emerged as a promising distributed learning paradigm for training deep neural networks (DNNs) at the wireless edge, but its performance can be severely hindered by unreliable wireless transmission and inherent data heterogeneity among clients. Existing solutions primarily address these challenges by incorporating wireless resource optimization strategies, often focusing on uplink resource allocation across clients under the assumption of homogeneous client-server network standards. However, these approaches overlooked the fact that mobile clients may connect to the server via diverse network standards (e.g., 4G, 5G, Wi-Fi) with customized configurations, limiting the flexibility of server-side modifications and restricting applicability in real-world commercial networks. This paper presents a novel theoretical analysis about how transmission failures in unreliable networks distort the effective label distributions of local samples, causing deviations from the global data distribution and introducing convergence bias in FL. Our analysis reveals that a carefully designed client selection strategy can mitigate biases induced by network unreliability and data heterogeneity. Motivated by this insight, we propose FedCote, a client selection approach that optimizes client selection probabilities without relying on wireless resource scheduling. Experimental results demonstrate the robustness of FedCote in DNN-based classification tasks under unreliable networks with frequent transmission failures.","sentences":["Federated learning (FL) has emerged as a promising distributed learning paradigm for training deep neural networks (DNNs) at the wireless edge, but its performance can be severely hindered by unreliable wireless transmission and inherent data heterogeneity among clients.","Existing solutions primarily address these challenges by incorporating wireless resource optimization strategies, often focusing on uplink resource allocation across clients under the assumption of homogeneous client-server network standards.","However, these approaches overlooked the fact that mobile clients may connect to the server via diverse network standards (e.g., 4G, 5G, Wi-Fi) with customized configurations, limiting the flexibility of server-side modifications and restricting applicability in real-world commercial networks.","This paper presents a novel theoretical analysis about how transmission failures in unreliable networks distort the effective label distributions of local samples, causing deviations from the global data distribution and introducing convergence bias in FL.","Our analysis reveals that a carefully designed client selection strategy can mitigate biases induced by network unreliability and data heterogeneity.","Motivated by this insight, we propose FedCote, a client selection approach that optimizes client selection probabilities without relying on wireless resource scheduling.","Experimental results demonstrate the robustness of FedCote in DNN-based classification tasks under unreliable networks with frequent transmission failures."],"url":"http://arxiv.org/abs/2502.17260v1"}
{"created":"2025-02-24 15:39:31","title":"Detecting Benchmark Contamination Through Watermarking","abstract":"Benchmark contamination poses a significant challenge to the reliability of Large Language Models (LLMs) evaluations, as it is difficult to assert whether a model has been trained on a test set. We introduce a solution to this problem by watermarking benchmarks before their release. The embedding involves reformulating the original questions with a watermarked LLM, in a way that does not alter the benchmark utility. During evaluation, we can detect ``radioactivity'', \\ie traces that the text watermarks leave in the model during training, using a theoretically grounded statistical test. We test our method by pre-training 1B models from scratch on 10B tokens with controlled benchmark contamination, and validate its effectiveness in detecting contamination on ARC-Easy, ARC-Challenge, and MMLU. Results show similar benchmark utility post-watermarking and successful contamination detection when models are contaminated enough to enhance performance, e.g. $p$-val $=10^{-3}$ for +5$\\%$ on ARC-Easy.","sentences":["Benchmark contamination poses a significant challenge to the reliability of Large Language Models (LLMs) evaluations, as it is difficult to assert whether a model has been trained on a test set.","We introduce a solution to this problem by watermarking benchmarks before their release.","The embedding involves reformulating the original questions with a watermarked LLM, in a way that does not alter the benchmark utility.","During evaluation, we can detect ``radioactivity'', \\ie traces that the text watermarks leave in the model during training, using a theoretically grounded statistical test.","We test our method by pre-training 1B models from scratch on 10B tokens with controlled benchmark contamination, and validate its effectiveness in detecting contamination on ARC-Easy, ARC-Challenge, and MMLU.","Results show similar benchmark utility post-watermarking and successful contamination detection when models are contaminated enough to enhance performance, e.g. $p$-val $=10^{-3}$ for +5$\\%$ on ARC-Easy."],"url":"http://arxiv.org/abs/2502.17259v1"}
{"created":"2025-02-24 15:39:14","title":"VideoGrain: Modulating Space-Time Attention for Multi-grained Video Editing","abstract":"Recent advancements in diffusion models have significantly improved video generation and editing capabilities. However, multi-grained video editing, which encompasses class-level, instance-level, and part-level modifications, remains a formidable challenge. The major difficulties in multi-grained editing include semantic misalignment of text-to-region control and feature coupling within the diffusion model. To address these difficulties, we present VideoGrain, a zero-shot approach that modulates space-time (cross- and self-) attention mechanisms to achieve fine-grained control over video content. We enhance text-to-region control by amplifying each local prompt's attention to its corresponding spatial-disentangled region while minimizing interactions with irrelevant areas in cross-attention. Additionally, we improve feature separation by increasing intra-region awareness and reducing inter-region interference in self-attention. Extensive experiments demonstrate our method achieves state-of-the-art performance in real-world scenarios. Our code, data, and demos are available at https://knightyxp.github.io/VideoGrain_project_page/","sentences":["Recent advancements in diffusion models have significantly improved video generation and editing capabilities.","However, multi-grained video editing, which encompasses class-level, instance-level, and part-level modifications, remains a formidable challenge.","The major difficulties in multi-grained editing include semantic misalignment of text-to-region control and feature coupling within the diffusion model.","To address these difficulties, we present VideoGrain, a zero-shot approach that modulates space-time (cross- and self-) attention mechanisms to achieve fine-grained control over video content.","We enhance text-to-region control by amplifying each local prompt's attention to its corresponding spatial-disentangled region while minimizing interactions with irrelevant areas in cross-attention.","Additionally, we improve feature separation by increasing intra-region awareness and reducing inter-region interference in self-attention.","Extensive experiments demonstrate our method achieves state-of-the-art performance in real-world scenarios.","Our code, data, and demos are available at https://knightyxp.github.io/VideoGrain_project_page/"],"url":"http://arxiv.org/abs/2502.17258v1"}
{"created":"2025-02-24 15:34:48","title":"REINFORCE Adversarial Attacks on Large Language Models: An Adaptive, Distributional, and Semantic Objective","abstract":"To circumvent the alignment of large language models (LLMs), current optimization-based adversarial attacks usually craft adversarial prompts by maximizing the likelihood of a so-called affirmative response. An affirmative response is a manually designed start of a harmful answer to an inappropriate request. While it is often easy to craft prompts that yield a substantial likelihood for the affirmative response, the attacked model frequently does not complete the response in a harmful manner. Moreover, the affirmative objective is usually not adapted to model-specific preferences and essentially ignores the fact that LLMs output a distribution over responses. If low attack success under such an objective is taken as a measure of robustness, the true robustness might be grossly overestimated. To alleviate these flaws, we propose an adaptive and semantic optimization problem over the population of responses. We derive a generally applicable objective via the REINFORCE policy-gradient formalism and demonstrate its efficacy with the state-of-the-art jailbreak algorithms Greedy Coordinate Gradient (GCG) and Projected Gradient Descent (PGD). For example, our objective doubles the attack success rate (ASR) on Llama3 and increases the ASR from 2% to 50% with circuit breaker defense.","sentences":["To circumvent the alignment of large language models (LLMs), current optimization-based adversarial attacks usually craft adversarial prompts by maximizing the likelihood of a so-called affirmative response.","An affirmative response is a manually designed start of a harmful answer to an inappropriate request.","While it is often easy to craft prompts that yield a substantial likelihood for the affirmative response, the attacked model frequently does not complete the response in a harmful manner.","Moreover, the affirmative objective is usually not adapted to model-specific preferences and essentially ignores the fact that LLMs output a distribution over responses.","If low attack success under such an objective is taken as a measure of robustness, the true robustness might be grossly overestimated.","To alleviate these flaws, we propose an adaptive and semantic optimization problem over the population of responses.","We derive a generally applicable objective via the REINFORCE policy-gradient formalism and demonstrate its efficacy with the state-of-the-art jailbreak algorithms Greedy Coordinate Gradient (GCG) and Projected Gradient Descent (PGD).","For example, our objective doubles the attack success rate (ASR) on Llama3 and increases the ASR from 2% to 50% with circuit breaker defense."],"url":"http://arxiv.org/abs/2502.17254v1"}
{"created":"2025-02-24 15:34:09","title":"MULTITAT: Benchmarking Multilingual Table-and-Text Question Answering","abstract":"Question answering on the hybrid context of tables and text (TATQA) is a critical task, with broad applications in data-intensive domains. However, existing TATQA datasets are limited to English, leading to several drawbacks: (i) They overlook the challenges of multilingual TAT-QA and cannot assess model performance in the multilingual setting. (ii) They do not reflect real-world scenarios where tables and texts frequently appear in non-English languages. To address the limitations, we propose the first multilingual TATQA dataset (MULTITAT). Specifically, we sample data from 3 mainstream TATQA datasets and translate it into 10 diverse languages. To align the model TATQA capabilities in English with other languages, we develop a baseline, Ours. Experimental results reveal that the performance on non-English data in MULTITAT drops by an average of 19.4% compared to English, proving the necessity of MULTITAT. We further analyze the reasons for this performance gap. Furthermore, Ours outperforms other baselines by an average of 3.3, demonstrating its effectiveness.","sentences":["Question answering on the hybrid context of tables and text (TATQA) is a critical task, with broad applications in data-intensive domains.","However, existing TATQA datasets are limited to English, leading to several drawbacks: (i) They overlook the challenges of multilingual TAT-QA and cannot assess model performance in the multilingual setting.","(ii) They do not reflect real-world scenarios where tables and texts frequently appear in non-English languages.","To address the limitations, we propose the first multilingual TATQA dataset (MULTITAT).","Specifically, we sample data from 3 mainstream TATQA datasets and translate it into 10 diverse languages.","To align the model TATQA capabilities in English with other languages, we develop a baseline, Ours.","Experimental results reveal that the performance on non-English data in MULTITAT drops by an average of 19.4% compared to English, proving the necessity of MULTITAT.","We further analyze the reasons for this performance gap.","Furthermore, Ours outperforms other baselines by an average of 3.3, demonstrating its effectiveness."],"url":"http://arxiv.org/abs/2502.17253v1"}
{"created":"2025-02-24 15:28:55","title":"CAR-LOAM: Color-Assisted Robust LiDAR Odometry and Mapping","abstract":"In this letter, we propose a color-assisted robust framework for accurate LiDAR odometry and mapping (LOAM). Simultaneously receiving data from both the LiDAR and the camera, the framework utilizes the color information from the camera images to colorize the LiDAR point clouds and then performs iterative pose optimization. For each LiDAR scan, the edge and planar features are extracted and colored using the corresponding image and then matched to a global map. Specifically, we adopt a perceptually uniform color difference weighting strategy to exclude color correspondence outliers and a robust error metric based on the Welsch's function to mitigate the impact of positional correspondence outliers during the pose optimization process. As a result, the system achieves accurate localization and reconstructs dense, accurate, colored and three-dimensional (3D) maps of the environment. Thorough experiments with challenging scenarios, including complex forests and a campus, show that our method provides higher robustness and accuracy compared with current state-of-the-art methods.","sentences":["In this letter, we propose a color-assisted robust framework for accurate LiDAR odometry and mapping (LOAM).","Simultaneously receiving data from both the LiDAR and the camera, the framework utilizes the color information from the camera images to colorize the LiDAR point clouds and then performs iterative pose optimization.","For each LiDAR scan, the edge and planar features are extracted and colored using the corresponding image and then matched to a global map.","Specifically, we adopt a perceptually uniform color difference weighting strategy to exclude color correspondence outliers and a robust error metric based on the Welsch's function to mitigate the impact of positional correspondence outliers during the pose optimization process.","As a result, the system achieves accurate localization and reconstructs dense, accurate, colored and three-dimensional (3D) maps of the environment.","Thorough experiments with challenging scenarios, including complex forests and a campus, show that our method provides higher robustness and accuracy compared with current state-of-the-art methods."],"url":"http://arxiv.org/abs/2502.17249v1"}
{"created":"2025-02-24 15:26:22","title":"Alpha-SQL: Zero-Shot Text-to-SQL using Monte Carlo Tree Search","abstract":"Text-to-SQL, which enables natural language interaction with databases, serves as a pivotal method across diverse industries. With new, more powerful large language models (LLMs) emerging every few months, fine-tuning has become incredibly costly, labor-intensive, and error-prone. As an alternative, zero-shot Text-to-SQL, which leverages the growing knowledge and reasoning capabilities encoded in LLMs without task-specific fine-tuning, presents a promising and more challenging direction. To address this challenge, we propose Alpha-SQL, a novel approach that leverages a Monte Carlo Tree Search (MCTS) framework to iteratively infer SQL construction actions based on partial SQL query states. To enhance the framework's reasoning capabilities, we introduce LLM-as-Action-Model to dynamically generate SQL construction actions during the MCTS process, steering the search toward more promising SQL queries. Moreover, Alpha-SQL employs a self-supervised reward function to evaluate the quality of candidate SQL queries, ensuring more accurate and efficient query generation. Experimental results show that Alpha-SQL achieves 69.7% execution accuracy on the BIRD development set, using a 32B open-source LLM without fine-tuning. Alpha-SQL outperforms the best previous zero-shot approach based on GPT-4o by 2.5% on the BIRD development set.","sentences":["Text-to-SQL, which enables natural language interaction with databases, serves as a pivotal method across diverse industries.","With new, more powerful large language models (LLMs) emerging every few months, fine-tuning has become incredibly costly, labor-intensive, and error-prone.","As an alternative, zero-shot Text-to-SQL, which leverages the growing knowledge and reasoning capabilities encoded in LLMs without task-specific fine-tuning, presents a promising and more challenging direction.","To address this challenge, we propose Alpha-SQL, a novel approach that leverages a Monte Carlo Tree Search (MCTS) framework to iteratively infer SQL construction actions based on partial SQL query states.","To enhance the framework's reasoning capabilities, we introduce LLM-as-Action-Model to dynamically generate SQL construction actions during the MCTS process, steering the search toward more promising SQL queries.","Moreover, Alpha-SQL employs a self-supervised reward function to evaluate the quality of candidate SQL queries, ensuring more accurate and efficient query generation.","Experimental results show that Alpha-SQL achieves 69.7% execution accuracy on the BIRD development set, using a 32B open-source LLM without fine-tuning.","Alpha-SQL outperforms the best previous zero-shot approach based on GPT-4o by 2.5% on the BIRD development set."],"url":"http://arxiv.org/abs/2502.17248v1"}
{"created":"2025-02-24 15:25:21","title":"Overconfident Oracles: Limitations of In Silico Sequence Design Benchmarking","abstract":"Machine learning methods can automate the in silico design of biological sequences, aiming to reduce costs and accelerate medical research. Given the limited access to wet labs, in silico design methods commonly use an oracle model to evaluate de novo generated sequences. However, the use of different oracle models across methods makes it challenging to compare them reliably, motivating the question: are in silico sequence design benchmarks reliable? In this work, we examine 12 sequence design methods that utilise ML oracles common in the literature and find that there are significant challenges with their cross-consistency and reproducibility. Indeed, oracles differing by architecture, or even just training seed, are shown to yield conflicting relative performance with our analysis suggesting poor out-of-distribution generalisation as a key issue. To address these challenges, we propose supplementing the evaluation with a suite of biophysical measures to assess the viability of generated sequences and limit out-of-distribution sequences the oracle is required to score, thereby improving the robustness of the design procedure. Our work aims to highlight potential pitfalls in the current evaluation process and contribute to the development of robust benchmarks, ultimately driving the improvement of in silico design methods.","sentences":["Machine learning methods can automate the in silico design of biological sequences, aiming to reduce costs and accelerate medical research.","Given the limited access to wet labs, in silico design methods commonly use an oracle model to evaluate de novo generated sequences.","However, the use of different oracle models across methods makes it challenging to compare them reliably, motivating the question: are in silico sequence design benchmarks reliable?","In this work, we examine 12 sequence design methods that utilise ML oracles common in the literature and find that there are significant challenges with their cross-consistency and reproducibility.","Indeed, oracles differing by architecture, or even just training seed, are shown to yield conflicting relative performance with our analysis suggesting poor out-of-distribution generalisation as a key issue.","To address these challenges, we propose supplementing the evaluation with a suite of biophysical measures to assess the viability of generated sequences and limit out-of-distribution sequences the oracle is required to score, thereby improving the robustness of the design procedure.","Our work aims to highlight potential pitfalls in the current evaluation process and contribute to the development of robust benchmarks, ultimately driving the improvement of in silico design methods."],"url":"http://arxiv.org/abs/2502.17246v1"}
{"created":"2025-02-24 15:21:02","title":"UNB StepUP: A footStep database for gait analysis and recognition using Underfoot Pressure","abstract":"Gait refers to the patterns of limb movement generated during walking, which are unique to each individual due to both physical and behavioural traits. Walking patterns have been widely studied in biometrics, biomechanics, sports, and rehabilitation. While traditional methods rely on video and motion capture, advances in underfoot pressure sensing technology now offer deeper insights into gait. However, underfoot pressures during walking remain underexplored due to the lack of large, publicly accessible datasets. To address this, the UNB StepUP database was created, featuring gait pressure data collected with high-resolution pressure sensing tiles (4 sensors/cm\\textsuperscript{2}, 1.2m by 3.6m). Its first release, UNB StepUP-P150, includes over 200,000 footsteps from 150 individuals across various walking speeds (preferred, slow-to-stop, fast, and slow) and footwear types (barefoot, standard shoes, and two personal shoes). As the largest and most comprehensive dataset of its kind, it supports biometric gait recognition while presenting new research opportunities in biomechanics and deep learning. The UNB StepUP-P150 dataset sets a new benchmark for pressure-based gait analysis and recognition.","sentences":["Gait refers to the patterns of limb movement generated during walking, which are unique to each individual due to both physical and behavioural traits.","Walking patterns have been widely studied in biometrics, biomechanics, sports, and rehabilitation.","While traditional methods rely on video and motion capture, advances in underfoot pressure sensing technology now offer deeper insights into gait.","However, underfoot pressures during walking remain underexplored due to the lack of large, publicly accessible datasets.","To address this, the UNB StepUP database was created, featuring gait pressure data collected with high-resolution pressure sensing tiles (4 sensors/cm\\textsuperscript{2}, 1.2m by 3.6m).","Its first release, UNB StepUP-P150, includes over 200,000 footsteps from 150 individuals across various walking speeds (preferred, slow-to-stop, fast, and slow) and footwear types (barefoot, standard shoes, and two personal shoes).","As the largest and most comprehensive dataset of its kind, it supports biometric gait recognition while presenting new research opportunities in biomechanics and deep learning.","The UNB StepUP-P150 dataset sets a new benchmark for pressure-based gait analysis and recognition."],"url":"http://arxiv.org/abs/2502.17244v1"}
{"created":"2025-02-24 15:16:34","title":"Baichuan-Audio: A Unified Framework for End-to-End Speech Interaction","abstract":"We introduce Baichuan-Audio, an end-to-end audio large language model that seamlessly integrates audio understanding and generation. It features a text-guided aligned speech generation mechanism, enabling real-time speech interaction with both comprehension and generation capabilities. Baichuan-Audio leverages a pre-trained ASR model, followed by multi-codebook discretization of speech at a frame rate of 12.5 Hz. This multi-codebook setup ensures that speech tokens retain both semantic and acoustic information. To further enhance modeling, an independent audio head is employed to process audio tokens, effectively capturing their unique characteristics. To mitigate the loss of intelligence during pre-training and preserve the original capabilities of the LLM, we propose a two-stage pre-training strategy that maintains language understanding while enhancing audio modeling. Following alignment, the model excels in real-time speech-based conversation and exhibits outstanding question-answering capabilities, demonstrating its versatility and efficiency. The proposed model demonstrates superior performance in real-time spoken dialogue and exhibits strong question-answering abilities. Our code, model and training data are available at https://github.com/baichuan-inc/Baichuan-Audio","sentences":["We introduce Baichuan-Audio, an end-to-end audio large language model that seamlessly integrates audio understanding and generation.","It features a text-guided aligned speech generation mechanism, enabling real-time speech interaction with both comprehension and generation capabilities.","Baichuan-Audio leverages a pre-trained ASR model, followed by multi-codebook discretization of speech at a frame rate of 12.5 Hz.","This multi-codebook setup ensures that speech tokens retain both semantic and acoustic information.","To further enhance modeling, an independent audio head is employed to process audio tokens, effectively capturing their unique characteristics.","To mitigate the loss of intelligence during pre-training and preserve the original capabilities of the LLM, we propose a two-stage pre-training strategy that maintains language understanding while enhancing audio modeling.","Following alignment, the model excels in real-time speech-based conversation and exhibits outstanding question-answering capabilities, demonstrating its versatility and efficiency.","The proposed model demonstrates superior performance in real-time spoken dialogue and exhibits strong question-answering abilities.","Our code, model and training data are available at https://github.com/baichuan-inc/Baichuan-Audio"],"url":"http://arxiv.org/abs/2502.17239v1"}
