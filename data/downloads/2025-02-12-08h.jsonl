{"created":"2025-02-11 18:59:59","title":"MatSwap: Light-aware material transfers in images","abstract":"We present MatSwap, a method to transfer materials to designated surfaces in an image photorealistically. Such a task is non-trivial due to the large entanglement of material appearance, geometry, and lighting in a photograph. In the literature, material editing methods typically rely on either cumbersome text engineering or extensive manual annotations requiring artist knowledge and 3D scene properties that are impractical to obtain. In contrast, we propose to directly learn the relationship between the input material -- as observed on a flat surface -- and its appearance within the scene, without the need for explicit UV mapping. To achieve this, we rely on a custom light- and geometry-aware diffusion model. We fine-tune a large-scale pre-trained text-to-image model for material transfer using our synthetic dataset, preserving its strong priors to ensure effective generalization to real images. As a result, our method seamlessly integrates a desired material into the target location in the photograph while retaining the identity of the scene. We evaluate our method on synthetic and real images and show that it compares favorably to recent work both qualitatively and quantitatively. We will release our code and data upon publication.","sentences":["We present MatSwap, a method to transfer materials to designated surfaces in an image photorealistically.","Such a task is non-trivial due to the large entanglement of material appearance, geometry, and lighting in a photograph.","In the literature, material editing methods typically rely on either cumbersome text engineering or extensive manual annotations requiring artist knowledge and 3D scene properties that are impractical to obtain.","In contrast, we propose to directly learn the relationship between the input material -- as observed on a flat surface -- and its appearance within the scene, without the need for explicit UV mapping.","To achieve this, we rely on a custom light- and geometry-aware diffusion model.","We fine-tune a large-scale pre-trained text-to-image model for material transfer using our synthetic dataset, preserving its strong priors to ensure effective generalization to real images.","As a result, our method seamlessly integrates a desired material into the target location in the photograph while retaining the identity of the scene.","We evaluate our method on synthetic and real images and show that it compares favorably to recent work both qualitatively and quantitatively.","We will release our code and data upon publication."],"url":"http://arxiv.org/abs/2502.07784v1"}
{"created":"2025-02-11 18:59:59","title":"Pippo: High-Resolution Multi-View Humans from a Single Image","abstract":"We present Pippo, a generative model capable of producing 1K resolution dense turnaround videos of a person from a single casually clicked photo. Pippo is a multi-view diffusion transformer and does not require any additional inputs - e.g., a fitted parametric model or camera parameters of the input image. We pre-train Pippo on 3B human images without captions, and conduct multi-view mid-training and post-training on studio captured humans. During mid-training, to quickly absorb the studio dataset, we denoise several (up to 48) views at low-resolution, and encode target cameras coarsely using a shallow MLP. During post-training, we denoise fewer views at high-resolution and use pixel-aligned controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent generations. At inference, we propose an attention biasing technique that allows Pippo to simultaneously generate greater than 5 times as many views as seen during training. Finally, we also introduce an improved metric to evaluate 3D consistency of multi-view generations, and show that Pippo outperforms existing works on multi-view human generation from a single image.","sentences":["We present Pippo, a generative model capable of producing 1K resolution dense turnaround videos of a person from a single casually clicked photo.","Pippo is a multi-view diffusion transformer and does not require any additional inputs - e.g., a fitted parametric model or camera parameters of the input image.","We pre-train Pippo on 3B human images without captions, and conduct multi-view mid-training and post-training on studio captured humans.","During mid-training, to quickly absorb the studio dataset, we denoise several (up to 48) views at low-resolution, and encode target cameras coarsely using a shallow MLP.","During post-training, we denoise fewer views at high-resolution and use pixel-aligned controls (e.g., Spatial anchor and Plucker rays) to enable 3D consistent generations.","At inference, we propose an attention biasing technique that allows Pippo to simultaneously generate greater than 5 times as many views as seen during training.","Finally, we also introduce an improved metric to evaluate 3D consistency of multi-view generations, and show that Pippo outperforms existing works on multi-view human generation from a single image."],"url":"http://arxiv.org/abs/2502.07785v1"}
{"created":"2025-02-11 18:59:57","title":"Curvature Tuning: Provable Training-free Model Steering From a Single Parameter","abstract":"The scaling of model size and data size has reshaped the paradigm of AI. As a result, the common protocol to leverage the latest models is to steer them towards a specific downstream task of interest through {\\em fine-tuning}. Despite its importance, the main methods for fine-tuning remain limited to full or low-rank adapters--containing countless hyper-parameters and lacking interpretability. In this paper, we take a step back and demonstrate how novel and explainable post-training steering solutions can be derived theoretically from {\\em spline operators}, a rich mathematical framing of Deep Networks that was recently developed. Our method--coined \\textbf{Curvature Tuning (CT)}--has a single parameter that provably modulates the curvature of the model's decision boundary henceforth allowing training-free steering. This makes CT both more efficient and interpretable than conventional fine-tuning methods. We empirically validate its effectiveness in improving generalization and robustness of pretrained models. For example, CT improves out-of-distribution transfer performances of ResNet-18/50 by 2.57\\%/1.74\\% across seventeen downstream datasets, and improves RobustBench robust accuracy by 11.76\\%/348.44\\%. Additionally, we apply CT to ReLU-based Swin-T/S, improving their generalization on nine downstream datasets by 2.43\\%/3.33\\%. Our code is available at \\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}.","sentences":["The scaling of model size and data size has reshaped the paradigm of AI.","As a result, the common protocol to leverage the latest models is to steer them towards a specific downstream task of interest through {\\em fine-tuning}.","Despite its importance, the main methods for fine-tuning remain limited to full or low-rank adapters--containing countless hyper-parameters and lacking interpretability.","In this paper, we take a step back and demonstrate how novel and explainable post-training steering solutions can be derived theoretically from {\\em spline operators}, a rich mathematical framing of Deep Networks that was recently developed.","Our method--coined \\textbf{Curvature Tuning (CT)}--has a single parameter that provably modulates the curvature of the model's decision boundary henceforth allowing training-free steering.","This makes CT both more efficient and interpretable than conventional fine-tuning methods.","We empirically validate its effectiveness in improving generalization and robustness of pretrained models.","For example, CT improves out-of-distribution transfer performances of ResNet-18/50 by 2.57\\%/1.74\\% across seventeen downstream datasets, and improves RobustBench robust accuracy by 11.76\\%/348.44\\%.","Additionally, we apply CT to ReLU-based Swin-T/S, improving their generalization on nine downstream datasets by 2.43\\%/3.33\\%.","Our code is available at \\href{https://github.com/Leon-Leyang/curvature-tuning}{https://github.com/Leon-Leyang/curvature-tuning}."],"url":"http://arxiv.org/abs/2502.07783v1"}
{"created":"2025-02-11 18:59:52","title":"A Flag Decomposition for Hierarchical Datasets","abstract":"Flag manifolds encode hierarchical nested sequences of subspaces and serve as powerful structures for various computer vision and machine learning applications. Despite their utility in tasks such as dimensionality reduction, motion averaging, and subspace clustering, current applications are often restricted to extracting flags using common matrix decomposition methods like the singular value decomposition. Here, we address the need for a general algorithm to factorize and work with hierarchical datasets. In particular, we propose a novel, flag-based method that decomposes arbitrary hierarchical real-valued data into a hierarchy-preserving flag representation in Stiefel coordinates. Our work harnesses the potential of flag manifolds in applications including denoising, clustering, and few-shot learning.","sentences":["Flag manifolds encode hierarchical nested sequences of subspaces and serve as powerful structures for various computer vision and machine learning applications.","Despite their utility in tasks such as dimensionality reduction, motion averaging, and subspace clustering, current applications are often restricted to extracting flags using common matrix decomposition methods like the singular value decomposition.","Here, we address the need for a general algorithm to factorize and work with hierarchical datasets.","In particular, we propose a novel, flag-based method that decomposes arbitrary hierarchical real-valued data into a hierarchy-preserving flag representation in Stiefel coordinates.","Our work harnesses the potential of flag manifolds in applications including denoising, clustering, and few-shot learning."],"url":"http://arxiv.org/abs/2502.07782v1"}
{"created":"2025-02-11 18:59:35","title":"DarwinLM: Evolutionary Structured Pruning of Large Language Models","abstract":"Large Language Models (LLMs) have achieved significant success across various NLP tasks. However, their massive computational costs limit their widespread use, particularly in real-time applications. Structured pruning offers an effective solution by compressing models and directly providing end-to-end speed improvements, regardless of the hardware environment. Meanwhile, different components of the model exhibit varying sensitivities towards pruning, calling for \\emph{non-uniform} model compression. However, a pruning method should not only identify a capable substructure, but also account for post-compression training. To this end, we propose \\sysname, a method for \\emph{training-aware} structured pruning. \\sysname builds upon an evolutionary search process, generating multiple offspring models in each generation through mutation, and selecting the fittest for survival. To assess the effect of post-training, we incorporate a lightweight, multistep training process within the offspring population, progressively increasing the number of tokens and eliminating poorly performing models in each selection stage. We validate our method through extensive experiments on Llama-2-7B, Llama-3.1-8B and Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured pruning. For instance, \\sysname surpasses ShearedLlama while requiring $5\\times$ less training data during post-compression training.","sentences":["Large Language Models (LLMs) have achieved significant success across various NLP tasks.","However, their massive computational costs limit their widespread use, particularly in real-time applications.","Structured pruning offers an effective solution by compressing models and directly providing end-to-end speed improvements, regardless of the hardware environment.","Meanwhile, different components of the model exhibit varying sensitivities towards pruning, calling for \\emph{non-uniform} model compression.","However, a pruning method should not only identify a capable substructure, but also account for post-compression training.","To this end, we propose \\sysname, a method for \\emph{training-aware} structured pruning.","\\sysname builds upon an evolutionary search process, generating multiple offspring models in each generation through mutation, and selecting the fittest for survival.","To assess the effect of post-training, we incorporate a lightweight, multistep training process within the offspring population, progressively increasing the number of tokens and eliminating poorly performing models in each selection stage.","We validate our method through extensive experiments on Llama-2-7B, Llama-3.1-8B and Qwen-2.5-14B-Instruct, achieving state-of-the-art performance for structured pruning.","For instance, \\sysname surpasses ShearedLlama while requiring $5\\times$ less training data during post-compression training."],"url":"http://arxiv.org/abs/2502.07780v1"}
{"created":"2025-02-11 18:59:10","title":"Stay-Positive: A Case for Ignoring Real Image Features in Fake Image Detection","abstract":"Detecting AI generated images is a challenging yet essential task. A primary difficulty arises from the detectors tendency to rely on spurious patterns, such as compression artifacts, which can influence its decisions. These issues often stem from specific patterns that the detector associates with the real data distribution, making it difficult to isolate the actual generative traces. We argue that an image should be classified as fake if and only if it contains artifacts introduced by the generative model. Based on this premise, we propose Stay Positive, an algorithm designed to constrain the detectors focus to generative artifacts while disregarding those associated with real data. Experimental results demonstrate that detectors trained with Stay Positive exhibit reduced susceptibility to spurious correlations, leading to improved generalization and robustness to post processing. Additionally, unlike detectors that associate artifacts with real images, those that focus purely on fake artifacts are better at detecting inpainted real images.","sentences":["Detecting AI generated images is a challenging yet essential task.","A primary difficulty arises from the detectors tendency to rely on spurious patterns, such as compression artifacts, which can influence its decisions.","These issues often stem from specific patterns that the detector associates with the real data distribution, making it difficult to isolate the actual generative traces.","We argue that an image should be classified as fake if and only if it contains artifacts introduced by the generative model.","Based on this premise, we propose Stay Positive, an algorithm designed to constrain the detectors focus to generative artifacts while disregarding those associated with real data.","Experimental results demonstrate that detectors trained with Stay Positive exhibit reduced susceptibility to spurious correlations, leading to improved generalization and robustness to post processing.","Additionally, unlike detectors that associate artifacts with real images, those that focus purely on fake artifacts are better at detecting inpainted real images."],"url":"http://arxiv.org/abs/2502.07778v1"}
{"created":"2025-02-11 18:58:04","title":"Auditing Prompt Caching in Language Model APIs","abstract":"Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts. These timing differences introduce the risk of side-channel timing attacks. For example, if the cache is shared across users, an attacker could identify cached prompts from fast API response times to learn information about other users' prompts. Because prompt caching may cause privacy leakage, transparency around the caching policies of API providers is important. To this end, we develop and conduct statistical audits to detect prompt caching in real-world LLM API providers. We detect global cache sharing across users in seven API providers, including OpenAI, resulting in potential privacy leakage about users' prompts. Timing variations due to prompt caching can also result in leakage of information about model architecture. Namely, we find evidence that OpenAI's embedding model is a decoder-only Transformer, which was previously not publicly known.","sentences":["Prompt caching in large language models (LLMs) results in data-dependent timing variations: cached prompts are processed faster than non-cached prompts.","These timing differences introduce the risk of side-channel timing attacks.","For example, if the cache is shared across users, an attacker could identify cached prompts from fast API response times to learn information about other users' prompts.","Because prompt caching may cause privacy leakage, transparency around the caching policies of API providers is important.","To this end, we develop and conduct statistical audits to detect prompt caching in real-world LLM API providers.","We detect global cache sharing across users in seven API providers, including OpenAI, resulting in potential privacy leakage about users' prompts.","Timing variations due to prompt caching can also result in leakage of information about model architecture.","Namely, we find evidence that OpenAI's embedding model is a decoder-only Transformer, which was previously not publicly known."],"url":"http://arxiv.org/abs/2502.07776v1"}
{"created":"2025-02-11 18:57:18","title":"Optimistic Interior Point Methods for Sequential Hypothesis Testing by Betting","abstract":"The technique of \"testing by betting\" frames nonparametric sequential hypothesis testing as a multiple-round game, where a player bets on future observations that arrive in a streaming fashion, accumulates wealth that quantifies evidence against the null hypothesis, and rejects the null once the wealth exceeds a specified threshold while controlling the false positive error. Designing an online learning algorithm that achieves a small regret in the game can help rapidly accumulate the bettor's wealth, which in turn can shorten the time to reject the null hypothesis under the alternative $H_1$. However, many of the existing works employ the Online Newton Step (ONS) to update within a halved decision space to avoid a gradient explosion issue, which is potentially conservative for rapid wealth accumulation. In this paper, we introduce a novel strategy utilizing interior-point methods in optimization that allows updates across the entire interior of the decision space without the risk of gradient explosion. Our approach not only maintains strong statistical guarantees but also facilitates faster null hypothesis rejection in critical scenarios, overcoming the limitations of existing approaches.","sentences":["The technique of \"testing by betting\" frames nonparametric sequential hypothesis testing as a multiple-round game, where a player bets on future observations that arrive in a streaming fashion, accumulates wealth that quantifies evidence against the null hypothesis, and rejects the null once the wealth exceeds a specified threshold while controlling the false positive error.","Designing an online learning algorithm that achieves a small regret in the game can help rapidly accumulate the bettor's wealth, which in turn can shorten the time to reject the null hypothesis under the alternative $H_1$. However, many of the existing works employ the Online Newton Step (ONS) to update within a halved decision space to avoid a gradient explosion issue, which is potentially conservative for rapid wealth accumulation.","In this paper, we introduce a novel strategy utilizing interior-point methods in optimization that allows updates across the entire interior of the decision space without the risk of gradient explosion.","Our approach not only maintains strong statistical guarantees but also facilitates faster null hypothesis rejection in critical scenarios, overcoming the limitations of existing approaches."],"url":"http://arxiv.org/abs/2502.07774v1"}
{"created":"2025-02-11 18:56:20","title":"Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming","abstract":"Accurate task planning is critical for controlling autonomous systems, such as robots, drones, and self-driving vehicles. Behavior Trees (BTs) are considered one of the most prominent control-policy-defining frameworks in task planning, due to their modularity, flexibility, and reusability. Generating reliable and accurate BT-based control policies for robotic systems remains challenging and often requires domain expertise. In this paper, we present the LLM-GP-BT technique that leverages the Large Language Model (LLM) and Genetic Programming (GP) to automate the generation and configuration of BTs. The LLM-GP-BT technique processes robot task commands expressed in human natural language and converts them into accurate and reliable BT-based task plans in a computationally efficient and user-friendly manner. The proposed technique is systematically developed and validated through simulation experiments, demonstrating its potential to streamline task planning for autonomous systems.","sentences":["Accurate task planning is critical for controlling autonomous systems, such as robots, drones, and self-driving vehicles.","Behavior Trees (BTs) are considered one of the most prominent control-policy-defining frameworks in task planning, due to their modularity, flexibility, and reusability.","Generating reliable and accurate BT-based control policies for robotic systems remains challenging and often requires domain expertise.","In this paper, we present the LLM-GP-BT technique that leverages the Large Language Model (LLM) and Genetic Programming (GP) to automate the generation and configuration of BTs.","The LLM-GP-BT technique processes robot task commands expressed in human natural language and converts them into accurate and reliable BT-based task plans in a computationally efficient and user-friendly manner.","The proposed technique is systematically developed and validated through simulation experiments, demonstrating its potential to streamline task planning for autonomous systems."],"url":"http://arxiv.org/abs/2502.07772v1"}
{"created":"2025-02-11 18:55:57","title":"Breaking Down Bias: On The Limits of Generalizable Pruning Strategies","abstract":"We employ model pruning to examine how LLMs conceptualize racial biases, and whether a generalizable mitigation strategy for such biases appears feasible. Our analysis yields several novel insights. We find that pruning can be an effective method to reduce bias without significantly increasing anomalous model behavior. Neuron-based pruning strategies generally yield better results than approaches pruning entire attention heads. However, our results also show that the effectiveness of either approach quickly deteriorates as pruning strategies become more generalized. For instance, a model that is trained on removing racial biases in the context of financial decision-making poorly generalizes to biases in commercial transactions. Overall, our analysis suggests that racial biases are only partially represented as a general concept within language models. The other part of these biases is highly context-specific, suggesting that generalizable mitigation strategies may be of limited effectiveness. Our findings have important implications for legal frameworks surrounding AI. In particular, they suggest that an effective mitigation strategy should include the allocation of legal responsibility on those that deploy models in a specific use case.","sentences":["We employ model pruning to examine how LLMs conceptualize racial biases, and whether a generalizable mitigation strategy for such biases appears feasible.","Our analysis yields several novel insights.","We find that pruning can be an effective method to reduce bias without significantly increasing anomalous model behavior.","Neuron-based pruning strategies generally yield better results than approaches pruning entire attention heads.","However, our results also show that the effectiveness of either approach quickly deteriorates as pruning strategies become more generalized.","For instance, a model that is trained on removing racial biases in the context of financial decision-making poorly generalizes to biases in commercial transactions.","Overall, our analysis suggests that racial biases are only partially represented as a general concept within language models.","The other part of these biases is highly context-specific, suggesting that generalizable mitigation strategies may be of limited effectiveness.","Our findings have important implications for legal frameworks surrounding AI.","In particular, they suggest that an effective mitigation strategy should include the allocation of legal responsibility on those that deploy models in a specific use case."],"url":"http://arxiv.org/abs/2502.07771v1"}
{"created":"2025-02-11 18:47:53","title":"Polynomial-Time Approximability of Constrained Reinforcement Learning","abstract":"We study the computational complexity of approximating general constrained Markov decision processes. Our primary contribution is the design of a polynomial time $(0,\\epsilon)$-additive bicriteria approximation algorithm for finding optimal constrained policies across a broad class of recursively computable constraints, including almost-sure, chance, expectation, and their anytime variants. Matching lower bounds imply our approximation guarantees are optimal so long as $P \\neq NP$. The generality of our approach results in answers to several long-standing open complexity questions in the constrained reinforcement learning literature. Specifically, we are the first to prove polynomial-time approximability for the following settings: policies under chance constraints, deterministic policies under multiple expectation constraints, policies under non-homogeneous constraints (i.e., constraints of different types), and policies under constraints for continuous-state processes.","sentences":["We study the computational complexity of approximating general constrained Markov decision processes.","Our primary contribution is the design of a polynomial time $(0,\\epsilon)$-additive bicriteria approximation algorithm for finding optimal constrained policies across a broad class of recursively computable constraints, including almost-sure, chance, expectation, and their anytime variants.","Matching lower bounds imply our approximation guarantees are optimal so long as $P \\neq NP$.","The generality of our approach results in answers to several long-standing open complexity questions in the constrained reinforcement learning literature.","Specifically, we are the first to prove polynomial-time approximability for the following settings: policies under chance constraints, deterministic policies under multiple expectation constraints, policies under non-homogeneous constraints (i.e., constraints of different types), and policies under constraints for continuous-state processes."],"url":"http://arxiv.org/abs/2502.07764v1"}
{"created":"2025-02-11 18:46:01","title":"Great Power Brings Great Responsibility: Personalizing Conversational AI for Diverse Problem-Solvers","abstract":"Newcomers onboarding to Open Source Software (OSS) projects face many challenges. Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for answering questions and providing guidance, with many developers now turning to ChatGPT over traditional Q&A sites like Stack Overflow. Nonetheless, LLMs may carry biases in presenting information, which can be especially impactful for newcomers whose problem-solving styles may not be broadly represented. This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects. This vision paper outlines the potential of adapting AI responses to various problem-solving styles to avoid privileging a particular subgroup. We discuss the potential of AI persona-based prompt engineering as a strategy for interacting with AI. This study invites further research to refine AI-based tools to better support contributions to OSS projects.","sentences":["Newcomers onboarding to Open Source Software (OSS) projects face many challenges.","Large Language Models (LLMs), like ChatGPT, have emerged as potential resources for answering questions and providing guidance, with many developers now turning to ChatGPT over traditional Q&A sites like Stack Overflow.","Nonetheless, LLMs may carry biases in presenting information, which can be especially impactful for newcomers whose problem-solving styles may not be broadly represented.","This raises important questions about the accessibility of AI-driven support for newcomers to OSS projects.","This vision paper outlines the potential of adapting AI responses to various problem-solving styles to avoid privileging a particular subgroup.","We discuss the potential of AI persona-based prompt engineering as a strategy for interacting with AI.","This study invites further research to refine AI-based tools to better support contributions to OSS projects."],"url":"http://arxiv.org/abs/2502.07763v1"}
{"created":"2025-02-11 18:43:07","title":"Scalable Fingerprinting of Large Language Models","abstract":"Model fingerprinting has emerged as a powerful tool for model owners to identify their shared model given API access. However, to lower false discovery rate, fight fingerprint leakage, and defend against coalitions of model users attempting to bypass detection, we argue that {\\em scalability} is critical, i.e., scaling up the number of fingerprints one can embed into a model. Hence, we pose scalability as a crucial requirement for fingerprinting schemes. We experiment with fingerprint design at a scale significantly larger than previously considered, and introduce a new method, dubbed Perinucleus sampling, to generate scalable, persistent, and harmless fingerprints. We demonstrate that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two orders of magnitude more than existing schemes -- without degrading the model's utility. Our inserted fingerprints persist even after supervised fine-tuning on standard post-training data. We further address security risks for fingerprinting, and theoretically and empirically show how a scalable fingerprinting scheme like ours can mitigate these risks.","sentences":["Model fingerprinting has emerged as a powerful tool for model owners to identify their shared model given API access.","However, to lower false discovery rate, fight fingerprint leakage, and defend against coalitions of model users attempting to bypass detection, we argue that {\\em scalability} is critical, i.e., scaling up the number of fingerprints one can embed into a model.","Hence, we pose scalability as a crucial requirement for fingerprinting schemes.","We experiment with fingerprint design at a scale significantly larger than previously considered, and introduce a new method, dubbed Perinucleus sampling, to generate scalable, persistent, and harmless fingerprints.","We demonstrate that this scheme can add 24,576 fingerprints to a Llama-3.1-8B model -- two orders of magnitude more than existing schemes -- without degrading the model's utility.","Our inserted fingerprints persist even after supervised fine-tuning on standard post-training data.","We further address security risks for fingerprinting, and theoretically and empirically show how a scalable fingerprinting scheme like ours can mitigate these risks."],"url":"http://arxiv.org/abs/2502.07760v1"}
{"created":"2025-02-11 18:38:02","title":"Novel computational workflows for natural and biomedical image processing based on hypercomplex algebras","abstract":"Hypercomplex image processing extends conventional techniques in a unified paradigm encompassing algebraic and geometric principles. This work leverages quaternions and the two-dimensional orthogonal planes split framework (splitting of a quaternion - representing a pixel - into pairs of orthogonal 2D planes) for natural/biomedical image analysis through the following computational workflows and outcomes: natural/biomedical image re-colorization, natural image de-colorization, natural/biomedical image contrast enhancement, computational re-staining and stain separation in histological images, and performance gains in machine/deep learning pipelines for histological images. The workflows are analyzed separately for natural and biomedical images to showcase the effectiveness of the proposed approaches. The proposed workflows can regulate color appearance (e.g. with alternative renditions and grayscale conversion) and image contrast, be part of automated image processing pipelines (e.g. isolating stain components, boosting learning models), and assist in digital pathology applications (e.g. enhancing biomarker visibility, enabling colorblind-friendly renditions). Employing only basic arithmetic and matrix operations, this work offers a computationally accessible methodology - in the hypercomplex domain - that showcases versatility and consistency across image processing tasks and a range of computer vision and biomedical applications. The proposed non-data-driven methods achieve comparable or better results (particularly in cases involving well-known methods) to those reported in the literature, showcasing the potential of robust theoretical frameworks with practical effectiveness. Results, methods, and limitations are detailed alongside discussion of promising extensions, emphasizing the potential of feature-rich mathematical/computational frameworks for natural and biomedical images.","sentences":["Hypercomplex image processing extends conventional techniques in a unified paradigm encompassing algebraic and geometric principles.","This work leverages quaternions and the two-dimensional orthogonal planes split framework (splitting of a quaternion - representing a pixel - into pairs of orthogonal 2D planes) for natural/biomedical image analysis through the following computational workflows and outcomes: natural/biomedical image re-colorization, natural image de-colorization, natural/biomedical image contrast enhancement, computational re-staining and stain separation in histological images, and performance gains in machine/deep learning pipelines for histological images.","The workflows are analyzed separately for natural and biomedical images to showcase the effectiveness of the proposed approaches.","The proposed workflows can regulate color appearance (e.g. with alternative renditions and grayscale conversion) and image contrast, be part of automated image processing pipelines (e.g. isolating stain components, boosting learning models), and assist in digital pathology applications (e.g. enhancing biomarker visibility, enabling colorblind-friendly renditions).","Employing only basic arithmetic and matrix operations, this work offers a computationally accessible methodology - in the hypercomplex domain - that showcases versatility and consistency across image processing tasks and a range of computer vision and biomedical applications.","The proposed non-data-driven methods achieve comparable or better results (particularly in cases involving well-known methods) to those reported in the literature, showcasing the potential of robust theoretical frameworks with practical effectiveness.","Results, methods, and limitations are detailed alongside discussion of promising extensions, emphasizing the potential of feature-rich mathematical/computational frameworks for natural and biomedical images."],"url":"http://arxiv.org/abs/2502.07758v1"}
{"created":"2025-02-11 18:32:24","title":"An Advanced NLP Framework for Automated Medical Diagnosis with DeBERTa and Dynamic Contextual Positional Gating","abstract":"This paper presents a novel Natural Language Processing (NLP) framework for enhancing medical diagnosis through the integration of advanced techniques in data augmentation, feature extraction, and classification. The proposed approach employs back-translation to generate diverse paraphrased datasets, improving robustness and mitigating overfitting in classification tasks. Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained contextual and positional relationships, dynamically adjusting the influence of positional information based on semantic context to produce high-quality text embeddings. For classification, an Attention-Based Feedforward Neural Network (ABFNN) is utilized, effectively focusing on the most relevant features to improve decision-making accuracy. Applied to the classification of symptoms, clinical notes, and other medical texts, this architecture demonstrates its ability to address the complexities of medical data. The combination of data augmentation, contextual embedding generation, and advanced classification mechanisms offers a robust and accurate diagnostic tool, with potential applications in automated medical diagnosis and clinical decision support. This method demonstrates the effectiveness of the proposed NLP framework for medical diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of 99.72%, precision of 99.79%, and an F1-score of 99.75%. These metrics not only underscore the model's robust performance in classifying medical texts with exceptional precision and reliability but also highlight its superiority over existing methods, making it a highly promising tool for automated diagnostic systems.","sentences":["This paper presents a novel Natural Language Processing (NLP) framework for enhancing medical diagnosis through the integration of advanced techniques in data augmentation, feature extraction, and classification.","The proposed approach employs back-translation to generate diverse paraphrased datasets, improving robustness and mitigating overfitting in classification tasks.","Leveraging Decoding-enhanced BERT with Disentangled Attention (DeBERTa) with Dynamic Contextual Positional Gating (DCPG), the model captures fine-grained contextual and positional relationships, dynamically adjusting the influence of positional information based on semantic context to produce high-quality text embeddings.","For classification, an Attention-Based Feedforward Neural Network (ABFNN) is utilized, effectively focusing on the most relevant features to improve decision-making accuracy.","Applied to the classification of symptoms, clinical notes, and other medical texts, this architecture demonstrates its ability to address the complexities of medical data.","The combination of data augmentation, contextual embedding generation, and advanced classification mechanisms offers a robust and accurate diagnostic tool, with potential applications in automated medical diagnosis and clinical decision support.","This method demonstrates the effectiveness of the proposed NLP framework for medical diagnosis, achieving remarkable results with an accuracy of 99.78%, recall of 99.72%, precision of 99.79%, and an F1-score of 99.75%.","These metrics not only underscore the model's robust performance in classifying medical texts with exceptional precision and reliability but also highlight its superiority over existing methods, making it a highly promising tool for automated diagnostic systems."],"url":"http://arxiv.org/abs/2502.07755v1"}
{"created":"2025-02-11 18:27:39","title":"MeshSplats: Mesh-Based Rendering with Gaussian Splatting Initialization","abstract":"Gaussian Splatting (GS) is a recent and pivotal technique in 3D computer graphics. GS-based algorithms almost always bypass classical methods such as ray tracing, which offers numerous inherent advantages for rendering. For example, ray tracing is able to handle incoherent rays for advanced lighting effects, including shadows and reflections. To address this limitation, we introduce MeshSplats, a method which converts GS to a mesh-like format. Following the completion of training, MeshSplats transforms Gaussian elements into mesh faces, enabling rendering using ray tracing methods with all their associated benefits. Our model can be utilized immediately following transformation, yielding a mesh of slightly reduced quality without additional training. Furthermore, we can enhance the reconstruction quality through the application of a dedicated optimization algorithm that operates on mesh faces rather than Gaussian components. The efficacy of our method is substantiated by experimental results, underscoring its extensive applications in computer graphics and image processing.","sentences":["Gaussian Splatting (GS) is a recent and pivotal technique in 3D computer graphics.","GS-based algorithms almost always bypass classical methods such as ray tracing, which offers numerous inherent advantages for rendering.","For example, ray tracing is able to handle incoherent rays for advanced lighting effects, including shadows and reflections.","To address this limitation, we introduce MeshSplats, a method which converts GS to a mesh-like format.","Following the completion of training, MeshSplats transforms Gaussian elements into mesh faces, enabling rendering using ray tracing methods with all their associated benefits.","Our model can be utilized immediately following transformation, yielding a mesh of slightly reduced quality without additional training.","Furthermore, we can enhance the reconstruction quality through the application of a dedicated optimization algorithm that operates on mesh faces rather than Gaussian components.","The efficacy of our method is substantiated by experimental results, underscoring its extensive applications in computer graphics and image processing."],"url":"http://arxiv.org/abs/2502.07754v1"}
{"created":"2025-02-11 18:27:27","title":"Direct Ascent Synthesis: Revealing Hidden Generative Capabilities in Discriminative Models","abstract":"We demonstrate that discriminative models inherently contain powerful generative capabilities, challenging the fundamental distinction between discriminative and generative architectures. Our method, Direct Ascent Synthesis (DAS), reveals these latent capabilities through multi-resolution optimization of CLIP model representations. While traditional inversion attempts produce adversarial patterns, DAS achieves high-quality image synthesis by decomposing optimization across multiple spatial scales (1x1 to 224x224), requiring no additional training. This approach not only enables diverse applications -- from text-to-image generation to style transfer -- but maintains natural image statistics ($1/f^2$ spectrum) and guides the generation away from non-robust adversarial patterns. Our results demonstrate that standard discriminative models encode substantially richer generative knowledge than previously recognized, providing new perspectives on model interpretability and the relationship between adversarial examples and natural image synthesis.","sentences":["We demonstrate that discriminative models inherently contain powerful generative capabilities, challenging the fundamental distinction between discriminative and generative architectures.","Our method, Direct Ascent Synthesis (DAS), reveals these latent capabilities through multi-resolution optimization of CLIP model representations.","While traditional inversion attempts produce adversarial patterns, DAS achieves high-quality image synthesis by decomposing optimization across multiple spatial scales (1x1 to 224x224), requiring no additional training.","This approach not only enables diverse applications -- from text-to-image generation to style transfer -- but maintains natural image statistics ($1/f^2$ spectrum) and guides the generation away from non-robust adversarial patterns.","Our results demonstrate that standard discriminative models encode substantially richer generative knowledge than previously recognized, providing new perspectives on model interpretability and the relationship between adversarial examples and natural image synthesis."],"url":"http://arxiv.org/abs/2502.07753v1"}
{"created":"2025-02-11 18:27:19","title":"Towards Efficient Optimizer Design for LLM via Structured Fisher Approximation with a Low-Rank Extension","abstract":"Designing efficient optimizers for large language models (LLMs) with low-memory requirements and fast convergence is an important and challenging problem. This paper makes a step towards the systematic design of such optimizers through the lens of structured Fisher information matrix (FIM) approximation. We show that many state-of-the-art efficient optimizers can be viewed as solutions to FIM approximation (under the Frobenius norm) with specific structural assumptions. Building on these insights, we propose two design recommendations of practical efficient optimizers for LLMs, involving the careful selection of structural assumptions to balance generality and efficiency, and enhancing memory efficiency of optimizers with general structures through a novel low-rank extension framework. We demonstrate how to use each design approach by deriving new memory-efficient optimizers: Row and Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation (Alice). Experiments on LLaMA pre-training (up to 1B parameters) validate the effectiveness, showing faster and better convergence than existing memory-efficient baselines and Adam with little memory overhead. Notably, Alice achieves better than 2x faster convergence over Adam, while RACS delivers strong performance on the 1B model with SGD-like memory.","sentences":["Designing efficient optimizers for large language models (LLMs) with low-memory requirements and fast convergence is an important and challenging problem.","This paper makes a step towards the systematic design of such optimizers through the lens of structured Fisher information matrix (FIM) approximation.","We show that many state-of-the-art efficient optimizers can be viewed as solutions to FIM approximation (under the Frobenius norm) with specific structural assumptions.","Building on these insights, we propose two design recommendations of practical efficient optimizers for LLMs, involving the careful selection of structural assumptions to balance generality and efficiency, and enhancing memory efficiency of optimizers with general structures through a novel low-rank extension framework.","We demonstrate how to use each design approach by deriving new memory-efficient optimizers: Row and Column Scaled SGD (RACS) and Adaptive low-dimensional subspace estimation (Alice).","Experiments on LLaMA pre-training (up to 1B parameters) validate the effectiveness, showing faster and better convergence than existing memory-efficient baselines and Adam with little memory overhead.","Notably, Alice achieves better than 2x faster convergence over Adam, while RACS delivers strong performance on the 1B model with SGD-like memory."],"url":"http://arxiv.org/abs/2502.07752v1"}
{"created":"2025-02-11 18:26:22","title":"CausalGeD: Blending Causality and Diffusion for Spatial Gene Expression Generation","abstract":"The integration of single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) data is crucial for understanding gene expression in spatial context. Existing methods for such integration have limited performance, with structural similarity often below 60\\%, We attribute this limitation to the failure to consider causal relationships between genes. We present CausalGeD, which combines diffusion and autoregressive processes to leverage these relationships. By generalizing the Causal Attention Transformer from image generation to gene expression data, our model captures regulatory mechanisms without predefined relationships. Across 10 tissue datasets, CausalGeD outperformed state-of-the-art baselines by 5- 32\\% in key metrics, including Pearson's correlation and structural similarity, advancing both technical and biological insights.","sentences":["The integration of single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics (ST) data is crucial for understanding gene expression in spatial context.","Existing methods for such integration have limited performance, with structural similarity often below 60\\%, We attribute this limitation to the failure to consider causal relationships between genes.","We present CausalGeD, which combines diffusion and autoregressive processes to leverage these relationships.","By generalizing the Causal Attention Transformer from image generation to gene expression data, our model captures regulatory mechanisms without predefined relationships.","Across 10 tissue datasets, CausalGeD outperformed state-of-the-art baselines by 5- 32\\% in key metrics, including Pearson's correlation and structural similarity, advancing both technical and biological insights."],"url":"http://arxiv.org/abs/2502.07751v1"}
{"created":"2025-02-11 18:25:48","title":"PFedDST: Personalized Federated Learning with Decentralized Selection Training","abstract":"Distributed Learning (DL) enables the training of machine learning models across multiple devices, yet it faces challenges like non-IID data distributions and device capability disparities, which can impede training efficiency. Communication bottlenecks further complicate traditional Federated Learning (FL) setups. To mitigate these issues, we introduce the Personalized Federated Learning with Decentralized Selection Training (PFedDST) framework. PFedDST enhances model training by allowing devices to strategically evaluate and select peers based on a comprehensive communication score. This score integrates loss, task similarity, and selection frequency, ensuring optimal peer connections. This selection strategy is tailored to increase local personalization and promote beneficial peer collaborations to strengthen the stability and efficiency of the training process. Our experiments demonstrate that PFedDST not only enhances model accuracy but also accelerates convergence. This approach outperforms state-of-the-art methods in handling data heterogeneity, delivering both faster and more effective training in diverse and decentralized systems.","sentences":["Distributed Learning (DL) enables the training of machine learning models across multiple devices, yet it faces challenges like non-IID data distributions and device capability disparities, which can impede training efficiency.","Communication bottlenecks further complicate traditional Federated Learning (FL) setups.","To mitigate these issues, we introduce the Personalized Federated Learning with Decentralized Selection Training (PFedDST) framework.","PFedDST enhances model training by allowing devices to strategically evaluate and select peers based on a comprehensive communication score.","This score integrates loss, task similarity, and selection frequency, ensuring optimal peer connections.","This selection strategy is tailored to increase local personalization and promote beneficial peer collaborations to strengthen the stability and efficiency of the training process.","Our experiments demonstrate that PFedDST not only enhances model accuracy but also accelerates convergence.","This approach outperforms state-of-the-art methods in handling data heterogeneity, delivering both faster and more effective training in diverse and decentralized systems."],"url":"http://arxiv.org/abs/2502.07750v1"}
{"created":"2025-02-11 18:14:44","title":"WHODUNIT: Evaluation benchmark for culprit detection in mystery stories","abstract":"We present a novel data set, WhoDunIt, to assess the deductive reasoning capabilities of large language models (LLM) within narrative contexts. Constructed from open domain mystery novels and short stories, the dataset challenges LLMs to identify the perpetrator after reading and comprehending the story. To evaluate model robustness, we apply a range of character-level name augmentations, including original names, name swaps, and substitutions with well-known real and/or fictional entities from popular discourse. We further use various prompting styles to investigate the influence of prompting on deductive reasoning accuracy.   We conduct evaluation study with state-of-the-art models, specifically GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with majority response selection to ensure reliability. The results demonstrate that while LLMs perform reliably on unaltered texts, accuracy diminishes with certain name substitutions, particularly those with wide recognition. This dataset is publicly available here.","sentences":["We present a novel data set, WhoDunIt, to assess the deductive reasoning capabilities of large language models (LLM) within narrative contexts.","Constructed from open domain mystery novels and short stories, the dataset challenges LLMs to identify the perpetrator after reading and comprehending the story.","To evaluate model robustness, we apply a range of character-level name augmentations, including original names, name swaps, and substitutions with well-known real and/or fictional entities from popular discourse.","We further use various prompting styles to investigate the influence of prompting on deductive reasoning accuracy.   ","We conduct evaluation study with state-of-the-art models, specifically GPT-4o, GPT-4-turbo, and GPT-4o-mini, evaluated through multiple trials with majority response selection to ensure reliability.","The results demonstrate that while LLMs perform reliably on unaltered texts, accuracy diminishes with certain name substitutions, particularly those with wide recognition.","This dataset is publicly available here."],"url":"http://arxiv.org/abs/2502.07747v1"}
{"created":"2025-02-11 18:13:29","title":"HiPoNet: A Topology-Preserving Multi-View Neural Network For High Dimensional Point Cloud and Single-Cell Data","abstract":"In this paper, we propose HiPoNet, an end-to-end differentiable neural network for regression, classification, and representation learning on high-dimensional point clouds. Single-cell data can have high dimensionality exceeding the capabilities of existing methods point cloud tailored for 3D data. Moreover, modern single-cell and spatial experiments now yield entire cohorts of datasets (i.e. one on every patient), necessitating models that can process large, high-dimensional point clouds at scale. Most current approaches build a single nearest-neighbor graph, discarding important geometric information. In contrast, HiPoNet forms higher-order simplicial complexes through learnable feature reweighting, generating multiple data views that disentangle distinct biological processes. It then employs simplicial wavelet transforms to extract multi-scale features - capturing both local and global topology. We empirically show that these components preserve topological information in the learned representations, and that HiPoNet significantly outperforms state-of-the-art point-cloud and graph-based models on single cell. We also show an application of HiPoNet on spatial transcriptomics datasets using spatial co-ordinates as one of the views. Overall, HiPoNet offers a robust and scalable solution for high-dimensional data analysis.","sentences":["In this paper, we propose HiPoNet, an end-to-end differentiable neural network for regression, classification, and representation learning on high-dimensional point clouds.","Single-cell data can have high dimensionality exceeding the capabilities of existing methods point cloud tailored for 3D data.","Moreover, modern single-cell and spatial experiments now yield entire cohorts of datasets (i.e. one on every patient), necessitating models that can process large, high-dimensional point clouds at scale.","Most current approaches build a single nearest-neighbor graph, discarding important geometric information.","In contrast, HiPoNet forms higher-order simplicial complexes through learnable feature reweighting, generating multiple data views that disentangle distinct biological processes.","It then employs simplicial wavelet transforms to extract multi-scale features - capturing both local and global topology.","We empirically show that these components preserve topological information in the learned representations, and that HiPoNet significantly outperforms state-of-the-art point-cloud and graph-based models on single cell.","We also show an application of HiPoNet on spatial transcriptomics datasets using spatial co-ordinates as one of the views.","Overall, HiPoNet offers a robust and scalable solution for high-dimensional data analysis."],"url":"http://arxiv.org/abs/2502.07746v1"}
{"created":"2025-02-11 18:05:54","title":"Advancing climate model interpretability: Feature attribution for Arctic melt anomalies","abstract":"The focus of our work is improving the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics. The Arctic and Antarctic ice sheets are experiencing rapid surface melting and increased freshwater runoff, contributing significantly to global sea level rise. Understanding the mechanisms driving snowmelt in these regions is crucial. ERA5, a widely used reanalysis dataset in polar climate studies, offers extensive climate variables and global data assimilation. However, its snowmelt model employs an energy imbalance approach that may oversimplify the complexity of surface melt. In contrast, the Glacier Energy and Mass Balance (GEMB) model incorporates additional physical processes, such as snow accumulation, firn densification, and meltwater percolation/refreezing, providing a more detailed representation of surface melt dynamics. In this research, we focus on analyzing surface snowmelt dynamics of the Greenland Ice Sheet using feature attribution for anomalous melt events in ERA5 and GEMB models. We present a novel unsupervised attribution method leveraging counterfactual explanation method to analyze detected anomalies in ERA5 and GEMB. Our anomaly detection results are validated using MEaSUREs ground-truth data, and the attributions are evaluated against established feature ranking methods, including XGBoost, Shapley values, and Random Forest. Our attribution framework identifies the physics behind each model and the climate features driving melt anomalies. These findings demonstrate the utility of our attribution method in enhancing the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics.","sentences":["The focus of our work is improving the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics.","The Arctic and Antarctic ice sheets are experiencing rapid surface melting and increased freshwater runoff, contributing significantly to global sea level rise.","Understanding the mechanisms driving snowmelt in these regions is crucial.","ERA5, a widely used reanalysis dataset in polar climate studies, offers extensive climate variables and global data assimilation.","However, its snowmelt model employs an energy imbalance approach that may oversimplify the complexity of surface melt.","In contrast, the Glacier Energy and Mass Balance (GEMB) model incorporates additional physical processes, such as snow accumulation, firn densification, and meltwater percolation/refreezing, providing a more detailed representation of surface melt dynamics.","In this research, we focus on analyzing surface snowmelt dynamics of the Greenland Ice Sheet using feature attribution for anomalous melt events in ERA5 and GEMB models.","We present a novel unsupervised attribution method leveraging counterfactual explanation method to analyze detected anomalies in ERA5 and GEMB.","Our anomaly detection results are validated using MEaSUREs ground-truth data, and the attributions are evaluated against established feature ranking methods, including XGBoost, Shapley values, and Random Forest.","Our attribution framework identifies the physics behind each model and the climate features driving melt anomalies.","These findings demonstrate the utility of our attribution method in enhancing the interpretability of anomalies in climate models and advancing our understanding of Arctic melt dynamics."],"url":"http://arxiv.org/abs/2502.07741v1"}
{"created":"2025-02-11 17:59:35","title":"HRP: High-Rank Preheating for Superior LoRA Initialization","abstract":"This paper studies the crucial impact of initialization on the convergence properties of Low-Rank Adaptation (LoRA). We theoretically demonstrate that random initialization, a widely used schema, will likely lead LoRA to random low-rank results, rather than the best low-rank result. While this issue can be mitigated by adjusting initialization towards a well-informed direction, it relies on prior knowledge of the target, which is typically unknown in real-world scenarios. To approximate this well-informed initial direction, we propose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a few steps and uses the singular value decomposition of the preheated result as a superior initialization. HRP initialization is theory-supported to combine the convergence strengths of high-rank LoRA and the generalization strengths of low-rank LoRA. Extensive experiments demonstrate that HRP significantly enhances LoRA's effectiveness across various models and tasks, achieving performance comparable to full-parameter fine-tuning and outperforming other initialization strategies.","sentences":["This paper studies the crucial impact of initialization on the convergence properties of Low-Rank Adaptation (LoRA).","We theoretically demonstrate that random initialization, a widely used schema, will likely lead LoRA to random low-rank results, rather than the best low-rank result.","While this issue can be mitigated by adjusting initialization towards a well-informed direction, it relies on prior knowledge of the target, which is typically unknown in real-world scenarios.","To approximate this well-informed initial direction, we propose High-Rank Preheating (HRP), which fine-tunes high-rank LoRA for a few steps and uses the singular value decomposition of the preheated result as a superior initialization.","HRP initialization is theory-supported to combine the convergence strengths of high-rank LoRA and the generalization strengths of low-rank LoRA.","Extensive experiments demonstrate that HRP significantly enhances LoRA's effectiveness across various models and tasks, achieving performance comparable to full-parameter fine-tuning and outperforming other initialization strategies."],"url":"http://arxiv.org/abs/2502.07739v1"}
{"created":"2025-02-11 17:57:53","title":"Next Block Prediction: Video Generation via Semi-Auto-Regressive Modeling","abstract":"Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR) video generation, but it suffers from suboptimal unidirectional dependencies and slow inference speed. In this work, we propose a semi-autoregressive (semi-AR) framework, called Next-Block Prediction (NBP), for video generation. By uniformly decomposing video content into equal-sized blocks (e.g., rows or frames), we shift the generation unit from individual tokens to blocks, allowing each token in the current block to simultaneously predict the corresponding token in the next block. Unlike traditional AR modeling, our framework employs bidirectional attention within each block, enabling tokens to capture more robust spatial dependencies. By predicting multiple tokens in parallel, NBP models significantly reduce the number of generation steps, leading to faster and more efficient inference. Our model achieves FVD scores of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an average of 4.4. Furthermore, thanks to the reduced number of inference steps, the NBP model generates 8.89 frames (128x128 resolution) per second, achieving an 11x speedup. We also explored model scales ranging from 700M to 3B parameters, observing significant improvements in generation quality, with FVD scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600, demonstrating the scalability of our approach.","sentences":["Next-Token Prediction (NTP) is a de facto approach for autoregressive (AR) video generation, but it suffers from suboptimal unidirectional dependencies and slow inference speed.","In this work, we propose a semi-autoregressive (semi-AR) framework, called Next-Block Prediction (NBP), for video generation.","By uniformly decomposing video content into equal-sized blocks (e.g., rows or frames), we shift the generation unit from individual tokens to blocks, allowing each token in the current block to simultaneously predict the corresponding token in the next block.","Unlike traditional AR modeling, our framework employs bidirectional attention within each block, enabling tokens to capture more robust spatial dependencies.","By predicting multiple tokens in parallel, NBP models significantly reduce the number of generation steps, leading to faster and more efficient inference.","Our model achieves FVD scores of 103.3 on UCF101 and 25.5 on K600, outperforming the vanilla NTP model by an average of 4.4.","Furthermore, thanks to the reduced number of inference steps, the NBP model generates 8.89 frames (128x128 resolution) per second, achieving an 11x speedup.","We also explored model scales ranging from 700M to 3B parameters, observing significant improvements in generation quality, with FVD scores dropping from 103.3 to 55.3 on UCF101 and from 25.5 to 19.5 on K600, demonstrating the scalability of our approach."],"url":"http://arxiv.org/abs/2502.07737v1"}
{"created":"2025-02-11 17:55:03","title":"Revisiting Non-Acyclic GFlowNets in Discrete Environments","abstract":"Generative Flow Networks (GFlowNets) are a family of generative models that learn to sample objects from a given probability distribution, potentially known up to a normalizing constant. Instead of working in the object space, GFlowNets proceed by sampling trajectories in an appropriately constructed directed acyclic graph environment, greatly relying on the acyclicity of the graph. In our paper, we revisit the theory that relaxes the acyclicity assumption and present a simpler theoretical framework for non-acyclic GFlowNets in discrete environments. Moreover, we provide various novel theoretical insights related to training with fixed backward policies, the nature of flow functions, and connections between entropy-regularized RL and non-acyclic GFlowNets, which naturally generalize the respective concepts and theoretical results from the acyclic setting. In addition, we experimentally re-examine the concept of loss stability in non-acyclic GFlowNet training, as well as validate our own theoretical findings.","sentences":["Generative Flow Networks (GFlowNets) are a family of generative models that learn to sample objects from a given probability distribution, potentially known up to a normalizing constant.","Instead of working in the object space, GFlowNets proceed by sampling trajectories in an appropriately constructed directed acyclic graph environment, greatly relying on the acyclicity of the graph.","In our paper, we revisit the theory that relaxes the acyclicity assumption and present a simpler theoretical framework for non-acyclic GFlowNets in discrete environments.","Moreover, we provide various novel theoretical insights related to training with fixed backward policies, the nature of flow functions, and connections between entropy-regularized RL and non-acyclic GFlowNets, which naturally generalize the respective concepts and theoretical results from the acyclic setting.","In addition, we experimentally re-examine the concept of loss stability in non-acyclic GFlowNet training, as well as validate our own theoretical findings."],"url":"http://arxiv.org/abs/2502.07735v1"}
{"created":"2025-02-11 17:53:33","title":"EdgeEar: Efficient and Accurate Ear Recognition for Edge Devices","abstract":"Ear recognition is a contactless and unobtrusive biometric technique with applications across various domains. However, deploying high-performing ear recognition models on resource-constrained devices is challenging, limiting their applicability and widespread adoption. This paper introduces EdgeEar, a lightweight model based on a proposed hybrid CNN-transformer architecture to solve this problem. By incorporating low-rank approximations into specific linear layers, EdgeEar reduces its parameter count by a factor of 50 compared to the current state-of-the-art, bringing it below two million while maintaining competitive accuracy. Evaluation on the Unconstrained Ear Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the lowest EER while significantly reducing computational costs. These findings demonstrate the feasibility of efficient and accurate ear recognition, which we believe will contribute to the wider adoption of ear biometrics.","sentences":["Ear recognition is a contactless and unobtrusive biometric technique with applications across various domains.","However, deploying high-performing ear recognition models on resource-constrained devices is challenging, limiting their applicability and widespread adoption.","This paper introduces EdgeEar, a lightweight model based on a proposed hybrid CNN-transformer architecture to solve this problem.","By incorporating low-rank approximations into specific linear layers, EdgeEar reduces its parameter count by a factor of 50 compared to the current state-of-the-art, bringing it below two million while maintaining competitive accuracy.","Evaluation on the Unconstrained Ear Recognition Challenge (UERC2023) benchmark shows that EdgeEar achieves the lowest EER while significantly reducing computational costs.","These findings demonstrate the feasibility of efficient and accurate ear recognition, which we believe will contribute to the wider adoption of ear biometrics."],"url":"http://arxiv.org/abs/2502.07734v1"}
{"created":"2025-02-11 17:51:52","title":"Economics of Sourcing Human Data","abstract":"Progress in AI has relied on human-generated data, from annotator marketplaces to the wider Internet. However, the widespread use of large language models now threatens the quality and integrity of human-generated data on these very platforms. We argue that this issue goes beyond the immediate challenge of filtering AI-generated content--it reveals deeper flaws in how data collection systems are designed. Existing systems often prioritize speed, scale, and efficiency at the cost of intrinsic human motivation, leading to declining engagement and data quality. We propose that rethinking data collection systems to align with contributors' intrinsic motivations--rather than relying solely on external incentives--can help sustain high-quality data sourcing at scale while maintaining contributor trust and long-term participation.","sentences":["Progress in AI has relied on human-generated data, from annotator marketplaces to the wider Internet.","However, the widespread use of large language models now threatens the quality and integrity of human-generated data on these very platforms.","We argue that this issue goes beyond the immediate challenge of filtering AI-generated content--it reveals deeper flaws in how data collection systems are designed.","Existing systems often prioritize speed, scale, and efficiency at the cost of intrinsic human motivation, leading to declining engagement and data quality.","We propose that rethinking data collection systems to align with contributors' intrinsic motivations--rather than relying solely on external incentives--can help sustain high-quality data sourcing at scale while maintaining contributor trust and long-term participation."],"url":"http://arxiv.org/abs/2502.07732v1"}
{"created":"2025-02-11 17:50:49","title":"Online matching and market imbalance","abstract":"Our work introduces the effect of supply/demand imbalances into the literature on online matching with stochastic rewards in bipartite graphs. We provide a parameterized definition that characterizes instances as over- or undersupplied (or balanced), and show that higher competitive ratios against an offline clairvoyant algorithm are achievable, for both adversarial and stochastic arrivals, when instances are more imbalanced. The competitive ratio guarantees we obtain are the best-possible for the class of delayed algorithms we focus on (such algorithms may adapt to the history of arrivals and the algorithm's own decisions, but not to the stochastic realization of each potential match).   We then explore the real-world implications of our improved competitive ratios. First, we demonstrate analytically that the improved competitive ratios under imbalanced instances is not a one-way street by showing that a platform that conducts effective supply- and demand management should incorporate the effect of imbalance on its matching performance on its supply planning in order to create imbalanced instances. Second, we empirically study the relationship between achieved competitive ratios and imbalance using the data of a volunteer matching platform.","sentences":["Our work introduces the effect of supply/demand imbalances into the literature on online matching with stochastic rewards in bipartite graphs.","We provide a parameterized definition that characterizes instances as over- or undersupplied (or balanced), and show that higher competitive ratios against an offline clairvoyant algorithm are achievable, for both adversarial and stochastic arrivals, when instances are more imbalanced.","The competitive ratio guarantees we obtain are the best-possible for the class of delayed algorithms we focus on (such algorithms may adapt to the history of arrivals and the algorithm's own decisions, but not to the stochastic realization of each potential match).   ","We then explore the real-world implications of our improved competitive ratios.","First, we demonstrate analytically that the improved competitive ratios under imbalanced instances is not a one-way street by showing that a platform that conducts effective supply- and demand management should incorporate the effect of imbalance on its matching performance on its supply planning in order to create imbalanced instances.","Second, we empirically study the relationship between achieved competitive ratios and imbalance using the data of a volunteer matching platform."],"url":"http://arxiv.org/abs/2502.07731v1"}
{"created":"2025-02-11 17:47:05","title":"DOGlove: Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove","abstract":"Dexterous hand teleoperation plays a pivotal role in enabling robots to achieve human-level manipulation dexterity. However, current teleoperation systems often rely on expensive equipment and lack multi-modal sensory feedback, restricting human operators' ability to perceive object properties and perform complex manipulation tasks. To address these limitations, we present DOGlove, a low-cost, precise, and haptic force feedback glove system for teleoperation and manipulation. DoGlove can be assembled in hours at a cost under 600 USD. It features a customized joint structure for 21-DoF motion capture, a compact cable-driven torque transmission mechanism for 5-DoF multidirectional force feedback, and a linear resonate actuator for 5-DoF fingertip haptic feedback. Leveraging action and haptic force retargeting, DOGlove enables precise and immersive teleoperation of dexterous robotic hands, achieving high success rates in complex, contact-rich tasks. We further evaluate DOGlove in scenarios without visual feedback, demonstrating the critical role of haptic force feedback in task performance. In addition, we utilize the collected demonstrations to train imitation learning policies, highlighting the potential and effectiveness of DOGlove. DOGlove's hardware and software system will be fully open-sourced at https://do-glove.github.io/.","sentences":["Dexterous hand teleoperation plays a pivotal role in enabling robots to achieve human-level manipulation dexterity.","However, current teleoperation systems often rely on expensive equipment and lack multi-modal sensory feedback, restricting human operators' ability to perceive object properties and perform complex manipulation tasks.","To address these limitations, we present DOGlove, a low-cost, precise, and haptic force feedback glove system for teleoperation and manipulation.","DoGlove can be assembled in hours at a cost under 600 USD.","It features a customized joint structure for 21-DoF motion capture, a compact cable-driven torque transmission mechanism for 5-DoF multidirectional force feedback, and a linear resonate actuator for 5-DoF fingertip haptic feedback.","Leveraging action and haptic force retargeting, DOGlove enables precise and immersive teleoperation of dexterous robotic hands, achieving high success rates in complex, contact-rich tasks.","We further evaluate DOGlove in scenarios without visual feedback, demonstrating the critical role of haptic force feedback in task performance.","In addition, we utilize the collected demonstrations to train imitation learning policies, highlighting the potential and effectiveness of DOGlove.","DOGlove's hardware and software system will be fully open-sourced at https://do-glove.github.io/."],"url":"http://arxiv.org/abs/2502.07730v1"}
{"created":"2025-02-11 17:42:07","title":"Verifying LLM-Generated Code in the Context of Software Verification with Ada/SPARK","abstract":"Large language models (LLMs) have demonstrated remarkable code generation capabilities, but the correctness of the generated code cannot be inherently trusted. This paper explores the feasibility of using formal software verification, specifically the SPARK framework for Ada, to ensure the reliability of LLM-generated code. We present Marmaragan, a tool that leverages an LLM in order to generate SPARK annotations for existing programs, enabling formal verification of the code. The tool is benchmarked on a curated set of SPARK programs, with annotations selectively removed to test specific capabilities. The performance of Marmaragan with GPT-4o on the benchmark is promising, with correct annotations having been generated for 50.7% of the benchmark cases. The results establish a foundation for future work on combining the power of LLMs with the reliability of formal software verification.","sentences":["Large language models (LLMs) have demonstrated remarkable code generation capabilities, but the correctness of the generated code cannot be inherently trusted.","This paper explores the feasibility of using formal software verification, specifically the SPARK framework for Ada, to ensure the reliability of LLM-generated code.","We present Marmaragan, a tool that leverages an LLM in order to generate SPARK annotations for existing programs, enabling formal verification of the code.","The tool is benchmarked on a curated set of SPARK programs, with annotations selectively removed to test specific capabilities.","The performance of Marmaragan with GPT-4o on the benchmark is promising, with correct annotations having been generated for 50.7% of the benchmark cases.","The results establish a foundation for future work on combining the power of LLMs with the reliability of formal software verification."],"url":"http://arxiv.org/abs/2502.07728v1"}
{"created":"2025-02-11 17:39:54","title":"DeepVL: Dynamics and Inertial Measurements-based Deep Velocity Learning for Underwater Odometry","abstract":"This paper presents a learned model to predict the robot-centric velocity of an underwater robot through dynamics-aware proprioception. The method exploits a recurrent neural network using as inputs inertial cues, motor commands, and battery voltage readings alongside the hidden state of the previous time-step to output robust velocity estimates and their associated uncertainty. An ensemble of networks is utilized to enhance the velocity and uncertainty predictions. Fusing the network's outputs into an Extended Kalman Filter, alongside inertial predictions and barometer updates, the method enables long-term underwater odometry without further exteroception. Furthermore, when integrated into visual-inertial odometry, the method assists in enhanced estimation resilience when dealing with an order of magnitude fewer total features tracked (as few as 1) as compared to conventional visual-inertial systems. Tested onboard an underwater robot deployed both in a laboratory pool and the Trondheim Fjord, the method takes less than 5ms for inference either on the CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than 4% relative position error in novel trajectories during complete visual blackout, and approximately 2% relative error when a maximum of 2 visual features from a monocular camera are available.","sentences":["This paper presents a learned model to predict the robot-centric velocity of an underwater robot through dynamics-aware proprioception.","The method exploits a recurrent neural network using as inputs inertial cues, motor commands, and battery voltage readings alongside the hidden state of the previous time-step to output robust velocity estimates and their associated uncertainty.","An ensemble of networks is utilized to enhance the velocity and uncertainty predictions.","Fusing the network's outputs into an Extended Kalman Filter, alongside inertial predictions and barometer updates, the method enables long-term underwater odometry without further exteroception.","Furthermore, when integrated into visual-inertial odometry, the method assists in enhanced estimation resilience when dealing with an order of magnitude fewer total features tracked (as few as 1) as compared to conventional visual-inertial systems.","Tested onboard an underwater robot deployed both in a laboratory pool and the Trondheim Fjord, the method takes less than 5ms for inference either on the CPU or the GPU of an NVIDIA Orin AGX and demonstrates less than 4% relative position error in novel trajectories during complete visual blackout, and approximately 2% relative error when a maximum of 2 visual features from a monocular camera are available."],"url":"http://arxiv.org/abs/2502.07726v1"}
{"created":"2025-02-11 17:38:06","title":"Pluto: Authoring Semantically Aligned Text and Charts for Data-Driven Communication","abstract":"Textual content (including titles, annotations, and captions) plays a central role in helping readers understand a visualization by emphasizing, contextualizing, or summarizing the depicted data. Yet, existing visualization tools provide limited support for jointly authoring the two modalities of text and visuals such that both convey semantically-rich information and are cohesively integrated. In response, we introduce Pluto, a mixed-initiative authoring system that uses features of a chart's construction (e.g., visual encodings) as well as any textual descriptions a user may have drafted to make suggestions about the content and presentation of the two modalities. For instance, a user can begin to type out a description and interactively brush a region of interest in the chart, and Pluto will generate a relevant auto-completion of the sentence. Similarly, based on a written description, Pluto may suggest lifting a sentence out as an annotation or the visualization's title, or may suggest applying a data transformation (e.g., sort) to better align the two modalities. A preliminary user study revealed that Pluto's recommendations were particularly useful for bootstrapping the authoring process and helped identify different strategies participants adopt when jointly authoring text and charts. Based on study feedback, we discuss design implications for integrating interactive verification features between charts and text, offering control over text verbosity and tone, and enhancing the bidirectional flow in unified text and chart authoring tools.","sentences":["Textual content (including titles, annotations, and captions) plays a central role in helping readers understand a visualization by emphasizing, contextualizing, or summarizing the depicted data.","Yet, existing visualization tools provide limited support for jointly authoring the two modalities of text and visuals such that both convey semantically-rich information and are cohesively integrated.","In response, we introduce Pluto, a mixed-initiative authoring system that uses features of a chart's construction (e.g., visual encodings) as well as any textual descriptions a user may have drafted to make suggestions about the content and presentation of the two modalities.","For instance, a user can begin to type out a description and interactively brush a region of interest in the chart, and Pluto will generate a relevant auto-completion of the sentence.","Similarly, based on a written description, Pluto may suggest lifting a sentence out as an annotation or the visualization's title, or may suggest applying a data transformation (e.g., sort) to better align the two modalities.","A preliminary user study revealed that Pluto's recommendations were particularly useful for bootstrapping the authoring process and helped identify different strategies participants adopt when jointly authoring text and charts.","Based on study feedback, we discuss design implications for integrating interactive verification features between charts and text, offering control over text verbosity and tone, and enhancing the bidirectional flow in unified text and chart authoring tools."],"url":"http://arxiv.org/abs/2502.07725v1"}
{"created":"2025-02-11 17:33:48","title":"TMLC-Net: Transferable Meta Label Correction for Noisy Label Learning","abstract":"The prevalence of noisy labels in real-world datasets poses a significant impediment to the effective deployment of deep learning models. While meta-learning strategies have emerged as a promising approach for addressing this challenge, existing methods often suffer from limited transferability and task-specific designs. This paper introduces TMLC-Net, a novel Transferable Meta-Learner for Correcting Noisy Labels, designed to overcome these limitations. TMLC-Net learns a general-purpose label correction strategy that can be readily applied across diverse datasets and model architectures without requiring extensive retraining or fine-tuning. Our approach integrates three core components: (1) Normalized Noise Perception, which captures and normalizes training dynamics to handle distribution shifts; (2) Time-Series Encoding, which models the temporal evolution of sample statistics using a recurrent neural network; and (3) Subclass Decoding, which predicts a corrected label distribution based on the learned representations. We conduct extensive experiments on benchmark datasets with various noise types and levels, demonstrating that TMLC-Net consistently outperforms state-of-the-art methods in terms of both accuracy and robustness to label noise. Furthermore, we analyze the transferability of TMLC-Net, showcasing its adaptability to new datasets and noise conditions, and establishing its potential as a broadly applicable solution for robust deep learning in noisy environments.","sentences":["The prevalence of noisy labels in real-world datasets poses a significant impediment to the effective deployment of deep learning models.","While meta-learning strategies have emerged as a promising approach for addressing this challenge, existing methods often suffer from limited transferability and task-specific designs.","This paper introduces TMLC-Net, a novel Transferable Meta-Learner for Correcting Noisy Labels, designed to overcome these limitations.","TMLC-Net learns a general-purpose label correction strategy that can be readily applied across diverse datasets and model architectures without requiring extensive retraining or fine-tuning.","Our approach integrates three core components: (1) Normalized Noise Perception, which captures and normalizes training dynamics to handle distribution shifts; (2) Time-Series Encoding, which models the temporal evolution of sample statistics using a recurrent neural network; and (3) Subclass Decoding, which predicts a corrected label distribution based on the learned representations.","We conduct extensive experiments on benchmark datasets with various noise types and levels, demonstrating that TMLC-Net consistently outperforms state-of-the-art methods in terms of both accuracy and robustness to label noise.","Furthermore, we analyze the transferability of TMLC-Net, showcasing its adaptability to new datasets and noise conditions, and establishing its potential as a broadly applicable solution for robust deep learning in noisy environments."],"url":"http://arxiv.org/abs/2502.07721v1"}
{"created":"2025-02-11 17:23:52","title":"OpenCat: Improving Interoperability of ADS Testing","abstract":"Testing Advanced Driving Assistance Systems (ADAS), such as lane-keeping functions, requires creating road topologies or using predefined benchmarks. However, the test cases in existing ADAS benchmarks are often designed in specific formats (e.g., OpenDRIVE) and tailored to specific ADAS models. This limits their reusability and interoperability with other simulators and models, making it challenging to assess ADAS functionalities independently of the platform-specific details used to create the test cases.   This paper evaluates the interoperability of SensoDat, a benchmark developed for ADAS regression testing. We introduce OpenCat, a converter that transforms OpenDRIVE test cases into the Catmull-Rom spline format, which is widely supported by many current test generators. By applying OpenCat to the SensoDat dataset, we achieved high accuracy in converting test cases into reusable road scenarios. To validate the converted scenarios, we used them to evaluate a lane-keeping ADAS model using the Udacity simulator. Both the simulator and the ADAS model operate independently of the technologies underlying SensoDat, ensuring an unbiased evaluation of the original test cases.   Our findings reveal that benchmarks built with specific ADAS models hinder their effective usage for regression testing. We conclude by offering insights and recommendations to enhance the reusability and transferability of ADAS benchmarks for more extensive applications.","sentences":["Testing Advanced Driving Assistance Systems (ADAS), such as lane-keeping functions, requires creating road topologies or using predefined benchmarks.","However, the test cases in existing ADAS benchmarks are often designed in specific formats (e.g., OpenDRIVE) and tailored to specific ADAS models.","This limits their reusability and interoperability with other simulators and models, making it challenging to assess ADAS functionalities independently of the platform-specific details used to create the test cases.   ","This paper evaluates the interoperability of SensoDat, a benchmark developed for ADAS regression testing.","We introduce OpenCat, a converter that transforms OpenDRIVE test cases into the Catmull-Rom spline format, which is widely supported by many current test generators.","By applying OpenCat to the SensoDat dataset, we achieved high accuracy in converting test cases into reusable road scenarios.","To validate the converted scenarios, we used them to evaluate a lane-keeping ADAS model using the Udacity simulator.","Both the simulator and the ADAS model operate independently of the technologies underlying SensoDat, ensuring an unbiased evaluation of the original test cases.   ","Our findings reveal that benchmarks built with specific ADAS models hinder their effective usage for regression testing.","We conclude by offering insights and recommendations to enhance the reusability and transferability of ADAS benchmarks for more extensive applications."],"url":"http://arxiv.org/abs/2502.07719v1"}
{"created":"2025-02-11 17:22:44","title":"Next-to-minimal weight of toric codes defined over hypersimplices","abstract":"Toric codes are a type of evaluation codes introduced by J.P. Hansen in 2000. They are produced by evaluating (a vector space composed by) polynomials at the points of $(\\mathbb{F}_q^*)^s$, the monomials of these polynomials being related to a certain polytope. Toric codes related to hypersimplices are the result of the evaluation of a vector space of square-free homogeneous polynomials of degree $d$. The dimension and minimum distance of toric codes related to hypersimplices have been determined by Jaramillo et al. in 2021. The next-to-minimal weight in the case $d = 1$ has been determined by Jaramillo-Velez et al. in 2023. In this work we use tools from Gr\\\"obner basis theory to determine the next-to-minimal weight of these codes for $d$ such that $3 \\leq d \\leq \\frac{s - 2}{2}$ or $\\frac{s + 2}{2} \\leq d < s$.","sentences":["Toric codes are a type of evaluation codes introduced by J.P. Hansen in 2000.","They are produced by evaluating (a vector space composed by) polynomials at the points of $(\\mathbb{F}_q^*)^s$, the monomials of these polynomials being related to a certain polytope.","Toric codes related to hypersimplices are the result of the evaluation of a vector space of square-free homogeneous polynomials of degree $d$.","The dimension and minimum distance of toric codes related to hypersimplices have been determined by Jaramillo et al.","in 2021.","The next-to-minimal weight in the case $d = 1$ has been determined by Jaramillo-Velez et al. in 2023.","In this work we use tools from Gr\\\"obner basis theory to determine the next-to-minimal weight of these codes for $d$ such that $3 \\leq d \\leq \\frac{s - 2}{2}$ or $\\frac{s + 2}{2} \\leq d < s$."],"url":"http://arxiv.org/abs/2502.07718v1"}
{"created":"2025-02-11 17:18:47","title":"Making Language Models Robust Against Negation","abstract":"Negation has been a long-standing challenge for language models. Previous studies have shown that they struggle with negation in many natural language understanding tasks. In this work, we propose a self-supervised method to make language models more robust against negation. We introduce a novel task, Next Sentence Polarity Prediction (NSPP), and a variation of the Next Sentence Prediction (NSP) task. We show that BERT and RoBERTa further pre-trained on our tasks outperform the off-the-shelf versions on nine negation-related benchmarks. Most notably, our pre-training tasks yield between 1.8% and 9.1% improvement on CondaQA, a large question-answering corpus requiring reasoning over negation.","sentences":["Negation has been a long-standing challenge for language models.","Previous studies have shown that they struggle with negation in many natural language understanding tasks.","In this work, we propose a self-supervised method to make language models more robust against negation.","We introduce a novel task, Next Sentence Polarity Prediction (NSPP), and a variation of the Next Sentence Prediction (NSP) task.","We show that BERT and RoBERTa further pre-trained on our tasks outperform the off-the-shelf versions on nine negation-related benchmarks.","Most notably, our pre-training tasks yield between 1.8% and 9.1% improvement on CondaQA, a large question-answering corpus requiring reasoning over negation."],"url":"http://arxiv.org/abs/2502.07717v1"}
{"created":"2025-02-11 17:15:55","title":"Near-Optimal Sample Complexity in Reward-Free Kernel-Based Reinforcement Learning","abstract":"Reinforcement Learning (RL) problems are being considered under increasingly more complex structures. While tabular and linear models have been thoroughly explored, the analytical study of RL under nonlinear function approximation, especially kernel-based models, has recently gained traction for their strong representational capacity and theoretical tractability. In this context, we examine the question of statistical efficiency in kernel-based RL within the reward-free RL framework, specifically asking: how many samples are required to design a near-optimal policy? Existing work addresses this question under restrictive assumptions about the class of kernel functions. We first explore this question by assuming a generative model, then relax this assumption at the cost of increasing the sample complexity by a factor of H, the length of the episode. We tackle this fundamental problem using a broad class of kernels and a simpler algorithm compared to prior work. Our approach derives new confidence intervals for kernel ridge regression, specific to our RL setting, which may be of broader applicability. We further validate our theoretical findings through simulations.","sentences":["Reinforcement Learning (RL) problems are being considered under increasingly more complex structures.","While tabular and linear models have been thoroughly explored, the analytical study of RL under nonlinear function approximation, especially kernel-based models, has recently gained traction for their strong representational capacity and theoretical tractability.","In this context, we examine the question of statistical efficiency in kernel-based RL within the reward-free RL framework, specifically asking: how many samples are required to design a near-optimal policy?","Existing work addresses this question under restrictive assumptions about the class of kernel functions.","We first explore this question by assuming a generative model, then relax this assumption at the cost of increasing the sample complexity by a factor of H, the length of the episode.","We tackle this fundamental problem using a broad class of kernels and a simpler algorithm compared to prior work.","Our approach derives new confidence intervals for kernel ridge regression, specific to our RL setting, which may be of broader applicability.","We further validate our theoretical findings through simulations."],"url":"http://arxiv.org/abs/2502.07715v1"}
{"created":"2025-02-11 17:11:11","title":"Mock Deep Testing: Toward Separate Development of Data and Models for Deep Learning","abstract":"While deep learning (DL) has permeated, and become an integral component of many critical software systems, today software engineering research hasn't explored how to separately test data and models that are integral for DL approaches to work effectively. The main challenge in independently testing these components arises from the tight dependency between data and models. This research explores this gap, introducing our methodology of mock deep testing for unit testing of DL applications. To enable unit testing, we introduce a design paradigm that decomposes the workflow into distinct, manageable components, minimizes sequential dependencies, and modularizes key stages of the DL. For unit testing these components, we propose modeling their dependencies using mocks. This modular approach facilitates independent development and testing of the components, ensuring comprehensive quality assurance throughout the development process. We have developed KUnit, a framework for enabling mock deep testing for the Keras library. We empirically evaluated KUnit to determine the effectiveness of mocks. Our assessment of 50 DL programs obtained from Stack Overflow and GitHub shows that mocks effectively identified 10 issues in the data preparation stage and 53 issues in the model design stage. We also conducted a user study with 36 participants using KUnit to perceive the effectiveness of our approach. Participants using KUnit successfully resolved 25 issues in the data preparation stage and 38 issues in the model design stage. Our findings highlight that mock objects provide a lightweight emulation of the dependencies for unit testing, facilitating early bug detection. Lastly, to evaluate the usability of KUnit, we conducted a post-study survey. The results reveal that KUnit is helpful to DL application developers, enabling them to independently test each component effectively in different stages.","sentences":["While deep learning (DL) has permeated, and become an integral component of many critical software systems, today software engineering research hasn't explored how to separately test data and models that are integral for DL approaches to work effectively.","The main challenge in independently testing these components arises from the tight dependency between data and models.","This research explores this gap, introducing our methodology of mock deep testing for unit testing of DL applications.","To enable unit testing, we introduce a design paradigm that decomposes the workflow into distinct, manageable components, minimizes sequential dependencies, and modularizes key stages of the DL.","For unit testing these components, we propose modeling their dependencies using mocks.","This modular approach facilitates independent development and testing of the components, ensuring comprehensive quality assurance throughout the development process.","We have developed KUnit, a framework for enabling mock deep testing for the Keras library.","We empirically evaluated KUnit to determine the effectiveness of mocks.","Our assessment of 50 DL programs obtained from Stack Overflow and GitHub shows that mocks effectively identified 10 issues in the data preparation stage and 53 issues in the model design stage.","We also conducted a user study with 36 participants using KUnit to perceive the effectiveness of our approach.","Participants using KUnit successfully resolved 25 issues in the data preparation stage and 38 issues in the model design stage.","Our findings highlight that mock objects provide a lightweight emulation of the dependencies for unit testing, facilitating early bug detection.","Lastly, to evaluate the usability of KUnit, we conducted a post-study survey.","The results reveal that KUnit is helpful to DL application developers, enabling them to independently test each component effectively in different stages."],"url":"http://arxiv.org/abs/2502.07712v1"}
{"created":"2025-02-11 17:08:00","title":"MAGELLAN: Metacognitive predictions of learning progress guide autotelic LLM agents in large goal spaces","abstract":"Open-ended learning agents must efficiently prioritize goals in vast possibility spaces, focusing on those that maximize learning progress (LP). When such autotelic exploration is achieved by LLM agents trained with online RL in high-dimensional and evolving goal spaces, a key challenge for LP prediction is modeling one's own competence, a form of metacognitive monitoring. Traditional approaches either require extensive sampling or rely on brittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive framework that lets LLM agents learn to predict their competence and LP online. By capturing semantic relationships between goals, MAGELLAN enables sample-efficient LP estimation and dynamic adaptation to evolving goal spaces through generalization. In an interactive learning environment, we show that MAGELLAN improves LP prediction efficiency and goal prioritization, being the only method allowing the agent to fully master a large and evolving goal space. These results demonstrate how augmenting LLM agents with a metacognitive ability for LP predictions can effectively scale curriculum learning to open-ended goal spaces.","sentences":["Open-ended learning agents must efficiently prioritize goals in vast possibility spaces, focusing on those that maximize learning progress (LP).","When such autotelic exploration is achieved by LLM agents trained with online RL in high-dimensional and evolving goal spaces, a key challenge for LP prediction is modeling one's own competence, a form of metacognitive monitoring.","Traditional approaches either require extensive sampling or rely on brittle expert-defined goal groupings.","We introduce MAGELLAN, a metacognitive framework that lets LLM agents learn to predict their competence and LP online.","By capturing semantic relationships between goals, MAGELLAN enables sample-efficient LP estimation and dynamic adaptation to evolving goal spaces through generalization.","In an interactive learning environment, we show that MAGELLAN improves LP prediction efficiency and goal prioritization, being the only method allowing the agent to fully master a large and evolving goal space.","These results demonstrate how augmenting LLM agents with a metacognitive ability for LP predictions can effectively scale curriculum learning to open-ended goal spaces."],"url":"http://arxiv.org/abs/2502.07709v1"}
{"created":"2025-02-11 17:04:31","title":"PRVQL: Progressive Knowledge-guided Refinement for Robust Egocentric Visual Query Localization","abstract":"Egocentric visual query localization (EgoVQL) focuses on localizing the target of interest in space and time from first-person videos, given a visual query. Despite recent progressive, existing methods often struggle to handle severe object appearance changes and cluttering background in the video due to lacking sufficient target cues, leading to degradation. Addressing this, we introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for EgoVQL. The core is to continuously exploit target-relevant knowledge directly from videos and utilize it as guidance to refine both query and video features for improving target localization. Our PRVQL contains multiple processing stages. The target knowledge from one stage, comprising appearance and spatial knowledge extracted via two specially designed knowledge learning modules, are utilized as guidance to refine the query and videos features for the next stage, which are used to generate more accurate knowledge for further feature refinement. With such a progressive process, target knowledge in PRVQL can be gradually improved, which, in turn, leads to better refined query and video features for localization in the final stage. Compared to previous methods, our PRVQL, besides the given object cues, enjoys additional crucial target information from a video as guidance to refine features, and hence enhances EgoVQL in complicated scenes. In our experiments on challenging Ego4D, PRVQL achieves state-of-the-art result and largely surpasses other methods, showing its efficacy. Our code, model and results will be released at https://github.com/fb-reps/PRVQL.","sentences":["Egocentric visual query localization (EgoVQL) focuses on localizing the target of interest in space and time from first-person videos, given a visual query.","Despite recent progressive, existing methods often struggle to handle severe object appearance changes and cluttering background in the video due to lacking sufficient target cues, leading to degradation.","Addressing this, we introduce PRVQL, a novel Progressive knowledge-guided Refinement framework for EgoVQL.","The core is to continuously exploit target-relevant knowledge directly from videos and utilize it as guidance to refine both query and video features for improving target localization.","Our PRVQL contains multiple processing stages.","The target knowledge from one stage, comprising appearance and spatial knowledge extracted via two specially designed knowledge learning modules, are utilized as guidance to refine the query and videos features for the next stage, which are used to generate more accurate knowledge for further feature refinement.","With such a progressive process, target knowledge in PRVQL can be gradually improved, which, in turn, leads to better refined query and video features for localization in the final stage.","Compared to previous methods, our PRVQL, besides the given object cues, enjoys additional crucial target information from a video as guidance to refine features, and hence enhances EgoVQL in complicated scenes.","In our experiments on challenging Ego4D, PRVQL achieves state-of-the-art result and largely surpasses other methods, showing its efficacy.","Our code, model and results will be released at https://github.com/fb-reps/PRVQL."],"url":"http://arxiv.org/abs/2502.07707v1"}
{"created":"2025-02-11 17:00:18","title":"GaRLIO: Gravity enhanced Radar-LiDAR-Inertial Odometry","abstract":"Recently, gravity has been highlighted as a crucial constraint for state estimation to alleviate potential vertical drift. Existing online gravity estimation methods rely on pose estimation combined with IMU measurements, which is considered best practice when direct velocity measurements are unavailable. However, with radar sensors providing direct velocity data-a measurement not yet utilized for gravity estimation-we found a significant opportunity to improve gravity estimation accuracy substantially. GaRLIO, the proposed gravity-enhanced Radar-LiDAR-Inertial Odometry, can robustly predict gravity to reduce vertical drift while simultaneously enhancing state estimation performance using pointwise velocity measurements. Furthermore, GaRLIO ensures robustness in dynamic environments by utilizing radar to remove dynamic objects from LiDAR point clouds. Our method is validated through experiments in various environments prone to vertical drift, demonstrating superior performance compared to traditional LiDAR-Inertial Odometry methods. We make our source code publicly available to encourage further research and development. https://github.com/ChiyunNoh/GaRLIO","sentences":["Recently, gravity has been highlighted as a crucial constraint for state estimation to alleviate potential vertical drift.","Existing online gravity estimation methods rely on pose estimation combined with IMU measurements, which is considered best practice when direct velocity measurements are unavailable.","However, with radar sensors providing direct velocity data-a measurement not yet utilized for gravity estimation-we found a significant opportunity to improve gravity estimation accuracy substantially.","GaRLIO, the proposed gravity-enhanced Radar-LiDAR-Inertial Odometry, can robustly predict gravity to reduce vertical drift while simultaneously enhancing state estimation performance using pointwise velocity measurements.","Furthermore, GaRLIO ensures robustness in dynamic environments by utilizing radar to remove dynamic objects from LiDAR point clouds.","Our method is validated through experiments in various environments prone to vertical drift, demonstrating superior performance compared to traditional LiDAR-Inertial Odometry methods.","We make our source code publicly available to encourage further research and development.","https://github.com/ChiyunNoh/GaRLIO"],"url":"http://arxiv.org/abs/2502.07703v1"}
{"created":"2025-02-11 16:58:15","title":"Magic 1-For-1: Generating One Minute Video Clips within One Minute","abstract":"In this technical report, we present Magic 1-For-1 (Magic141), an efficient video generation model with optimized memory consumption and inference latency. The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation. We verify that with the same optimization algorithm, the image-to-video task is indeed easier to converge over the text-to-video task. We also explore a bag of optimization tricks to reduce the computational cost of training the image-to-video (I2V) models from three aspects: 1) model convergence speedup by using a multi-modal prior condition injection; 2) inference latency speed up by applying an adversarial step distillation, and 3) inference memory cost optimization with parameter sparsification. With those techniques, we are able to generate 5-second video clips within 3 seconds. By applying a test time sliding window, we are able to generate a minute-long video within one minute with significantly improved visual quality and motion dynamics, spending less than 1 second for generating 1 second video clips on average. We conduct a series of preliminary explorations to find out the optimal tradeoff between computational cost and video quality during diffusion step distillation and hope this could be a good foundation model for open-source explorations. The code and the model weights are available at https://github.com/DA-Group-PKU/Magic-1-For-1.","sentences":["In this technical report, we present Magic 1-For-1 (Magic141), an efficient video generation model with optimized memory consumption and inference latency.","The key idea is simple: factorize the text-to-video generation task into two separate easier tasks for diffusion step distillation, namely text-to-image generation and image-to-video generation.","We verify that with the same optimization algorithm, the image-to-video task is indeed easier to converge over the text-to-video task.","We also explore a bag of optimization tricks to reduce the computational cost of training the image-to-video (I2V) models from three aspects: 1) model convergence speedup by using a multi-modal prior condition injection; 2) inference latency speed up by applying an adversarial step distillation, and 3) inference memory cost optimization with parameter sparsification.","With those techniques, we are able to generate 5-second video clips within 3 seconds.","By applying a test time sliding window, we are able to generate a minute-long video within one minute with significantly improved visual quality and motion dynamics, spending less than 1 second for generating 1 second video clips on average.","We conduct a series of preliminary explorations to find out the optimal tradeoff between computational cost and video quality during diffusion step distillation and hope this could be a good foundation model for open-source explorations.","The code and the model weights are available at https://github.com/DA-Group-PKU/Magic-1-For-1."],"url":"http://arxiv.org/abs/2502.07701v1"}
{"created":"2025-02-11 16:51:11","title":"A Framework for LLM-powered Design Assistants","abstract":"Design assistants are frameworks, tools or applications intended to facilitate both the creative and technical facets of design processes. Large language models (LLMs) are AI systems engineered to analyze and produce text resembling human language, leveraging extensive datasets. This study introduces a framework wherein LLMs are employed as Design Assistants, focusing on three key modalities within the Design Process: Idea Exploration, Dialogue with Designers, and Design Evaluation. Importantly, our framework is not confined to a singular design process but is adaptable across various processes.","sentences":["Design assistants are frameworks, tools or applications intended to facilitate both the creative and technical facets of design processes.","Large language models (LLMs) are AI systems engineered to analyze and produce text resembling human language, leveraging extensive datasets.","This study introduces a framework wherein LLMs are employed as Design Assistants, focusing on three key modalities within the Design Process: Idea Exploration, Dialogue with Designers, and Design Evaluation.","Importantly, our framework is not confined to a singular design process but is adaptable across various processes."],"url":"http://arxiv.org/abs/2502.07698v1"}
{"created":"2025-02-11 16:48:48","title":"Methodology for Identifying Social Groups within a Transactional Graph","abstract":"Social network analysis is pivotal for organizations aiming to leverage the vast amounts of data generated from user interactions on social media and other digital platforms. These interactions often reveal complex social structures, such as tightly-knit groups based on common interests, which are crucial for enhancing service personalization or fraud detection. Traditional methods like community detection and graph matching, while useful, often fall short of accurately identifying specific groups of users. This paper introduces a novel framework specifically designed to identify groups of users within transactional graphs by focusing on the contextual and structural nuances that define these groups.","sentences":["Social network analysis is pivotal for organizations aiming to leverage the vast amounts of data generated from user interactions on social media and other digital platforms.","These interactions often reveal complex social structures, such as tightly-knit groups based on common interests, which are crucial for enhancing service personalization or fraud detection.","Traditional methods like community detection and graph matching, while useful, often fall short of accurately identifying specific groups of users.","This paper introduces a novel framework specifically designed to identify groups of users within transactional graphs by focusing on the contextual and structural nuances that define these groups."],"url":"http://arxiv.org/abs/2502.07694v1"}
{"created":"2025-02-11 16:46:56","title":"SoK: A Classification for AI-driven Personalized Privacy Assistants","abstract":"To help users make privacy-related decisions, personalized privacy assistants based on AI technology have been developed in recent years. These AI-driven Personalized Privacy Assistants (AI-driven PPAs) can reap significant benefits for users, who may otherwise struggle to make decisions regarding their personal data in environments saturated with privacy-related decision requests. However, no study systematically inquired about the features of these AI-driven PPAs, their underlying technologies, or the accuracy of their decisions. To fill this gap, we present a Systematization of Knowledge (SoK) to map the existing solutions found in the scientific literature. We screened 1697 unique research papers over the last decade (2013-2023), constructing a classification from 39 included papers. As a result, this SoK reviews several aspects of existing research on AI-driven PPAs in terms of types of publications, contributions, methodological quality, and other quantitative insights. Furthermore, we provide a comprehensive classification for AI-driven PPAs, delving into their architectural choices, system contexts, types of AI used, data sources, types of decisions, and control over decisions, among other facets. Based on our SoK, we further underline the research gaps and challenges and formulate recommendations for the design and development of AI-driven PPAs as well as avenues for future research.","sentences":["To help users make privacy-related decisions, personalized privacy assistants based on AI technology have been developed in recent years.","These AI-driven Personalized Privacy Assistants (AI-driven PPAs) can reap significant benefits for users, who may otherwise struggle to make decisions regarding their personal data in environments saturated with privacy-related decision requests.","However, no study systematically inquired about the features of these AI-driven PPAs, their underlying technologies, or the accuracy of their decisions.","To fill this gap, we present a Systematization of Knowledge (SoK) to map the existing solutions found in the scientific literature.","We screened 1697 unique research papers over the last decade (2013-2023), constructing a classification from 39 included papers.","As a result, this SoK reviews several aspects of existing research on AI-driven PPAs in terms of types of publications, contributions, methodological quality, and other quantitative insights.","Furthermore, we provide a comprehensive classification for AI-driven PPAs, delving into their architectural choices, system contexts, types of AI used, data sources, types of decisions, and control over decisions, among other facets.","Based on our SoK, we further underline the research gaps and challenges and formulate recommendations for the design and development of AI-driven PPAs as well as avenues for future research."],"url":"http://arxiv.org/abs/2502.07693v1"}
{"created":"2025-02-11 16:38:16","title":"Large Language Models as Proxies for Theories of Human Linguistic Cognition","abstract":"We consider the possible role of current large language models (LLMs) in the study of human linguistic cognition. We focus on the use of such models as proxies for theories of cognition that are relatively linguistically-neutral in their representations and learning but differ from current LLMs in key ways. We illustrate this potential use of LLMs as proxies for theories of cognition in the context of two kinds of questions: (a) whether the target theory accounts for the acquisition of a given pattern from a given corpus; and (b) whether the target theory makes a given typologically-attested pattern easier to acquire than another, typologically-unattested pattern. For each of the two questions we show, building on recent literature, how current LLMs can potentially be of help, but we note that at present this help is quite limited.","sentences":["We consider the possible role of current large language models (LLMs) in the study of human linguistic cognition.","We focus on the use of such models as proxies for theories of cognition that are relatively linguistically-neutral in their representations and learning but differ from current LLMs in key ways.","We illustrate this potential use of LLMs as proxies for theories of cognition in the context of two kinds of questions: (a) whether the target theory accounts for the acquisition of a given pattern from a given corpus; and (b) whether the target theory makes a given typologically-attested pattern easier to acquire than another, typologically-unattested pattern.","For each of the two questions we show, building on recent literature, how current LLMs can potentially be of help, but we note that at present this help is quite limited."],"url":"http://arxiv.org/abs/2502.07687v1"}
{"created":"2025-02-11 16:36:55","title":"Matrix3D: Large Photogrammetry Model All-in-One","abstract":"We present Matrix3D, a unified model that performs several photogrammetry subtasks, including pose estimation, depth prediction, and novel view synthesis using just the same model. Matrix3D utilizes a multi-modal diffusion transformer (DiT) to integrate transformations across several modalities, such as images, camera parameters, and depth maps. The key to Matrix3D's large-scale multi-modal training lies in the incorporation of a mask learning strategy. This enables full-modality model training even with partially complete data, such as bi-modality data of image-pose and image-depth pairs, thus significantly increases the pool of available training data. Matrix3D demonstrates state-of-the-art performance in pose estimation and novel view synthesis tasks. Additionally, it offers fine-grained control through multi-round interactions, making it an innovative tool for 3D content creation. Project page: https://nju-3dv.github.io/projects/matrix3d.","sentences":["We present Matrix3D, a unified model that performs several photogrammetry subtasks, including pose estimation, depth prediction, and novel view synthesis using just the same model.","Matrix3D utilizes a multi-modal diffusion transformer (DiT) to integrate transformations across several modalities, such as images, camera parameters, and depth maps.","The key to Matrix3D's large-scale multi-modal training lies in the incorporation of a mask learning strategy.","This enables full-modality model training even with partially complete data, such as bi-modality data of image-pose and image-depth pairs, thus significantly increases the pool of available training data.","Matrix3D demonstrates state-of-the-art performance in pose estimation and novel view synthesis tasks.","Additionally, it offers fine-grained control through multi-round interactions, making it an innovative tool for 3D content creation.","Project page: https://nju-3dv.github.io/projects/matrix3d."],"url":"http://arxiv.org/abs/2502.07685v1"}
{"created":"2025-02-11 16:35:04","title":"exHarmony: Authorship and Citations for Benchmarking the Reviewer Assignment Problem","abstract":"The peer review process is crucial for ensuring the quality and reliability of scholarly work, yet assigning suitable reviewers remains a significant challenge. Traditional manual methods are labor-intensive and often ineffective, leading to nonconstructive or biased reviews. This paper introduces the exHarmony (eHarmony but for connecting experts to manuscripts) benchmark, designed to address these challenges by re-imagining the Reviewer Assignment Problem (RAP) as a retrieval task. Utilizing the extensive data from OpenAlex, we propose a novel approach that considers a host of signals from the authors, most similar experts, and the citation relations as potential indicators for a suitable reviewer for a manuscript. This approach allows us to develop a standard benchmark dataset for evaluating the reviewer assignment problem without needing explicit labels. We benchmark various methods, including traditional lexical matching, static neural embeddings, and contextualized neural embeddings, and introduce evaluation metrics that assess both relevance and diversity in the context of RAP. Our results indicate that while traditional methods perform reasonably well, contextualized embeddings trained on scholarly literature show the best performance. The findings underscore the importance of further research to enhance the diversity and effectiveness of reviewer assignments.","sentences":["The peer review process is crucial for ensuring the quality and reliability of scholarly work, yet assigning suitable reviewers remains a significant challenge.","Traditional manual methods are labor-intensive and often ineffective, leading to nonconstructive or biased reviews.","This paper introduces the exHarmony (eHarmony but for connecting experts to manuscripts) benchmark, designed to address these challenges by re-imagining the Reviewer Assignment Problem (RAP) as a retrieval task.","Utilizing the extensive data from OpenAlex, we propose a novel approach that considers a host of signals from the authors, most similar experts, and the citation relations as potential indicators for a suitable reviewer for a manuscript.","This approach allows us to develop a standard benchmark dataset for evaluating the reviewer assignment problem without needing explicit labels.","We benchmark various methods, including traditional lexical matching, static neural embeddings, and contextualized neural embeddings, and introduce evaluation metrics that assess both relevance and diversity in the context of RAP.","Our results indicate that while traditional methods perform reasonably well, contextualized embeddings trained on scholarly literature show the best performance.","The findings underscore the importance of further research to enhance the diversity and effectiveness of reviewer assignments."],"url":"http://arxiv.org/abs/2502.07683v1"}
{"created":"2025-02-11 16:30:14","title":"Multiview Point Cloud Registration Based on Minimum Potential Energy for Free-Form Blade Measurement","abstract":"Point cloud registration is an essential step for free-form blade reconstruction in industrial measurement. Nonetheless, measuring defects of the 3D acquisition system unavoidably result in noisy and incomplete point cloud data, which renders efficient and accurate registration challenging. In this paper, we propose a novel global registration method that is based on the minimum potential energy (MPE) method to address these problems. The basic strategy is that the objective function is defined as the minimum potential energy optimization function of the physical registration system. The function distributes more weight to the majority of inlier points and less weight to the noise and outliers, which essentially reduces the influence of perturbations in the mathematical formulation. We decompose the solution into a globally optimal approximation procedure and a fine registration process with the trimmed iterative closest point algorithm to boost convergence. The approximation procedure consists of two main steps. First, according to the construction of the force traction operator, we can simply compute the position of the potential energy minimum. Second, to find the MPE point, we propose a new theory that employs two flags to observe the status of the registration procedure. We demonstrate the performance of the proposed algorithm on four types of blades. The proposed method outperforms the other global methods in terms of both accuracy and noise resistance.","sentences":["Point cloud registration is an essential step for free-form blade reconstruction in industrial measurement.","Nonetheless, measuring defects of the 3D acquisition system unavoidably result in noisy and incomplete point cloud data, which renders efficient and accurate registration challenging.","In this paper, we propose a novel global registration method that is based on the minimum potential energy (MPE) method to address these problems.","The basic strategy is that the objective function is defined as the minimum potential energy optimization function of the physical registration system.","The function distributes more weight to the majority of inlier points and less weight to the noise and outliers, which essentially reduces the influence of perturbations in the mathematical formulation.","We decompose the solution into a globally optimal approximation procedure and a fine registration process with the trimmed iterative closest point algorithm to boost convergence.","The approximation procedure consists of two main steps.","First, according to the construction of the force traction operator, we can simply compute the position of the potential energy minimum.","Second, to find the MPE point, we propose a new theory that employs two flags to observe the status of the registration procedure.","We demonstrate the performance of the proposed algorithm on four types of blades.","The proposed method outperforms the other global methods in terms of both accuracy and noise resistance."],"url":"http://arxiv.org/abs/2502.07680v1"}
{"created":"2025-02-11 16:27:28","title":"Auto-Drafting Police Reports from Noisy ASR Outputs: A Trust-Centered LLM Approach","abstract":"Achieving a delicate balance between fostering trust in law en- forcement and protecting the rights of both officers and civilians continues to emerge as a pressing research and product challenge in the world today. In the pursuit of fairness and transparency, this study presents an innovative AI-driven system designed to generate police report drafts from complex, noisy, and multi-role dialogue data. Our approach intelligently extracts key elements of law enforcement interactions and includes them in the draft, producing structured narratives that are not only high in quality but also reinforce accountability and procedural clarity. This frame- work holds the potential to transform the reporting process, ensur- ing greater oversight, consistency, and fairness in future policing practices. A demonstration video of our system can be accessed at https://drive.google.com/file/d/1kBrsGGR8e3B5xPSblrchRGj- Y-kpCHNO/view?usp=sharing","sentences":["Achieving a delicate balance between fostering trust in law en-","forcement and protecting the rights of both officers and civilians continues to emerge as a pressing research and product challenge in the world today.","In the pursuit of fairness and transparency, this study presents an innovative AI-driven system designed to generate police report drafts from complex, noisy, and multi-role dialogue data.","Our approach intelligently extracts key elements of law enforcement interactions and includes them in the draft, producing structured narratives that are not only high in quality but also reinforce accountability and procedural clarity.","This frame- work holds the potential to transform the reporting process, ensur- ing greater oversight, consistency, and fairness in future policing practices.","A demonstration video of our system can be accessed at https://drive.google.com/file/d/1kBrsGGR8e3B5xPSblrchRGj- Y-kpCHNO/view?usp=sharing"],"url":"http://arxiv.org/abs/2502.07677v1"}
{"created":"2025-02-11 16:14:53","title":"Coresets for Robust Clustering via Black-box Reductions to Vanilla Case","abstract":"We devise $\\epsilon$-coresets for robust $(k,z)$-Clustering with $m$ outliers through black-box reductions to vanilla case. Given an $\\epsilon$-coreset construction for vanilla clustering with size $N$, we construct coresets of size $N\\cdot \\mathrm{poly}\\log(km\\epsilon^{-1}) + O_z\\left(\\min\\{km\\epsilon^{-1}, m\\epsilon^{-2z}\\log^z(km\\epsilon^{-1}) \\}\\right)$ for various metric spaces, where $O_z$ hides $2^{O(z\\log z)}$ factors. This increases the size of the vanilla coreset by a small multiplicative factor of $\\mathrm{poly}\\log(km\\epsilon^{-1})$, and the additive term is up to a $(\\epsilon^{-1}\\log (km))^{O(z)}$ factor to the size of the optimal robust coreset. Plugging in vanilla coreset results of [Cohen-Addad et al., STOC'21], we obtain the first coresets for $(k,z)$-Clustering with $m$ outliers with size near-linear in $k$ while previous results have size at least $\\Omega(k^2)$ [Huang et al., ICLR'23; Huang et al., SODA'25].   Technically, we establish two conditions under which a vanilla coreset is as well a robust coreset. The first condition requires the dataset to satisfy special structures - it can be broken into \"dense\" parts with bounded diameter. We combine this with a new bounded-diameter decomposition that has only $O_z(km \\epsilon^{-1})$ non-dense points to obtain the $O_z(km \\epsilon^{-1})$ additive bound. Another condition requires the vanilla coreset to possess an extra size-preserving property. We further give a black-box reduction that turns a vanilla coreset to the one satisfying the said size-preserving property, leading to the alternative $O_z(m\\epsilon^{-2z}\\log^{z}(km\\epsilon^{-1}))$ additive bound.   We also implement our reductions in the dynamic streaming setting and obtain the first streaming algorithms for $k$-Median and $k$-Means with $m$ outliers, using space $\\tilde{O}(k+m)\\cdot\\mathrm{poly}(d\\epsilon^{-1}\\log\\Delta)$ for inputs on the grid $[\\Delta]^d$.","sentences":["We devise $\\epsilon$-coresets for robust $(k,z)$-Clustering with $m$ outliers through black-box reductions to vanilla case.","Given an $\\epsilon$-coreset construction for vanilla clustering with size $N$, we construct coresets of size $N\\cdot \\mathrm{poly}\\log(km\\epsilon^{-1}) + O_z\\left(\\min\\{km\\epsilon^{-1}, m\\epsilon^{-2z}\\log^z(km\\epsilon^{-1}) \\}\\right)$ for various metric spaces, where $O_z$ hides $2^{O(z\\log z)}$ factors.","This increases the size of the vanilla coreset by a small multiplicative factor of $\\mathrm{poly}\\log(km\\epsilon^{-1})$, and the additive term is up to a $(\\epsilon^{-1}\\log (km))^{O(z)}$ factor to the size of the optimal robust coreset.","Plugging in vanilla coreset results of [Cohen-Addad et al., STOC'21], we obtain the first coresets for $(k,z)$-Clustering with $m$ outliers with size near-linear in $k$ while previous results have size at least $\\Omega(k^2)$","[Huang et al., ICLR'23; Huang et al., SODA'25].   ","Technically, we establish two conditions under which a vanilla coreset is as well a robust coreset.","The first condition requires the dataset to satisfy special structures - it can be broken into \"dense\" parts with bounded diameter.","We combine this with a new bounded-diameter decomposition that has only $O_z(km \\epsilon^{-1})$ non-dense points to obtain the $O_z(km \\epsilon^{-1})$ additive bound.","Another condition requires the vanilla coreset to possess an extra size-preserving property.","We further give a black-box reduction that turns a vanilla coreset to the one satisfying the said size-preserving property, leading to the alternative $O_z(m\\epsilon^{-2z}\\log^{z}(km\\epsilon^{-1}))$ additive bound.   ","We also implement our reductions in the dynamic streaming setting and obtain the first streaming algorithms for $k$-Median and $k$-Means with $m$ outliers, using space $\\tilde{O}(k+m)\\cdot\\mathrm{poly}(d\\epsilon^{-1}\\log\\Delta)$ for inputs on the grid $[\\Delta]^d$."],"url":"http://arxiv.org/abs/2502.07669v1"}
{"created":"2025-02-11 15:56:22","title":"Human Decision-making is Susceptible to AI-driven Manipulation","abstract":"Artificial Intelligence (AI) systems are increasingly intertwined with daily life, assisting users in executing various tasks and providing guidance on decision-making. This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes. Through a randomized controlled trial with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts. Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit psychological tactics to reach its hidden objectives. By analyzing participants' decision patterns and shifts in their preference ratings post-interaction, we found significant susceptibility to AI-driven manipulation. Particularly, across both decision-making domains, participants interacting with the manipulative agents shifted toward harmful options at substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA: 42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional, 12.8%). Notably, our findings reveal that even subtle manipulative objectives (MA) can be as effective as employing explicit psychological strategies (SEMA) in swaying human decision-making. By revealing the potential for covert AI influence, this study highlights a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to ensure responsible deployment of AI technologies and protect human autonomy.","sentences":["Artificial Intelligence (AI) systems are increasingly intertwined with daily life, assisting users in executing various tasks and providing guidance on decision-making.","This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes.","Through a randomized controlled trial with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts.","Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit psychological tactics to reach its hidden objectives.","By analyzing participants' decision patterns and shifts in their preference ratings post-interaction, we found significant susceptibility to AI-driven manipulation.","Particularly, across both decision-making domains, participants interacting with the manipulative agents shifted toward harmful options at substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA: 42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional, 12.8%).","Notably, our findings reveal that even subtle manipulative objectives (MA) can be as effective as employing explicit psychological strategies (SEMA) in swaying human decision-making.","By revealing the potential for covert AI influence, this study highlights a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to ensure responsible deployment of AI technologies and protect human autonomy."],"url":"http://arxiv.org/abs/2502.07663v1"}
{"created":"2025-02-11 15:51:23","title":"Partial-Label Learning with Conformal Candidate Cleaning","abstract":"Real-world data is often ambiguous; for example, human annotation produces instances with multiple conflicting class labels. Partial-label learning (PLL) aims at training a classifier in this challenging setting, where each instance is associated with a set of candidate labels and one correct, but unknown, class label. A multitude of algorithms targeting this setting exists and, to enhance their prediction quality, several extensions that are applicable across a wide range of PLL methods have been introduced. While many of these extensions rely on heuristics, this article proposes a novel enhancing method that incrementally prunes candidate sets using conformal prediction. To work around the missing labeled validation set, which is typically required for conformal prediction, we propose a strategy that alternates between training a PLL classifier to label the validation set, leveraging these predicted class labels for calibration, and pruning candidate labels that are not part of the resulting conformal sets. In this sense, our method alternates between empirical risk minimization and candidate set pruning. We establish that our pruning method preserves the conformal validity with respect to the unknown ground truth. Our extensive experiments on artificial and real-world data show that the proposed approach significantly improves the test set accuracies of several state-of-the-art PLL classifiers.","sentences":["Real-world data is often ambiguous; for example, human annotation produces instances with multiple conflicting class labels.","Partial-label learning (PLL) aims at training a classifier in this challenging setting, where each instance is associated with a set of candidate labels and one correct, but unknown, class label.","A multitude of algorithms targeting this setting exists and, to enhance their prediction quality, several extensions that are applicable across a wide range of PLL methods have been introduced.","While many of these extensions rely on heuristics, this article proposes a novel enhancing method that incrementally prunes candidate sets using conformal prediction.","To work around the missing labeled validation set, which is typically required for conformal prediction, we propose a strategy that alternates between training a PLL classifier to label the validation set, leveraging these predicted class labels for calibration, and pruning candidate labels that are not part of the resulting conformal sets.","In this sense, our method alternates between empirical risk minimization and candidate set pruning.","We establish that our pruning method preserves the conformal validity with respect to the unknown ground truth.","Our extensive experiments on artificial and real-world data show that the proposed approach significantly improves the test set accuracies of several state-of-the-art PLL classifiers."],"url":"http://arxiv.org/abs/2502.07661v1"}
{"created":"2025-02-11 15:48:12","title":"Reachability and Related Problems in Vector Addition Systems with Nested Zero Tests","abstract":"Vector addition systems with states (VASS), also known as Petri nets, are a popular model of concurrent systems. Many problems from many areas reduce to the reachability problem for VASS, which consists of deciding whether a target configuration of a VASS is reachable from a given initial configuration. In this paper, we obtain an Ackermannian (primitive-recursive in fixed dimension) upper bound for the reachability problem in VASS with nested zero tests. Furthermore, we provide a uniform approach which also allows to decide most related problems, for example semilinearity and separability, in the same complexity. For some of these problems like semilinearity the complexity was unknown even for plain VASS.","sentences":["Vector addition systems with states (VASS), also known as Petri nets, are a popular model of concurrent systems.","Many problems from many areas reduce to the reachability problem for VASS, which consists of deciding whether a target configuration of a VASS is reachable from a given initial configuration.","In this paper, we obtain an Ackermannian (primitive-recursive in fixed dimension) upper bound for the reachability problem in VASS with nested zero tests.","Furthermore, we provide a uniform approach which also allows to decide most related problems, for example semilinearity and separability, in the same complexity.","For some of these problems like semilinearity the complexity was unknown even for plain VASS."],"url":"http://arxiv.org/abs/2502.07660v1"}
{"created":"2025-02-11 15:46:28","title":"IU4Rec: Interest Unit-Based Product Organization and Recommendation for E-Commerce Platform","abstract":"Most recommendation systems typically follow a product-based paradigm utilizing user-product interactions to identify the most engaging items for users. However, this product-based paradigm has notable drawbacks for Xianyu~\\footnote{Xianyu is China's largest online C2C e-commerce platform where a large portion of the product are post by individual sellers}. Most of the product on Xianyu posted from individual sellers often have limited stock available for distribution, and once the product is sold, it's no longer available for distribution. This result in most items distributed product on Xianyu having relatively few interactions, affecting the effectiveness of traditional recommendation depending on accumulating user-item interactions. To address these issues, we introduce \\textbf{IU4Rec}, an \\textbf{I}nterest \\textbf{U}nit-based two-stage \\textbf{Rec}ommendation system framework. We first group products into clusters based on attributes such as category, image, and semantics. These IUs are then integrated into the Recommendation system, delivering both product and technological innovations. IU4Rec begins by grouping products into clusters based on attributes such as category, image, and semantics, forming Interest Units (IUs). Then we redesign the recommendation process into two stages. In the first stage, the focus is on recommend these Interest Units, capturing broad-level interests. In the second stage, it guides users to find the best option among similar products within the selected Interest Unit. User-IU interactions are incorporated into our ranking models, offering the advantage of more persistent IU behaviors compared to item-specific interactions. Experimental results on the production dataset and online A/B testing demonstrate the effectiveness and superiority of our proposed IU-centric recommendation approach.","sentences":["Most recommendation systems typically follow a product-based paradigm utilizing user-product interactions to identify the most engaging items for users.","However, this product-based paradigm has notable drawbacks for Xianyu~\\footnote{Xianyu is China's largest online C2C e-commerce platform where a large portion of the product are post by individual sellers}.","Most of the product on Xianyu posted from individual sellers often have limited stock available for distribution, and once the product is sold, it's no longer available for distribution.","This result in most items distributed product on Xianyu having relatively few interactions, affecting the effectiveness of traditional recommendation depending on accumulating user-item interactions.","To address these issues, we introduce \\textbf{IU4Rec}, an \\textbf{I}nterest \\textbf{U}nit-based two-stage \\textbf{Rec}ommendation system framework.","We first group products into clusters based on attributes such as category, image, and semantics.","These IUs are then integrated into the Recommendation system, delivering both product and technological innovations.","IU4Rec begins by grouping products into clusters based on attributes such as category, image, and semantics, forming Interest Units (IUs).","Then we redesign the recommendation process into two stages.","In the first stage, the focus is on recommend these Interest Units, capturing broad-level interests.","In the second stage, it guides users to find the best option among similar products within the selected Interest Unit.","User-IU interactions are incorporated into our ranking models, offering the advantage of more persistent IU behaviors compared to item-specific interactions.","Experimental results on the production dataset and online A/B testing demonstrate the effectiveness and superiority of our proposed IU-centric recommendation approach."],"url":"http://arxiv.org/abs/2502.07658v1"}
{"created":"2025-02-11 15:46:03","title":"Private Low-Rank Approximation for Covariance Matrices, Dyson Brownian Motion, and Eigenvalue-Gap Bounds for Gaussian Perturbations","abstract":"We consider the problem of approximating a $d \\times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\\varepsilon,\\delta)$-differential privacy. We present and analyze a complex variant of the Gaussian mechanism and obtain upper bounds on the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$. Our analysis provides improvements over previous bounds, particularly when the spectrum of $M$ satisfies natural structural assumptions. The novel insight is to view the addition of Gaussian noise to a matrix as a continuous-time matrix Brownian motion. This viewpoint allows us to track the evolution of eigenvalues and eigenvectors of the matrix, which are governed by stochastic differential equations discovered by Dyson. These equations enable us to upper bound the Frobenius distance between the best rank-$k$ approximation of $M$ and that of a Gaussian perturbation of $M$ as an integral that involves inverse eigenvalue gaps of the stochastically evolving matrix, as opposed to a sum of perturbation bounds obtained via Davis-Kahan-type theorems. Subsequently, again using the Dyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$ perturbed by Gaussian noise have large gaps with high probability. These results also contribute to the analysis of low-rank approximations under average-case perturbations, and to an understanding of eigenvalue gaps for random matrices, both of which may be of independent interest.","sentences":["We consider the problem of approximating a $d \\times d$ covariance matrix $M$ with a rank-$k$ matrix under $(\\varepsilon,\\delta)$-differential privacy.","We present and analyze a complex variant of the Gaussian mechanism and obtain upper bounds on the Frobenius norm of the difference between the matrix output by this mechanism and the best rank-$k$ approximation to $M$. Our analysis provides improvements over previous bounds, particularly when the spectrum of $M$ satisfies natural structural assumptions.","The novel insight is to view the addition of Gaussian noise to a matrix as a continuous-time matrix Brownian motion.","This viewpoint allows us to track the evolution of eigenvalues and eigenvectors of the matrix, which are governed by stochastic differential equations discovered by Dyson.","These equations enable us to upper bound the Frobenius distance between the best rank-$k$ approximation of $M$ and that of a Gaussian perturbation of $M$ as an integral that involves inverse eigenvalue gaps of the stochastically evolving matrix, as opposed to a sum of perturbation bounds obtained via Davis-Kahan-type theorems.","Subsequently, again using the Dyson Brownian motion viewpoint, we show that the eigenvalues of the matrix $M$ perturbed by Gaussian noise have large gaps with high probability.","These results also contribute to the analysis of low-rank approximations under average-case perturbations, and to an understanding of eigenvalue gaps for random matrices, both of which may be of independent interest."],"url":"http://arxiv.org/abs/2502.07657v1"}
{"created":"2025-02-11 15:43:49","title":"A Unifying Framework for Causal Imitation Learning with Hidden Confounders","abstract":"We propose a general and unifying framework for causal Imitation Learning (IL) with hidden confounders that subsumes several existing confounded IL settings from the literature. Our framework accounts for two types of hidden confounders: (a) those observed by the expert, which thus influence the expert's policy, and (b) confounding noise hidden to both the expert and the IL algorithm. For additional flexibility, we also introduce a confounding noise horizon and time-varying expert-observable hidden variables. We show that causal IL in our framework can be reduced to a set of Conditional Moment Restrictions (CMRs) by leveraging trajectory histories as instruments to learn a history-dependent policy. We propose DML-IL, a novel algorithm that uses instrumental variable regression to solve these CMRs and learn a policy. We provide a bound on the imitation gap for DML-IL, which recovers prior results as special cases. Empirical evaluation on a toy environment with continues state-action spaces and multiple Mujoco tasks demonstrate that DML-IL outperforms state-of-the-art causal IL algorithms.","sentences":["We propose a general and unifying framework for causal Imitation Learning (IL) with hidden confounders that subsumes several existing confounded IL settings from the literature.","Our framework accounts for two types of hidden confounders: (a) those observed by the expert, which thus influence the expert's policy, and (b) confounding noise hidden to both the expert and the IL algorithm.","For additional flexibility, we also introduce a confounding noise horizon and time-varying expert-observable hidden variables.","We show that causal IL in our framework can be reduced to a set of Conditional Moment Restrictions (CMRs) by leveraging trajectory histories as instruments to learn a history-dependent policy.","We propose DML-IL, a novel algorithm that uses instrumental variable regression to solve these CMRs and learn a policy.","We provide a bound on the imitation gap for DML-IL, which recovers prior results as special cases.","Empirical evaluation on a toy environment with continues state-action spaces and multiple Mujoco tasks demonstrate that DML-IL outperforms state-of-the-art","causal IL algorithms."],"url":"http://arxiv.org/abs/2502.07656v1"}
{"created":"2025-02-11 15:40:27","title":"Robust-Sorting and Applications to Ulam-Median","abstract":"Sorting is one of the most basic primitives in many algorithms and data analysis tasks. Comparison-based sorting algorithms, like quick-sort and merge-sort, are known to be optimal when the outcome of each comparison is error-free. However, many real-world sorting applications operate in scenarios where the outcome of each comparison can be noisy. In this work, we explore settings where a bounded number of comparisons are potentially corrupted by erroneous agents, resulting in arbitrary, adversarial outcomes.   We model the sorting problem as a query-limited tournament graph where edges involving erroneous nodes may yield arbitrary results. Our primary contribution is a randomized algorithm inspired by quick-sort that, in expectation, produces an ordering close to the true total order while only querying $\\tilde{O}(n)$ edges. We achieve a distance from the target order $\\pi$ within $(3 + \\epsilon)|B|$, where $B$ is the set of erroneous nodes, balancing the competing objectives of minimizing both query complexity and misalignment with $\\pi$. Our algorithm needs to carefully balance two aspects: identify a pivot that partitions the vertex set evenly and ensure that this partition is \"truthful\" and yet query as few \"triangles\" in the graph $G$ as possible. Since the nodes in $B$ can potentially hide in an intricate manner, our algorithm requires several technical steps.   Additionally, we demonstrate significant implications for the Ulam-$k$-Median problem, a classical clustering problem where the metric is defined on the set of permutations on a set of $d$ elements. Chakraborty, Das, and Krauthgamer gave a $(2-\\varepsilon)$ FPT approximation algorithm for this problem, where the running time is super-linear in both $n$ and $d$. We use our robust sorting framework to give the first $(2-\\varepsilon)$ FPT linear time approximation algorithm for this problem.","sentences":["Sorting is one of the most basic primitives in many algorithms and data analysis tasks.","Comparison-based sorting algorithms, like quick-sort and merge-sort, are known to be optimal when the outcome of each comparison is error-free.","However, many real-world sorting applications operate in scenarios where the outcome of each comparison can be noisy.","In this work, we explore settings where a bounded number of comparisons are potentially corrupted by erroneous agents, resulting in arbitrary, adversarial outcomes.   ","We model the sorting problem as a query-limited tournament graph where edges involving erroneous nodes may yield arbitrary results.","Our primary contribution is a randomized algorithm inspired by quick-sort that, in expectation, produces an ordering close to the true total order while only querying $\\tilde{O}(n)$ edges.","We achieve a distance from the target order $\\pi$ within $(3 + \\epsilon)|B|$, where $B$ is the set of erroneous nodes, balancing the competing objectives of minimizing both query complexity and misalignment with $\\pi$. Our algorithm needs to carefully balance two aspects: identify a pivot that partitions the vertex set evenly and ensure that this partition is \"truthful\" and yet query as few \"triangles\" in the graph $G$ as possible.","Since the nodes in $B$ can potentially hide in an intricate manner, our algorithm requires several technical steps.   ","Additionally, we demonstrate significant implications for the Ulam-$k$-Median problem, a classical clustering problem where the metric is defined on the set of permutations on a set of $d$ elements.","Chakraborty, Das, and Krauthgamer gave a $(2-\\varepsilon)$ FPT approximation algorithm for this problem, where the running time is super-linear in both $n$ and $d$. We use our robust sorting framework to give the first $(2-\\varepsilon)$ FPT linear time approximation algorithm for this problem."],"url":"http://arxiv.org/abs/2502.07653v1"}
{"created":"2025-02-11 15:40:09","title":"Insuperable strategies in two-player and reducible multi-player games","abstract":"Real populations are seldom found at the Nash equilibrium strategy. The present work focuses on how population size can be a relevant evolutionary force diverting the population from its expected Nash equilibrium. We introduce the concept of insuperable strategy, a strategy that guarantees that no other player can have a larger payoff than the player that adopts it. We show that this concept is different from the rationality assumption frequently used in game theory and that for small populations the insuperable strategy is the most probable evolutionary outcome for any dynamics that equal game payoff and reproductive fitness. We support our ideas with several examples and numerical simulations. We finally discuss how to extend the concept to multiplayer games, introducing, in a limited way, the concept of game reduction.","sentences":["Real populations are seldom found at the Nash equilibrium strategy.","The present work focuses on how population size can be a relevant evolutionary force diverting the population from its expected Nash equilibrium.","We introduce the concept of insuperable strategy, a strategy that guarantees that no other player can have a larger payoff than the player that adopts it.","We show that this concept is different from the rationality assumption frequently used in game theory and that for small populations the insuperable strategy is the most probable evolutionary outcome for any dynamics that equal game payoff and reproductive fitness.","We support our ideas with several examples and numerical simulations.","We finally discuss how to extend the concept to multiplayer games, introducing, in a limited way, the concept of game reduction."],"url":"http://arxiv.org/abs/2502.07652v1"}
{"created":"2025-02-11 15:36:55","title":"Linting is People! Exploring the Potential of Human Computation as a Sociotechnical Linter of Data Visualizations","abstract":"Traditionally, linters are code analysis tools that help developers by flagging potential issues from syntax and logic errors to enforcing syntactical and stylistic conventions. Recently, linting has been taken as an interface metaphor, allowing it to be extended to more complex inputs, such as visualizations, which demand a broader perspective and alternative approach to evaluation. We explore a further extended consideration of linting inputs, and modes of evaluation, across the puritanical, neutral, and rebellious dimensions. We specifically investigate the potential for leveraging human computation in linting operations through Community Notes -- crowd-sourced contextual text snippets aimed at checking and critiquing potentially accurate or misleading content on social media. We demonstrate that human-powered assessments not only identify misleading or error-prone visualizations but that integrating human computation enhances traditional linting by offering social insights. As is required these days, we consider the implications of building linters powered by Artificial Intelligence.","sentences":["Traditionally, linters are code analysis tools that help developers by flagging potential issues from syntax and logic errors to enforcing syntactical and stylistic conventions.","Recently, linting has been taken as an interface metaphor, allowing it to be extended to more complex inputs, such as visualizations, which demand a broader perspective and alternative approach to evaluation.","We explore a further extended consideration of linting inputs, and modes of evaluation, across the puritanical, neutral, and rebellious dimensions.","We specifically investigate the potential for leveraging human computation in linting operations through Community Notes -- crowd-sourced contextual text snippets aimed at checking and critiquing potentially accurate or misleading content on social media.","We demonstrate that human-powered assessments not only identify misleading or error-prone visualizations but that integrating human computation enhances traditional linting by offering social insights.","As is required these days, we consider the implications of building linters powered by Artificial Intelligence."],"url":"http://arxiv.org/abs/2502.07649v1"}
{"created":"2025-02-11 15:35:15","title":"Causal Additive Models with Unobserved Causal Paths and Backdoor Paths","abstract":"Causal additive models have been employed as tractable yet expressive frameworks for causal discovery involving hidden variables. State-of-the-art methodologies suggest that determining the causal relationship between a pair of variables is infeasible in the presence of an unobserved backdoor or an unobserved causal path. Contrary to this assumption, we theoretically show that resolving the causal direction is feasible in certain scenarios by incorporating two novel components into the theory. The first component introduces a novel characterization of regression sets within independence between regression residuals. The second component leverages conditional independence among the observed variables. We also provide a search algorithm that integrates these innovations and demonstrate its competitive performance against existing methods.","sentences":["Causal additive models have been employed as tractable yet expressive frameworks for causal discovery involving hidden variables.","State-of-the-art methodologies suggest that determining the causal relationship between a pair of variables is infeasible in the presence of an unobserved backdoor or an unobserved causal path.","Contrary to this assumption, we theoretically show that resolving the causal direction is feasible in certain scenarios by incorporating two novel components into the theory.","The first component introduces a novel characterization of regression sets within independence between regression residuals.","The second component leverages conditional independence among the observed variables.","We also provide a search algorithm that integrates these innovations and demonstrate its competitive performance against existing methods."],"url":"http://arxiv.org/abs/2502.07646v1"}
{"created":"2025-02-11 15:34:24","title":"Beyond Behavior Cloning: Robustness through Interactive Imitation and Contrastive Learning","abstract":"Behavior cloning (BC) traditionally relies on demonstration data, assuming the demonstrated actions are optimal. This can lead to overfitting under noisy data, particularly when expressive models are used (e.g., the energy-based model in Implicit BC). To address this, we extend behavior cloning into an iterative process of optimal action estimation within the Interactive Imitation Learning framework. Specifically, we introduce Contrastive policy Learning from Interactive Corrections (CLIC). CLIC leverages human corrections to estimate a set of desired actions and optimizes the policy to select actions from this set. We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases. Extensive simulation and real-robot experiments validate CLIC's advantages over existing state-of-the-art methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback types beyond demonstrations. Our code will be publicly available soon.","sentences":["Behavior cloning (BC) traditionally relies on demonstration data, assuming the demonstrated actions are optimal.","This can lead to overfitting under noisy data, particularly when expressive models are used (e.g., the energy-based model in Implicit BC).","To address this, we extend behavior cloning into an iterative process of optimal action estimation within the Interactive Imitation Learning framework.","Specifically, we introduce Contrastive policy Learning from Interactive Corrections (CLIC).","CLIC leverages human corrections to estimate a set of desired actions and optimizes the policy to select actions from this set.","We provide theoretical guarantees for the convergence of the desired action set to optimal actions in both single and multiple optimal action cases.","Extensive simulation and real-robot experiments validate CLIC's advantages over existing state-of-the-art methods, including stable training of energy-based models, robustness to feedback noise, and adaptability to diverse feedback types beyond demonstrations.","Our code will be publicly available soon."],"url":"http://arxiv.org/abs/2502.07645v1"}
{"created":"2025-02-11 15:34:00","title":"SymGPT: Auditing Smart Contracts via Combining Symbolic Execution with Large Language Models","abstract":"To govern smart contracts running on Ethereum, multiple Ethereum Request for Comment (ERC) standards have been developed, each having a set of rules to guide the behaviors of smart contracts. Violating the ERC rules could cause serious security issues and financial loss, signifying the importance of verifying smart contracts follow ERCs. Today's practices of such verification are to manually audit each single contract, use expert-developed program-analysis tools, or use large language models (LLMs), all of which are far from effective in identifying ERC rule violations. This paper introduces SymGPT, a tool that combines the natural language understanding of large language models (LLMs) with the formal guarantees of symbolic execution to automatically verify smart contracts' compliance with ERC rules. To develop SymGPT, we conduct an empirical study of 132 ERC rules from three widely used ERC standards, examining their content, security implications, and natural language descriptions. Based on this study, we design SymGPT by first instructing an LLM to translate ERC rules into a defined EBNF grammar. We then synthesize constraints from the formalized rules to represent scenarios where violations may occur and use symbolic execution to detect them. Our evaluation shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world contracts, including 1,375 violations with clear attack paths for stealing financial assets, demonstrating its effectiveness. Furthermore, SymGPT outperforms six automated techniques and a security-expert auditing service, underscoring its superiority over current smart contract analysis methods.","sentences":["To govern smart contracts running on Ethereum, multiple Ethereum Request for Comment (ERC) standards have been developed, each having a set of rules to guide the behaviors of smart contracts.","Violating the ERC rules could cause serious security issues and financial loss, signifying the importance of verifying smart contracts follow ERCs.","Today's practices of such verification are to manually audit each single contract, use expert-developed program-analysis tools, or use large language models (LLMs), all of which are far from effective in identifying ERC rule violations.","This paper introduces SymGPT, a tool that combines the natural language understanding of large language models (LLMs) with the formal guarantees of symbolic execution to automatically verify smart contracts' compliance with ERC rules.","To develop SymGPT, we conduct an empirical study of 132 ERC rules from three widely used ERC standards, examining their content, security implications, and natural language descriptions.","Based on this study, we design SymGPT by first instructing an LLM to translate ERC rules into a defined EBNF grammar.","We then synthesize constraints from the formalized rules to represent scenarios where violations may occur and use symbolic execution to detect them.","Our evaluation shows that SymGPT identifies 5,783 ERC rule violations in 4,000 real-world contracts, including 1,375 violations with clear attack paths for stealing financial assets, demonstrating its effectiveness.","Furthermore, SymGPT outperforms six automated techniques and a security-expert auditing service, underscoring its superiority over current smart contract analysis methods."],"url":"http://arxiv.org/abs/2502.07644v1"}
{"created":"2025-02-11 15:33:17","title":"FoQA: A Faroese Question-Answering Dataset","abstract":"We present FoQA, a Faroese extractive question-answering (QA) dataset with 2,000 samples, created using a semi-automated approach combining Large Language Models (LLMs) and human validation. The dataset was generated from Faroese Wikipedia articles using GPT-4-turbo for initial QA generation, followed by question rephrasing to increase complexity and native speaker validation to ensure quality. We provide baseline performance metrics for FoQA across multiple models, including LLMs and BERT, demonstrating its effectiveness in evaluating Faroese QA performance. The dataset is released in three versions: a validated set of 2,000 samples, a complete set of all 10,001 generated samples, and a set of 2,395 rejected samples for error analysis.","sentences":["We present FoQA, a Faroese extractive question-answering (QA) dataset with 2,000 samples, created using a semi-automated approach combining Large Language Models (LLMs) and human validation.","The dataset was generated from Faroese Wikipedia articles using GPT-4-turbo for initial QA generation, followed by question rephrasing to increase complexity and native speaker validation to ensure quality.","We provide baseline performance metrics for FoQA across multiple models, including LLMs and BERT, demonstrating its effectiveness in evaluating Faroese QA performance.","The dataset is released in three versions: a validated set of 2,000 samples, a complete set of all 10,001 generated samples, and a set of 2,395 rejected samples for error analysis."],"url":"http://arxiv.org/abs/2502.07642v1"}
{"created":"2025-02-11 15:27:35","title":"Goedel-Prover: A Frontier Model for Open-Source Automated Theorem Proving","abstract":"We introduce Goedel-Prover, an open-source large language model (LLM) that achieves the state-of-the-art (SOTA) performance in automated formal proof generation for mathematical problems. The key challenge in this field is the scarcity of formalized math statements and proofs, which we tackle in the following ways. We train statement formalizers to translate the natural language math problems from Numina into formal language (Lean 4), creating a dataset of 1.64 million formal statements. LLMs are used to check that the formal statements accurately preserve the content of the original natural language problems. We then iteratively build a large dataset of formal proofs by training a series of provers. Each prover succeeds in proving many statements that the previous ones could not, and these new proofs are added to the training set for the next prover. The final prover outperforms all existing open-source models in whole-proof generation. On the miniF2F benchmark, it achieves a 57.6% success rate (Pass@32), exceeding the previous best open-source model by 7.6%. On PutnamBench, Goedel-Prover successfully solves 7 problems (Pass@512), ranking first on the leaderboard. Furthermore, it generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the 15.7K produced by earlier works.","sentences":["We introduce Goedel-Prover, an open-source large language model (LLM) that achieves the state-of-the-art (SOTA) performance in automated formal proof generation for mathematical problems.","The key challenge in this field is the scarcity of formalized math statements and proofs, which we tackle in the following ways.","We train statement formalizers to translate the natural language math problems from Numina into formal language (Lean 4), creating a dataset of 1.64 million formal statements.","LLMs are used to check that the formal statements accurately preserve the content of the original natural language problems.","We then iteratively build a large dataset of formal proofs by training a series of provers.","Each prover succeeds in proving many statements that the previous ones could not, and these new proofs are added to the training set for the next prover.","The final prover outperforms all existing open-source models in whole-proof generation.","On the miniF2F benchmark, it achieves a 57.6% success rate (Pass@32), exceeding the previous best open-source model by 7.6%.","On PutnamBench, Goedel-Prover successfully solves 7 problems (Pass@512), ranking first on the leaderboard.","Furthermore, it generates 29.7K formal proofs for Lean Workbook problems, nearly doubling the 15.7K produced by earlier works."],"url":"http://arxiv.org/abs/2502.07640v1"}
{"created":"2025-02-11 15:25:10","title":"BiaSWE: An Expert Annotated Dataset for Misogyny Detection in Swedish","abstract":"In this study, we introduce the process for creating BiaSWE, an expert-annotated dataset tailored for misogyny detection in the Swedish language. To address the cultural and linguistic specificity of misogyny in Swedish, we collaborated with experts from the social sciences and humanities. Our interdisciplinary team developed a rigorous annotation process, incorporating both domain knowledge and language expertise, to capture the nuances of misogyny in a Swedish context. This methodology ensures that the dataset is not only culturally relevant but also aligned with broader efforts in bias detection for low-resource languages. The dataset, along with the annotation guidelines, is publicly available for further research.","sentences":["In this study, we introduce the process for creating BiaSWE, an expert-annotated dataset tailored for misogyny detection in the Swedish language.","To address the cultural and linguistic specificity of misogyny in Swedish, we collaborated with experts from the social sciences and humanities.","Our interdisciplinary team developed a rigorous annotation process, incorporating both domain knowledge and language expertise, to capture the nuances of misogyny in a Swedish context.","This methodology ensures that the dataset is not only culturally relevant but also aligned with broader efforts in bias detection for low-resource languages.","The dataset, along with the annotation guidelines, is publicly available for further research."],"url":"http://arxiv.org/abs/2502.07637v1"}
{"created":"2025-02-11 15:23:14","title":"Consistency Training with Physical Constraints","abstract":"We propose a physics-aware Consistency Training (CT) method that accelerates sampling in Diffusion Models with physical constraints. Our approach leverages a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2) incorporating physics constraints as a regularizer. Experiments on toy examples show that our method generates samples in a single step while adhering to the imposed constraints. This approach has the potential to efficiently solve partial differential equations (PDEs) using deep generative modeling.","sentences":["We propose a physics-aware Consistency Training (CT) method that accelerates sampling in Diffusion Models with physical constraints.","Our approach leverages a two-stage strategy: (1) learning the noise-to-data mapping via CT, and (2) incorporating physics constraints as a regularizer.","Experiments on toy examples show that our method generates samples in a single step while adhering to the imposed constraints.","This approach has the potential to efficiently solve partial differential equations (PDEs) using deep generative modeling."],"url":"http://arxiv.org/abs/2502.07636v1"}
{"created":"2025-02-11 15:23:05","title":"Distributed Value Decomposition Networks with Networked Agents","abstract":"We investigate the problem of distributed training under partial observability, whereby cooperative multi-agent reinforcement learning agents (MARL) maximize the expected cumulative joint reward. We propose distributed value decomposition networks (DVDN) that generate a joint Q-function that factorizes into agent-wise Q-functions. Whereas the original value decomposition networks rely on centralized training, our approach is suitable for domains where centralized training is not possible and agents must learn by interacting with the physical environment in a decentralized manner while communicating with their peers. DVDN overcomes the need for centralized training by locally estimating the shared objective. We contribute with two innovative algorithms, DVDN and DVDN (GT), for the heterogeneous and homogeneous agents settings respectively. Empirically, both algorithms approximate the performance of value decomposition networks, in spite of the information loss during communication, as demonstrated in ten MARL tasks in three standard environments.","sentences":["We investigate the problem of distributed training under partial observability, whereby cooperative multi-agent reinforcement learning agents (MARL) maximize the expected cumulative joint reward.","We propose distributed value decomposition networks (DVDN) that generate a joint Q-function that factorizes into agent-wise Q-functions.","Whereas the original value decomposition networks rely on centralized training, our approach is suitable for domains where centralized training is not possible and agents must learn by interacting with the physical environment in a decentralized manner while communicating with their peers.","DVDN overcomes the need for centralized training by locally estimating the shared objective.","We contribute with two innovative algorithms, DVDN and DVDN (GT), for the heterogeneous and homogeneous agents settings respectively.","Empirically, both algorithms approximate the performance of value decomposition networks, in spite of the information loss during communication, as demonstrated in ten MARL tasks in three standard environments."],"url":"http://arxiv.org/abs/2502.07635v1"}
{"created":"2025-02-11 15:21:31","title":"Divide and Merge: Motion and Semantic Learning in End-to-End Autonomous Driving","abstract":"Perceiving the environment and its changes over time corresponds to two fundamental yet heterogeneous types of information: semantics and motion. Previous end-to-end autonomous driving works represent both types of information in a single feature vector. However, including motion tasks, such as prediction and planning, always impairs detection and tracking performance, a phenomenon known as negative transfer in multi-task learning. To address this issue, we propose Neural-Bayes motion decoding, a novel parallel detection, tracking, and prediction method separating semantic and motion learning, similar to the Bayes filter. Specifically, we employ a set of learned motion queries that operate in parallel with the detection and tracking queries, sharing a unified set of recursively updated reference points. Moreover, we employ interactive semantic decoding to enhance information exchange in semantic tasks, promoting positive transfer. Experiments on the nuScenes dataset show improvements of 5% in detection and 11% in tracking. Our method achieves state-of-the-art collision rates in open-loop planning evaluation without any modifications to the planning module.","sentences":["Perceiving the environment and its changes over time corresponds to two fundamental yet heterogeneous types of information: semantics and motion.","Previous end-to-end autonomous driving works represent both types of information in a single feature vector.","However, including motion tasks, such as prediction and planning, always impairs detection and tracking performance, a phenomenon known as negative transfer in multi-task learning.","To address this issue, we propose Neural-Bayes motion decoding, a novel parallel detection, tracking, and prediction method separating semantic and motion learning, similar to the Bayes filter.","Specifically, we employ a set of learned motion queries that operate in parallel with the detection and tracking queries, sharing a unified set of recursively updated reference points.","Moreover, we employ interactive semantic decoding to enhance information exchange in semantic tasks, promoting positive transfer.","Experiments on the nuScenes dataset show improvements of 5% in detection and 11% in tracking.","Our method achieves state-of-the-art collision rates in open-loop planning evaluation without any modifications to the planning module."],"url":"http://arxiv.org/abs/2502.07631v1"}
{"created":"2025-02-11 15:17:00","title":"Exploring Mobile Touch Interaction with Large Language Models","abstract":"Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface. In this paper, we propose to control the LLM via touch gestures performed directly on the text. We first chart a design space that covers fundamental touch input and text transformations. In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops. We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator. The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation. This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices.","sentences":["Interacting with Large Language Models (LLMs) for text editing on mobile devices currently requires users to break out of their writing environment and switch to a conversational AI interface.","In this paper, we propose to control the LLM via touch gestures performed directly on the text.","We first chart a design space that covers fundamental touch input and text transformations.","In this space, we then concretely explore two control mappings: spread-to-generate and pinch-to-shorten, with visual feedback loops.","We evaluate this concept in a user study (N=14) that compares three feedback designs: no visualisation, text length indicator, and length + word indicator.","The results demonstrate that touch-based control of LLMs is both feasible and user-friendly, with the length + word indicator proving most effective for managing text generation.","This work lays the foundation for further research into gesture-based interaction with LLMs on touch devices."],"url":"http://arxiv.org/abs/2502.07629v1"}
{"created":"2025-02-11 15:16:58","title":"HarmonyCut: Supporting Creative Chinese Paper-cutting Design with Form and Connotation Harmony","abstract":"Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements. While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users' and models' lack of comprehensive paper-cutting knowledge. To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern). We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas. This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design. A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation.","sentences":["Chinese paper-cutting, an Intangible Cultural Heritage (ICH), faces challenges from the erosion of traditional culture due to the prevalence of realism alongside limited public access to cultural elements.","While generative AI can enhance paper-cutting design with its extensive knowledge base and efficient production capabilities, it often struggles to align content with cultural meaning due to users' and models' lack of comprehensive paper-cutting knowledge.","To address these issues, we conducted a formative study (N=7) to identify the workflow and design space, including four core factors (Function, Subject Matter, Style, and Method of Expression) and a key element (Pattern).","We then developed HarmonyCut, a generative AI-based tool that translates abstract intentions into creative and structured ideas.","This tool facilitates the exploration of suggested related content (knowledge, works, and patterns), enabling users to select, combine, and adjust elements for creative paper-cutting design.","A user study (N=16) and an expert evaluation (N=3) demonstrated that HarmonyCut effectively provided relevant knowledge, aiding the ideation of diverse paper-cutting designs and maintaining design quality within the design space to ensure alignment between form and cultural connotation."],"url":"http://arxiv.org/abs/2502.07628v1"}
{"created":"2025-02-11 15:10:23","title":"Lexical categories of stem-forming roots in Mapud\u00fcngun verb forms","abstract":"After developing a computational system for morphological analysis of the Mapuche language, and evaluating it with texts from various authors and styles, it became necessary to verify the linguistic assumptions of the source used as the basis for implementing this tool.   In the present work, the primary focus is on the lexical category classification of Mapud\\\"ungun roots recognised as verbal in the source utilised for the development of the morphological analysis system.   The results of this lexical category revision directly benefit the computational analyser, as they are implemented as soon as they are verified. Additionally, it is hoped that these results will help clarify some uncertainties about lexical categories in the Mapuche language.   This work addresses a preliminary task to identify the valency of true verbal roots, the results of which will be presented in a subsequent work that complements this article.","sentences":["After developing a computational system for morphological analysis of the Mapuche language, and evaluating it with texts from various authors and styles, it became necessary to verify the linguistic assumptions of the source used as the basis for implementing this tool.   ","In the present work, the primary focus is on the lexical category classification of Mapud\\\"ungun roots recognised as verbal in the source utilised for the development of the morphological analysis system.   ","The results of this lexical category revision directly benefit the computational analyser, as they are implemented as soon as they are verified.","Additionally, it is hoped that these results will help clarify some uncertainties about lexical categories in the Mapuche language.   ","This work addresses a preliminary task to identify the valency of true verbal roots, the results of which will be presented in a subsequent work that complements this article."],"url":"http://arxiv.org/abs/2502.07623v1"}
{"created":"2025-02-11 15:09:05","title":"Causal-Informed Contrastive Learning: Towards Bias-Resilient Pre-training under Concept Drift","abstract":"The evolution of large-scale contrastive pre-training propelled by top-tier datasets has reached a transition point in the scaling law. Consequently, sustaining and enhancing a model's pre-training capabilities in drift environments have surfaced as a notable challenge. In this paper, we initially uncover that contrastive pre-training methods are significantly impacted by concept drift wherein distributions change unpredictably, resulting in notable biases in the feature space of the pre-trained model. Empowered by causal inference, we construct a structural causal graph to analyze the impact of concept drift to contrastive pre-training systemically, and propose the causal interventional contrastive objective. Upon achieving this, we devise a resilient contrastive pre-training approach to accommodate the data stream of concept drift, with simple and scalable implementation. Extensive experiments on various downstream tasks demonstrate our resilient contrastive pre-training effectively mitigates the bias stemming from the concept drift data stream. Codes are available at https://anonymous.4open.science/r/ResilientCL/.","sentences":["The evolution of large-scale contrastive pre-training propelled by top-tier datasets has reached a transition point in the scaling law.","Consequently, sustaining and enhancing a model's pre-training capabilities in drift environments have surfaced as a notable challenge.","In this paper, we initially uncover that contrastive pre-training methods are significantly impacted by concept drift wherein distributions change unpredictably, resulting in notable biases in the feature space of the pre-trained model.","Empowered by causal inference, we construct a structural causal graph to analyze the impact of concept drift to contrastive pre-training systemically, and propose the causal interventional contrastive objective.","Upon achieving this, we devise a resilient contrastive pre-training approach to accommodate the data stream of concept drift, with simple and scalable implementation.","Extensive experiments on various downstream tasks demonstrate our resilient contrastive pre-training effectively mitigates the bias stemming from the concept drift data stream.","Codes are available at https://anonymous.4open.science/r/ResilientCL/."],"url":"http://arxiv.org/abs/2502.07620v1"}
{"created":"2025-02-11 15:05:33","title":"Scaling Pre-training to One Hundred Billion Data for Vision Language Models","abstract":"We provide an empirical investigation of the potential of pre-training vision-language models on an unprecedented scale: 100 billion examples. We find that model performance tends to saturate at this scale on many common Western-centric classification and retrieval benchmarks, such as COCO Captions. Nevertheless, tasks of cultural diversity achieve more substantial gains from the 100-billion scale web data, thanks to its coverage of long-tail concepts. Furthermore, we analyze the model's multilinguality and show gains in low-resource languages as well. In addition, we observe that reducing the size of the pretraining dataset via quality filters like using CLIP, typically used to enhance performance, may inadvertently reduce the cultural diversity represented even in large-scale datasets. Our results highlight that while traditional benchmarks may not benefit significantly from scaling noisy, raw web data to 100 billion examples, this data scale is vital for building truly inclusive multimodal systems.","sentences":["We provide an empirical investigation of the potential of pre-training vision-language models on an unprecedented scale: 100 billion examples.","We find that model performance tends to saturate at this scale on many common Western-centric classification and retrieval benchmarks, such as COCO Captions.","Nevertheless, tasks of cultural diversity achieve more substantial gains from the 100-billion scale web data, thanks to its coverage of long-tail concepts.","Furthermore, we analyze the model's multilinguality and show gains in low-resource languages as well.","In addition, we observe that reducing the size of the pretraining dataset via quality filters like using CLIP, typically used to enhance performance, may inadvertently reduce the cultural diversity represented even in large-scale datasets.","Our results highlight that while traditional benchmarks may not benefit significantly from scaling noisy, raw web data to 100 billion examples, this data scale is vital for building truly inclusive multimodal systems."],"url":"http://arxiv.org/abs/2502.07617v1"}
{"created":"2025-02-11 15:05:26","title":"Flow Distillation Sampling: Regularizing 3D Gaussians with Pre-trained Matching Priors","abstract":"3D Gaussian Splatting (3DGS) has achieved excellent rendering quality with fast training and rendering speed. However, its optimization process lacks explicit geometric constraints, leading to suboptimal geometric reconstruction in regions with sparse or no observational input views. In this work, we try to mitigate the issue by incorporating a pre-trained matching prior to the 3DGS optimization process. We introduce Flow Distillation Sampling (FDS), a technique that leverages pre-trained geometric knowledge to bolster the accuracy of the Gaussian radiance field. Our method employs a strategic sampling technique to target unobserved views adjacent to the input views, utilizing the optical flow calculated from the matching model (Prior Flow) to guide the flow analytically calculated from the 3DGS geometry (Radiance Flow). Comprehensive experiments in depth rendering, mesh reconstruction, and novel view synthesis showcase the significant advantages of FDS over state-of-the-art methods. Additionally, our interpretive experiments and analysis aim to shed light on the effects of FDS on geometric accuracy and rendering quality, potentially providing readers with insights into its performance. Project page: https://nju-3dv.github.io/projects/fds","sentences":["3D Gaussian Splatting (3DGS) has achieved excellent rendering quality with fast training and rendering speed.","However, its optimization process lacks explicit geometric constraints, leading to suboptimal geometric reconstruction in regions with sparse or no observational input views.","In this work, we try to mitigate the issue by incorporating a pre-trained matching prior to the 3DGS optimization process.","We introduce Flow Distillation Sampling (FDS), a technique that leverages pre-trained geometric knowledge to bolster the accuracy of the Gaussian radiance field.","Our method employs a strategic sampling technique to target unobserved views adjacent to the input views, utilizing the optical flow calculated from the matching model (Prior Flow) to guide the flow analytically calculated from the 3DGS geometry (Radiance Flow).","Comprehensive experiments in depth rendering, mesh reconstruction, and novel view synthesis showcase the significant advantages of FDS over state-of-the-art methods.","Additionally, our interpretive experiments and analysis aim to shed light on the effects of FDS on geometric accuracy and rendering quality, potentially providing readers with insights into its performance.","Project page: https://nju-3dv.github.io/projects/fds"],"url":"http://arxiv.org/abs/2502.07615v1"}
{"created":"2025-02-11 15:05:26","title":"Tractable Transformers for Flexible Conditional Generation","abstract":"Non-autoregressive (NAR) generative models are valuable because they can handle diverse conditional generation tasks in a more principled way than their autoregressive (AR) counterparts, which are constrained by sequential dependency requirements. Recent advancements in NAR models, such as diffusion language models, have demonstrated superior performance in unconditional generation compared to AR models (e.g., GPTs) of similar sizes. However, such improvements do not always lead to improved conditional generation performance. We show that a key reason for this gap is the difficulty in generalizing to conditional probability queries unseen during training. As a result, strong unconditional generation performance does not guarantee high-quality conditional generation. This paper proposes Tractable Transformers (Tracformer), a Transformer-based generative model that is more robust to different conditional generation tasks. Unlike existing models that rely solely on global contextual features derived from full inputs, Tracformers incorporate a sparse Transformer encoder to capture both local and global contextual information. This information is routed through a decoder for conditional generation. Empirical results demonstrate that Tracformers achieve state-of-the-art conditional generation performance on text modeling compared to recent diffusion and AR model baselines.","sentences":["Non-autoregressive (NAR) generative models are valuable because they can handle diverse conditional generation tasks in a more principled way than their autoregressive (AR) counterparts, which are constrained by sequential dependency requirements.","Recent advancements in NAR models, such as diffusion language models, have demonstrated superior performance in unconditional generation compared to AR models (e.g., GPTs) of similar sizes.","However, such improvements do not always lead to improved conditional generation performance.","We show that a key reason for this gap is the difficulty in generalizing to conditional probability queries unseen during training.","As a result, strong unconditional generation performance does not guarantee high-quality conditional generation.","This paper proposes Tractable Transformers (Tracformer), a Transformer-based generative model that is more robust to different conditional generation tasks.","Unlike existing models that rely solely on global contextual features derived from full inputs, Tracformers incorporate a sparse Transformer encoder to capture both local and global contextual information.","This information is routed through a decoder for conditional generation.","Empirical results demonstrate that Tracformers achieve state-of-the-art conditional generation performance on text modeling compared to recent diffusion and AR model baselines."],"url":"http://arxiv.org/abs/2502.07616v1"}
{"created":"2025-02-11 15:02:19","title":"Optimizing Datasets for Code Summarization: Is Code-Comment Coherence Enough?","abstract":"Automated code summarization is a long-standing goal for code comprehension. This task automatically generates documentation using a given method. Deep Learning (DL)-based approaches have been proven beneficial for various software engineering (SE) tasks, including this one. Most state-of-the-art datasets for code summarization are automatically mined from GitHub and, thus, might contain erroneous or sub-optimal examples. Previous work showed that using a simple rule-based approach for removing noisy instances allows for a tangible reduction of the training set size while not reducing the effectiveness of the trained models. Motivated by this finding, we conjecture that it is possible to further reduce the dataset size by removing instances that contain different issues. In this paper, we explore the extent to which code-comment coherence, a specific quality attribute of code summaries, can be used to optimize code summarization datasets. Specifically, we hypothesize that removing incoherent code-comment pairs might positively impact the effectiveness of the models. To do this, we rely on SIDE, a recently introduced metric for code-summary coherence. We examine multiple selectivity levels of training instances from two state-of-the-art datasets (TL-CodeSum and Funcom) and evaluate the resulting models on three manually curated test sets. The results show that even halving the training set sizes does not significantly affect the model's ability to generate summaries. However, when comparing the most restrictive selection strategy with a simpler one that randomly selects the training instances, we observe that the resulting accuracy of the model also does not change. This result suggests that (i) current datasets contain many irrelevant examples, and (ii) different quality attributes should be explored for optimizing code summarization datasets.","sentences":["Automated code summarization is a long-standing goal for code comprehension.","This task automatically generates documentation using a given method.","Deep Learning (DL)-based approaches have been proven beneficial for various software engineering (SE) tasks, including this one.","Most state-of-the-art datasets for code summarization are automatically mined from GitHub and, thus, might contain erroneous or sub-optimal examples.","Previous work showed that using a simple rule-based approach for removing noisy instances allows for a tangible reduction of the training set size while not reducing the effectiveness of the trained models.","Motivated by this finding, we conjecture that it is possible to further reduce the dataset size by removing instances that contain different issues.","In this paper, we explore the extent to which code-comment coherence, a specific quality attribute of code summaries, can be used to optimize code summarization datasets.","Specifically, we hypothesize that removing incoherent code-comment pairs might positively impact the effectiveness of the models.","To do this, we rely on SIDE, a recently introduced metric for code-summary coherence.","We examine multiple selectivity levels of training instances from two state-of-the-art datasets (TL-CodeSum and Funcom) and evaluate the resulting models on three manually curated test sets.","The results show that even halving the training set sizes does not significantly affect the model's ability to generate summaries.","However, when comparing the most restrictive selection strategy with a simpler one that randomly selects the training instances, we observe that the resulting accuracy of the model also does not change.","This result suggests that (i) current datasets contain many irrelevant examples, and (ii) different quality attributes should be explored for optimizing code summarization datasets."],"url":"http://arxiv.org/abs/2502.07611v1"}
{"created":"2025-02-11 14:58:54","title":"Beyond Prompting: Time2Lang -- Bridging Time-Series Foundation Models and Large Language Models for Health Sensing","abstract":"Large language models (LLMs) show promise for health applications when combined with behavioral sensing data. Traditional approaches convert sensor data into text prompts, but this process is prone to errors, computationally expensive, and requires domain expertise. These challenges are particularly acute when processing extended time series data. While time series foundation models (TFMs) have recently emerged as powerful tools for learning representations from temporal data, bridging TFMs and LLMs remains challenging. Here, we present Time2Lang, a framework that directly maps TFM outputs to LLM representations without intermediate text conversion. Our approach first trains on synthetic data using periodicity prediction as a pretext task, followed by evaluation on mental health classification tasks. We validate Time2Lang on two longitudinal wearable and mobile sensing datasets: daily depression prediction using step count data (17,251 days from 256 participants) and flourishing classification based on conversation duration (46 participants over 10 weeks). Time2Lang maintains near constant inference times regardless of input length, unlike traditional prompting methods. The generated embeddings preserve essential time-series characteristics such as auto-correlation. Our results demonstrate that TFMs and LLMs can be effectively integrated while minimizing information loss and enabling performance transfer across these distinct modeling paradigms. To our knowledge, we are the first to integrate a TFM and an LLM for health, thus establishing a foundation for future research combining general-purpose large models for complex healthcare tasks.","sentences":["Large language models (LLMs) show promise for health applications when combined with behavioral sensing data.","Traditional approaches convert sensor data into text prompts, but this process is prone to errors, computationally expensive, and requires domain expertise.","These challenges are particularly acute when processing extended time series data.","While time series foundation models (TFMs) have recently emerged as powerful tools for learning representations from temporal data, bridging TFMs and LLMs remains challenging.","Here, we present Time2Lang, a framework that directly maps TFM outputs to LLM representations without intermediate text conversion.","Our approach first trains on synthetic data using periodicity prediction as a pretext task, followed by evaluation on mental health classification tasks.","We validate Time2Lang on two longitudinal wearable and mobile sensing datasets: daily depression prediction using step count data (17,251 days from 256 participants) and flourishing classification based on conversation duration (46 participants over 10 weeks).","Time2Lang maintains near constant inference times regardless of input length, unlike traditional prompting methods.","The generated embeddings preserve essential time-series characteristics such as auto-correlation.","Our results demonstrate that TFMs and LLMs can be effectively integrated while minimizing information loss and enabling performance transfer across these distinct modeling paradigms.","To our knowledge, we are the first to integrate a TFM and an LLM for health, thus establishing a foundation for future research combining general-purpose large models for complex healthcare tasks."],"url":"http://arxiv.org/abs/2502.07608v1"}
{"created":"2025-02-11 14:56:16","title":"Algorithmic Aspects of Strategic Trading","abstract":"Algorithmic trading in modern financial markets is widely acknowledged to exhibit strategic, game-theoretic behaviors whose complexity can be difficult to model. A recent series of papers (Chriss, 2024b,c,a, 2025) has made progress in the setting of trading for position building. Here parties wish to buy or sell a fixed number of shares in a fixed time period in the presence of both temporary and permanent market impact, resulting in exponentially large strategy spaces. While these papers primarily consider the existence and structural properties of equilibrium strategies, in this work we focus on the algorithmic aspects of the proposed model. We give an efficient algorithm for computing best responses, and show that while the temporary impact only setting yields a potential game, best response dynamics do not generally converge for the general setting, for which no fast algorithm for (Nash) equilibrium computation is known. This leads us to consider the broader notion of Coarse Correlated Equilibria (CCE), which we show can be computed efficiently via an implementation of Follow the Perturbed Leader (FTPL). We illustrate the model and our results with an experimental investigation, where FTPL exhibits interesting behavior in different regimes of the relative weighting between temporary and permanent market impact.","sentences":["Algorithmic trading in modern financial markets is widely acknowledged to exhibit strategic, game-theoretic behaviors whose complexity can be difficult to model.","A recent series of papers (Chriss, 2024b,c,a, 2025) has made progress in the setting of trading for position building.","Here parties wish to buy or sell a fixed number of shares in a fixed time period in the presence of both temporary and permanent market impact, resulting in exponentially large strategy spaces.","While these papers primarily consider the existence and structural properties of equilibrium strategies, in this work we focus on the algorithmic aspects of the proposed model.","We give an efficient algorithm for computing best responses, and show that while the temporary impact only setting yields a potential game, best response dynamics do not generally converge for the general setting, for which no fast algorithm for (Nash) equilibrium computation is known.","This leads us to consider the broader notion of Coarse Correlated Equilibria (CCE), which we show can be computed efficiently via an implementation of Follow the Perturbed Leader (FTPL).","We illustrate the model and our results with an experimental investigation, where FTPL exhibits interesting behavior in different regimes of the relative weighting between temporary and permanent market impact."],"url":"http://arxiv.org/abs/2502.07606v1"}
{"created":"2025-02-11 14:52:11","title":"An Improved Optimal Proximal Gradient Algorithm for Non-Blind Image Deblurring","abstract":"Image deblurring remains a central research area within image processing, critical for its role in enhancing image quality and facilitating clearer visual representations across diverse applications. This paper tackles the optimization problem of image deblurring, assuming a known blurring kernel. We introduce an improved optimal proximal gradient algorithm (IOptISTA), which builds upon the optimal gradient method and a weighting matrix, to efficiently address the non-blind image deblurring problem. Based on two regularization cases, namely the $l_1$ norm and total variation norm, we perform numerical experiments to assess the performance of our proposed algorithm. The results indicate that our algorithm yields enhanced PSNR and SSIM values, as well as a reduced tolerance, compared to existing methods.","sentences":["Image deblurring remains a central research area within image processing, critical for its role in enhancing image quality and facilitating clearer visual representations across diverse applications.","This paper tackles the optimization problem of image deblurring, assuming a known blurring kernel.","We introduce an improved optimal proximal gradient algorithm (IOptISTA), which builds upon the optimal gradient method and a weighting matrix, to efficiently address the non-blind image deblurring problem.","Based on two regularization cases, namely the $l_1$ norm and total variation norm, we perform numerical experiments to assess the performance of our proposed algorithm.","The results indicate that our algorithm yields enhanced PSNR and SSIM values, as well as a reduced tolerance, compared to existing methods."],"url":"http://arxiv.org/abs/2502.07602v1"}
{"created":"2025-02-11 14:50:43","title":"Towards Zero-Shot Anomaly Detection and Reasoning with Multimodal Large Language Models","abstract":"Zero-Shot Anomaly Detection (ZSAD) is an emerging AD paradigm. Unlike the traditional unsupervised AD setting that requires a large number of normal samples to train a model, ZSAD is more practical for handling data-restricted real-world scenarios. Recently, Multimodal Large Language Models (MLLMs) have shown revolutionary reasoning capabilities in various vision tasks. However, the reasoning of image abnormalities remains underexplored due to the lack of corresponding datasets and benchmarks. To facilitate research in AD & reasoning, we establish the first visual instruction tuning dataset, Anomaly-Instruct-125k, and the evaluation benchmark, VisA-D&R. Through investigation with our benchmark, we reveal that current MLLMs like GPT-4o cannot accurately detect and describe fine-grained anomalous details in images. To address this, we propose Anomaly-OneVision (Anomaly-OV), the first specialist visual assistant for ZSAD and reasoning. Inspired by human behavior in visual inspection, Anomaly-OV leverages a Look-Twice Feature Matching (LTFM) mechanism to adaptively select and emphasize abnormal visual tokens. Extensive experiments demonstrate that Anomaly-OV achieves significant improvements over advanced generalist models in both detection and reasoning. Extensions to medical and 3D AD are provided for future study. The link to our project page: https://xujiacong.github.io/Anomaly-OV/","sentences":["Zero-Shot Anomaly Detection (ZSAD) is an emerging AD paradigm.","Unlike the traditional unsupervised AD setting that requires a large number of normal samples to train a model, ZSAD is more practical for handling data-restricted real-world scenarios.","Recently, Multimodal Large Language Models (MLLMs) have shown revolutionary reasoning capabilities in various vision tasks.","However, the reasoning of image abnormalities remains underexplored due to the lack of corresponding datasets and benchmarks.","To facilitate research in AD & reasoning, we establish the first visual instruction tuning dataset, Anomaly-Instruct-125k, and the evaluation benchmark, VisA-D&R.","Through investigation with our benchmark, we reveal that current MLLMs like GPT-4o cannot accurately detect and describe fine-grained anomalous details in images.","To address this, we propose Anomaly-OneVision (Anomaly-OV), the first specialist visual assistant for ZSAD and reasoning.","Inspired by human behavior in visual inspection, Anomaly-OV leverages a Look-Twice Feature Matching (LTFM) mechanism to adaptively select and emphasize abnormal visual tokens.","Extensive experiments demonstrate that Anomaly-OV achieves significant improvements over advanced generalist models in both detection and reasoning.","Extensions to medical and 3D AD are provided for future study.","The link to our project page: https://xujiacong.github.io/Anomaly-OV/"],"url":"http://arxiv.org/abs/2502.07601v1"}
{"created":"2025-02-11 14:50:10","title":"PlaySlot: Learning Inverse Latent Dynamics for Controllable Object-Centric Video Prediction and Planning","abstract":"Predicting future scene representations is a crucial task for enabling robots to understand and interact with the environment. However, most existing methods rely on video sequences and simulations with precise action annotations, limiting their ability to leverage the large amount of available unlabeled video data. To address this challenge, we propose PlaySlot, an object-centric video prediction model that infers object representations and latent actions from unlabeled video sequences. It then uses these representations to forecast future object states and video frames. PlaySlot allows to generate multiple possible futures conditioned on latent actions, which can be inferred from video dynamics, provided by a user, or generated by a learned action policy, thus enabling versatile and interpretable world modeling. Our results show that PlaySlot outperforms both stochastic and object-centric baselines for video prediction across different environments. Furthermore, we show that our inferred latent actions can be used to learn robot behaviors sample-efficiently from unlabeled video demonstrations. Videos and code are available at https://play-slot.github.io/PlaySlot/.","sentences":["Predicting future scene representations is a crucial task for enabling robots to understand and interact with the environment.","However, most existing methods rely on video sequences and simulations with precise action annotations, limiting their ability to leverage the large amount of available unlabeled video data.","To address this challenge, we propose PlaySlot, an object-centric video prediction model that infers object representations and latent actions from unlabeled video sequences.","It then uses these representations to forecast future object states and video frames.","PlaySlot allows to generate multiple possible futures conditioned on latent actions, which can be inferred from video dynamics, provided by a user, or generated by a learned action policy, thus enabling versatile and interpretable world modeling.","Our results show that PlaySlot outperforms both stochastic and object-centric baselines for video prediction across different environments.","Furthermore, we show that our inferred latent actions can be used to learn robot behaviors sample-efficiently from unlabeled video demonstrations.","Videos and code are available at https://play-slot.github.io/PlaySlot/."],"url":"http://arxiv.org/abs/2502.07600v1"}
{"created":"2025-02-11 14:49:44","title":"DPO-Shift: Shifting the Distribution of Direct Preference Optimization","abstract":"Direct Preference Optimization (DPO) and its variants have become increasingly popular for aligning language models with human preferences. These methods aim to teach models to better distinguish between chosen (or preferred) and rejected (or dispreferred) responses. However, prior research has identified that the probability of chosen responses often decreases during training, and this phenomenon is known as likelihood displacement. To tackle this challenge, in this work we introduce \\method to controllably shift the distribution of the chosen probability. Then, we show that \\method exhibits a fundamental trade-off between improving the chosen probability and sacrificing the reward margin, as supported by both theoretical analysis and experimental validation. Furthermore, we demonstrate the superiority of \\method over DPO on downstream tasks such as MT-Bench and a designed win rate experiment. We believe this study shows that the likelihood displacement issue of DPO can be effectively mitigated with a simple, theoretically grounded solution. Our code is available at https://github.com/Meaquadddd/DPO-Shift.","sentences":["Direct Preference Optimization (DPO) and its variants have become increasingly popular for aligning language models with human preferences.","These methods aim to teach models to better distinguish between chosen (or preferred) and rejected (or dispreferred) responses.","However, prior research has identified that the probability of chosen responses often decreases during training, and this phenomenon is known as likelihood displacement.","To tackle this challenge, in this work we introduce \\method to controllably shift the distribution of the chosen probability.","Then, we show that \\method exhibits a fundamental trade-off between improving the chosen probability and sacrificing the reward margin, as supported by both theoretical analysis and experimental validation.","Furthermore, we demonstrate the superiority of \\method over DPO on downstream tasks such as MT-Bench and a designed win rate experiment.","We believe this study shows that the likelihood displacement issue of DPO can be effectively mitigated with a simple, theoretically grounded solution.","Our code is available at https://github.com/Meaquadddd/DPO-Shift."],"url":"http://arxiv.org/abs/2502.07599v1"}
{"created":"2025-02-11 14:47:32","title":"Towards spatial computing: recent advances in multimodal natural interaction for XR headsets","abstract":"With the widespread adoption of Extended Reality (XR) headsets, spatial computing technologies are gaining increasing attention. Spatial computing enables interaction with virtual elements through natural input methods such as eye tracking, hand gestures, and voice commands, thus placing natural human-computer interaction at its core. While previous surveys have reviewed conventional XR interaction techniques, recent advancements in natural interaction, particularly driven by artificial intelligence (AI) and large language models (LLMs), have introduced new paradigms and technologies. In this paper, we review research on multimodal natural interaction for wearable XR, focusing on papers published between 2022 and 2024 in six top venues: ACM CHI, UIST, IMWUT (Ubicomp), IEEE VR, ISMAR, and TVCG. We classify and analyze these studies based on application scenarios, operation types, and interaction modalities. This analysis provides a structured framework for understanding how researchers are designing advanced natural interaction techniques in XR. Based on these findings, we discuss the challenges in natural interaction techniques and suggest potential directions for future research. This review provides valuable insights for researchers aiming to design natural and efficient interaction systems for XR, ultimately contributing to the advancement of spatial computing.","sentences":["With the widespread adoption of Extended Reality (XR) headsets, spatial computing technologies are gaining increasing attention.","Spatial computing enables interaction with virtual elements through natural input methods such as eye tracking, hand gestures, and voice commands, thus placing natural human-computer interaction at its core.","While previous surveys have reviewed conventional XR interaction techniques, recent advancements in natural interaction, particularly driven by artificial intelligence (AI) and large language models (LLMs), have introduced new paradigms and technologies.","In this paper, we review research on multimodal natural interaction for wearable XR, focusing on papers published between 2022 and 2024 in six top venues: ACM CHI, UIST, IMWUT (Ubicomp), IEEE VR, ISMAR, and TVCG.","We classify and analyze these studies based on application scenarios, operation types, and interaction modalities.","This analysis provides a structured framework for understanding how researchers are designing advanced natural interaction techniques in XR.","Based on these findings, we discuss the challenges in natural interaction techniques and suggest potential directions for future research.","This review provides valuable insights for researchers aiming to design natural and efficient interaction systems for XR, ultimately contributing to the advancement of spatial computing."],"url":"http://arxiv.org/abs/2502.07598v1"}
{"created":"2025-02-11 14:45:17","title":"Distributed Coverage Control for Time-Varying Spatial Processes","abstract":"Multi-robot systems are essential for environmental monitoring, particularly for tracking spatial phenomena like pollution, soil minerals, and water salinity, and more. This study addresses the challenge of deploying a multi-robot team for optimal coverage in environments where the density distribution, describing areas of interest, is unknown and changes over time. We propose a fully distributed control strategy that uses Gaussian Processes (GPs) to model the spatial field and balance the trade-off between learning the field and optimally covering it. Unlike existing approaches, we address a more realistic scenario by handling time-varying spatial fields, where the exploration-exploitation trade-off is dynamically adjusted over time. Each robot operates locally, using only its own collected data and the information shared by the neighboring robots. To address the computational limits of GPs, the algorithm efficiently manages the volume of data by selecting only the most relevant samples for the process estimation. The performance of the proposed algorithm is evaluated through several simulations and experiments, incorporating real-world data phenomena to validate its effectiveness.","sentences":["Multi-robot systems are essential for environmental monitoring, particularly for tracking spatial phenomena like pollution, soil minerals, and water salinity, and more.","This study addresses the challenge of deploying a multi-robot team for optimal coverage in environments where the density distribution, describing areas of interest, is unknown and changes over time.","We propose a fully distributed control strategy that uses Gaussian Processes (GPs) to model the spatial field and balance the trade-off between learning the field and optimally covering it.","Unlike existing approaches, we address a more realistic scenario by handling time-varying spatial fields, where the exploration-exploitation trade-off is dynamically adjusted over time.","Each robot operates locally, using only its own collected data and the information shared by the neighboring robots.","To address the computational limits of GPs, the algorithm efficiently manages the volume of data by selecting only the most relevant samples for the process estimation.","The performance of the proposed algorithm is evaluated through several simulations and experiments, incorporating real-world data phenomena to validate its effectiveness."],"url":"http://arxiv.org/abs/2502.07595v1"}
{"created":"2025-02-11 14:44:51","title":"Distributed Non-Interactive Zero-Knowledge Proofs","abstract":"Distributed certification is a set of mechanisms that allows an all-knowing prover to convince the units of a communication network that the network's state has some desired property, such as being 3-colorable or triangle-free. Classical mechanisms, such as proof labeling schemes (PLS), consist of a message from the prover to each unit, followed by one round of communication between each unit and its neighbors. Later works consider extensions, called distributed interactive proofs, where the prover and the units can have multiple rounds of communication before the communication among the units.   Recently, Bick, Kol, and Oshman (SODA '22) defined a zero-knowledge version of distributed interactive proofs, where the prover convinces the units of the network's state without revealing any other information about the network's state or structure. In their work, they propose different variants of this model and show that many graph properties of interest can be certified with them.   In this work, we define and study distributed non-interactive zero-knowledge proofs (dNIZK); these can be seen as a non-interactive version of the aforementioned model, and also as a zero-knowledge version of PLS. We prove the following:   - There exists a dNIZK protocol for 3-coloring with O(log n)-bit messages from the prover and O(log n)-size messages among neighbors.   - There exists a family of dNIZK protocols for triangle-freeness, that presents a trade-off between the size of the messages from the prover and the size of the messages among neighbors.   - There exists a dNIZK protocol for any graph property in NP in the random oracle models, which is secure against an arbitrary number of malicious parties.","sentences":["Distributed certification is a set of mechanisms that allows an all-knowing prover to convince the units of a communication network that the network's state has some desired property, such as being 3-colorable or triangle-free.","Classical mechanisms, such as proof labeling schemes (PLS), consist of a message from the prover to each unit, followed by one round of communication between each unit and its neighbors.","Later works consider extensions, called distributed interactive proofs, where the prover and the units can have multiple rounds of communication before the communication among the units.   ","Recently, Bick, Kol, and Oshman (SODA '22) defined a zero-knowledge version of distributed interactive proofs, where the prover convinces the units of the network's state without revealing any other information about the network's state or structure.","In their work, they propose different variants of this model and show that many graph properties of interest can be certified with them.   ","In this work, we define and study distributed non-interactive zero-knowledge proofs (dNIZK); these can be seen as a non-interactive version of the aforementioned model, and also as a zero-knowledge version of PLS.","We prove the following:   - There exists a dNIZK protocol for 3-coloring with O(log n)-bit messages from the prover and O(log n)-size messages among neighbors.   ","- There exists a family of dNIZK protocols for triangle-freeness, that presents a trade-off between the size of the messages from the prover and the size of the messages among neighbors.   ","- There exists a dNIZK protocol for any graph property in NP in the random oracle models, which is secure against an arbitrary number of malicious parties."],"url":"http://arxiv.org/abs/2502.07594v1"}
{"created":"2025-02-11 14:44:32","title":"Decision-Making Under Complete Uncertainty: You Will Regret Not Being Greedy","abstract":"In this paper, we propose a probabilistic game-theoretic model to study the properties of the worst-case regret of the greedy strategy under complete (Knightian) uncertainty. In a game between a decision-maker (DM) and an adversarial agent (Nature), the DM observes a realization of product ratings for each product. Upon observation, the DM chooses a strategy, which is a function from the set of observations to the set of products. We study the theoretical properties, including the worst-case regret of the greedy strategy that chooses the product with the highest observed average rating. We prove that, with respect to the worst-case regret, the greedy strategy is optimal and that, in the limit, the regret of the greedy strategy converges to zero. We validate the model on data collected from Google reviews for restaurants, showing that the greedy strategy not only performs according to the theoretical findings but also outperforms the uniform strategy and the Thompson Sampling algorithm.","sentences":["In this paper, we propose a probabilistic game-theoretic model to study the properties of the worst-case regret of the greedy strategy under complete (Knightian) uncertainty.","In a game between a decision-maker (DM) and an adversarial agent (Nature), the DM observes a realization of product ratings for each product.","Upon observation, the DM chooses a strategy, which is a function from the set of observations to the set of products.","We study the theoretical properties, including the worst-case regret of the greedy strategy that chooses the product with the highest observed average rating.","We prove that, with respect to the worst-case regret, the greedy strategy is optimal and that, in the limit, the regret of the greedy strategy converges to zero.","We validate the model on data collected from Google reviews for restaurants, showing that the greedy strategy not only performs according to the theoretical findings but also outperforms the uniform strategy and the Thompson Sampling algorithm."],"url":"http://arxiv.org/abs/2502.07593v1"}
{"created":"2025-02-11 14:41:30","title":"YOLO Network For Defect Detection In Optical lenses","abstract":"Mass-produced optical lenses often exhibit defects that alter their scattering properties and compromise quality standards. Manual inspection is usually adopted to detect defects, but it is not recommended due to low accuracy, high error rate and limited scalability. To address these challenges, this study presents an automated defect detection system based on the YOLOv8 deep learning model. A custom dataset of optical lenses, annotated with defect and lens regions, was created to train the model. Experimental results obtained in this study reveal that the system can be used to efficiently and accurately detect defects in optical lenses. The proposed system can be utilized in real-time industrial environments to enhance quality control processes by enabling reliable and scalable defect detection in optical lens manufacturing.","sentences":["Mass-produced optical lenses often exhibit defects that alter their scattering properties and compromise quality standards.","Manual inspection is usually adopted to detect defects, but it is not recommended due to low accuracy, high error rate and limited scalability.","To address these challenges, this study presents an automated defect detection system based on the YOLOv8 deep learning model.","A custom dataset of optical lenses, annotated with defect and lens regions, was created to train the model.","Experimental results obtained in this study reveal that the system can be used to efficiently and accurately detect defects in optical lenses.","The proposed system can be utilized in real-time industrial environments to enhance quality control processes by enabling reliable and scalable defect detection in optical lens manufacturing."],"url":"http://arxiv.org/abs/2502.07592v1"}
{"created":"2025-02-11 14:40:57","title":"DMWM: Dual-Mind World Model with Long-Term Imagination","abstract":"Imagination in world models is crucial for enabling agents to learn long-horizon policy in a sample-efficient manner. Existing recurrent state-space model (RSSM)-based world models depend on single-step statistical inference to capture the environment dynamics, and, hence, they are unable to perform long-term imagination tasks due to the accumulation of prediction errors. Inspired by the dual-process theory of human cognition, we propose a novel dual-mind world model (DMWM) framework that integrates logical reasoning to enable imagination with logical consistency. DMWM is composed of two components: an RSSM-based System 1 (RSSM-S1) component that handles state transitions in an intuitive manner and a logic-integrated neural network-based System 2 (LINN-S2) component that guides the imagination process through hierarchical deep logical reasoning. The inter-system feedback mechanism is designed to ensure that the imagination process follows the logical rules of the real environment. The proposed framework is evaluated on benchmark tasks that require long-term planning from the DMControl suite. Extensive experimental results demonstrate that the proposed framework yields significant improvements in terms of logical coherence, trial efficiency, data efficiency and long-term imagination over the state-of-the-art world models.","sentences":["Imagination in world models is crucial for enabling agents to learn long-horizon policy in a sample-efficient manner.","Existing recurrent state-space model (RSSM)-based world models depend on single-step statistical inference to capture the environment dynamics, and, hence, they are unable to perform long-term imagination tasks due to the accumulation of prediction errors.","Inspired by the dual-process theory of human cognition, we propose a novel dual-mind world model (DMWM) framework that integrates logical reasoning to enable imagination with logical consistency.","DMWM is composed of two components: an RSSM-based System 1 (RSSM-S1) component that handles state transitions in an intuitive manner and a logic-integrated neural network-based System 2 (LINN-S2) component that guides the imagination process through hierarchical deep logical reasoning.","The inter-system feedback mechanism is designed to ensure that the imagination process follows the logical rules of the real environment.","The proposed framework is evaluated on benchmark tasks that require long-term planning from the DMControl suite.","Extensive experimental results demonstrate that the proposed framework yields significant improvements in terms of logical coherence, trial efficiency, data efficiency and long-term imagination over the state-of-the-art world models."],"url":"http://arxiv.org/abs/2502.07591v1"}
{"created":"2025-02-11 14:39:59","title":"DSV: Exploiting Dynamic Sparsity to Accelerate Large-Scale Video DiT Training","abstract":"Diffusion Transformers (DiTs) have shown remarkable performance in modeling and generating high-quality videos. However, the quadratic computational complexity of 3D full attention mechanism presents significant challenges in scaling video DiT training, especially for high-definition and lengthy videos, where attention can dominate up to 95% of the end-to-end time and necessitate specialized communication paradigms to handle large input sizes.   This paper introduces DSV, a novel framework designed to accelerate and scale the training of video DiTs by leveraging the inherent dynamic attention sparsity throughout the training process. DSV employs a two-stage training algorithm that exploits sparsity patterns, focusing on critical elements supported by efficient, tailored kernels. To accommodate the new sparsity dimension, we develop a hybrid sparsity-aware context parallelism that effectively scales to large inputs by addressing the heterogeneity of sparsity across attention heads and blocks, resulting in optimized sparse computation and communication. Extensive evaluations demonstrate that DSV achieves up to 3.02x gain in training throughput with nearly no quality degradation.","sentences":["Diffusion Transformers (DiTs) have shown remarkable performance in modeling and generating high-quality videos.","However, the quadratic computational complexity of 3D full attention mechanism presents significant challenges in scaling video DiT training, especially for high-definition and lengthy videos, where attention can dominate up to 95% of the end-to-end time and necessitate specialized communication paradigms to handle large input sizes.   ","This paper introduces DSV, a novel framework designed to accelerate and scale the training of video DiTs by leveraging the inherent dynamic attention sparsity throughout the training process.","DSV employs a two-stage training algorithm that exploits sparsity patterns, focusing on critical elements supported by efficient, tailored kernels.","To accommodate the new sparsity dimension, we develop a hybrid sparsity-aware context parallelism that effectively scales to large inputs by addressing the heterogeneity of sparsity across attention heads and blocks, resulting in optimized sparse computation and communication.","Extensive evaluations demonstrate that DSV achieves up to 3.02x gain in training throughput with nearly no quality degradation."],"url":"http://arxiv.org/abs/2502.07590v1"}
{"created":"2025-02-11 14:36:39","title":"SEMU: Singular Value Decomposition for Efficient Machine Unlearning","abstract":"While the capabilities of generative foundational models have advanced rapidly in recent years, methods to prevent harmful and unsafe behaviors remain underdeveloped. Among the pressing challenges in AI safety, machine unlearning (MU) has become increasingly critical to meet upcoming safety regulations. Most existing MU approaches focus on altering the most significant parameters of the model. However, these methods often require fine-tuning substantial portions of the model, resulting in high computational costs and training instabilities, which are typically mitigated by access to the original training dataset.   In this work, we address these limitations by leveraging Singular Value Decomposition (SVD) to create a compact, low-dimensional projection that enables the selective forgetting of specific data points. We propose Singular Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach designed to optimize MU in two key aspects. First, SEMU minimizes the number of model parameters that need to be modified, effectively removing unwanted knowledge while making only minimal changes to the model's weights. Second, SEMU eliminates the dependency on the original training dataset, preserving the model's previously acquired knowledge without additional data requirements.   Extensive experiments demonstrate that SEMU achieves competitive performance while significantly improving efficiency in terms of both data usage and the number of modified parameters.","sentences":["While the capabilities of generative foundational models have advanced rapidly in recent years, methods to prevent harmful and unsafe behaviors remain underdeveloped.","Among the pressing challenges in AI safety, machine unlearning (MU) has become increasingly critical to meet upcoming safety regulations.","Most existing MU approaches focus on altering the most significant parameters of the model.","However, these methods often require fine-tuning substantial portions of the model, resulting in high computational costs and training instabilities, which are typically mitigated by access to the original training dataset.   ","In this work, we address these limitations by leveraging Singular Value Decomposition (SVD) to create a compact, low-dimensional projection that enables the selective forgetting of specific data points.","We propose Singular Value Decomposition for Efficient Machine Unlearning (SEMU), a novel approach designed to optimize MU in two key aspects.","First, SEMU minimizes the number of model parameters that need to be modified, effectively removing unwanted knowledge while making only minimal changes to the model's weights.","Second, SEMU eliminates the dependency on the original training dataset, preserving the model's previously acquired knowledge without additional data requirements.   ","Extensive experiments demonstrate that SEMU achieves competitive performance while significantly improving efficiency in terms of both data usage and the number of modified parameters."],"url":"http://arxiv.org/abs/2502.07587v1"}
{"created":"2025-02-11 14:34:05","title":"We Can't Understand AI Using our Existing Vocabulary","abstract":"This position paper argues that, in order to understand AI, we cannot rely on our existing vocabulary of human words. Instead, we should strive to develop neologisms: new words that represent precise human concepts that we want to teach machines, or machine concepts that we need to learn. We start from the premise that humans and machines have differing concepts. This means interpretability can be framed as a communication problem: humans must be able to reference and control machine concepts, and communicate human concepts to machines. Creating a shared human-machine language through developing neologisms, we believe, could solve this communication problem. Successful neologisms achieve a useful amount of abstraction: not too detailed, so they're reusable in many contexts, and not too high-level, so they convey precise information. As a proof of concept, we demonstrate how a \"length neologism\" enables controlling LLM response length, while a \"diversity neologism\" allows sampling more variable responses. Taken together, we argue that we cannot understand AI using our existing vocabulary, and expanding it through neologisms creates opportunities for both controlling and understanding machines better.","sentences":["This position paper argues that, in order to understand AI, we cannot rely on our existing vocabulary of human words.","Instead, we should strive to develop neologisms: new words that represent precise human concepts that we want to teach machines, or machine concepts that we need to learn.","We start from the premise that humans and machines have differing concepts.","This means interpretability can be framed as a communication problem: humans must be able to reference and control machine concepts, and communicate human concepts to machines.","Creating a shared human-machine language through developing neologisms, we believe, could solve this communication problem.","Successful neologisms achieve a useful amount of abstraction: not too detailed, so they're reusable in many contexts, and not too high-level, so they convey precise information.","As a proof of concept, we demonstrate how a \"length neologism\" enables controlling LLM response length, while a \"diversity neologism\" allows sampling more variable responses.","Taken together, we argue that we cannot understand AI using our existing vocabulary, and expanding it through neologisms creates opportunities for both controlling and understanding machines better."],"url":"http://arxiv.org/abs/2502.07586v1"}
