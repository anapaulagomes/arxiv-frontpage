{"created":"2024-10-28 17:59:35","title":"Enhancing Action Recognition by Leveraging the Hierarchical Structure of Actions and Textual Context","abstract":"The sequential execution of actions and their hierarchical structure consisting of different levels of abstraction, provide features that remain unexplored in the task of action recognition. In this study, we present a novel approach to improve action recognition by exploiting the hierarchical organization of actions and by incorporating contextualized textual information, including location and prior actions to reflect the sequential context. To achieve this goal, we introduce a novel transformer architecture tailored for action recognition that utilizes both visual and textual features. Visual features are obtained from RGB and optical flow data, while text embeddings represent contextual information. Furthermore, we define a joint loss function to simultaneously train the model for both coarse and fine-grained action recognition, thereby exploiting the hierarchical nature of actions. To demonstrate the effectiveness of our method, we extend the Toyota Smarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducing the Hierarchical TSU dataset. We also conduct an ablation study to assess the impact of different methods for integrating contextual and hierarchical data on action recognition performance. Results show that the proposed approach outperforms pre-trained SOTA methods when trained with the same hyperparameters. Moreover, they also show a 17.12% improvement in top-1 accuracy over the equivalent fine-grained RGB version when using ground-truth contextual information, and a 5.33% improvement when contextual information is obtained from actual predictions.","sentences":["The sequential execution of actions and their hierarchical structure consisting of different levels of abstraction, provide features that remain unexplored in the task of action recognition.","In this study, we present a novel approach to improve action recognition by exploiting the hierarchical organization of actions and by incorporating contextualized textual information, including location and prior actions to reflect the sequential context.","To achieve this goal, we introduce a novel transformer architecture tailored for action recognition that utilizes both visual and textual features.","Visual features are obtained from RGB and optical flow data, while text embeddings represent contextual information.","Furthermore, we define a joint loss function to simultaneously train the model for both coarse and fine-grained action recognition, thereby exploiting the hierarchical nature of actions.","To demonstrate the effectiveness of our method, we extend the Toyota Smarthome Untrimmed (TSU) dataset to introduce action hierarchies, introducing the Hierarchical TSU dataset.","We also conduct an ablation study to assess the impact of different methods for integrating contextual and hierarchical data on action recognition performance.","Results show that the proposed approach outperforms pre-trained SOTA methods when trained with the same hyperparameters.","Moreover, they also show a 17.12% improvement in top-1 accuracy over the equivalent fine-grained RGB version when using ground-truth contextual information, and a 5.33% improvement when contextual information is obtained from actual predictions."],"url":"http://arxiv.org/abs/2410.21275v1"}
{"created":"2024-10-28 17:59:30","title":"High-level hybridization of heuristics and metaheuristics to solve symmetric TSP: a comparative study","abstract":"The Travelling Salesman Problem - TSP is one of the most explored problems in the scientific literature to solve real problems regarding the economy, transportation, and logistics, to cite a few cases. Adapting TSP to solve different problems has originated several variants of the optimization problem with more complex objectives and different restrictions. Metaheuristics have been used to solve the problem in polynomial time. Several studies have tried hybridising metaheuristics with specialised heuristics to improve the quality of the solutions. However, we have found no study to evaluate whether the searching mechanism of a particular metaheuristic is more adequate for exploring hybridization. This paper focuses on the solution of the classical TSP using high-level hybridisations, experimenting with eight metaheuristics and heuristics derived from k-OPT, SISR, and segment intersection search, resulting in twenty-four combinations. Some combinations allow more than one set of searching parameters. Problems with 50 to 280 cities are solved. Parameter tuning of the metaheuristics is not carried out, exploiting the different searching patterns of the eight metaheuristics instead. The solutions' quality is compared to those presented in the literature.","sentences":["The Travelling Salesman Problem - TSP is one of the most explored problems in the scientific literature to solve real problems regarding the economy, transportation, and logistics, to cite a few cases.","Adapting TSP to solve different problems has originated several variants of the optimization problem with more complex objectives and different restrictions.","Metaheuristics have been used to solve the problem in polynomial time.","Several studies have tried hybridising metaheuristics with specialised heuristics to improve the quality of the solutions.","However, we have found no study to evaluate whether the searching mechanism of a particular metaheuristic is more adequate for exploring hybridization.","This paper focuses on the solution of the classical TSP using high-level hybridisations, experimenting with eight metaheuristics and heuristics derived from k-OPT, SISR, and segment intersection search, resulting in twenty-four combinations.","Some combinations allow more than one set of searching parameters.","Problems with 50 to 280 cities are solved.","Parameter tuning of the metaheuristics is not carried out, exploiting the different searching patterns of the eight metaheuristics instead.","The solutions' quality is compared to those presented in the literature."],"url":"http://arxiv.org/abs/2410.21274v1"}
{"created":"2024-10-28 17:59:13","title":"On Inductive Biases That Enable Generalization of Diffusion Transformers","abstract":"Recent work studying the generalization of diffusion models with UNet-based denoisers reveals inductive biases that can be expressed via geometry-adaptive harmonic bases. However, in practice, more recent denoising networks are often based on transformers, e.g., the diffusion transformer (DiT). This raises the question: do transformer-based denoising networks exhibit inductive biases that can also be expressed via geometry-adaptive harmonic bases? To our surprise, we find that this is not the case. This discrepancy motivates our search for the inductive bias that can lead to good generalization in DiT models. Investigating the pivotal attention modules of a DiT, we find that locality of attention maps are closely associated with generalization. To verify this finding, we modify the generalization of a DiT by restricting its attention windows. We inject local attention windows to a DiT and observe an improvement in generalization. Furthermore, we empirically find that both the placement and the effective attention size of these local attention windows are crucial factors. Experimental results on the CelebA, ImageNet, and LSUN datasets show that strengthening the inductive bias of a DiT can improve both generalization and generation quality when less training data is available. Source code will be released publicly upon paper publication. Project page: dit-generalization.github.io/.","sentences":["Recent work studying the generalization of diffusion models with UNet-based denoisers reveals inductive biases that can be expressed via geometry-adaptive harmonic bases.","However, in practice, more recent denoising networks are often based on transformers, e.g., the diffusion transformer (DiT).","This raises the question: do transformer-based denoising networks exhibit inductive biases that can also be expressed via geometry-adaptive harmonic bases?","To our surprise, we find that this is not the case.","This discrepancy motivates our search for the inductive bias that can lead to good generalization in DiT models.","Investigating the pivotal attention modules of a DiT, we find that locality of attention maps are closely associated with generalization.","To verify this finding, we modify the generalization of a DiT by restricting its attention windows.","We inject local attention windows to a DiT and observe an improvement in generalization.","Furthermore, we empirically find that both the placement and the effective attention size of these local attention windows are crucial factors.","Experimental results on the CelebA, ImageNet, and LSUN datasets show that strengthening the inductive bias of a DiT can improve both generalization and generation quality when less training data is available.","Source code will be released publicly upon paper publication.","Project page: dit-generalization.github.io/."],"url":"http://arxiv.org/abs/2410.21273v1"}
{"created":"2024-10-28 17:59:06","title":"Arithmetic Without Algorithms: Language Models Solve Math With a Bag of Heuristics","abstract":"Do large language models (LLMs) solve reasoning tasks by learning robust generalizable algorithms, or do they memorize training data? To investigate this question, we use arithmetic reasoning as a representative task. Using causal analysis, we identify a subset of the model (a circuit) that explains most of the model's behavior for basic arithmetic logic and examine its functionality. By zooming in on the level of individual circuit neurons, we discover a sparse set of important neurons that implement simple heuristics. Each heuristic identifies a numerical input pattern and outputs corresponding answers. We hypothesize that the combination of these heuristic neurons is the mechanism used to produce correct arithmetic answers. To test this, we categorize each neuron into several heuristic types-such as neurons that activate when an operand falls within a certain range-and find that the unordered combination of these heuristic types is the mechanism that explains most of the model's accuracy on arithmetic prompts. Finally, we demonstrate that this mechanism appears as the main source of arithmetic accuracy early in training. Overall, our experimental results across several LLMs show that LLMs perform arithmetic using neither robust algorithms nor memorization; rather, they rely on a \"bag of heuristics\".","sentences":["Do large language models (LLMs) solve reasoning tasks by learning robust generalizable algorithms, or do they memorize training data?","To investigate this question, we use arithmetic reasoning as a representative task.","Using causal analysis, we identify a subset of the model (a circuit) that explains most of the model's behavior for basic arithmetic logic and examine its functionality.","By zooming in on the level of individual circuit neurons, we discover a sparse set of important neurons that implement simple heuristics.","Each heuristic identifies a numerical input pattern and outputs corresponding answers.","We hypothesize that the combination of these heuristic neurons is the mechanism used to produce correct arithmetic answers.","To test this, we categorize each neuron into several heuristic types-such as neurons that activate when an operand falls within a certain range-and find that the unordered combination of these heuristic types is the mechanism that explains most of the model's accuracy on arithmetic prompts.","Finally, we demonstrate that this mechanism appears as the main source of arithmetic accuracy early in training.","Overall, our experimental results across several LLMs show that LLMs perform arithmetic using neither robust algorithms nor memorization; rather, they rely on a \"bag of heuristics\"."],"url":"http://arxiv.org/abs/2410.21272v1"}
{"created":"2024-10-28 17:59:03","title":"EoRA: Training-free Compensation for Compressed LLM with Eigenspace Low-Rank Approximation","abstract":"In this work, we re-formulate the model compression problem into the customized compensation problem: Given a compressed model, we aim to introduce residual low-rank paths to compensate for compression errors under customized requirements from users (e.g., tasks, compression ratios), resulting in greater flexibility in adjusting overall capacity without being constrained by specific compression formats. However, naively applying SVD to derive residual paths causes suboptimal utilization of the low-rank representation capacity. Instead, we propose Training-free Eigenspace Low-Rank Approximation (EoRA), a method that directly minimizes compression-induced errors without requiring gradient-based training, achieving fast optimization in minutes using a small amount of calibration data. EoRA projects compression errors into the eigenspace of input activations, leveraging eigenvalues to effectively prioritize the reconstruction of high-importance error components. Moreover, EoRA can be seamlessly integrated with fine-tuning and quantization to further improve effectiveness and efficiency. EoRA consistently outperforms previous methods in compensating errors for compressed LLaMA2/3 models on various tasks, such as language generation, commonsense reasoning, and math reasoning tasks (e.g., 31.31%/12.88% and 9.69% improvements on ARC-Easy/ARC-Challenge and MathQA when compensating LLaMA3-8B that is quantized to 4-bit and pruned to 2:4 sparsity). EoRA offers a scalable, training-free solution to compensate for compression errors, making it a powerful tool to deploy LLMs in various capacity and efficiency requirements.","sentences":["In this work, we re-formulate the model compression problem into the customized compensation problem: Given a compressed model, we aim to introduce residual low-rank paths to compensate for compression errors under customized requirements from users (e.g., tasks, compression ratios), resulting in greater flexibility in adjusting overall capacity without being constrained by specific compression formats.","However, naively applying SVD to derive residual paths causes suboptimal utilization of the low-rank representation capacity.","Instead, we propose Training-free Eigenspace Low-Rank Approximation (EoRA), a method that directly minimizes compression-induced errors without requiring gradient-based training, achieving fast optimization in minutes using a small amount of calibration data.","EoRA projects compression errors into the eigenspace of input activations, leveraging eigenvalues to effectively prioritize the reconstruction of high-importance error components.","Moreover, EoRA can be seamlessly integrated with fine-tuning and quantization to further improve effectiveness and efficiency.","EoRA consistently outperforms previous methods in compensating errors for compressed LLaMA2/3 models on various tasks, such as language generation, commonsense reasoning, and math reasoning tasks (e.g., 31.31%/12.88% and 9.69% improvements on ARC-Easy/ARC-Challenge and MathQA when compensating LLaMA3-8B that is quantized to 4-bit and pruned to 2:4 sparsity).","EoRA offers a scalable, training-free solution to compensate for compression errors, making it a powerful tool to deploy LLMs in various capacity and efficiency requirements."],"url":"http://arxiv.org/abs/2410.21271v1"}
{"created":"2024-10-28 17:58:15","title":"OmniSep: Unified Omni-Modality Sound Separation with Query-Mixup","abstract":"The scaling up has brought tremendous success in the fields of vision and language in recent years. When it comes to audio, however, researchers encounter a major challenge in scaling up the training data, as most natural audio contains diverse interfering signals. To address this limitation, we introduce Omni-modal Sound Separation (OmniSep), a novel framework capable of isolating clean soundtracks based on omni-modal queries, encompassing both single-modal and multi-modal composed queries. Specifically, we introduce the Query-Mixup strategy, which blends query features from different modalities during training. This enables OmniSep to optimize multiple modalities concurrently, effectively bringing all modalities under a unified framework for sound separation. We further enhance this flexibility by allowing queries to influence sound separation positively or negatively, facilitating the retention or removal of specific sounds as desired. Finally, OmniSep employs a retrieval-augmented approach known as Query-Aug, which enables open-vocabulary sound separation. Experimental evaluations on MUSIC, VGGSOUND-CLEAN+, and MUSIC-CLEAN+ datasets demonstrate effectiveness of OmniSep, achieving state-of-the-art performance in text-, image-, and audio-queried sound separation tasks. For samples and further information, please visit the demo page at \\url{https://omnisep.github.io/}.","sentences":["The scaling up has brought tremendous success in the fields of vision and language in recent years.","When it comes to audio, however, researchers encounter a major challenge in scaling up the training data, as most natural audio contains diverse interfering signals.","To address this limitation, we introduce Omni-modal Sound Separation (OmniSep), a novel framework capable of isolating clean soundtracks based on omni-modal queries, encompassing both single-modal and multi-modal composed queries.","Specifically, we introduce the Query-Mixup strategy, which blends query features from different modalities during training.","This enables OmniSep to optimize multiple modalities concurrently, effectively bringing all modalities under a unified framework for sound separation.","We further enhance this flexibility by allowing queries to influence sound separation positively or negatively, facilitating the retention or removal of specific sounds as desired.","Finally, OmniSep employs a retrieval-augmented approach known as Query-Aug, which enables open-vocabulary sound separation.","Experimental evaluations on MUSIC, VGGSOUND-CLEAN+, and MUSIC-CLEAN+ datasets demonstrate effectiveness of OmniSep, achieving state-of-the-art performance in text-, image-, and audio-queried sound separation tasks.","For samples and further information, please visit the demo page at \\url{https://omnisep.github.io/}."],"url":"http://arxiv.org/abs/2410.21269v1"}
{"created":"2024-10-28 17:58:06","title":"Optimizing Puncturing Patterns of 5G NR LDPC Codes for Few-Iteration Decoding","abstract":"Rate-matching of low-density parity-check (LDPC) codes enables a single code description to support a wide range of code lengths and rates. In 5G NR, rate matching is accomplished by extending (lifting) a base code to a desired target length and by puncturing (not transmitting) certain code bits. LDPC codes and rate matching are typically designed for the asymptotic performance limit with an ideal decoder. Practical LDPC decoders, however, carry out tens or fewer message-passing decoding iterations to achieve the target throughput and latency of modern wireless systems. We show that one can optimize LDPC code puncturing patterns for such few-iteration-constrained decoders using a method we call swapping of punctured and transmitted blocks (SPAT). Our simulation results show that SPAT yields from 0.20 dB up to 0.55 dB improved signal-to-noise ratio performance compared to the standard 5G NR LDPC code puncturing pattern for a wide range of code lengths and rates.","sentences":["Rate-matching of low-density parity-check (LDPC) codes enables a single code description to support a wide range of code lengths and rates.","In 5G NR, rate matching is accomplished by extending (lifting) a base code to a desired target length and by puncturing (not transmitting) certain code bits.","LDPC codes and rate matching are typically designed for the asymptotic performance limit with an ideal decoder.","Practical LDPC decoders, however, carry out tens or fewer message-passing decoding iterations to achieve the target throughput and latency of modern wireless systems.","We show that one can optimize LDPC code puncturing patterns for such few-iteration-constrained decoders using a method we call swapping of punctured and transmitted blocks (SPAT).","Our simulation results show that SPAT yields from 0.20 dB up to 0.55 dB improved signal-to-noise ratio performance compared to the standard 5G NR LDPC code puncturing pattern for a wide range of code lengths and rates."],"url":"http://arxiv.org/abs/2410.21267v1"}
{"created":"2024-10-28 17:57:40","title":"Online Weighted Paging with Unknown Weights","abstract":"Online paging is a fundamental problem in the field of online algorithms, in which one maintains a cache of $k$ slots as requests for fetching pages arrive online. In the weighted variant of this problem, each page has its own fetching cost; a substantial line of work on this problem culminated in an (optimal) $O(\\log k)$-competitive randomized algorithm, due to Bansal, Buchbinder and Naor (FOCS'07).   Existing work for weighted paging assumes that page weights are known in advance, which is not always the case in practice. For example, in multi-level caching architectures, the expected cost of fetching a memory block is a function of its probability of being in a mid-level cache rather than the main memory. This complex property cannot be predicted in advance; over time, however, one may glean information about page weights through sampling their fetching cost multiple times.   We present the first algorithm for online weighted paging that does not know page weights in advance, but rather learns from weight samples. In terms of techniques, this requires providing (integral) samples to a fractional solver, requiring a delicate interface between this solver and the randomized rounding scheme; we believe that our work can inspire online algorithms to other problems that involve cost sampling.","sentences":["Online paging is a fundamental problem in the field of online algorithms, in which one maintains a cache of $k$ slots as requests for fetching pages arrive online.","In the weighted variant of this problem, each page has its own fetching cost; a substantial line of work on this problem culminated in an (optimal) $O(\\log k)$-competitive randomized algorithm, due to Bansal, Buchbinder and Naor (FOCS'07).   ","Existing work for weighted paging assumes that page weights are known in advance, which is not always the case in practice.","For example, in multi-level caching architectures, the expected cost of fetching a memory block is a function of its probability of being in a mid-level cache rather than the main memory.","This complex property cannot be predicted in advance; over time, however, one may glean information about page weights through sampling their fetching cost multiple times.   ","We present the first algorithm for online weighted paging that does not know page weights in advance, but rather learns from weight samples.","In terms of techniques, this requires providing (integral) samples to a fractional solver, requiring a delicate interface between this solver and the randomized rounding scheme; we believe that our work can inspire online algorithms to other problems that involve cost sampling."],"url":"http://arxiv.org/abs/2410.21266v1"}
{"created":"2024-10-28 17:57:31","title":"Modular Duality in Deep Learning","abstract":"An old idea in optimization theory says that since the gradient is a dual vector it may not be subtracted from the weights without first being mapped to the primal space where the weights reside. We take this idea seriously in this paper and construct such a duality map for general neural networks. Our map, which we call modular dualization, forms a unifying theoretical basis for training algorithms that are a) fast and b) scalable. Modular dualization involves first assigning operator norms to layers based on the semantics of each layer, and then using these layerwise norms to recursively induce a duality map on the weight space of the full neural architecture. We conclude by deriving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers -- the latter two methods are based on a new rectangular Newton-Schulz iteration that we propose. Our iteration was recently used to set new speed records for training NanoGPT. Overall, we hope that our theory of modular duality will yield a next generation of fast and scalable optimizers for general neural architectures.","sentences":["An old idea in optimization theory says that since the gradient is a dual vector it may not be subtracted from the weights without first being mapped to the primal space where the weights reside.","We take this idea seriously in this paper and construct such a duality map for general neural networks.","Our map, which we call modular dualization, forms a unifying theoretical basis for training algorithms that are a) fast and b) scalable.","Modular dualization involves first assigning operator norms to layers based on the semantics of each layer, and then using these layerwise norms to recursively induce a duality map on the weight space of the full neural architecture.","We conclude by deriving GPU-friendly algorithms for dualizing Embed, Linear and Conv2D layers -- the latter two methods are based on a new rectangular Newton-Schulz iteration that we propose.","Our iteration was recently used to set new speed records for training NanoGPT.","Overall, we hope that our theory of modular duality will yield a next generation of fast and scalable optimizers for general neural architectures."],"url":"http://arxiv.org/abs/2410.21265v1"}
{"created":"2024-10-28 17:57:07","title":"LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior","abstract":"We present LARP, a novel video tokenizer designed to overcome limitations in current video tokenization methods for autoregressive (AR) generative models. Unlike traditional patchwise tokenizers that directly encode local visual patches into discrete tokens, LARP introduces a holistic tokenization scheme that gathers information from the visual content using a set of learned holistic queries. This design allows LARP to capture more global and semantic representations, rather than being limited to local patch-level information. Furthermore, it offers flexibility by supporting an arbitrary number of discrete tokens, enabling adaptive and efficient tokenization based on the specific requirements of the task. To align the discrete token space with downstream AR generation tasks, LARP integrates a lightweight AR transformer as a training-time prior model that predicts the next token on its discrete latent space. By incorporating the prior model during training, LARP learns a latent space that is not only optimized for video reconstruction but is also structured in a way that is more conducive to autoregressive generation. Moreover, this process defines a sequential order for the discrete tokens, progressively pushing them toward an optimal configuration during training, ensuring smoother and more accurate AR generation at inference time. Comprehensive experiments demonstrate LARP's strong performance, achieving state-of-the-art FVD on the UCF101 class-conditional video generation benchmark. LARP enhances the compatibility of AR models with videos and opens up the potential to build unified high-fidelity multimodal large language models (MLLMs).","sentences":["We present LARP, a novel video tokenizer designed to overcome limitations in current video tokenization methods for autoregressive (AR) generative models.","Unlike traditional patchwise tokenizers that directly encode local visual patches into discrete tokens, LARP introduces a holistic tokenization scheme that gathers information from the visual content using a set of learned holistic queries.","This design allows LARP to capture more global and semantic representations, rather than being limited to local patch-level information.","Furthermore, it offers flexibility by supporting an arbitrary number of discrete tokens, enabling adaptive and efficient tokenization based on the specific requirements of the task.","To align the discrete token space with downstream AR generation tasks, LARP integrates a lightweight AR transformer as a training-time prior model that predicts the next token on its discrete latent space.","By incorporating the prior model during training, LARP learns a latent space that is not only optimized for video reconstruction but is also structured in a way that is more conducive to autoregressive generation.","Moreover, this process defines a sequential order for the discrete tokens, progressively pushing them toward an optimal configuration during training, ensuring smoother and more accurate AR generation at inference time.","Comprehensive experiments demonstrate LARP's strong performance, achieving state-of-the-art FVD on the UCF101 class-conditional video generation benchmark.","LARP enhances the compatibility of AR models with videos and opens up the potential to build unified high-fidelity multimodal large language models (MLLMs)."],"url":"http://arxiv.org/abs/2410.21264v1"}
{"created":"2024-10-28 17:56:18","title":"BLAST: Block-Level Adaptive Structured Matrices for Efficient Deep Neural Network Inference","abstract":"Large-scale foundation models have demonstrated exceptional performance in language and vision tasks. However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference. To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models. Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices. We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70\\% and 40\\%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices. Our code is available at \\url{https://github.com/changwoolee/BLAST}.","sentences":["Large-scale foundation models have demonstrated exceptional performance in language and vision tasks.","However, the numerous dense matrix-vector operations involved in these large networks pose significant computational challenges during inference.","To address these challenges, we introduce the Block-Level Adaptive STructured (BLAST) matrix, designed to learn and leverage efficient structures prevalent in the weight matrices of linear layers within deep learning models.","Compared to existing structured matrices, the BLAST matrix offers substantial flexibility, as it can represent various types of structures that are either learned from data or computed from pre-existing weight matrices.","We demonstrate the efficiency of using the BLAST matrix for compressing both language and vision tasks, showing that (i) for medium-sized models such as ViT and GPT-2, training with BLAST weights boosts performance while reducing complexity by 70\\% and 40\\%, respectively; and (ii) for large foundation models such as Llama-7B and DiT-XL, the BLAST matrix achieves a 2x compression while exhibiting the lowest performance degradation among all tested structured matrices.","Our code is available at \\url{https://github.com/changwoolee/BLAST}."],"url":"http://arxiv.org/abs/2410.21262v1"}
{"created":"2024-10-28 17:55:51","title":"Fine-Grained Clustering-Based Power Identification for Multicores","abstract":"Fine-grained power estimation in multicore Systems on Chips (SoCs) is crucial for efficient thermal management. BPI (Blind Power Identification) is a recent approach that determines the power consumption of different cores and the thermal model of the chip using only thermal sensor measurements and total power consumption. BPI relies on steady-state thermal data along with a naive initialization in its Non-negative Matrix Factorization (NMF) process, which negatively impacts the power estimation accuracy of BPI. This paper proposes a two-fold approach to reduce these impacts on BPI. First, this paper introduces an innovative approach for NMF initializing, i.e., density-oriented spatial clustering to identify centroid data points of active cores as initial values. This enhances BPI accuracy by focusing on dense regions in the dataset and excluding outlier data points. Second, it proposes the utilization of steady-state temperature data points to enhance the power estimation accuracy by leveraging the physical relationship between temperature and power consumption. Our extensive simulations of real-world cases demonstrate that our approach enhances BPI accuracy in estimating the power per core with no performance cost. For instance, in a four-core processor, the proposed approach reduces the error rate by 76% compared to BPI and by 24% compared to the state of the art in the literature, namely, Blind Power Identification Steady State (BPISS). The results underline the potential of integrating advanced clustering techniques in thermal model identification, paving the way for more accurate and reliable thermal management in multicores and SoCs.","sentences":["Fine-grained power estimation in multicore Systems on Chips (SoCs) is crucial for efficient thermal management.","BPI (Blind Power Identification) is a recent approach that determines the power consumption of different cores and the thermal model of the chip using only thermal sensor measurements and total power consumption.","BPI relies on steady-state thermal data along with a naive initialization in its Non-negative Matrix Factorization (NMF) process, which negatively impacts the power estimation accuracy of BPI.","This paper proposes a two-fold approach to reduce these impacts on BPI.","First, this paper introduces an innovative approach for NMF initializing, i.e., density-oriented spatial clustering to identify centroid data points of active cores as initial values.","This enhances BPI accuracy by focusing on dense regions in the dataset and excluding outlier data points.","Second, it proposes the utilization of steady-state temperature data points to enhance the power estimation accuracy by leveraging the physical relationship between temperature and power consumption.","Our extensive simulations of real-world cases demonstrate that our approach enhances BPI accuracy in estimating the power per core with no performance cost.","For instance, in a four-core processor, the proposed approach reduces the error rate by 76% compared to BPI and by 24% compared to the state of the art in the literature, namely, Blind Power Identification Steady State (BPISS).","The results underline the potential of integrating advanced clustering techniques in thermal model identification, paving the way for more accurate and reliable thermal management in multicores and SoCs."],"url":"http://arxiv.org/abs/2410.21261v1"}
{"created":"2024-10-28 17:55:08","title":"AutoBench-V: Can Large Vision-Language Models Benchmark Themselves?","abstract":"Large Vision-Language Models (LVLMs) have become essential for advancing the integration of visual and linguistic information, facilitating a wide range of complex applications and tasks. However, the evaluation of LVLMs presents significant challenges as the evaluation benchmark always demands lots of human cost for its construction, and remains static, lacking flexibility once constructed. Even though automatic evaluation has been explored in textual modality, the visual modality remains under-explored. As a result, in this work, we address a question: \"Can LVLMs serve as a path to automatic benchmarking?\". We introduce AutoBench-V, an automated framework for serving evaluation on demand, i.e., benchmarking LVLMs based on specific aspects of model capability. Upon receiving an evaluation capability, AutoBench-V leverages text-to-image models to generate relevant image samples and then utilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing the evaluation process efficiently and flexibly. Through an extensive evaluation of seven popular LVLMs across five demanded user inputs (i.e., evaluation capabilities), the framework shows effectiveness and reliability. We observe the following: (1) Our constructed benchmark accurately reflects varying task difficulties; (2) As task difficulty rises, the performance gap between models widens; (3) While models exhibit strong performance in abstract level understanding, they underperform in details reasoning tasks; and (4) Constructing a dataset with varying levels of difficulties is critical for a comprehensive and exhaustive evaluation. Overall, AutoBench-V not only successfully utilizes LVLMs for automated benchmarking but also reveals that LVLMs as judges have significant potential in various domains.","sentences":["Large Vision-Language Models (LVLMs) have become essential for advancing the integration of visual and linguistic information, facilitating a wide range of complex applications and tasks.","However, the evaluation of LVLMs presents significant challenges as the evaluation benchmark always demands lots of human cost for its construction, and remains static, lacking flexibility once constructed.","Even though automatic evaluation has been explored in textual modality, the visual modality remains under-explored.","As a result, in this work, we address a question: \"Can LVLMs serve as a path to automatic benchmarking?\".","We introduce AutoBench-V, an automated framework for serving evaluation on demand, i.e., benchmarking LVLMs based on specific aspects of model capability.","Upon receiving an evaluation capability, AutoBench-V leverages text-to-image models to generate relevant image samples and then utilizes LVLMs to orchestrate visual question-answering (VQA) tasks, completing the evaluation process efficiently and flexibly.","Through an extensive evaluation of seven popular LVLMs across five demanded user inputs (i.e., evaluation capabilities), the framework shows effectiveness and reliability.","We observe the following: (1) Our constructed benchmark accurately reflects varying task difficulties; (2) As task difficulty rises, the performance gap between models widens; (3) While models exhibit strong performance in abstract level understanding, they underperform in details reasoning tasks; and (4) Constructing a dataset with varying levels of difficulties is critical for a comprehensive and exhaustive evaluation.","Overall, AutoBench-V not only successfully utilizes LVLMs for automated benchmarking but also reveals that LVLMs as judges have significant potential in various domains."],"url":"http://arxiv.org/abs/2410.21259v1"}
{"created":"2024-10-28 17:54:31","title":"One-Step Diffusion Policy: Fast Visuomotor Policies via Diffusion Distillation","abstract":"Diffusion models, praised for their success in generative tasks, are increasingly being applied to robotics, demonstrating exceptional performance in behavior cloning. However, their slow generation process stemming from iterative denoising steps poses a challenge for real-time applications in resource-constrained robotics setups and dynamically changing environments. In this paper, we introduce the One-Step Diffusion Policy (OneDP), a novel approach that distills knowledge from pre-trained diffusion policies into a single-step action generator, significantly accelerating response times for robotic control tasks. We ensure the distilled generator closely aligns with the original policy distribution by minimizing the Kullback-Leibler (KL) divergence along the diffusion chain, requiring only $2\\%$-$10\\%$ additional pre-training cost for convergence. We evaluated OneDP on 6 challenging simulation tasks as well as 4 self-designed real-world tasks using the Franka robot. The results demonstrate that OneDP not only achieves state-of-the-art success rates but also delivers an order-of-magnitude improvement in inference speed, boosting action prediction frequency from 1.5 Hz to 62 Hz, establishing its potential for dynamic and computationally constrained robotic applications. We share the project page at https://research.nvidia.com/labs/dir/onedp/.","sentences":["Diffusion models, praised for their success in generative tasks, are increasingly being applied to robotics, demonstrating exceptional performance in behavior cloning.","However, their slow generation process stemming from iterative denoising steps poses a challenge for real-time applications in resource-constrained robotics setups and dynamically changing environments.","In this paper, we introduce the One-Step Diffusion Policy (OneDP), a novel approach that distills knowledge from pre-trained diffusion policies into a single-step action generator, significantly accelerating response times for robotic control tasks.","We ensure the distilled generator closely aligns with the original policy distribution by minimizing the Kullback-Leibler (KL) divergence along the diffusion chain, requiring only $2\\%$-$10\\%$ additional pre-training cost for convergence.","We evaluated OneDP on 6 challenging simulation tasks as well as 4 self-designed real-world tasks using the Franka robot.","The results demonstrate that OneDP not only achieves state-of-the-art success rates but also delivers an order-of-magnitude improvement in inference speed, boosting action prediction frequency from 1.5 Hz to 62 Hz, establishing its potential for dynamic and computationally constrained robotic applications.","We share the project page at https://research.nvidia.com/labs/dir/onedp/."],"url":"http://arxiv.org/abs/2410.21257v1"}
{"created":"2024-10-28 17:54:29","title":"Multi-modal AI for comprehensive breast cancer prognostication","abstract":"Treatment selection in breast cancer is guided by molecular subtypes and clinical characteristics. Recurrence risk assessment plays a crucial role in personalizing treatment. Current methods, including genomic assays, have limited accuracy and clinical utility, leading to suboptimal decisions for many patients. We developed a test for breast cancer patient stratification based on digital pathology and clinical characteristics using novel AI methods. Specifically, we utilized a vision transformer-based pan-cancer foundation model trained with self-supervised learning to extract features from digitized H&E-stained slides. These features were integrated with clinical data to form a multi-modal AI test predicting cancer recurrence and death. The test was developed and evaluated using data from a total of 8,161 breast cancer patients across 15 cohorts originating from seven countries. Of these, 3,502 patients from five cohorts were used exclusively for evaluation, while the remaining patients were used for training. Our test accurately predicted our primary endpoint, disease-free interval, in the five external cohorts (C-index: 0.71 [0.68-0.75], HR: 3.63 [3.02-4.37, p<0.01]). In a direct comparison (N=858), the AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay, with a C-index of 0.67 [0.61-0.74] versus 0.61 [0.49-0.73], respectively. Additionally, the AI test added independent information to Oncotype DX in a multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]). The test demonstrated robust accuracy across all major breast cancer subtypes, including TNBC (C-index: 0.71 [0.62-0.81], HR: 3.81 [2.35-6.17, p=0.02]), where no diagnostic tools are currently recommended by clinical guidelines. These results suggest that our AI test can improve accuracy, extend applicability to a wider range of patients, and enhance access to treatment selection tools.","sentences":["Treatment selection in breast cancer is guided by molecular subtypes and clinical characteristics.","Recurrence risk assessment plays a crucial role in personalizing treatment.","Current methods, including genomic assays, have limited accuracy and clinical utility, leading to suboptimal decisions for many patients.","We developed a test for breast cancer patient stratification based on digital pathology and clinical characteristics using novel AI methods.","Specifically, we utilized a vision transformer-based pan-cancer foundation model trained with self-supervised learning to extract features from digitized H&E-stained slides.","These features were integrated with clinical data to form a multi-modal AI test predicting cancer recurrence and death.","The test was developed and evaluated using data from a total of 8,161 breast cancer patients across 15 cohorts originating from seven countries.","Of these, 3,502 patients from five cohorts were used exclusively for evaluation, while the remaining patients were used for training.","Our test accurately predicted our primary endpoint, disease-free interval, in the five external cohorts (C-index: 0.71","[0.68-0.75], HR: 3.63","[3.02-4.37, p<0.01]).","In a direct comparison (N=858), the AI test was more accurate than Oncotype DX, the standard-of-care 21-gene assay, with a C-index of 0.67","[0.61-0.74] versus 0.61","[0.49-0.73], respectively.","Additionally, the AI test added independent information to Oncotype DX in a multivariate analysis (HR: 3.11 [1.91-5.09, p<0.01)]).","The test demonstrated robust accuracy across all major breast cancer subtypes, including TNBC (C-index: 0.71","[0.62-0.81], HR: 3.81","[2.35-6.17, p=0.02]), where no diagnostic tools are currently recommended by clinical guidelines.","These results suggest that our AI test can improve accuracy, extend applicability to a wider range of patients, and enhance access to treatment selection tools."],"url":"http://arxiv.org/abs/2410.21256v1"}
{"created":"2024-10-28 17:52:15","title":"Are BabyLMs Second Language Learners?","abstract":"This paper describes a linguistically-motivated approach to the 2024 edition of the BabyLM Challenge (Warstadt et al. 2023). Rather than pursuing a first language learning (L1) paradigm, we approach the challenge from a second language (L2) learning perspective. In L2 learning, there is a stronger focus on learning explicit linguistic information, such as grammatical notions, definitions of words or different ways of expressing a meaning. This makes L2 learning potentially more efficient and concise. We approximate this using data from Wiktionary, grammar examples either generated by an LLM or sourced from grammar books, and paraphrase data. We find that explicit information about word meaning (in our case, Wiktionary) does not boost model performance, while grammatical information can give a small improvement. The most impactful data ingredient is sentence paraphrases, with our two best models being trained on 1) a mix of paraphrase data and data from the BabyLM pretraining dataset, and 2) exclusively paraphrase data.","sentences":["This paper describes a linguistically-motivated approach to the 2024 edition of the BabyLM Challenge (Warstadt et al. 2023).","Rather than pursuing a first language learning (L1) paradigm, we approach the challenge from a second language (L2) learning perspective.","In L2 learning, there is a stronger focus on learning explicit linguistic information, such as grammatical notions, definitions of words or different ways of expressing a meaning.","This makes L2 learning potentially more efficient and concise.","We approximate this using data from Wiktionary, grammar examples either generated by an LLM or sourced from grammar books, and paraphrase data.","We find that explicit information about word meaning (in our case, Wiktionary) does not boost model performance, while grammatical information can give a small improvement.","The most impactful data ingredient is sentence paraphrases, with our two best models being trained on 1) a mix of paraphrase data and data from the BabyLM pretraining dataset, and 2) exclusively paraphrase data."],"url":"http://arxiv.org/abs/2410.21254v1"}
{"created":"2024-10-28 17:50:42","title":"LongReward: Improving Long-context Large Language Models with AI Feedback","abstract":"Though significant advancements have been achieved in developing long-context large language models (LLMs), the compromised quality of LLM-synthesized data for supervised fine-tuning (SFT) often affects the long-context performance of SFT models and leads to inherent limitations. In principle, reinforcement learning (RL) with appropriate reward signals can further enhance models' capacities. However, how to obtain reliable rewards in long-context scenarios remains unexplored. To this end, we propose LongReward, a novel method that utilizes an off-the-shelf LLM to provide rewards for long-context model responses from four human-valued dimensions: helpfulness, logicality, faithfulness, and completeness, each with a carefully designed assessment pipeline. By combining LongReward and offline RL algorithm DPO, we are able to effectively improve long-context SFT models. Our experiments indicate that LongReward not only significantly improves models' long-context performance but also enhances their ability to follow short instructions. We also find that long-context DPO with LongReward and conventional short-context DPO can be used together without hurting either one's performance.","sentences":["Though significant advancements have been achieved in developing long-context large language models (LLMs), the compromised quality of LLM-synthesized data for supervised fine-tuning (SFT) often affects the long-context performance of SFT models and leads to inherent limitations.","In principle, reinforcement learning (RL) with appropriate reward signals can further enhance models' capacities.","However, how to obtain reliable rewards in long-context scenarios remains unexplored.","To this end, we propose LongReward, a novel method that utilizes an off-the-shelf LLM to provide rewards for long-context model responses from four human-valued dimensions: helpfulness, logicality, faithfulness, and completeness, each with a carefully designed assessment pipeline.","By combining LongReward and offline RL algorithm DPO, we are able to effectively improve long-context SFT models.","Our experiments indicate that LongReward not only significantly improves models' long-context performance but also enhances their ability to follow short instructions.","We also find that long-context DPO with LongReward and conventional short-context DPO can be used together without hurting either one's performance."],"url":"http://arxiv.org/abs/2410.21252v1"}
{"created":"2024-10-28 17:48:45","title":"Capacity-Aware Planning and Scheduling in Budget-Constrained Monotonic MDPs: A Meta-RL Approach","abstract":"Many real-world sequential repair problems can be effectively modeled using monotonic Markov Decision Processes (MDPs), where the system state stochastically decreases and can only be increased by performing a restorative action. This work addresses the problem of solving multi-component monotonic MDPs with both budget and capacity constraints. The budget constraint limits the total number of restorative actions and the capacity constraint limits the number of restorative actions that can be performed simultaneously. While prior methods dealt with budget constraints, including capacity constraints in prior methods leads to an exponential increase in computational complexity as the number of components in the MDP grows. We propose a two-step planning approach to address this challenge. First, we partition the components of the multi-component MDP into groups, where the number of groups is determined by the capacity constraint. We achieve this partitioning by solving a Linear Sum Assignment Problem (LSAP). Each group is then allocated a fraction of the total budget proportional to its size. This partitioning effectively decouples the large multi-component MDP into smaller subproblems, which are computationally feasible because the capacity constraint is simplified and the budget constraint can be addressed using existing methods. Subsequently, we use a meta-trained PPO agent to obtain an approximately optimal policy for each group. To validate our approach, we apply it to the problem of scheduling repairs for a large group of industrial robots, constrained by a limited number of repair technicians and a total repair budget. Our results demonstrate that the proposed method outperforms baseline approaches in terms of maximizing the average uptime of the robot swarm, particularly for large swarm sizes.","sentences":["Many real-world sequential repair problems can be effectively modeled using monotonic Markov Decision Processes (MDPs), where the system state stochastically decreases and can only be increased by performing a restorative action.","This work addresses the problem of solving multi-component monotonic MDPs with both budget and capacity constraints.","The budget constraint limits the total number of restorative actions and the capacity constraint limits the number of restorative actions that can be performed simultaneously.","While prior methods dealt with budget constraints, including capacity constraints in prior methods leads to an exponential increase in computational complexity as the number of components in the MDP grows.","We propose a two-step planning approach to address this challenge.","First, we partition the components of the multi-component MDP into groups, where the number of groups is determined by the capacity constraint.","We achieve this partitioning by solving a Linear Sum Assignment Problem (LSAP).","Each group is then allocated a fraction of the total budget proportional to its size.","This partitioning effectively decouples the large multi-component MDP into smaller subproblems, which are computationally feasible because the capacity constraint is simplified and the budget constraint can be addressed using existing methods.","Subsequently, we use a meta-trained PPO agent to obtain an approximately optimal policy for each group.","To validate our approach, we apply it to the problem of scheduling repairs for a large group of industrial robots, constrained by a limited number of repair technicians and a total repair budget.","Our results demonstrate that the proposed method outperforms baseline approaches in terms of maximizing the average uptime of the robot swarm, particularly for large swarm sizes."],"url":"http://arxiv.org/abs/2410.21249v1"}
{"created":"2024-10-28 17:45:10","title":"Scheduling Policies in a Multi-Source Status Update System with Dedicated and Shared Servers","abstract":"Use of multi-path network topologies has become a prominent technique to assert timeliness in terms of age of information (AoI) and to improve resilience to link disruptions in communication systems. However, establishing multiple dedicated communication links among network nodes is a costly endeavor. Therefore, quite often, these secondary communication links are shared among multiple entities. Moreover, these multi-path networks come with the added challenge of out-of-order transmissions. In this paper, we study an amalgamation of the above two aspects, i.e., multi-path transmissions and link sharing. In contrast to the existing literature where the main focus has been scheduling multiple sources on a single shared server, we delve into the realm where each source sharing the shared server is also supplemented with its dedicated server so as to improve its timeliness. In this multi-path link sharing setting with generate-at-will transmissions, we first present the optimal probabilistic scheduler, and then propose several heuristic-based cyclic scheduling algorithms for the shared server, to minimize the weighted average age of information of the sources.","sentences":["Use of multi-path network topologies has become a prominent technique to assert timeliness in terms of age of information (AoI) and to improve resilience to link disruptions in communication systems.","However, establishing multiple dedicated communication links among network nodes is a costly endeavor.","Therefore, quite often, these secondary communication links are shared among multiple entities.","Moreover, these multi-path networks come with the added challenge of out-of-order transmissions.","In this paper, we study an amalgamation of the above two aspects, i.e., multi-path transmissions and link sharing.","In contrast to the existing literature where the main focus has been scheduling multiple sources on a single shared server, we delve into the realm where each source sharing the shared server is also supplemented with its dedicated server so as to improve its timeliness.","In this multi-path link sharing setting with generate-at-will transmissions, we first present the optimal probabilistic scheduler, and then propose several heuristic-based cyclic scheduling algorithms for the shared server, to minimize the weighted average age of information of the sources."],"url":"http://arxiv.org/abs/2410.21246v1"}
{"created":"2024-10-28 17:40:40","title":"Zero-Shot Dense Retrieval with Embeddings from Relevance Feedback","abstract":"Building effective dense retrieval systems remains difficult when relevance supervision is not available. Recent work has looked to overcome this challenge by using a Large Language Model (LLM) to generate hypothetical documents that can be used to find the closest real document. However, this approach relies solely on the LLM to have domain-specific knowledge relevant to the query, which may not be practical. Furthermore, generating hypothetical documents can be inefficient as it requires the LLM to generate a large number of tokens for each query. To address these challenges, we introduce Real Document Embeddings from Relevance Feedback (ReDE-RF). Inspired by relevance feedback, ReDE-RF proposes to re-frame hypothetical document generation as a relevance estimation task, using an LLM to select which documents should be used for nearest neighbor search. Through this re-framing, the LLM no longer needs domain-specific knowledge but only needs to judge what is relevant. Additionally, relevance estimation only requires the LLM to output a single token, thereby improving search latency. Our experiments show that ReDE-RF consistently surpasses state-of-the-art zero-shot dense retrieval methods across a wide range of low-resource retrieval datasets while also making significant improvements in latency per-query.","sentences":["Building effective dense retrieval systems remains difficult when relevance supervision is not available.","Recent work has looked to overcome this challenge by using a Large Language Model (LLM) to generate hypothetical documents that can be used to find the closest real document.","However, this approach relies solely on the LLM to have domain-specific knowledge relevant to the query, which may not be practical.","Furthermore, generating hypothetical documents can be inefficient as it requires the LLM to generate a large number of tokens for each query.","To address these challenges, we introduce Real Document Embeddings from Relevance Feedback (ReDE-RF).","Inspired by relevance feedback, ReDE-RF proposes to re-frame hypothetical document generation as a relevance estimation task, using an LLM to select which documents should be used for nearest neighbor search.","Through this re-framing, the LLM no longer needs domain-specific knowledge but only needs to judge what is relevant.","Additionally, relevance estimation only requires the LLM to output a single token, thereby improving search latency.","Our experiments show that ReDE-RF consistently surpasses state-of-the-art zero-shot dense retrieval methods across a wide range of low-resource retrieval datasets while also making significant improvements in latency per-query."],"url":"http://arxiv.org/abs/2410.21242v1"}
{"created":"2024-10-28 17:34:05","title":"Hierarchical Knowledge Graph Construction from Images for Scalable E-Commerce","abstract":"Knowledge Graph (KG) is playing an increasingly important role in various AI systems. For e-commerce, an efficient and low-cost automated knowledge graph construction method is the foundation of enabling various successful downstream applications. In this paper, we propose a novel method for constructing structured product knowledge graphs from raw product images. The method cooperatively leverages recent advances in the vision-language model (VLM) and large language model (LLM), fully automating the process and allowing timely graph updates. We also present a human-annotated e-commerce product dataset for benchmarking product property extraction in knowledge graph construction. Our method outperforms our baseline in all metrics and evaluated properties, demonstrating its effectiveness and bright usage potential.","sentences":["Knowledge Graph (KG) is playing an increasingly important role in various AI systems.","For e-commerce, an efficient and low-cost automated knowledge graph construction method is the foundation of enabling various successful downstream applications.","In this paper, we propose a novel method for constructing structured product knowledge graphs from raw product images.","The method cooperatively leverages recent advances in the vision-language model (VLM) and large language model (LLM), fully automating the process and allowing timely graph updates.","We also present a human-annotated e-commerce product dataset for benchmarking product property extraction in knowledge graph construction.","Our method outperforms our baseline in all metrics and evaluated properties, demonstrating its effectiveness and bright usage potential."],"url":"http://arxiv.org/abs/2410.21237v1"}
{"created":"2024-10-28 17:30:01","title":"Flaming-hot Initiation with Regular Execution Sampling for Large Language Models","abstract":"Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains. A key challenge in developing these general capabilities is efficiently sourcing diverse, high-quality data. This becomes especially critical in reasoning-related tasks with sandbox checkers, such as math or code, where the goal is to generate correct solutions to specific problems with higher probability. In this work, we introduce Flaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet highly effective method to efficiently find good responses. Our empirical findings show that FIRE sampling enhances inference-time generation quality and also benefits training in the alignment stage. Furthermore, we explore how FIRE sampling improves performance by promoting diversity and analyze the impact of employing FIRE at different positions within a response.","sentences":["Since the release of ChatGPT, large language models (LLMs) have demonstrated remarkable capabilities across various domains.","A key challenge in developing these general capabilities is efficiently sourcing diverse, high-quality data.","This becomes especially critical in reasoning-related tasks with sandbox checkers, such as math or code, where the goal is to generate correct solutions to specific problems with higher probability.","In this work, we introduce Flaming-hot Initiation with Regular Execution (FIRE) sampling, a simple yet highly effective method to efficiently find good responses.","Our empirical findings show that FIRE sampling enhances inference-time generation quality and also benefits training in the alignment stage.","Furthermore, we explore how FIRE sampling improves performance by promoting diversity and analyze the impact of employing FIRE at different positions within a response."],"url":"http://arxiv.org/abs/2410.21236v1"}
{"created":"2024-10-28 17:24:37","title":"ST-ITO: Controlling Audio Effects for Style Transfer with Inference-Time Optimization","abstract":"Audio production style transfer is the task of processing an input to impart stylistic elements from a reference recording. Existing approaches often train a neural network to estimate control parameters for a set of audio effects. However, these approaches are limited in that they can only control a fixed set of effects, where the effects must be differentiable or otherwise employ specialized training techniques. In this work, we introduce ST-ITO, Style Transfer with Inference-Time Optimization, an approach that instead searches the parameter space of an audio effect chain at inference. This method enables control of arbitrary audio effect chains, including unseen and non-differentiable effects. Our approach employs a learned metric of audio production style, which we train through a simple and scalable self-supervised pretraining strategy, along with a gradient-free optimizer. Due to the limited existing evaluation methods for audio production style transfer, we introduce a multi-part benchmark to evaluate audio production style metrics and style transfer systems. This evaluation demonstrates that our audio representation better captures attributes related to audio production and enables expressive style transfer via control of arbitrary audio effects.","sentences":["Audio production style transfer is the task of processing an input to impart stylistic elements from a reference recording.","Existing approaches often train a neural network to estimate control parameters for a set of audio effects.","However, these approaches are limited in that they can only control a fixed set of effects, where the effects must be differentiable or otherwise employ specialized training techniques.","In this work, we introduce ST-ITO, Style Transfer with Inference-Time Optimization, an approach that instead searches the parameter space of an audio effect chain at inference.","This method enables control of arbitrary audio effect chains, including unseen and non-differentiable effects.","Our approach employs a learned metric of audio production style, which we train through a simple and scalable self-supervised pretraining strategy, along with a gradient-free optimizer.","Due to the limited existing evaluation methods for audio production style transfer, we introduce a multi-part benchmark to evaluate audio production style metrics and style transfer systems.","This evaluation demonstrates that our audio representation better captures attributes related to audio production and enables expressive style transfer via control of arbitrary audio effects."],"url":"http://arxiv.org/abs/2410.21233v1"}
{"created":"2024-10-28 17:16:00","title":"$\\texttt{skwdro}$: a library for Wasserstein distributionally robust machine learning","abstract":"We present skwdro, a Python library for training robust machine learning models. The library is based on distributionally robust optimization using optimal transport distances. For ease of use, it features both scikit-learn compatible estimators for popular objectives, as well as a wrapper for PyTorch modules, enabling researchers and practitioners to use it in a wide range of models with minimal code changes. Its implementation relies on an entropic smoothing of the original robust objective in order to ensure maximal model flexibility. The library is available at https://github.com/iutzeler/skwdro","sentences":["We present skwdro, a Python library for training robust machine learning models.","The library is based on distributionally robust optimization using optimal transport distances.","For ease of use, it features both scikit-learn compatible estimators for popular objectives, as well as a wrapper for PyTorch modules, enabling researchers and practitioners to use it in a wide range of models with minimal code changes.","Its implementation relies on an entropic smoothing of the original robust objective in order to ensure maximal model flexibility.","The library is available at https://github.com/iutzeler/skwdro"],"url":"http://arxiv.org/abs/2410.21231v1"}
{"created":"2024-10-28 17:15:24","title":"HOVER: Versatile Neural Whole-Body Controller for Humanoid Robots","abstract":"Humanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control. For example, navigation relies on root velocity tracking, while tabletop manipulation prioritizes upper-body joint angle tracking. Existing approaches typically train individual policies tailored to a specific command space, limiting their transferability across modes. We present the key insight that full-body kinematic motion imitation can serve as a common abstraction for all these tasks and provide general-purpose motor skills for learning multiple modes of whole-body control. Building on this, we propose HOVER (Humanoid Versatile Controller), a multi-mode policy distillation framework that consolidates diverse control modes into a unified policy. HOVER enables seamless transitions between control modes while preserving the distinct advantages of each, offering a robust and scalable solution for humanoid control across a wide range of modes. By eliminating the need for policy retraining for each control mode, our approach improves efficiency and flexibility for future humanoid applications.","sentences":["Humanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control.","For example, navigation relies on root velocity tracking, while tabletop manipulation prioritizes upper-body joint angle tracking.","Existing approaches typically train individual policies tailored to a specific command space, limiting their transferability across modes.","We present the key insight that full-body kinematic motion imitation can serve as a common abstraction for all these tasks and provide general-purpose motor skills for learning multiple modes of whole-body control.","Building on this, we propose HOVER (Humanoid Versatile Controller), a multi-mode policy distillation framework that consolidates diverse control modes into a unified policy.","HOVER enables seamless transitions between control modes while preserving the distinct advantages of each, offering a robust and scalable solution for humanoid control across a wide range of modes.","By eliminating the need for policy retraining for each control mode, our approach improves efficiency and flexibility for future humanoid applications."],"url":"http://arxiv.org/abs/2410.21229v1"}
{"created":"2024-10-28 17:14:01","title":"LoRA vs Full Fine-tuning: An Illusion of Equivalence","abstract":"Fine-tuning is a crucial paradigm for adapting pre-trained large language models to downstream tasks. Recently, methods like Low-Rank Adaptation (LoRA) have been shown to match the performance of fully fine-tuned models on various tasks with an extreme reduction in the number of trainable parameters. Even in settings where both methods learn similarly accurate models, \\emph{are their learned solutions really equivalent?} We study how different fine-tuning methods change pre-trained models by analyzing the model's weight matrices through the lens of their spectral properties. We find that full fine-tuning and LoRA yield weight matrices whose singular value decompositions exhibit very different structure; moreover, the fine-tuned models themselves show distinct generalization behaviors when tested outside the adaptation task's distribution. More specifically, we first show that the weight matrices trained with LoRA have new, high-ranking singular vectors, which we call \\emph{intruder dimensions}. Intruder dimensions do not appear during full fine-tuning. Second, we show that LoRA models with intruder dimensions, despite achieving similar performance to full fine-tuning on the target task, become worse models of the pre-training distribution and adapt less robustly to multiple tasks sequentially. Higher-rank, rank-stabilized LoRA models closely mirror full fine-tuning, even when performing on par with lower-rank LoRA models on the same tasks. These results suggest that models updated with LoRA and full fine-tuning access different parts of parameter space, even when they perform equally on the fine-tuned distribution. We conclude by examining why intruder dimensions appear in LoRA fine-tuned models, why they are undesirable, and how their effects can be minimized.","sentences":["Fine-tuning is a crucial paradigm for adapting pre-trained large language models to downstream tasks.","Recently, methods like Low-Rank Adaptation (LoRA) have been shown to match the performance of fully fine-tuned models on various tasks with an extreme reduction in the number of trainable parameters.","Even in settings where both methods learn similarly accurate models, \\emph{are their learned solutions really equivalent?","} We study how different fine-tuning methods change pre-trained models by analyzing the model's weight matrices through the lens of their spectral properties.","We find that full fine-tuning and LoRA yield weight matrices whose singular value decompositions exhibit very different structure; moreover, the fine-tuned models themselves show distinct generalization behaviors when tested outside the adaptation task's distribution.","More specifically, we first show that the weight matrices trained with LoRA have new, high-ranking singular vectors, which we call \\emph{intruder dimensions}.","Intruder dimensions do not appear during full fine-tuning.","Second, we show that LoRA models with intruder dimensions, despite achieving similar performance to full fine-tuning on the target task, become worse models of the pre-training distribution and adapt less robustly to multiple tasks sequentially.","Higher-rank, rank-stabilized LoRA models closely mirror full fine-tuning, even when performing on par with lower-rank LoRA models on the same tasks.","These results suggest that models updated with LoRA and full fine-tuning access different parts of parameter space, even when they perform equally on the fine-tuned distribution.","We conclude by examining why intruder dimensions appear in LoRA fine-tuned models, why they are undesirable, and how their effects can be minimized."],"url":"http://arxiv.org/abs/2410.21228v1"}
{"created":"2024-10-28 17:05:04","title":"Reconstructing dynamics from sparse observations with no training on target system","abstract":"In applications, an anticipated situation is where the system of interest has never been encountered before and sparse observations can be made only once. Can the dynamics be faithfully reconstructed from the limited observations without any training data? This problem defies any known traditional methods of nonlinear time-series analysis as well as existing machine-learning methods that typically require extensive data from the target system for training. We address this challenge by developing a hybrid transformer and reservoir-computing machine-learning scheme. The key idea is that, for a complex and nonlinear target system, the training of the transformer can be conducted not using any data from the target system, but with essentially unlimited synthetic data from known chaotic systems. The trained transformer is then tested with the sparse data from the target system. The output of the transformer is further fed into a reservoir computer for predicting the long-term dynamics or the attractor of the target system. The power of the proposed hybrid machine-learning framework is demonstrated using a large number of prototypical nonlinear dynamical systems, with high reconstruction accuracy even when the available data is only 20% of that required to faithfully represent the dynamical behavior of the underlying system. The framework provides a paradigm of reconstructing complex and nonlinear dynamics in the extreme situation where training data does not exist and the observations are random and sparse.","sentences":["In applications, an anticipated situation is where the system of interest has never been encountered before and sparse observations can be made only once.","Can the dynamics be faithfully reconstructed from the limited observations without any training data?","This problem defies any known traditional methods of nonlinear time-series analysis as well as existing machine-learning methods that typically require extensive data from the target system for training.","We address this challenge by developing a hybrid transformer and reservoir-computing machine-learning scheme.","The key idea is that, for a complex and nonlinear target system, the training of the transformer can be conducted not using any data from the target system, but with essentially unlimited synthetic data from known chaotic systems.","The trained transformer is then tested with the sparse data from the target system.","The output of the transformer is further fed into a reservoir computer for predicting the long-term dynamics or the attractor of the target system.","The power of the proposed hybrid machine-learning framework is demonstrated using a large number of prototypical nonlinear dynamical systems, with high reconstruction accuracy even when the available data is only 20% of that required to faithfully represent the dynamical behavior of the underlying system.","The framework provides a paradigm of reconstructing complex and nonlinear dynamics in the extreme situation where training data does not exist and the observations are random and sparse."],"url":"http://arxiv.org/abs/2410.21222v1"}
{"created":"2024-10-28 17:04:18","title":"Vision Search Assistant: Empower Vision-Language Models as Multimodal Search Engines","abstract":"Search engines enable the retrieval of unknown information with texts. However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before. This challenge is particularly pronounced for large vision-language models (VLMs): if the model has not been exposed to the object depicted in an image, it struggles to generate reliable answers to the user's question regarding that image. Moreover, as new objects and events continuously emerge, frequently updating VLMs is impractical due to heavy computational burdens. To address this limitation, we propose Vision Search Assistant, a novel framework that facilitates collaboration between VLMs and web agents. This approach leverages VLMs' visual understanding capabilities and web agents' real-time information access to perform open-world Retrieval-Augmented Generation via the web. By integrating visual and textual representations through this collaboration, the model can provide informed responses even when the image is novel to the system. Extensive experiments conducted on both open-set and closed-set QA benchmarks demonstrate that the Vision Search Assistant significantly outperforms the other models and can be widely applied to existing VLMs.","sentences":["Search engines enable the retrieval of unknown information with texts.","However, traditional methods fall short when it comes to understanding unfamiliar visual content, such as identifying an object that the model has never seen before.","This challenge is particularly pronounced for large vision-language models (VLMs): if the model has not been exposed to the object depicted in an image, it struggles to generate reliable answers to the user's question regarding that image.","Moreover, as new objects and events continuously emerge, frequently updating VLMs is impractical due to heavy computational burdens.","To address this limitation, we propose Vision Search Assistant, a novel framework that facilitates collaboration between VLMs and web agents.","This approach leverages VLMs' visual understanding capabilities and web agents' real-time information access to perform open-world Retrieval-Augmented Generation via the web.","By integrating visual and textual representations through this collaboration, the model can provide informed responses even when the image is novel to the system.","Extensive experiments conducted on both open-set and closed-set QA benchmarks demonstrate that the Vision Search Assistant significantly outperforms the other models and can be widely applied to existing VLMs."],"url":"http://arxiv.org/abs/2410.21220v1"}
{"created":"2024-10-28 17:02:12","title":"Lifting the Veil on the Large Language Model Supply Chain: Composition, Risks, and Mitigations","abstract":"Large language models (LLM) have sparked significant impact with regard to both intelligence and productivity. In recent years, a great surge has been witnessed in the introduction of both commercial and open-source LLMs. Many businesses have adopted the LLMs into their applications to solve their own domain-specific tasks. However, integrating LLMs into specific business scenarios requires more than just utilizing the models themselves. Instead, it is a systematic process that involves substantial components, which are collectively referred to as the LLM supply chain. The LLM supply chain inherently carries risks. Therefore, it is essential to understand the types of components that may be introduced into the supply chain and the associated risks, enabling different stakeholders to implement effective mitigation measures. While some literature touches on risks associated with the LLM supply chain, there is currently no paper that explicitly defines its scope, identifies inherent risks, and examines potential mitigation strategies. As LLMs have become essential infrastructure in the new era, we believe that a thorough review of the LLM supply chain, along with its inherent risks and mitigation strategies, would be valuable for industry practitioners to avoid potential damages and losses, and enlightening for academic researchers to rethink existing approaches and explore new avenues of research. Our paper provides a comprehensive overview of the LLM supply chain, detailing the stakeholders, composing artifacts, and the supplying types. We developed taxonomies of risk types, risky actions, and mitigations related to various supply chain stakeholders and components. In summary, our work explores the technical and operational aspects of the LLM supply chain, offering valuable insights for researchers and engineers in the evolving LLM landscape.","sentences":["Large language models (LLM) have sparked significant impact with regard to both intelligence and productivity.","In recent years, a great surge has been witnessed in the introduction of both commercial and open-source LLMs.","Many businesses have adopted the LLMs into their applications to solve their own domain-specific tasks.","However, integrating LLMs into specific business scenarios requires more than just utilizing the models themselves.","Instead, it is a systematic process that involves substantial components, which are collectively referred to as the LLM supply chain.","The LLM supply chain inherently carries risks.","Therefore, it is essential to understand the types of components that may be introduced into the supply chain and the associated risks, enabling different stakeholders to implement effective mitigation measures.","While some literature touches on risks associated with the LLM supply chain, there is currently no paper that explicitly defines its scope, identifies inherent risks, and examines potential mitigation strategies.","As LLMs have become essential infrastructure in the new era, we believe that a thorough review of the LLM supply chain, along with its inherent risks and mitigation strategies, would be valuable for industry practitioners to avoid potential damages and losses, and enlightening for academic researchers to rethink existing approaches and explore new avenues of research.","Our paper provides a comprehensive overview of the LLM supply chain, detailing the stakeholders, composing artifacts, and the supplying types.","We developed taxonomies of risk types, risky actions, and mitigations related to various supply chain stakeholders and components.","In summary, our work explores the technical and operational aspects of the LLM supply chain, offering valuable insights for researchers and engineers in the evolving LLM landscape."],"url":"http://arxiv.org/abs/2410.21218v1"}
{"created":"2024-10-28 17:01:52","title":"HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation","abstract":"Many positional encodings (PEs) are designed to exhibit long-term decay, based on an entrenched and long-standing inductive opinion: tokens farther away from the current position carry less relevant information. We argue that long-term decay is outdated in the era of LLMs, as LLMs are now applied to tasks demanding precise retrieval of in-context information from arbitrary positions. Firstly, we present empirical analyses on various PEs, demonstrating that models inherently learn attention with only a local-decay pattern while forming a U-shape pattern globally, contradicting the principle of long-term decay. Furthermore, we conduct a detailed analysis of rotary position encoding (RoPE, a prevalent relative positional encoding in LLMs), and found that the U-shape attention is caused by some learned components, which are also the key factor limiting RoPE's expressiveness and extrapolation.Inspired by these insights, we propose High-frequency rotary Position Encoding (HoPE). HoPE replaces the specific components in RoPE with position-independent ones, retaining only high-frequency signals, which also breaks the principle of long-term decay in theory. HoPE achieves two major advantages: (1) Without constraints imposed by long-term decay, contradictory factors that limit spontaneous attention optimization and model extrapolation performance are removed. (2) Components representing positions and semantics are are optimized. These enhances model's context awareness and extrapolation, as validated by extensive experiments.","sentences":["Many positional encodings (PEs) are designed to exhibit long-term decay, based on an entrenched and long-standing inductive opinion: tokens farther away from the current position carry less relevant information.","We argue that long-term decay is outdated in the era of LLMs, as LLMs are now applied to tasks demanding precise retrieval of in-context information from arbitrary positions.","Firstly, we present empirical analyses on various PEs, demonstrating that models inherently learn attention with only a local-decay pattern while forming a U-shape pattern globally, contradicting the principle of long-term decay.","Furthermore, we conduct a detailed analysis of rotary position encoding (RoPE, a prevalent relative positional encoding in LLMs), and found that the U-shape attention is caused by some learned components, which are also the key factor limiting RoPE's expressiveness and extrapolation.","Inspired by these insights, we propose High-frequency rotary Position Encoding (HoPE).","HoPE replaces the specific components in RoPE with position-independent ones, retaining only high-frequency signals, which also breaks the principle of long-term decay in theory.","HoPE achieves two major advantages: (1) Without constraints imposed by long-term decay, contradictory factors that limit spontaneous attention optimization and model extrapolation performance are removed.","(2) Components representing positions and semantics are are optimized.","These enhances model's context awareness and extrapolation, as validated by extensive experiments."],"url":"http://arxiv.org/abs/2410.21216v1"}
{"created":"2024-10-28 17:00:47","title":"Policies for Fair Exchanges of Resources","abstract":"People increasingly use digital platforms to exchange resources in accordance to some policies stating what resources users offer and what they require in return. In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones. To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics. To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable. Notably, the operator for contractual implication of MuACL is not expressible in linear logic. We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL. Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens.","sentences":["People increasingly use digital platforms to exchange resources in accordance to some policies stating what resources users offer and what they require in return.","In this paper, we propose a formal model of these environments, focussing on how users' policies are defined and enforced, so ensuring that malicious users cannot take advantage of honest ones.","To that end, we introduce the declarative policy language MuAC and equip it with a formal semantics.","To determine if a resource exchange is fair, i.e., if it respects the MuAC policies in force, we introduce the non-standard logic MuACL that combines non-linear, linear and contractual aspects, and prove it decidable.","Notably, the operator for contractual implication of MuACL is not expressible in linear logic.","We define a semantics preserving compilation of MuAC policies into MuACL, thus establishing that exchange fairness is reduced to finding a proof in MuACL.","Finally, we show how this approach can be put to work on a blockchain to exchange non-fungible tokens."],"url":"http://arxiv.org/abs/2410.21214v1"}
{"created":"2024-10-28 16:56:30","title":"Exploring contextual modeling with linear complexity for point cloud segmentation","abstract":"Point cloud segmentation is an important topic in 3D understanding that has traditionally has been tackled using either the CNN or Transformer. Recently, Mamba has emerged as a promising alternative, offering efficient long-range contextual modeling capabilities without the quadratic complexity associated with Transformer's attention mechanisms. However, despite Mamba's potential, early efforts have all failed to achieve better performance than the best CNN-based and Transformer-based methods. In this work, we address this challenge by identifying the key components of an effective and efficient point cloud segmentation architecture. Specifically, we show that: 1) Spatial locality and robust contextual understanding are critical for strong performance, and 2) Mamba features linear computational complexity, offering superior data and inference efficiency compared to Transformers, while still being capable of delivering strong contextual understanding. Additionally, we further enhance the standard Mamba specifically for point cloud segmentation by identifying its two key shortcomings. First, the enforced causality in the original Mamba is unsuitable for processing point clouds that have no such dependencies. Second, its unidirectional scanning strategy imposes a directional bias, hampering its ability to capture the full context of unordered point clouds in a single pass. To address these issues, we carefully remove the causal convolutions and introduce a novel Strided Bidirectional SSM to enhance the model's capability to capture spatial relationships. Our efforts culminate in the development of a novel architecture named MEEPO, which effectively integrates the strengths of CNN and Mamba. MEEPO surpasses the previous state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple key benchmark datasets, while being 42.1% faster and 5.53x more memory efficient.","sentences":["Point cloud segmentation is an important topic in 3D understanding that has traditionally has been tackled using either the CNN or Transformer.","Recently, Mamba has emerged as a promising alternative, offering efficient long-range contextual modeling capabilities without the quadratic complexity associated with Transformer's attention mechanisms.","However, despite Mamba's potential, early efforts have all failed to achieve better performance than the best CNN-based and Transformer-based methods.","In this work, we address this challenge by identifying the key components of an effective and efficient point cloud segmentation architecture.","Specifically, we show that: 1) Spatial locality and robust contextual understanding are critical for strong performance, and 2) Mamba features linear computational complexity, offering superior data and inference efficiency compared to Transformers, while still being capable of delivering strong contextual understanding.","Additionally, we further enhance the standard Mamba specifically for point cloud segmentation by identifying its two key shortcomings.","First, the enforced causality in the original Mamba is unsuitable for processing point clouds that have no such dependencies.","Second, its unidirectional scanning strategy imposes a directional bias, hampering its ability to capture the full context of unordered point clouds in a single pass.","To address these issues, we carefully remove the causal convolutions and introduce a novel Strided Bidirectional SSM to enhance the model's capability to capture spatial relationships.","Our efforts culminate in the development of a novel architecture named MEEPO, which effectively integrates the strengths of CNN and Mamba.","MEEPO surpasses the previous state-of-the-art method, PTv3, by up to +0.8 mIoU on multiple key benchmark datasets, while being 42.1% faster and 5.53x more memory efficient."],"url":"http://arxiv.org/abs/2410.21211v1"}
{"created":"2024-10-28 16:51:50","title":"Simplest Mechanism Builder Algorithm (SiMBA): An Automated Microkinetic Model Discovery Tool","abstract":"Microkinetic models are key for evaluating industrial processes' efficiency and chemicals' environmental impact. Manual construction of these models is difficult and time-consuming, prompting a shift to automated methods. This study introduces SiMBA (Simplest Mechanism Builder Algorithm), a novel approach for generating microkinetic models from kinetic data. SiMBA operates through four phases: mechanism generation, mechanism translation, parameter estimation, and model comparison. Our approach systematically proposes reaction mechanisms, using matrix representations and a parallelized backtracking algorithm to manage complexity. These mechanisms are then translated into microkinetic models represented by ordinary differential equations, and optimized to fit available data. Models are compared using information criteria to balance accuracy and complexity, iterating until convergence to an optimal model is reached. Case studies on an aldol condensation reaction, and the dehydration of fructose demonstrate SiMBA's effectiveness in distilling complex kinetic behaviors into simple yet accurate models. While SiMBA predicts intermediates correctly for all case studies, it does not chemically identify intermediates, requiring expert input for complex systems. Despite this, SiMBA significantly enhances mechanistic exploration, offering a robust initial mechanism that accelerates the development and modeling of chemical processes.","sentences":["Microkinetic models are key for evaluating industrial processes' efficiency and chemicals' environmental impact.","Manual construction of these models is difficult and time-consuming, prompting a shift to automated methods.","This study introduces SiMBA (Simplest Mechanism Builder Algorithm), a novel approach for generating microkinetic models from kinetic data.","SiMBA operates through four phases: mechanism generation, mechanism translation, parameter estimation, and model comparison.","Our approach systematically proposes reaction mechanisms, using matrix representations and a parallelized backtracking algorithm to manage complexity.","These mechanisms are then translated into microkinetic models represented by ordinary differential equations, and optimized to fit available data.","Models are compared using information criteria to balance accuracy and complexity, iterating until convergence to an optimal model is reached.","Case studies on an aldol condensation reaction, and the dehydration of fructose demonstrate SiMBA's effectiveness in distilling complex kinetic behaviors into simple yet accurate models.","While SiMBA predicts intermediates correctly for all case studies, it does not chemically identify intermediates, requiring expert input for complex systems.","Despite this, SiMBA significantly enhances mechanistic exploration, offering a robust initial mechanism that accelerates the development and modeling of chemical processes."],"url":"http://arxiv.org/abs/2410.21205v1"}
{"created":"2024-10-28 16:49:03","title":"SeriesGAN: Time Series Generation via Adversarial and Autoregressive Learning","abstract":"Current Generative Adversarial Network (GAN)-based approaches for time series generation face challenges such as suboptimal convergence, information loss in embedding spaces, and instability. To overcome these challenges, we introduce an advanced framework that integrates the advantages of an autoencoder-generated embedding space with the adversarial training dynamics of GANs. This method employs two discriminators: one to specifically guide the generator and another to refine both the autoencoder's and generator's output. Additionally, our framework incorporates a novel autoencoder-based loss function and supervision from a teacher-forcing supervisor network, which captures the stepwise conditional distributions of the data. The generator operates within the latent space, while the two discriminators work on latent and feature spaces separately, providing crucial feedback to both the generator and the autoencoder. By leveraging this dual-discriminator approach, we minimize information loss in the embedding space. Through joint training, our framework excels at generating high-fidelity time series data, consistently outperforming existing state-of-the-art benchmarks both qualitatively and quantitatively across a range of real and synthetic multivariate time series datasets.","sentences":["Current Generative Adversarial Network (GAN)-based approaches for time series generation face challenges such as suboptimal convergence, information loss in embedding spaces, and instability.","To overcome these challenges, we introduce an advanced framework that integrates the advantages of an autoencoder-generated embedding space with the adversarial training dynamics of GANs.","This method employs two discriminators: one to specifically guide the generator and another to refine both the autoencoder's and generator's output.","Additionally, our framework incorporates a novel autoencoder-based loss function and supervision from a teacher-forcing supervisor network, which captures the stepwise conditional distributions of the data.","The generator operates within the latent space, while the two discriminators work on latent and feature spaces separately, providing crucial feedback to both the generator and the autoencoder.","By leveraging this dual-discriminator approach, we minimize information loss in the embedding space.","Through joint training, our framework excels at generating high-fidelity time series data, consistently outperforming existing state-of-the-art benchmarks both qualitatively and quantitatively across a range of real and synthetic multivariate time series datasets."],"url":"http://arxiv.org/abs/2410.21203v1"}
{"created":"2024-10-28 16:44:02","title":"BongLLaMA: LLaMA for Bangla Language","abstract":"Bangla (or \"Bengali\") is a language spoken by approximately 240 million native speakers and around 300 million people worldwide. Despite being the 5th largest spoken language in the world, Bangla is still a \"low-resource\" language, and existing pretrained language models often struggle to perform well on Bangla Language Processing (BLP) tasks. This work addresses this gap by introducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model fine-tuned exclusively on large Bangla corpora and instruction-tuning datasets. We present our methodology, data augmentation techniques, fine-tuning details, and comprehensive benchmarking results showcasing the utility of BongLLaMA on BLP tasks. We believe BongLLaMA will serve as the new standard baseline for Bangla Language Models and, thus, facilitate future benchmarking studies focused on this widely-spoken yet \"low-resource\" language. All BongLLaMA models are available for public use at https://huggingface.co/BanglaLLM.","sentences":["Bangla (or \"Bengali\") is a language spoken by approximately 240 million native speakers and around 300 million people worldwide.","Despite being the 5th largest spoken language in the world, Bangla is still a \"low-resource\" language, and existing pretrained language models often struggle to perform well on Bangla Language Processing (BLP) tasks.","This work addresses this gap by introducing BongLLaMA (i.e., Bangla-LLaMA), an open-source large language model fine-tuned exclusively on large Bangla corpora and instruction-tuning datasets.","We present our methodology, data augmentation techniques, fine-tuning details, and comprehensive benchmarking results showcasing the utility of BongLLaMA on BLP tasks.","We believe BongLLaMA will serve as the new standard baseline for Bangla Language Models and, thus, facilitate future benchmarking studies focused on this widely-spoken yet \"low-resource\" language.","All BongLLaMA models are available for public use at https://huggingface.co/BanglaLLM."],"url":"http://arxiv.org/abs/2410.21200v1"}
{"created":"2024-10-28 16:39:38","title":"User-Centered Design of Socially Assistive Robotic Combined with Non-Immersive Virtual Reality-based Dyadic Activities for Older Adults Residing in Long Term Care Facilities","abstract":"Apathy impairs the quality of life for older adults and their care providers. While few pharmacological remedies exist, current non-pharmacologic approaches are resource intensive. To address these concerns, this study utilizes a user-centered design (UCD) process to develop and test a set of dyadic activities that provide physical, cognitive, and social stimuli to older adults residing in long-term care (LTC) communities. Within the design, a novel framework that combines socially assistive robots and non-immersive virtual reality (SAR-VR) emphasizing human-robot interaction (HRI) and human-computer interaction (HCI) is utilized with the roles of the robots being coach and entertainer. An interdisciplinary team of engineers, nurses, and physicians collaborated with an advisory panel comprising LTC activity coordinators, staff, and residents to prototype the activities. The study resulted in four virtual activities: three with the humanoid robot, Nao, and one with the animal robot, Aibo. Fourteen participants tested the acceptability of the different components of the system and provided feedback at different stages of development. Participant approval increased significantly over successive iterations of the system highlighting the importance of stakeholder feedback. Five LTC staff members successfully set up the system with minimal help from the researchers, demonstrating the usability of the system for caregivers. Rationale for activity selection, design changes, and both quantitative and qualitative results on the acceptability and usability of the system have been presented. The paper discusses the challenges encountered in developing activities for older adults in LTCs and underscores the necessity of the UCD process to address them.","sentences":["Apathy impairs the quality of life for older adults and their care providers.","While few pharmacological remedies exist, current non-pharmacologic approaches are resource intensive.","To address these concerns, this study utilizes a user-centered design (UCD) process to develop and test a set of dyadic activities that provide physical, cognitive, and social stimuli to older adults residing in long-term care (LTC) communities.","Within the design, a novel framework that combines socially assistive robots and non-immersive virtual reality (SAR-VR) emphasizing human-robot interaction (HRI) and human-computer interaction (HCI) is utilized with the roles of the robots being coach and entertainer.","An interdisciplinary team of engineers, nurses, and physicians collaborated with an advisory panel comprising LTC activity coordinators, staff, and residents to prototype the activities.","The study resulted in four virtual activities: three with the humanoid robot, Nao, and one with the animal robot, Aibo.","Fourteen participants tested the acceptability of the different components of the system and provided feedback at different stages of development.","Participant approval increased significantly over successive iterations of the system highlighting the importance of stakeholder feedback.","Five LTC staff members successfully set up the system with minimal help from the researchers, demonstrating the usability of the system for caregivers.","Rationale for activity selection, design changes, and both quantitative and qualitative results on the acceptability and usability of the system have been presented.","The paper discusses the challenges encountered in developing activities for older adults in LTCs and underscores the necessity of the UCD process to address them."],"url":"http://arxiv.org/abs/2410.21197v1"}
{"created":"2024-10-28 16:38:20","title":"Belief in the Machine: Investigating Epistemological Blind Spots of Language Models","abstract":"As language models (LMs) become integral to fields like healthcare, law, and journalism, their ability to differentiate between fact, belief, and knowledge is essential for reliable decision-making. Failure to grasp these distinctions can lead to significant consequences in areas such as medical diagnosis, legal judgments, and dissemination of fake news. Despite this, current literature has largely focused on more complex issues such as theory of mind, overlooking more fundamental epistemic challenges. This study systematically evaluates the epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13 tasks. Our results reveal key limitations. First, while LMs achieve 86% accuracy on factual scenarios, their performance drops significantly with false scenarios, particularly in belief-related tasks. Second, LMs struggle with recognizing and affirming personal beliefs, especially when those beliefs contradict factual data, which raises concerns for applications in healthcare and counseling, where engaging with a person's beliefs is critical. Third, we identify a salient bias in how LMs process first-person versus third-person beliefs, performing better on third-person tasks (80.7%) compared to first-person tasks (54.4%). Fourth, LMs lack a robust understanding of the factive nature of knowledge, namely, that knowledge inherently requires truth. Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the deeper reasoning. These findings highlight significant concerns about current LMs' ability to reason about truth, belief, and knowledge while emphasizing the need for advancements in these areas before broad deployment in critical sectors.","sentences":["As language models (LMs) become integral to fields like healthcare, law, and journalism, their ability to differentiate between fact, belief, and knowledge is essential for reliable decision-making.","Failure to grasp these distinctions can lead to significant consequences in areas such as medical diagnosis, legal judgments, and dissemination of fake news.","Despite this, current literature has largely focused on more complex issues such as theory of mind, overlooking more fundamental epistemic challenges.","This study systematically evaluates the epistemic reasoning capabilities of modern LMs, including GPT-4, Claude-3, and Llama-3, using a new dataset, KaBLE, consisting of 13,000 questions across 13 tasks.","Our results reveal key limitations.","First, while LMs achieve 86% accuracy on factual scenarios, their performance drops significantly with false scenarios, particularly in belief-related tasks.","Second, LMs struggle with recognizing and affirming personal beliefs, especially when those beliefs contradict factual data, which raises concerns for applications in healthcare and counseling, where engaging with a person's beliefs is critical.","Third, we identify a salient bias in how LMs process first-person versus third-person beliefs, performing better on third-person tasks (80.7%) compared to first-person tasks (54.4%).","Fourth, LMs lack a robust understanding of the factive nature of knowledge, namely, that knowledge inherently requires truth.","Fifth, LMs rely on linguistic cues for fact-checking and sometimes bypass the deeper reasoning.","These findings highlight significant concerns about current LMs' ability to reason about truth, belief, and knowledge while emphasizing the need for advancements in these areas before broad deployment in critical sectors."],"url":"http://arxiv.org/abs/2410.21195v1"}
{"created":"2024-10-28 16:36:58","title":"SoS Certifiability of Subgaussian Distributions and its Algorithmic Applications","abstract":"We prove that there is a universal constant $C>0$ so that for every $d \\in \\mathbb N$, every centered subgaussian distribution $\\mathcal D$ on $\\mathbb R^d$, and every even $p \\in \\mathbb N$, the $d$-variate polynomial $(Cp)^{p/2} \\cdot \\|v\\|_{2}^p - \\mathbb E_{X \\sim \\mathcal D} \\langle v,X\\rangle^p$ is a sum of square polynomials. This establishes that every subgaussian distribution is \\emph{SoS-certifiably subgaussian} -- a condition that yields efficient learning algorithms for a wide variety of high-dimensional statistical tasks. As a direct corollary, we obtain computationally efficient algorithms with near-optimal guarantees for the following tasks, when given samples from an arbitrary subgaussian distribution: robust mean estimation, list-decodable mean estimation, clustering mean-separated mixture models, robust covariance-aware mean estimation, robust covariance estimation, and robust linear regression. Our proof makes essential use of Talagrand's generic chaining/majorizing measures theorem.","sentences":["We prove that there is a universal constant $C>0$ so that for every $d \\in \\mathbb N$, every centered subgaussian distribution $\\mathcal D$ on $\\mathbb R^d$, and every even $p \\in \\mathbb N$, the $d$-variate polynomial $(Cp)^{p/2} \\cdot \\|v\\|_{2}^p - \\mathbb E_{X \\sim \\mathcal D} \\langle v,X\\rangle^p$ is a sum of square polynomials.","This establishes that every subgaussian distribution is \\emph{SoS-certifiably subgaussian} -- a condition that yields efficient learning algorithms for a wide variety of high-dimensional statistical tasks.","As a direct corollary, we obtain computationally efficient algorithms with near-optimal guarantees for the following tasks, when given samples from an arbitrary subgaussian distribution: robust mean estimation, list-decodable mean estimation, clustering mean-separated mixture models, robust covariance-aware mean estimation, robust covariance estimation, and robust linear regression.","Our proof makes essential use of Talagrand's generic chaining/majorizing measures theorem."],"url":"http://arxiv.org/abs/2410.21194v1"}
{"created":"2024-10-28 16:35:40","title":"On Homomorphic Encryption Based Strategies for Class Imbalance in Federated Learning","abstract":"Class imbalance in training datasets can lead to bias and poor generalization in machine learning models. While pre-processing of training datasets can efficiently address both these issues in centralized learning environments, it is challenging to detect and address these issues in a distributed learning environment such as federated learning. In this paper, we propose FLICKER, a privacy preserving framework to address issues related to global class imbalance in federated learning. At the heart of our contribution lies the popular CKKS homomorphic encryption scheme, which is used by the clients to privately share their data attributes, and subsequently balance their datasets before implementing the FL scheme. Extensive experimental results show that our proposed method significantly improves the FL accuracy numbers when used along with popular datasets and relevant baselines.","sentences":["Class imbalance in training datasets can lead to bias and poor generalization in machine learning models.","While pre-processing of training datasets can efficiently address both these issues in centralized learning environments, it is challenging to detect and address these issues in a distributed learning environment such as federated learning.","In this paper, we propose FLICKER, a privacy preserving framework to address issues related to global class imbalance in federated learning.","At the heart of our contribution lies the popular CKKS homomorphic encryption scheme, which is used by the clients to privately share their data attributes, and subsequently balance their datasets before implementing the FL scheme.","Extensive experimental results show that our proposed method significantly improves the FL accuracy numbers when used along with popular datasets and relevant baselines."],"url":"http://arxiv.org/abs/2410.21192v1"}
{"created":"2024-10-28 16:31:58","title":"Soundness Correction of Data Petri Nets","abstract":"A process model is called sound if it always terminates properly and each model activity can occur in a process instance. Conducting soundness verification right after process design allows to detect and eliminate design errors in a process to be implemented. Deadlocks, livelocks, and unlimited resource growth are examples of critical design errors that must be addressed before process implementation.However, eliminating such failure points is usually a time-consuming and error-prone task even for modeling experts. This task becomes even more complicated in a data-aware setting when both control and data flows are represented in a model. In this paper, we introduce an algorithm that allows to repair soundness property of data-aware process models, represented as data Petri nets (DPNs), that preserves the correct behavior of the source model. In DPNs, each transition is associated with a guard that includes input and output conditions on process variables.Our algorithm restricts transition guards of a DPN so that executions that previously led to improper termination become prohibited.The algorithm does not require the underlying control flow of the net to be sound and can be applied to the models that have at least one execution leading to the final marking. The algorithm is implemented and results of the preliminary evaluation demonstrate its applicability on process models of moderate sizes.","sentences":["A process model is called sound if it always terminates properly and each model activity can occur in a process instance.","Conducting soundness verification right after process design allows to detect and eliminate design errors in a process to be implemented.","Deadlocks, livelocks, and unlimited resource growth are examples of critical design errors that must be addressed before process implementation.","However, eliminating such failure points is usually a time-consuming and error-prone task even for modeling experts.","This task becomes even more complicated in a data-aware setting when both control and data flows are represented in a model.","In this paper, we introduce an algorithm that allows to repair soundness property of data-aware process models, represented as data Petri nets (DPNs), that preserves the correct behavior of the source model.","In DPNs, each transition is associated with a guard that includes input and output conditions on process variables.","Our algorithm restricts transition guards of a DPN so that executions that previously led to improper termination become prohibited.","The algorithm does not require the underlying control flow of the net to be sound and can be applied to the models that have at least one execution leading to the final marking.","The algorithm is implemented and results of the preliminary evaluation demonstrate its applicability on process models of moderate sizes."],"url":"http://arxiv.org/abs/2410.21188v1"}
{"created":"2024-10-28 16:25:34","title":"Efficiency Optimization of a Two-link Planar Robotic Arm","abstract":"Energy consumption optimization of a two-link planar robotic arm is considered with the system's efficiency being the target for optimization. A new formulation of thermodynamic principles within the framework of dynamical systems is used. This approach is applied by considering cyclic motions for the robotic arm and analyzing the cyclic averaged energies while the robotic arm is tasked with going from point A to point B in the task space while resisting an external force. The energy transfer rate between the links is classified into positive and negative and the results combined with the averaged energy quantities, are used to address the optimization problem while adhering to the constraints imposed by the second law of thermodynamics in its new formulation.","sentences":["Energy consumption optimization of a two-link planar robotic arm is considered with the system's efficiency being the target for optimization.","A new formulation of thermodynamic principles within the framework of dynamical systems is used.","This approach is applied by considering cyclic motions for the robotic arm and analyzing the cyclic averaged energies while the robotic arm is tasked with going from point A to point B in the task space while resisting an external force.","The energy transfer rate between the links is classified into positive and negative and the results combined with the averaged energy quantities, are used to address the optimization problem while adhering to the constraints imposed by the second law of thermodynamics in its new formulation."],"url":"http://arxiv.org/abs/2410.21185v1"}
{"created":"2024-10-28 16:23:53","title":"Towards Human-centered Design of Explainable Artificial Intelligence (XAI): A Survey of Empirical Studies","abstract":"With the advances of AI research, AI has been increasingly adopted in numerous domains, ranging from low-stakes daily tasks such as movie recommendations to high-stakes tasks such as medicine, and criminal justice decision-making. Explainability is becoming an essential requirement for people to understand, trust and adopt AI applications.   Despite a vast collection of explainable AI (XAI) algorithms produced by the AI research community, successful examples of XAI are still relatively scarce in real-world AI applications. This can be due to the gap between what the XAI is designed for and how the XAI is actually perceived by end-users. As explainability is an inherently human-centered property, in recent years, the XAI field is starting to embrace human-centered approaches and increasingly realizing the importance of empirical studies of XAI design by involving human subjects.   To move a step towards a systematic review of empirical study for human-centered XAI design, in this survey, we first brief the technical landscape of commonly used XAI algorithms in existing empirical studies. Then we analyze the diverse stakeholders and needs-finding approaches. Next, we provide an overview of the design space explored in the current human-centered XAI design. Further, we summarize the evaluation metrics based on evaluation goals. Afterward, we analyze the common findings and pitfalls derived from existing studies. For each chapter, we provide a summary of current challenges and research opportunities. Finally, we conclude the survey with a framework for human-centered XAI design with empirical studies.","sentences":["With the advances of AI research, AI has been increasingly adopted in numerous domains, ranging from low-stakes daily tasks such as movie recommendations to high-stakes tasks such as medicine, and criminal justice decision-making.","Explainability is becoming an essential requirement for people to understand, trust and adopt AI applications.   ","Despite a vast collection of explainable AI (XAI) algorithms produced by the AI research community, successful examples of XAI are still relatively scarce in real-world AI applications.","This can be due to the gap between what the XAI is designed for and how the XAI is actually perceived by end-users.","As explainability is an inherently human-centered property, in recent years, the XAI field is starting to embrace human-centered approaches and increasingly realizing the importance of empirical studies of XAI design by involving human subjects.   ","To move a step towards a systematic review of empirical study for human-centered XAI design, in this survey, we first brief the technical landscape of commonly used XAI algorithms in existing empirical studies.","Then we analyze the diverse stakeholders and needs-finding approaches.","Next, we provide an overview of the design space explored in the current human-centered XAI design.","Further, we summarize the evaluation metrics based on evaluation goals.","Afterward, we analyze the common findings and pitfalls derived from existing studies.","For each chapter, we provide a summary of current challenges and research opportunities.","Finally, we conclude the survey with a framework for human-centered XAI design with empirical studies."],"url":"http://arxiv.org/abs/2410.21183v1"}
{"created":"2024-10-28 16:20:01","title":"Unharmful Backdoor-based Client-side Watermarking in Federated Learning","abstract":"Protecting intellectual property (IP) in federated learning (FL) is increasingly important as clients contribute proprietary data to collaboratively train models. Model watermarking, particularly through backdoor-based methods, has emerged as a popular approach for verifying ownership and contributions in deep neural networks trained via FL. By manipulating their datasets, clients can embed a secret pattern, resulting in non-intuitive predictions that serve as proof of participation, useful for claiming incentives or IP co-ownership. However, this technique faces practical challenges: client watermarks can collide, leading to ambiguous ownership claims, and malicious clients may exploit watermarks to inject harmful backdoors, jeopardizing model integrity. To address these issues, we propose Sanitizer, a server-side method that ensures client-embedded backdoors cannot be triggered on natural queries in harmful ways. It identifies subnets within client-submitted models, extracts backdoors throughout the FL process, and confines them to harmless, client-specific input subspaces. This approach not only enhances Sanitizer's efficiency but also resolves conflicts when clients use similar triggers with different target labels. Our empirical results demonstrate that Sanitizer achieves near-perfect success in verifying client contributions while mitigating the risks of malicious watermark use. Additionally, it reduces GPU memory consumption by 85% and cuts processing time by at least 5 times compared to the baseline.","sentences":["Protecting intellectual property (IP) in federated learning (FL) is increasingly important as clients contribute proprietary data to collaboratively train models.","Model watermarking, particularly through backdoor-based methods, has emerged as a popular approach for verifying ownership and contributions in deep neural networks trained via FL.","By manipulating their datasets, clients can embed a secret pattern, resulting in non-intuitive predictions that serve as proof of participation, useful for claiming incentives or IP co-ownership.","However, this technique faces practical challenges: client watermarks can collide, leading to ambiguous ownership claims, and malicious clients may exploit watermarks to inject harmful backdoors, jeopardizing model integrity.","To address these issues, we propose Sanitizer, a server-side method that ensures client-embedded backdoors cannot be triggered on natural queries in harmful ways.","It identifies subnets within client-submitted models, extracts backdoors throughout the FL process, and confines them to harmless, client-specific input subspaces.","This approach not only enhances Sanitizer's efficiency but also resolves conflicts when clients use similar triggers with different target labels.","Our empirical results demonstrate that Sanitizer achieves near-perfect success in verifying client contributions while mitigating the risks of malicious watermark use.","Additionally, it reduces GPU memory consumption by 85% and cuts processing time by at least 5 times compared to the baseline."],"url":"http://arxiv.org/abs/2410.21179v1"}
{"created":"2024-10-28 16:17:07","title":"Privacy-Preserving for Images in Satellite Communications: A Comprehensive Review of Chaos-Based Encryption","abstract":"In an era where global connectivity has become critical, satellite communication is essential for businesses, governments, and individuals. Widely used services with satellite communication such as climate change monitoring, military surveillance and real-time event broadcasting, involve data in the form of images rather text. Therefore, securing image transmission in satellite communication using efficient and effective encryption approaches, has gained a significant attention from academia as well as the industry. In this paper, we specifically focus on chaos based image encryption as one of the key privacy-preserving techniques for satellite communication. While there are several privacy enhancing techniques for protecting image data but chaos based encryption has distinct advantages such as high flexibility, high security, less computational overheads, less computing power and ease of implementation. First, we present a solid background about satellite communication and image encryption in satellite communication, covering theoretical aspects of chaotic systems and their practical usage for image encryption. Next we present a comprehensive literature review on all state-of-the-art studies specifically for chaos based satellite image encryption, with a detailed analysis of the evaluation process, including evaluation parameters and conditions. Finally, we discuss about existing challenges and open research problems for chaos based satellite image encryption.","sentences":["In an era where global connectivity has become critical, satellite communication is essential for businesses, governments, and individuals.","Widely used services with satellite communication such as climate change monitoring, military surveillance and real-time event broadcasting, involve data in the form of images rather text.","Therefore, securing image transmission in satellite communication using efficient and effective encryption approaches, has gained a significant attention from academia as well as the industry.","In this paper, we specifically focus on chaos based image encryption as one of the key privacy-preserving techniques for satellite communication.","While there are several privacy enhancing techniques for protecting image data but chaos based encryption has distinct advantages such as high flexibility, high security, less computational overheads, less computing power and ease of implementation.","First, we present a solid background about satellite communication and image encryption in satellite communication, covering theoretical aspects of chaotic systems and their practical usage for image encryption.","Next we present a comprehensive literature review on all state-of-the-art studies specifically for chaos based satellite image encryption, with a detailed analysis of the evaluation process, including evaluation parameters and conditions.","Finally, we discuss about existing challenges and open research problems for chaos based satellite image encryption."],"url":"http://arxiv.org/abs/2410.21177v1"}
{"created":"2024-10-28 16:16:15","title":"Deep Learning-Based Fatigue Cracks Detection in Bridge Girders using Feature Pyramid Networks","abstract":"For structural health monitoring, continuous and automatic crack detection has been a challenging problem. This study is conducted to propose a framework of automatic crack segmentation from high-resolution images containing crack information about steel box girders of bridges. Considering the multi-scale feature of cracks, convolutional neural network architecture of Feature Pyramid Networks (FPN) for crack detection is proposed. As for input, 120 raw images are processed via two approaches (shrinking the size of images and splitting images into sub-images). Then, models with the proposed structure of FPN for crack detection are developed. The result shows all developed models can automatically detect the cracks at the raw images. By shrinking the images, the computation efficiency is improved without decreasing accuracy. Because of the separable characteristic of crack, models using the splitting method provide more accurate crack segmentations than models using the resizing method. Therefore, for high-resolution images, the FPN structure coupled with the splitting method is an promising solution for the crack segmentation and detection.","sentences":["For structural health monitoring, continuous and automatic crack detection has been a challenging problem.","This study is conducted to propose a framework of automatic crack segmentation from high-resolution images containing crack information about steel box girders of bridges.","Considering the multi-scale feature of cracks, convolutional neural network architecture of Feature Pyramid Networks (FPN) for crack detection is proposed.","As for input, 120 raw images are processed via two approaches (shrinking the size of images and splitting images into sub-images).","Then, models with the proposed structure of FPN for crack detection are developed.","The result shows all developed models can automatically detect the cracks at the raw images.","By shrinking the images, the computation efficiency is improved without decreasing accuracy.","Because of the separable characteristic of crack, models using the splitting method provide more accurate crack segmentations than models using the resizing method.","Therefore, for high-resolution images, the FPN structure coupled with the splitting method is an promising solution for the crack segmentation and detection."],"url":"http://arxiv.org/abs/2410.21175v1"}
{"created":"2024-10-28 16:13:44","title":"Joint Audio-Visual Idling Vehicle Detection with Streamlined Input Dependencies","abstract":"Idling vehicle detection (IVD) can be helpful in monitoring and reducing unnecessary idling and can be integrated into real-time systems to address the resulting pollution and harmful products. The previous approach [13], a non-end-to-end model, requires extra user clicks to specify a part of the input, making system deployment more error-prone or even not feasible. In contrast, we introduce an end-to-end joint audio-visual IVD task designed to detect vehicles visually under three states: moving, idling and engine off. Unlike feature co-occurrence task such as audio-visual vehicle tracking, our IVD task addresses complementary features, where labels cannot be determined by a single modality alone. To this end, we propose AVIVD-Net, a novel network that integrates audio and visual features through a bidirectional attention mechanism. AVIVD-Net streamlines the input process by learning a joint feature space, reducing the deployment complexity of previous methods. Additionally, we introduce the AVIVD dataset, which is seven times larger than previous datasets, offering significantly more annotated samples to study the IVD problem. Our model achieves performance comparable to prior approaches, making it suitable for automated deployment. Furthermore, by evaluating AVIVDNet on the feature co-occurrence public dataset MAVD [23], we demonstrate its potential for extension to self-driving vehicle video-camera setups.","sentences":["Idling vehicle detection (IVD) can be helpful in monitoring and reducing unnecessary idling and can be integrated into real-time systems to address the resulting pollution and harmful products.","The previous approach [13], a non-end-to-end model, requires extra user clicks to specify a part of the input, making system deployment more error-prone or even not feasible.","In contrast, we introduce an end-to-end joint audio-visual IVD task designed to detect vehicles visually under three states: moving, idling and engine off.","Unlike feature co-occurrence task such as audio-visual vehicle tracking, our IVD task addresses complementary features, where labels cannot be determined by a single modality alone.","To this end, we propose AVIVD-Net, a novel network that integrates audio and visual features through a bidirectional attention mechanism.","AVIVD-Net streamlines the input process by learning a joint feature space, reducing the deployment complexity of previous methods.","Additionally, we introduce the AVIVD dataset, which is seven times larger than previous datasets, offering significantly more annotated samples to study the IVD problem.","Our model achieves performance comparable to prior approaches, making it suitable for automated deployment.","Furthermore, by evaluating AVIVDNet on the feature co-occurrence public dataset MAVD","[23], we demonstrate its potential for extension to self-driving vehicle video-camera setups."],"url":"http://arxiv.org/abs/2410.21170v1"}
{"created":"2024-10-28 16:11:35","title":"Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction","abstract":"Document parsing is essential for converting unstructured and semi-structured documents-such as contracts, academic papers, and invoices-into structured, machine-readable data. Document parsing extract reliable structured data from unstructured inputs, providing huge convenience for numerous applications. Especially with recent achievements in Large Language Models, document parsing plays an indispensable role in both knowledge base construction and training data generation. This survey presents a comprehensive review of the current state of document parsing, covering key methodologies, from modular pipeline systems to end-to-end models driven by large vision-language models. Core components such as layout detection, content extraction (including text, tables, and mathematical expressions), and multi-modal data integration are examined in detail. Additionally, this paper discusses the challenges faced by modular document parsing systems and vision-language models in handling complex layouts, integrating multiple modules, and recognizing high-density text. It emphasizes the importance of developing larger and more diverse datasets and outlines future research directions.","sentences":["Document parsing is essential for converting unstructured and semi-structured documents-such as contracts, academic papers, and invoices-into structured, machine-readable data.","Document parsing extract reliable structured data from unstructured inputs, providing huge convenience for numerous applications.","Especially with recent achievements in Large Language Models, document parsing plays an indispensable role in both knowledge base construction and training data generation.","This survey presents a comprehensive review of the current state of document parsing, covering key methodologies, from modular pipeline systems to end-to-end models driven by large vision-language models.","Core components such as layout detection, content extraction (including text, tables, and mathematical expressions), and multi-modal data integration are examined in detail.","Additionally, this paper discusses the challenges faced by modular document parsing systems and vision-language models in handling complex layouts, integrating multiple modules, and recognizing high-density text.","It emphasizes the importance of developing larger and more diverse datasets and outlines future research directions."],"url":"http://arxiv.org/abs/2410.21169v1"}
{"created":"2024-10-28 16:04:58","title":"Differentially Private Learned Indexes","abstract":"In this paper, we address the problem of efficiently answering predicate queries on encrypted databases, those secured by Trusted Execution Environments (TEEs), which enable untrusted providers to process encrypted user data without revealing its contents. A common strategy in modern databases to accelerate predicate queries is the use of indexes, which map attribute values (keys) to their corresponding positions in a sorted data array. This allows for fast lookup and retrieval of data subsets that satisfy specific predicates. Unfortunately, indexes cannot be directly applied to encrypted databases due to strong data dependent leakages. Recent approaches apply differential privacy (DP) to construct noisy indexes that enable faster access to encrypted data while maintaining provable privacy guarantees. However, these methods often suffer from large storage costs, with index sizes typically scaling linearly with the key space. To address this challenge, we propose leveraging learned indexes, a trending technique that repurposes machine learning models as indexing structures, to build more compact DP indexes.","sentences":["In this paper, we address the problem of efficiently answering predicate queries on encrypted databases, those secured by Trusted Execution Environments (TEEs), which enable untrusted providers to process encrypted user data without revealing its contents.","A common strategy in modern databases to accelerate predicate queries is the use of indexes, which map attribute values (keys) to their corresponding positions in a sorted data array.","This allows for fast lookup and retrieval of data subsets that satisfy specific predicates.","Unfortunately, indexes cannot be directly applied to encrypted databases due to strong data dependent leakages.","Recent approaches apply differential privacy (DP) to construct noisy indexes that enable faster access to encrypted data while maintaining provable privacy guarantees.","However, these methods often suffer from large storage costs, with index sizes typically scaling linearly with the key space.","To address this challenge, we propose leveraging learned indexes, a trending technique that repurposes machine learning models as indexing structures, to build more compact DP indexes."],"url":"http://arxiv.org/abs/2410.21164v1"}
{"created":"2024-10-28 16:04:22","title":"Resilience in Knowledge Graph Embeddings","abstract":"In recent years, knowledge graphs have gained interest and witnessed widespread applications in various domains, such as information retrieval, question-answering, recommendation systems, amongst others. Large-scale knowledge graphs to this end have demonstrated their utility in effectively representing structured knowledge. To further facilitate the application of machine learning techniques, knowledge graph embedding (KGE) models have been developed. Such models can transform entities and relationships within knowledge graphs into vectors. However, these embedding models often face challenges related to noise, missing information, distribution shift, adversarial attacks, etc. This can lead to sub-optimal embeddings and incorrect inferences, thereby negatively impacting downstream applications. While the existing literature has focused so far on adversarial attacks on KGE models, the challenges related to the other critical aspects remain unexplored. In this paper, we, first of all, give a unified definition of resilience, encompassing several factors such as generalisation, performance consistency, distribution adaption, and robustness. After formalizing these concepts for machine learning in general, we define them in the context of knowledge graphs. To find the gap in the existing works on resilience in the context of knowledge graphs, we perform a systematic survey, taking into account all these aspects mentioned previously. Our survey results show that most of the existing works focus on a specific aspect of resilience, namely robustness. After categorizing such works based on their respective aspects of resilience, we discuss the challenges and future research directions.","sentences":["In recent years, knowledge graphs have gained interest and witnessed widespread applications in various domains, such as information retrieval, question-answering, recommendation systems, amongst others.","Large-scale knowledge graphs to this end have demonstrated their utility in effectively representing structured knowledge.","To further facilitate the application of machine learning techniques, knowledge graph embedding (KGE) models have been developed.","Such models can transform entities and relationships within knowledge graphs into vectors.","However, these embedding models often face challenges related to noise, missing information, distribution shift, adversarial attacks, etc.","This can lead to sub-optimal embeddings and incorrect inferences, thereby negatively impacting downstream applications.","While the existing literature has focused so far on adversarial attacks on KGE models, the challenges related to the other critical aspects remain unexplored.","In this paper, we, first of all, give a unified definition of resilience, encompassing several factors such as generalisation, performance consistency, distribution adaption, and robustness.","After formalizing these concepts for machine learning in general, we define them in the context of knowledge graphs.","To find the gap in the existing works on resilience in the context of knowledge graphs, we perform a systematic survey, taking into account all these aspects mentioned previously.","Our survey results show that most of the existing works focus on a specific aspect of resilience, namely robustness.","After categorizing such works based on their respective aspects of resilience, we discuss the challenges and future research directions."],"url":"http://arxiv.org/abs/2410.21163v1"}
{"created":"2024-10-28 15:59:31","title":"CURATe: Benchmarking Personalised Alignment of Conversational AI Assistants","abstract":"We introduce a multi-turn benchmark for evaluating personalised alignment in LLM-based AI assistants, focusing on their ability to handle user-provided safety-critical contexts. Our assessment of ten leading models across five scenarios (each with 337 use cases) reveals systematic inconsistencies in maintaining user-specific consideration, with even top-rated \"harmless\" models making recommendations that should be recognised as obviously harmful to the user given the context provided. Key failure modes include inappropriate weighing of conflicting preferences, sycophancy (prioritising user preferences above safety), a lack of attentiveness to critical user information within the context window, and inconsistent application of user-specific knowledge. The same systematic biases were observed in OpenAI's o1, suggesting that strong reasoning capacities do not necessarily transfer to this kind of personalised thinking. We find that prompting LLMs to consider safety-critical context significantly improves performance, unlike a generic 'harmless and helpful' instruction. Based on these findings, we propose research directions for embedding self-reflection capabilities, online user modelling, and dynamic risk assessment in AI assistants. Our work emphasises the need for nuanced, context-aware approaches to alignment in systems designed for persistent human interaction, aiding the development of safe and considerate AI assistants.","sentences":["We introduce a multi-turn benchmark for evaluating personalised alignment in LLM-based AI assistants, focusing on their ability to handle user-provided safety-critical contexts.","Our assessment of ten leading models across five scenarios (each with 337 use cases) reveals systematic inconsistencies in maintaining user-specific consideration, with even top-rated \"harmless\" models making recommendations that should be recognised as obviously harmful to the user given the context provided.","Key failure modes include inappropriate weighing of conflicting preferences, sycophancy (prioritising user preferences above safety), a lack of attentiveness to critical user information within the context window, and inconsistent application of user-specific knowledge.","The same systematic biases were observed in OpenAI's o1, suggesting that strong reasoning capacities do not necessarily transfer to this kind of personalised thinking.","We find that prompting LLMs to consider safety-critical context significantly improves performance, unlike a generic 'harmless and helpful' instruction.","Based on these findings, we propose research directions for embedding self-reflection capabilities, online user modelling, and dynamic risk assessment in AI assistants.","Our work emphasises the need for nuanced, context-aware approaches to alignment in systems designed for persistent human interaction, aiding the development of safe and considerate AI assistants."],"url":"http://arxiv.org/abs/2410.21159v1"}
{"created":"2024-10-28 15:58:41","title":"M2rc-Eval: Massively Multilingual Repository-level Code Completion Evaluation","abstract":"Repository-level code completion has drawn great attention in software engineering, and several benchmark datasets have been introduced. However, existing repository-level code completion benchmarks usually focus on a limited number of languages (<5), which cannot evaluate the general code intelligence abilities across different languages for existing code Large Language Models (LLMs). Besides, the existing benchmarks usually report overall average scores of different languages, where the fine-grained abilities in different completion scenarios are ignored. Therefore, to facilitate the research of code LLMs in multilingual scenarios, we propose a massively multilingual repository-level code completion benchmark covering 18 programming languages (called M2RC-EVAL), and two types of fine-grained annotations (i.e., bucket-level and semantic-level) on different completion scenarios are provided, where we obtain these annotations based on the parsed abstract syntax tree. Moreover, we also curate a massively multilingual instruction corpora M2RC- INSTRUCT dataset to improve the repository-level code completion abilities of existing code LLMs. Comprehensive experimental results demonstrate the effectiveness of our M2RC-EVAL and M2RC-INSTRUCT.","sentences":["Repository-level code completion has drawn great attention in software engineering, and several benchmark datasets have been introduced.","However, existing repository-level code completion benchmarks usually focus on a limited number of languages (<5), which cannot evaluate the general code intelligence abilities across different languages for existing code Large Language Models (LLMs).","Besides, the existing benchmarks usually report overall average scores of different languages, where the fine-grained abilities in different completion scenarios are ignored.","Therefore, to facilitate the research of code LLMs in multilingual scenarios, we propose a massively multilingual repository-level code completion benchmark covering 18 programming languages (called M2RC-EVAL), and two types of fine-grained annotations (i.e., bucket-level and semantic-level) on different completion scenarios are provided, where we obtain these annotations based on the parsed abstract syntax tree.","Moreover, we also curate a massively multilingual instruction corpora M2RC- INSTRUCT dataset to improve the repository-level code completion abilities of existing code LLMs.","Comprehensive experimental results demonstrate the effectiveness of our M2RC-EVAL and M2RC-INSTRUCT."],"url":"http://arxiv.org/abs/2410.21157v1"}
{"created":"2024-10-28 15:56:49","title":"SciER: An Entity and Relation Extraction Dataset for Datasets, Methods, and Tasks in Scientific Documents","abstract":"Scientific information extraction (SciIE) is critical for converting unstructured knowledge from scholarly articles into structured data (entities and relations). Several datasets have been proposed for training and validating SciIE models. However, due to the high complexity and cost of annotating scientific texts, those datasets restrict their annotations to specific parts of paper, such as abstracts, resulting in the loss of diverse entity mentions and relations in context. In this paper, we release a new entity and relation extraction dataset for entities related to datasets, methods, and tasks in scientific articles. Our dataset contains 106 manually annotated full-text scientific publications with over 24k entities and 12k relations. To capture the intricate use and interactions among entities in full texts, our dataset contains a fine-grained tag set for relations. Additionally, we provide an out-of-distribution test set to offer a more realistic evaluation. We conduct comprehensive experiments, including state-of-the-art supervised models and our proposed LLM-based baselines, and highlight the challenges presented by our dataset, encouraging the development of innovative models to further the field of SciIE.","sentences":["Scientific information extraction (SciIE) is critical for converting unstructured knowledge from scholarly articles into structured data (entities and relations).","Several datasets have been proposed for training and validating SciIE models.","However, due to the high complexity and cost of annotating scientific texts, those datasets restrict their annotations to specific parts of paper, such as abstracts, resulting in the loss of diverse entity mentions and relations in context.","In this paper, we release a new entity and relation extraction dataset for entities related to datasets, methods, and tasks in scientific articles.","Our dataset contains 106 manually annotated full-text scientific publications with over 24k entities and 12k relations.","To capture the intricate use and interactions among entities in full texts, our dataset contains a fine-grained tag set for relations.","Additionally, we provide an out-of-distribution test set to offer a more realistic evaluation.","We conduct comprehensive experiments, including state-of-the-art supervised models and our proposed LLM-based baselines, and highlight the challenges presented by our dataset, encouraging the development of innovative models to further the field of SciIE."],"url":"http://arxiv.org/abs/2410.21155v1"}
{"created":"2024-10-28 15:54:50","title":"Trajectory Flow Matching with Applications to Clinical Time Series Modeling","abstract":"Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine. Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks. However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability. To address this, we propose Trajectory Flow Matching (TFM), which trains a Neural SDE in a simulation-free manner, bypassing backpropagation through the dynamics. TFM leverages the flow matching technique from generative modeling to model time series. In this work we first establish necessary conditions for TFM to learn time series data. Next, we present a reparameterization trick which improves training stability. Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on three clinical time series datasets both in terms of absolute performance and uncertainty prediction.","sentences":["Modeling stochastic and irregularly sampled time series is a challenging problem found in a wide range of applications, especially in medicine.","Neural stochastic differential equations (Neural SDEs) are an attractive modeling technique for this problem, which parameterize the drift and diffusion terms of an SDE with neural networks.","However, current algorithms for training Neural SDEs require backpropagation through the SDE dynamics, greatly limiting their scalability and stability.","To address this, we propose Trajectory Flow Matching (TFM), which trains a Neural SDE in a simulation-free manner, bypassing backpropagation through the dynamics.","TFM leverages the flow matching technique from generative modeling to model time series.","In this work we first establish necessary conditions for TFM to learn time series data.","Next, we present a reparameterization trick which improves training stability.","Finally, we adapt TFM to the clinical time series setting, demonstrating improved performance on three clinical time series datasets both in terms of absolute performance and uncertainty prediction."],"url":"http://arxiv.org/abs/2410.21154v1"}
{"created":"2024-10-28 15:50:56","title":"Synthetica: Large Scale Synthetic Data for Robot Perception","abstract":"Vision-based object detectors are a crucial basis for robotics applications as they provide valuable information about object localisation in the environment. These need to ensure high reliability in different lighting conditions, occlusions, and visual artifacts, all while running in real-time. Collecting and annotating real-world data for these networks is prohibitively time consuming and costly, especially for custom assets, such as industrial objects, making it untenable for generalization to in-the-wild scenarios. To this end, we present Synthetica, a method for large-scale synthetic data generation for training robust state estimators. This paper focuses on the task of object detection, an important problem which can serve as the front-end for most state estimation problems, such as pose estimation. Leveraging data from a photorealistic ray-tracing renderer, we scale up data generation, generating 2.7 million images, to train highly accurate real-time detection transformers. We present a collection of rendering randomization and training-time data augmentation techniques conducive to robust sim-to-real performance for vision tasks. We demonstrate state-of-the-art performance on the task of object detection while having detectors that run at 50-100Hz which is 9 times faster than the prior SOTA. We further demonstrate the usefulness of our training methodology for robotics applications by showcasing a pipeline for use in the real world with custom objects for which there do not exist prior datasets. Our work highlights the importance of scaling synthetic data generation for robust sim-to-real transfer while achieving the fastest real-time inference speeds. Videos and supplementary information can be found at this URL: https://sites.google.com/view/synthetica-vision.","sentences":["Vision-based object detectors are a crucial basis for robotics applications as they provide valuable information about object localisation in the environment.","These need to ensure high reliability in different lighting conditions, occlusions, and visual artifacts, all while running in real-time.","Collecting and annotating real-world data for these networks is prohibitively time consuming and costly, especially for custom assets, such as industrial objects, making it untenable for generalization to in-the-wild scenarios.","To this end, we present Synthetica, a method for large-scale synthetic data generation for training robust state estimators.","This paper focuses on the task of object detection, an important problem which can serve as the front-end for most state estimation problems, such as pose estimation.","Leveraging data from a photorealistic ray-tracing renderer, we scale up data generation, generating 2.7 million images, to train highly accurate real-time detection transformers.","We present a collection of rendering randomization and training-time data augmentation techniques conducive to robust sim-to-real performance for vision tasks.","We demonstrate state-of-the-art performance on the task of object detection while having detectors that run at 50-100Hz which is 9 times faster than the prior SOTA.","We further demonstrate the usefulness of our training methodology for robotics applications by showcasing a pipeline for use in the real world with custom objects for which there do not exist prior datasets.","Our work highlights the importance of scaling synthetic data generation for robust sim-to-real transfer while achieving the fastest real-time inference speeds.","Videos and supplementary information can be found at this URL: https://sites.google.com/view/synthetica-vision."],"url":"http://arxiv.org/abs/2410.21153v1"}
{"created":"2024-10-28 15:49:46","title":"Offline Reinforcement Learning With Combinatorial Action Spaces","abstract":"Reinforcement learning problems often involve large action spaces arising from the simultaneous execution of multiple sub-actions, resulting in combinatorial action spaces. Learning in combinatorial action spaces is difficult due to the exponential growth in action space size with the number of sub-actions and the dependencies among these sub-actions. In offline settings, this challenge is compounded by limited and suboptimal data. Current methods for offline learning in combinatorial spaces simplify the problem by assuming sub-action independence. We propose Branch Value Estimation (BVE), which effectively captures sub-action dependencies and scales to large combinatorial spaces by learning to evaluate only a small subset of actions at each timestep. Our experiments show that BVE outperforms state-of-the-art methods across a range of action space sizes.","sentences":["Reinforcement learning problems often involve large action spaces arising from the simultaneous execution of multiple sub-actions, resulting in combinatorial action spaces.","Learning in combinatorial action spaces is difficult due to the exponential growth in action space size with the number of sub-actions and the dependencies among these sub-actions.","In offline settings, this challenge is compounded by limited and suboptimal data.","Current methods for offline learning in combinatorial spaces simplify the problem by assuming sub-action independence.","We propose Branch Value Estimation (BVE), which effectively captures sub-action dependencies and scales to large combinatorial spaces by learning to evaluate only a small subset of actions at each timestep.","Our experiments show that BVE outperforms state-of-the-art methods across a range of action space sizes."],"url":"http://arxiv.org/abs/2410.21151v1"}
{"created":"2024-10-28 15:48:50","title":"coVoxSLAM: GPU Accelerated Globally Consistent Dense SLAM","abstract":"A dense SLAM system is essential for mobile robots, as it provides localization and allows navigation, path planning, obstacle avoidance, and decision-making in unstructured environments. Due to increasing computational demands the use of GPUs in dense SLAM is expanding. In this work, we present coVoxSLAM, a novel GPU-accelerated volumetric SLAM system that takes full advantage of the parallel processing power of the GPU to build globally consistent maps even in large-scale environments. It was deployed on different platforms (discrete and embedded GPU) and compared with the state of the art. The results obtained using public datasets show that coVoxSLAM delivers a significant performance improvement considering execution times while maintaining accurate localization. The presented system is available as open-source on GitHub https://github.com/lrse-uba/coVoxSLAM.","sentences":["A dense SLAM system is essential for mobile robots, as it provides localization and allows navigation, path planning, obstacle avoidance, and decision-making in unstructured environments.","Due to increasing computational demands the use of GPUs in dense SLAM is expanding.","In this work, we present coVoxSLAM, a novel GPU-accelerated volumetric SLAM system that takes full advantage of the parallel processing power of the GPU to build globally consistent maps even in large-scale environments.","It was deployed on different platforms (discrete and embedded GPU) and compared with the state of the art.","The results obtained using public datasets show that coVoxSLAM delivers a significant performance improvement considering execution times while maintaining accurate localization.","The presented system is available as open-source on GitHub https://github.com/lrse-uba/coVoxSLAM."],"url":"http://arxiv.org/abs/2410.21149v1"}
{"created":"2024-10-28 15:47:03","title":"Palisade -- Prompt Injection Detection Framework","abstract":"The advent of Large Language Models LLMs marks a milestone in Artificial Intelligence, altering how machines comprehend and generate human language. However, LLMs are vulnerable to malicious prompt injection attacks, where crafted inputs manipulate the models behavior in unintended ways, compromising system integrity and causing incorrect outcomes. Conventional detection methods rely on static, rule-based approaches, which often fail against sophisticated threats like abnormal token sequences and alias substitutions, leading to limited adaptability and higher rates of false positives and false negatives.This paper proposes a novel NLP based approach for prompt injection detection, emphasizing accuracy and optimization through a layered input screening process. In this framework, prompts are filtered through three distinct layers rule-based, ML classifier, and companion LLM before reaching the target model, thereby minimizing the risk of malicious interaction.Tests show the ML classifier achieves the highest accuracy among individual layers, yet the multi-layer framework enhances overall detection accuracy by reducing false negatives. Although this increases false positives, it minimizes the risk of overlooking genuine injected prompts, thus prioritizing security.This multi-layered detection approach highlights LLM vulnerabilities and provides a comprehensive framework for future research, promoting secure interactions between humans and AI systems.","sentences":["The advent of Large Language Models LLMs marks a milestone in Artificial Intelligence, altering how machines comprehend and generate human language.","However, LLMs are vulnerable to malicious prompt injection attacks, where crafted inputs manipulate the models behavior in unintended ways, compromising system integrity and causing incorrect outcomes.","Conventional detection methods rely on static, rule-based approaches, which often fail against sophisticated threats like abnormal token sequences and alias substitutions, leading to limited adaptability and higher rates of false positives and false negatives.","This paper proposes a novel NLP based approach for prompt injection detection, emphasizing accuracy and optimization through a layered input screening process.","In this framework, prompts are filtered through three distinct layers rule-based, ML classifier, and companion LLM before reaching the target model, thereby minimizing the risk of malicious interaction.","Tests show the ML classifier achieves the highest accuracy among individual layers, yet the multi-layer framework enhances overall detection accuracy by reducing false negatives.","Although this increases false positives, it minimizes the risk of overlooking genuine injected prompts, thus prioritizing security.","This multi-layered detection approach highlights LLM vulnerabilities and provides a comprehensive framework for future research, promoting secure interactions between humans and AI systems."],"url":"http://arxiv.org/abs/2410.21146v1"}
{"created":"2024-10-28 15:44:35","title":"Enhancing Learned Image Compression via Cross Window-based Attention","abstract":"In recent years, learned image compression methods have demonstrated superior rate-distortion performance compared to traditional image compression methods. Recent methods utilize convolutional neural networks (CNN), variational autoencoders (VAE), invertible neural networks (INN), and transformers. Despite their significant contributions, a main drawback of these models is their poor performance in capturing local redundancy. Therefore, to leverage global features along with local redundancy, we propose a CNN-based solution integrated with a feature encoding module. The feature encoding module encodes important features before feeding them to the CNN and then utilizes cross-scale window-based attention, which further captures local redundancy. Cross-scale window-based attention is inspired by the attention mechanism in transformers and effectively enlarges the receptive field. Both the feature encoding module and the cross-scale window-based attention module in our architecture are flexible and can be incorporated into any other network architecture. We evaluate our method on the Kodak and CLIC datasets and demonstrate that our approach is effective and on par with state-of-the-art methods.","sentences":["In recent years, learned image compression methods have demonstrated superior rate-distortion performance compared to traditional image compression methods.","Recent methods utilize convolutional neural networks (CNN), variational autoencoders (VAE), invertible neural networks (INN), and transformers.","Despite their significant contributions, a main drawback of these models is their poor performance in capturing local redundancy.","Therefore, to leverage global features along with local redundancy, we propose a CNN-based solution integrated with a feature encoding module.","The feature encoding module encodes important features before feeding them to the CNN and then utilizes cross-scale window-based attention, which further captures local redundancy.","Cross-scale window-based attention is inspired by the attention mechanism in transformers and effectively enlarges the receptive field.","Both the feature encoding module and the cross-scale window-based attention module in our architecture are flexible and can be incorporated into any other network architecture.","We evaluate our method on the Kodak and CLIC datasets and demonstrate that our approach is effective and on par with state-of-the-art methods."],"url":"http://arxiv.org/abs/2410.21144v1"}
{"created":"2024-10-28 15:43:33","title":"Modeling and Monitoring of Indoor Populations using Sparse Positioning Data (Extension)","abstract":"In large venues like shopping malls and airports, knowledge on the indoor populations fuels applications such as business analytics, venue management, and safety control. In this work, we provide means of modeling populations in partitions of indoor space offline and of monitoring indoor populations continuously, by using indoor positioning data. However, the low-sampling rates of indoor positioning render the data temporally and spatially sparse, which in turn renders the offline capture of indoor populations challenging. It is even more challenging to continuously monitor indoor populations, as positioning data may be missing or not ready yet at the current moment. To address these challenges, we first enable probabilistic modeling of populations in indoor space partitions as Normal distributions. Based on that, we propose two learning-based estimators for on-the-fly prediction of population distributions. Leveraging the prediction-based schemes, we provide a unified continuous query processing framework for a type of query that enables continuous monitoring of populated partitions. The framework encompasses caching and result validity mechanisms to reduce cost and maintain monitoring effectiveness. Extensive experiments on two real data sets show that the proposed estimators are able to outperform the state-of-the-art alternatives and that the query processing framework is effective and efficient.","sentences":["In large venues like shopping malls and airports, knowledge on the indoor populations fuels applications such as business analytics, venue management, and safety control.","In this work, we provide means of modeling populations in partitions of indoor space offline and of monitoring indoor populations continuously, by using indoor positioning data.","However, the low-sampling rates of indoor positioning render the data temporally and spatially sparse, which in turn renders the offline capture of indoor populations challenging.","It is even more challenging to continuously monitor indoor populations, as positioning data may be missing or not ready yet at the current moment.","To address these challenges, we first enable probabilistic modeling of populations in indoor space partitions as Normal distributions.","Based on that, we propose two learning-based estimators for on-the-fly prediction of population distributions.","Leveraging the prediction-based schemes, we provide a unified continuous query processing framework for a type of query that enables continuous monitoring of populated partitions.","The framework encompasses caching and result validity mechanisms to reduce cost and maintain monitoring effectiveness.","Extensive experiments on two real data sets show that the proposed estimators are able to outperform the state-of-the-art alternatives and that the query processing framework is effective and efficient."],"url":"http://arxiv.org/abs/2410.21142v1"}
{"created":"2024-10-28 15:43:31","title":"LLM-initialized Differentiable Causal Discovery","abstract":"The discovery of causal relationships between random variables is an important yet challenging problem that has applications across many scientific domains. Differentiable causal discovery (DCD) methods are effective in uncovering causal relationships from observational data; however, these approaches often suffer from limited interpretability and face challenges in incorporating domain-specific prior knowledge. In contrast, Large Language Models (LLMs)-based causal discovery approaches have recently been shown capable of providing useful priors for causal discovery but struggle with formal causal reasoning. In this paper, we propose LLM-DCD, which uses an LLM to initialize the optimization of the maximum likelihood objective function of DCD approaches, thereby incorporating strong priors into the discovery method. To achieve this initialization, we design our objective function to depend on an explicitly defined adjacency matrix of the causal graph as its only variational parameter. Directly optimizing the explicitly defined adjacency matrix provides a more interpretable approach to causal discovery. Additionally, we demonstrate higher accuracy on key benchmarking datasets of our approach compared to state-of-the-art alternatives, and provide empirical evidence that the quality of the initialization directly impacts the quality of the final output of our DCD approach. LLM-DCD opens up new opportunities for traditional causal discovery methods like DCD to benefit from future improvements in the causal reasoning capabilities of LLMs.","sentences":["The discovery of causal relationships between random variables is an important yet challenging problem that has applications across many scientific domains.","Differentiable causal discovery (DCD) methods are effective in uncovering causal relationships from observational data; however, these approaches often suffer from limited interpretability and face challenges in incorporating domain-specific prior knowledge.","In contrast, Large Language Models (LLMs)-based causal discovery approaches have recently been shown capable of providing useful priors for causal discovery but struggle with formal causal reasoning.","In this paper, we propose LLM-DCD, which uses an LLM to initialize the optimization of the maximum likelihood objective function of DCD approaches, thereby incorporating strong priors into the discovery method.","To achieve this initialization, we design our objective function to depend on an explicitly defined adjacency matrix of the causal graph as its only variational parameter.","Directly optimizing the explicitly defined adjacency matrix provides a more interpretable approach to causal discovery.","Additionally, we demonstrate higher accuracy on key benchmarking datasets of our approach compared to state-of-the-art alternatives, and provide empirical evidence that the quality of the initialization directly impacts the quality of the final output of our DCD approach.","LLM-DCD opens up new opportunities for traditional causal discovery methods like DCD to benefit from future improvements in the causal reasoning capabilities of LLMs."],"url":"http://arxiv.org/abs/2410.21141v1"}
{"created":"2024-10-28 15:42:45","title":"uOttawa at LegalLens-2024: Transformer-based Classification Experiments","abstract":"This paper presents the methods used for LegalLens-2024 shared task, which focused on detecting legal violations within unstructured textual data and associating these violations with potentially affected individuals. The shared task included two subtasks: A) Legal Named Entity Recognition (L-NER) and B) Legal Natural Language Inference (L-NLI). For subtask A, we utilized the spaCy library, while for subtask B, we employed a combined model incorporating RoBERTa and CNN. Our results were 86.3% in the L-NER subtask and 88.25% in the L-NLI subtask. Overall, our paper demonstrates the effectiveness of transformer models in addressing complex tasks in the legal domain. The source code for our implementation is publicly available at https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification","sentences":["This paper presents the methods used for LegalLens-2024 shared task, which focused on detecting legal violations within unstructured textual data and associating these violations with potentially affected individuals.","The shared task included two subtasks: A) Legal Named Entity Recognition (L-NER) and B) Legal Natural Language Inference (L-NLI).","For subtask A, we utilized the spaCy library, while for subtask B, we employed a combined model incorporating RoBERTa and CNN.","Our results were 86.3% in the L-NER subtask and 88.25% in the L-NLI subtask.","Overall, our paper demonstrates the effectiveness of transformer models in addressing complex tasks in the legal domain.","The source code for our implementation is publicly available at https://github.com/NimaMeghdadi/uOttawa-at-LegalLens-2024-Transformer-based-Classification"],"url":"http://arxiv.org/abs/2410.21139v1"}
{"created":"2024-10-28 15:37:06","title":"Do LLMs generate test oracles that capture the actual or the expected program behaviour?","abstract":"Software testing is an essential part of the software development cycle to improve the code quality. Typically, a unit test consists of a test prefix and a test oracle which captures the developer's intended behaviour. A known limitation of traditional test generation techniques (e.g. Randoop and Evosuite) is that they produce test oracles that capture the actual program behaviour rather than the expected one. Recent approaches leverage Large Language Models (LLMs), trained on an enormous amount of data, to generate developer-like code and test cases. We investigate whether the LLM-generated test oracles capture the actual or expected software behaviour. We thus, conduct a controlled experiment to answer this question, by studying LLMs performance on two tasks, namely, test oracle classification and generation. The study includes developer-written and automatically generated test cases and oracles for 24 open-source Java repositories, and different well tested prompts. Our findings show that LLM-based test generation approaches are also prone on generating oracles that capture the actual program behaviour rather than the expected one. Moreover, LLMs are better at generating test oracles rather than classifying the correct ones, and can generate better test oracles when the code contains meaningful test or variable names. Finally, LLM-generated test oracles have higher fault detection potential than the Evosuite ones.","sentences":["Software testing is an essential part of the software development cycle to improve the code quality.","Typically, a unit test consists of a test prefix and a test oracle which captures the developer's intended behaviour.","A known limitation of traditional test generation techniques (e.g. Randoop and Evosuite) is that they produce test oracles that capture the actual program behaviour rather than the expected one.","Recent approaches leverage Large Language Models (LLMs), trained on an enormous amount of data, to generate developer-like code and test cases.","We investigate whether the LLM-generated test oracles capture the actual or expected software behaviour.","We thus, conduct a controlled experiment to answer this question, by studying LLMs performance on two tasks, namely, test oracle classification and generation.","The study includes developer-written and automatically generated test cases and oracles for 24 open-source Java repositories, and different well tested prompts.","Our findings show that LLM-based test generation approaches are also prone on generating oracles that capture the actual program behaviour rather than the expected one.","Moreover, LLMs are better at generating test oracles rather than classifying the correct ones, and can generate better test oracles when the code contains meaningful test or variable names.","Finally, LLM-generated test oracles have higher fault detection potential than the Evosuite ones."],"url":"http://arxiv.org/abs/2410.21136v1"}
{"created":"2024-10-28 15:33:37","title":"Towards Unifying Evaluation of Counterfactual Explanations: Leveraging Large Language Models for Human-Centric Assessments","abstract":"As machine learning models evolve, maintaining transparency demands more human-centric explainable AI techniques. Counterfactual explanations, with roots in human reasoning, identify the minimal input changes needed to obtain a given output and, hence, are crucial for supporting decision-making. Despite their importance, the evaluation of these explanations often lacks grounding in user studies and remains fragmented, with existing metrics not fully capturing human perspectives. To address this challenge, we developed a diverse set of 30 counterfactual scenarios and collected ratings across 8 evaluation metrics from 206 respondents. Subsequently, we fine-tuned different Large Language Models (LLMs) to predict average or individual human judgment across these metrics. Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot evaluations and 85% (over a 3-classes prediction) with fine-tuning across all metrics. The fine-tuned models predicting human ratings offer better comparability and scalability in evaluating different counterfactual explanation frameworks.","sentences":["As machine learning models evolve, maintaining transparency demands more human-centric explainable AI techniques.","Counterfactual explanations, with roots in human reasoning, identify the minimal input changes needed to obtain a given output and, hence, are crucial for supporting decision-making.","Despite their importance, the evaluation of these explanations often lacks grounding in user studies and remains fragmented, with existing metrics not fully capturing human perspectives.","To address this challenge, we developed a diverse set of 30 counterfactual scenarios and collected ratings across 8 evaluation metrics from 206 respondents.","Subsequently, we fine-tuned different Large Language Models (LLMs) to predict average or individual human judgment across these metrics.","Our methodology allowed LLMs to achieve an accuracy of up to 63% in zero-shot evaluations and 85% (over a 3-classes prediction) with fine-tuning across all metrics.","The fine-tuned models predicting human ratings offer better comparability and scalability in evaluating different counterfactual explanation frameworks."],"url":"http://arxiv.org/abs/2410.21131v1"}
{"created":"2024-10-28 15:31:47","title":"Extrapolating Prospective Glaucoma Fundus Images through Diffusion Model in Irregular Longitudinal Sequences","abstract":"The utilization of longitudinal datasets for glaucoma progression prediction offers a compelling approach to support early therapeutic interventions. Predominant methodologies in this domain have primarily focused on the direct prediction of glaucoma stage labels from longitudinal datasets. However, such methods may not adequately encapsulate the nuanced developmental trajectory of the disease. To enhance the diagnostic acumen of medical practitioners, we propose a novel diffusion-based model to predict prospective images by extrapolating from existing longitudinal fundus images of patients. The methodology delineated in this study distinctively leverages sequences of images as inputs. Subsequently, a time-aligned mask is employed to select a specific year for image generation. During the training phase, the time-aligned mask resolves the issue of irregular temporal intervals in longitudinal image sequence sampling. Additionally, we utilize a strategy of randomly masking a frame in the sequence to establish the ground truth. This methodology aids the network in continuously acquiring knowledge regarding the internal relationships among the sequences throughout the learning phase. Moreover, the introduction of textual labels is instrumental in categorizing images generated within the sequence. The empirical findings from the conducted experiments indicate that our proposed model not only effectively generates longitudinal data but also significantly improves the precision of downstream classification tasks.","sentences":["The utilization of longitudinal datasets for glaucoma progression prediction offers a compelling approach to support early therapeutic interventions.","Predominant methodologies in this domain have primarily focused on the direct prediction of glaucoma stage labels from longitudinal datasets.","However, such methods may not adequately encapsulate the nuanced developmental trajectory of the disease.","To enhance the diagnostic acumen of medical practitioners, we propose a novel diffusion-based model to predict prospective images by extrapolating from existing longitudinal fundus images of patients.","The methodology delineated in this study distinctively leverages sequences of images as inputs.","Subsequently, a time-aligned mask is employed to select a specific year for image generation.","During the training phase, the time-aligned mask resolves the issue of irregular temporal intervals in longitudinal image sequence sampling.","Additionally, we utilize a strategy of randomly masking a frame in the sequence to establish the ground truth.","This methodology aids the network in continuously acquiring knowledge regarding the internal relationships among the sequences throughout the learning phase.","Moreover, the introduction of textual labels is instrumental in categorizing images generated within the sequence.","The empirical findings from the conducted experiments indicate that our proposed model not only effectively generates longitudinal data but also significantly improves the precision of downstream classification tasks."],"url":"http://arxiv.org/abs/2410.21130v1"}
{"created":"2024-10-28 15:29:35","title":"Fast Calibrated Explanations: Efficient and Uncertainty-Aware Explanations for Machine Learning Models","abstract":"This paper introduces Fast Calibrated Explanations, a method designed for generating rapid, uncertainty-aware explanations for machine learning models. By incorporating perturbation techniques from ConformaSight - a global explanation framework - into the core elements of Calibrated Explanations (CE), we achieve significant speedups. These core elements include local feature importance with calibrated predictions, both of which retain uncertainty quantification. While the new method sacrifices a small degree of detail, it excels in computational efficiency, making it ideal for high-stakes, real-time applications. Fast Calibrated Explanations are applicable to probabilistic explanations in classification and thresholded regression tasks, where they provide the likelihood of a target being above or below a user-defined threshold. This approach maintains the versatility of CE for both classification and probabilistic regression, making it suitable for a range of predictive tasks where uncertainty quantification is crucial.","sentences":["This paper introduces Fast Calibrated Explanations, a method designed for generating rapid, uncertainty-aware explanations for machine learning models.","By incorporating perturbation techniques from ConformaSight - a global explanation framework - into the core elements of Calibrated Explanations (CE), we achieve significant speedups.","These core elements include local feature importance with calibrated predictions, both of which retain uncertainty quantification.","While the new method sacrifices a small degree of detail, it excels in computational efficiency, making it ideal for high-stakes, real-time applications.","Fast Calibrated Explanations are applicable to probabilistic explanations in classification and thresholded regression tasks, where they provide the likelihood of a target being above or below a user-defined threshold.","This approach maintains the versatility of CE for both classification and probabilistic regression, making it suitable for a range of predictive tasks where uncertainty quantification is crucial."],"url":"http://arxiv.org/abs/2410.21129v1"}
{"created":"2024-10-28 15:28:51","title":"Retrieval-Enhanced Mutation Mastery: Augmenting Zero-Shot Prediction of Protein Language Model","abstract":"Enzyme engineering enables the modification of wild-type proteins to meet industrial and research demands by enhancing catalytic activity, stability, binding affinities, and other properties. The emergence of deep learning methods for protein modeling has demonstrated superior results at lower costs compared to traditional approaches such as directed evolution and rational design. In mutation effect prediction, the key to pre-training deep learning models lies in accurately interpreting the complex relationships among protein sequence, structure, and function. This study introduces a retrieval-enhanced protein language model for comprehensive analysis of native properties from sequence and local structural interactions, as well as evolutionary properties from retrieved homologous sequences. The state-of-the-art performance of the proposed ProtREM is validated on over 2 million mutants across 217 assays from an open benchmark (ProteinGym). We also conducted post-hoc analyses of the model's ability to improve the stability and binding affinity of a VHH antibody. Additionally, we designed 10 new mutants on a DNA polymerase and conducted wet-lab experiments to evaluate their enhanced activity at higher temperatures. Both in silico and experimental evaluations confirmed that our method provides reliable predictions of mutation effects, offering an auxiliary tool for biologists aiming to evolve existing enzymes. The implementation is publicly available at https://github.com/tyang816/ProtREM.","sentences":["Enzyme engineering enables the modification of wild-type proteins to meet industrial and research demands by enhancing catalytic activity, stability, binding affinities, and other properties.","The emergence of deep learning methods for protein modeling has demonstrated superior results at lower costs compared to traditional approaches such as directed evolution and rational design.","In mutation effect prediction, the key to pre-training deep learning models lies in accurately interpreting the complex relationships among protein sequence, structure, and function.","This study introduces a retrieval-enhanced protein language model for comprehensive analysis of native properties from sequence and local structural interactions, as well as evolutionary properties from retrieved homologous sequences.","The state-of-the-art performance of the proposed ProtREM is validated on over 2 million mutants across 217 assays from an open benchmark (ProteinGym).","We also conducted post-hoc analyses of the model's ability to improve the stability and binding affinity of a VHH antibody.","Additionally, we designed 10 new mutants on a DNA polymerase and conducted wet-lab experiments to evaluate their enhanced activity at higher temperatures.","Both in silico and experimental evaluations confirmed that our method provides reliable predictions of mutation effects, offering an auxiliary tool for biologists aiming to evolve existing enzymes.","The implementation is publicly available at https://github.com/tyang816/ProtREM."],"url":"http://arxiv.org/abs/2410.21127v1"}
{"created":"2024-10-28 15:28:50","title":"Current State-of-the-Art of Bias Detection and Mitigation in Machine Translation for African and European Languages: a Review","abstract":"Studying bias detection and mitigation methods in natural language processing and the particular case of machine translation is highly relevant, as societal stereotypes might be reflected or reinforced by these systems. In this paper, we analyze the state-of-the-art with a particular focus on European and African languages. We show how the majority of the work in this field concentrates on few languages, and that there is potential for future research to cover also the less investigated languages to contribute to more diversity in the research field.","sentences":["Studying bias detection and mitigation methods in natural language processing and the particular case of machine translation is highly relevant, as societal stereotypes might be reflected or reinforced by these systems.","In this paper, we analyze the state-of-the-art with a particular focus on European and African languages.","We show how the majority of the work in this field concentrates on few languages, and that there is potential for future research to cover also the less investigated languages to contribute to more diversity in the research field."],"url":"http://arxiv.org/abs/2410.21126v1"}
{"created":"2024-10-28 15:21:23","title":"FusedInf: Efficient Swapping of DNN Models for On-Demand Serverless Inference Services on the Edge","abstract":"Edge AI computing boxes are a new class of computing devices that are aimed to revolutionize the AI industry. These compact and robust hardware units bring the power of AI processing directly to the source of data--on the edge of the network. On the other hand, on-demand serverless inference services are becoming more and more popular as they minimize the infrastructural cost associated with hosting and running DNN models for small to medium-sized businesses. However, these computing devices are still constrained in terms of resource availability. As such, the service providers need to load and unload models efficiently in order to meet the growing demand. In this paper, we introduce FusedInf to efficiently swap DNN models for on-demand serverless inference services on the edge. FusedInf combines multiple models into a single Direct Acyclic Graph (DAG) to efficiently load the models into the GPU memory and make execution faster. Our evaluation of popular DNN models showed that creating a single DAG can make the execution of the models up to 14\\% faster while reducing the memory requirement by up to 17\\%. The prototype implementation is available at https://github.com/SifatTaj/FusedInf.","sentences":["Edge AI computing boxes are a new class of computing devices that are aimed to revolutionize the AI industry.","These compact and robust hardware units bring the power of AI processing directly to the source of data--on the edge of the network.","On the other hand, on-demand serverless inference services are becoming more and more popular as they minimize the infrastructural cost associated with hosting and running DNN models for small to medium-sized businesses.","However, these computing devices are still constrained in terms of resource availability.","As such, the service providers need to load and unload models efficiently in order to meet the growing demand.","In this paper, we introduce FusedInf to efficiently swap DNN models for on-demand serverless inference services on the edge.","FusedInf combines multiple models into a single Direct Acyclic Graph (DAG) to efficiently load the models into the GPU memory and make execution faster.","Our evaluation of popular DNN models showed that creating a single DAG can make the execution of the models up to 14\\% faster while reducing the memory requirement by up to 17\\%.","The prototype implementation is available at https://github.com/SifatTaj/FusedInf."],"url":"http://arxiv.org/abs/2410.21120v1"}
{"created":"2024-10-28 15:20:52","title":"A Unified Solution to Diverse Heterogeneities in One-shot Federated Learning","abstract":"One-shot federated learning (FL) limits the communication between the server and clients to a single round, which largely decreases the privacy leakage risks in traditional FLs requiring multiple communications. However, we find existing one-shot FL frameworks are vulnerable to distributional heterogeneity due to their insufficient focus on data heterogeneity while concentrating predominantly on model heterogeneity. Filling this gap, we propose a unified, data-free, one-shot federated learning framework (FedHydra) that can effectively address both model and data heterogeneity. Rather than applying existing value-only learning mechanisms, a structure-value learning mechanism is proposed in FedHydra. Specifically, a new stratified learning structure is proposed to cover data heterogeneity, and the value of each item during computation reflects model heterogeneity. By this design, the data and model heterogeneity issues are simultaneously monitored from different aspects during learning. Consequently, FedHydra can effectively mitigate both issues by minimizing their inherent conflicts. We compared FedHydra with three SOTA baselines on four benchmark datasets. Experimental results show that our method outperforms the previous one-shot FL methods in both homogeneous and heterogeneous settings.","sentences":["One-shot federated learning (FL) limits the communication between the server and clients to a single round, which largely decreases the privacy leakage risks in traditional FLs requiring multiple communications.","However, we find existing one-shot FL frameworks are vulnerable to distributional heterogeneity due to their insufficient focus on data heterogeneity while concentrating predominantly on model heterogeneity.","Filling this gap, we propose a unified, data-free, one-shot federated learning framework (FedHydra) that can effectively address both model and data heterogeneity.","Rather than applying existing value-only learning mechanisms, a structure-value learning mechanism is proposed in FedHydra.","Specifically, a new stratified learning structure is proposed to cover data heterogeneity, and the value of each item during computation reflects model heterogeneity.","By this design, the data and model heterogeneity issues are simultaneously monitored from different aspects during learning.","Consequently, FedHydra can effectively mitigate both issues by minimizing their inherent conflicts.","We compared FedHydra with three SOTA baselines on four benchmark datasets.","Experimental results show that our method outperforms the previous one-shot FL methods in both homogeneous and heterogeneous settings."],"url":"http://arxiv.org/abs/2410.21119v1"}
{"created":"2024-10-28 15:13:53","title":"Zero-Shot Action Recognition in Surveillance Videos","abstract":"The growing demand for surveillance in public spaces presents significant challenges due to the shortage of human resources. Current AI-based video surveillance systems heavily rely on core computer vision models that require extensive finetuning, which is particularly difficult in surveillance settings due to limited datasets and difficult setting (viewpoint, low quality, etc.). In this work, we propose leveraging Large Vision-Language Models (LVLMs), known for their strong zero and few-shot generalization, to tackle video understanding tasks in surveillance. Specifically, we explore VideoLLaMA2, a state-of-the-art LVLM, and an improved token-level sampling method, Self-Reflective Sampling (Self-ReS). Our experiments on the UCF-Crime dataset show that VideoLLaMA2 represents a significant leap in zero-shot performance, with 20% boost over the baseline. Self-ReS additionally increases zero-shot action recognition performance to 44.6%. These results highlight the potential of LVLMs, paired with improved sampling techniques, for advancing surveillance video analysis in diverse scenarios.","sentences":["The growing demand for surveillance in public spaces presents significant challenges due to the shortage of human resources.","Current AI-based video surveillance systems heavily rely on core computer vision models that require extensive finetuning, which is particularly difficult in surveillance settings due to limited datasets and difficult setting (viewpoint, low quality, etc.).","In this work, we propose leveraging Large Vision-Language Models (LVLMs), known for their strong zero and few-shot generalization, to tackle video understanding tasks in surveillance.","Specifically, we explore VideoLLaMA2, a state-of-the-art LVLM, and an improved token-level sampling method, Self-Reflective Sampling (Self-ReS).","Our experiments on the UCF-Crime dataset show that VideoLLaMA2 represents a significant leap in zero-shot performance, with 20% boost over the baseline.","Self-ReS additionally increases zero-shot action recognition performance to 44.6%.","These results highlight the potential of LVLMs, paired with improved sampling techniques, for advancing surveillance video analysis in diverse scenarios."],"url":"http://arxiv.org/abs/2410.21113v1"}
{"created":"2024-10-28 15:13:52","title":"Magnetic Milli-spinner for Robotic Endovascular Surgery","abstract":"Vascular diseases such as thrombosis, atherosclerosis, and aneurysm, which can lead to blockage of blood flow or blood vessel rupture, are common and life-threatening. Conventional minimally invasive treatments utilize catheters, or long tubes, to guide small devices or therapeutic agents to targeted regions for intervention. Unfortunately, catheters suffer from difficult and unreliable navigation in narrow, winding vessels such as those found in the brain. Magnetically actuated untethered robots, which have been extensively explored as an alternative, are promising for navigation in complex vasculatures and vascular disease treatments. Most current robots, however, cannot swim against high flows or are inadequate in treating certain conditions. Here, we introduce a multifunctional and magnetically actuated milli-spinner robot for rapid navigation and performance of various treatments in complicated vasculatures. The milli-spinner, with a unique hollow structure including helical fins and slits for propulsion, generates a distinct flow field upon spinning. The milli-spinner is the fastest-ever untethered magnetic robot for movement in tubular environments, easily achieving speeds of 23 cm/s, demonstrating promise as an untethered medical device for effective navigation in blood vessels and robotic treatment of numerous vascular diseases.","sentences":["Vascular diseases such as thrombosis, atherosclerosis, and aneurysm, which can lead to blockage of blood flow or blood vessel rupture, are common and life-threatening.","Conventional minimally invasive treatments utilize catheters, or long tubes, to guide small devices or therapeutic agents to targeted regions for intervention.","Unfortunately, catheters suffer from difficult and unreliable navigation in narrow, winding vessels such as those found in the brain.","Magnetically actuated untethered robots, which have been extensively explored as an alternative, are promising for navigation in complex vasculatures and vascular disease treatments.","Most current robots, however, cannot swim against high flows or are inadequate in treating certain conditions.","Here, we introduce a multifunctional and magnetically actuated milli-spinner robot for rapid navigation and performance of various treatments in complicated vasculatures.","The milli-spinner, with a unique hollow structure including helical fins and slits for propulsion, generates a distinct flow field upon spinning.","The milli-spinner is the fastest-ever untethered magnetic robot for movement in tubular environments, easily achieving speeds of 23 cm/s, demonstrating promise as an untethered medical device for effective navigation in blood vessels and robotic treatment of numerous vascular diseases."],"url":"http://arxiv.org/abs/2410.21112v1"}
{"created":"2024-10-28 15:13:04","title":"LAMA: Stable Dual-Domain Deep Reconstruction For Sparse-View CT","abstract":"Inverse problems arise in many applications, especially tomographic imaging. We develop a Learned Alternating Minimization Algorithm (LAMA) to solve such problems via two-block optimization by synergizing data-driven and classical techniques with proven convergence. LAMA is naturally induced by a variational model with learnable regularizers in both data and image domains, parameterized as composite functions of neural networks trained with domain-specific data. We allow these regularizers to be nonconvex and nonsmooth to extract features from data effectively. We minimize the overall objective function using Nesterov's smoothing technique and residual learning architecture. It is demonstrated that LAMA reduces network complexity, improves memory efficiency, and enhances reconstruction accuracy, stability, and interpretability. Extensive experiments show that LAMA significantly outperforms state-of-the-art methods on popular benchmark datasets for Computed Tomography.","sentences":["Inverse problems arise in many applications, especially tomographic imaging.","We develop a Learned Alternating Minimization Algorithm (LAMA) to solve such problems via two-block optimization by synergizing data-driven and classical techniques with proven convergence.","LAMA is naturally induced by a variational model with learnable regularizers in both data and image domains, parameterized as composite functions of neural networks trained with domain-specific data.","We allow these regularizers to be nonconvex and nonsmooth to extract features from data effectively.","We minimize the overall objective function using Nesterov's smoothing technique and residual learning architecture.","It is demonstrated that LAMA reduces network complexity, improves memory efficiency, and enhances reconstruction accuracy, stability, and interpretability.","Extensive experiments show that LAMA significantly outperforms state-of-the-art methods on popular benchmark datasets for Computed Tomography."],"url":"http://arxiv.org/abs/2410.21111v1"}
{"created":"2024-10-28 15:12:04","title":"Dual-Agent Deep Reinforcement Learning for Dynamic Pricing and Replenishment","abstract":"We study the dynamic pricing and replenishment problems under inconsistent decision frequencies. Different from the traditional demand assumption, the discreteness of demand and the parameter within the Poisson distribution as a function of price introduce complexity into analyzing the problem property. We demonstrate the concavity of the single-period profit function with respect to product price and inventory within their respective domains. The demand model is enhanced by integrating a decision tree-based machine learning approach, trained on comprehensive market data. Employing a two-timescale stochastic approximation scheme, we address the discrepancies in decision frequencies between pricing and replenishment, ensuring convergence to local optimum. We further refine our methodology by incorporating deep reinforcement learning (DRL) techniques and propose a fast-slow dual-agent DRL algorithm. In this approach, two agents handle pricing and inventory and are updated on different scales. Numerical results from both single and multiple products scenarios validate the effectiveness of our methods.","sentences":["We study the dynamic pricing and replenishment problems under inconsistent decision frequencies.","Different from the traditional demand assumption, the discreteness of demand and the parameter within the Poisson distribution as a function of price introduce complexity into analyzing the problem property.","We demonstrate the concavity of the single-period profit function with respect to product price and inventory within their respective domains.","The demand model is enhanced by integrating a decision tree-based machine learning approach, trained on comprehensive market data.","Employing a two-timescale stochastic approximation scheme, we address the discrepancies in decision frequencies between pricing and replenishment, ensuring convergence to local optimum.","We further refine our methodology by incorporating deep reinforcement learning (DRL) techniques and propose a fast-slow dual-agent DRL algorithm.","In this approach, two agents handle pricing and inventory and are updated on different scales.","Numerical results from both single and multiple products scenarios validate the effectiveness of our methods."],"url":"http://arxiv.org/abs/2410.21109v1"}
{"created":"2024-10-28 15:11:49","title":"LiGAR: LiDAR-Guided Hierarchical Transformer for Multi-Modal Group Activity Recognition","abstract":"Group Activity Recognition (GAR) remains challenging in computer vision due to the complex nature of multi-agent interactions. This paper introduces LiGAR, a LIDAR-Guided Hierarchical Transformer for Multi-Modal Group Activity Recognition. LiGAR leverages LiDAR data as a structural backbone to guide the processing of visual and textual information, enabling robust handling of occlusions and complex spatial arrangements. Our framework incorporates a Multi-Scale LIDAR Transformer, Cross-Modal Guided Attention, and an Adaptive Fusion Module to integrate multi-modal data at different semantic levels effectively. LiGAR's hierarchical architecture captures group activities at various granularities, from individual actions to scene-level dynamics. Extensive experiments on the JRDB-PAR, Volleyball, and NBA datasets demonstrate LiGAR's superior performance, achieving state-of-the-art results with improvements of up to 10.6% in F1-score on JRDB-PAR and 5.9% in Mean Per Class Accuracy on the NBA dataset. Notably, LiGAR maintains high performance even when LiDAR data is unavailable during inference, showcasing its adaptability. Our ablation studies highlight the significant contributions of each component and the effectiveness of our multi-modal, multi-scale approach in advancing the field of group activity recognition.","sentences":["Group Activity Recognition (GAR) remains challenging in computer vision due to the complex nature of multi-agent interactions.","This paper introduces LiGAR, a LIDAR-Guided Hierarchical Transformer for Multi-Modal Group Activity Recognition.","LiGAR leverages LiDAR data as a structural backbone to guide the processing of visual and textual information, enabling robust handling of occlusions and complex spatial arrangements.","Our framework incorporates a Multi-Scale LIDAR Transformer, Cross-Modal Guided Attention, and an Adaptive Fusion Module to integrate multi-modal data at different semantic levels effectively.","LiGAR's hierarchical architecture captures group activities at various granularities, from individual actions to scene-level dynamics.","Extensive experiments on the JRDB-PAR, Volleyball, and NBA datasets demonstrate LiGAR's superior performance, achieving state-of-the-art results with improvements of up to 10.6% in F1-score on JRDB-PAR and 5.9% in Mean Per Class Accuracy on the NBA dataset.","Notably, LiGAR maintains high performance even when LiDAR data is unavailable during inference, showcasing its adaptability.","Our ablation studies highlight the significant contributions of each component and the effectiveness of our multi-modal, multi-scale approach in advancing the field of group activity recognition."],"url":"http://arxiv.org/abs/2410.21108v1"}
{"created":"2024-10-28 15:11:23","title":"Tree-Wasserstein Distance for High Dimensional Data with a Latent Feature Hierarchy","abstract":"Finding meaningful distances between high-dimensional data samples is an important scientific task. To this end, we propose a new tree-Wasserstein distance (TWD) for high-dimensional data with two key aspects. First, our TWD is specifically designed for data with a latent feature hierarchy, i.e., the features lie in a hierarchical space, in contrast to the usual focus on embedding samples in hyperbolic space. Second, while the conventional use of TWD is to speed up the computation of the Wasserstein distance, we use its inherent tree as a means to learn the latent feature hierarchy. The key idea of our method is to embed the features into a multi-scale hyperbolic space using diffusion geometry and then present a new tree decoding method by establishing analogies between the hyperbolic embedding and trees. We show that our TWD computed based on data observations provably recovers the TWD defined with the latent feature hierarchy and that its computation is efficient and scalable. We showcase the usefulness of the proposed TWD in applications to word-document and single-cell RNA-sequencing datasets, demonstrating its advantages over existing TWDs and methods based on pre-trained models.","sentences":["Finding meaningful distances between high-dimensional data samples is an important scientific task.","To this end, we propose a new tree-Wasserstein distance (TWD) for high-dimensional data with two key aspects.","First, our TWD is specifically designed for data with a latent feature hierarchy, i.e., the features lie in a hierarchical space, in contrast to the usual focus on embedding samples in hyperbolic space.","Second, while the conventional use of TWD is to speed up the computation of the Wasserstein distance, we use its inherent tree as a means to learn the latent feature hierarchy.","The key idea of our method is to embed the features into a multi-scale hyperbolic space using diffusion geometry and then present a new tree decoding method by establishing analogies between the hyperbolic embedding and trees.","We show that our TWD computed based on data observations provably recovers the TWD defined with the latent feature hierarchy and that its computation is efficient and scalable.","We showcase the usefulness of the proposed TWD in applications to word-document and single-cell RNA-sequencing datasets, demonstrating its advantages over existing TWDs and methods based on pre-trained models."],"url":"http://arxiv.org/abs/2410.21107v1"}
{"created":"2024-10-28 15:06:31","title":"Fingerprinting Browsers in Encrypted Communications","abstract":"Browser fingerprinting is the identification of a browser through the network traffic captured during communication between the browser and server. This can be done using the HTTP protocol, browser extensions, and other methods. This paper discusses browser fingerprinting using the HTTPS over TLS 1.3 protocol. The study observed that different browsers use a different number of messages to communicate with the server, and the length of messages also varies. To conduct the study, a network was set up using a UTM hypervisor with one virtual machine as the server and another as a VM with a different browser. The communication was captured, and it was found that there was a 30\\%-35\\% dissimilarity in the behavior of different browsers.","sentences":["Browser fingerprinting is the identification of a browser through the network traffic captured during communication between the browser and server.","This can be done using the HTTP protocol, browser extensions, and other methods.","This paper discusses browser fingerprinting using the HTTPS over TLS 1.3 protocol.","The study observed that different browsers use a different number of messages to communicate with the server, and the length of messages also varies.","To conduct the study, a network was set up using a UTM hypervisor with one virtual machine as the server and another as a VM with a different browser.","The communication was captured, and it was found that there was a 30\\%-35\\% dissimilarity in the behavior of different browsers."],"url":"http://arxiv.org/abs/2410.21101v1"}
{"created":"2024-10-28 14:57:10","title":"CloudHeatMap: Heatmap-Based Monitoring for Large-Scale Cloud Systems","abstract":"Cloud computing is essential for modern enterprises, requiring robust tools to monitor and manage Large-Scale Cloud Systems (LCS). Traditional monitoring tools often miss critical insights due to the complexity and volume of LCS telemetry data. This paper presents CloudHeatMap, a novel heatmap-based visualization tool for near-real-time monitoring of LCS health. It offers intuitive visualizations of key metrics such as call volumes, response times, and HTTP response codes, enabling operators to quickly identify performance issues. A case study on the IBM Cloud Console demonstrates the tool's effectiveness in enhancing operational monitoring and decision-making. A demonstration is available at https://www.youtube.com/watch?v=3u5K1qp51EA .","sentences":["Cloud computing is essential for modern enterprises, requiring robust tools to monitor and manage Large-Scale Cloud Systems (LCS).","Traditional monitoring tools often miss critical insights due to the complexity and volume of LCS telemetry data.","This paper presents CloudHeatMap, a novel heatmap-based visualization tool for near-real-time monitoring of LCS health.","It offers intuitive visualizations of key metrics such as call volumes, response times, and HTTP response codes, enabling operators to quickly identify performance issues.","A case study on the IBM Cloud Console demonstrates the tool's effectiveness in enhancing operational monitoring and decision-making.","A demonstration is available at https://www.youtube.com/watch?v=3u5K1qp51EA ."],"url":"http://arxiv.org/abs/2410.21092v1"}
{"created":"2024-10-28 14:56:51","title":"Large Language Model-assisted Speech and Pointing Benefits Multiple 3D Object Selection in Virtual Reality","abstract":"Selection of occluded objects is a challenging problem in virtual reality, even more so if multiple objects are involved. With the advent of new artificial intelligence technologies, we explore the possibility of leveraging large language models to assist multi-object selection tasks in virtual reality via a multimodal speech and raycast interaction technique. We validate the findings in a comparative user study (n=24), where participants selected target objects in a virtual reality scene with different levels of scene perplexity. The performance metrics and user experience metrics are compared against a mini-map based occluded object selection technique that serves as the baseline. Results indicate that the introduced technique, AssistVR, outperforms the baseline technique when there are multiple target objects. Contrary to the common belief for speech interfaces, AssistVR was able to outperform the baseline even when the target objects were difficult to reference verbally. This work demonstrates the viability and interaction potential of an intelligent multimodal interactive system powered by large laguage models. Based on the results, we discuss the implications for design of future intelligent multimodal interactive systems in immersive environments.","sentences":["Selection of occluded objects is a challenging problem in virtual reality, even more so if multiple objects are involved.","With the advent of new artificial intelligence technologies, we explore the possibility of leveraging large language models to assist multi-object selection tasks in virtual reality via a multimodal speech and raycast interaction technique.","We validate the findings in a comparative user study (n=24), where participants selected target objects in a virtual reality scene with different levels of scene perplexity.","The performance metrics and user experience metrics are compared against a mini-map based occluded object selection technique that serves as the baseline.","Results indicate that the introduced technique, AssistVR, outperforms the baseline technique when there are multiple target objects.","Contrary to the common belief for speech interfaces, AssistVR was able to outperform the baseline even when the target objects were difficult to reference verbally.","This work demonstrates the viability and interaction potential of an intelligent multimodal interactive system powered by large laguage models.","Based on the results, we discuss the implications for design of future intelligent multimodal interactive systems in immersive environments."],"url":"http://arxiv.org/abs/2410.21091v1"}
{"created":"2024-10-28 14:51:04","title":"Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models","abstract":"The widespread use of AI-generated content from diffusion models has raised significant concerns regarding misinformation and copyright infringement. Watermarking is a crucial technique for identifying these AI-generated images and preventing their misuse. In this paper, we introduce Shallow Diffuse, a new watermarking technique that embeds robust and invisible watermarks into diffusion model outputs. Unlike existing approaches that integrate watermarking throughout the entire diffusion sampling process, Shallow Diffuse decouples these steps by leveraging the presence of a low-dimensional subspace in the image generation process. This method ensures that a substantial portion of the watermark lies in the null space of this subspace, effectively separating it from the image generation process. Our theoretical and empirical analyses show that this decoupling strategy greatly enhances the consistency of data generation and the detectability of the watermark. Extensive experiments further validate that our Shallow Diffuse outperforms existing watermarking methods in terms of robustness and consistency. The codes will be released at https://github.com/liwd190019/Shallow-Diffuse.","sentences":["The widespread use of AI-generated content from diffusion models has raised significant concerns regarding misinformation and copyright infringement.","Watermarking is a crucial technique for identifying these AI-generated images and preventing their misuse.","In this paper, we introduce Shallow Diffuse, a new watermarking technique that embeds robust and invisible watermarks into diffusion model outputs.","Unlike existing approaches that integrate watermarking throughout the entire diffusion sampling process, Shallow Diffuse decouples these steps by leveraging the presence of a low-dimensional subspace in the image generation process.","This method ensures that a substantial portion of the watermark lies in the null space of this subspace, effectively separating it from the image generation process.","Our theoretical and empirical analyses show that this decoupling strategy greatly enhances the consistency of data generation and the detectability of the watermark.","Extensive experiments further validate that our Shallow Diffuse outperforms existing watermarking methods in terms of robustness and consistency.","The codes will be released at https://github.com/liwd190019/Shallow-Diffuse."],"url":"http://arxiv.org/abs/2410.21088v1"}
{"created":"2024-10-28 14:49:18","title":"Efficient Mixture-of-Expert for Video-based Driver State and Physiological Multi-task Estimation in Conditional Autonomous Driving","abstract":"Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors. As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task. This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts. In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively. By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency. Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks. A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks. We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets. Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems. The code and data will be released.","sentences":["Road safety remains a critical challenge worldwide, with approximately 1.35 million fatalities annually attributed to traffic accidents, often due to human errors.","As we advance towards higher levels of vehicle automation, challenges still exist, as driving with automation can cognitively over-demand drivers if they engage in non-driving-related tasks (NDRTs), or lead to drowsiness if driving was the sole task.","This calls for the urgent need for an effective Driver Monitoring System (DMS) that can evaluate cognitive load and drowsiness in SAE Level-2/3 autonomous driving contexts.","In this study, we propose a novel multi-task DMS, termed VDMoE, which leverages RGB video input to monitor driver states non-invasively.","By utilizing key facial features to minimize computational load and integrating remote Photoplethysmography (rPPG) for physiological insights, our approach enhances detection accuracy while maintaining efficiency.","Additionally, we optimize the Mixture-of-Experts (MoE) framework to accommodate multi-modal inputs and improve performance across different tasks.","A novel prior-inclusive regularization method is introduced to align model outputs with statistical priors, thus accelerating convergence and mitigating overfitting risks.","We validate our method with the creation of a new dataset (MCDD), which comprises RGB video and physiological indicators from 42 participants, and two public datasets.","Our findings demonstrate the effectiveness of VDMoE in monitoring driver states, contributing to safer autonomous driving systems.","The code and data will be released."],"url":"http://arxiv.org/abs/2410.21086v1"}
{"created":"2024-10-28 14:49:17","title":"KA$^2$ER: Knowledge Adaptive Amalgamation of ExpeRts for Medical Images Segmentation","abstract":"Recently, many foundation models for medical image analysis such as MedSAM, SwinUNETR have been released and proven to be useful in multiple tasks. However, considering the inherent heterogeneity and inhomogeneity of real-world medical data, directly applying these models to specific medical image segmentation tasks often leads to negative domain shift effects, which can severely weaken the model's segmentation capabilities. To this end, we propose an adaptive amalgamation knowledge framework that aims to train a versatile foundation model to handle the joint goals of multiple expert models, each specialized for a distinct task. Specifically, we first train an nnUNet-based expert model for each task, and reuse the pre-trained SwinUNTER as the target foundation model. Then, the input data for all challenging tasks are encoded in the foundation model and the expert models, respectively, and their backbone features are jointly projected into the adaptive amalgamation layer. Within the hidden layer, the hierarchical attention mechanisms are designed to achieve adaptive merging of the target model to the hidden layer feature knowledge of all experts, which significantly reduces the domain shift arising from the inter-task differences. Finally, the gold amalgamated features and the prompt features are fed into the mask decoder to obtain the segmentation results. Extensive experiments conducted in these challenging tasks demonstrate the effectiveness and adaptability of our foundation model for real-world medical image segmentation.","sentences":["Recently, many foundation models for medical image analysis such as MedSAM, SwinUNETR have been released and proven to be useful in multiple tasks.","However, considering the inherent heterogeneity and inhomogeneity of real-world medical data, directly applying these models to specific medical image segmentation tasks often leads to negative domain shift effects, which can severely weaken the model's segmentation capabilities.","To this end, we propose an adaptive amalgamation knowledge framework that aims to train a versatile foundation model to handle the joint goals of multiple expert models, each specialized for a distinct task.","Specifically, we first train an nnUNet-based expert model for each task, and reuse the pre-trained SwinUNTER as the target foundation model.","Then, the input data for all challenging tasks are encoded in the foundation model and the expert models, respectively, and their backbone features are jointly projected into the adaptive amalgamation layer.","Within the hidden layer, the hierarchical attention mechanisms are designed to achieve adaptive merging of the target model to the hidden layer feature knowledge of all experts, which significantly reduces the domain shift arising from the inter-task differences.","Finally, the gold amalgamated features and the prompt features are fed into the mask decoder to obtain the segmentation results.","Extensive experiments conducted in these challenging tasks demonstrate the effectiveness and adaptability of our foundation model for real-world medical image segmentation."],"url":"http://arxiv.org/abs/2410.21085v1"}
{"created":"2024-10-28 14:48:05","title":"Stealthy Jailbreak Attacks on Large Language Models via Benign Data Mirroring","abstract":"Large language model (LLM) safety is a critical issue, with numerous studies employing red team testing to enhance model security. Among these, jailbreak methods explore potential vulnerabilities by crafting malicious prompts that induce model outputs contrary to safety alignments. Existing black-box jailbreak methods often rely on model feedback, repeatedly submitting queries with detectable malicious instructions during the attack search process. Although these approaches are effective, the attacks may be intercepted by content moderators during the search process. We propose an improved transfer attack method that guides malicious prompt construction by locally training a mirror model of the target black-box model through benign data distillation. This method offers enhanced stealth, as it does not involve submitting identifiable malicious instructions to the target model during the search phase. Our approach achieved a maximum attack success rate of 92%, or a balanced value of 80% with an average of 1.5 detectable jailbreak queries per sample against GPT-3.5 Turbo on a subset of AdvBench. These results underscore the need for more robust defense mechanisms.","sentences":["Large language model (LLM) safety is a critical issue, with numerous studies employing red team testing to enhance model security.","Among these, jailbreak methods explore potential vulnerabilities by crafting malicious prompts that induce model outputs contrary to safety alignments.","Existing black-box jailbreak methods often rely on model feedback, repeatedly submitting queries with detectable malicious instructions during the attack search process.","Although these approaches are effective, the attacks may be intercepted by content moderators during the search process.","We propose an improved transfer attack method that guides malicious prompt construction by locally training a mirror model of the target black-box model through benign data distillation.","This method offers enhanced stealth, as it does not involve submitting identifiable malicious instructions to the target model during the search phase.","Our approach achieved a maximum attack success rate of 92%, or a balanced value of 80% with an average of 1.5 detectable jailbreak queries per sample against GPT-3.5 Turbo on a subset of AdvBench.","These results underscore the need for more robust defense mechanisms."],"url":"http://arxiv.org/abs/2410.21083v1"}
{"created":"2024-10-28 14:35:12","title":"Skip2-LoRA: A Lightweight On-device DNN Fine-tuning Method for Low-cost Edge Devices","abstract":"This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep neural networks to address the gap between pre-trained and deployed models. In our approach, trainable LoRA (low-rank adaptation) adapters are inserted between the last layer and every other layer to enhance the network expressive power while keeping the backward computation cost low. This architecture is well-suited to cache intermediate computation results of the forward pass and then can skip the forward computation of seen samples as training epochs progress. We implemented the combination of the proposed architecture and cache, denoted as Skip2-LoRA, and tested it on a $15 single board computer. Our results show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average compared to the counterpart that has the same number of trainable parameters while preserving the accuracy, while taking only a few seconds on the microcontroller board.","sentences":["This paper proposes Skip2-LoRA as a lightweight fine-tuning method for deep neural networks to address the gap between pre-trained and deployed models.","In our approach, trainable LoRA (low-rank adaptation) adapters are inserted between the last layer and every other layer to enhance the network expressive power while keeping the backward computation cost low.","This architecture is well-suited to cache intermediate computation results of the forward pass and then can skip the forward computation of seen samples as training epochs progress.","We implemented the combination of the proposed architecture and cache, denoted as Skip2-LoRA, and tested it on a $15 single board computer.","Our results show that Skip2-LoRA reduces the fine-tuning time by 90.0% on average compared to the counterpart that has the same number of trainable parameters while preserving the accuracy, while taking only a few seconds on the microcontroller board."],"url":"http://arxiv.org/abs/2410.21073v1"}
{"created":"2024-10-28 14:35:07","title":"Federated Time Series Generation on Feature and Temporally Misaligned Data","abstract":"Distributed time series data presents a challenge for federated learning, as clients often possess different feature sets and have misaligned time steps. Existing federated time series models are limited by the assumption of perfect temporal or feature alignment across clients. In this paper, we propose FedTDD, a novel federated time series diffusion model that jointly learns a synthesizer across clients. At the core of FedTDD is a novel data distillation and aggregation framework that reconciles the differences between clients by imputing the misaligned timesteps and features. In contrast to traditional federated learning, FedTDD learns the correlation across clients' time series through the exchange of local synthetic outputs instead of model parameters. A coordinator iteratively improves a global distiller network by leveraging shared knowledge from clients through the exchange of synthetic data. As the distiller becomes more refined over time, it subsequently enhances the quality of the clients' local feature estimates, allowing each client to then improve its local imputations for missing data using the latest, more accurate distiller. Experimental results on five datasets demonstrate FedTDD's effectiveness compared to centralized training, and the effectiveness of sharing synthetic outputs to transfer knowledge of local time series. Notably, FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID and Correlational scores.","sentences":["Distributed time series data presents a challenge for federated learning, as clients often possess different feature sets and have misaligned time steps.","Existing federated time series models are limited by the assumption of perfect temporal or feature alignment across clients.","In this paper, we propose FedTDD, a novel federated time series diffusion model that jointly learns a synthesizer across clients.","At the core of FedTDD is a novel data distillation and aggregation framework that reconciles the differences between clients by imputing the misaligned timesteps and features.","In contrast to traditional federated learning, FedTDD learns the correlation across clients' time series through the exchange of local synthetic outputs instead of model parameters.","A coordinator iteratively improves a global distiller network by leveraging shared knowledge from clients through the exchange of synthetic data.","As the distiller becomes more refined over time, it subsequently enhances the quality of the clients' local feature estimates, allowing each client to then improve its local imputations for missing data using the latest, more accurate distiller.","Experimental results on five datasets demonstrate FedTDD's effectiveness compared to centralized training, and the effectiveness of sharing synthetic outputs to transfer knowledge of local time series.","Notably, FedTDD achieves 79.4% and 62.8% improvement over local training in Context-FID and Correlational scores."],"url":"http://arxiv.org/abs/2410.21072v1"}
