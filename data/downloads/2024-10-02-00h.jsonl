{"created":"2024-09-30 17:59:50","title":"Continuously Improving Mobile Manipulation with Autonomous Real-World RL","abstract":"We present a fully autonomous real-world RL framework for mobile manipulation that can learn policies without extensive instrumentation or human supervision. This is enabled by 1) task-relevant autonomy, which guides exploration towards object interactions and prevents stagnation near goal states, 2) efficient policy learning by leveraging basic task knowledge in behavior priors, and 3) formulating generic rewards that combine human-interpretable semantic information with low-level, fine-grained observations. We demonstrate that our approach allows Spot robots to continually improve their performance on a set of four challenging mobile manipulation tasks, obtaining an average success rate of 80% across tasks, a 3-4 improvement over existing approaches. Videos can be found at https://continual-mobile-manip.github.io/","sentences":["We present a fully autonomous real-world RL framework for mobile manipulation that can learn policies without extensive instrumentation or human supervision.","This is enabled by 1) task-relevant autonomy, which guides exploration towards object interactions and prevents stagnation near goal states, 2) efficient policy learning by leveraging basic task knowledge in behavior priors, and 3) formulating generic rewards that combine human-interpretable semantic information with low-level, fine-grained observations.","We demonstrate that our approach allows Spot robots to continually improve their performance on a set of four challenging mobile manipulation tasks, obtaining an average success rate of 80% across tasks, a 3-4 improvement over existing approaches.","Videos can be found at https://continual-mobile-manip.github.io/"],"url":"http://arxiv.org/abs/2409.20568v1"}
{"created":"2024-09-30 17:59:34","title":"MM1.5: Methods, Analysis & Insights from Multimodal LLM Fine-tuning","abstract":"We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning. Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle. This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning. Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B). Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding. Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development.","sentences":["We present MM1.5, a new family of multimodal large language models (MLLMs) designed to enhance capabilities in text-rich image understanding, visual referring and grounding, and multi-image reasoning.","Building upon the MM1 architecture, MM1.5 adopts a data-centric approach to model training, systematically exploring the impact of diverse data mixtures across the entire model training lifecycle.","This includes high-quality OCR data and synthetic captions for continual pre-training, as well as an optimized visual instruction-tuning data mixture for supervised fine-tuning.","Our models range from 1B to 30B parameters, encompassing both dense and mixture-of-experts (MoE) variants, and demonstrate that careful data curation and training strategies can yield strong performance even at small scales (1B and 3B).","Additionally, we introduce two specialized variants: MM1.5-Video, designed for video understanding, and MM1.5-UI, tailored for mobile UI understanding.","Through extensive empirical studies and ablations, we provide detailed insights into the training processes and decisions that inform our final designs, offering valuable guidance for future research in MLLM development."],"url":"http://arxiv.org/abs/2409.20566v1"}
{"created":"2024-09-30 17:59:33","title":"Ranking Over Scoring: Towards Reliable and Robust Automated Evaluation of LLM-Generated Medical Explanatory Arguments","abstract":"Evaluating LLM-generated text has become a key challenge, especially in domain-specific contexts like the medical field. This work introduces a novel evaluation methodology for LLM-generated medical explanatory arguments, relying on Proxy Tasks and rankings to closely align results with human evaluation criteria, overcoming the biases typically seen in LLMs used as judges. We demonstrate that the proposed evaluators are robust against adversarial attacks, including the assessment of non-argumentative text. Additionally, the human-crafted arguments needed to train the evaluators are minimized to just one example per Proxy Task. By examining multiple LLM-generated arguments, we establish a methodology for determining whether a Proxy Task is suitable for evaluating LLM-generated medical explanatory arguments, requiring only five examples and two human experts.","sentences":["Evaluating LLM-generated text has become a key challenge, especially in domain-specific contexts like the medical field.","This work introduces a novel evaluation methodology for LLM-generated medical explanatory arguments, relying on Proxy Tasks and rankings to closely align results with human evaluation criteria, overcoming the biases typically seen in LLMs used as judges.","We demonstrate that the proposed evaluators are robust against adversarial attacks, including the assessment of non-argumentative text.","Additionally, the human-crafted arguments needed to train the evaluators are minimized to just one example per Proxy Task.","By examining multiple LLM-generated arguments, we establish a methodology for determining whether a Proxy Task is suitable for evaluating LLM-generated medical explanatory arguments, requiring only five examples and two human experts."],"url":"http://arxiv.org/abs/2409.20565v1"}
{"created":"2024-09-30 17:59:15","title":"DressRecon: Freeform 4D Human Reconstruction from Monocular Video","abstract":"We present a method to reconstruct time-consistent human body models from monocular videos, focusing on extremely loose clothing or handheld object interactions. Prior work in human reconstruction is either limited to tight clothing with no object interactions, or requires calibrated multi-view captures or personalized template scans which are costly to collect at scale. Our key insight for high-quality yet flexible reconstruction is the careful combination of generic human priors about articulated body shape (learned from large-scale training data) with video-specific articulated \"bag-of-bones\" deformation (fit to a single video via test-time optimization). We accomplish this by learning a neural implicit model that disentangles body versus clothing deformations as separate motion model layers. To capture subtle geometry of clothing, we leverage image-based priors such as human body pose, surface normals, and optical flow during optimization. The resulting neural fields can be extracted into time-consistent meshes, or further optimized as explicit 3D Gaussians for high-fidelity interactive rendering. On datasets with highly challenging clothing deformations and object interactions, DressRecon yields higher-fidelity 3D reconstructions than prior art. Project page: https://jefftan969.github.io/dressrecon/","sentences":["We present a method to reconstruct time-consistent human body models from monocular videos, focusing on extremely loose clothing or handheld object interactions.","Prior work in human reconstruction is either limited to tight clothing with no object interactions, or requires calibrated multi-view captures or personalized template scans which are costly to collect at scale.","Our key insight for high-quality yet flexible reconstruction is the careful combination of generic human priors about articulated body shape (learned from large-scale training data) with video-specific articulated \"bag-of-bones\" deformation (fit to a single video via test-time optimization).","We accomplish this by learning a neural implicit model that disentangles body versus clothing deformations as separate motion model layers.","To capture subtle geometry of clothing, we leverage image-based priors such as human body pose, surface normals, and optical flow during optimization.","The resulting neural fields can be extracted into time-consistent meshes, or further optimized as explicit 3D Gaussians for high-fidelity interactive rendering.","On datasets with highly challenging clothing deformations and object interactions, DressRecon yields higher-fidelity 3D reconstructions than prior art.","Project page: https://jefftan969.github.io/dressrecon/"],"url":"http://arxiv.org/abs/2409.20563v1"}
{"created":"2024-09-30 17:59:03","title":"SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes","abstract":"Meshes are ubiquitous in visual computing and simulation, yet most existing machine learning techniques represent meshes only indirectly, e.g. as the level set of a scalar field or deformation of a template, or as a disordered triangle soup lacking local structure. This work presents a scheme to directly generate manifold, polygonal meshes of complex connectivity as the output of a neural network. Our key innovation is to define a continuous latent connectivity space at each mesh vertex, which implies the discrete mesh. In particular, our vertex embeddings generate cyclic neighbor relationships in a halfedge mesh representation, which gives a guarantee of edge-manifoldness and the ability to represent general polygonal meshes. This representation is well-suited to machine learning and stochastic optimization, without restriction on connectivity or topology. We first explore the basic properties of this representation, then use it to fit distributions of meshes from large datasets. The resulting models generate diverse meshes with tessellation structure learned from the dataset population, with concise details and high-quality mesh elements. In applications, this approach not only yields high-quality outputs from generative models, but also enables directly learning challenging geometry processing tasks such as mesh repair.","sentences":["Meshes are ubiquitous in visual computing and simulation, yet most existing machine learning techniques represent meshes only indirectly, e.g. as the level set of a scalar field or deformation of a template, or as a disordered triangle soup lacking local structure.","This work presents a scheme to directly generate manifold, polygonal meshes of complex connectivity as the output of a neural network.","Our key innovation is to define a continuous latent connectivity space at each mesh vertex, which implies the discrete mesh.","In particular, our vertex embeddings generate cyclic neighbor relationships in a halfedge mesh representation, which gives a guarantee of edge-manifoldness and the ability to represent general polygonal meshes.","This representation is well-suited to machine learning and stochastic optimization, without restriction on connectivity or topology.","We first explore the basic properties of this representation, then use it to fit distributions of meshes from large datasets.","The resulting models generate diverse meshes with tessellation structure learned from the dataset population, with concise details and high-quality mesh elements.","In applications, this approach not only yields high-quality outputs from generative models, but also enables directly learning challenging geometry processing tasks such as mesh repair."],"url":"http://arxiv.org/abs/2409.20562v1"}
{"created":"2024-09-30 17:58:18","title":"LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner","abstract":"Language models (LMs) possess a strong capability to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks. Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams. To address this issue, we propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that features household tasks with two different levels of complexity based on the AI2-THOR environment. The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multi-agent planners. The experimental videos, code, and datasets of this work as well as the detailed prompts used in each module are available at https://lamma-p.github.io.","sentences":["Language models (LMs) possess a strong capability to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks.","Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams.","To address this issue, we propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks.","LaMMA-P integrates the strengths of the LMs' reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks.","Additionally, we create MAT-THOR, a comprehensive benchmark that features household tasks with two different levels of complexity based on the AI2-THOR environment.","The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multi-agent planners.","The experimental videos, code, and datasets of this work as well as the detailed prompts used in each module are available at https://lamma-p.github.io."],"url":"http://arxiv.org/abs/2409.20560v1"}
{"created":"2024-09-30 17:58:03","title":"Supervised Multi-Modal Fission Learning","abstract":"Learning from multimodal datasets can leverage complementary information and improve performance in prediction tasks. A commonly used strategy to account for feature correlations in high-dimensional datasets is the latent variable approach. Several latent variable methods have been proposed for multimodal datasets. However, these methods either focus on extracting the shared component across all modalities or on extracting both a shared component and individual components specific to each modality. To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that simultaneously identifies globally joint, partially joint, and individual components underlying the features of multimodal datasets. Unlike existing latent variable methods, MMFL uses supervision from the response variable to identify predictive latent components and has a natural extension for incorporating incomplete multimodal data. Through simulation studies, we demonstrate that MMFL outperforms various existing multimodal algorithms in both complete and incomplete modality settings. We applied MMFL to a real-world case study for early prediction of Alzheimers Disease using multimodal neuroimaging and genomics data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset. MMFL provided more accurate predictions and better insights into within- and across-modality correlations compared to existing methods.","sentences":["Learning from multimodal datasets can leverage complementary information and improve performance in prediction tasks.","A commonly used strategy to account for feature correlations in high-dimensional datasets is the latent variable approach.","Several latent variable methods have been proposed for multimodal datasets.","However, these methods either focus on extracting the shared component across all modalities or on extracting both a shared component and individual components specific to each modality.","To address this gap, we propose a Multi-Modal Fission Learning (MMFL) model that simultaneously identifies globally joint, partially joint, and individual components underlying the features of multimodal datasets.","Unlike existing latent variable methods, MMFL uses supervision from the response variable to identify predictive latent components and has a natural extension for incorporating incomplete multimodal data.","Through simulation studies, we demonstrate that MMFL outperforms various existing multimodal algorithms in both complete and incomplete modality settings.","We applied MMFL to a real-world case study for early prediction of Alzheimers Disease using multimodal neuroimaging and genomics data from the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset.","MMFL provided more accurate predictions and better insights into within- and across-modality correlations compared to existing methods."],"url":"http://arxiv.org/abs/2409.20559v1"}
{"created":"2024-09-30 17:57:50","title":"Uni$^2$Det: Unified and Universal Framework for Prompt-Guided Multi-dataset 3D Detection","abstract":"We present Uni$^2$Det, a brand new framework for unified and universal multi-dataset training on 3D detection, enabling robust performance across diverse domains and generalization to unseen domains. Due to substantial disparities in data distribution and variations in taxonomy across diverse domains, training such a detector by simply merging datasets poses a significant challenge. Motivated by this observation, we introduce multi-stage prompting modules for multi-dataset 3D detection, which leverages prompts based on the characteristics of corresponding datasets to mitigate existing differences. This elegant design facilitates seamless plug-and-play integration within various advanced 3D detection frameworks in a unified manner, while also allowing straightforward adaptation for universal applicability across datasets. Experiments are conducted across multiple dataset consolidation scenarios involving KITTI, Waymo, and nuScenes, demonstrating that our Uni$^2$Det outperforms existing methods by a large margin in multi-dataset training. Notably, results on zero-shot cross-dataset transfer validate the generalization capability of our proposed method.","sentences":["We present Uni$^2$Det, a brand new framework for unified and universal multi-dataset training on 3D detection, enabling robust performance across diverse domains and generalization to unseen domains.","Due to substantial disparities in data distribution and variations in taxonomy across diverse domains, training such a detector by simply merging datasets poses a significant challenge.","Motivated by this observation, we introduce multi-stage prompting modules for multi-dataset 3D detection, which leverages prompts based on the characteristics of corresponding datasets to mitigate existing differences.","This elegant design facilitates seamless plug-and-play integration within various advanced 3D detection frameworks in a unified manner, while also allowing straightforward adaptation for universal applicability across datasets.","Experiments are conducted across multiple dataset consolidation scenarios involving KITTI, Waymo, and nuScenes, demonstrating that our Uni$^2$Det outperforms existing methods by a large margin in multi-dataset training.","Notably, results on zero-shot cross-dataset transfer validate the generalization capability of our proposed method."],"url":"http://arxiv.org/abs/2409.20558v1"}
{"created":"2024-09-30 17:57:28","title":"Propose, Assess, Search: Harnessing LLMs for Goal-Oriented Planning in Instructional Videos","abstract":"Goal-oriented planning, or anticipating a series of actions that transition an agent from its current state to a predefined objective, is crucial for developing intelligent assistants aiding users in daily procedural tasks. The problem presents significant challenges due to the need for comprehensive knowledge of temporal and hierarchical task structures, as well as strong capabilities in reasoning and planning. To achieve this, prior work typically relies on extensive training on the target dataset, which often results in significant dataset bias and a lack of generalization to unseen tasks. In this work, we introduce VidAssist, an integrated framework designed for zero/few-shot goal-oriented planning in instructional videos. VidAssist leverages large language models (LLMs) as both the knowledge base and the assessment tool for generating and evaluating action plans, thus overcoming the challenges of acquiring procedural knowledge from small-scale, low-diversity datasets. Moreover, VidAssist employs a breadth-first search algorithm for optimal plan generation, in which a composite of value functions designed for goal-oriented planning is utilized to assess the predicted actions at each step. Extensive experiments demonstrate that VidAssist offers a unified framework for different goal-oriented planning setups, e.g., visual planning for assistance (VPA) and procedural planning (PP), and achieves remarkable performance in zero-shot and few-shot setups. Specifically, our few-shot model outperforms the prior fully supervised state-of-the-art method by +7.7% in VPA and +4.81% PP task on the COIN dataset while predicting 4 future actions. Code, and models are publicly available at https://sites.google.com/view/vidassist.","sentences":["Goal-oriented planning, or anticipating a series of actions that transition an agent from its current state to a predefined objective, is crucial for developing intelligent assistants aiding users in daily procedural tasks.","The problem presents significant challenges due to the need for comprehensive knowledge of temporal and hierarchical task structures, as well as strong capabilities in reasoning and planning.","To achieve this, prior work typically relies on extensive training on the target dataset, which often results in significant dataset bias and a lack of generalization to unseen tasks.","In this work, we introduce VidAssist, an integrated framework designed for zero/few-shot goal-oriented planning in instructional videos.","VidAssist leverages large language models (LLMs) as both the knowledge base and the assessment tool for generating and evaluating action plans, thus overcoming the challenges of acquiring procedural knowledge from small-scale, low-diversity datasets.","Moreover, VidAssist employs a breadth-first search algorithm for optimal plan generation, in which a composite of value functions designed for goal-oriented planning is utilized to assess the predicted actions at each step.","Extensive experiments demonstrate that VidAssist offers a unified framework for different goal-oriented planning setups, e.g., visual planning for assistance (VPA) and procedural planning (PP), and achieves remarkable performance in zero-shot and few-shot setups.","Specifically, our few-shot model outperforms the prior fully supervised state-of-the-art method by +7.7% in VPA and +4.81% PP task on the COIN dataset while predicting 4 future actions.","Code, and models are publicly available at https://sites.google.com/view/vidassist."],"url":"http://arxiv.org/abs/2409.20557v1"}
{"created":"2024-09-30 17:56:52","title":"Inverse Painting: Reconstructing The Painting Process","abstract":"Given an input painting, we reconstruct a time-lapse video of how it may have been painted. We formulate this as an autoregressive image generation problem, in which an initially blank \"canvas\" is iteratively updated. The model learns from real artists by training on many painting videos. Our approach incorporates text and region understanding to define a set of painting \"instructions\" and updates the canvas with a novel diffusion-based renderer. The method extrapolates beyond the limited, acrylic style paintings on which it has been trained, showing plausible results for a wide range of artistic styles and genres.","sentences":["Given an input painting, we reconstruct a time-lapse video of how it may have been painted.","We formulate this as an autoregressive image generation problem, in which an initially blank \"canvas\" is iteratively updated.","The model learns from real artists by training on many painting videos.","Our approach incorporates text and region understanding to define a set of painting \"instructions\" and updates the canvas with a novel diffusion-based renderer.","The method extrapolates beyond the limited, acrylic style paintings on which it has been trained, showing plausible results for a wide range of artistic styles and genres."],"url":"http://arxiv.org/abs/2409.20556v1"}
{"created":"2024-09-30 17:55:27","title":"Online identification of skidding modes with interactive multiple model estimation","abstract":"Skid-steered wheel mobile robots (SSWMRs) operate in a variety of outdoor environments exhibiting motion behaviors dominated by the effects of complex wheel-ground interactions. Characterizing these interactions is crucial both from the immediate robot autonomy perspective (for motion prediction and control) as well as a long-term predictive maintenance and diagnostics perspective. An ideal solution entails capturing precise state measurements for decisions and controls, which is considerably difficult, especially in increasingly unstructured outdoor regimes of operations for these robots. In this milieu, a framework to identify pre-determined discrete modes of operation can considerably simplify the motion model identification process. To this end, we propose an interactive multiple model (IMM) based filtering framework to probabilistically identify predefined robot operation modes that could arise due to traversal in different terrains or loss of wheel traction.","sentences":["Skid-steered wheel mobile robots (SSWMRs) operate in a variety of outdoor environments exhibiting motion behaviors dominated by the effects of complex wheel-ground interactions.","Characterizing these interactions is crucial both from the immediate robot autonomy perspective (for motion prediction and control) as well as a long-term predictive maintenance and diagnostics perspective.","An ideal solution entails capturing precise state measurements for decisions and controls, which is considerably difficult, especially in increasingly unstructured outdoor regimes of operations for these robots.","In this milieu, a framework to identify pre-determined discrete modes of operation can considerably simplify the motion model identification process.","To this end, we propose an interactive multiple model (IMM) based filtering framework to probabilistically identify predefined robot operation modes that could arise due to traversal in different terrains or loss of wheel traction."],"url":"http://arxiv.org/abs/2409.20554v1"}
{"created":"2024-09-30 17:54:23","title":"Maia-2: A Unified Model for Human-AI Alignment in Chess","abstract":"There are an increasing number of domains in which artificial intelligence (AI) systems both surpass human ability and accurately model human behavior. This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making. Critical to achieving this goal, however, is coherently modeling human behavior at various skill levels. Chess is an ideal model system for conducting research into this kind of human-AI alignment, with its rich history as a pivotal testbed for AI research, mature superhuman AI systems like AlphaZero, and precise measurements of skill via chess rating systems. Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools. In this work, we propose a unified modeling approach for human-AI alignment in chess that coherently captures human style across different skill levels and directly captures how people improve. Recognizing the complex, non-linear nature of human learning, we introduce a skill-aware attention mechanism to dynamically integrate players' strengths with encoded chess positions, enabling our model to be sensitive to evolving player skill. Our experimental results demonstrate that this unified framework significantly enhances the alignment between AI and human players across a diverse range of expertise levels, paving the way for deeper insights into human decision-making and AI-guided teaching tools.","sentences":["There are an increasing number of domains in which artificial intelligence (AI) systems both surpass human ability and accurately model human behavior.","This introduces the possibility of algorithmically-informed teaching in these domains through more relatable AI partners and deeper insights into human decision-making.","Critical to achieving this goal, however, is coherently modeling human behavior at various skill levels.","Chess is an ideal model system for conducting research into this kind of human-AI alignment, with its rich history as a pivotal testbed for AI research, mature superhuman AI systems like AlphaZero, and precise measurements of skill via chess rating systems.","Previous work in modeling human decision-making in chess uses completely independent models to capture human style at different skill levels, meaning they lack coherence in their ability to adapt to the full spectrum of human improvement and are ultimately limited in their effectiveness as AI partners and teaching tools.","In this work, we propose a unified modeling approach for human-AI alignment in chess that coherently captures human style across different skill levels and directly captures how people improve.","Recognizing the complex, non-linear nature of human learning, we introduce a skill-aware attention mechanism to dynamically integrate players' strengths with encoded chess positions, enabling our model to be sensitive to evolving player skill.","Our experimental results demonstrate that this unified framework significantly enhances the alignment between AI and human players across a diverse range of expertise levels, paving the way for deeper insights into human decision-making and AI-guided teaching tools."],"url":"http://arxiv.org/abs/2409.20553v1"}
{"created":"2024-09-30 17:52:05","title":"UniAff: A Unified Representation of Affordances for Tool Usage and Articulation with Vision-Language Models","abstract":"Previous studies on robotic manipulation are based on a limited understanding of the underlying 3D motion constraints and affordances. To address these challenges, we propose a comprehensive paradigm, termed UniAff, that integrates 3D object-centric manipulation and task understanding in a unified formulation. Specifically, we constructed a dataset labeled with manipulation-related key attributes, comprising 900 articulated objects from 19 categories and 600 tools from 12 categories. Furthermore, we leverage MLLMs to infer object-centric representations for manipulation tasks, including affordance recognition and reasoning about 3D motion constraints. Comprehensive experiments in both simulation and real-world settings indicate that UniAff significantly improves the generalization of robotic manipulation for tools and articulated objects. We hope that UniAff will serve as a general baseline for unified robotic manipulation tasks in the future. Images, videos, dataset, and code are published on the project website at:https://sites.google.com/view/uni-aff/home","sentences":["Previous studies on robotic manipulation are based on a limited understanding of the underlying 3D motion constraints and affordances.","To address these challenges, we propose a comprehensive paradigm, termed UniAff, that integrates 3D object-centric manipulation and task understanding in a unified formulation.","Specifically, we constructed a dataset labeled with manipulation-related key attributes, comprising 900 articulated objects from 19 categories and 600 tools from 12 categories.","Furthermore, we leverage MLLMs to infer object-centric representations for manipulation tasks, including affordance recognition and reasoning about 3D motion constraints.","Comprehensive experiments in both simulation and real-world settings indicate that UniAff significantly improves the generalization of robotic manipulation for tools and articulated objects.","We hope that UniAff will serve as a general baseline for unified robotic manipulation tasks in the future.","Images, videos, dataset, and code are published on the project website at:https://sites.google.com/view/uni-aff/home"],"url":"http://arxiv.org/abs/2409.20551v1"}
{"created":"2024-09-30 17:51:15","title":"LLM Hallucinations in Practical Code Generation: Phenomena, Mechanism, and Mitigation","abstract":"Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency. Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task. Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process. Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation. In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario. First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code. Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models. We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations. Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs. The replication package including code, data, and experimental results is available at https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination","sentences":["Code generation aims to automatically generate code from input requirements, significantly enhancing development efficiency.","Recent large language models (LLMs) based approaches have shown promising results and revolutionized code generation task.","Despite the promising performance, LLMs often generate contents with hallucinations, especially for the code generation scenario requiring the handling of complex contextual dependencies in practical development process.","Although previous study has analyzed hallucinations in LLM-powered code generation, the study is limited to standalone function generation.","In this paper, we conduct an empirical study to study the phenomena, mechanism, and mitigation of LLM hallucinations within more practical and complex development contexts in repository-level generation scenario.","First, we manually examine the code generation results from six mainstream LLMs to establish a hallucination taxonomy of LLM-generated code.","Next, we elaborate on the phenomenon of hallucinations, analyze their distribution across different models.","We then analyze causes of hallucinations and identify four potential factors contributing to hallucinations.","Finally, we propose an RAG-based mitigation method, which demonstrates consistent effectiveness in all studied LLMs.","The replication package including code, data, and experimental results is available at https://github.com/DeepSoftwareAnalytics/LLMCodingHallucination"],"url":"http://arxiv.org/abs/2409.20550v1"}
{"created":"2024-09-30 17:49:09","title":"Robi Butler: Remote Multimodal Interactions with Household Robot Assistant","abstract":"In this paper, we introduce Robi Butler, a novel household robotic system that enables multimodal interactions with remote users. Building on the advanced communication interfaces, Robi Butler allows users to monitor the robot's status, send text or voice instructions, and select target objects by hand pointing. At the core of our system is a high-level behavior module, powered by Large Language Models (LLMs), that interprets multimodal instructions to generate action plans. These plans are composed of a set of open vocabulary primitives supported by Vision Language Models (VLMs) that handle both text and pointing queries. The integration of the above components allows Robi Butler to ground remote multimodal instructions in the real-world home environment in a zero-shot manner. We demonstrate the effectiveness and efficiency of this system using a variety of daily household tasks that involve remote users giving multimodal instructions. Additionally, we conducted a user study to analyze how multimodal interactions affect efficiency and user experience during remote human-robot interaction and discuss the potential improvements.","sentences":["In this paper, we introduce Robi Butler, a novel household robotic system that enables multimodal interactions with remote users.","Building on the advanced communication interfaces, Robi Butler allows users to monitor the robot's status, send text or voice instructions, and select target objects by hand pointing.","At the core of our system is a high-level behavior module, powered by Large Language Models (LLMs), that interprets multimodal instructions to generate action plans.","These plans are composed of a set of open vocabulary primitives supported by Vision Language Models (VLMs) that handle both text and pointing queries.","The integration of the above components allows Robi Butler to ground remote multimodal instructions in the real-world home environment in a zero-shot manner.","We demonstrate the effectiveness and efficiency of this system using a variety of daily household tasks that involve remote users giving multimodal instructions.","Additionally, we conducted a user study to analyze how multimodal interactions affect efficiency and user experience during remote human-robot interaction and discuss the potential improvements."],"url":"http://arxiv.org/abs/2409.20548v1"}
{"created":"2024-09-30 17:41:00","title":"Visual collective behaviors on spherical robots","abstract":"The implementation of collective motion, traditionally, disregard the limited sensing capabilities of an individual, to instead assuming an omniscient perception of the environment. This study implements a visual flocking model in a ``robot-in-the-loop'' approach to reproduce these behaviors with a flock composed of 10 independent spherical robots. The model achieves robotic collective motion by only using panoramic visual information of each robot, such as retinal position, optical size and optic flow of the neighboring robots. We introduce a virtual anchor to confine the collective robotic movements so to avoid wall interactions. For the first time, a simple visual robot-in-the-loop approach succeed in reproducing several collective motion phases, in particular, swarming, and milling. Another milestone achieved with by this model is bridging the gap between simulation and physical experiments by demonstrating nearly identical behaviors in both environments with the same visual model. To conclude, we show that our minimal visual collective motion model is sufficient to recreate most collective behaviors on a robot-in-the-loop system that is scalable, behaves as numerical simulations predict and is easily comparable to traditional models.","sentences":["The implementation of collective motion, traditionally, disregard the limited sensing capabilities of an individual, to instead assuming an omniscient perception of the environment.","This study implements a visual flocking model in a ``robot-in-the-loop'' approach to reproduce these behaviors with a flock composed of 10 independent spherical robots.","The model achieves robotic collective motion by only using panoramic visual information of each robot, such as retinal position, optical size and optic flow of the neighboring robots.","We introduce a virtual anchor to confine the collective robotic movements so to avoid wall interactions.","For the first time, a simple visual robot-in-the-loop approach succeed in reproducing several collective motion phases, in particular, swarming, and milling.","Another milestone achieved with by this model is bridging the gap between simulation and physical experiments by demonstrating nearly identical behaviors in both environments with the same visual model.","To conclude, we show that our minimal visual collective motion model is sufficient to recreate most collective behaviors on a robot-in-the-loop system that is scalable, behaves as numerical simulations predict and is easily comparable to traditional models."],"url":"http://arxiv.org/abs/2409.20539v1"}
{"created":"2024-09-30 17:39:41","title":"Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers","abstract":"One of the roadblocks for training generalist robotic models today is heterogeneity. Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting. This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale. We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation. This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks. Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity. We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets. HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings. See the project website (https://liruiw.github.io/hpt/) for code and videos.","sentences":["One of the roadblocks for training generalist robotic models today is heterogeneity.","Previous robot learning methods often collect data to train with one specific embodiment for one task, which is expensive and prone to overfitting.","This work studies the problem of learning policy representations through heterogeneous pre-training on robot data across different embodiments and tasks at scale.","We propose Heterogeneous Pre-trained Transformers (HPT), which pre-train a large, shareable trunk of a policy neural network to learn a task and embodiment agnostic shared representation.","This general architecture aligns the specific proprioception and vision inputs from distinct embodiments to a short sequence of tokens and then processes such tokens to map to control robots for different tasks.","Leveraging the recent large-scale multi-embodiment real-world robotic datasets as well as simulation, deployed robots, and human video datasets, we investigate pre-training policies across heterogeneity.","We conduct experiments to investigate the scaling behaviors of training objectives, to the extent of 52 datasets.","HPTs outperform several baselines and enhance the fine-tuned policy performance by over 20% on unseen tasks in multiple simulator benchmarks and real-world settings.","See the project website (https://liruiw.github.io/hpt/) for code and videos."],"url":"http://arxiv.org/abs/2409.20537v1"}
{"created":"2024-09-30 17:39:38","title":"Best Practices for Responsible Machine Learning in Credit Scoring","abstract":"The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making. However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems. This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability. We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups. Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications. Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness. By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices.","sentences":["The widespread use of machine learning in credit scoring has brought significant advancements in risk assessment and decision-making.","However, it has also raised concerns about potential biases, discrimination, and lack of transparency in these automated systems.","This tutorial paper performed a non-systematic literature review to guide best practices for developing responsible machine learning models in credit scoring, focusing on fairness, reject inference, and explainability.","We discuss definitions, metrics, and techniques for mitigating biases and ensuring equitable outcomes across different groups.","Additionally, we address the issue of limited data representativeness by exploring reject inference methods that incorporate information from rejected loan applications.","Finally, we emphasize the importance of transparency and explainability in credit models, discussing techniques that provide insights into the decision-making process and enable individuals to understand and potentially improve their creditworthiness.","By adopting these best practices, financial institutions can harness the power of machine learning while upholding ethical and responsible lending practices."],"url":"http://arxiv.org/abs/2409.20536v1"}
{"created":"2024-09-30 17:38:27","title":"End-to-End Conformal Calibration for Optimization Under Uncertainty","abstract":"Machine learning can significantly improve performance for decision-making under uncertainty in a wide range of domains. However, ensuring robustness guarantees requires well-calibrated uncertainty estimates, which can be difficult to achieve in high-capacity prediction models such as deep neural networks. Moreover, in high-dimensional settings, there may be many valid uncertainty estimates, each with their own performance profile - i.e., not all uncertainty is equally valuable for downstream decision-making. To address this problem, this paper develops an end-to-end framework to learn the uncertainty estimates for conditional robust optimization, with robustness and calibration guarantees provided by conformal prediction. In addition, we propose to represent arbitrary convex uncertainty sets with partially input-convex neural networks, which are learned as part of our framework. Our approach consistently improves upon two-stage estimate-then-optimize baselines on concrete applications in energy storage arbitrage and portfolio optimization.","sentences":["Machine learning can significantly improve performance for decision-making under uncertainty in a wide range of domains.","However, ensuring robustness guarantees requires well-calibrated uncertainty estimates, which can be difficult to achieve in high-capacity prediction models such as deep neural networks.","Moreover, in high-dimensional settings, there may be many valid uncertainty estimates, each with their own performance profile - i.e., not all uncertainty is equally valuable for downstream decision-making.","To address this problem, this paper develops an end-to-end framework to learn the uncertainty estimates for conditional robust optimization, with robustness and calibration guarantees provided by conformal prediction.","In addition, we propose to represent arbitrary convex uncertainty sets with partially input-convex neural networks, which are learned as part of our framework.","Our approach consistently improves upon two-stage estimate-then-optimize baselines on concrete applications in energy storage arbitrage and portfolio optimization."],"url":"http://arxiv.org/abs/2409.20534v1"}
{"created":"2024-09-30 17:30:23","title":"Dual Encoder GAN Inversion for High-Fidelity 3D Head Reconstruction from Single Images","abstract":"3D GAN inversion aims to project a single image into the latent space of a 3D Generative Adversarial Network (GAN), thereby achieving 3D geometry reconstruction. While there exist encoders that achieve good results in 3D GAN inversion, they are predominantly built on EG3D, which specializes in synthesizing near-frontal views and is limiting in synthesizing comprehensive 3D scenes from diverse viewpoints. In contrast to existing approaches, we propose a novel framework built on PanoHead, which excels in synthesizing images from a 360-degree perspective. To achieve realistic 3D modeling of the input image, we introduce a dual encoder system tailored for high-fidelity reconstruction and realistic generation from different viewpoints. Accompanying this, we propose a stitching framework on the triplane domain to get the best predictions from both. To achieve seamless stitching, both encoders must output consistent results despite being specialized for different tasks. For this reason, we carefully train these encoders using specialized losses, including an adversarial loss based on our novel occlusion-aware triplane discriminator. Experiments reveal that our approach surpasses the existing encoder training methods qualitatively and quantitatively. Please visit the project page: https://berkegokmen1.github.io/dual-enc-3d-gan-inv.","sentences":["3D GAN inversion aims to project a single image into the latent space of a 3D Generative Adversarial Network (GAN), thereby achieving 3D geometry reconstruction.","While there exist encoders that achieve good results in 3D GAN inversion, they are predominantly built on EG3D, which specializes in synthesizing near-frontal views and is limiting in synthesizing comprehensive 3D scenes from diverse viewpoints.","In contrast to existing approaches, we propose a novel framework built on PanoHead, which excels in synthesizing images from a 360-degree perspective.","To achieve realistic 3D modeling of the input image, we introduce a dual encoder system tailored for high-fidelity reconstruction and realistic generation from different viewpoints.","Accompanying this, we propose a stitching framework on the triplane domain to get the best predictions from both.","To achieve seamless stitching, both encoders must output consistent results despite being specialized for different tasks.","For this reason, we carefully train these encoders using specialized losses, including an adversarial loss based on our novel occlusion-aware triplane discriminator.","Experiments reveal that our approach surpasses the existing encoder training methods qualitatively and quantitatively.","Please visit the project page: https://berkegokmen1.github.io/dual-enc-3d-gan-inv."],"url":"http://arxiv.org/abs/2409.20530v1"}
{"created":"2024-09-30 17:26:23","title":"Bi-directional Momentum-based Haptic Feedback and Control System for Dexterous Telemanipulation","abstract":"Haptic feedback is essential for dexterous telemanipulation that enables operators to control robotic hands remotely with high skill and precision, mimicking a human hand's natural movement and sensation. However, current haptic methods for dexterous telemanipulation cannot support torque feedback, resulting in object rotation and rolling mismatches. The operator must make tedious adjustments in these tasks, leading to delays, reduced situational awareness, and suboptimal task performance. This work presents a Bi-directional Momentum-based Haptic Feedback and Control (Bi-Hap) system for real-time dexterous telemanipulation. Bi-Hap integrates multi-modal sensors to extract human interactive information with the object and share it with the robot's learning-based controller. A Field-Oriented Control (FOC) algorithm is developed to enable the integrated brushless active momentum wheel to generate precise torque and vibrative feedback, bridging the gap between human intent and robotic actions. Different feedback strategies are designed for varying error states to align with the operator's intuition. Extensive experiments with human subjects using a virtual Shadow Dexterous Hand demonstrate the effectiveness of Bi-Hap in enhancing task performance and user confidence. Bi-Hap achieved real-time feedback capability with low command following latency (delay<0.025s) and highly accurate torque feedback (RMSE<0.010 Nm).","sentences":["Haptic feedback is essential for dexterous telemanipulation that enables operators to control robotic hands remotely with high skill and precision, mimicking a human hand's natural movement and sensation.","However, current haptic methods for dexterous telemanipulation cannot support torque feedback, resulting in object rotation and rolling mismatches.","The operator must make tedious adjustments in these tasks, leading to delays, reduced situational awareness, and suboptimal task performance.","This work presents a Bi-directional Momentum-based Haptic Feedback and Control (Bi-Hap) system for real-time dexterous telemanipulation.","Bi-Hap integrates multi-modal sensors to extract human interactive information with the object and share it with the robot's learning-based controller.","A Field-Oriented Control (FOC) algorithm is developed to enable the integrated brushless active momentum wheel to generate precise torque and vibrative feedback, bridging the gap between human intent and robotic actions.","Different feedback strategies are designed for varying error states to align with the operator's intuition.","Extensive experiments with human subjects using a virtual Shadow Dexterous Hand demonstrate the effectiveness of Bi-Hap in enhancing task performance and user confidence.","Bi-Hap achieved real-time feedback capability with low command following latency (delay<0.025s) and highly accurate torque feedback (RMSE<0.010 Nm)."],"url":"http://arxiv.org/abs/2409.20527v1"}
{"created":"2024-09-30 17:22:33","title":"Word Sense Disambiguation in Native Spanish: A Comprehensive Lexical Evaluation Resource","abstract":"Human language, while aimed at conveying meaning, inherently carries ambiguity. It poses challenges for speech and language processing, but also serves crucial communicative functions. Efficiently solve ambiguity is both a desired and a necessary characteristic. The lexical meaning of a word in context can be determined automatically by Word Sense Disambiguation (WSD) algorithms that rely on external knowledge often limited and biased toward English. When adapting content to other languages, automated translations are frequently inaccurate and a high degree of expert human validation is necessary to ensure both accuracy and understanding. The current study addresses previous limitations by introducing a new resource for Spanish WSD. It includes a sense inventory and a lexical dataset sourced from the Diccionario de la Lengua Espa\\~nola which is maintained by the Real Academia Espa\\~nola. We also review current resources for Spanish and report metrics on them by a state-of-the-art system.","sentences":["Human language, while aimed at conveying meaning, inherently carries ambiguity.","It poses challenges for speech and language processing, but also serves crucial communicative functions.","Efficiently solve ambiguity is both a desired and a necessary characteristic.","The lexical meaning of a word in context can be determined automatically by Word Sense Disambiguation (WSD) algorithms that rely on external knowledge often limited and biased toward English.","When adapting content to other languages, automated translations are frequently inaccurate and a high degree of expert human validation is necessary to ensure both accuracy and understanding.","The current study addresses previous limitations by introducing a new resource for Spanish WSD.","It includes a sense inventory and a lexical dataset sourced from the Diccionario de la Lengua Espa\\~nola which is maintained by the Real Academia Espa\\~nola.","We also review current resources for Spanish and report metrics on them by a state-of-the-art system."],"url":"http://arxiv.org/abs/2409.20524v1"}
{"created":"2024-09-30 17:21:15","title":"Upper and Lower Bounds for Distributionally Robust Off-Dynamics Reinforcement Learning","abstract":"We study off-dynamics Reinforcement Learning (RL), where the policy training and deployment environments are different. To deal with this environmental perturbation, we focus on learning policies robust to uncertainties in transition dynamics under the framework of distributionally robust Markov decision processes (DRMDPs), where the nominal and perturbed dynamics are linear Markov Decision Processes. We propose a novel algorithm We-DRIVE-U that enjoys an average suboptimality $\\widetilde{\\mathcal{O}}\\big({d H \\cdot \\min \\{1/{\\rho}, H\\}/\\sqrt{K} }\\big)$, where $K$ is the number of episodes, $H$ is the horizon length, $d$ is the feature dimension and $\\rho$ is the uncertainty level. This result improves the state-of-the-art by $\\mathcal{O}(dH/\\min\\{1/\\rho,H\\})$. We also construct a novel hard instance and derive the first information-theoretic lower bound in this setting, which indicates our algorithm is near-optimal up to $\\mathcal{O}(\\sqrt{H})$ for any uncertainty level $\\rho\\in(0,1]$. Our algorithm also enjoys a 'rare-switching' design, and thus only requires $\\mathcal{O}(dH\\log(1+H^2K))$ policy switches and $\\mathcal{O}(d^2H\\log(1+H^2K))$ calls for oracle to solve dual optimization problems, which significantly improves the computational efficiency of existing algorithms for DRMDPs, whose policy switch and oracle complexities are both $\\mathcal{O}(K)$.","sentences":["We study off-dynamics Reinforcement Learning (RL), where the policy training and deployment environments are different.","To deal with this environmental perturbation, we focus on learning policies robust to uncertainties in transition dynamics under the framework of distributionally robust Markov decision processes (DRMDPs), where the nominal and perturbed dynamics are linear Markov Decision Processes.","We propose a novel algorithm We-DRIVE-U that enjoys an average suboptimality $\\widetilde{\\mathcal{O}}\\big({d H \\cdot \\min \\{1/{\\rho}, H\\}/\\sqrt{K} }\\big)$, where $K$ is the number of episodes, $H$ is the horizon length, $d$ is the feature dimension and $\\rho$ is the uncertainty level.","This result improves the state-of-the-art by $\\mathcal{O}(dH/\\min\\{1/\\rho,H\\})$. We also construct a novel hard instance and derive the first information-theoretic lower bound in this setting, which indicates our algorithm is near-optimal up to $\\mathcal{O}(\\sqrt{H})$ for any uncertainty level $\\rho\\in(0,1]$. Our algorithm also enjoys a 'rare-switching' design, and thus only requires $\\mathcal{O}(dH\\log(1+H^2K))$ policy switches and $\\mathcal{O}(d^2H\\log(1+H^2K))$ calls for oracle to solve dual optimization problems, which significantly improves the computational efficiency of existing algorithms for DRMDPs, whose policy switch and oracle complexities are both $\\mathcal{O}(K)$."],"url":"http://arxiv.org/abs/2409.20521v1"}
{"created":"2024-09-30 17:20:49","title":"Accelerating Non-Maximum Suppression: A Graph Theory Perspective","abstract":"Non-maximum suppression (NMS) is an indispensable post-processing step in object detection. With the continuous optimization of network models, NMS has become the ``last mile'' to enhance the efficiency of object detection. This paper systematically analyzes NMS from a graph theory perspective for the first time, revealing its intrinsic structure. Consequently, we propose two optimization methods, namely QSI-NMS and BOE-NMS. The former is a fast recursive divide-and-conquer algorithm with negligible mAP loss, and its extended version (eQSI-NMS) achieves optimal complexity of $\\mathcal{O}(n\\log n)$. The latter, concentrating on the locality of NMS, achieves an optimization at a constant level without an mAP loss penalty. Moreover, to facilitate rapid evaluation of NMS methods for researchers, we introduce NMS-Bench, the first benchmark designed to comprehensively assess various NMS methods. Taking the YOLOv8-N model on MS COCO 2017 as the benchmark setup, our method QSI-NMS provides $6.2\\times$ speed of original NMS on the benchmark, with a $0.1\\%$ decrease in mAP. The optimal eQSI-NMS, with only a $0.3\\%$ mAP decrease, achieves $10.7\\times$ speed. Meanwhile, BOE-NMS exhibits $5.1\\times$ speed with no compromise in mAP.","sentences":["Non-maximum suppression (NMS) is an indispensable post-processing step in object detection.","With the continuous optimization of network models, NMS has become the ``last mile'' to enhance the efficiency of object detection.","This paper systematically analyzes NMS from a graph theory perspective for the first time, revealing its intrinsic structure.","Consequently, we propose two optimization methods, namely QSI-NMS and BOE-NMS.","The former is a fast recursive divide-and-conquer algorithm with negligible mAP loss, and its extended version (eQSI-NMS) achieves optimal complexity of $\\mathcal{O}(n\\log n)$. The latter, concentrating on the locality of NMS, achieves an optimization at a constant level without an mAP loss penalty.","Moreover, to facilitate rapid evaluation of NMS methods for researchers, we introduce NMS-Bench, the first benchmark designed to comprehensively assess various NMS methods.","Taking the YOLOv8-N model on MS COCO 2017 as the benchmark setup, our method QSI-NMS provides $6.2\\times$ speed of original NMS on the benchmark, with a $0.1\\%$ decrease in mAP.","The optimal eQSI-NMS, with only a $0.3\\%$ mAP decrease, achieves $10.7\\times$ speed.","Meanwhile, BOE-NMS exhibits $5.1\\times$ speed with no compromise in mAP."],"url":"http://arxiv.org/abs/2409.20520v1"}
{"created":"2024-09-30 17:19:57","title":"SMLE: Safe Machine Learning via Embedded Overapproximation","abstract":"Despite the extent of recent advances in Machine Learning (ML) and Neural Networks, providing formal guarantees on the behavior of these systems is still an open problem, and a crucial requirement for their adoption in regulated or safety-critical scenarios. We consider the task of training differentiable ML models guaranteed to satisfy designer-chosen properties, stated as input-output implications. This is very challenging, due to the computational complexity of rigorously verifying and enforcing compliance in modern neural models. We provide an innovative approach based on three components: 1) a general, simple architecture enabling efficient verification with a conservative semantic; 2) a rigorous training algorithm based on the Projected Gradient Method; 3) a formulation of the problem of searching for strong counterexamples. The proposed framework, being only marginally affected by model complexity, scales well to practical applications, and produces models that provide full property satisfaction guarantees. We evaluate our approach on properties defined by linear inequalities in regression, and on mutually exclusive classes in multilabel classification. Our approach is competitive with a baseline that includes property enforcement during preprocessing, i.e. on the training data, as well as during postprocessing, i.e. on the model predictions. Finally, our contributions establish a framework that opens up multiple research directions and potential improvements.","sentences":["Despite the extent of recent advances in Machine Learning (ML) and Neural Networks, providing formal guarantees on the behavior of these systems is still an open problem, and a crucial requirement for their adoption in regulated or safety-critical scenarios.","We consider the task of training differentiable ML models guaranteed to satisfy designer-chosen properties, stated as input-output implications.","This is very challenging, due to the computational complexity of rigorously verifying and enforcing compliance in modern neural models.","We provide an innovative approach based on three components: 1) a general, simple architecture enabling efficient verification with a conservative semantic; 2) a rigorous training algorithm based on the Projected Gradient Method; 3) a formulation of the problem of searching for strong counterexamples.","The proposed framework, being only marginally affected by model complexity, scales well to practical applications, and produces models that provide full property satisfaction guarantees.","We evaluate our approach on properties defined by linear inequalities in regression, and on mutually exclusive classes in multilabel classification.","Our approach is competitive with a baseline that includes property enforcement during preprocessing, i.e. on the training data, as well as during postprocessing, i.e. on the model predictions.","Finally, our contributions establish a framework that opens up multiple research directions and potential improvements."],"url":"http://arxiv.org/abs/2409.20517v1"}
{"created":"2024-09-30 17:16:26","title":"Opt2Skill: Imitating Dynamically-feasible Whole-Body Trajectories for Versatile Humanoid Loco-Manipulation","abstract":"Humanoid robots are designed to perform diverse loco-manipulation tasks. However, they face challenges due to their high-dimensional and unstable dynamics, as well as the complex contact-rich nature of the tasks. Model-based optimal control methods offer precise and systematic control but are limited by high computational complexity and accurate contact sensing. On the other hand, reinforcement learning (RL) provides robustness and handles high-dimensional spaces but suffers from inefficient learning, unnatural motion, and sim-to-real gaps. To address these challenges, we introduce Opt2Skill, an end-to-end pipeline that combines model-based trajectory optimization with RL to achieve robust whole-body loco-manipulation. We generate reference motions for the Digit humanoid robot using differential dynamic programming (DDP) and train RL policies to track these trajectories. Our results demonstrate that Opt2Skill outperforms pure RL methods in both training efficiency and task performance, with optimal trajectories that account for torque limits enhancing trajectory tracking. We successfully transfer our approach to real-world applications.","sentences":["Humanoid robots are designed to perform diverse loco-manipulation tasks.","However, they face challenges due to their high-dimensional and unstable dynamics, as well as the complex contact-rich nature of the tasks.","Model-based optimal control methods offer precise and systematic control but are limited by high computational complexity and accurate contact sensing.","On the other hand, reinforcement learning (RL) provides robustness and handles high-dimensional spaces but suffers from inefficient learning, unnatural motion, and sim-to-real gaps.","To address these challenges, we introduce Opt2Skill, an end-to-end pipeline that combines model-based trajectory optimization with RL to achieve robust whole-body loco-manipulation.","We generate reference motions for the Digit humanoid robot using differential dynamic programming (DDP) and train RL policies to track these trajectories.","Our results demonstrate that Opt2Skill outperforms pure RL methods in both training efficiency and task performance, with optimal trajectories that account for torque limits enhancing trajectory tracking.","We successfully transfer our approach to real-world applications."],"url":"http://arxiv.org/abs/2409.20514v1"}
{"created":"2024-09-30 17:10:25","title":"NUTRIVISION: A System for Automatic Diet Management in Smart Healthcare","abstract":"Maintaining health and fitness through a balanced diet is essential for preventing non communicable diseases such as heart disease, diabetes, and cancer. NutriVision combines smart healthcare with computer vision and machine learning to address the challenges of nutrition and dietary management. This paper introduces a novel system that can identify food items, estimate quantities, and provide comprehensive nutritional information. NutriVision employs the Faster Region based Convolutional Neural Network, a deep learning algorithm that improves object detection by generating region proposals and then classifying those regions, making it highly effective for accurate and fast food identification even in complex and disorganized meal settings. Through smartphone based image capture, NutriVision delivers instant nutritional data, including macronutrient breakdown, calorie count, and micronutrient details. One of the standout features of NutriVision is its personalized nutritional analysis and diet recommendations, which are tailored to each user's dietary preferences, nutritional needs, and health history. By providing customized advice, NutriVision helps users achieve specific health and fitness goals, such as managing dietary restrictions or controlling weight. In addition to offering precise food detection and nutritional assessment, NutriVision supports smarter dietary decisions by integrating user data with recommendations that promote a balanced, healthful diet. This system presents a practical and advanced solution for nutrition management and has the potential to significantly influence how people approach their dietary choices, promoting healthier eating habits and overall well being. This paper discusses the design, performance evaluation, and prospective applications of the NutriVision system.","sentences":["Maintaining health and fitness through a balanced diet is essential for preventing non communicable diseases such as heart disease, diabetes, and cancer.","NutriVision combines smart healthcare with computer vision and machine learning to address the challenges of nutrition and dietary management.","This paper introduces a novel system that can identify food items, estimate quantities, and provide comprehensive nutritional information.","NutriVision employs the Faster Region based Convolutional Neural Network, a deep learning algorithm that improves object detection by generating region proposals and then classifying those regions, making it highly effective for accurate and fast food identification even in complex and disorganized meal settings.","Through smartphone based image capture, NutriVision delivers instant nutritional data, including macronutrient breakdown, calorie count, and micronutrient details.","One of the standout features of NutriVision is its personalized nutritional analysis and diet recommendations, which are tailored to each user's dietary preferences, nutritional needs, and health history.","By providing customized advice, NutriVision helps users achieve specific health and fitness goals, such as managing dietary restrictions or controlling weight.","In addition to offering precise food detection and nutritional assessment, NutriVision supports smarter dietary decisions by integrating user data with recommendations that promote a balanced, healthful diet.","This system presents a practical and advanced solution for nutrition management and has the potential to significantly influence how people approach their dietary choices, promoting healthier eating habits and overall well being.","This paper discusses the design, performance evaluation, and prospective applications of the NutriVision system."],"url":"http://arxiv.org/abs/2409.20508v1"}
{"created":"2024-09-30 17:03:13","title":"What Information Contributes to Log-based Anomaly Detection? Insights from a Configurable Transformer-Based Approach","abstract":"Log data are generated from logging statements in the source code, providing insights into the execution processes of software applications and systems. State-of-the-art log-based anomaly detection approaches typically leverage deep learning models to capture the semantic or sequential information in the log data and detect anomalous runtime behaviors. However, the impacts of these different types of information are not clear. In addition, existing approaches have not captured the timestamps in the log data, which can potentially provide more fine-grained temporal information than sequential information. In this work, we propose a configurable transformer-based anomaly detection model that can capture the semantic, sequential, and temporal information in the log data and allows us to configure the different types of information as the model's features. Additionally, we train and evaluate the proposed model using log sequences of different lengths, thus overcoming the constraint of existing methods that rely on fixed-length or time-windowed log sequences as inputs. With the proposed model, we conduct a series of experiments with different combinations of input features to evaluate the roles of different types of information in anomaly detection. When presented with log sequences of varying lengths, the model can attain competitive and consistently stable performance compared to the baselines. The results indicate that the event occurrence information plays a key role in identifying anomalies, while the impact of the sequential and temporal information is not significant for anomaly detection in the studied public datasets. On the other hand, the findings also reveal the simplicity of the studied public datasets and highlight the importance of constructing new datasets that contain different types of anomalies to better evaluate the performance of anomaly detection models.","sentences":["Log data are generated from logging statements in the source code, providing insights into the execution processes of software applications and systems.","State-of-the-art log-based anomaly detection approaches typically leverage deep learning models to capture the semantic or sequential information in the log data and detect anomalous runtime behaviors.","However, the impacts of these different types of information are not clear.","In addition, existing approaches have not captured the timestamps in the log data, which can potentially provide more fine-grained temporal information than sequential information.","In this work, we propose a configurable transformer-based anomaly detection model that can capture the semantic, sequential, and temporal information in the log data and allows us to configure the different types of information as the model's features.","Additionally, we train and evaluate the proposed model using log sequences of different lengths, thus overcoming the constraint of existing methods that rely on fixed-length or time-windowed log sequences as inputs.","With the proposed model, we conduct a series of experiments with different combinations of input features to evaluate the roles of different types of information in anomaly detection.","When presented with log sequences of varying lengths, the model can attain competitive and consistently stable performance compared to the baselines.","The results indicate that the event occurrence information plays a key role in identifying anomalies, while the impact of the sequential and temporal information is not significant for anomaly detection in the studied public datasets.","On the other hand, the findings also reveal the simplicity of the studied public datasets and highlight the importance of constructing new datasets that contain different types of anomalies to better evaluate the performance of anomaly detection models."],"url":"http://arxiv.org/abs/2409.20503v1"}
{"created":"2024-09-30 17:02:13","title":"COLLAGE: Collaborative Human-Agent Interaction Generation using Hierarchical Latent Diffusion and Language Models","abstract":"We propose a novel framework COLLAGE for generating collaborative agent-object-agent interactions by leveraging large language models (LLMs) and hierarchical motion-specific vector-quantized variational autoencoders (VQ-VAEs). Our model addresses the lack of rich datasets in this domain by incorporating the knowledge and reasoning abilities of LLMs to guide a generative diffusion model. The hierarchical VQ-VAE architecture captures different motion-specific characteristics at multiple levels of abstraction, avoiding redundant concepts and enabling efficient multi-resolution representation. We introduce a diffusion model that operates in the latent space and incorporates LLM-generated motion planning cues to guide the denoising process, resulting in prompt-specific motion generation with greater control and diversity. Experimental results on the CORE-4D, and InterHuman datasets demonstrate the effectiveness of our approach in generating realistic and diverse collaborative human-object-human interactions, outperforming state-of-the-art methods. Our work opens up new possibilities for modeling complex interactions in various domains, such as robotics, graphics and computer vision.","sentences":["We propose a novel framework COLLAGE for generating collaborative agent-object-agent interactions by leveraging large language models (LLMs) and hierarchical motion-specific vector-quantized variational autoencoders (VQ-VAEs).","Our model addresses the lack of rich datasets in this domain by incorporating the knowledge and reasoning abilities of LLMs to guide a generative diffusion model.","The hierarchical VQ-VAE architecture captures different motion-specific characteristics at multiple levels of abstraction, avoiding redundant concepts and enabling efficient multi-resolution representation.","We introduce a diffusion model that operates in the latent space and incorporates LLM-generated motion planning cues to guide the denoising process, resulting in prompt-specific motion generation with greater control and diversity.","Experimental results on the CORE-4D, and InterHuman datasets demonstrate the effectiveness of our approach in generating realistic and diverse collaborative human-object-human interactions, outperforming state-of-the-art methods.","Our work opens up new possibilities for modeling complex interactions in various domains, such as robotics, graphics and computer vision."],"url":"http://arxiv.org/abs/2409.20502v1"}
{"created":"2024-09-30 17:01:32","title":"Packet Aggregation May Harm Batched Network Coding","abstract":"Batched network coding (BNC) is a solution to multi-hop transmission on networks with packet loss. To be compatible with the existing infrastructure, BNC is usually implemented over UDP. A single error bit will probably result in discarding the packet. UDP-Lite is a variant of UDP that supports partial checksums. As long as the data covered by the checksum is correct, damaged payload will be delivered. With UDP-Lite, we can cope with other techniques such as payload aggregation of BNC packets to reduce the protocol overhead, and forward error correction to combat against bit errors. Unlike traditional transmissions, BNC has a loss resilience feature and there are dependencies between BNC packets. In this paper, we conduct a preliminary investigation on BNC over UDP-Lite. We show that aggregating as much as we can is not always the best strategy, and a hop-by-hop distributed efficiency optimization approach may lead to a worse throughput compared with the scheme without aggregation in a long network. These unnatural results caution that a casual integration of techniques with BNC can be harmful, and give us hints on future research directions.","sentences":["Batched network coding (BNC) is a solution to multi-hop transmission on networks with packet loss.","To be compatible with the existing infrastructure, BNC is usually implemented over UDP.","A single error bit will probably result in discarding the packet.","UDP-Lite is a variant of UDP that supports partial checksums.","As long as the data covered by the checksum is correct, damaged payload will be delivered.","With UDP-Lite, we can cope with other techniques such as payload aggregation of BNC packets to reduce the protocol overhead, and forward error correction to combat against bit errors.","Unlike traditional transmissions, BNC has a loss resilience feature and there are dependencies between BNC packets.","In this paper, we conduct a preliminary investigation on BNC over UDP-Lite.","We show that aggregating as much as we can is not always the best strategy, and a hop-by-hop distributed efficiency optimization approach may lead to a worse throughput compared with the scheme without aggregation in a long network.","These unnatural results caution that a casual integration of techniques with BNC can be harmful, and give us hints on future research directions."],"url":"http://arxiv.org/abs/2409.20501v1"}
{"created":"2024-09-30 17:01:26","title":"FreeMask: Rethinking the Importance of Attention Masks for Zero-Shot Video Editing","abstract":"Text-to-video diffusion models have made remarkable advancements. Driven by their ability to generate temporally coherent videos, research on zero-shot video editing using these fundamental models has expanded rapidly. To enhance editing quality, structural controls are frequently employed in video editing. Among these techniques, cross-attention mask control stands out for its effectiveness and efficiency. However, when cross-attention masks are naively applied to video editing, they can introduce artifacts such as blurring and flickering. Our experiments uncover a critical factor overlooked in previous video editing research: cross-attention masks are not consistently clear but vary with model structure and denoising timestep. To address this issue, we propose the metric Mask Matching Cost (MMC) that quantifies this variability and propose FreeMask, a method for selecting optimal masks tailored to specific video editing tasks. Using MMC-selected masks, we further improve the masked fusion mechanism within comprehensive attention features, e.g., temp, cross, and self-attention modules. Our approach can be seamlessly integrated into existing zero-shot video editing frameworks with better performance, requiring no control assistance or parameter fine-tuning but enabling adaptive decoupling of unedited semantic layouts with mask precision control. Extensive experiments demonstrate that FreeMask achieves superior semantic fidelity, temporal consistency, and editing quality compared to state-of-the-art methods.","sentences":["Text-to-video diffusion models have made remarkable advancements.","Driven by their ability to generate temporally coherent videos, research on zero-shot video editing using these fundamental models has expanded rapidly.","To enhance editing quality, structural controls are frequently employed in video editing.","Among these techniques, cross-attention mask control stands out for its effectiveness and efficiency.","However, when cross-attention masks are naively applied to video editing, they can introduce artifacts such as blurring and flickering.","Our experiments uncover a critical factor overlooked in previous video editing research: cross-attention masks are not consistently clear but vary with model structure and denoising timestep.","To address this issue, we propose the metric Mask Matching Cost (MMC) that quantifies this variability and propose FreeMask, a method for selecting optimal masks tailored to specific video editing tasks.","Using MMC-selected masks, we further improve the masked fusion mechanism within comprehensive attention features, e.g., temp, cross, and self-attention modules.","Our approach can be seamlessly integrated into existing zero-shot video editing frameworks with better performance, requiring no control assistance or parameter fine-tuning but enabling adaptive decoupling of unedited semantic layouts with mask precision control.","Extensive experiments demonstrate that FreeMask achieves superior semantic fidelity, temporal consistency, and editing quality compared to state-of-the-art methods."],"url":"http://arxiv.org/abs/2409.20500v1"}
{"created":"2024-09-30 16:59:48","title":"Enhancing Romanian Offensive Language Detection through Knowledge Distillation, Multi-Task Learning, and Data Augmentation","abstract":"This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language. Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers. This paper explores advanced methodologies for attaining smaller and more efficient NLP models. Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency. The culmination of these methods has yielded demonstrably improved outcomes.","sentences":["This paper highlights the significance of natural language processing (NLP) within artificial intelligence, underscoring its pivotal role in comprehending and modeling human language.","Recent advancements in NLP, particularly in conversational bots, have garnered substantial attention and adoption among developers.","This paper explores advanced methodologies for attaining smaller and more efficient NLP models.","Specifically, we employ three key approaches: (1) training a Transformer-based neural network to detect offensive language, (2) employing data augmentation and knowledge distillation techniques to increase performance, and (3) incorporating multi-task learning with knowledge distillation and teacher annealing using diverse datasets to enhance efficiency.","The culmination of these methods has yielded demonstrably improved outcomes."],"url":"http://arxiv.org/abs/2409.20498v1"}
{"created":"2024-09-30 16:57:45","title":"An Effectively $\u03a9(c)$ Language and Runtime","abstract":"The performance of an application/runtime is usually thought of as a continuous function where, the lower the amount of memory/time used on a given workload, then the better the compiler/runtime is. However, in practice, good performance of an application is conceptually more of a binary function -- either the application responds in under, say 100ms, and is fast enough for a user to barely notice, or it takes a noticeable amount of time, leaving the user waiting and potentially abandoning the task. Thus, performance really means how often the application is fast enough to be usable, leading industrial developers to focus on the 95th and 99th percentile latencies as heavily, or moreso, than average response time.   Unfortunately, tracking and optimizing for these high percentile latencies is difficult and often requires a deep understanding of the application, runtime, GC, and OS interactions. This is further complicated by the fact that tail performance is often only seen occasionally, and is specific to a certain workload or input, making these issues uniquely painful to handle. Our vision is to create a language and runtime that is designed to be $\\Omega(c)$ in its performance -- that is, it is designed to have an effectively constant time to execute all operations, there is a constant fixed memory overhead for the application footprint, and the garbage-collector performs a constant amount of work per allocation + a (small) bounded pause for all collection/release operations.","sentences":["The performance of an application/runtime is usually thought of as a continuous function where, the lower the amount of memory/time used on a given workload, then the better the compiler/runtime is.","However, in practice, good performance of an application is conceptually more of a binary function -- either the application responds in under, say 100ms, and is fast enough for a user to barely notice, or it takes a noticeable amount of time, leaving the user waiting and potentially abandoning the task.","Thus, performance really means how often the application is fast enough to be usable, leading industrial developers to focus on the 95th and 99th percentile latencies as heavily, or moreso, than average response time.   ","Unfortunately, tracking and optimizing for these high percentile latencies is difficult and often requires a deep understanding of the application, runtime, GC, and OS interactions.","This is further complicated by the fact that tail performance is often only seen occasionally, and is specific to a certain workload or input, making these issues uniquely painful to handle.","Our vision is to create a language and runtime that is designed to be $\\Omega(c)$ in its performance -- that is, it is designed to have an effectively constant time to execute all operations, there is a constant fixed memory overhead for the application footprint, and the garbage-collector performs a constant amount of work per allocation + a (small) bounded pause for all collection/release operations."],"url":"http://arxiv.org/abs/2409.20494v1"}
{"created":"2024-09-30 16:53:30","title":"Age of Gossip with the Push-Pull Protocol","abstract":"We consider a wireless network where a source generates packets and forwards them to a network containing $n$ nodes. The nodes in the network use the asynchronous push, pull or push-pull gossip communication protocols to maintain the most recent updates from the source. We use the version age of information metric to quantify the freshness of information in the network. Prior to this work, only the push gossiping protocol has been studied for age of information analysis. In this paper, we use the stochastic hybrid systems (SHS) framework to obtain recursive equations for the expected version age of sets of nodes in the time limit. We then show that the pull and push-pull protocols can achieve constant version age, while it is already known that the push protocol can only achieve logarithmic version age. We then show that the push-pull protocol performs better than the push and the pull protocol. Finally, we carry out numerical simulations to evaluate these results.","sentences":["We consider a wireless network where a source generates packets and forwards them to a network containing $n$ nodes.","The nodes in the network use the asynchronous push, pull or push-pull gossip communication protocols to maintain the most recent updates from the source.","We use the version age of information metric to quantify the freshness of information in the network.","Prior to this work, only the push gossiping protocol has been studied for age of information analysis.","In this paper, we use the stochastic hybrid systems (SHS) framework to obtain recursive equations for the expected version age of sets of nodes in the time limit.","We then show that the pull and push-pull protocols can achieve constant version age, while it is already known that the push protocol can only achieve logarithmic version age.","We then show that the push-pull protocol performs better than the push and the pull protocol.","Finally, we carry out numerical simulations to evaluate these results."],"url":"http://arxiv.org/abs/2409.20490v1"}
{"created":"2024-09-30 16:53:27","title":"Online Decision Deferral under Budget Constraints","abstract":"Machine Learning (ML) models are increasingly used to support or substitute decision making. In applications where skilled experts are a limited resource, it is crucial to reduce their burden and automate decisions when the performance of an ML model is at least of equal quality. However, models are often pre-trained and fixed, while tasks arrive sequentially and their distribution may shift. In that case, the respective performance of the decision makers may change, and the deferral algorithm must remain adaptive. We propose a contextual bandit model of this online decision making problem. Our framework includes budget constraints and different types of partial feedback models. Beyond the theoretical guarantees of our algorithm, we propose efficient extensions that achieve remarkable performance on real-world datasets.","sentences":["Machine Learning (ML) models are increasingly used to support or substitute decision making.","In applications where skilled experts are a limited resource, it is crucial to reduce their burden and automate decisions when the performance of an ML model is at least of equal quality.","However, models are often pre-trained and fixed, while tasks arrive sequentially and their distribution may shift.","In that case, the respective performance of the decision makers may change, and the deferral algorithm must remain adaptive.","We propose a contextual bandit model of this online decision making problem.","Our framework includes budget constraints and different types of partial feedback models.","Beyond the theoretical guarantees of our algorithm, we propose efficient extensions that achieve remarkable performance on real-world datasets."],"url":"http://arxiv.org/abs/2409.20489v1"}
{"created":"2024-09-30 16:52:37","title":"Evaluating the Impact of Convolutional Neural Network Layer Depth on the Enhancement of Inertial Navigation System Solutions","abstract":"Secure navigation is pivotal for several applications including autonomous vehicles, robotics, and aviation. The inertial navigation system estimates position, velocity, and attitude through dead reckoning especially when external references like GPS are unavailable. However, the three accelerometers and three gyroscopes that compose the system are exposed to various types of errors including bias errors, scale factor errors, and noise, which can significantly degrade the accuracy of navigation constituting also a key vulnerability of this system. This work aims to adopt a supervised convolutional neural network (ConvNet) to address this vulnerability inherent in inertial navigation systems. In addition to this, this paper evaluates the impact of the ConvNet layer's depth on the accuracy of these corrections. This evaluation aims to determine the optimal layer configuration maximizing the effectiveness of error correction in INS (Inertial Navigation System) leading to precise navigation solutions.","sentences":["Secure navigation is pivotal for several applications including autonomous vehicles, robotics, and aviation.","The inertial navigation system estimates position, velocity, and attitude through dead reckoning especially when external references like GPS are unavailable.","However, the three accelerometers and three gyroscopes that compose the system are exposed to various types of errors including bias errors, scale factor errors, and noise, which can significantly degrade the accuracy of navigation constituting also a key vulnerability of this system.","This work aims to adopt a supervised convolutional neural network (ConvNet) to address this vulnerability inherent in inertial navigation systems.","In addition to this, this paper evaluates the impact of the ConvNet layer's depth on the accuracy of these corrections.","This evaluation aims to determine the optimal layer configuration maximizing the effectiveness of error correction in INS (Inertial Navigation System) leading to precise navigation solutions."],"url":"http://arxiv.org/abs/2409.20488v1"}
{"created":"2024-09-30 16:51:30","title":"Propelling Innovation to Defeat Data-Leakage Hardware Trojans: From Theory to Practice","abstract":"Many design companies have gone fabless and rely on external fabrication facilities to produce chips due to increasing cost of semiconductor manufacturing. However, not all of these facilities can be considered trustworthy; some may inject hardware Trojans and jeopardize the security of the system. One common objective of hardware Trojans is to establish a side channel for data leakage. While extensive literature exists on various defensive measures, almost all of them focus on preventing the establishment of side channels, and can be compromised if attackers gain access to the physical chip and can perform reverse engineering between multiple fabrication runs. In this paper, we advance (from theory to practice) RECORD: Randomized Encoding of COmbinational Logic for Resistance to Data Leakage. RECORD is a novel scheme of temporarily randomized encoding for combinational logic that, with the aid of Quilt Packaging, prevents attackers from interpreting the data.","sentences":["Many design companies have gone fabless and rely on external fabrication facilities to produce chips due to increasing cost of semiconductor manufacturing.","However, not all of these facilities can be considered trustworthy; some may inject hardware Trojans and jeopardize the security of the system.","One common objective of hardware Trojans is to establish a side channel for data leakage.","While extensive literature exists on various defensive measures, almost all of them focus on preventing the establishment of side channels, and can be compromised if attackers gain access to the physical chip and can perform reverse engineering between multiple fabrication runs.","In this paper, we advance (from theory to practice) RECORD:","Randomized Encoding of COmbinational Logic for Resistance to Data Leakage.","RECORD is a novel scheme of temporarily randomized encoding for combinational logic that, with the aid of Quilt Packaging, prevents attackers from interpreting the data."],"url":"http://arxiv.org/abs/2409.20486v1"}
{"created":"2024-09-30 16:42:57","title":"RecSys Challenge 2024: Balancing Accuracy and Editorial Values in News Recommendations","abstract":"The RecSys Challenge 2024 aims to advance news recommendation by addressing both the technical and normative challenges inherent in designing effective and responsible recommender systems for news publishing. This paper describes the challenge, including its objectives, problem setting, and the dataset provided by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group (\"Ekstra Bladet\"). The challenge explores the unique aspects of news recommendation, such as modeling user preferences based on behavior, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items. Additionally, the challenge embraces normative complexities, investigating the effects of recommender systems on news flow and their alignment with editorial values. We summarize the challenge setup, dataset characteristics, and evaluation metrics. Finally, we announce the winners and highlight their contributions. The dataset is available at: https://recsys.eb.dk.","sentences":["The RecSys Challenge 2024 aims to advance news recommendation by addressing both the technical and normative challenges inherent in designing effective and responsible recommender systems for news publishing.","This paper describes the challenge, including its objectives, problem setting, and the dataset provided by the Danish news publishers Ekstra Bladet and JP/Politikens Media Group (\"Ekstra Bladet\").","The challenge explores the unique aspects of news recommendation, such as modeling user preferences based on behavior, accounting for the influence of the news agenda on user interests, and managing the rapid decay of news items.","Additionally, the challenge embraces normative complexities, investigating the effects of recommender systems on news flow and their alignment with editorial values.","We summarize the challenge setup, dataset characteristics, and evaluation metrics.","Finally, we announce the winners and highlight their contributions.","The dataset is available at: https://recsys.eb.dk."],"url":"http://arxiv.org/abs/2409.20483v1"}
{"created":"2024-09-30 16:38:05","title":"Impartial Selection Under Combinatorial Constraints","abstract":"Impartial selection problems are concerned with the selection of one or more agents from a set based on mutual nominations from within the set. To avoid strategic nominations of the agents, the axiom of impartiality requires that the selection of each agent is independent of the nominations cast by that agent. This paper initiates the study of impartial selection problems where the nominations are weighted and the set of agents that can be selected is restricted by a combinatorial constraint. We call a selection mechanism $\\alpha$-optimal if, for every instance, the ratio between the total sum of weighted nominations of the selected set and that of the best feasible set of agents is at least $\\alpha$. We show that a natural extension of a mechanism studied for the selection of a single agent remains impartial and $\\frac{1}{4}$-optimal for general independence systems, and we generalize upper bounds from the selection of multiple agents by parameterizing them by the girth of the independence system. We then focus on independence systems defined by knapsack and matroid constraints, giving impartial mechanisms that exploit a greedy order of the agents and achieve approximation ratios of $\\frac{1}{3}$ and $\\frac{1}{2}$, respectively, when agents cast a single nomination. For graphic matroids, we further devise an impartial and $\\frac{1}{3}$-optimal mechanism for an arbitrary number of unweighted nominations.","sentences":["Impartial selection problems are concerned with the selection of one or more agents from a set based on mutual nominations from within the set.","To avoid strategic nominations of the agents, the axiom of impartiality requires that the selection of each agent is independent of the nominations cast by that agent.","This paper initiates the study of impartial selection problems where the nominations are weighted and the set of agents that can be selected is restricted by a combinatorial constraint.","We call a selection mechanism $\\alpha$-optimal if, for every instance, the ratio between the total sum of weighted nominations of the selected set and that of the best feasible set of agents is at least $\\alpha$. We show that a natural extension of a mechanism studied for the selection of a single agent remains impartial and $\\frac{1}{4}$-optimal for general independence systems, and we generalize upper bounds from the selection of multiple agents by parameterizing them by the girth of the independence system.","We then focus on independence systems defined by knapsack and matroid constraints, giving impartial mechanisms that exploit a greedy order of the agents and achieve approximation ratios of $\\frac{1}{3}$ and $\\frac{1}{2}$, respectively, when agents cast a single nomination.","For graphic matroids, we further devise an impartial and $\\frac{1}{3}$-optimal mechanism for an arbitrary number of unweighted nominations."],"url":"http://arxiv.org/abs/2409.20477v1"}
{"created":"2024-09-30 16:36:10","title":"Intel(R) SHMEM: GPU-initiated OpenSHMEM using SYCL","abstract":"Modern high-end systems are increasingly becoming heterogeneous, providing users options to use general purpose Graphics Processing Units (GPU) and other accelerators for additional performance. High Performance Computing (HPC) and Artificial Intelligence (AI) applications are often carefully arranged to overlap communications and computation for increased efficiency on such platforms. This has led to efforts to extend popular communication libraries to support GPU awareness and more recently, GPU-initiated operations. In this paper, we present Intel SHMEM, a library that enables users to write programs that are GPU aware, in that API calls support GPU memory, and also support GPU-initiated communication operations by embedding OpenSHMEM style calls within GPU kernels. We also propose thread-collaborative extensions to the OpenSHMEM standard that can enable users to better exploit the strengths of GPUs. Our implementation adapts to choose between direct load/store from GPU and the GPU copy engine based transfer to optimize performance on different configurations.","sentences":["Modern high-end systems are increasingly becoming heterogeneous, providing users options to use general purpose Graphics Processing Units (GPU) and other accelerators for additional performance.","High Performance Computing (HPC) and Artificial Intelligence (AI) applications are often carefully arranged to overlap communications and computation for increased efficiency on such platforms.","This has led to efforts to extend popular communication libraries to support GPU awareness and more recently, GPU-initiated operations.","In this paper, we present Intel SHMEM, a library that enables users to write programs that are GPU aware, in that API calls support GPU memory, and also support GPU-initiated communication operations by embedding OpenSHMEM style calls within GPU kernels.","We also propose thread-collaborative extensions to the OpenSHMEM standard that can enable users to better exploit the strengths of GPUs.","Our implementation adapts to choose between direct load/store from GPU and the GPU copy engine based transfer to optimize performance on different configurations."],"url":"http://arxiv.org/abs/2409.20476v1"}
{"created":"2024-09-30 16:35:16","title":"IRFusionFormer: Enhancing Pavement Crack Segmentation with RGB-T Fusion and Topological-Based Loss","abstract":"Crack segmentation is crucial in civil engineering, particularly for assessing pavement integrity and ensuring the durability of infrastructure. While deep learning has advanced RGB-based segmentation, performance degrades under adverse conditions like low illumination or motion blur. Thermal imaging offers complementary information by capturing emitted radiation, improving crack detection in challenging environments. Combining RGB and thermal images (RGB-T) for crack segmentation shows promise in complex real-world conditions, such as adverse weather, yet research in this area remains limited. Current RGB-T segmentation methods often fail to fully exploit the complementary relationships between modalities at various levels of interaction. To address this, we propose IRFusionFormer, a novel model for crack segmentation that effectively integrates RGB and thermal data. Our Efficient RGB-T Cross Fusion Module captures multi-scale relationships and long-range dependencies between modalities without significant computational overhead. Additionally, we introduce the Interaction-Hybrid-Branch-Supervision framework, which enhances interaction between modalities by distributing fused features across branches with joint supervision. To maintain the topological structure of cracks, we introduce a novel topology-based loss function that preserves connectivity during training. Our method achieves state-of-the-art performance, with a Dice score of 90.01% and an IoU of 81.83%, significantly improving robustness and accuracy in varying environmental conditions. These advancements address key challenges in pavement crack segmentation, offering a more reliable and efficient solution. For access to the codes, data, and models from this study, visit https://github.com/sheauhuu/IRFusionFormer","sentences":["Crack segmentation is crucial in civil engineering, particularly for assessing pavement integrity and ensuring the durability of infrastructure.","While deep learning has advanced RGB-based segmentation, performance degrades under adverse conditions like low illumination or motion blur.","Thermal imaging offers complementary information by capturing emitted radiation, improving crack detection in challenging environments.","Combining RGB and thermal images (RGB-T) for crack segmentation shows promise in complex real-world conditions, such as adverse weather, yet research in this area remains limited.","Current RGB-T segmentation methods often fail to fully exploit the complementary relationships between modalities at various levels of interaction.","To address this, we propose IRFusionFormer, a novel model for crack segmentation that effectively integrates RGB and thermal data.","Our Efficient RGB-T Cross Fusion Module captures multi-scale relationships and long-range dependencies between modalities without significant computational overhead.","Additionally, we introduce the Interaction-Hybrid-Branch-Supervision framework, which enhances interaction between modalities by distributing fused features across branches with joint supervision.","To maintain the topological structure of cracks, we introduce a novel topology-based loss function that preserves connectivity during training.","Our method achieves state-of-the-art performance, with a Dice score of 90.01% and an IoU of 81.83%, significantly improving robustness and accuracy in varying environmental conditions.","These advancements address key challenges in pavement crack segmentation, offering a more reliable and efficient solution.","For access to the codes, data, and models from this study, visit https://github.com/sheauhuu/IRFusionFormer"],"url":"http://arxiv.org/abs/2409.20474v1"}
{"created":"2024-09-30 16:32:09","title":"Impact of Tactile Sensor Quantities and Placements on Learning-based Dexterous Manipulation","abstract":"Tactile information effectively enables faster training and better task performance for learning-based in-hand manipulation. Existing approaches are validated in simulated environments with a large number of tactile sensors. However, attaching such sensors to a real robot hand is not applicable due to high cost and physical limitations. To enable real-world adoption of tactile sensors, this study investigates the impact of tactile sensors, including their varying quantities and placements on robot hands, on the dexterous manipulation task performance and analyzes the importance of each. Through empirically decreasing the sensor quantities, we successfully find an optimized set of tactile sensors (21 sensors) configuration, which keeps over 93% task performance with only 20% sensor quantities compared to the original set (92 sensors) for the block manipulation task, leading to a potential reduction of over 80% in sensor manufacturing and design costs. To transform the empirical results into a generalizable understanding, we build a task performance prediction model with a weighted linear regression algorithm and use it to forecast the task performance with different sensor configurations. To show its generalizability, we verified this model in egg and pen manipulation tasks and achieved an average prediction error of 3.12%.","sentences":["Tactile information effectively enables faster training and better task performance for learning-based in-hand manipulation.","Existing approaches are validated in simulated environments with a large number of tactile sensors.","However, attaching such sensors to a real robot hand is not applicable due to high cost and physical limitations.","To enable real-world adoption of tactile sensors, this study investigates the impact of tactile sensors, including their varying quantities and placements on robot hands, on the dexterous manipulation task performance and analyzes the importance of each.","Through empirically decreasing the sensor quantities, we successfully find an optimized set of tactile sensors (21 sensors) configuration, which keeps over 93% task performance with only 20% sensor quantities compared to the original set (92 sensors) for the block manipulation task, leading to a potential reduction of over 80% in sensor manufacturing and design costs.","To transform the empirical results into a generalizable understanding, we build a task performance prediction model with a weighted linear regression algorithm and use it to forecast the task performance with different sensor configurations.","To show its generalizability, we verified this model in egg and pen manipulation tasks and achieved an average prediction error of 3.12%."],"url":"http://arxiv.org/abs/2409.20473v1"}
{"created":"2024-09-30 16:29:30","title":"Continual Human Pose Estimation for Incremental Integration of Keypoints and Pose Variations","abstract":"This paper reformulates cross-dataset human pose estimation as a continual learning task, aiming to integrate new keypoints and pose variations into existing models without losing accuracy on previously learned datasets. We benchmark this formulation against established regularization-based methods for mitigating catastrophic forgetting, including EWC, LFL, and LwF. Moreover, we propose a novel regularization method called Importance-Weighted Distillation (IWD), which enhances conventional LwF by introducing a layer-wise distillation penalty and dynamic temperature adjustment based on layer importance for previously learned knowledge. This allows for a controlled adaptation to new tasks that respects the stability-plasticity balance critical in continual learning. Through extensive experiments across three datasets, we demonstrate that our approach outperforms existing regularization-based continual learning strategies. IWD shows an average improvement of 3.60\\% over the state-of-the-art LwF method. The results highlight the potential of our method to serve as a robust framework for real-world applications where models must evolve with new data without forgetting past knowledge.","sentences":["This paper reformulates cross-dataset human pose estimation as a continual learning task, aiming to integrate new keypoints and pose variations into existing models without losing accuracy on previously learned datasets.","We benchmark this formulation against established regularization-based methods for mitigating catastrophic forgetting, including EWC, LFL, and LwF.","Moreover, we propose a novel regularization method called Importance-Weighted Distillation (IWD), which enhances conventional LwF by introducing a layer-wise distillation penalty and dynamic temperature adjustment based on layer importance for previously learned knowledge.","This allows for a controlled adaptation to new tasks that respects the stability-plasticity balance critical in continual learning.","Through extensive experiments across three datasets, we demonstrate that our approach outperforms existing regularization-based continual learning strategies.","IWD shows an average improvement of 3.60\\% over the state-of-the-art LwF method.","The results highlight the potential of our method to serve as a robust framework for real-world applications where models must evolve with new data without forgetting past knowledge."],"url":"http://arxiv.org/abs/2409.20469v1"}
{"created":"2024-09-30 16:26:40","title":"A Weakly Supervised Data Labeling Framework for Machine Lexical Normalization in Vietnamese Social Media","abstract":"This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese. Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive. To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques. This approach enhances the quality of training dataset and expands its size while minimizing manual labeling efforts. Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data. Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing Pre-trained Language Models. The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally, it effectively handles undiacritized text under various conditions. This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1-3%.","sentences":["This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese.","Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive.","To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques.","This approach enhances the quality of training dataset and expands its size while minimizing manual labeling efforts.","Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data.","Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing Pre-trained Language Models.","The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%.","Additionally, it effectively handles undiacritized text under various conditions.","This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1-3%."],"url":"http://arxiv.org/abs/2409.20467v1"}
{"created":"2024-09-30 16:26:19","title":"Language Resources in Spanish for Automatic Text Simplification across Domains","abstract":"This work describes the language resources and models developed for automatic simplification of Spanish texts in three domains: Finance, Medicine and History studies. We created several corpora in each domain, annotation and simplification guidelines, a lexicon of technical and simplified medical terms, datasets used in shared tasks for the financial domain, and two simplification tools. The methodology, resources and companion publications are shared publicly on the web-site: https://clara-nlp.uned.es/.","sentences":["This work describes the language resources and models developed for automatic simplification of Spanish texts in three domains: Finance, Medicine and History studies.","We created several corpora in each domain, annotation and simplification guidelines, a lexicon of technical and simplified medical terms, datasets used in shared tasks for the financial domain, and two simplification tools.","The methodology, resources and companion publications are shared publicly on the web-site: https://clara-nlp.uned.es/."],"url":"http://arxiv.org/abs/2409.20466v1"}
{"created":"2024-09-30 16:20:58","title":"Time Efficiency of BATS Coding on Wireless Relay Network With Overhearing","abstract":"Wireless relay network is a solution to extend the reach of a wireless connection by installing a relay node between the source node and the sink node. Due to the broadcast nature of wireless transmission, the sink node has a chance to receive part of the data sent by the source node. In this paper, we apply a network coding scheme called BATS codes on a wireless relay network where the relay node has a stable power supply, so that we can aim for the best decoding time instead of minimizing the number of transmissions for saving energy. We optimize the time efficiency that maximize the average decoding rate per unit time by some heuristics, and bring out a message that it is not optimal to set an average number of recoded packets per batch at the relay node equals the number of packets per batch sent by the source node.","sentences":["Wireless relay network is a solution to extend the reach of a wireless connection by installing a relay node between the source node and the sink node.","Due to the broadcast nature of wireless transmission, the sink node has a chance to receive part of the data sent by the source node.","In this paper, we apply a network coding scheme called BATS codes on a wireless relay network where the relay node has a stable power supply, so that we can aim for the best decoding time instead of minimizing the number of transmissions for saving energy.","We optimize the time efficiency that maximize the average decoding rate per unit time by some heuristics, and bring out a message that it is not optimal to set an average number of recoded packets per batch at the relay node equals the number of packets per batch sent by the source node."],"url":"http://arxiv.org/abs/2409.20463v1"}
{"created":"2024-09-30 16:17:16","title":"The Secretary Problem with Predicted Additive Gap","abstract":"The secretary problem is one of the fundamental problems in online decision making; a tight competitive ratio for this problem of $1/\\mathrm{e} \\approx 0.368$ has been known since the 1960s. Much more recently, the study of algorithms with predictions was introduced: The algorithm is equipped with a (possibly erroneous) additional piece of information upfront which can be used to improve the algorithm's performance. Complementing previous work on secretary problems with prior knowledge, we tackle the following question:   What is the weakest piece of information that allows us to break the $1/\\mathrm{e}$ barrier?   To this end, we introduce the secretary problem with predicted additive gap. As in the classical problem, weights are fixed by an adversary and elements appear in random order. In contrast to previous variants of predictions, our algorithm only has access to a much weaker piece of information: an \\emph{additive gap} $c$. This gap is the difference between the highest and $k$-th highest weight in the sequence. Unlike previous pieces of advice, knowing an exact additive gap does not make the problem trivial. Our contribution is twofold. First, we show that for any index $k$ and any gap $c$, we can obtain a competitive ratio of $0.4$ when knowing the exact gap (even if we do not know $k$), hence beating the prevalent bound for the classical problem by a constant. Second, a slightly modified version of our algorithm allows to prove standard robustness-consistency properties as well as improved guarantees when knowing a range for the error of the prediction.","sentences":["The secretary problem is one of the fundamental problems in online decision making; a tight competitive ratio for this problem of $1/\\mathrm{e} \\approx 0.368$ has been known since the 1960s.","Much more recently, the study of algorithms with predictions was introduced: The algorithm is equipped with a (possibly erroneous) additional piece of information upfront which can be used to improve the algorithm's performance.","Complementing previous work on secretary problems with prior knowledge, we tackle the following question:   What is the weakest piece of information that allows us to break the $1/\\mathrm{e}$ barrier?   ","To this end, we introduce the secretary problem with predicted additive gap.","As in the classical problem, weights are fixed by an adversary and elements appear in random order.","In contrast to previous variants of predictions, our algorithm only has access to a much weaker piece of information: an \\emph{additive gap} $c$. This gap is the difference between the highest and $k$-th highest weight in the sequence.","Unlike previous pieces of advice, knowing an exact additive gap does not make the problem trivial.","Our contribution is twofold.","First, we show that for any index $k$ and any gap $c$, we can obtain a competitive ratio of $0.4$ when knowing the exact gap (even if we do not know $k$), hence beating the prevalent bound for the classical problem by a constant.","Second, a slightly modified version of our algorithm allows to prove standard robustness-consistency properties as well as improved guarantees when knowing a range for the error of the prediction."],"url":"http://arxiv.org/abs/2409.20460v1"}
{"created":"2024-09-30 16:07:34","title":"Linear Projections of Teacher Embeddings for Few-Class Distillation","abstract":"Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model. Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations. Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory. This is because the information about the teacher model's generalization patterns scales directly with the number of classes. Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision. Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment. Taking these observations into account, we introduce a novel method for distilling knowledge from the teacher's model representations, which we term Learning Embedding Linear Projections (LELP). Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses. The student model is then trained to replicate these pseudo-classes. Our experimental evaluation on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate the LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer.","sentences":["Knowledge Distillation (KD) has emerged as a promising approach for transferring knowledge from a larger, more complex teacher model to a smaller student model.","Traditionally, KD involves training the student to mimic the teacher's output probabilities, while more advanced techniques have explored guiding the student to adopt the teacher's internal representations.","Despite its widespread success, the performance of KD in binary classification and few-class problems has been less satisfactory.","This is because the information about the teacher model's generalization patterns scales directly with the number of classes.","Moreover, several sophisticated distillation methods may not be universally applicable or effective for data types beyond Computer Vision.","Consequently, effective distillation techniques remain elusive for a range of key real-world applications, such as sentiment analysis, search query understanding, and advertisement-query relevance assessment.","Taking these observations into account, we introduce a novel method for distilling knowledge from the teacher's model representations, which we term Learning Embedding Linear Projections (LELP).","Inspired by recent findings about the structure of final-layer representations, LELP works by identifying informative linear subspaces in the teacher's embedding space, and splitting them into pseudo-subclasses.","The student model is then trained to replicate these pseudo-classes.","Our experimental evaluation on large-scale NLP benchmarks like Amazon Reviews and Sentiment140 demonstrate the LELP is consistently competitive with, and typically superior to, existing state-of-the-art distillation algorithms for binary and few-class problems, where most KD methods suffer."],"url":"http://arxiv.org/abs/2409.20449v1"}
{"created":"2024-09-30 16:05:29","title":"POMONAG: Pareto-Optimal Many-Objective Neural Architecture Generator","abstract":"Neural Architecture Search (NAS) automates neural network design, reducing dependence on human expertise. While NAS methods are computationally intensive and dataset-specific, auxiliary predictors reduce the models needing training, decreasing search time. This strategy is used to generate architectures satisfying multiple computational constraints. Recently, Transferable NAS has emerged, generalizing the search process from dataset-dependent to task-dependent. In this field, DiffusionNAG is a state-of-the-art method. This diffusion-based approach streamlines computation, generating architectures optimized for accuracy on unseen datasets without further adaptation. However, by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives like model complexity, computational efficiency, and inference latency -- factors essential for deploying models in resource-constrained environments. This paper introduces the Pareto-Optimal Many-Objective Neural Architecture Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion process. POMONAG simultaneously considers accuracy, number of parameters, multiply-accumulate operations (MACs), and inference latency. It integrates Performance Predictor models to estimate these metrics and guide diffusion gradients. POMONAG's optimization is enhanced by expanding its training Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for conditional generation. These enhancements enable POMONAG to generate Pareto-optimal architectures that outperform the previous state-of-the-art in performance and efficiency. Results were validated on two search spaces -- NASBench201 and MobileNetV3 -- and evaluated across 15 image classification datasets.","sentences":["Neural Architecture Search (NAS) automates neural network design, reducing dependence on human expertise.","While NAS methods are computationally intensive and dataset-specific, auxiliary predictors reduce the models needing training, decreasing search time.","This strategy is used to generate architectures satisfying multiple computational constraints.","Recently, Transferable NAS has emerged, generalizing the search process from dataset-dependent to task-dependent.","In this field, DiffusionNAG is a state-of-the-art method.","This diffusion-based approach streamlines computation, generating architectures optimized for accuracy on unseen datasets without further adaptation.","However, by focusing solely on accuracy, DiffusionNAG overlooks other crucial objectives like model complexity, computational efficiency, and inference latency -- factors essential for deploying models in resource-constrained environments.","This paper introduces the Pareto-Optimal Many-Objective Neural Architecture Generator (POMONAG), extending DiffusionNAG via a many-objective diffusion process.","POMONAG simultaneously considers accuracy, number of parameters, multiply-accumulate operations (MACs), and inference latency.","It integrates Performance Predictor models to estimate these metrics and guide diffusion gradients.","POMONAG's optimization is enhanced by expanding its training Meta-Dataset, applying Pareto Front Filtering, and refining embeddings for conditional generation.","These enhancements enable POMONAG to generate Pareto-optimal architectures that outperform the previous state-of-the-art in performance and efficiency.","Results were validated on two search spaces -- NASBench201 and MobileNetV3 -- and evaluated across 15 image classification datasets."],"url":"http://arxiv.org/abs/2409.20447v1"}
{"created":"2024-09-30 16:03:44","title":"Robot Navigation Using Physically Grounded Vision-Language Models in Outdoor Environments","abstract":"We present a novel autonomous robot navigation algorithm for outdoor environments that is capable of handling diverse terrain traversability conditions. Our approach, VLM-GroNav, uses vision-language models (VLMs) and integrates them with physical grounding that is used to assess intrinsic terrain properties such as deformability and slipperiness. We use proprioceptive-based sensing, which provides direct measurements of these physical properties, and enhances the overall semantic understanding of the terrains. Our formulation uses in-context learning to ground the VLM's semantic understanding with proprioceptive data to allow dynamic updates of traversability estimates based on the robot's real-time physical interactions with the environment. We use the updated traversability estimations to inform both the local and global planners for real-time trajectory replanning. We validate our method on a legged robot (Ghost Vision 60) and a wheeled robot (Clearpath Husky), in diverse real-world outdoor environments with different deformable and slippery terrains. In practice, we observe significant improvements over state-of-the-art methods by up to 50% increase in navigation success rate.","sentences":["We present a novel autonomous robot navigation algorithm for outdoor environments that is capable of handling diverse terrain traversability conditions.","Our approach, VLM-GroNav, uses vision-language models (VLMs) and integrates them with physical grounding that is used to assess intrinsic terrain properties such as deformability and slipperiness.","We use proprioceptive-based sensing, which provides direct measurements of these physical properties, and enhances the overall semantic understanding of the terrains.","Our formulation uses in-context learning to ground the VLM's semantic understanding with proprioceptive data to allow dynamic updates of traversability estimates based on the robot's real-time physical interactions with the environment.","We use the updated traversability estimations to inform both the local and global planners for real-time trajectory replanning.","We validate our method on a legged robot (Ghost Vision 60) and a wheeled robot (Clearpath Husky), in diverse real-world outdoor environments with different deformable and slippery terrains.","In practice, we observe significant improvements over state-of-the-art methods by up to 50% increase in navigation success rate."],"url":"http://arxiv.org/abs/2409.20445v1"}
{"created":"2024-09-30 16:00:34","title":"Instance-adaptive Zero-shot Chain-of-Thought Prompting","abstract":"Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective strategy for enhancing the performance of large language models (LLMs) in real-world reasoning tasks. Nonetheless, the efficacy of a singular, task-level prompt uniformly applied across the whole of instances is inherently limited since one prompt cannot be a good partner for all, a more appropriate approach should consider the interaction between the prompt and each instance meticulously. This work introduces an instance-adaptive prompting algorithm as an alternative zero-shot CoT reasoning scheme by adaptively differentiating good and bad prompts. Concretely, we first employ analysis on LLMs through the lens of information flow to detect the mechanism under zero-shot CoT reasoning, in which we discover that information flows from question to prompt and question to rationale jointly influence the reasoning results most. We notice that a better zero-shot CoT reasoning needs the prompt to obtain semantic information from the question then the rationale aggregates sufficient information from the question directly and via the prompt indirectly. On the contrary, lacking any of those would probably lead to a bad one. Stem from that, we further propose an instance-adaptive prompting strategy (IAP) for zero-shot CoT reasoning. Experiments conducted with LLaMA-2, LLaMA-3, and Qwen on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal Judgement) obtain consistent improvement, demonstrating that the instance-adaptive zero-shot CoT prompting performs better than other task-level methods with some curated prompts or sophisticated procedures, showing the significance of our findings in the zero-shot CoT reasoning mechanism.","sentences":["Zero-shot Chain-of-Thought (CoT) prompting emerges as a simple and effective strategy for enhancing the performance of large language models (LLMs) in real-world reasoning tasks.","Nonetheless, the efficacy of a singular, task-level prompt uniformly applied across the whole of instances is inherently limited since one prompt cannot be a good partner for all, a more appropriate approach should consider the interaction between the prompt and each instance meticulously.","This work introduces an instance-adaptive prompting algorithm as an alternative zero-shot CoT reasoning scheme by adaptively differentiating good and bad prompts.","Concretely, we first employ analysis on LLMs through the lens of information flow to detect the mechanism under zero-shot CoT reasoning, in which we discover that information flows from question to prompt and question to rationale jointly influence the reasoning results most.","We notice that a better zero-shot CoT reasoning needs the prompt to obtain semantic information from the question then the rationale aggregates sufficient information from the question directly and via the prompt indirectly.","On the contrary, lacking any of those would probably lead to a bad one.","Stem from that, we further propose an instance-adaptive prompting strategy (IAP) for zero-shot CoT reasoning.","Experiments conducted with LLaMA-2, LLaMA-3, and Qwen on math, logic, and commonsense reasoning tasks (e.g., GSM8K, MMLU, Causal Judgement) obtain consistent improvement, demonstrating that the instance-adaptive zero-shot CoT prompting performs better than other task-level methods with some curated prompts or sophisticated procedures, showing the significance of our findings in the zero-shot CoT reasoning mechanism."],"url":"http://arxiv.org/abs/2409.20441v2"}
{"created":"2024-09-30 16:00:23","title":"Optimism in the Face of Ambiguity Principle for Multi-Armed Bandits","abstract":"Follow-The-Regularized-Leader (FTRL) algorithms often enjoy optimal regret for adversarial as well as stochastic bandit problems and allow for a streamlined analysis. Nonetheless, FTRL algorithms require the solution of an optimization problem in every iteration and are thus computationally challenging. In contrast, Follow-The-Perturbed-Leader (FTPL) algorithms achieve computational efficiency by perturbing the estimates of the rewards of the arms, but their regret analysis is cumbersome. We propose a new FTPL algorithm that generates optimal policies for both adversarial and stochastic multi-armed bandits. Like FTRL, our algorithm admits a unified regret analysis, and similar to FTPL, it offers low computational costs. Unlike existing FTPL algorithms that rely on independent additive disturbances governed by a \\textit{known} distribution, we allow for disturbances governed by an \\textit{ambiguous} distribution that is only known to belong to a given set and propose a principle of optimism in the face of ambiguity. Consequently, our framework generalizes existing FTPL algorithms. It also encapsulates a broad range of FTRL methods as special cases, including several optimal ones, which appears to be impossible with current FTPL methods. Finally, we use techniques from discrete choice theory to devise an efficient bisection algorithm for computing the optimistic arm sampling probabilities. This algorithm is up to $10^4$ times faster than standard FTRL algorithms that solve an optimization problem in every iteration. Our results not only settle existing conjectures but also provide new insights into the impact of perturbations by mapping FTRL to FTPL.","sentences":["Follow-The-Regularized-Leader (FTRL) algorithms often enjoy optimal regret for adversarial as well as stochastic bandit problems and allow for a streamlined analysis.","Nonetheless, FTRL algorithms require the solution of an optimization problem in every iteration and are thus computationally challenging.","In contrast, Follow-The-Perturbed-Leader (FTPL) algorithms achieve computational efficiency by perturbing the estimates of the rewards of the arms, but their regret analysis is cumbersome.","We propose a new FTPL algorithm that generates optimal policies for both adversarial and stochastic multi-armed bandits.","Like FTRL, our algorithm admits a unified regret analysis, and similar to FTPL, it offers low computational costs.","Unlike existing FTPL algorithms that rely on independent additive disturbances governed by a \\textit{known} distribution, we allow for disturbances governed by an \\textit{ambiguous} distribution that is only known to belong to a given set and propose a principle of optimism in the face of ambiguity.","Consequently, our framework generalizes existing FTPL algorithms.","It also encapsulates a broad range of FTRL methods as special cases, including several optimal ones, which appears to be impossible with current FTPL methods.","Finally, we use techniques from discrete choice theory to devise an efficient bisection algorithm for computing the optimistic arm sampling probabilities.","This algorithm is up to $10^4$ times faster than standard FTRL algorithms that solve an optimization problem in every iteration.","Our results not only settle existing conjectures but also provide new insights into the impact of perturbations by mapping FTRL to FTPL."],"url":"http://arxiv.org/abs/2409.20440v1"}
{"created":"2024-09-30 15:53:46","title":"ALLO: A Photorealistic Dataset and Data Generation Pipeline for Anomaly Detection During Robotic Proximity Operations in Lunar Orbit","abstract":"NASA's forthcoming Lunar Gateway space station, which will be uncrewed most of the time, will need to operate with an unprecedented level of autonomy. Enhancing autonomy on the Gateway presents several unique challenges, one of which is to equip the Canadarm3, the Gateway's external robotic system, with the capability to perform worksite monitoring. Monitoring will involve using the arm's inspection cameras to detect any anomalies within the operating environment, a task complicated by the widely-varying lighting conditions in space. In this paper, we introduce the visual anomaly detection and localization task for space applications and establish a benchmark with our novel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit). We develop a complete data generation pipeline to create ALLO, which we use to evaluate the performance of state-of-the-art visual anomaly detection algorithms. Given the low tolerance for risk during space operations and the lack of relevant data, we emphasize the need for novel, robust, and accurate anomaly detection methods to handle the challenging visual conditions found in lunar orbit and beyond.","sentences":["NASA's forthcoming Lunar Gateway space station, which will be uncrewed most of the time, will need to operate with an unprecedented level of autonomy.","Enhancing autonomy on the Gateway presents several unique challenges, one of which is to equip the Canadarm3, the Gateway's external robotic system, with the capability to perform worksite monitoring.","Monitoring will involve using the arm's inspection cameras to detect any anomalies within the operating environment, a task complicated by the widely-varying lighting conditions in space.","In this paper, we introduce the visual anomaly detection and localization task for space applications and establish a benchmark with our novel synthetic dataset called ALLO (for Anomaly Localization in Lunar Orbit).","We develop a complete data generation pipeline to create ALLO, which we use to evaluate the performance of state-of-the-art visual anomaly detection algorithms.","Given the low tolerance for risk during space operations and the lack of relevant data, we emphasize the need for novel, robust, and accurate anomaly detection methods to handle the challenging visual conditions found in lunar orbit and beyond."],"url":"http://arxiv.org/abs/2409.20435v1"}
{"created":"2024-09-30 15:53:38","title":"QAEncoder: Towards Aligned Representation Learning in Question Answering System","abstract":"Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses. However, the inherent gap between user queries and relevant documents hinders precise matching. Motivated by our conical distribution hypothesis, which posits that potential queries and documents form a cone-like structure in the embedding space, we introduce QAEncoder, a training-free approach to bridge this gap. Specifically, QAEncoder estimates the expectation of potential queries in the embedding space as a robust surrogate for the document embedding, and attaches document fingerprints to effectively distinguish these embeddings. Extensive experiments on fourteen embedding models across six languages and eight datasets validate QAEncoder's alignment capability, which offers a plug-and-play solution that seamlessly integrates with existing RAG architectures and training-based methods.","sentences":["Modern QA systems entail retrieval-augmented generation (RAG) for accurate and trustworthy responses.","However, the inherent gap between user queries and relevant documents hinders precise matching.","Motivated by our conical distribution hypothesis, which posits that potential queries and documents form a cone-like structure in the embedding space, we introduce QAEncoder, a training-free approach to bridge this gap.","Specifically, QAEncoder estimates the expectation of potential queries in the embedding space as a robust surrogate for the document embedding, and attaches document fingerprints to effectively distinguish these embeddings.","Extensive experiments on fourteen embedding models across six languages and eight datasets validate QAEncoder's alignment capability, which offers a plug-and-play solution that seamlessly integrates with existing RAG architectures and training-based methods."],"url":"http://arxiv.org/abs/2409.20434v1"}
{"created":"2024-09-30 15:52:05","title":"HELPD: Mitigating Hallucination of LVLMs by Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding","abstract":"Large Vision-Language Models (LVLMs) have shown remarkable performance on many visual-language tasks. However, these models still suffer from multimodal hallucination, which means the generation of objects or content that violates the images. Many existing work detects hallucination by directly judging whether an object exists in an image, overlooking the association between the object and semantics. To address this issue, we propose Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding (HELPD). This framework incorporates hallucination feedback at both object and sentence semantic levels. Remarkably, even with a marginal degree of training, this approach can alleviate over 15% of hallucination. Simultaneously, HELPD penalizes the output logits according to the image attention window to avoid being overly affected by generated text. HELPD can be seamlessly integrated with any LVLMs. Our experiments demonstrate that the proposed framework yields favorable results across multiple hallucination benchmarks. It effectively mitigates hallucination for different LVLMs and concurrently improves their text generation quality.","sentences":["Large Vision-Language Models (LVLMs) have shown remarkable performance on many visual-language tasks.","However, these models still suffer from multimodal hallucination, which means the generation of objects or content that violates the images.","Many existing work detects hallucination by directly judging whether an object exists in an image, overlooking the association between the object and semantics.","To address this issue, we propose Hierarchical Feedback Learning with Vision-enhanced Penalty Decoding (HELPD).","This framework incorporates hallucination feedback at both object and sentence semantic levels.","Remarkably, even with a marginal degree of training, this approach can alleviate over 15% of hallucination.","Simultaneously, HELPD penalizes the output logits according to the image attention window to avoid being overly affected by generated text.","HELPD can be seamlessly integrated with any LVLMs.","Our experiments demonstrate that the proposed framework yields favorable results across multiple hallucination benchmarks.","It effectively mitigates hallucination for different LVLMs and concurrently improves their text generation quality."],"url":"http://arxiv.org/abs/2409.20429v1"}
{"created":"2024-09-30 15:51:06","title":"Decoding the Echoes of Vision from fMRI: Memory Disentangling for Past Semantic Information","abstract":"The human visual system is capable of processing continuous streams of visual information, but how the brain encodes and retrieves recent visual memories during continuous visual processing remains unexplored. This study investigates the capacity of working memory to retain past information under continuous visual stimuli. And then we propose a new task Memory Disentangling, which aims to extract and decode past information from fMRI signals. To address the issue of interference from past memory information, we design a disentangled contrastive learning method inspired by the phenomenon of proactive interference. This method separates the information between adjacent fMRI signals into current and past components and decodes them into image descriptions. Experimental results demonstrate that this method effectively disentangles the information within fMRI signals. This research could advance brain-computer interfaces and mitigate the problem of low temporal resolution in fMRI.","sentences":["The human visual system is capable of processing continuous streams of visual information, but how the brain encodes and retrieves recent visual memories during continuous visual processing remains unexplored.","This study investigates the capacity of working memory to retain past information under continuous visual stimuli.","And then we propose a new task Memory Disentangling, which aims to extract and decode past information from fMRI signals.","To address the issue of interference from past memory information, we design a disentangled contrastive learning method inspired by the phenomenon of proactive interference.","This method separates the information between adjacent fMRI signals into current and past components and decodes them into image descriptions.","Experimental results demonstrate that this method effectively disentangles the information within fMRI signals.","This research could advance brain-computer interfaces and mitigate the problem of low temporal resolution in fMRI."],"url":"http://arxiv.org/abs/2409.20428v1"}
{"created":"2024-09-30 15:50:36","title":"Navigating Threats: A Survey of Physical Adversarial Attacks on LiDAR Perception Systems in Autonomous Vehicles","abstract":"Autonomous vehicles (AVs) rely heavily on LiDAR (Light Detection and Ranging) systems for accurate perception and navigation, providing high-resolution 3D environmental data that is crucial for object detection and classification. However, LiDAR systems are vulnerable to adversarial attacks, which pose significant challenges to the safety and robustness of AVs. This survey presents a thorough review of the current research landscape on physical adversarial attacks targeting LiDAR-based perception systems, covering both single-modality and multi-modality contexts. We categorize and analyze various attack types, including spoofing and physical adversarial object attacks, detailing their methodologies, impacts, and potential real-world implications. Through detailed case studies and analyses, we identify critical challenges and highlight gaps in existing attacks for LiDAR-based systems. Additionally, we propose future research directions to enhance the security and resilience of these systems, ultimately contributing to the safer deployment of autonomous vehicles.","sentences":["Autonomous vehicles (AVs) rely heavily on LiDAR (Light Detection and Ranging) systems for accurate perception and navigation, providing high-resolution 3D environmental data that is crucial for object detection and classification.","However, LiDAR systems are vulnerable to adversarial attacks, which pose significant challenges to the safety and robustness of AVs.","This survey presents a thorough review of the current research landscape on physical adversarial attacks targeting LiDAR-based perception systems, covering both single-modality and multi-modality contexts.","We categorize and analyze various attack types, including spoofing and physical adversarial object attacks, detailing their methodologies, impacts, and potential real-world implications.","Through detailed case studies and analyses, we identify critical challenges and highlight gaps in existing attacks for LiDAR-based systems.","Additionally, we propose future research directions to enhance the security and resilience of these systems, ultimately contributing to the safer deployment of autonomous vehicles."],"url":"http://arxiv.org/abs/2409.20426v1"}
{"created":"2024-09-30 15:49:54","title":"World to Code: Multi-modal Data Generation via Self-Instructed Compositional Captioning and Filtering","abstract":"Recent advances in Vision-Language Models (VLMs) and the scarcity of high-quality multi-modal alignment data have inspired numerous researches on synthetic VLM data generation. The conventional norm in VLM data construction uses a mixture of specialists in caption and OCR, or stronger VLM APIs and expensive human annotation. In this paper, we present World to Code (W2C), a meticulously curated multi-modal data construction pipeline that organizes the final generation output into a Python code format. The pipeline leverages the VLM itself to extract cross-modal information via different prompts and filter the generated outputs again via a consistency filtering strategy. Experiments have demonstrated the high quality of W2C by improving various existing visual question answering and visual grounding benchmarks across different VLMs. Further analysis also demonstrates that the new code parsing ability of VLMs presents better cross-modal equivalence than the commonly used detail caption ability. Our code is available at https://github.com/foundation-multimodal-models/World2Code.","sentences":["Recent advances in Vision-Language Models (VLMs) and the scarcity of high-quality multi-modal alignment data have inspired numerous researches on synthetic VLM data generation.","The conventional norm in VLM data construction uses a mixture of specialists in caption and OCR, or stronger VLM APIs and expensive human annotation.","In this paper, we present World to Code (W2C), a meticulously curated multi-modal data construction pipeline that organizes the final generation output into a Python code format.","The pipeline leverages the VLM itself to extract cross-modal information via different prompts and filter the generated outputs again via a consistency filtering strategy.","Experiments have demonstrated the high quality of W2C by improving various existing visual question answering and visual grounding benchmarks across different VLMs.","Further analysis also demonstrates that the new code parsing ability of VLMs presents better cross-modal equivalence than the commonly used detail caption ability.","Our code is available at https://github.com/foundation-multimodal-models/World2Code."],"url":"http://arxiv.org/abs/2409.20424v1"}
{"created":"2024-09-30 15:43:06","title":"AI-Based Fully Automatic Analysis of Retinal Vascular Morphology in Pediatric High Myopia","abstract":"Purpose: To investigate the changes in retinal vascular structures associated various stages of myopia by designing automated software based on an artif intelligencemodel. Methods: The study involved 1324 pediatric participants from the National Childr Medical Center in China, and 2366 high-quality retinal images and correspon refractive parameters were obtained and analyzed. Spherical equivalent refrac(SER) degree was calculated. We proposed a data analysis model based c combination of the Convolutional Neural Networks (CNN) model and the atter module to classify images, segment vascular structures, and measure vasc parameters, such as main angle (MA), branching angle (BA), bifurcation edge al(BEA) and bifurcation edge coefficient (BEC). One-way ANOVA compared param measurements betweenthenormalfundus,lowmyopia,moderate myopia,and high myopia group. Results: There were 279 (12.38%) images in normal group and 384 (16.23%) images in the high myopia group. Compared normal fundus, the MA of fundus vessels in different myopic refractive groups significantly reduced (P = 0.006, P = 0.004, P = 0.019, respectively), and performance of the venous system was particularly obvious (P<0.001). At the sa time, the BEC decreased disproportionately (P<0.001). Further analysis of fundus vascular parameters at different degrees of myopia showed that there were also significant differences in BA and branching coefficient (BC). The arterial BA value of the fundus vessel in the high myopia group was lower than that of other groups (P : 0.032, 95% confidence interval [Ci], 0.22-4.86), while the venous BA values increased(P = 0.026). The BEC values of high myopia were higher than those of low and moderate myopia groups. When the loss function of our data classification model converged to 0.09,the model accuracy reached 94.19%","sentences":["Purpose: To investigate the changes in retinal vascular structures associated various stages of myopia by designing automated software based on an artif intelligencemodel.","Methods: The study involved 1324 pediatric participants from the National Childr Medical Center in China, and 2366 high-quality retinal images and correspon refractive parameters were obtained and analyzed.","Spherical equivalent refrac(SER) degree was calculated.","We proposed a data analysis model based c combination of the Convolutional Neural Networks (CNN) model and the atter module to classify images, segment vascular structures, and measure vasc parameters, such as main angle (MA), branching angle (BA), bifurcation edge al(BEA) and bifurcation edge coefficient (BEC).","One-way ANOVA compared param measurements betweenthenormalfundus,lowmyopia,moderate myopia,and high myopia group.","Results:","There were 279 (12.38%) images in normal group and 384 (16.23%) images in the high myopia group.","Compared normal fundus, the MA of fundus vessels in different myopic refractive groups significantly reduced (P = 0.006, P = 0.004, P = 0.019, respectively), and performance of the venous system was particularly obvious (P<0.001).","At the sa time, the BEC decreased disproportionately (P<0.001).","Further analysis of fundus vascular parameters at different degrees of myopia showed that there were also significant differences in BA and branching coefficient (BC).","The arterial BA value of the fundus vessel in the high myopia group was lower than that of other groups (P : 0.032, 95% confidence interval","[Ci], 0.22-4.86), while the venous BA values increased(P = 0.026).","The BEC values of high myopia were higher than those of low and moderate myopia groups.","When the loss function of our data classification model converged to 0.09,the model accuracy reached 94.19%"],"url":"http://arxiv.org/abs/2409.20419v1"}
{"created":"2024-09-30 15:40:54","title":"Conformal Prediction for Dose-Response Models with Continuous Treatments","abstract":"Understanding the dose-response relation between a continuous treatment and the outcome for an individual can greatly drive decision-making, particularly in areas like personalized drug dosing and personalized healthcare interventions. Point estimates are often insufficient in these high-risk environments, highlighting the need for uncertainty quantification to support informed decisions. Conformal prediction, a distribution-free and model-agnostic method for uncertainty quantification, has seen limited application in continuous treatments or dose-response models. To address this gap, we propose a novel methodology that frames the causal dose-response problem as a covariate shift, leveraging weighted conformal prediction. By incorporating propensity estimation, conformal predictive systems, and likelihood ratios, we present a practical solution for generating prediction intervals for dose-response models. Additionally, our method approximates local coverage for every treatment value by applying kernel functions as weights in weighted conformal prediction. Finally, we use a new synthetic benchmark dataset to demonstrate the significance of covariate shift assumptions in achieving robust prediction intervals for dose-response models.","sentences":["Understanding the dose-response relation between a continuous treatment and the outcome for an individual can greatly drive decision-making, particularly in areas like personalized drug dosing and personalized healthcare interventions.","Point estimates are often insufficient in these high-risk environments, highlighting the need for uncertainty quantification to support informed decisions.","Conformal prediction, a distribution-free and model-agnostic method for uncertainty quantification, has seen limited application in continuous treatments or dose-response models.","To address this gap, we propose a novel methodology that frames the causal dose-response problem as a covariate shift, leveraging weighted conformal prediction.","By incorporating propensity estimation, conformal predictive systems, and likelihood ratios, we present a practical solution for generating prediction intervals for dose-response models.","Additionally, our method approximates local coverage for every treatment value by applying kernel functions as weights in weighted conformal prediction.","Finally, we use a new synthetic benchmark dataset to demonstrate the significance of covariate shift assumptions in achieving robust prediction intervals for dose-response models."],"url":"http://arxiv.org/abs/2409.20412v1"}
{"created":"2024-09-30 15:38:33","title":"Does Positive Reinforcement Work?: A Quasi-Experimental Study of the Effects of Positive Feedback on Reddit","abstract":"Social media platform design often incorporates explicit signals of positive feedback. Some moderators provide positive feedback with the goal of positive reinforcement, but are often unsure of their ability to actually influence user behavior. Despite its widespread use and theory touting positive feedback as crucial for user motivation, its effect on recipients is relatively unknown. This paper examines how positive feedback impacts Reddit users and evaluates its differential effects to understand who benefits most from receiving positive feedback. Through a causal inference study of 11M posts across 4 months, we find that users who received positive feedback made more frequent (2% per day) and higher quality (57% higher score; 2% fewer removals per day) posts compared to a set of matched control users. Our findings highlight the need for platforms and communities to expand their perspective on moderation and complement punitive approaches with positive reinforcement strategies.","sentences":["Social media platform design often incorporates explicit signals of positive feedback.","Some moderators provide positive feedback with the goal of positive reinforcement, but are often unsure of their ability to actually influence user behavior.","Despite its widespread use and theory touting positive feedback as crucial for user motivation, its effect on recipients is relatively unknown.","This paper examines how positive feedback impacts Reddit users and evaluates its differential effects to understand who benefits most from receiving positive feedback.","Through a causal inference study of 11M posts across 4 months, we find that users who received positive feedback made more frequent (2% per day) and higher quality (57% higher score; 2% fewer removals per day) posts compared to a set of matched control users.","Our findings highlight the need for platforms and communities to expand their perspective on moderation and complement punitive approaches with positive reinforcement strategies."],"url":"http://arxiv.org/abs/2409.20410v1"}
{"created":"2024-09-30 15:36:14","title":"Physics-Regularized Multi-Modal Image Assimilation for Brain Tumor Localization","abstract":"Physical models in the form of partial differential equations represent an important prior for many under-constrained problems. One example is tumor treatment planning, which heavily depends on accurate estimates of the spatial distribution of tumor cells in a patient's anatomy. Medical imaging scans can identify the bulk of the tumor, but they cannot reveal its full spatial distribution. Tumor cells at low concentrations remain undetectable, for example, in the most frequent type of primary brain tumors, glioblastoma. Deep-learning-based approaches fail to estimate the complete tumor cell distribution due to a lack of reliable training data. Most existing works therefore rely on physics-based simulations to match observed tumors, providing anatomically and physiologically plausible estimations. However, these approaches struggle with complex and unknown initial conditions and are limited by overly rigid physical models. In this work, we present a novel method that balances data-driven and physics-based cost functions. In particular, we propose a unique discretization scheme that quantifies the adherence of our learned spatiotemporal tumor and brain tissue distributions to their corresponding growth and elasticity equations. This quantification, serving as a regularization term rather than a hard constraint, enables greater flexibility and proficiency in assimilating patient data than existing models. We demonstrate improved coverage of tumor recurrence areas compared to existing techniques on real-world data from a cohort of patients. The method holds the potential to enhance clinical adoption of model-driven treatment planning for glioblastoma.","sentences":["Physical models in the form of partial differential equations represent an important prior for many under-constrained problems.","One example is tumor treatment planning, which heavily depends on accurate estimates of the spatial distribution of tumor cells in a patient's anatomy.","Medical imaging scans can identify the bulk of the tumor, but they cannot reveal its full spatial distribution.","Tumor cells at low concentrations remain undetectable, for example, in the most frequent type of primary brain tumors, glioblastoma.","Deep-learning-based approaches fail to estimate the complete tumor cell distribution due to a lack of reliable training data.","Most existing works therefore rely on physics-based simulations to match observed tumors, providing anatomically and physiologically plausible estimations.","However, these approaches struggle with complex and unknown initial conditions and are limited by overly rigid physical models.","In this work, we present a novel method that balances data-driven and physics-based cost functions.","In particular, we propose a unique discretization scheme that quantifies the adherence of our learned spatiotemporal tumor and brain tissue distributions to their corresponding growth and elasticity equations.","This quantification, serving as a regularization term rather than a hard constraint, enables greater flexibility and proficiency in assimilating patient data than existing models.","We demonstrate improved coverage of tumor recurrence areas compared to existing techniques on real-world data from a cohort of patients.","The method holds the potential to enhance clinical adoption of model-driven treatment planning for glioblastoma."],"url":"http://arxiv.org/abs/2409.20409v1"}
{"created":"2024-09-30 15:36:04","title":"Beacon based uplink transmission for lorawan direct to satellite internet of things","abstract":"Direct-to-satellite IoT DtS IoT communication structure is a promising solution to provide connectivity and extend the coverage of traditional low-power and long-range technologies, especially for isolated and remote areas where deploying traditional infrastructure is impracticable. Despite their bounded visibility, the Low Earth Orbit LEO satellites complement the terrestrial networks, offering broader gateway coverage and terrestrial network traffic offloading. However, the dynamics of LEO and the nature of such integration come with several challenges affecting the efficacy of the network. Therefore, this paper proposes Beacon based Uplink LoRaWAN BU LoRaWAN to enhance satellite-terrestrial communication efficiency. The proposed scheme exploits the LoRaWAN class B synchronization mechanism to provide efficient uplink transmission from LoRaWAN devices placed on the ground to satellite gateways. BU LoRaWAN proposes an uplink transmission slot approach to synchronize ground devices uplink traffic with LEO based orbiting gateways. It also uses a queue data structure to buffer end devices ready to send packets until the appropriate moment. BU LoRaWAN avoids possible transmission collision by optimizing a random transmission slot for an end device within the beacon window. The proposed system is implemented and evaluated using OMNeT network simulator and FLoRaSat framework. The result demonstrates the feasibility of the proposed system. BU-LoRaWAN achieves better performance compared to the standard LoRaWAN, which manages to deliver almost double the traffic delivered by the standard one.","sentences":["Direct-to-satellite IoT DtS IoT communication structure is a promising solution to provide connectivity and extend the coverage of traditional low-power and long-range technologies, especially for isolated and remote areas where deploying traditional infrastructure is impracticable.","Despite their bounded visibility, the Low Earth Orbit LEO satellites complement the terrestrial networks, offering broader gateway coverage and terrestrial network traffic offloading.","However, the dynamics of LEO and the nature of such integration come with several challenges affecting the efficacy of the network.","Therefore, this paper proposes Beacon based Uplink LoRaWAN BU LoRaWAN to enhance satellite-terrestrial communication efficiency.","The proposed scheme exploits the LoRaWAN class B synchronization mechanism to provide efficient uplink transmission from LoRaWAN devices placed on the ground to satellite gateways.","BU LoRaWAN proposes an uplink transmission slot approach to synchronize ground devices uplink traffic with LEO based orbiting gateways.","It also uses a queue data structure to buffer end devices ready to send packets until the appropriate moment.","BU LoRaWAN avoids possible transmission collision by optimizing a random transmission slot for an end device within the beacon window.","The proposed system is implemented and evaluated using OMNeT network simulator and FLoRaSat framework.","The result demonstrates the feasibility of the proposed system.","BU-LoRaWAN achieves better performance compared to the standard LoRaWAN, which manages to deliver almost double the traffic delivered by the standard one."],"url":"http://arxiv.org/abs/2409.20408v1"}
{"created":"2024-09-30 15:35:27","title":"Open-Source Periorbital Segmentation Dataset for Ophthalmic Applications","abstract":"Periorbital segmentation and distance prediction using deep learning allows for the objective quantification of disease state, treatment monitoring, and remote medicine. However, there are currently no reports of segmentation datasets for the purposes of training deep learning models with sub mm accuracy on the regions around the eyes. All images (n=2842) had the iris, sclera, lid, caruncle, and brow segmented by five trained annotators. Here, we validate this dataset through intra and intergrader reliability tests and show the utility of the data in training periorbital segmentation networks. All the annotations are publicly available for free download. Having access to segmentation datasets designed specifically for oculoplastic surgery will permit more rapid development of clinically useful segmentation networks which can be leveraged for periorbital distance prediction and disease classification. In addition to the annotations, we also provide an open-source toolkit for periorbital distance prediction from segmentation masks. The weights of all models have also been open-sourced and are publicly available for use by the community.","sentences":["Periorbital segmentation and distance prediction using deep learning allows for the objective quantification of disease state, treatment monitoring, and remote medicine.","However, there are currently no reports of segmentation datasets for the purposes of training deep learning models with sub mm accuracy on the regions around the eyes.","All images (n=2842) had the iris, sclera, lid, caruncle, and brow segmented by five trained annotators.","Here, we validate this dataset through intra and intergrader reliability tests and show the utility of the data in training periorbital segmentation networks.","All the annotations are publicly available for free download.","Having access to segmentation datasets designed specifically for oculoplastic surgery will permit more rapid development of clinically useful segmentation networks which can be leveraged for periorbital distance prediction and disease classification.","In addition to the annotations, we also provide an open-source toolkit for periorbital distance prediction from segmentation masks.","The weights of all models have also been open-sourced and are publicly available for use by the community."],"url":"http://arxiv.org/abs/2409.20407v1"}
{"created":"2024-09-30 15:33:47","title":"Accelerating PoT Quantization on Edge Devices","abstract":"Non-uniform quantization, such as power-of-two (PoT) quantization, matches data distributions better than uniform quantization, which reduces the quantization error of Deep Neural Networks (DNNs). PoT quantization also allows bit-shift operations to replace multiplications, but there are limited studies on the efficiency of shift-based accelerators for PoT quantization. Furthermore, existing pipelines for accelerating PoT-quantized DNNs on edge devices are not open-source. In this paper, we first design shift-based processing elements (shift-PE) for different PoT quantization methods and evaluate their efficiency using synthetic benchmarks. Then we design a shift-based accelerator using our most efficient shift-PE and propose PoTAcc, an open-source pipeline for end-to-end acceleration of PoT-quantized DNNs on resource-constrained edge devices. Using PoTAcc, we evaluate the performance of our shift-based accelerator across three DNNs. On average, it achieves a 1.23x speedup and 1.24x energy reduction compared to a multiplier-based accelerator, and a 2.46x speedup and 1.83x energy reduction compared to CPU-only execution. Our code is available at https://github.com/gicLAB/PoTAcc","sentences":["Non-uniform quantization, such as power-of-two (PoT) quantization, matches data distributions better than uniform quantization, which reduces the quantization error of Deep Neural Networks (DNNs).","PoT quantization also allows bit-shift operations to replace multiplications, but there are limited studies on the efficiency of shift-based accelerators for PoT quantization.","Furthermore, existing pipelines for accelerating PoT-quantized DNNs on edge devices are not open-source.","In this paper, we first design shift-based processing elements (shift-PE) for different PoT quantization methods and evaluate their efficiency using synthetic benchmarks.","Then we design a shift-based accelerator using our most efficient shift-PE and propose PoTAcc, an open-source pipeline for end-to-end acceleration of PoT-quantized DNNs on resource-constrained edge devices.","Using PoTAcc, we evaluate the performance of our shift-based accelerator across three DNNs.","On average, it achieves a 1.23x speedup and 1.24x energy reduction compared to a multiplier-based accelerator, and a 2.46x speedup and 1.83x energy reduction compared to CPU-only execution.","Our code is available at https://github.com/gicLAB/PoTAcc"],"url":"http://arxiv.org/abs/2409.20403v1"}
{"created":"2024-09-30 15:32:17","title":"Multi-Robot Target Monitoring and Encirclement via Triggered Distributed Feedback Optimization","abstract":"We design a distributed feedback optimization strategy, embedded into a modular ROS 2 control architecture, which allows a team of heterogeneous robots to cooperatively monitor and encircle a target while patrolling points of interest. Relying on the aggregative feedback optimization framework, we handle multi-robot dynamics while minimizing a global performance index depending on both microscopic (e.g., the location of single robots) and macroscopic variables (e.g., the spatial distribution of the team). The proposed distributed policy allows the robots to cooperatively address the global problem by employing only local measurements and neighboring data exchanges. These exchanges are performed through an asynchronous communication protocol ruled by locally-verifiable triggering conditions. We formally prove that our strategy steers the robots to a set of configurations representing stationary points of the considered optimization problem. The effectiveness and scalability of the overall strategy are tested via Monte Carlo campaigns of realistic Webots ROS 2 virtual experiments. Finally, the applicability of our solution is shown with real experiments on ground and aerial robots.","sentences":["We design a distributed feedback optimization strategy, embedded into a modular ROS 2 control architecture, which allows a team of heterogeneous robots to cooperatively monitor and encircle a target while patrolling points of interest.","Relying on the aggregative feedback optimization framework, we handle multi-robot dynamics while minimizing a global performance index depending on both microscopic (e.g., the location of single robots) and macroscopic variables (e.g., the spatial distribution of the team).","The proposed distributed policy allows the robots to cooperatively address the global problem by employing only local measurements and neighboring data exchanges.","These exchanges are performed through an asynchronous communication protocol ruled by locally-verifiable triggering conditions.","We formally prove that our strategy steers the robots to a set of configurations representing stationary points of the considered optimization problem.","The effectiveness and scalability of the overall strategy are tested via Monte Carlo campaigns of realistic Webots ROS 2 virtual experiments.","Finally, the applicability of our solution is shown with real experiments on ground and aerial robots."],"url":"http://arxiv.org/abs/2409.20399v1"}
{"created":"2024-09-30 15:31:02","title":"AUCSeg: AUC-oriented Pixel-level Long-tail Semantic Segmentation","abstract":"The Area Under the ROC Curve (AUC) is a well-known metric for evaluating instance-level long-tail learning problems. In the past two decades, many AUC optimization methods have been proposed to improve model performance under long-tail distributions. In this paper, we explore AUC optimization methods in the context of pixel-level long-tail semantic segmentation, a much more complicated scenario. This task introduces two major challenges for AUC optimization techniques. On one hand, AUC optimization in a pixel-level task involves complex coupling across loss terms, with structured inner-image and pairwise inter-image dependencies, complicating theoretical analysis. On the other hand, we find that mini-batch estimation of AUC loss in this case requires a larger batch size, resulting in an unaffordable space complexity. To address these issues, we develop a pixel-level AUC loss function and conduct a dependency-graph-based theoretical analysis of the algorithm's generalization ability. Additionally, we design a Tail-Classes Memory Bank (T-Memory Bank) to manage the significant memory demand. Finally, comprehensive experiments across various benchmarks confirm the effectiveness of our proposed AUCSeg method. The code is available at https://github.com/boyuh/AUCSeg.","sentences":["The Area Under the ROC Curve (AUC) is a well-known metric for evaluating instance-level long-tail learning problems.","In the past two decades, many AUC optimization methods have been proposed to improve model performance under long-tail distributions.","In this paper, we explore AUC optimization methods in the context of pixel-level long-tail semantic segmentation, a much more complicated scenario.","This task introduces two major challenges for AUC optimization techniques.","On one hand, AUC optimization in a pixel-level task involves complex coupling across loss terms, with structured inner-image and pairwise inter-image dependencies, complicating theoretical analysis.","On the other hand, we find that mini-batch estimation of AUC loss in this case requires a larger batch size, resulting in an unaffordable space complexity.","To address these issues, we develop a pixel-level AUC loss function and conduct a dependency-graph-based theoretical analysis of the algorithm's generalization ability.","Additionally, we design a Tail-Classes Memory Bank (T-Memory Bank) to manage the significant memory demand.","Finally, comprehensive experiments across various benchmarks confirm the effectiveness of our proposed AUCSeg method.","The code is available at https://github.com/boyuh/AUCSeg."],"url":"http://arxiv.org/abs/2409.20398v1"}
{"created":"2024-09-30 15:29:50","title":"Facility Location Games with Competitors","abstract":"In this paper, we consider facility location games with competitors where the agents are divided into groups and the agents in the same group have competitive relationships, i.e., the cost of an agent will increase if the facility is closer to their competitors. We consider three types of misreporting: misreporting the location only, misreporting the group membership only, and misreporting both. To minimize the social cost, we propose a strategyproof mechanism that is optimal when misreporting the location only. For the other two types of manipulation, we reuse the median mechanism and achieve tight bounds of 2. To minimize the maximum cost, we design new strategyproof mechanisms for the first two types of misreporting. We reuse the leftmost mechanism for misreporting both. All bounds are almost tight.","sentences":["In this paper, we consider facility location games with competitors where the agents are divided into groups and the agents in the same group have competitive relationships, i.e., the cost of an agent will increase if the facility is closer to their competitors.","We consider three types of misreporting: misreporting the location only, misreporting the group membership only, and misreporting both.","To minimize the social cost, we propose a strategyproof mechanism that is optimal when misreporting the location only.","For the other two types of manipulation, we reuse the median mechanism and achieve tight bounds of 2.","To minimize the maximum cost, we design new strategyproof mechanisms for the first two types of misreporting.","We reuse the leftmost mechanism for misreporting both.","All bounds are almost tight."],"url":"http://arxiv.org/abs/2409.20396v1"}
{"created":"2024-09-30 15:22:40","title":"Machine Learning-enabled Traffic Steering in O-RAN: A Case Study on Hierarchical Learning Approach","abstract":"Traffic Steering is a crucial technology for wireless networks, and multiple efforts have been put into developing efficient Machine Learning (ML)-enabled traffic steering schemes for Open Radio Access Networks (O-RAN). Given the swift emergence of novel ML techniques, conducting a timely survey that comprehensively examines the ML-based traffic steering schemes in O-RAN is critical. In this article, we provide such a survey along with a case study of hierarchical learning-enabled traffic steering in O-RAN. In particular, we first introduce the background of traffic steering in O-RAN and overview relevant state-of-the-art ML techniques and their applications. Then, we analyze the compatibility of the hierarchical learning framework in O-RAN and further propose a Hierarchical Deep-Q-Learning (h-DQN) framework for traffic steering. Compared to existing works, which focus on single-layer architecture with standalone agents, h-DQN decomposes the traffic steering problem into a bi-level architecture with hierarchical intelligence. The meta-controller makes long-term and high-level policies, while the controller executes instant traffic steering actions under high-level policies. Finally, the case study shows that the hierarchical learning approach can provide significant performance improvements over the baseline algorithms.","sentences":["Traffic Steering is a crucial technology for wireless networks, and multiple efforts have been put into developing efficient Machine Learning (ML)-enabled traffic steering schemes for Open Radio Access Networks (O-RAN).","Given the swift emergence of novel ML techniques, conducting a timely survey that comprehensively examines the ML-based traffic steering schemes in O-RAN is critical.","In this article, we provide such a survey along with a case study of hierarchical learning-enabled traffic steering in O-RAN.","In particular, we first introduce the background of traffic steering in O-RAN and overview relevant state-of-the-art ML techniques and their applications.","Then, we analyze the compatibility of the hierarchical learning framework in O-RAN and further propose a Hierarchical Deep-Q-Learning (h-DQN) framework for traffic steering.","Compared to existing works, which focus on single-layer architecture with standalone agents, h-DQN decomposes the traffic steering problem into a bi-level architecture with hierarchical intelligence.","The meta-controller makes long-term and high-level policies, while the controller executes instant traffic steering actions under high-level policies.","Finally, the case study shows that the hierarchical learning approach can provide significant performance improvements over the baseline algorithms."],"url":"http://arxiv.org/abs/2409.20391v1"}
{"created":"2024-09-30 15:21:25","title":"Anti-stereotypical Predictive Text Suggestions Do Not Reliably Yield Anti-stereotypical Writing","abstract":"AI-based systems such as language models can replicate and amplify social biases reflected in their training data. Among other questionable behavior, this can lead to LM-generated text--and text suggestions--that contain normatively inappropriate stereotypical associations. In this paper, we consider the question of how \"debiasing\" a language model impacts stories that people write using that language model in a predictive text scenario. We find that (n=414), in certain scenarios, language model suggestions that align with common social stereotypes are more likely to be accepted by human authors. Conversely, although anti-stereotypical language model suggestions sometimes lead to an increased rate of anti-stereotypical stories, this influence is far from sufficient to lead to \"fully debiased\" stories.","sentences":["AI-based systems such as language models can replicate and amplify social biases reflected in their training data.","Among other questionable behavior, this can lead to LM-generated text--and text suggestions--that contain normatively inappropriate stereotypical associations.","In this paper, we consider the question of how \"debiasing\" a language model impacts stories that people write using that language model in a predictive text scenario.","We find that (n=414), in certain scenarios, language model suggestions that align with common social stereotypes are more likely to be accepted by human authors.","Conversely, although anti-stereotypical language model suggestions sometimes lead to an increased rate of anti-stereotypical stories, this influence is far from sufficient to lead to \"fully debiased\" stories."],"url":"http://arxiv.org/abs/2409.20390v1"}
{"created":"2024-09-30 15:21:21","title":"SAMIPS: A Synthesised Asynchronous Processor","abstract":"Miniaturisation and ever increasing clock speeds pose significant challenges to synchronous VLSI design with clock distribution becoming an increasingly costly and complicated issue and power consumption rapidly emerging as a major concern. Asynchronous logic promises to alleviate these challenges however its development and adoption has been hindered by the lack of mature design tools. Balsa is a response to this gap, encompassing a CSP-based asynchronous hardware description language and a framework for automatically synnthesising asynchronous circuits. This paper discusses SAMIPS, an asynchronous implementation of the MIPS microprocessor and the first full scale asynchronous microprocessor to be synthesised in Balsa. The objectives of the paper are twofold: first to provide a holistic description of SAMIPS and its components, the approach that it has been followed for the asynchronisation of MIPS and the innovative solutions that have been developed to address hazard challenges and a quantitative performance analysis of the system; secondly, to provide insights about the effectiveness of Balsa as a hardware description language and synthesis system.","sentences":["Miniaturisation and ever increasing clock speeds pose significant challenges to synchronous VLSI design with clock distribution becoming an increasingly costly and complicated issue and power consumption rapidly emerging as a major concern.","Asynchronous logic promises to alleviate these challenges however its development and adoption has been hindered by the lack of mature design tools.","Balsa is a response to this gap, encompassing a CSP-based asynchronous hardware description language and a framework for automatically synnthesising asynchronous circuits.","This paper discusses SAMIPS, an asynchronous implementation of the MIPS microprocessor and the first full scale asynchronous microprocessor to be synthesised in Balsa.","The objectives of the paper are twofold: first to provide a holistic description of SAMIPS and its components, the approach that it has been followed for the asynchronisation of MIPS and the innovative solutions that have been developed to address hazard challenges and a quantitative performance analysis of the system; secondly, to provide insights about the effectiveness of Balsa as a hardware description language and synthesis system."],"url":"http://arxiv.org/abs/2409.20388v1"}
{"created":"2024-09-30 15:21:08","title":"Automation from the Worker's Perspective","abstract":"Common narratives about automation often pit new technologies against workers. The introduction of advanced machine tools, industrial robots, and AI have all been met with concern that technological progress will mean fewer jobs. However, workers themselves offer a more optimistic, nuanced perspective. Drawing on a far-reaching 2024 survey of more than 9,000 workers across nine countries, this paper finds that more workers report potential benefits from new technologies like robots and AI for their safety and comfort at work, their pay, and their autonomy on the job than report potential costs. Workers with jobs that ask them to solve complex problems, workers who feel valued by their employers, and workers who are motivated to move up in their careers are all more likely to see new technologies as beneficial. In contrast to assumptions in previous research, more formal education is in some cases associated with more negative attitudes toward automation and its impact on work. In an experimental setting, the prospect of financial incentives for workers improve their perceptions of automation technologies, whereas the prospect of increased input about how new technologies are used does not have a significant effect on workers' attitudes toward automation.","sentences":["Common narratives about automation often pit new technologies against workers.","The introduction of advanced machine tools, industrial robots, and AI have all been met with concern that technological progress will mean fewer jobs.","However, workers themselves offer a more optimistic, nuanced perspective.","Drawing on a far-reaching 2024 survey of more than 9,000 workers across nine countries, this paper finds that more workers report potential benefits from new technologies like robots and AI for their safety and comfort at work, their pay, and their autonomy on the job than report potential costs.","Workers with jobs that ask them to solve complex problems, workers who feel valued by their employers, and workers who are motivated to move up in their careers are all more likely to see new technologies as beneficial.","In contrast to assumptions in previous research, more formal education is in some cases associated with more negative attitudes toward automation and its impact on work.","In an experimental setting, the prospect of financial incentives for workers improve their perceptions of automation technologies, whereas the prospect of increased input about how new technologies are used does not have a significant effect on workers' attitudes toward automation."],"url":"http://arxiv.org/abs/2409.20387v1"}
{"created":"2024-09-30 15:20:58","title":"Wait, but Tylenol is Acetaminophen... Investigating and Improving Language Models' Ability to Resist Requests for Misinformation","abstract":"Background: Large language models (LLMs) are trained to follow directions, but this introduces a vulnerability to blindly comply with user requests even if they generate wrong information. In medicine, this could accelerate the generation of misinformation that impacts human well-being.   Objectives/Methods: We analyzed compliance to requests to generate misleading content about medications in settings where models know the request is illogical. We investigated whether in-context directions and instruction-tuning of LLMs to prioritize logical reasoning over compliance reduced misinformation risk.   Results: While all frontier LLMs complied with misinformation requests, both prompt-based and parameter-based approaches can improve the detection of logic flaws in requests and prevent the dissemination of medical misinformation.   Conclusion: Shifting LLMs to prioritize logic over compliance could reduce risks of exploitation for medical misinformation.","sentences":["Background: Large language models (LLMs) are trained to follow directions, but this introduces a vulnerability to blindly comply with user requests even if they generate wrong information.","In medicine, this could accelerate the generation of misinformation that impacts human well-being.   ","Objectives/Methods: We analyzed compliance to requests to generate misleading content about medications in settings where models know the request is illogical.","We investigated whether in-context directions and instruction-tuning of LLMs to prioritize logical reasoning over compliance reduced misinformation risk.   ","Results: While all frontier LLMs complied with misinformation requests, both prompt-based and parameter-based approaches can improve the detection of logic flaws in requests and prevent the dissemination of medical misinformation.   ","Conclusion: Shifting LLMs to prioritize logic over compliance could reduce risks of exploitation for medical misinformation."],"url":"http://arxiv.org/abs/2409.20385v1"}
{"created":"2024-09-30 15:20:28","title":"FireLite: Leveraging Transfer Learning for Efficient Fire Detection in Resource-Constrained Environments","abstract":"Fire hazards are extremely dangerous, particularly in sectors such as the transportation industry, where political unrest increases the likelihood of their occurrence. By employing IP cameras to facilitate the setup of fire detection systems on transport vehicles, losses from fire events may be prevented proactively. However, the development of lightweight fire detection models is required due to the computational constraints of the embedded systems within these cameras. We introduce FireLite, a low-parameter convolutional neural network (CNN) designed for quick fire detection in contexts with limited resources, in response to this difficulty. With an accuracy of 98.77\\%, our model -- which has just 34,978 trainable parameters achieves remarkable performance numbers. It also shows a validation loss of 8.74 and peaks at 98.77 for precision, recall, and F1-score measures. Because of its precision and efficiency, FireLite is a promising solution for fire detection in resource-constrained environments.","sentences":["Fire hazards are extremely dangerous, particularly in sectors such as the transportation industry, where political unrest increases the likelihood of their occurrence.","By employing IP cameras to facilitate the setup of fire detection systems on transport vehicles, losses from fire events may be prevented proactively.","However, the development of lightweight fire detection models is required due to the computational constraints of the embedded systems within these cameras.","We introduce FireLite, a low-parameter convolutional neural network (CNN) designed for quick fire detection in contexts with limited resources, in response to this difficulty.","With an accuracy of 98.77\\%, our model -- which has just 34,978 trainable parameters achieves remarkable performance numbers.","It also shows a validation loss of 8.74 and peaks at 98.77 for precision, recall, and F1-score measures.","Because of its precision and efficiency, FireLite is a promising solution for fire detection in resource-constrained environments."],"url":"http://arxiv.org/abs/2409.20384v1"}
{"created":"2024-09-30 15:20:10","title":"Beyond Derivative Pathology of PINNs: Variable Splitting Strategy with Convergence Analysis","abstract":"Physics-informed neural networks (PINNs) have recently emerged as effective methods for solving partial differential equations (PDEs) in various problems. Substantial research focuses on the failure modes of PINNs due to their frequent inaccuracies in predictions. However, most are based on the premise that minimizing the loss function to zero causes the network to converge to a solution of the governing PDE. In this study, we prove that PINNs encounter a fundamental issue that the premise is invalid. We also reveal that this issue stems from the inability to regulate the behavior of the derivatives of the predicted solution. Inspired by the \\textit{derivative pathology} of PINNs, we propose a \\textit{variable splitting} strategy that addresses this issue by parameterizing the gradient of the solution as an auxiliary variable. We demonstrate that using the auxiliary variable eludes derivative pathology by enabling direct monitoring and regulation of the gradient of the predicted solution. Moreover, we prove that the proposed method guarantees convergence to a generalized solution for second-order linear PDEs, indicating its applicability to various problems.","sentences":["Physics-informed neural networks (PINNs) have recently emerged as effective methods for solving partial differential equations (PDEs) in various problems.","Substantial research focuses on the failure modes of PINNs due to their frequent inaccuracies in predictions.","However, most are based on the premise that minimizing the loss function to zero causes the network to converge to a solution of the governing PDE.","In this study, we prove that PINNs encounter a fundamental issue that the premise is invalid.","We also reveal that this issue stems from the inability to regulate the behavior of the derivatives of the predicted solution.","Inspired by the \\textit{derivative pathology} of PINNs, we propose a \\textit{variable splitting} strategy that addresses this issue by parameterizing the gradient of the solution as an auxiliary variable.","We demonstrate that using the auxiliary variable eludes derivative pathology by enabling direct monitoring and regulation of the gradient of the predicted solution.","Moreover, we prove that the proposed method guarantees convergence to a generalized solution for second-order linear PDEs, indicating its applicability to various problems."],"url":"http://arxiv.org/abs/2409.20383v1"}
{"created":"2024-09-30 15:16:35","title":"Heterogeneous computing in a strongly-connected CPU-GPU environment: fast multiple time-evolution equation-based modeling accelerated using data-driven approach","abstract":"We propose a CPU-GPU heterogeneous computing method for solving time-evolution partial differential equation problems many times with guaranteed accuracy, in short time-to-solution and low energy-to-solution. On a single-GH200 node, the proposed method improved the computation speed by 86.4 and 8.67 times compared to the conventional method run only on CPU and only on GPU, respectively. Furthermore, the energy-to-solution was reduced by 32.2-fold (from 9944 J to 309 J) and 7.01-fold (from 2163 J to 309 J) when compared to using only the CPU and GPU, respectively. Using the proposed method on the Alps supercomputer, a 51.6-fold and 6.98-fold speedup was attained when compared to using only the CPU and GPU, respectively, and a high weak scaling efficiency of 94.3% was obtained up to 1,920 compute nodes. These implementations were realized using directive-based parallel programming models while enabling portability, indicating that directives are highly effective in analyses in heterogeneous computing environments.","sentences":["We propose a CPU-GPU heterogeneous computing method for solving time-evolution partial differential equation problems many times with guaranteed accuracy, in short time-to-solution and low energy-to-solution.","On a single-GH200 node, the proposed method improved the computation speed by 86.4 and 8.67 times compared to the conventional method run only on CPU and only on GPU, respectively.","Furthermore, the energy-to-solution was reduced by 32.2-fold (from 9944 J to 309 J) and 7.01-fold (from 2163 J to 309 J) when compared to using only the CPU and GPU, respectively.","Using the proposed method on the Alps supercomputer, a 51.6-fold and 6.98-fold speedup was attained when compared to using only the CPU and GPU, respectively, and a high weak scaling efficiency of 94.3% was obtained up to 1,920 compute nodes.","These implementations were realized using directive-based parallel programming models while enabling portability, indicating that directives are highly effective in analyses in heterogeneous computing environments."],"url":"http://arxiv.org/abs/2409.20380v1"}
{"created":"2024-09-30 15:09:42","title":"Word-wise intonation model for cross-language TTS systems","abstract":"In this paper we propose a word-wise intonation model for Russian language and show how it can be generalized for other languages. The proposed model is suitable for automatic data markup and its extended application to text-to-speech systems. It can also be implemented for an intonation contour modeling by using rule-based algorithms or by predicting contours with language models. The key idea is a partial elimination of the variability connected with different placements of a stressed syllable in a word. It is achieved with simultaneous applying of pitch simplification with a dynamic time warping clustering. The proposed model could be used as a tool for intonation research or as a backbone for prosody description in text-to-speech systems. As the advantage of the model, we show its relations with the existing intonation systems as well as the possibility of using language models for prosody prediction. Finally, we demonstrate some practical evidence of the system robustness to parameter variations.","sentences":["In this paper we propose a word-wise intonation model for Russian language and show how it can be generalized for other languages.","The proposed model is suitable for automatic data markup and its extended application to text-to-speech systems.","It can also be implemented for an intonation contour modeling by using rule-based algorithms or by predicting contours with language models.","The key idea is a partial elimination of the variability connected with different placements of a stressed syllable in a word.","It is achieved with simultaneous applying of pitch simplification with a dynamic time warping clustering.","The proposed model could be used as a tool for intonation research or as a backbone for prosody description in text-to-speech systems.","As the advantage of the model, we show its relations with the existing intonation systems as well as the possibility of using language models for prosody prediction.","Finally, we demonstrate some practical evidence of the system robustness to parameter variations."],"url":"http://arxiv.org/abs/2409.20374v1"}
{"created":"2024-09-30 15:07:16","title":"Frequency Adaptive Normalization For Non-stationary Time Series Forecasting","abstract":"Time series forecasting typically needs to address non-stationary data with evolving trend and seasonal patterns. To address the non-stationarity, reversible instance normalization has been recently proposed to alleviate impacts from the trend with certain statistical measures, e.g., mean and variance. Although they demonstrate improved predictive accuracy, they are limited to expressing basic trends and are incapable of handling seasonal patterns. To address this limitation, this paper proposes a new instance normalization solution, called frequency adaptive normalization (FAN), which extends instance normalization in handling both dynamic trend and seasonal patterns. Specifically, we employ the Fourier transform to identify instance-wise predominant frequent components that cover most non-stationary factors. Furthermore, the discrepancy of those frequency components between inputs and outputs is explicitly modeled as a prediction task with a simple MLP model. FAN is a model-agnostic method that can be applied to arbitrary predictive backbones. We instantiate FAN on four widely used forecasting models as the backbone and evaluate their prediction performance improvements on eight benchmark datasets. FAN demonstrates significant performance advancement, achieving 7.76% ~ 37.90% average improvements in MSE.","sentences":["Time series forecasting typically needs to address non-stationary data with evolving trend and seasonal patterns.","To address the non-stationarity, reversible instance normalization has been recently proposed to alleviate impacts from the trend with certain statistical measures, e.g., mean and variance.","Although they demonstrate improved predictive accuracy, they are limited to expressing basic trends and are incapable of handling seasonal patterns.","To address this limitation, this paper proposes a new instance normalization solution, called frequency adaptive normalization (FAN), which extends instance normalization in handling both dynamic trend and seasonal patterns.","Specifically, we employ the Fourier transform to identify instance-wise predominant frequent components that cover most non-stationary factors.","Furthermore, the discrepancy of those frequency components between inputs and outputs is explicitly modeled as a prediction task with a simple MLP model.","FAN is a model-agnostic method that can be applied to arbitrary predictive backbones.","We instantiate FAN on four widely used forecasting models as the backbone and evaluate their prediction performance improvements on eight benchmark datasets.","FAN demonstrates significant performance advancement, achieving 7.76% ~ 37.90% average improvements in MSE."],"url":"http://arxiv.org/abs/2409.20371v1"}
{"created":"2024-09-30 15:06:53","title":"The Perfect Blend: Redefining RLHF with Mixture of Judges","abstract":"Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM). However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives). Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations. This is often done via human intuition and does not generalize. In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO). The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner. It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines. Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.   Our empirical evaluations demonstrate that CGPO significantly outperforms standard RLHF algorithms like PPO and DPO across various tasks including general chat, STEM questions, instruction following, and coding. Specifically, CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM & reasoning), and consistent gains in other domains like math and coding. Notably, PPO, while commonly used, is prone to severe reward hacking in popular coding benchmarks, which CGPO successfully addresses. This breakthrough in RLHF not only tackles reward hacking and extreme multi-objective optimization challenges but also advances the state-of-the-art in aligning general-purpose LLMs for diverse applications.","sentences":["Reinforcement learning from human feedback (RLHF) has become the leading approach for fine-tuning large language models (LLM).","However, RLHF has limitations in multi-task learning (MTL) due to challenges of reward hacking and extreme multi-objective optimization (i.e., trade-off of multiple and/or sometimes conflicting objectives).","Applying RLHF for MTL currently requires careful tuning of the weights for reward model and data combinations.","This is often done via human intuition and does not generalize.","In this work, we introduce a novel post-training paradigm which we called Constrained Generative Policy Optimization (CGPO).","The core of CGPO is Mixture of Judges (MoJ) with cost-efficient constrained policy optimization with stratification, which can identify the perfect blend in RLHF in a principled manner.","It shows strong empirical results with theoretical guarantees, does not require extensive hyper-parameter tuning, and is plug-and-play in common post-training pipelines.","Together, this can detect and mitigate reward hacking behaviors while reaching a pareto-optimal point across an extremely large number of objectives.   ","Our empirical evaluations demonstrate that CGPO significantly outperforms standard RLHF algorithms like PPO and DPO across various tasks including general chat, STEM questions, instruction following, and coding.","Specifically, CGPO shows improvements of 7.4% in AlpacaEval-2 (general chat), 12.5% in Arena-Hard (STEM & reasoning), and consistent gains in other domains like math and coding.","Notably, PPO, while commonly used, is prone to severe reward hacking in popular coding benchmarks, which CGPO successfully addresses.","This breakthrough in RLHF not only tackles reward hacking and extreme multi-objective optimization challenges but also advances the state-of-the-art in aligning general-purpose LLMs for diverse applications."],"url":"http://arxiv.org/abs/2409.20370v1"}
