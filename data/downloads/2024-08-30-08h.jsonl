{"created":"2024-08-29 17:59:54","title":"3D Whole-body Grasp Synthesis with Directional Controllability","abstract":"Synthesizing 3D whole-bodies that realistically grasp objects is useful for animation, mixed reality, and robotics. This is challenging, because the hands and body need to look natural w.r.t. each other, the grasped object, as well as the local scene (i.e., a receptacle supporting the object). Only recent work tackles this, with a divide-and-conquer approach; it first generates a \"guiding\" right-hand grasp, and then searches for bodies that match this. However, the guiding-hand synthesis lacks controllability and receptacle awareness, so it likely has an implausible direction (i.e., a body can't match this without penetrating the receptacle) and needs corrections through major post-processing. Moreover, the body search needs exhaustive sampling and is expensive. These are strong limitations. We tackle these with a novel method called CWGrasp. Our key idea is that performing geometry-based reasoning \"early on,\" instead of \"too late,\" provides rich \"control\" signals for inference. To this end, CWGrasp first samples a plausible reaching-direction vector (used later for both the arm and hand) from a probabilistic model built via raycasting from the object and collision checking. Then, it generates a reaching body with a desired arm direction, as well as a \"guiding\" grasping hand with a desired palm direction that complies with the arm's one. Eventually, CWGrasp refines the body to match the \"guiding\" hand, while plausibly contacting the scene. Notably, generating already-compatible \"parts\" greatly simplifies the \"whole.\" Moreover, CWGrasp uniquely tackles both right- and left-hand grasps. We evaluate on the GRAB and ReplicaGrasp datasets. CWGrasp outperforms baselines, at lower runtime and budget, while all components help performance. Code and models will be released.","sentences":["Synthesizing 3D whole-bodies that realistically grasp objects is useful for animation, mixed reality, and robotics.","This is challenging, because the hands and body need to look natural w.r.t.","each other, the grasped object, as well as the local scene (i.e., a receptacle supporting the object).","Only recent work tackles this, with a divide-and-conquer approach; it first generates a \"guiding\" right-hand grasp, and then searches for bodies that match this.","However, the guiding-hand synthesis lacks controllability and receptacle awareness, so it likely has an implausible direction (i.e., a body can't match this without penetrating the receptacle) and needs corrections through major post-processing.","Moreover, the body search needs exhaustive sampling and is expensive.","These are strong limitations.","We tackle these with a novel method called CWGrasp.","Our key idea is that performing geometry-based reasoning \"early on,\" instead of \"too late,\" provides rich \"control\" signals for inference.","To this end, CWGrasp first samples a plausible reaching-direction vector (used later for both the arm and hand) from a probabilistic model built via raycasting from the object and collision checking.","Then, it generates a reaching body with a desired arm direction, as well as a \"guiding\" grasping hand with a desired palm direction that complies with the arm's one.","Eventually, CWGrasp refines the body to match the \"guiding\" hand, while plausibly contacting the scene.","Notably, generating already-compatible \"parts\" greatly simplifies the \"whole.\"","Moreover, CWGrasp uniquely tackles both right- and left-hand grasps.","We evaluate on the GRAB and ReplicaGrasp datasets.","CWGrasp outperforms baselines, at lower runtime and budget, while all components help performance.","Code and models will be released."],"url":"http://arxiv.org/abs/2408.16770v1"}
{"created":"2024-08-29 17:59:45","title":"SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners","abstract":"We introduce SAM2Point, a preliminary exploration adapting Segment Anything Model 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2Point interprets any 3D data as a series of multi-directional videos, and leverages SAM 2 for 3D-space segmentation, without further training or 2D-3D projection. Our framework supports various prompt types, including 3D points, boxes, and masks, and can generalize across diverse scenarios, such as 3D objects, indoor scenes, outdoor environments, and raw sparse LiDAR. Demonstrations on multiple 3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight the robust generalization capabilities of SAM2Point. To our best knowledge, we present the most faithful implementation of SAM in 3D, which may serve as a starting point for future research in promptable 3D segmentation. Online Demo: https://huggingface.co/spaces/ZiyuG/SAM2Point . Code: https://github.com/ZiyuGuo99/SAM2Point .","sentences":["We introduce SAM2Point, a preliminary exploration adapting Segment Anything Model 2 (SAM 2) for zero-shot and promptable 3D segmentation.","SAM2Point interprets any 3D data as a series of multi-directional videos, and leverages SAM 2 for 3D-space segmentation, without further training or 2D-3D projection.","Our framework supports various prompt types, including 3D points, boxes, and masks, and can generalize across diverse scenarios, such as 3D objects, indoor scenes, outdoor environments, and raw sparse LiDAR.","Demonstrations on multiple 3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight the robust generalization capabilities of SAM2Point.","To our best knowledge, we present the most faithful implementation of SAM in 3D, which may serve as a starting point for future research in promptable 3D segmentation.","Online Demo: https://huggingface.co/spaces/ZiyuG/SAM2Point .","Code: https://github.com/ZiyuGuo99/SAM2Point ."],"url":"http://arxiv.org/abs/2408.16768v1"}
{"created":"2024-08-29 17:59:45","title":"PromptSmooth: Certifying Robustness of Medical Vision-Language Models via Prompt Learning","abstract":"Medical vision-language models (Med-VLMs) trained on large datasets of medical image-text pairs and later fine-tuned for specific tasks have emerged as a mainstream paradigm in medical image analysis. However, recent studies have highlighted the susceptibility of these Med-VLMs to adversarial attacks, raising concerns about their safety and robustness. Randomized smoothing is a well-known technique for turning any classifier into a model that is certifiably robust to adversarial perturbations. However, this approach requires retraining the Med-VLM-based classifier so that it classifies well under Gaussian noise, which is often infeasible in practice. In this paper, we propose a novel framework called PromptSmooth to achieve efficient certified robustness of Med-VLMs by leveraging the concept of prompt learning. Given any pre-trained Med-VLM, PromptSmooth adapts it to handle Gaussian noise by learning textual prompts in a zero-shot or few-shot manner, achieving a delicate balance between accuracy and robustness, while minimizing the computational overhead. Moreover, PromptSmooth requires only a single model to handle multiple noise levels, which substantially reduces the computational cost compared to traditional methods that rely on training a separate model for each noise level. Comprehensive experiments based on three Med-VLMs and across six downstream datasets of various imaging modalities demonstrate the efficacy of PromptSmooth. Our code and models are available at https://github.com/nhussein/promptsmooth.","sentences":["Medical vision-language models (Med-VLMs) trained on large datasets of medical image-text pairs and later fine-tuned for specific tasks have emerged as a mainstream paradigm in medical image analysis.","However, recent studies have highlighted the susceptibility of these Med-VLMs to adversarial attacks, raising concerns about their safety and robustness.","Randomized smoothing is a well-known technique for turning any classifier into a model that is certifiably robust to adversarial perturbations.","However, this approach requires retraining the Med-VLM-based classifier so that it classifies well under Gaussian noise, which is often infeasible in practice.","In this paper, we propose a novel framework called PromptSmooth to achieve efficient certified robustness of Med-VLMs by leveraging the concept of prompt learning.","Given any pre-trained Med-VLM, PromptSmooth adapts it to handle Gaussian noise by learning textual prompts in a zero-shot or few-shot manner, achieving a delicate balance between accuracy and robustness, while minimizing the computational overhead.","Moreover, PromptSmooth requires only a single model to handle multiple noise levels, which substantially reduces the computational cost compared to traditional methods that rely on training a separate model for each noise level.","Comprehensive experiments based on three Med-VLMs and across six downstream datasets of various imaging modalities demonstrate the efficacy of PromptSmooth.","Our code and models are available at https://github.com/nhussein/promptsmooth."],"url":"http://arxiv.org/abs/2408.16769v1"}
{"created":"2024-08-29 17:59:40","title":"ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model","abstract":"Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos. Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas. In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task. The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction. However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models. To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition. Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives. Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme. Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability.","sentences":["Advancements in 3D scene reconstruction have transformed 2D images from the real world into 3D models, producing realistic 3D results from hundreds of input photos.","Despite great success in dense-view reconstruction scenarios, rendering a detailed scene from insufficient captured views is still an ill-posed optimization problem, often resulting in artifacts and distortions in unseen areas.","In this paper, we propose ReconX, a novel 3D scene reconstruction paradigm that reframes the ambiguous reconstruction challenge as a temporal generation task.","The key insight is to unleash the strong generative prior of large pre-trained video diffusion models for sparse-view reconstruction.","However, 3D view consistency struggles to be accurately preserved in directly generated video frames from pre-trained models.","To address this, given limited input views, the proposed ReconX first constructs a global point cloud and encodes it into a contextual space as the 3D structure condition.","Guided by the condition, the video diffusion model then synthesizes video frames that are both detail-preserved and exhibit a high degree of 3D consistency, ensuring the coherence of the scene from various perspectives.","Finally, we recover the 3D scene from the generated video through a confidence-aware 3D Gaussian Splatting optimization scheme.","Extensive experiments on various real-world datasets show the superiority of our ReconX over state-of-the-art methods in terms of quality and generalizability."],"url":"http://arxiv.org/abs/2408.16767v1"}
{"created":"2024-08-29 17:59:30","title":"CSGO: Content-Style Composition in Text-to-Image Generation","abstract":"The diffusion model has shown exceptional capabilities in controlled image generation, which has further fueled interest in image style transfer. Existing works mainly focus on training free-based methods (e.g., image inversion) due to the scarcity of specific data. In this study, we present a data construction pipeline for content-style-stylized image triplets that generates and automatically cleanses stylized data triplets. Based on this pipeline, we construct a dataset IMAGStyle, the first large-scale style transfer dataset containing 210k image triplets, available for the community to explore and research. Equipped with IMAGStyle, we propose CSGO, a style transfer model based on end-to-end training, which explicitly decouples content and style features employing independent feature injection. The unified CSGO implements image-driven style transfer, text-driven stylized synthesis, and text editing-driven stylized synthesis. Extensive experiments demonstrate the effectiveness of our approach in enhancing style control capabilities in image generation. Additional visualization and access to the source code can be located on the project page: \\url{https://csgo-gen.github.io/}.","sentences":["The diffusion model has shown exceptional capabilities in controlled image generation, which has further fueled interest in image style transfer.","Existing works mainly focus on training free-based methods (e.g., image inversion) due to the scarcity of specific data.","In this study, we present a data construction pipeline for content-style-stylized image triplets that generates and automatically cleanses stylized data triplets.","Based on this pipeline, we construct a dataset IMAGStyle, the first large-scale style transfer dataset containing 210k image triplets, available for the community to explore and research.","Equipped with IMAGStyle, we propose CSGO, a style transfer model based on end-to-end training, which explicitly decouples content and style features employing independent feature injection.","The unified CSGO implements image-driven style transfer, text-driven stylized synthesis, and text editing-driven stylized synthesis.","Extensive experiments demonstrate the effectiveness of our approach in enhancing style control capabilities in image generation.","Additional visualization and access to the source code can be located on the project page: \\url{https://csgo-gen.github.io/}."],"url":"http://arxiv.org/abs/2408.16766v1"}
{"created":"2024-08-29 17:59:07","title":"A Score-Based Density Formula, with Applications in Diffusion Generative Models","abstract":"Score-based generative models (SGMs) have revolutionized the field of generative modeling, achieving unprecedented success in generating realistic and diverse content. Despite empirical advances, the theoretical basis for why optimizing the evidence lower bound (ELBO) on the log-likelihood is effective for training diffusion generative models, such as DDPMs, remains largely unexplored. In this paper, we address this question by establishing a density formula for a continuous-time diffusion process, which can be viewed as the continuous-time limit of the forward process in an SGM. This formula reveals the connection between the target density and the score function associated with each step of the forward process. Building on this, we demonstrate that the minimizer of the optimization objective for training DDPMs nearly coincides with that of the true objective, providing a theoretical foundation for optimizing DDPMs using the ELBO. Furthermore, we offer new insights into the role of score-matching regularization in training GANs, the use of ELBO in diffusion classifiers, and the recently proposed diffusion loss.","sentences":["Score-based generative models (SGMs) have revolutionized the field of generative modeling, achieving unprecedented success in generating realistic and diverse content.","Despite empirical advances, the theoretical basis for why optimizing the evidence lower bound (ELBO) on the log-likelihood is effective for training diffusion generative models, such as DDPMs, remains largely unexplored.","In this paper, we address this question by establishing a density formula for a continuous-time diffusion process, which can be viewed as the continuous-time limit of the forward process in an SGM.","This formula reveals the connection between the target density and the score function associated with each step of the forward process.","Building on this, we demonstrate that the minimizer of the optimization objective for training DDPMs nearly coincides with that of the true objective, providing a theoretical foundation for optimizing DDPMs using the ELBO.","Furthermore, we offer new insights into the role of score-matching regularization in training GANs, the use of ELBO in diffusion classifiers, and the recently proposed diffusion loss."],"url":"http://arxiv.org/abs/2408.16765v1"}
{"created":"2024-08-29 17:57:05","title":"UV-free Texture Generation with Denoising and Geodesic Heat Diffusions","abstract":"Seams, distortions, wasted UV space, vertex-duplication, and varying resolution over the surface are the most prominent issues of the standard UV-based texturing of meshes. These issues are particularly acute when automatic UV-unwrapping techniques are used. For this reason, instead of generating textures in automatically generated UV-planes like most state-of-the-art methods, we propose to represent textures as coloured point-clouds whose colours are generated by a denoising diffusion probabilistic model constrained to operate on the surface of 3D objects. Our sampling and resolution agnostic generative model heavily relies on heat diffusion over the surface of the meshes for spatial communication between points. To enable processing of arbitrarily sampled point-cloud textures and ensure long-distance texture consistency we introduce a fast re-sampling of the mesh spectral properties used during the heat diffusion and introduce a novel heat-diffusion-based self-attention mechanism. Our code and pre-trained models are available at github.com/simofoti/UV3-TeD.","sentences":["Seams, distortions, wasted UV space, vertex-duplication, and varying resolution over the surface are the most prominent issues of the standard UV-based texturing of meshes.","These issues are particularly acute when automatic UV-unwrapping techniques are used.","For this reason, instead of generating textures in automatically generated UV-planes like most state-of-the-art methods, we propose to represent textures as coloured point-clouds whose colours are generated by a denoising diffusion probabilistic model constrained to operate on the surface of 3D objects.","Our sampling and resolution agnostic generative model heavily relies on heat diffusion over the surface of the meshes for spatial communication between points.","To enable processing of arbitrarily sampled point-cloud textures and ensure long-distance texture consistency we introduce a fast re-sampling of the mesh spectral properties used during the heat diffusion and introduce a novel heat-diffusion-based self-attention mechanism.","Our code and pre-trained models are available at github.com/simofoti/UV3-TeD."],"url":"http://arxiv.org/abs/2408.16762v1"}
{"created":"2024-08-29 17:56:33","title":"OmniRe: Omni Urban Scene Reconstruction","abstract":"We introduce OmniRe, a holistic approach for efficiently reconstructing high-fidelity dynamic urban scenes from on-device logs. Recent methods for modeling driving sequences using neural radiance fields or Gaussian Splatting have demonstrated the potential of reconstructing challenging dynamic scenes, but often overlook pedestrians and other non-vehicle dynamic actors, hindering a complete pipeline for dynamic urban scene reconstruction. To that end, we propose a comprehensive 3DGS framework for driving scenes, named OmniRe, that allows for accurate, full-length reconstruction of diverse dynamic objects in a driving log. OmniRe builds dynamic neural scene graphs based on Gaussian representations and constructs multiple local canonical spaces that model various dynamic actors, including vehicles, pedestrians, and cyclists, among many others. This capability is unmatched by existing methods. OmniRe allows us to holistically reconstruct different objects present in the scene, subsequently enabling the simulation of reconstructed scenarios with all actors participating in real-time (~60Hz). Extensive evaluations on the Waymo dataset show that our approach outperforms prior state-of-the-art methods quantitatively and qualitatively by a large margin. We believe our work fills a critical gap in driving reconstruction.","sentences":["We introduce OmniRe, a holistic approach for efficiently reconstructing high-fidelity dynamic urban scenes from on-device logs.","Recent methods for modeling driving sequences using neural radiance fields or Gaussian Splatting have demonstrated the potential of reconstructing challenging dynamic scenes, but often overlook pedestrians and other non-vehicle dynamic actors, hindering a complete pipeline for dynamic urban scene reconstruction.","To that end, we propose a comprehensive 3DGS framework for driving scenes, named OmniRe, that allows for accurate, full-length reconstruction of diverse dynamic objects in a driving log.","OmniRe builds dynamic neural scene graphs based on Gaussian representations and constructs multiple local canonical spaces that model various dynamic actors, including vehicles, pedestrians, and cyclists, among many others.","This capability is unmatched by existing methods.","OmniRe allows us to holistically reconstruct different objects present in the scene, subsequently enabling the simulation of reconstructed scenarios with all actors participating in real-time (~60Hz).","Extensive evaluations on the Waymo dataset show that our approach outperforms prior state-of-the-art methods quantitatively and qualitatively by a large margin.","We believe our work fills a critical gap in driving reconstruction."],"url":"http://arxiv.org/abs/2408.16760v1"}
{"created":"2024-08-29 17:55:07","title":"Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks","abstract":"Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years. In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers. Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research. Code: \\url{https://github.com/Visual-AI/Dissect-OOD-OSR}","sentences":["Detecting test-time distribution shift has emerged as a key capability for safely deployed machine learning models, with the question being tackled under various guises in recent years.","In this paper, we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-distribution (OOD) detection and open-set recognition (OSR).","In particular, we aim to provide rigorous empirical analysis of different methods across settings and provide actionable takeaways for practitioners and researchers.","Concretely, we make the following contributions: (i) We perform rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings and identify a strong correlation between the performances of methods for them; (ii) We propose a new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting; (iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure) struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and highlight directions for future research.","Code: \\url{https://github.com/Visual-AI/Dissect-OOD-OSR}"],"url":"http://arxiv.org/abs/2408.16757v1"}
{"created":"2024-08-29 17:54:14","title":"How Far Can Cantonese NLP Go? Benchmarking Cantonese Capabilities of Large Language Models","abstract":"The rapid evolution of large language models (LLMs) has transformed the competitive landscape in natural language processing (NLP), particularly for English and other data-rich languages. However, underrepresented languages like Cantonese, spoken by over 85 million people, face significant development gaps, which is particularly concerning given the economic significance of the Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial Cantonese-speaking populations in places like Singapore and North America. Despite its wide use, Cantonese has scant representation in NLP research, especially compared to other languages from similarly developed regions. To bridge these gaps, we outline current Cantonese NLP methods and introduce new benchmarks designed to evaluate LLM performance in factual generation, mathematical logic, complex reasoning, and general knowledge in Cantonese, which aim to advance open-source Cantonese LLM technology. We also propose future research directions and recommended models to enhance Cantonese LLM development.","sentences":["The rapid evolution of large language models (LLMs) has transformed the competitive landscape in natural language processing (NLP), particularly for English and other data-rich languages.","However, underrepresented languages like Cantonese, spoken by over 85 million people, face significant development gaps, which is particularly concerning given the economic significance of the Guangdong-Hong Kong-Macau Greater Bay Area, and in substantial Cantonese-speaking populations in places like Singapore and North America.","Despite its wide use, Cantonese has scant representation in NLP research, especially compared to other languages from similarly developed regions.","To bridge these gaps, we outline current Cantonese NLP methods and introduce new benchmarks designed to evaluate LLM performance in factual generation, mathematical logic, complex reasoning, and general knowledge in Cantonese, which aim to advance open-source Cantonese LLM technology.","We also propose future research directions and recommended models to enhance Cantonese LLM development."],"url":"http://arxiv.org/abs/2408.16756v1"}
{"created":"2024-08-29 17:53:00","title":"A compact neuromorphic system for ultra energy-efficient, on-device robot localization","abstract":"Neuromorphic computing offers a transformative pathway to overcome the computational and energy challenges faced in deploying robotic localization and navigation systems at the edge. Visual place recognition, a critical component for navigation, is often hampered by the high resource demands of conventional systems, making them unsuitable for small-scale robotic platforms which still require to perform complex, long-range tasks. Although neuromorphic approaches offer potential for greater efficiency, real-time edge deployment remains constrained by the complexity and limited scalability of bio-realistic networks. Here, we demonstrate a neuromorphic localization system that performs accurate place recognition in up to 8km of traversal using models as small as 180 KB with 44k parameters, while consuming less than 1% of the energy required by conventional methods. Our Locational Encoding with Neuromorphic Systems (LENS) integrates spiking neural networks, an event-based dynamic vision sensor, and a neuromorphic processor within a single SPECK(TM) chip, enabling real-time, energy-efficient localization on a hexapod robot. LENS represents the first fully neuromorphic localization system capable of large-scale, on-device deployment, setting a new benchmark for energy efficient robotic place recognition.","sentences":["Neuromorphic computing offers a transformative pathway to overcome the computational and energy challenges faced in deploying robotic localization and navigation systems at the edge.","Visual place recognition, a critical component for navigation, is often hampered by the high resource demands of conventional systems, making them unsuitable for small-scale robotic platforms which still require to perform complex, long-range tasks.","Although neuromorphic approaches offer potential for greater efficiency, real-time edge deployment remains constrained by the complexity and limited scalability of bio-realistic networks.","Here, we demonstrate a neuromorphic localization system that performs accurate place recognition in up to 8km of traversal using models as small as 180 KB with 44k parameters, while consuming less than 1% of the energy required by conventional methods.","Our Locational Encoding with Neuromorphic Systems (LENS) integrates spiking neural networks, an event-based dynamic vision sensor, and a neuromorphic processor within a single SPECK(TM) chip, enabling real-time, energy-efficient localization on a hexapod robot.","LENS represents the first fully neuromorphic localization system capable of large-scale, on-device deployment, setting a new benchmark for energy efficient robotic place recognition."],"url":"http://arxiv.org/abs/2408.16754v1"}
{"created":"2024-08-29 17:49:18","title":"Reinforcement Learning without Human Feedback for Last Mile Fine-Tuning of Large Language Models","abstract":"Reinforcement learning is used to align language models with human preference signals after first pre-training the model to predict the next token of text within a large corpus using likelihood maximization. Before being deployed in a specific domain, models are often further fine-tuned on task specific data. Since human preferences are often unavailable for the last step, it is performed using likelihood maximization as that is the typical default method. However, reinforcement learning has other advantages besides facilitating alignment to a human derived reward function. For one, whereas likelihood maximization is a form of imitation learning in which the model is trained on what to do under ideal conditions, reinforcement learning is not limited to demonstrating actions just for optimally reached states and trains a model what to do under a range of scenarios as it explores the policy space. In addition, it also trains a model what not to do, suppressing competitive but poor actions. This work develops a framework for last-mile fine-tuning using reinforcement learning and tests whether it garners performance gains. The experiments center on abstractive summarization, but the framework is general and broadly applicable. Use of the procedure produced significantly better results than likelihood maximization when comparing raw predictions. For the specific data tested, the gap could be bridged by employing post-processing of the maximum likelihood outputs. Nonetheless, the framework offers a new avenue for model optimization in situations where post-processing may be less straightforward or effective, and it can be extended to include more complex classes of undesirable outputs to penalize and train against, such as hallucinations.","sentences":["Reinforcement learning is used to align language models with human preference signals after first pre-training the model to predict the next token of text within a large corpus using likelihood maximization.","Before being deployed in a specific domain, models are often further fine-tuned on task specific data.","Since human preferences are often unavailable for the last step, it is performed using likelihood maximization as that is the typical default method.","However, reinforcement learning has other advantages besides facilitating alignment to a human derived reward function.","For one, whereas likelihood maximization is a form of imitation learning in which the model is trained on what to do under ideal conditions, reinforcement learning is not limited to demonstrating actions just for optimally reached states and trains a model what to do under a range of scenarios as it explores the policy space.","In addition, it also trains a model what not to do, suppressing competitive but poor actions.","This work develops a framework for last-mile fine-tuning using reinforcement learning and tests whether it garners performance gains.","The experiments center on abstractive summarization, but the framework is general and broadly applicable.","Use of the procedure produced significantly better results than likelihood maximization when comparing raw predictions.","For the specific data tested, the gap could be bridged by employing post-processing of the maximum likelihood outputs.","Nonetheless, the framework offers a new avenue for model optimization in situations where post-processing may be less straightforward or effective, and it can be extended to include more complex classes of undesirable outputs to penalize and train against, such as hallucinations."],"url":"http://arxiv.org/abs/2408.16753v1"}
{"created":"2024-08-29 17:46:18","title":"A Gradient Analysis Framework for Rewarding Good and Penalizing Bad Examples in Language Models","abstract":"Beyond maximum likelihood estimation (MLE), the standard objective of a language model (LM) that optimizes good examples probabilities, many studies have explored ways that also penalize bad examples for enhancing the quality of output distribution, including unlikelihood training, exponential maximizing average treatment effect (ExMATE), and direct preference optimization (DPO). To systematically compare these methods and further provide a unified recipe for LM optimization, in this paper, we present a unique angle of gradient analysis of loss functions that simultaneously reward good examples and penalize bad ones in LMs. Through both mathematical results and experiments on CausalDialogue and Anthropic HH-RLHF datasets, we identify distinct functional characteristics among these methods. We find that ExMATE serves as a superior surrogate for MLE, and that combining DPO with ExMATE instead of MLE further enhances both the statistical (5-7%) and generative (+18% win rate) performance.","sentences":["Beyond maximum likelihood estimation (MLE), the standard objective of a language model (LM) that optimizes good examples probabilities, many studies have explored ways that also penalize bad examples for enhancing the quality of output distribution, including unlikelihood training, exponential maximizing average treatment effect (ExMATE), and direct preference optimization (DPO).","To systematically compare these methods and further provide a unified recipe for LM optimization, in this paper, we present a unique angle of gradient analysis of loss functions that simultaneously reward good examples and penalize bad ones in LMs.","Through both mathematical results and experiments on CausalDialogue and Anthropic HH-RLHF datasets, we identify distinct functional characteristics among these methods.","We find that ExMATE serves as a superior surrogate for MLE, and that combining DPO with ExMATE instead of MLE further enhances both the statistical (5-7%) and generative (+18% win rate) performance."],"url":"http://arxiv.org/abs/2408.16751v1"}
{"created":"2024-08-29 17:43:03","title":"Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge","abstract":"The United States has experienced a significant increase in violent extremism, prompting the need for automated tools to detect and limit the spread of extremist ideology online. This study evaluates the performance of Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformers (GPT) in detecting and classifying online domestic extremist posts. We collected social media posts containing \"far-right\" and \"far-left\" ideological keywords and manually labeled them as extremist or non-extremist. Extremist posts were further classified into one or more of five contributing elements of extremism based on a working definitional framework. The BERT model's performance was evaluated based on training data size and knowledge transfer between categories. We also compared the performance of GPT 3.5 and GPT 4 models using different prompts: na\\\"ive, layperson-definition, role-playing, and professional-definition. Results showed that the best performing GPT models outperformed the best performing BERT models, with more detailed prompts generally yielding better results. However, overly complex prompts may impair performance. Different versions of GPT have unique sensitives to what they consider extremist. GPT 3.5 performed better at classifying far-left extremist posts, while GPT 4 performed better at classifying far-right extremist posts. Large language models, represented by GPT models, hold significant potential for online extremism classification tasks, surpassing traditional BERT models in a zero-shot setting. Future research should explore human-computer interactions in optimizing GPT models for extremist detection and classification tasks to develop more efficient (e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes) methods for identifying extremist content.","sentences":["The United States has experienced a significant increase in violent extremism, prompting the need for automated tools to detect and limit the spread of extremist ideology online.","This study evaluates the performance of Bidirectional Encoder Representations from Transformers (BERT) and Generative Pre-Trained Transformers (GPT) in detecting and classifying online domestic extremist posts.","We collected social media posts containing \"far-right\" and \"far-left\" ideological keywords and manually labeled them as extremist or non-extremist.","Extremist posts were further classified into one or more of five contributing elements of extremism based on a working definitional framework.","The BERT model's performance was evaluated based on training data size and knowledge transfer between categories.","We also compared the performance of GPT 3.5 and GPT 4 models using different prompts: na\\\"ive, layperson-definition, role-playing, and professional-definition.","Results showed that the best performing GPT models outperformed the best performing BERT models, with more detailed prompts generally yielding better results.","However, overly complex prompts may impair performance.","Different versions of GPT have unique sensitives to what they consider extremist.","GPT 3.5 performed better at classifying far-left extremist posts, while GPT 4 performed better at classifying far-right extremist posts.","Large language models, represented by GPT models, hold significant potential for online extremism classification tasks, surpassing traditional BERT models in a zero-shot setting.","Future research should explore human-computer interactions in optimizing GPT models for extremist detection and classification tasks to develop more efficient (e.g., quicker, less effort) and effective (e.g., fewer errors or mistakes) methods for identifying extremist content."],"url":"http://arxiv.org/abs/2408.16749v1"}
{"created":"2024-08-29 17:34:10","title":"Theoretical and Methodological Framework for Studying Texts Produced by Large Language Models","abstract":"This paper addresses the conceptual, methodological and technical challenges in studying large language models (LLMs) and the texts they produce from a quantitative linguistics perspective. It builds on a theoretical framework that distinguishes between the LLM as a substrate and the entities the model simulates. The paper advocates for a strictly non-anthropomorphic approach to models while cautiously applying methodologies used in studying human linguistic behavior to the simulated entities. While natural language processing researchers focus on the models themselves, their architecture, evaluation, and methods for improving performance, we as quantitative linguists should strive to build a robust theory concerning the characteristics of texts produced by LLMs, how they differ from human-produced texts, and the properties of simulated entities. Additionally, we should explore the potential of LLMs as an instrument for studying human culture, of which language is an integral part.","sentences":["This paper addresses the conceptual, methodological and technical challenges in studying large language models (LLMs) and the texts they produce from a quantitative linguistics perspective.","It builds on a theoretical framework that distinguishes between the LLM as a substrate and the entities the model simulates.","The paper advocates for a strictly non-anthropomorphic approach to models while cautiously applying methodologies used in studying human linguistic behavior to the simulated entities.","While natural language processing researchers focus on the models themselves, their architecture, evaluation, and methods for improving performance, we as quantitative linguists should strive to build a robust theory concerning the characteristics of texts produced by LLMs, how they differ from human-produced texts, and the properties of simulated entities.","Additionally, we should explore the potential of LLMs as an instrument for studying human culture, of which language is an integral part."],"url":"http://arxiv.org/abs/2408.16740v1"}
{"created":"2024-08-29 17:32:35","title":"Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling","abstract":"Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs). To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model. We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates. We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM. Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models. These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners.","sentences":["Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs.","In this work, we revisit whether this strategy is compute-optimal under a fixed inference budget (e.g., FLOPs).","To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model.","We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates.","We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM.","Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models.","These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners."],"url":"http://arxiv.org/abs/2408.16737v1"}
{"created":"2024-08-29 17:21:58","title":"VideoLLM-MoD: Efficient Video-Language Streaming with Mixture-of-Depths Vision Computation","abstract":"A well-known dilemma in large vision-language models (e.g., GPT-4, LLaVA) is that while increasing the number of vision tokens generally enhances visual understanding, it also significantly raises memory and computational costs, especially in long-term, dense video frame streaming scenarios. Although learnable approaches like Q-Former and Perceiver Resampler have been developed to reduce the vision token burden, they overlook the context causally modeled by LLMs (i.e., key-value cache), potentially leading to missed visual cues when addressing user queries. In this paper, we introduce a novel approach to reduce vision compute by leveraging redundant vision tokens \"skipping layers\" rather than decreasing the number of vision tokens. Our method, VideoLLM-MoD, is inspired by mixture-of-depths LLMs and addresses the challenge of numerous vision tokens in long-term or streaming video. Specifically, for each transformer layer, we learn to skip the computation for a high proportion (e.g., 80\\%) of vision tokens, passing them directly to the next layer. This approach significantly enhances model efficiency, achieving approximately \\textasciitilde42\\% time and \\textasciitilde30\\% memory savings for the entire training. Moreover, our method reduces the computation in the context and avoid decreasing the vision tokens, thus preserving or even improving performance compared to the vanilla model. We conduct extensive experiments to demonstrate the effectiveness of VideoLLM-MoD, showing its state-of-the-art results on multiple benchmarks, including narration, forecasting, and summarization tasks in COIN, Ego4D, and Ego-Exo4D datasets.","sentences":["A well-known dilemma in large vision-language models (e.g., GPT-4, LLaVA) is that while increasing the number of vision tokens generally enhances visual understanding, it also significantly raises memory and computational costs, especially in long-term, dense video frame streaming scenarios.","Although learnable approaches like Q-Former and Perceiver Resampler have been developed to reduce the vision token burden, they overlook the context causally modeled by LLMs (i.e., key-value cache), potentially leading to missed visual cues when addressing user queries.","In this paper, we introduce a novel approach to reduce vision compute by leveraging redundant vision tokens \"skipping layers\" rather than decreasing the number of vision tokens.","Our method, VideoLLM-MoD, is inspired by mixture-of-depths LLMs and addresses the challenge of numerous vision tokens in long-term or streaming video.","Specifically, for each transformer layer, we learn to skip the computation for a high proportion (e.g., 80\\%) of vision tokens, passing them directly to the next layer.","This approach significantly enhances model efficiency, achieving approximately \\textasciitilde42\\% time and \\textasciitilde30\\% memory savings for the entire training.","Moreover, our method reduces the computation in the context and avoid decreasing the vision tokens, thus preserving or even improving performance compared to the vanilla model.","We conduct extensive experiments to demonstrate the effectiveness of VideoLLM-MoD, showing its state-of-the-art results on multiple benchmarks, including narration, forecasting, and summarization tasks in COIN, Ego4D, and Ego-Exo4D datasets."],"url":"http://arxiv.org/abs/2408.16730v1"}
{"created":"2024-08-29 17:20:59","title":"Prediction-Feedback DETR for Temporal Action Detection","abstract":"Temporal Action Detection (TAD) is fundamental yet challenging for real-world video applications. Leveraging the unique benefits of transformers, various DETR-based approaches have been adopted in TAD. However, it has recently been identified that the attention collapse in self-attention causes the performance degradation of DETR for TAD. Building upon previous research, this paper newly addresses the attention collapse problem in cross-attention within DETR-based TAD methods. Moreover, our findings reveal that cross-attention exhibits patterns distinct from predictions, indicating a short-cut phenomenon. To resolve this, we propose a new framework, Prediction-Feedback DETR (Pred-DETR), which utilizes predictions to restore the collapse and align the cross- and self-attention with predictions. Specifically, we devise novel prediction-feedback objectives using guidance from the relations of the predictions. As a result, Pred-DETR significantly alleviates the collapse and achieves state-of-the-art performance among DETR-based methods on various challenging benchmarks including THUMOS14, ActivityNet-v1.3, HACS, and FineAction.","sentences":["Temporal Action Detection (TAD) is fundamental yet challenging for real-world video applications.","Leveraging the unique benefits of transformers, various DETR-based approaches have been adopted in TAD.","However, it has recently been identified that the attention collapse in self-attention causes the performance degradation of DETR for TAD.","Building upon previous research, this paper newly addresses the attention collapse problem in cross-attention within DETR-based TAD methods.","Moreover, our findings reveal that cross-attention exhibits patterns distinct from predictions, indicating a short-cut phenomenon.","To resolve this, we propose a new framework, Prediction-Feedback DETR (Pred-DETR), which utilizes predictions to restore the collapse and align the cross- and self-attention with predictions.","Specifically, we devise novel prediction-feedback objectives using guidance from the relations of the predictions.","As a result, Pred-DETR significantly alleviates the collapse and achieves state-of-the-art performance among DETR-based methods on various challenging benchmarks including THUMOS14, ActivityNet-v1.3, HACS, and FineAction."],"url":"http://arxiv.org/abs/2408.16729v1"}
{"created":"2024-08-29 17:18:57","title":"Bipedal locomotion using geometric techniques","abstract":"This article describes a bipedal walking algorithm with inverse kinematics resolution based solely on geometric methods, so that all mathematical concepts are explained from the base, in order to clarify the reason for this solution. To do so, it has been necessary to simplify the problem and carry out didactic work to distribute content. In general, the articles related to this topic use matrix systems to solve both direct and inverse kinematics, using complex techniques such as decoupling or the Jacobian calculation. By simplifying the walking process, its resolution has been proposed in a simple way using only geometric techniques.","sentences":["This article describes a bipedal walking algorithm with inverse kinematics resolution based solely on geometric methods, so that all mathematical concepts are explained from the base, in order to clarify the reason for this solution.","To do so, it has been necessary to simplify the problem and carry out didactic work to distribute content.","In general, the articles related to this topic use matrix systems to solve both direct and inverse kinematics, using complex techniques such as decoupling or the Jacobian calculation.","By simplifying the walking process, its resolution has been proposed in a simple way using only geometric techniques."],"url":"http://arxiv.org/abs/2408.16726v1"}
{"created":"2024-08-29 17:18:53","title":"Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming","abstract":"Recent advances in language models have achieved significant progress. GPT-4o, as a new milestone, has enabled real-time conversations with humans, demonstrating near-human natural fluency. Such human-computer interaction necessitates models with the capability to perform reasoning directly with the audio modality and generate output in streaming. However, this remains beyond the reach of current academic models, as they typically depend on extra TTS systems for speech synthesis, resulting in undesirable latency. This paper introduces the Mini-Omni, an audio-based end-to-end conversational model, capable of real-time speech interaction. To achieve this capability, we propose a text-instructed speech generation method, along with batch-parallel strategies during inference to further boost the performance. Our method also helps to retain the original model's language capabilities with minimal degradation, enabling other works to establish real-time interaction capabilities. We call this training method \"Any Model Can Talk\". We also introduce the VoiceAssistant-400K dataset to fine-tune models optimized for speech output. To our best knowledge, Mini-Omni is the first fully end-to-end, open-source model for real-time speech interaction, offering valuable potential for future research.","sentences":["Recent advances in language models have achieved significant progress.","GPT-4o, as a new milestone, has enabled real-time conversations with humans, demonstrating near-human natural fluency.","Such human-computer interaction necessitates models with the capability to perform reasoning directly with the audio modality and generate output in streaming.","However, this remains beyond the reach of current academic models, as they typically depend on extra TTS systems for speech synthesis, resulting in undesirable latency.","This paper introduces the Mini-Omni, an audio-based end-to-end conversational model, capable of real-time speech interaction.","To achieve this capability, we propose a text-instructed speech generation method, along with batch-parallel strategies during inference to further boost the performance.","Our method also helps to retain the original model's language capabilities with minimal degradation, enabling other works to establish real-time interaction capabilities.","We call this training method \"Any Model Can Talk\".","We also introduce the VoiceAssistant-400K dataset to fine-tune models optimized for speech output.","To our best knowledge, Mini-Omni is the first fully end-to-end, open-source model for real-time speech interaction, offering valuable potential for future research."],"url":"http://arxiv.org/abs/2408.16725v1"}
{"created":"2024-08-29 17:11:38","title":"H-SGANet: Hybrid Sparse Graph Attention Network for Deformable Medical Image Registration","abstract":"The integration of Convolutional Neural Network (ConvNet) and Transformer has emerged as a strong candidate for image registration, leveraging the strengths of both models and a large parameter space. However, this hybrid model, treating brain MRI volumes as grid or sequence structures, faces challenges in accurately representing anatomical connectivity, diverse brain regions, and vital connections contributing to the brain's internal architecture. Concerns also arise regarding the computational expense and GPU memory usage associated with this model. To tackle these issues, a lightweight hybrid sparse graph attention network (H-SGANet) has been developed. This network incorporates a central mechanism, Sparse Graph Attention (SGA), based on a Vision Graph Neural Network (ViG) with predetermined anatomical connections. The SGA module expands the model's receptive field and seamlessly integrates into the network. To further amplify the advantages of the hybrid network, the Separable Self-Attention (SSA) is employed as an enhanced token mixer, integrated with depth-wise convolution to constitute SSAFormer. This strategic integration is designed to more effectively extract long-range dependencies. As a hybrid ConvNet-ViG-Transformer model, H-SGANet offers threefold benefits for volumetric medical image registration. It optimizes fixed and moving images concurrently through a hybrid feature fusion layer and an end-to-end learning framework. Compared to VoxelMorph, a model with a similar parameter count, H-SGANet demonstrates significant performance enhancements of 3.5% and 1.5% in Dice score on the OASIS dataset and LPBA40 dataset, respectively.","sentences":["The integration of Convolutional Neural Network (ConvNet) and Transformer has emerged as a strong candidate for image registration, leveraging the strengths of both models and a large parameter space.","However, this hybrid model, treating brain MRI volumes as grid or sequence structures, faces challenges in accurately representing anatomical connectivity, diverse brain regions, and vital connections contributing to the brain's internal architecture.","Concerns also arise regarding the computational expense and GPU memory usage associated with this model.","To tackle these issues, a lightweight hybrid sparse graph attention network (H-SGANet) has been developed.","This network incorporates a central mechanism, Sparse Graph Attention (SGA), based on a Vision Graph Neural Network (ViG) with predetermined anatomical connections.","The SGA module expands the model's receptive field and seamlessly integrates into the network.","To further amplify the advantages of the hybrid network, the Separable Self-Attention (SSA) is employed as an enhanced token mixer, integrated with depth-wise convolution to constitute SSAFormer.","This strategic integration is designed to more effectively extract long-range dependencies.","As a hybrid ConvNet-ViG-Transformer model, H-SGANet offers threefold benefits for volumetric medical image registration.","It optimizes fixed and moving images concurrently through a hybrid feature fusion layer and an end-to-end learning framework.","Compared to VoxelMorph, a model with a similar parameter count, H-SGANet demonstrates significant performance enhancements of 3.5% and 1.5% in Dice score on the OASIS dataset and LPBA40 dataset, respectively."],"url":"http://arxiv.org/abs/2408.16719v1"}
{"created":"2024-08-29 17:07:43","title":"A GREAT Architecture for Edge-Based Graph Problems Like TSP","abstract":"In the last years, many neural network-based approaches have been proposed to tackle combinatorial optimization problems such as routing problems. Many of these approaches are based on graph neural networks (GNNs) or related transformers, operating on the Euclidean coordinates representing the routing problems. However, GNNs are inherently not well suited to operate on dense graphs, such as in routing problems. Furthermore, models operating on Euclidean coordinates cannot be applied to non-Euclidean versions of routing problems that are often found in real-world settings. To overcome these limitations, we propose a novel GNN-related edge-based neural model called Graph Edge Attention Network (GREAT). We evaluate the performance of GREAT in the edge-classification task to predict optimal edges in the Traveling Salesman Problem (TSP). We can use such a trained GREAT model to produce sparse TSP graph instances, keeping only the edges GREAT finds promising. Compared to other, non-learning-based methods to sparsify TSP graphs, GREAT can produce very sparse graphs while keeping most of the optimal edges. Furthermore, we build a reinforcement learning-based GREAT framework which we apply to Euclidean and non-Euclidean asymmetric TSP. This framework achieves state-of-the-art results.","sentences":["In the last years, many neural network-based approaches have been proposed to tackle combinatorial optimization problems such as routing problems.","Many of these approaches are based on graph neural networks (GNNs) or related transformers, operating on the Euclidean coordinates representing the routing problems.","However, GNNs are inherently not well suited to operate on dense graphs, such as in routing problems.","Furthermore, models operating on Euclidean coordinates cannot be applied to non-Euclidean versions of routing problems that are often found in real-world settings.","To overcome these limitations, we propose a novel GNN-related edge-based neural model called Graph Edge Attention Network (GREAT).","We evaluate the performance of GREAT in the edge-classification task to predict optimal edges in the Traveling Salesman Problem (TSP).","We can use such a trained GREAT model to produce sparse TSP graph instances, keeping only the edges GREAT finds promising.","Compared to other, non-learning-based methods to sparsify TSP graphs, GREAT can produce very sparse graphs while keeping most of the optimal edges.","Furthermore, we build a reinforcement learning-based GREAT framework which we apply to Euclidean and non-Euclidean asymmetric TSP.","This framework achieves state-of-the-art results."],"url":"http://arxiv.org/abs/2408.16717v1"}
{"created":"2024-08-29 17:06:20","title":"ARINC 429 Cyber-vulnerabilities and Voltage Data in a Hardware-in-the-Loop Simulator","abstract":"ARINC 429 is a ubiquitous data bus for civil avionics, enabling reliable communication between devices from disparate manufacturers. However, ARINC 429 lacks any form of encryption or authentication, making it an inherently insecure communication protocol and rendering any connected avionics vulnerable to a range of attacks. We constructed a hardware-in-the-loop simulator with ARINC 429 buses, explored these vulnerabilities, and identified their potential to deny, degrade, or disrupt aircraft capabilities. We performed a denial-of-service attack against a multi-function display via a compromised ARINC 429 bus using commercially available tools, which succeeded in disabling important navigational aids. This proven attack on physical avionics illustrates the risk inherent in ARINC 429 and the need for the ability to detect these attacks. One potential mitigation is an intrusion detection system (IDS) trained on data collected from the electrical properties of the physical bus. Although previous research has demonstrated the feasibility of an IDS on an ARINC 429 bus, no IDS has been trained on data generated by avionics hardware. To facilitate this, we recorded voltage traces and message history generated by avionics and adversarial devices on the ARINC 429 bus. To the best of our knowledge, this is the first publicly available collection of hardware-generated ARINC 429 signal data.","sentences":["ARINC 429 is a ubiquitous data bus for civil avionics, enabling reliable communication between devices from disparate manufacturers.","However, ARINC 429 lacks any form of encryption or authentication, making it an inherently insecure communication protocol and rendering any connected avionics vulnerable to a range of attacks.","We constructed a hardware-in-the-loop simulator with ARINC 429 buses, explored these vulnerabilities, and identified their potential to deny, degrade, or disrupt aircraft capabilities.","We performed a denial-of-service attack against a multi-function display via a compromised ARINC 429 bus using commercially available tools, which succeeded in disabling important navigational aids.","This proven attack on physical avionics illustrates the risk inherent in ARINC 429 and the need for the ability to detect these attacks.","One potential mitigation is an intrusion detection system (IDS) trained on data collected from the electrical properties of the physical bus.","Although previous research has demonstrated the feasibility of an IDS on an ARINC 429 bus, no IDS has been trained on data generated by avionics hardware.","To facilitate this, we recorded voltage traces and message history generated by avionics and adversarial devices on the ARINC 429 bus.","To the best of our knowledge, this is the first publicly available collection of hardware-generated ARINC 429 signal data."],"url":"http://arxiv.org/abs/2408.16714v1"}
{"created":"2024-08-29 17:05:10","title":"Hydrogen reaction rate modeling based on convolutional neural network for large eddy simulation","abstract":"This paper establishes a data-driven modeling framework for lean Hydrogen (H2)-air reaction rates for the Large Eddy Simulation (LES) of turbulent reactive flows. This is particularly challenging since H2 molecules diffuse much faster than heat, leading to large variations in burning rates, thermodiffusive instabilities at the subfilter scale, and complex turbulence-chemistry interactions. Our data-driven approach leverages a Convolutional Neural Network (CNN), trained to approximate filtered burning rates from emulated LES data. First, five different lean premixed turbulent H2-air flame Direct Numerical Simulations (DNSs) are computed each with a unique global equivalence ratio. Second, DNS snapshots are filtered and downsampled to emulate LES data. Third, a CNN is trained to approximate the filtered burning rates as a function of LES scalar quantities: progress variable, local equivalence ratio and flame thickening due to filtering. Finally, the performances of the CNN model are assessed on test solutions never seen during training. The model retrieves burning rates with very high accuracy. It is also tested on two filter and downsampling parameters and two global equivalence ratios between those used during training. For these interpolation cases, the model approximates burning rates with low error even though the cases were not included in the training dataset. This a priori study shows that the proposed data-driven machine learning framework is able to address the challenge of modeling lean premixed H2-air burning rates. It paves the way for a new modeling paradigm for the simulation of carbon-free hydrogen combustion systems.","sentences":["This paper establishes a data-driven modeling framework for lean Hydrogen (H2)-air reaction rates for the Large Eddy Simulation (LES) of turbulent reactive flows.","This is particularly challenging since H2 molecules diffuse much faster than heat, leading to large variations in burning rates, thermodiffusive instabilities at the subfilter scale, and complex turbulence-chemistry interactions.","Our data-driven approach leverages a Convolutional Neural Network (CNN), trained to approximate filtered burning rates from emulated LES data.","First, five different lean premixed turbulent H2-air flame Direct Numerical Simulations (DNSs) are computed each with a unique global equivalence ratio.","Second, DNS snapshots are filtered and downsampled to emulate LES data.","Third, a CNN is trained to approximate the filtered burning rates as a function of LES scalar quantities: progress variable, local equivalence ratio and flame thickening due to filtering.","Finally, the performances of the CNN model are assessed on test solutions never seen during training.","The model retrieves burning rates with very high accuracy.","It is also tested on two filter and downsampling parameters and two global equivalence ratios between those used during training.","For these interpolation cases, the model approximates burning rates with low error even though the cases were not included in the training dataset.","This a priori study shows that the proposed data-driven machine learning framework is able to address the challenge of modeling lean premixed H2-air burning rates.","It paves the way for a new modeling paradigm for the simulation of carbon-free hydrogen combustion systems."],"url":"http://arxiv.org/abs/2408.16709v1"}
{"created":"2024-08-29 17:00:47","title":"Enhanced forecasting of stock prices based on variational mode decomposition, PatchTST, and adaptive scale-weighted layer","abstract":"The significant fluctuations in stock index prices in recent years highlight the critical need for accurate forecasting to guide investment and financial strategies. This study introduces a novel composite forecasting framework that integrates variational mode decomposition (VMD), PatchTST, and adaptive scale-weighted layer (ASWL) to address these challenges. Utilizing datasets of four major stock indices--SP500, DJI, SSEC, and FTSE--from 2000 to 2024, the proposed method first decomposes the raw price series into intrinsic mode functions (IMFs) using VMD. Each IMF is then modeled with PatchTST to capture temporal patterns effectively. The ASWL module is applied to incorporate scale information, enhancing prediction accuracy. The final forecast is derived by aggregating predictions from all IMFs. The VMD-PatchTST-ASWL framework demonstrates significant improvements in forecasting accuracy compared to traditional models, showing robust performance across different indices. This innovative approach provides a powerful tool for stock index price forecasting, with potential applications in various financial analysis and investment decision-making contexts.","sentences":["The significant fluctuations in stock index prices in recent years highlight the critical need for accurate forecasting to guide investment and financial strategies.","This study introduces a novel composite forecasting framework that integrates variational mode decomposition (VMD), PatchTST, and adaptive scale-weighted layer (ASWL) to address these challenges.","Utilizing datasets of four major stock indices--SP500, DJI, SSEC, and FTSE--from 2000 to 2024, the proposed method first decomposes the raw price series into intrinsic mode functions (IMFs) using VMD.","Each IMF is then modeled with PatchTST to capture temporal patterns effectively.","The ASWL module is applied to incorporate scale information, enhancing prediction accuracy.","The final forecast is derived by aggregating predictions from all IMFs.","The VMD-PatchTST-ASWL framework demonstrates significant improvements in forecasting accuracy compared to traditional models, showing robust performance across different indices.","This innovative approach provides a powerful tool for stock index price forecasting, with potential applications in various financial analysis and investment decision-making contexts."],"url":"http://arxiv.org/abs/2408.16707v1"}
{"created":"2024-08-29 17:00:38","title":"Incremental Context-free Grammar Inference in Black Box Settings","abstract":"Black-box context-free grammar inference presents a significant challenge in many practical settings due to limited access to example programs. The state-of-the-art methods, Arvada and Treevada, employ heuristic approaches to generalize grammar rules, initiating from flat parse trees and exploring diverse generalization sequences. We have observed that these approaches suffer from low quality and readability, primarily because they process entire example strings, adding to the complexity and substantially slowing down computations. To overcome these limitations, we propose a novel method that segments example strings into smaller units and incrementally infers the grammar. Our approach, named Kedavra, has demonstrated superior grammar quality (enhanced precision and recall), faster runtime, and improved readability through empirical comparison.","sentences":["Black-box context-free grammar inference presents a significant challenge in many practical settings due to limited access to example programs.","The state-of-the-art methods, Arvada and Treevada, employ heuristic approaches to generalize grammar rules, initiating from flat parse trees and exploring diverse generalization sequences.","We have observed that these approaches suffer from low quality and readability, primarily because they process entire example strings, adding to the complexity and substantially slowing down computations.","To overcome these limitations, we propose a novel method that segments example strings into smaller units and incrementally infers the grammar.","Our approach, named Kedavra, has demonstrated superior grammar quality (enhanced precision and recall), faster runtime, and improved readability through empirical comparison."],"url":"http://arxiv.org/abs/2408.16706v1"}
{"created":"2024-08-29 16:58:10","title":"One-Shot Learning Meets Depth Diffusion in Multi-Object Videos","abstract":"Creating editable videos that depict complex interactions between multiple objects in various artistic styles has long been a challenging task in filmmaking. Progress is often hampered by the scarcity of data sets that contain paired text descriptions and corresponding videos that showcase these interactions. This paper introduces a novel depth-conditioning approach that significantly advances this field by enabling the generation of coherent and diverse videos from just a single text-video pair using a pre-trained depth-aware Text-to-Image (T2I) model. Our method fine-tunes the pre-trained model to capture continuous motion by employing custom-designed spatial and temporal attention mechanisms. During inference, we use the DDIM inversion to provide structural guidance for video generation. This innovative technique allows for continuously controllable depth in videos, facilitating the generation of multiobject interactions while maintaining the concept generation and compositional strengths of the original T2I model across various artistic styles, such as photorealism, animation, and impressionism.","sentences":["Creating editable videos that depict complex interactions between multiple objects in various artistic styles has long been a challenging task in filmmaking.","Progress is often hampered by the scarcity of data sets that contain paired text descriptions and corresponding videos that showcase these interactions.","This paper introduces a novel depth-conditioning approach that significantly advances this field by enabling the generation of coherent and diverse videos from just a single text-video pair using a pre-trained depth-aware Text-to-Image (T2I) model.","Our method fine-tunes the pre-trained model to capture continuous motion by employing custom-designed spatial and temporal attention mechanisms.","During inference, we use the DDIM inversion to provide structural guidance for video generation.","This innovative technique allows for continuously controllable depth in videos, facilitating the generation of multiobject interactions while maintaining the concept generation and compositional strengths of the original T2I model across various artistic styles, such as photorealism, animation, and impressionism."],"url":"http://arxiv.org/abs/2408.16704v1"}
{"created":"2024-08-29 16:56:40","title":"RoboMNIST: A Multimodal Dataset for Multi-Robot Activity Recognition Using WiFi Sensing, Video, and Audio","abstract":"We introduce a novel dataset for multi-robot activity recognition (MRAR) using two robotic arms integrating WiFi channel state information (CSI), video, and audio data. This multimodal dataset utilizes signals of opportunity, leveraging existing WiFi infrastructure to provide detailed indoor environmental sensing without additional sensor deployment. Data were collected using two Franka Emika robotic arms, complemented by three cameras, three WiFi sniffers to collect CSI, and three microphones capturing distinct yet complementary audio data streams. The combination of CSI, visual, and auditory data can enhance robustness and accuracy in MRAR. This comprehensive dataset enables a holistic understanding of robotic environments, facilitating advanced autonomous operations that mimic human-like perception and interaction. By repurposing ubiquitous WiFi signals for environmental sensing, this dataset offers significant potential aiming to advance robotic perception and autonomous systems. It provides a valuable resource for developing sophisticated decision-making and adaptive capabilities in dynamic environments.","sentences":["We introduce a novel dataset for multi-robot activity recognition (MRAR) using two robotic arms integrating WiFi channel state information (CSI), video, and audio data.","This multimodal dataset utilizes signals of opportunity, leveraging existing WiFi infrastructure to provide detailed indoor environmental sensing without additional sensor deployment.","Data were collected using two Franka Emika robotic arms, complemented by three cameras, three WiFi sniffers to collect CSI, and three microphones capturing distinct yet complementary audio data streams.","The combination of CSI, visual, and auditory data can enhance robustness and accuracy in MRAR.","This comprehensive dataset enables a holistic understanding of robotic environments, facilitating advanced autonomous operations that mimic human-like perception and interaction.","By repurposing ubiquitous WiFi signals for environmental sensing, this dataset offers significant potential aiming to advance robotic perception and autonomous systems.","It provides a valuable resource for developing sophisticated decision-making and adaptive capabilities in dynamic environments."],"url":"http://arxiv.org/abs/2408.16703v1"}
{"created":"2024-08-29 16:56:35","title":"VMC: A Grammar for Visualizing Statistical Model Checks","abstract":"Visualizations play a critical role in validating and improving statistical models. However, the design space of model check visualizations is not well understood, making it difficult for authors to explore and specify effective graphical model checks. VMC defines a model check visualization using four components: (1) samples of distributions of checkable quantities generated from the model, including predictive distributions for new data and distributions of model parameters; (2) transformations on observed data to facilitate comparison; (3) visual representations of distributions; and (4) layouts to facilitate comparing model samples and observed data. We contribute an implementation of VMC as an R package. We validate VMC by reproducing a set of canonical model check examples, and show how using VMC to generate model checks reduces the edit distance between visualizations relative to existing visualization toolkits. The findings of an interview study with three expert modelers who used VMC highlight challenges and opportunities for encouraging exploration of correct, effective model check visualizations.","sentences":["Visualizations play a critical role in validating and improving statistical models.","However, the design space of model check visualizations is not well understood, making it difficult for authors to explore and specify effective graphical model checks.","VMC defines a model check visualization using four components: (1) samples of distributions of checkable quantities generated from the model, including predictive distributions for new data and distributions of model parameters; (2) transformations on observed data to facilitate comparison; (3) visual representations of distributions; and (4) layouts to facilitate comparing model samples and observed data.","We contribute an implementation of VMC as an R package.","We validate VMC by reproducing a set of canonical model check examples, and show how using VMC to generate model checks reduces the edit distance between visualizations relative to existing visualization toolkits.","The findings of an interview study with three expert modelers who used VMC highlight challenges and opportunities for encouraging exploration of correct, effective model check visualizations."],"url":"http://arxiv.org/abs/2408.16702v1"}
{"created":"2024-08-29 16:51:07","title":"GradBias: Unveiling Word Influence on Bias in Text-to-Image Generative Models","abstract":"Recent progress in Text-to-Image (T2I) generative models has enabled high-quality image generation. As performance and accessibility increase, these models are gaining significant attraction and popularity: ensuring their fairness and safety is a priority to prevent the dissemination and perpetuation of biases. However, existing studies in bias detection focus on closed sets of predefined biases (e.g., gender, ethnicity). In this paper, we propose a general framework to identify, quantify, and explain biases in an open set setting, i.e. without requiring a predefined set. This pipeline leverages a Large Language Model (LLM) to propose biases starting from a set of captions. Next, these captions are used by the target generative model for generating a set of images. Finally, Vision Question Answering (VQA) is leveraged for bias evaluation. We show two variations of this framework: OpenBias and GradBias. OpenBias detects and quantifies biases, while GradBias determines the contribution of individual prompt words on biases. OpenBias effectively detects both well-known and novel biases related to people, objects, and animals and highly aligns with existing closed-set bias detection methods and human judgment. GradBias shows that neutral words can significantly influence biases and it outperforms several baselines, including state-of-the-art foundation models. Code available here: https://github.com/Moreno98/GradBias.","sentences":["Recent progress in Text-to-Image (T2I) generative models has enabled high-quality image generation.","As performance and accessibility increase, these models are gaining significant attraction and popularity: ensuring their fairness and safety is a priority to prevent the dissemination and perpetuation of biases.","However, existing studies in bias detection focus on closed sets of predefined biases (e.g., gender, ethnicity).","In this paper, we propose a general framework to identify, quantify, and explain biases in an open set setting, i.e. without requiring a predefined set.","This pipeline leverages a Large Language Model (LLM) to propose biases starting from a set of captions.","Next, these captions are used by the target generative model for generating a set of images.","Finally, Vision Question Answering (VQA) is leveraged for bias evaluation.","We show two variations of this framework: OpenBias and GradBias.","OpenBias detects and quantifies biases, while GradBias determines the contribution of individual prompt words on biases.","OpenBias effectively detects both well-known and novel biases related to people, objects, and animals and highly aligns with existing closed-set bias detection methods and human judgment.","GradBias shows that neutral words can significantly influence biases and it outperforms several baselines, including state-of-the-art foundation models.","Code available here: https://github.com/Moreno98/GradBias."],"url":"http://arxiv.org/abs/2408.16700v1"}
{"created":"2024-08-29 16:48:03","title":"To Be or Not To Be: Adding Integrity Constraints to stableKanren to Make a Decision","abstract":"We integrate integrity constraints to stableKanren to enable a new problem-solving paradigm in combinatorial search problems. stableKanren extends miniKanren to reasoning about contradictions under stable model semantics. However, writing programs to solve combinatorial search problems in stableKanren did not fully utilize the contradiction reasoning. This is mainly due to the lack of control over the predicate (goal function) outcome during resolution. Integrity constraints defined by answer set programming (ASP) provide the ability to constrain the predicate outcome. However, integrity constraints are headless normal clauses, and stableKanren cannot create a goal function without a valid head. There are two approaches to handling integrity constraints, but they do not fit stableKanren. Therefore, we design a new approach to integrate integrity constraints into stableKanren. We show a uniform framework to solve combinatorial search problems using integrity constraints in extended stableKanren.","sentences":["We integrate integrity constraints to stableKanren to enable a new problem-solving paradigm in combinatorial search problems.","stableKanren extends miniKanren to reasoning about contradictions under stable model semantics.","However, writing programs to solve combinatorial search problems in stableKanren did not fully utilize the contradiction reasoning.","This is mainly due to the lack of control over the predicate (goal function) outcome during resolution.","Integrity constraints defined by answer set programming (ASP) provide the ability to constrain the predicate outcome.","However, integrity constraints are headless normal clauses, and stableKanren cannot create a goal function without a valid head.","There are two approaches to handling integrity constraints, but they do not fit stableKanren.","Therefore, we design a new approach to integrate integrity constraints into stableKanren.","We show a uniform framework to solve combinatorial search problems using integrity constraints in extended stableKanren."],"url":"http://arxiv.org/abs/2408.16699v1"}
{"created":"2024-08-29 16:47:58","title":"SympGNNs: Symplectic Graph Neural Networks for identifiying high-dimensional Hamiltonian systems and node classification","abstract":"Existing neural network models to learn Hamiltonian systems, such as SympNets, although accurate in low-dimensions, struggle to learn the correct dynamics for high-dimensional many-body systems. Herein, we introduce Symplectic Graph Neural Networks (SympGNNs) that can effectively handle system identification in high-dimensional Hamiltonian systems, as well as node classification. SympGNNs combines symplectic maps with permutation equivariance, a property of graph neural networks. Specifically, we propose two variants of SympGNNs: i) G-SympGNN and ii) LA-SympGNN, arising from different parameterizations of the kinetic and potential energy. We demonstrate the capabilities of SympGNN on two physical examples: a 40-particle coupled Harmonic oscillator, and a 2000-particle molecular dynamics simulation in a two-dimensional Lennard-Jones potential. Furthermore, we demonstrate the performance of SympGNN in the node classification task, achieving accuracy comparable to the state-of-the-art. We also empirically show that SympGNN can overcome the oversmoothing and heterophily problems, two key challenges in the field of graph neural networks.","sentences":["Existing neural network models to learn Hamiltonian systems, such as SympNets, although accurate in low-dimensions, struggle to learn the correct dynamics for high-dimensional many-body systems.","Herein, we introduce Symplectic Graph Neural Networks (SympGNNs) that can effectively handle system identification in high-dimensional Hamiltonian systems, as well as node classification.","SympGNNs combines symplectic maps with permutation equivariance, a property of graph neural networks.","Specifically, we propose two variants of SympGNNs: i) G-SympGNN and ii) LA-SympGNN, arising from different parameterizations of the kinetic and potential energy.","We demonstrate the capabilities of SympGNN on two physical examples: a 40-particle coupled Harmonic oscillator, and a 2000-particle molecular dynamics simulation in a two-dimensional Lennard-Jones potential.","Furthermore, we demonstrate the performance of SympGNN in the node classification task, achieving accuracy comparable to the state-of-the-art.","We also empirically show that SympGNN can overcome the oversmoothing and heterophily problems, two key challenges in the field of graph neural networks."],"url":"http://arxiv.org/abs/2408.16698v1"}
{"created":"2024-08-29 16:40:29","title":"Fast and Simple $(1+\u03b5)\u0394$-Edge-Coloring of Dense Graphs","abstract":"Let $\\epsilon \\in (0, 1)$ and $n, \\Delta \\in \\mathbb N$ be such that $\\Delta = \\Omega\\left(\\max\\left\\{\\frac{\\log n}{\\epsilon},\\, \\left(\\frac{1}{\\epsilon}\\log \\frac{1}{\\epsilon}\\right)^2\\right\\}\\right)$. Given an $n$-vertex $m$-edge simple graph $G$ of maximum degree $\\Delta$, we present a randomized $O\\left(m\\,\\log^3 \\Delta\\,/\\,\\epsilon^2\\right)$-time algorithm that computes a proper $(1+\\epsilon)\\Delta$-edge-coloring of $G$ with high probability. This improves upon the best known results for a wide range of the parameters $\\epsilon$, $n$, and $\\Delta$. Our approach combines a flagging strategy from earlier work of the author with a shifting procedure employed by Duan, He, and Zhang for dynamic edge-coloring. The resulting algorithm is simple to implement and may be of practical interest.","sentences":["Let $\\epsilon \\in (0, 1)$ and $n, \\Delta \\in \\mathbb N$ be such that $\\Delta = \\Omega\\left(\\max\\left\\{\\frac{\\log n}{\\epsilon},\\, \\left(\\frac{1}{\\epsilon}\\log \\frac{1}{\\epsilon}\\right)^2\\right\\}\\right)$. Given an $n$-vertex $m$-edge simple graph $G$ of maximum degree $\\Delta$, we present a randomized $O\\left(m\\,\\log^3 \\Delta\\,/\\,\\epsilon^2\\right)$-time algorithm that computes a proper $(1+\\epsilon)\\Delta$-edge-coloring of $G$ with high probability.","This improves upon the best known results for a wide range of the parameters $\\epsilon$, $n$, and $\\Delta$. Our approach combines a flagging strategy from earlier work of the author with a shifting procedure employed by Duan, He, and Zhang for dynamic edge-coloring.","The resulting algorithm is simple to implement and may be of practical interest."],"url":"http://arxiv.org/abs/2408.16692v1"}
{"created":"2024-08-29 16:37:58","title":"Generic Objects as Pose Probes for Few-Shot View Synthesis","abstract":"Radiance fields including NeRFs and 3D Gaussians demonstrate great potential in high-fidelity rendering and scene reconstruction, while they require a substantial number of posed images as inputs. COLMAP is frequently employed for preprocessing to estimate poses, while it necessitates a large number of feature matches to operate effectively, and it struggles with scenes characterized by sparse features, large baselines between images, or a limited number of input images. We aim to tackle few-view NeRF reconstruction using only 3 to 6 unposed scene images. Traditional methods often use calibration boards but they are not common in images. We propose a novel idea of utilizing everyday objects, commonly found in both images and real life, as \"pose probes\". The probe object is automatically segmented by SAM, whose shape is initialized from a cube. We apply a dual-branch volume rendering optimization (object NeRF and scene NeRF) to constrain the pose optimization and jointly refine the geometry. Specifically, object poses of two views are first estimated by PnP matching in an SDF representation, which serves as initial poses. PnP matching, requiring only a few features, is suitable for feature-sparse scenes. Additional views are incrementally incorporated to refine poses from preceding views. In experiments, PoseProbe achieves state-of-the-art performance in both pose estimation and novel view synthesis across multiple datasets. We demonstrate its effectiveness, particularly in few-view and large-baseline scenes where COLMAP struggles. In ablations, using different objects in a scene yields comparable performance.","sentences":["Radiance fields including NeRFs and 3D Gaussians demonstrate great potential in high-fidelity rendering and scene reconstruction, while they require a substantial number of posed images as inputs.","COLMAP is frequently employed for preprocessing to estimate poses, while it necessitates a large number of feature matches to operate effectively, and it struggles with scenes characterized by sparse features, large baselines between images, or a limited number of input images.","We aim to tackle few-view NeRF reconstruction using only 3 to 6 unposed scene images.","Traditional methods often use calibration boards but they are not common in images.","We propose a novel idea of utilizing everyday objects, commonly found in both images and real life, as \"pose probes\".","The probe object is automatically segmented by SAM, whose shape is initialized from a cube.","We apply a dual-branch volume rendering optimization (object NeRF and scene NeRF) to constrain the pose optimization and jointly refine the geometry.","Specifically, object poses of two views are first estimated by PnP matching in an SDF representation, which serves as initial poses.","PnP matching, requiring only a few features, is suitable for feature-sparse scenes.","Additional views are incrementally incorporated to refine poses from preceding views.","In experiments, PoseProbe achieves state-of-the-art performance in both pose estimation and novel view synthesis across multiple datasets.","We demonstrate its effectiveness, particularly in few-view and large-baseline scenes where COLMAP struggles.","In ablations, using different objects in a scene yields comparable performance."],"url":"http://arxiv.org/abs/2408.16690v1"}
{"created":"2024-08-29 16:35:06","title":"Hypercontractivity on HDX II: Symmetrization and q-Norms","abstract":"Bourgain's symmetrization theorem is a powerful technique reducing boolean analysis on product spaces to the cube. It states that for any product $\\Omega_i^{\\otimes d}$, function $f: \\Omega_i^{\\otimes d} \\to \\mathbb{R}$, and $q > 1$:   $$||T_{\\frac{1}{2}}f(x)||_q \\leq ||\\tilde{f}(r,x)||_{q} \\leq ||T_{c_q}f(x)||_q$$ where $T_{\\rho}f = \\sum\\limits \\rho^Sf^{=S}$ is the noise operator and $\\widetilde{f}(r,x) = \\sum\\limits r_Sf^{=S}(x)$ `symmetrizes' $f$ by convolving its Fourier components $\\{f^{=S}\\}_{S \\subseteq [d]}$ with a random boolean string $r \\in \\{\\pm 1\\}^d$.   In this work, we extend the symmetrization theorem to high dimensional expanders (HDX). Adapting work of O'Donnell and Zhao (2021), we give as a corollary a proof of optimal global hypercontractivity for partite HDX, resolving one of the main open questions of Gur, Lifshitz, and Liu (STOC 2022). Adapting work of Bourgain (JAMS 1999), we also give the first booster theorem for HDX, resolving a main open questions of Bafna, Hopkins, Kaufman, and Lovett (STOC 2022).   Our proof is based on two elementary new ideas in the theory of high dimensional expansion. First we introduce `$q$-norm HDX', generalizing standard spectral notions to higher moments, and observe every spectral HDX is a $q$-norm HDX. Second, we introduce a simple method of coordinate-wise analysis on HDX which breaks high dimensional random walks into coordinate-wise components, and allows each component to be analyzed as a $1$-dimensional operator locally within $X$. This allows for application of standard tricks such as the replacement method, greatly simplifying prior analytic techniques.","sentences":["Bourgain's symmetrization theorem is a powerful technique reducing boolean analysis on product spaces to the cube.","It states that for any product $\\Omega_i^{\\otimes d}$, function $f: \\Omega_i^{\\otimes d} \\to \\mathbb{R}$, and $q > 1$:   $$||T_{\\frac{1}{2}}f(x)||_q \\leq ||\\tilde{f}(r,x)||_{q} \\leq ||T_{c_q}f(x)||_q$$ where $T_{\\rho}f = \\sum\\limits \\rho^Sf^{=S}$ is the noise operator and $\\widetilde{f}(r,x) = \\sum\\limits r_Sf^{=S}(x)$ `symmetrizes' $f$ by convolving its Fourier components $\\{f^{=S}\\}_{S","\\subseteq","[d]}$ with a random boolean string $r \\in \\{\\pm 1\\}^d$.   In this work, we extend the symmetrization theorem to high dimensional expanders (HDX).","Adapting work of O'Donnell and Zhao (2021), we give as a corollary a proof of optimal global hypercontractivity for partite HDX, resolving one of the main open questions of Gur, Lifshitz, and Liu (STOC 2022).","Adapting work of Bourgain (JAMS 1999), we also give the first booster theorem for HDX, resolving a main open questions of Bafna, Hopkins, Kaufman, and Lovett (STOC 2022).   ","Our proof is based on two elementary new ideas in the theory of high dimensional expansion.","First we introduce `$q$-norm HDX', generalizing standard spectral notions to higher moments, and observe every spectral HDX is a $q$-norm HDX.","Second, we introduce a simple method of coordinate-wise analysis on HDX which breaks high dimensional random walks into coordinate-wise components, and allows each component to be analyzed as a $1$-dimensional operator locally within $X$. This allows for application of standard tricks such as the replacement method, greatly simplifying prior analytic techniques."],"url":"http://arxiv.org/abs/2408.16687v1"}
{"created":"2024-08-29 16:32:24","title":"CW-CNN & CW-AN: Convolutional Networks and Attention Networks for CW-Complexes","abstract":"We present a novel framework for learning on CW-complex structured data points. Recent advances have discussed CW-complexes as ideal learning representations for problems in cheminformatics. However, there is a lack of available machine learning methods suitable for learning on CW-complexes. In this paper we develop notions of convolution and attention that are well defined for CW-complexes. These notions enable us to create the first neural network that can receive a CW-complex as input. We illustrate and interpret this framework in the context of supervised prediction.","sentences":["We present a novel framework for learning on CW-complex structured data points.","Recent advances have discussed CW-complexes as ideal learning representations for problems in cheminformatics.","However, there is a lack of available machine learning methods suitable for learning on CW-complexes.","In this paper we develop notions of convolution and attention that are well defined for CW-complexes.","These notions enable us to create the first neural network that can receive a CW-complex as input.","We illustrate and interpret this framework in the context of supervised prediction."],"url":"http://arxiv.org/abs/2408.16686v1"}
{"created":"2024-08-29 16:31:05","title":"PartFormer: Awakening Latent Diverse Representation from Vision Transformer for Object Re-Identification","abstract":"Extracting robust feature representation is critical for object re-identification to accurately identify objects across non-overlapping cameras. Although having a strong representation ability, the Vision Transformer (ViT) tends to overfit on most distinct regions of training data, limiting its generalizability and attention to holistic object features. Meanwhile, due to the structural difference between CNN and ViT, fine-grained strategies that effectively address this issue in CNN do not continue to be successful in ViT. To address this issue, by observing the latent diverse representation hidden behind the multi-head attention, we present PartFormer, an innovative adaptation of ViT designed to overcome the granularity limitations in object Re-ID tasks. The PartFormer integrates a Head Disentangling Block (HDB) that awakens the diverse representation of multi-head self-attention without the typical loss of feature richness induced by concatenation and FFN layers post-attention. To avoid the homogenization of attention heads and promote robust part-based feature learning, two head diversity constraints are imposed: attention diversity constraint and correlation diversity constraint. These constraints enable the model to exploit diverse and discriminative feature representations from different attention heads. Comprehensive experiments on various object Re-ID benchmarks demonstrate the superiority of the PartFormer. Specifically, our framework significantly outperforms state-of-the-art by 2.4\\% mAP scores on the most challenging MSMT17 dataset.","sentences":["Extracting robust feature representation is critical for object re-identification to accurately identify objects across non-overlapping cameras.","Although having a strong representation ability, the Vision Transformer (ViT) tends to overfit on most distinct regions of training data, limiting its generalizability and attention to holistic object features.","Meanwhile, due to the structural difference between CNN and ViT, fine-grained strategies that effectively address this issue in CNN do not continue to be successful in ViT. To address this issue, by observing the latent diverse representation hidden behind the multi-head attention, we present PartFormer, an innovative adaptation of ViT designed to overcome the granularity limitations in object Re-ID tasks.","The PartFormer integrates a Head Disentangling Block (HDB) that awakens the diverse representation of multi-head self-attention without the typical loss of feature richness induced by concatenation and FFN layers post-attention.","To avoid the homogenization of attention heads and promote robust part-based feature learning, two head diversity constraints are imposed: attention diversity constraint and correlation diversity constraint.","These constraints enable the model to exploit diverse and discriminative feature representations from different attention heads.","Comprehensive experiments on various object Re-ID benchmarks demonstrate the superiority of the PartFormer.","Specifically, our framework significantly outperforms state-of-the-art by 2.4\\% mAP scores on the most challenging MSMT17 dataset."],"url":"http://arxiv.org/abs/2408.16684v1"}
{"created":"2024-08-29 16:28:43","title":"A Catalog of Fairness-Aware Practices in Machine Learning Engineering","abstract":"Machine learning's widespread adoption in decision-making processes raises concerns about fairness, particularly regarding the treatment of sensitive features and potential discrimination against minorities. The software engineering community has responded by developing fairness-oriented metrics, empirical studies, and approaches. However, there remains a gap in understanding and categorizing practices for engineering fairness throughout the machine learning lifecycle. This paper presents a novel catalog of practices for addressing fairness in machine learning derived from a systematic mapping study. The study identifies and categorizes 28 practices from existing literature, mapping them onto different stages of the machine learning lifecycle. From this catalog, the authors extract actionable items and implications for both researchers and practitioners in software engineering. This work aims to provide a comprehensive resource for integrating fairness considerations into the development and deployment of machine learning systems, enhancing their reliability, accountability, and credibility.","sentences":["Machine learning's widespread adoption in decision-making processes raises concerns about fairness, particularly regarding the treatment of sensitive features and potential discrimination against minorities.","The software engineering community has responded by developing fairness-oriented metrics, empirical studies, and approaches.","However, there remains a gap in understanding and categorizing practices for engineering fairness throughout the machine learning lifecycle.","This paper presents a novel catalog of practices for addressing fairness in machine learning derived from a systematic mapping study.","The study identifies and categorizes 28 practices from existing literature, mapping them onto different stages of the machine learning lifecycle.","From this catalog, the authors extract actionable items and implications for both researchers and practitioners in software engineering.","This work aims to provide a comprehensive resource for integrating fairness considerations into the development and deployment of machine learning systems, enhancing their reliability, accountability, and credibility."],"url":"http://arxiv.org/abs/2408.16683v1"}
{"created":"2024-08-29 16:21:00","title":"Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever","abstract":"Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval. ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search. In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data. Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models.","sentences":["Multi-vector dense models, such as ColBERT, have proven highly effective in information retrieval.","ColBERT's late interaction scoring approximates the joint query-document attention seen in cross-encoders while maintaining inference efficiency closer to traditional dense retrieval models, thanks to its bi-encoder architecture and recent optimizations in indexing and search.","In this paper, we introduce several improvements to the ColBERT model architecture and training pipeline, leveraging techniques successful in the more established single-vector embedding model paradigm, particularly those suited for heterogeneous multilingual data.","Our new model, Jina-ColBERT-v2, demonstrates strong performance across a range of English and multilingual retrieval tasks, while also cutting storage requirements by up to 50% compared to previous models."],"url":"http://arxiv.org/abs/2408.16672v1"}
{"created":"2024-08-29 16:21:00","title":"Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity","abstract":"Large language models rely on Supervised Fine-Tuning (SFT) to specialize in downstream tasks. Cross Entropy (CE) loss is the de facto choice in SFT, but it often leads to overfitting and limited output diversity due to its aggressive updates to the data distribution. This paper aim to address these issues by introducing the maximum entropy principle, which favors models with flatter distributions that still effectively capture the data. Specifically, we develop a new distribution matching method called GEM, which solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.   For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects. First, when applied to the UltraFeedback dataset to develop general instruction-following abilities, GEM exhibits reduced overfitting, evidenced by lower perplexity and better performance on the IFEval benchmark. Furthermore, GEM enhances output diversity, leading to performance gains of up to 7 points on math reasoning and code generation tasks using best-of-n sampling, even without domain-specific data. Second, when fine-tuning with domain-specific datasets for math reasoning and code generation, GEM also shows less overfitting and improvements of up to 10 points compared with CE.","sentences":["Large language models rely on Supervised Fine-Tuning (SFT) to specialize in downstream tasks.","Cross Entropy (CE) loss is the de facto choice in SFT, but it often leads to overfitting and limited output diversity due to its aggressive updates to the data distribution.","This paper aim to address these issues by introducing the maximum entropy principle, which favors models with flatter distributions that still effectively capture the data.","Specifically, we develop a new distribution matching method called GEM, which solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.   ","For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects.","First, when applied to the UltraFeedback dataset to develop general instruction-following abilities, GEM exhibits reduced overfitting, evidenced by lower perplexity and better performance on the IFEval benchmark.","Furthermore, GEM enhances output diversity, leading to performance gains of up to 7 points on math reasoning and code generation tasks using best-of-n sampling, even without domain-specific data.","Second, when fine-tuning with domain-specific datasets for math reasoning and code generation, GEM also shows less overfitting and improvements of up to 10 points compared with CE."],"url":"http://arxiv.org/abs/2408.16673v1"}
{"created":"2024-08-29 16:15:01","title":"Iterative Graph Alignment","abstract":"By compressing diverse narratives, LLMs go beyond memorization, achieving intelligence by capturing generalizable causal relationships. However, they suffer from local 'representation gaps' due to insufficient training data diversity, limiting their real-world utility, especially in tasks requiring strict alignment to rules. Traditional alignment methods relying on heavy human annotations are inefficient and unscalable. Recent self-alignment techniques also fall short, as they often depend on self-selection based prompting and memorization-based learning. To address these issues, we introduce Iterative Graph Alignment (IGA), an annotation-free rule-based alignment algorithm. A teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical graphs and reference answers. The student model (LLM) identifies local knowledge gaps by attempting to align its responses with these references, collaborating with helper models to generate diverse answers. These aligned responses are then used for iterative supervised fine-tuning (SFT). Our evaluations across five rule-based scenarios demonstrate IGP's effectiveness, with a 73.12\\% alignment improvement in Claude Sonnet 3.5, and Llama3-8B-Instruct achieving an 86.20\\% improvement, outperforming Claude Sonnet 3.5 in rule-based alignment.","sentences":["By compressing diverse narratives, LLMs go beyond memorization, achieving intelligence by capturing generalizable causal relationships.","However, they suffer from local 'representation gaps' due to insufficient training data diversity, limiting their real-world utility, especially in tasks requiring strict alignment to rules.","Traditional alignment methods relying on heavy human annotations are inefficient and unscalable.","Recent self-alignment techniques also fall short, as they often depend on self-selection based prompting and memorization-based learning.","To address these issues, we introduce Iterative Graph Alignment (IGA), an annotation-free rule-based alignment algorithm.","A teacher model (VLM) employs Iterative Graph Prompting (IGP) to create logical graphs and reference answers.","The student model (LLM) identifies local knowledge gaps by attempting to align its responses with these references, collaborating with helper models to generate diverse answers.","These aligned responses are then used for iterative supervised fine-tuning (SFT).","Our evaluations across five rule-based scenarios demonstrate IGP's effectiveness, with a 73.12\\% alignment improvement in Claude Sonnet 3.5, and Llama3-8B-Instruct achieving an 86.20\\% improvement, outperforming Claude Sonnet 3.5 in rule-based alignment."],"url":"http://arxiv.org/abs/2408.16667v1"}
{"created":"2024-08-29 16:05:22","title":"Space3D-Bench: Spatial 3D Question Answering Benchmark","abstract":"Answering questions about the spatial properties of the environment poses challenges for existing language and vision foundation models due to a lack of understanding of the 3D world notably in terms of relationships between objects. To push the field forward, multiple 3D Q&A datasets were proposed which, overall, provide a variety of questions, but they individually focus on particular aspects of 3D reasoning or are limited in terms of data modalities. To address this, we present Space3D-Bench - a collection of 1000 general spatial questions and answers related to scenes of the Replica dataset which offers a variety of data modalities: point clouds, posed RGB-D images, navigation meshes and 3D object detections. To ensure that the questions cover a wide range of 3D objectives, we propose an indoor spatial questions taxonomy inspired by geographic information systems and use it to balance the dataset accordingly. Moreover, we provide an assessment system that grades natural language responses based on predefined ground-truth answers by leveraging a Vision Language Model's comprehension of both text and images to compare the responses with ground-truth textual information or relevant visual data. Finally, we introduce a baseline called RAG3D-Chat integrating the world understanding of foundation models with rich context retrieval, achieving an accuracy of 67% on the proposed dataset.","sentences":["Answering questions about the spatial properties of the environment poses challenges for existing language and vision foundation models due to a lack of understanding of the 3D world notably in terms of relationships between objects.","To push the field forward, multiple 3D Q&A datasets were proposed which, overall, provide a variety of questions, but they individually focus on particular aspects of 3D reasoning or are limited in terms of data modalities.","To address this, we present Space3D-Bench - a collection of 1000 general spatial questions and answers related to scenes of the Replica dataset which offers a variety of data modalities: point clouds, posed RGB-D images, navigation meshes and 3D object detections.","To ensure that the questions cover a wide range of 3D objectives, we propose an indoor spatial questions taxonomy inspired by geographic information systems and use it to balance the dataset accordingly.","Moreover, we provide an assessment system that grades natural language responses based on predefined ground-truth answers by leveraging a Vision Language Model's comprehension of both text and images to compare the responses with ground-truth textual information or relevant visual data.","Finally, we introduce a baseline called RAG3D-Chat integrating the world understanding of foundation models with rich context retrieval, achieving an accuracy of 67% on the proposed dataset."],"url":"http://arxiv.org/abs/2408.16662v1"}
{"created":"2024-08-29 16:05:05","title":"Eigen-Cluster VIS: Improving Weakly-supervised Video Instance Segmentation by Leveraging Spatio-temporal Consistency","abstract":"The performance of Video Instance Segmentation (VIS) methods has improved significantly with the advent of transformer networks. However, these networks often face challenges in training due to the high annotation cost. To address this, unsupervised and weakly-supervised methods have been developed to reduce the dependency on annotations. This work introduces a novel weakly-supervised method called Eigen-cluster VIS that, without requiring any mask annotations, achieves competitive accuracy compared to other VIS approaches. This method is based on two key innovations: a Temporal Eigenvalue Loss (TEL) and a clip-level Quality Cluster Coefficient (QCC). The TEL ensures temporal coherence by leveraging the eigenvalues of the Laplacian matrix derived from graph adjacency matrices. By minimizing the mean absolute error (MAE) between the eigenvalues of adjacent frames, this loss function promotes smooth transitions and stable segmentation boundaries over time, reducing temporal discontinuities and improving overall segmentation quality. The QCC employs the K-means method to ensure the quality of spatio-temporal clusters without relying on ground truth masks. Using the Davies-Bouldin score, the QCC provides an unsupervised measure of feature discrimination, allowing the model to self-evaluate and adapt to varying object distributions, enhancing robustness during the testing phase. These enhancements are computationally efficient and straightforward, offering significant performance gains without additional annotated data. The proposed Eigen-Cluster VIS method is evaluated on the YouTube-VIS 2019/2021 and OVIS datasets, demonstrating that it effectively narrows the performance gap between the fully-supervised and weakly-supervised VIS approaches. The code is available on: https://github.com/farnooshar/EigenClusterVIS","sentences":["The performance of Video Instance Segmentation (VIS) methods has improved significantly with the advent of transformer networks.","However, these networks often face challenges in training due to the high annotation cost.","To address this, unsupervised and weakly-supervised methods have been developed to reduce the dependency on annotations.","This work introduces a novel weakly-supervised method called Eigen-cluster VIS that, without requiring any mask annotations, achieves competitive accuracy compared to other VIS approaches.","This method is based on two key innovations: a Temporal Eigenvalue Loss (TEL) and a clip-level Quality Cluster Coefficient (QCC).","The TEL ensures temporal coherence by leveraging the eigenvalues of the Laplacian matrix derived from graph adjacency matrices.","By minimizing the mean absolute error (MAE) between the eigenvalues of adjacent frames, this loss function promotes smooth transitions and stable segmentation boundaries over time, reducing temporal discontinuities and improving overall segmentation quality.","The QCC employs the K-means method to ensure the quality of spatio-temporal clusters without relying on ground truth masks.","Using the Davies-Bouldin score, the QCC provides an unsupervised measure of feature discrimination, allowing the model to self-evaluate and adapt to varying object distributions, enhancing robustness during the testing phase.","These enhancements are computationally efficient and straightforward, offering significant performance gains without additional annotated data.","The proposed Eigen-Cluster VIS method is evaluated on the YouTube-VIS 2019/2021 and OVIS datasets, demonstrating that it effectively narrows the performance gap between the fully-supervised and weakly-supervised VIS approaches.","The code is available on: https://github.com/farnooshar/EigenClusterVIS"],"url":"http://arxiv.org/abs/2408.16661v1"}
{"created":"2024-08-29 15:56:22","title":"Optimal Parallelization of Boosting","abstract":"Recent works on the parallel complexity of Boosting have established strong lower bounds on the tradeoff between the number of training rounds $p$ and the total parallel work per round $t$. These works have also presented highly non-trivial parallel algorithms that shed light on different regions of this tradeoff. Despite these advancements, a significant gap persists between the theoretical lower bounds and the performance of these algorithms across much of the tradeoff space. In this work, we essentially close this gap by providing both improved lower bounds on the parallel complexity of weak-to-strong learners, and a parallel Boosting algorithm whose performance matches these bounds across the entire $p$ vs.~$t$ compromise spectrum, up to logarithmic factors. Ultimately, this work settles the true parallel complexity of Boosting algorithms that are nearly sample-optimal.","sentences":["Recent works on the parallel complexity of Boosting have established strong lower bounds on the tradeoff between the number of training rounds $p$ and the total parallel work per round $t$. These works have also presented highly non-trivial parallel algorithms that shed light on different regions of this tradeoff.","Despite these advancements, a significant gap persists between the theoretical lower bounds and the performance of these algorithms across much of the tradeoff space.","In this work, we essentially close this gap by providing both improved lower bounds on the parallel complexity of weak-to-strong learners, and a parallel Boosting algorithm whose performance matches these bounds across the entire $p$ vs.~$t$ compromise spectrum, up to logarithmic factors.","Ultimately, this work settles the true parallel complexity of Boosting algorithms that are nearly sample-optimal."],"url":"http://arxiv.org/abs/2408.16653v1"}
{"created":"2024-08-29 15:55:27","title":"Towards Efficient Modelling of String Dynamics: A Comparison of State Space and Koopman based Deep Learning Methods","abstract":"This paper presents an examination of State Space Models (SSM) and Koopman-based deep learning methods for modelling the dynamics of both linear and non-linear stiff strings. Through experiments with datasets generated under different initial conditions and sample rates, we assess the capacity of these models to accurately model the complex behaviours observed in string dynamics. Our findings indicate that our proposed Koopman-based model performs as well as or better than other existing approaches in non-linear cases for long-sequence modelling.   We inform the design of these architectures with the structure of the problems at hand. Although challenges remain in extending model predictions beyond the training horizon (i.e., extrapolation), the focus of our investigation lies in the models' ability to generalise across different initial conditions within the training time interval. This research contributes insights into the physical modelling of dynamical systems (in particular those addressing musical acoustics) by offering a comparative overview of these and previous methods and introducing innovative strategies for model improvement. Our results highlight the efficacy of these models in simulating non-linear dynamics and emphasise their wide-ranging applicability in accurately modelling dynamical systems over extended sequences.","sentences":["This paper presents an examination of State Space Models (SSM) and Koopman-based deep learning methods for modelling the dynamics of both linear and non-linear stiff strings.","Through experiments with datasets generated under different initial conditions and sample rates, we assess the capacity of these models to accurately model the complex behaviours observed in string dynamics.","Our findings indicate that our proposed Koopman-based model performs as well as or better than other existing approaches in non-linear cases for long-sequence modelling.   ","We inform the design of these architectures with the structure of the problems at hand.","Although challenges remain in extending model predictions beyond the training horizon (i.e., extrapolation), the focus of our investigation lies in the models' ability to generalise across different initial conditions within the training time interval.","This research contributes insights into the physical modelling of dynamical systems (in particular those addressing musical acoustics) by offering a comparative overview of these and previous methods and introducing innovative strategies for model improvement.","Our results highlight the efficacy of these models in simulating non-linear dynamics and emphasise their wide-ranging applicability in accurately modelling dynamical systems over extended sequences."],"url":"http://arxiv.org/abs/2408.16650v1"}
{"created":"2024-08-29 15:52:56","title":"DriveGenVLM: Real-world Video Generation for Vision Language Model based Autonomous Driving","abstract":"The advancement of autonomous driving technologies necessitates increasingly sophisticated methods for understanding and predicting real-world scenarios. Vision language models (VLMs) are emerging as revolutionary tools with significant potential to influence autonomous driving. In this paper, we propose the DriveGenVLM framework to generate driving videos and use VLMs to understand them. To achieve this, we employ a video generation framework grounded in denoising diffusion probabilistic models (DDPM) aimed at predicting real-world video sequences. We then explore the adequacy of our generated videos for use in VLMs by employing a pre-trained model known as Efficient In-context Learning on Egocentric Videos (EILEV). The diffusion model is trained with the Waymo open dataset and evaluated using the Fr\\'echet Video Distance (FVD) score to ensure the quality and realism of the generated videos. Corresponding narrations are provided by EILEV for these generated videos, which may be beneficial in the autonomous driving domain. These narrations can enhance traffic scene understanding, aid in navigation, and improve planning capabilities. The integration of video generation with VLMs in the DriveGenVLM framework represents a significant step forward in leveraging advanced AI models to address complex challenges in autonomous driving.","sentences":["The advancement of autonomous driving technologies necessitates increasingly sophisticated methods for understanding and predicting real-world scenarios.","Vision language models (VLMs) are emerging as revolutionary tools with significant potential to influence autonomous driving.","In this paper, we propose the DriveGenVLM framework to generate driving videos and use VLMs to understand them.","To achieve this, we employ a video generation framework grounded in denoising diffusion probabilistic models (DDPM) aimed at predicting real-world video sequences.","We then explore the adequacy of our generated videos for use in VLMs by employing a pre-trained model known as Efficient In-context Learning on Egocentric Videos (EILEV).","The diffusion model is trained with the Waymo open dataset and evaluated using the Fr\\'echet Video Distance (FVD) score to ensure the quality and realism of the generated videos.","Corresponding narrations are provided by EILEV for these generated videos, which may be beneficial in the autonomous driving domain.","These narrations can enhance traffic scene understanding, aid in navigation, and improve planning capabilities.","The integration of video generation with VLMs in the DriveGenVLM framework represents a significant step forward in leveraging advanced AI models to address complex challenges in autonomous driving."],"url":"http://arxiv.org/abs/2408.16647v1"}
{"created":"2024-08-29 15:51:06","title":"SODAWideNet++: Combining Attention and Convolutions for Salient Object Detection","abstract":"Salient Object Detection (SOD) has traditionally relied on feature refinement modules that utilize the features of an ImageNet pre-trained backbone. However, this approach limits the possibility of pre-training the entire network because of the distinct nature of SOD and image classification. Additionally, the architecture of these backbones originally built for Image classification is sub-optimal for a dense prediction task like SOD. To address these issues, we propose a novel encoder-decoder-style neural network called SODAWideNet++ that is designed explicitly for SOD. Inspired by the vision transformers ability to attain a global receptive field from the initial stages, we introduce the Attention Guided Long Range Feature Extraction (AGLRFE) module, which combines large dilated convolutions and self-attention. Specifically, we use attention features to guide long-range information extracted by multiple dilated convolutions, thus taking advantage of the inductive biases of a convolution operation and the input dependency brought by self-attention. In contrast to the current paradigm of ImageNet pre-training, we modify 118K annotated images from the COCO semantic segmentation dataset by binarizing the annotations to pre-train the proposed model end-to-end. Further, we supervise the background predictions along with the foreground to push our model to generate accurate saliency predictions. SODAWideNet++ performs competitively on five different datasets while only containing 35% of the trainable parameters compared to the state-of-the-art models. The code and pre-computed saliency maps are provided at https://github.com/VimsLab/SODAWideNetPlusPlus.","sentences":["Salient Object Detection (SOD) has traditionally relied on feature refinement modules that utilize the features of an ImageNet pre-trained backbone.","However, this approach limits the possibility of pre-training the entire network because of the distinct nature of SOD and image classification.","Additionally, the architecture of these backbones originally built for Image classification is sub-optimal for a dense prediction task like SOD.","To address these issues, we propose a novel encoder-decoder-style neural network called SODAWideNet++ that is designed explicitly for SOD.","Inspired by the vision transformers ability to attain a global receptive field from the initial stages, we introduce the Attention Guided Long Range Feature Extraction (AGLRFE) module, which combines large dilated convolutions and self-attention.","Specifically, we use attention features to guide long-range information extracted by multiple dilated convolutions, thus taking advantage of the inductive biases of a convolution operation and the input dependency brought by self-attention.","In contrast to the current paradigm of ImageNet pre-training, we modify 118K annotated images from the COCO semantic segmentation dataset by binarizing the annotations to pre-train the proposed model end-to-end.","Further, we supervise the background predictions along with the foreground to push our model to generate accurate saliency predictions.","SODAWideNet++ performs competitively on five different datasets while only containing 35% of the trainable parameters compared to the state-of-the-art models.","The code and pre-computed saliency maps are provided at https://github.com/VimsLab/SODAWideNetPlusPlus."],"url":"http://arxiv.org/abs/2408.16645v1"}
{"created":"2024-08-29 15:42:06","title":"3D Pose-Based Temporal Action Segmentation for Figure Skating: A Fine-Grained and Jump Procedure-Aware Annotation Approach","abstract":"Understanding human actions from videos is essential in many domains, including sports. In figure skating, technical judgments are performed by watching skaters' 3D movements, and its part of the judging procedure can be regarded as a Temporal Action Segmentation (TAS) task. TAS tasks in figure skating that automatically assign temporal semantics to video are actively researched. However, there is a lack of datasets and effective methods for TAS tasks requiring 3D pose data. In this study, we first created the FS-Jump3D dataset of complex and dynamic figure skating jumps using optical markerless motion capture. We also propose a new fine-grained figure skating jump TAS dataset annotation method with which TAS models can learn jump procedures. In the experimental results, we validated the usefulness of 3D pose features as input and the fine-grained dataset for the TAS model in figure skating. FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D.","sentences":["Understanding human actions from videos is essential in many domains, including sports.","In figure skating, technical judgments are performed by watching skaters' 3D movements, and its part of the judging procedure can be regarded as a Temporal Action Segmentation (TAS) task.","TAS tasks in figure skating that automatically assign temporal semantics to video are actively researched.","However, there is a lack of datasets and effective methods for TAS tasks requiring 3D pose data.","In this study, we first created the FS-Jump3D dataset of complex and dynamic figure skating jumps using optical markerless motion capture.","We also propose a new fine-grained figure skating jump TAS dataset annotation method with which TAS models can learn jump procedures.","In the experimental results, we validated the usefulness of 3D pose features as input and the fine-grained dataset for the TAS model in figure skating.","FS-Jump3D Dataset is available at https://github.com/ryota-skating/FS-Jump3D."],"url":"http://arxiv.org/abs/2408.16638v1"}
{"created":"2024-08-29 15:39:33","title":"RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model","abstract":"The increasing sophistication of text-to-image generative models has led to complex challenges in defining and enforcing copyright infringement criteria and protection. Existing methods, such as watermarking and dataset deduplication, fail to provide comprehensive solutions due to the lack of standardized metrics and the inherent complexity of addressing copyright infringement in diffusion models. To deal with these challenges, we propose a Reinforcement Learning-based Copyright Protection(RLCP) method for Text-to-Image Diffusion Model, which minimizes the generation of copyright-infringing content while maintaining the quality of the model-generated dataset. Our approach begins with the introduction of a novel copyright metric grounded in copyright law and court precedents on infringement. We then utilize the Denoising Diffusion Policy Optimization (DDPO) framework to guide the model through a multi-step decision-making process, optimizing it using a reward function that incorporates our proposed copyright metric. Additionally, we employ KL divergence as a regularization term to mitigate some failure modes and stabilize RL fine-tuning. Experiments conducted on 3 mixed datasets of copyright and non-copyright images demonstrate that our approach significantly reduces copyright infringement risk while maintaining image quality.","sentences":["The increasing sophistication of text-to-image generative models has led to complex challenges in defining and enforcing copyright infringement criteria and protection.","Existing methods, such as watermarking and dataset deduplication, fail to provide comprehensive solutions due to the lack of standardized metrics and the inherent complexity of addressing copyright infringement in diffusion models.","To deal with these challenges, we propose a Reinforcement Learning-based Copyright Protection(RLCP) method for Text-to-Image Diffusion Model, which minimizes the generation of copyright-infringing content while maintaining the quality of the model-generated dataset.","Our approach begins with the introduction of a novel copyright metric grounded in copyright law and court precedents on infringement.","We then utilize the Denoising Diffusion Policy Optimization (DDPO) framework to guide the model through a multi-step decision-making process, optimizing it using a reward function that incorporates our proposed copyright metric.","Additionally, we employ KL divergence as a regularization term to mitigate some failure modes and stabilize RL fine-tuning.","Experiments conducted on 3 mixed datasets of copyright and non-copyright images demonstrate that our approach significantly reduces copyright infringement risk while maintaining image quality."],"url":"http://arxiv.org/abs/2408.16634v1"}
{"created":"2024-08-29 15:39:12","title":"Optimizing Automated Picking Systems in Warehouse Robots Using Machine Learning","abstract":"With the rapid growth of global e-commerce, the demand for automation in the logistics industry is increasing. This study focuses on automated picking systems in warehouses, utilizing deep learning and reinforcement learning technologies to enhance picking efficiency and accuracy while reducing system failure rates. Through empirical analysis, we demonstrate the effectiveness of these technologies in improving robot picking performance and adaptability to complex environments. The results show that the integrated machine learning model significantly outperforms traditional methods, effectively addressing the challenges of peak order processing, reducing operational errors, and improving overall logistics efficiency. Additionally, by analyzing environmental factors, this study further optimizes system design to ensure efficient and stable operation under variable conditions. This research not only provides innovative solutions for logistics automation but also offers a theoretical and empirical foundation for future technological development and application.","sentences":["With the rapid growth of global e-commerce, the demand for automation in the logistics industry is increasing.","This study focuses on automated picking systems in warehouses, utilizing deep learning and reinforcement learning technologies to enhance picking efficiency and accuracy while reducing system failure rates.","Through empirical analysis, we demonstrate the effectiveness of these technologies in improving robot picking performance and adaptability to complex environments.","The results show that the integrated machine learning model significantly outperforms traditional methods, effectively addressing the challenges of peak order processing, reducing operational errors, and improving overall logistics efficiency.","Additionally, by analyzing environmental factors, this study further optimizes system design to ensure efficient and stable operation under variable conditions.","This research not only provides innovative solutions for logistics automation but also offers a theoretical and empirical foundation for future technological development and application."],"url":"http://arxiv.org/abs/2408.16633v1"}
{"created":"2024-08-29 15:39:04","title":"Maelstrom Networks","abstract":"Artificial Neural Networks has struggled to devise a way to incorporate working memory into neural networks. While the ``long term'' memory can be seen as the learned weights, the working memory consists likely more of dynamical activity, that is missing from feed-forward models. Current state of the art models such as transformers tend to ``solve'' this by ignoring working memory entirely and simply process the sequence as an entire piece of data; however this means the network cannot process the sequence in an online fashion, and leads to an immense explosion in memory requirements. Here, inspired by a combination of controls, reservoir computing, deep learning, and recurrent neural networks, we offer an alternative paradigm that combines the strength of recurrent networks, with the pattern matching capability of feed-forward neural networks, which we call the \\textit{Maelstrom Networks} paradigm. This paradigm leaves the recurrent component - the \\textit{Maelstrom} - unlearned, and offloads the learning to a powerful feed-forward network. This allows the network to leverage the strength of feed-forward training without unrolling the network, and allows for the memory to be implemented in new neuromorphic hardware. It endows a neural network with a sequential memory that takes advantage of the inductive bias that data is organized causally in the temporal domain, and imbues the network with a state that represents the agent's ``self'', moving through the environment. This could also lead the way to continual learning, with the network modularized and ``'protected'' from overwrites that come with new data. In addition to aiding in solving these performance problems that plague current non-temporal deep networks, this also could finally lead towards endowing artificial networks with a sense of ``self''.","sentences":["Artificial Neural Networks has struggled to devise a way to incorporate working memory into neural networks.","While the ``long term'' memory can be seen as the learned weights, the working memory consists likely more of dynamical activity, that is missing from feed-forward models.","Current state of the art models such as transformers tend to ``solve'' this by ignoring working memory entirely and simply process the sequence as an entire piece of data; however this means the network cannot process the sequence in an online fashion, and leads to an immense explosion in memory requirements.","Here, inspired by a combination of controls, reservoir computing, deep learning, and recurrent neural networks, we offer an alternative paradigm that combines the strength of recurrent networks, with the pattern matching capability of feed-forward neural networks, which we call the \\textit{Maelstrom Networks} paradigm.","This paradigm leaves the recurrent component - the \\textit{Maelstrom} - unlearned, and offloads the learning to a powerful feed-forward network.","This allows the network to leverage the strength of feed-forward training without unrolling the network, and allows for the memory to be implemented in new neuromorphic hardware.","It endows a neural network with a sequential memory that takes advantage of the inductive bias that data is organized causally in the temporal domain, and imbues the network with a state that represents the agent's ``self'', moving through the environment.","This could also lead the way to continual learning, with the network modularized and ``'protected'' from overwrites that come with new data.","In addition to aiding in solving these performance problems that plague current non-temporal deep networks, this also could finally lead towards endowing artificial networks with a sense of ``self''."],"url":"http://arxiv.org/abs/2408.16632v1"}
{"created":"2024-08-29 15:36:52","title":"LLMs generate structurally realistic social networks but overestimate political homophily","abstract":"Generating social networks is essential for many applications, such as epidemic modeling and social simulations. Prior approaches either involve deep learning models, which require many observed networks for training, or stylized models, which are limited in their realism and flexibility. In contrast, LLMs offer the potential for zero-shot and flexible network generation. However, two key questions are: (1) are LLM's generated networks realistic, and (2) what are risks of bias, given the importance of demographics in forming social ties? To answer these questions, we develop three prompting methods for network generation and compare the generated networks to real social networks. We find that more realistic networks are generated with \"local\" methods, where the LLM constructs relations for one persona at a time, compared to \"global\" methods that construct the entire network at once. We also find that the generated networks match real networks on many characteristics, including density, clustering, community structure, and degree. However, we find that LLMs emphasize political homophily over all other types of homophily and overestimate political homophily relative to real-world measures.","sentences":["Generating social networks is essential for many applications, such as epidemic modeling and social simulations.","Prior approaches either involve deep learning models, which require many observed networks for training, or stylized models, which are limited in their realism and flexibility.","In contrast, LLMs offer the potential for zero-shot and flexible network generation.","However, two key questions are: (1) are LLM's generated networks realistic, and (2) what are risks of bias, given the importance of demographics in forming social ties?","To answer these questions, we develop three prompting methods for network generation and compare the generated networks to real social networks.","We find that more realistic networks are generated with \"local\" methods, where the LLM constructs relations for one persona at a time, compared to \"global\" methods that construct the entire network at once.","We also find that the generated networks match real networks on many characteristics, including density, clustering, community structure, and degree.","However, we find that LLMs emphasize political homophily over all other types of homophily and overestimate political homophily relative to real-world measures."],"url":"http://arxiv.org/abs/2408.16629v1"}
{"created":"2024-08-29 15:34:35","title":"A Score-based Generative Solver for PDE-constrained Inverse Problems with Complex Priors","abstract":"In the field of inverse estimation for systems modeled by partial differential equations (PDEs), challenges arise when estimating high- (or even infinite-) dimensional parameters. Typically, the ill-posed nature of such problems necessitates leveraging prior information to achieve well-posedness. In most existing inverse solvers, the prior distribution is assumed to be of either Gaussian or Laplace form which, in many practical scenarios, is an oversimplification. In case the prior is complex and the likelihood model is computationally expensive (e.g., due to expensive forward models), drawing the sample from such posteriors can be computationally intractable, especially when the unknown parameter is high-dimensional. In this work, to sample efficiently, we propose a score-based diffusion model, which combines a score-based generative sampling tool with a noising and denoising process driven by stochastic differential equations. This tool is used for iterative sample generation in accordance with the posterior distribution, while simultaneously learning and leveraging the underlying information and constraints inherent in the given complex prior. A time-varying time schedule is proposed to adapt the method for posterior sampling. To expedite the simulation of non-parameterized PDEs and enhance the generalization capacity, we introduce a physics-informed convolutional neural network (CNN) surrogate for the forward model. Finally, numerical experiments, including a hyper-elastic problem and a multi-scale mechanics problem, demonstrate the efficacy of the proposed approach. In particular, the score-based diffusion model, coupled with the physics-informed CNN surrogate, effectively learns geometrical features from provided prior samples, yielding better inverse estimation results compared to the state-of-the-art techniques.","sentences":["In the field of inverse estimation for systems modeled by partial differential equations (PDEs), challenges arise when estimating high- (or even infinite-) dimensional parameters.","Typically, the ill-posed nature of such problems necessitates leveraging prior information to achieve well-posedness.","In most existing inverse solvers, the prior distribution is assumed to be of either Gaussian or Laplace form which, in many practical scenarios, is an oversimplification.","In case the prior is complex and the likelihood model is computationally expensive (e.g., due to expensive forward models), drawing the sample from such posteriors can be computationally intractable, especially when the unknown parameter is high-dimensional.","In this work, to sample efficiently, we propose a score-based diffusion model, which combines a score-based generative sampling tool with a noising and denoising process driven by stochastic differential equations.","This tool is used for iterative sample generation in accordance with the posterior distribution, while simultaneously learning and leveraging the underlying information and constraints inherent in the given complex prior.","A time-varying time schedule is proposed to adapt the method for posterior sampling.","To expedite the simulation of non-parameterized PDEs and enhance the generalization capacity, we introduce a physics-informed convolutional neural network (CNN) surrogate for the forward model.","Finally, numerical experiments, including a hyper-elastic problem and a multi-scale mechanics problem, demonstrate the efficacy of the proposed approach.","In particular, the score-based diffusion model, coupled with the physics-informed CNN surrogate, effectively learns geometrical features from provided prior samples, yielding better inverse estimation results compared to the state-of-the-art techniques."],"url":"http://arxiv.org/abs/2408.16626v1"}
{"created":"2024-08-29 15:34:25","title":"MultiMediate'24: Multi-Domain Engagement Estimation","abstract":"Estimating the momentary level of participant's engagement is an important prerequisite for assistive systems that support human interactions. Previous work has addressed this task in within-domain evaluation scenarios, i.e. training and testing on the same dataset. This is in contrast to real-life scenarios where domain shifts between training and testing data frequently occur. With MultiMediate'24, we present the first challenge addressing multi-domain engagement estimation. As training data, we utilise the NOXI database of dyadic novice-expert interactions. In addition to within-domain test data, we add two new test domains. First, we introduce recordings following the NOXI protocol but covering languages that are not present in the NOXI training data. Second, we collected novel engagement annotations on the MPIIGroupInteraction dataset which consists of group discussions between three to four people. In this way, MultiMediate'24 evaluates the ability of approaches to generalise across factors such as language and cultural background, group size, task, and screen-mediated vs. face-to-face interaction. This paper describes the MultiMediate'24 challenge and presents baseline results. In addition, we discuss selected challenge solutions.","sentences":["Estimating the momentary level of participant's engagement is an important prerequisite for assistive systems that support human interactions.","Previous work has addressed this task in within-domain evaluation scenarios, i.e. training and testing on the same dataset.","This is in contrast to real-life scenarios where domain shifts between training and testing data frequently occur.","With MultiMediate'24, we present the first challenge addressing multi-domain engagement estimation.","As training data, we utilise the NOXI database of dyadic novice-expert interactions.","In addition to within-domain test data, we add two new test domains.","First, we introduce recordings following the NOXI protocol but covering languages that are not present in the NOXI training data.","Second, we collected novel engagement annotations on the MPIIGroupInteraction dataset which consists of group discussions between three to four people.","In this way, MultiMediate'24 evaluates the ability of approaches to generalise across factors such as language and cultural background, group size, task, and screen-mediated vs. face-to-face interaction.","This paper describes the MultiMediate'24 challenge and presents baseline results.","In addition, we discuss selected challenge solutions."],"url":"http://arxiv.org/abs/2408.16625v1"}
{"created":"2024-08-29 15:31:51","title":"Turbulence Strength $C_n^2$ Estimation from Video using Physics-based Deep Learning","abstract":"Images captured from a long distance suffer from dynamic image distortion due to turbulent flow of air cells with random temperatures, and thus refractive indices. This phenomenon, known as image dancing, is commonly characterized by its refractive-index structure constant $C_n^2$ as a measure of the turbulence strength. For many applications such as atmospheric forecast model, long-range/astronomy imaging, and aviation safety, optical communication technology, $C_n^2$ estimation is critical for accurately sensing the turbulent environment. Previous methods for $C_n^2$ estimation include estimation from meteorological data (temperature, relative humidity, wind shear, etc.) for single-point measurements, two-ended pathlength measurements from optical scintillometer for path-averaged $C_n^2$, and more recently estimating $C_n^2$ from passive video cameras for low cost and hardware complexity. In this paper, we present a comparative analysis of classical image gradient methods for $C_n^2$ estimation and modern deep learning-based methods leveraging convolutional neural networks. To enable this, we collect a dataset of video capture along with reference scintillometer measurements for ground truth, and we release this unique dataset to the scientific community. We observe that deep learning methods can achieve higher accuracy when trained on similar data, but suffer from generalization errors to other, unseen imagery as compared to classical methods. To overcome this trade-off, we present a novel physics-based network architecture that combines learned convolutional layers with a differentiable image gradient method that maintains high accuracy while being generalizable across image datasets.","sentences":["Images captured from a long distance suffer from dynamic image distortion due to turbulent flow of air cells with random temperatures, and thus refractive indices.","This phenomenon, known as image dancing, is commonly characterized by its refractive-index structure constant $C_n^2$ as a measure of the turbulence strength.","For many applications such as atmospheric forecast model, long-range/astronomy imaging, and aviation safety, optical communication technology, $C_n^2$ estimation is critical for accurately sensing the turbulent environment.","Previous methods for $C_n^2$ estimation include estimation from meteorological data (temperature, relative humidity, wind shear, etc.)","for single-point measurements, two-ended pathlength measurements from optical scintillometer for path-averaged $C_n^2$, and more recently estimating $C_n^2$ from passive video cameras for low cost and hardware complexity.","In this paper, we present a comparative analysis of classical image gradient methods for $C_n^2$ estimation and modern deep learning-based methods leveraging convolutional neural networks.","To enable this, we collect a dataset of video capture along with reference scintillometer measurements for ground truth, and we release this unique dataset to the scientific community.","We observe that deep learning methods can achieve higher accuracy when trained on similar data, but suffer from generalization errors to other, unseen imagery as compared to classical methods.","To overcome this trade-off, we present a novel physics-based network architecture that combines learned convolutional layers with a differentiable image gradient method that maintains high accuracy while being generalizable across image datasets."],"url":"http://arxiv.org/abs/2408.16623v1"}
{"created":"2024-08-29 15:28:42","title":"Towards Infusing Auxiliary Knowledge for Distracted Driver Detection","abstract":"Distracted driving is a leading cause of road accidents globally. Identification of distracted driving involves reliably detecting and classifying various forms of driver distraction (e.g., texting, eating, or using in-car devices) from in-vehicle camera feeds to enhance road safety. This task is challenging due to the need for robust models that can generalize to a diverse set of driver behaviors without requiring extensive annotated datasets. In this paper, we propose KiD3, a novel method for distracted driver detection (DDD) by infusing auxiliary knowledge about semantic relations between entities in a scene and the structural configuration of the driver's pose. Specifically, we construct a unified framework that integrates the scene graphs, and driver pose information with the visual cues in video frames to create a holistic representation of the driver's actions.Our results indicate that KiD3 achieves a 13.64% accuracy improvement over the vision-only baseline by incorporating such auxiliary knowledge with visual information.","sentences":["Distracted driving is a leading cause of road accidents globally.","Identification of distracted driving involves reliably detecting and classifying various forms of driver distraction (e.g., texting, eating, or using in-car devices) from in-vehicle camera feeds to enhance road safety.","This task is challenging due to the need for robust models that can generalize to a diverse set of driver behaviors without requiring extensive annotated datasets.","In this paper, we propose KiD3, a novel method for distracted driver detection (DDD) by infusing auxiliary knowledge about semantic relations between entities in a scene and the structural configuration of the driver's pose.","Specifically, we construct a unified framework that integrates the scene graphs, and driver pose information with the visual cues in video frames to create a holistic representation of the driver's actions.","Our results indicate that KiD3 achieves a 13.64% accuracy improvement over the vision-only baseline by incorporating such auxiliary knowledge with visual information."],"url":"http://arxiv.org/abs/2408.16621v1"}
{"created":"2024-08-29 15:28:01","title":"Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation","abstract":"We construct a two-layered model for learning and generating sequential data that is both computationally fast and competitive with vanilla Tsetlin machines, adding numerous advantages. Through the use of hyperdimensional vector computing (HVC) algebras and Tsetlin machine clause structures, we demonstrate that the combination of both inherits the generality of data encoding and decoding of HVC with the fast interpretable nature of Tsetlin machines to yield a powerful machine learning model. We apply the approach in two areas, namely in forecasting, generating new sequences, and classification. For the latter, we derive results for the entire UCR Time Series Archive and compare with the standard benchmarks to see how well the method competes in time series classification.","sentences":["We construct a two-layered model for learning and generating sequential data that is both computationally fast and competitive with vanilla Tsetlin machines, adding numerous advantages.","Through the use of hyperdimensional vector computing (HVC) algebras and Tsetlin machine clause structures, we demonstrate that the combination of both inherits the generality of data encoding and decoding of HVC with the fast interpretable nature of Tsetlin machines to yield a powerful machine learning model.","We apply the approach in two areas, namely in forecasting, generating new sequences, and classification.","For the latter, we derive results for the entire UCR Time Series Archive and compare with the standard benchmarks to see how well the method competes in time series classification."],"url":"http://arxiv.org/abs/2408.16620v1"}
{"created":"2024-08-29 15:20:17","title":"Blending Low and High-Level Semantics of Time Series for Better Masked Time Series Generation","abstract":"State-of-the-art approaches in time series generation (TSG), such as TimeVQVAE, utilize vector quantization-based tokenization to effectively model complex distributions of time series. These approaches first learn to transform time series into a sequence of discrete latent vectors, and then a prior model is learned to model the sequence. The discrete latent vectors, however, only capture low-level semantics (\\textit{e.g.,} shapes). We hypothesize that higher-fidelity time series can be generated by training a prior model on more informative discrete latent vectors that contain both low and high-level semantics (\\textit{e.g.,} characteristic dynamics). In this paper, we introduce a novel framework, termed NC-VQVAE, to integrate self-supervised learning into those TSG methods to derive a discrete latent space where low and high-level semantics are captured. Our experimental results demonstrate that NC-VQVAE results in a considerable improvement in the quality of synthetic samples.","sentences":["State-of-the-art approaches in time series generation (TSG), such as TimeVQVAE, utilize vector quantization-based tokenization to effectively model complex distributions of time series.","These approaches first learn to transform time series into a sequence of discrete latent vectors, and then a prior model is learned to model the sequence.","The discrete latent vectors, however, only capture low-level semantics (\\textit{e.g.,} shapes).","We hypothesize that higher-fidelity time series can be generated by training a prior model on more informative discrete latent vectors that contain both low and high-level semantics (\\textit{e.g.,} characteristic dynamics).","In this paper, we introduce a novel framework, termed NC-VQVAE, to integrate self-supervised learning into those TSG methods to derive a discrete latent space where low and high-level semantics are captured.","Our experimental results demonstrate that NC-VQVAE results in a considerable improvement in the quality of synthetic samples."],"url":"http://arxiv.org/abs/2408.16613v1"}
{"created":"2024-08-29 15:19:06","title":"Data Quality Monitoring through Transfer Learning on Anomaly Detection for the Hadron Calorimeters","abstract":"The proliferation of sensors brings an immense volume of spatio-temporal (ST) data in many domains for various purposes, including monitoring, diagnostics, and prognostics applications. Data curation is a time-consuming process for a large volume of data, making it challenging and expensive to deploy data analytics platforms in new environments. Transfer learning (TL) mechanisms promise to mitigate data sparsity and model complexity by utilizing pre-trained models for a new task. Despite the triumph of TL in fields like computer vision and natural language processing, efforts on complex ST models for anomaly detection (AD) applications are limited. In this study, we present the potential of TL within the context of AD for the Hadron Calorimeter of the Compact Muon Solenoid experiment at CERN. We have transferred the ST AD models trained on data collected from one part of a calorimeter to another. We have investigated different configurations of TL on semi-supervised autoencoders of the ST AD models -- transferring convolutional, graph, and recurrent neural networks of both the encoder and decoder networks. The experiment results demonstrate that TL effectively enhances the model learning accuracy on a target subdetector. The TL achieves promising data reconstruction and AD performance while substantially reducing the trainable parameters of the AD models. It also improves robustness against anomaly contamination in the training data sets of the semi-supervised AD models.","sentences":["The proliferation of sensors brings an immense volume of spatio-temporal (ST) data in many domains for various purposes, including monitoring, diagnostics, and prognostics applications.","Data curation is a time-consuming process for a large volume of data, making it challenging and expensive to deploy data analytics platforms in new environments.","Transfer learning (TL) mechanisms promise to mitigate data sparsity and model complexity by utilizing pre-trained models for a new task.","Despite the triumph of TL in fields like computer vision and natural language processing, efforts on complex ST models for anomaly detection (AD) applications are limited.","In this study, we present the potential of TL within the context of AD for the Hadron Calorimeter of the Compact Muon Solenoid experiment at CERN.","We have transferred the ST AD models trained on data collected from one part of a calorimeter to another.","We have investigated different configurations of TL on semi-supervised autoencoders of the ST AD models -- transferring convolutional, graph, and recurrent neural networks of both the encoder and decoder networks.","The experiment results demonstrate that TL effectively enhances the model learning accuracy on a target subdetector.","The TL achieves promising data reconstruction and AD performance while substantially reducing the trainable parameters of the AD models.","It also improves robustness against anomaly contamination in the training data sets of the semi-supervised AD models."],"url":"http://arxiv.org/abs/2408.16612v1"}
{"created":"2024-08-29 15:17:34","title":"ppOpen-AT: A Directive-base Auto-tuning Language","abstract":"ppOpen-AT is a domain-specific language designed to ease the workload for developers creating libraries with auto-tuning (AT) capabilities. It consists of a set of directives that allow for the automatic generation of code necessary for AT by placing annotations in the source program. This approach significantly reduces the effort required by numerical library developers. This technical report details the implementation of the AT software and its extended functions, and provides an explanation of the internal specifications of ppOpen-AT.","sentences":["ppOpen-AT is a domain-specific language designed to ease the workload for developers creating libraries with auto-tuning (AT) capabilities.","It consists of a set of directives that allow for the automatic generation of code necessary for AT by placing annotations in the source program.","This approach significantly reduces the effort required by numerical library developers.","This technical report details the implementation of the AT software and its extended functions, and provides an explanation of the internal specifications of ppOpen-AT."],"url":"http://arxiv.org/abs/2408.16607v1"}
{"created":"2024-08-29 15:12:16","title":"Examination of Code generated by Large Language Models","abstract":"Large language models (LLMs), such as ChatGPT and Copilot, are transforming software development by automating code generation and, arguably, enable rapid prototyping, support education, and boost productivity. Therefore, correctness and quality of the generated code should be on par with manually written code. To assess the current state of LLMs in generating correct code of high quality, we conducted controlled experiments with ChatGPT and Copilot: we let the LLMs generate simple algorithms in Java and Python along with the corresponding unit tests and assessed the correctness and the quality (coverage) of the generated (test) codes. We observed significant differences between the LLMs, between the languages, between algorithm and test codes, and over time. The present paper reports these results together with the experimental methods allowing repeated and comparable assessments for more algorithms, languages, and LLMs over time.","sentences":["Large language models (LLMs), such as ChatGPT and Copilot, are transforming software development by automating code generation and, arguably, enable rapid prototyping, support education, and boost productivity.","Therefore, correctness and quality of the generated code should be on par with manually written code.","To assess the current state of LLMs in generating correct code of high quality, we conducted controlled experiments with ChatGPT and Copilot: we let the LLMs generate simple algorithms in Java and Python along with the corresponding unit tests and assessed the correctness and the quality (coverage) of the generated (test) codes.","We observed significant differences between the LLMs, between the languages, between algorithm and test codes, and over time.","The present paper reports these results together with the experimental methods allowing repeated and comparable assessments for more algorithms, languages, and LLMs over time."],"url":"http://arxiv.org/abs/2408.16601v1"}
{"created":"2024-08-29 15:09:04","title":"sEMG-Driven Physics-Informed Gated Recurrent Networks for Modeling Upper Limb Multi-Joint Movement Dynamics","abstract":"Exoskeletons and rehabilitation systems offer great potential for enhancing human strength and recovery through advanced human-machine interfaces (HMIs) that adapt to movement dynamics. However, the real-time application of physics-informed neural networks (PINNs) is limited by their reliance on fixed input lengths and surrogate models. This study introduces a novel physics-informed Gated Recurrent Network (PiGRN) designed to predict multi-joint torques using surface electromyography (sEMG) data. The PiGRN model employs a Gated Recurrent Unit (GRU) to convert time-series sEMG inputs into multi-joint kinematics and external loads, which are then integrated into an equation of motion to ensure consistency with physical laws. Experimental validation with sEMG data from five participants performing elbow flexion-extension tasks showed that the PiGRN model accurately predicted joint torques for 10 unfamiliar movements, with RMSE values between 4.02\\% and 11.40\\% and correlation coefficients ranging from 0.87 to 0.98. These findings highlight the PiGRN's potential for real-time exoskeleton and rehabilitation applications. Future research will explore more diverse datasets, improve musculoskeletal models, and investigate unsupervised learning methods.","sentences":["Exoskeletons and rehabilitation systems offer great potential for enhancing human strength and recovery through advanced human-machine interfaces (HMIs) that adapt to movement dynamics.","However, the real-time application of physics-informed neural networks (PINNs) is limited by their reliance on fixed input lengths and surrogate models.","This study introduces a novel physics-informed Gated Recurrent Network (PiGRN) designed to predict multi-joint torques using surface electromyography (sEMG) data.","The PiGRN model employs a Gated Recurrent Unit (GRU) to convert time-series sEMG inputs into multi-joint kinematics and external loads, which are then integrated into an equation of motion to ensure consistency with physical laws.","Experimental validation with sEMG data from five participants performing elbow flexion-extension tasks showed that the PiGRN model accurately predicted joint torques for 10 unfamiliar movements, with RMSE values between 4.02\\% and 11.40\\% and correlation coefficients ranging from 0.87 to 0.98.","These findings highlight the PiGRN's potential for real-time exoskeleton and rehabilitation applications.","Future research will explore more diverse datasets, improve musculoskeletal models, and investigate unsupervised learning methods."],"url":"http://arxiv.org/abs/2408.16599v1"}
{"created":"2024-08-29 14:55:33","title":"High-Dimensional Sparse Data Low-rank Representation via Accelerated Asynchronous Parallel Stochastic Gradient Descent","abstract":"Data characterized by high dimensionality and sparsity are commonly used to describe real-world node interactions. Low-rank representation (LR) can map high-dimensional sparse (HDS) data to low-dimensional feature spaces and infer node interactions via modeling data latent associations. Unfortunately, existing optimization algorithms for LR models are computationally inefficient and slowly convergent on large-scale datasets. To address this issue, this paper proposes an Accelerated Asynchronous Parallel Stochastic Gradient Descent A2PSGD for High-Dimensional Sparse Data Low-rank Representation with three fold-ideas: a) establishing a lock-free scheduler to simultaneously respond to scheduling requests from multiple threads; b) introducing a greedy algorithm-based load balancing strategy for balancing the computational load among threads; c) incorporating Nesterov's accelerated gradient into the learning scheme to accelerate model convergence. Empirical studies show that A2PSGD outperforms existing optimization algorithms for HDS data LR in both accuracy and training time.","sentences":["Data characterized by high dimensionality and sparsity are commonly used to describe real-world node interactions.","Low-rank representation (LR) can map high-dimensional sparse (HDS) data to low-dimensional feature spaces and infer node interactions via modeling data latent associations.","Unfortunately, existing optimization algorithms for LR models are computationally inefficient and slowly convergent on large-scale datasets.","To address this issue, this paper proposes an Accelerated Asynchronous Parallel Stochastic Gradient Descent A2PSGD for High-Dimensional Sparse Data Low-rank Representation with three fold-ideas: a) establishing a lock-free scheduler to simultaneously respond to scheduling requests from multiple threads; b) introducing a greedy algorithm-based load balancing strategy for balancing the computational load among threads; c) incorporating Nesterov's accelerated gradient into the learning scheme to accelerate model convergence.","Empirical studies show that A2PSGD outperforms existing optimization algorithms for HDS data LR in both accuracy and training time."],"url":"http://arxiv.org/abs/2408.16592v1"}
{"created":"2024-08-29 14:52:42","title":"CrisperWhisper: Accurate Timestamps on Verbatim Speech Transcriptions","abstract":"We demonstrate that carefully adjusting the tokenizer of the Whisper speech recognition model significantly improves the precision of word-level timestamps when applying dynamic time warping to the decoder's cross-attention scores. We fine-tune the model to produce more verbatim speech transcriptions and employ several techniques to increase robustness against multiple speakers and background noise. These adjustments achieve state-of-the-art performance on benchmarks for verbatim speech transcription, word segmentation, and the timed detection of filler events, and can further mitigate transcription hallucinations. The code is available open https://github.com/nyrahealth/CrisperWhisper.","sentences":["We demonstrate that carefully adjusting the tokenizer of the Whisper speech recognition model significantly improves the precision of word-level timestamps when applying dynamic time warping to the decoder's cross-attention scores.","We fine-tune the model to produce more verbatim speech transcriptions and employ several techniques to increase robustness against multiple speakers and background noise.","These adjustments achieve state-of-the-art performance on benchmarks for verbatim speech transcription, word segmentation, and the timed detection of filler events, and can further mitigate transcription hallucinations.","The code is available open https://github.com/nyrahealth/CrisperWhisper."],"url":"http://arxiv.org/abs/2408.16589v1"}
{"created":"2024-08-29 14:49:13","title":"Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies","abstract":"Recent advancements in natural language processing, particularly with large language models (LLMs) like GPT-4, have significantly enhanced dialogue systems, enabling them to generate more natural and fluent conversations. Despite these improvements, challenges persist, such as managing continuous dialogues, memory retention, and minimizing hallucinations. The AIWolfDial2024 addresses these challenges by employing the Werewolf Game, an incomplete information game, to test the capabilities of LLMs in complex interactive environments. This paper introduces a LLM-based Werewolf Game AI, where each role is supported by situation analysis to aid response generation. Additionally, for the werewolf role, various persuasion strategies, including logical appeal, credibility appeal, and emotional appeal, are employed to effectively persuade other players to align with its actions.","sentences":["Recent advancements in natural language processing, particularly with large language models (LLMs) like GPT-4, have significantly enhanced dialogue systems, enabling them to generate more natural and fluent conversations.","Despite these improvements, challenges persist, such as managing continuous dialogues, memory retention, and minimizing hallucinations.","The AIWolfDial2024 addresses these challenges by employing the Werewolf Game, an incomplete information game, to test the capabilities of LLMs in complex interactive environments.","This paper introduces a LLM-based Werewolf Game AI, where each role is supported by situation analysis to aid response generation.","Additionally, for the werewolf role, various persuasion strategies, including logical appeal, credibility appeal, and emotional appeal, are employed to effectively persuade other players to align with its actions."],"url":"http://arxiv.org/abs/2408.16586v1"}
{"created":"2024-08-29 14:48:56","title":"$\\varepsilon$-MSR Codes for Any Set of Helper Nodes","abstract":"Minimum storage regenerating (MSR) codes are a class of maximum distance separable (MDS) array codes capable of repairing any single failed node by downloading the minimum amount of information from each of the helper nodes. However, MSR codes require large sub-packetization levels, which hinders their usefulness in practical settings. This led to the development of another class of MDS array codes called $\\varepsilon$-MSR codes, for which the repair information downloaded from each helper node is at most a factor of $(1+\\varepsilon)$ from the minimum amount for some $\\varepsilon > 0$. The advantage of $\\varepsilon$-MSR codes over MSR codes is their small sub-packetization levels. In previous constructions of epsilon-MSR codes, however, several specific nodes are required to participate in the repair of a failed node, which limits the performance of the code in cases where these nodes are not available. In this work, we present a construction of $\\varepsilon$-MSR codes without this restriction. For a code with $n$ nodes, out of which $k$ store uncoded information, and for any number $d$ of helper nodes ($k\\le d<n$), the repair of a failed node can be done by contacting any set of $d$ surviving nodes. Our construction utilizes group algebra techniques, and requires linear field size. We also generalize the construction to MDS array codes capable of repairing $h$ failed nodes using $d$ helper nodes with a slightly sub-optimal download from each helper node, for all $h \\le r$ and $k \\le d \\le n-h$ simultaneously.","sentences":["Minimum storage regenerating (MSR) codes are a class of maximum distance separable (MDS) array codes capable of repairing any single failed node by downloading the minimum amount of information from each of the helper nodes.","However, MSR codes require large sub-packetization levels, which hinders their usefulness in practical settings.","This led to the development of another class of MDS array codes called $\\varepsilon$-MSR codes, for which the repair information downloaded from each helper node is at most a factor of $(1+\\varepsilon)$ from the minimum amount for some $\\varepsilon > 0$.","The advantage of $\\varepsilon$-MSR codes over MSR codes is their small sub-packetization levels.","In previous constructions of epsilon-MSR codes, however, several specific nodes are required to participate in the repair of a failed node, which limits the performance of the code in cases where these nodes are not available.","In this work, we present a construction of $\\varepsilon$-MSR codes without this restriction.","For a code with $n$ nodes, out of which $k$ store uncoded information, and for any number $d$ of helper nodes ($k\\le d<n$), the repair of a failed node can be done by contacting any set of $d$ surviving nodes.","Our construction utilizes group algebra techniques, and requires linear field size.","We also generalize the construction to MDS array codes capable of repairing $h$ failed nodes using $d$ helper nodes with a slightly sub-optimal download from each helper node, for all $h \\le r$ and $k \\le d \\le n-h$ simultaneously."],"url":"http://arxiv.org/abs/2408.16584v1"}
{"created":"2024-08-29 14:48:00","title":"FastForensics: Efficient Two-Stream Design for Real-Time Image Manipulation Detection","abstract":"With the rise in popularity of portable devices, the spread of falsified media on social platforms has become rampant. This necessitates the timely identification of authentic content. However, most advanced detection methods are computationally heavy, hindering their real-time application. In this paper, we describe an efficient two-stream architecture for real-time image manipulation detection. Our method consists of two-stream branches targeting the cognitive and inspective perspectives. In the cognitive branch, we propose efficient wavelet-guided Transformer blocks to capture the global manipulation traces related to frequency. This block contains an interactive wavelet-guided self-attention module that integrates wavelet transformation with efficient attention design, interacting with the knowledge from the inspective branch. The inspective branch consists of simple convolutions that capture fine-grained traces and interact bidirectionally with Transformer blocks to provide mutual support. Our method is lightweight ($\\sim$ 8M) but achieves competitive performance compared to many other counterparts, demonstrating its efficacy in image manipulation detection and its potential for portable integration.","sentences":["With the rise in popularity of portable devices, the spread of falsified media on social platforms has become rampant.","This necessitates the timely identification of authentic content.","However, most advanced detection methods are computationally heavy, hindering their real-time application.","In this paper, we describe an efficient two-stream architecture for real-time image manipulation detection.","Our method consists of two-stream branches targeting the cognitive and inspective perspectives.","In the cognitive branch, we propose efficient wavelet-guided Transformer blocks to capture the global manipulation traces related to frequency.","This block contains an interactive wavelet-guided self-attention module that integrates wavelet transformation with efficient attention design, interacting with the knowledge from the inspective branch.","The inspective branch consists of simple convolutions that capture fine-grained traces and interact bidirectionally with Transformer blocks to provide mutual support.","Our method is lightweight ($\\sim$ 8M) but achieves competitive performance compared to many other counterparts, demonstrating its efficacy in image manipulation detection and its potential for portable integration."],"url":"http://arxiv.org/abs/2408.16582v1"}
{"created":"2024-08-29 14:44:12","title":"Transformers Meet ACT-R: Repeat-Aware and Sequential Listening Session Recommendation","abstract":"Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions. Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors. This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song. In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation. PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics. This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones. We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation. Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use.","sentences":["Music streaming services often leverage sequential recommender systems to predict the best music to showcase to users based on past sequences of listening sessions.","Nonetheless, most sequential recommendation methods ignore or insufficiently account for repetitive behaviors.","This is a crucial limitation for music recommendation, as repeatedly listening to the same song over time is a common phenomenon that can even change the way users perceive this song.","In this paper, we introduce PISA (Psychology-Informed Session embedding using ACT-R), a session-level sequential recommender system that overcomes this limitation.","PISA employs a Transformer architecture learning embedding representations of listening sessions and users using attention mechanisms inspired by Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics.","This approach enables us to capture dynamic and repetitive patterns from user behaviors, allowing us to effectively predict the songs they will listen to in subsequent sessions, whether they are repeated or new ones.","We demonstrate the empirical relevance of PISA using both publicly available listening data from Last.fm and proprietary data from Deezer, a global music streaming service, confirming the critical importance of repetition modeling for sequential listening session recommendation.","Along with this paper, we publicly release our proprietary dataset to foster future research in this field, as well as the source code of PISA to facilitate its future use."],"url":"http://arxiv.org/abs/2408.16578v1"}
{"created":"2024-08-29 14:43:42","title":"Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning","abstract":"Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability. This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur). However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges. The challenges arise as the conditions for PNS identifiability, Exogeneity and Monotonicity, need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities. To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components. We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation. Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance. Experiments demonstrate the effectiveness of our method on both synthetic and real-world data.","sentences":["Learning representations with a high Probability of Necessary and Sufficient Causes (PNS) has been shown to enhance deep learning models' ability.","This task involves identifying causal features that are both sufficient (guaranteeing the outcome) and necessary (without which the outcome cannot occur).","However, current research predominantly focuses on unimodal data, and extending PNS learning to multimodal settings presents significant challenges.","The challenges arise as the conditions for PNS identifiability, Exogeneity and Monotonicity, need to be reconsidered in a multimodal context, where sufficient and necessary causal features are distributed across different modalities.","To address this, we first propose conceptualizing multimodal representations as comprising modality-invariant and modality-specific components.","We then analyze PNS identifiability for each component, while ensuring non-trivial PNS estimation.","Finally, we formulate tractable optimization objectives that enable multimodal models to learn high-PNS representations, thereby enhancing their predictive performance.","Experiments demonstrate the effectiveness of our method on both synthetic and real-world data."],"url":"http://arxiv.org/abs/2408.16577v1"}
{"created":"2024-08-29 14:40:32","title":"An Adaptive Latent Factorization of Tensors Model for Embedding Dynamic Communication Network","abstract":"The Dynamic Communication Network (DCN) describes the interactions over time among various communication nodes, and it is widely used in Big-data applications as a data source. As the number of communication nodes increases and temporal slots accumulate, each node interacts in with only a few nodes in a given temporal slot, the DCN can be represented by an High-Dimensional Sparse (HDS) tensor. In order to extract rich behavioral patterns from an HDS tensor in DCN, this paper proposes an Adaptive Temporal-dependent Tensor low-rank representation (ATT) model. It adopts a three-fold approach: a) designing a temporal-dependent method to reconstruct temporal feature matrix, thereby precisely represent the data by capturing the temporal patterns; b) achieving hyper-parameters adaptation of the model via the Differential Evolutionary Algorithms (DEA) to avoid tedious hyper-parameters tuning; c) employing nonnegative learning schemes for the model parameters to effectively handle an the nonnegativity inherent in HDS data. The experimental results on four real-world DCNs demonstrate that the proposed ATT model significantly outperforms several state-of-the-art models in both prediction errors and convergence rounds.","sentences":["The Dynamic Communication Network (DCN) describes the interactions over time among various communication nodes, and it is widely used in Big-data applications as a data source.","As the number of communication nodes increases and temporal slots accumulate, each node interacts in with only a few nodes in a given temporal slot, the DCN can be represented by an High-Dimensional Sparse (HDS) tensor.","In order to extract rich behavioral patterns from an HDS tensor in DCN, this paper proposes an Adaptive Temporal-dependent Tensor low-rank representation (ATT) model.","It adopts a three-fold approach: a) designing a temporal-dependent method to reconstruct temporal feature matrix, thereby precisely represent the data by capturing the temporal patterns; b) achieving hyper-parameters adaptation of the model via the Differential Evolutionary Algorithms (DEA) to avoid tedious hyper-parameters tuning; c) employing nonnegative learning schemes for the model parameters to effectively handle an the nonnegativity inherent in HDS data.","The experimental results on four real-world DCNs demonstrate that the proposed ATT model significantly outperforms several state-of-the-art models in both prediction errors and convergence rounds."],"url":"http://arxiv.org/abs/2408.16573v1"}
{"created":"2024-08-29 14:37:05","title":"Predictability maximization and the origins of word order harmony","abstract":"We address the linguistic problem of the sequential arrangement of a head and its dependents from an information theoretic perspective. In particular, we consider the optimal placement of a head that maximizes the predictability of the sequence. We assume that dependents are statistically independent given a head, in line with the open-choice principle and the core assumptions of dependency grammar. We demonstrate the optimality of harmonic order, i.e., placing the head last maximizes the predictability of the head whereas placing the head first maximizes the predictability of dependents. We also show that postponing the head is the optimal strategy to maximize its predictability while bringing it forward is the optimal strategy to maximize the predictability of dependents. We unravel the advantages of the strategy of maximizing the predictability of the head over maximizing the predictability of dependents. Our findings shed light on the placements of the head adopted by real languages or emerging in different kinds of experiments.","sentences":["We address the linguistic problem of the sequential arrangement of a head and its dependents from an information theoretic perspective.","In particular, we consider the optimal placement of a head that maximizes the predictability of the sequence.","We assume that dependents are statistically independent given a head, in line with the open-choice principle and the core assumptions of dependency grammar.","We demonstrate the optimality of harmonic order, i.e., placing the head last maximizes the predictability of the head whereas placing the head first maximizes the predictability of dependents.","We also show that postponing the head is the optimal strategy to maximize its predictability while bringing it forward is the optimal strategy to maximize the predictability of dependents.","We unravel the advantages of the strategy of maximizing the predictability of the head over maximizing the predictability of dependents.","Our findings shed light on the placements of the head adopted by real languages or emerging in different kinds of experiments."],"url":"http://arxiv.org/abs/2408.16570v1"}
{"created":"2024-08-29 14:35:56","title":"Audio xLSTMs: Learning Self-supervised audio representations with xLSTMs","abstract":"While the transformer has emerged as the eminent neural architecture, several independent lines of research have emerged to address its limitations. Recurrent neural approaches have also observed a lot of renewed interest, including the extended long short-term memory (xLSTM) architecture, which reinvigorates the original LSTM architecture. However, while xLSTMs have shown competitive performance compared to the transformer, their viability for learning self-supervised general-purpose audio representations has not yet been evaluated. This work proposes Audio xLSTM (AxLSTM), an approach to learn audio representations from masked spectrogram patches in a self-supervised setting. Pretrained on the AudioSet dataset, the proposed AxLSTM models outperform comparable self-supervised audio spectrogram transformer (SSAST) baselines by up to 20% in relative performance across a set of ten diverse downstream tasks while having up to 45% fewer parameters.","sentences":["While the transformer has emerged as the eminent neural architecture, several independent lines of research have emerged to address its limitations.","Recurrent neural approaches have also observed a lot of renewed interest, including the extended long short-term memory (xLSTM) architecture, which reinvigorates the original LSTM architecture.","However, while xLSTMs have shown competitive performance compared to the transformer, their viability for learning self-supervised general-purpose audio representations has not yet been evaluated.","This work proposes Audio xLSTM (AxLSTM), an approach to learn audio representations from masked spectrogram patches in a self-supervised setting.","Pretrained on the AudioSet dataset, the proposed AxLSTM models outperform comparable self-supervised audio spectrogram transformer (SSAST) baselines by up to 20% in relative performance across a set of ten diverse downstream tasks while having up to 45% fewer parameters."],"url":"http://arxiv.org/abs/2408.16568v1"}
{"created":"2024-08-29 14:35:14","title":"Identifying Terrain Physical Parameters from Vision -- Towards Physical-Parameter-Aware Locomotion and Navigation","abstract":"Identifying the physical properties of the surrounding environment is essential for robotic locomotion and navigation to deal with non-geometric hazards, such as slippery and deformable terrains. It would be of great benefit for robots to anticipate these extreme physical properties before contact; however, estimating environmental physical parameters from vision is still an open challenge. Animals can achieve this by using their prior experience and knowledge of what they have seen and how it felt. In this work, we propose a cross-modal self-supervised learning framework for vision-based environmental physical parameter estimation, which paves the way for future physical-property-aware locomotion and navigation. We bridge the gap between existing policies trained in simulation and identification of physical terrain parameters from vision. We propose to train a physical decoder in simulation to predict friction and stiffness from multi-modal input. The trained network allows the labeling of real-world images with physical parameters in a self-supervised manner to further train a visual network during deployment, which can densely predict the friction and stiffness from image data. We validate our physical decoder in simulation and the real world using a quadruped ANYmal robot, outperforming an existing baseline method. We show that our visual network can predict the physical properties in indoor and outdoor experiments while allowing fast adaptation to new environments.","sentences":["Identifying the physical properties of the surrounding environment is essential for robotic locomotion and navigation to deal with non-geometric hazards, such as slippery and deformable terrains.","It would be of great benefit for robots to anticipate these extreme physical properties before contact; however, estimating environmental physical parameters from vision is still an open challenge.","Animals can achieve this by using their prior experience and knowledge of what they have seen and how it felt.","In this work, we propose a cross-modal self-supervised learning framework for vision-based environmental physical parameter estimation, which paves the way for future physical-property-aware locomotion and navigation.","We bridge the gap between existing policies trained in simulation and identification of physical terrain parameters from vision.","We propose to train a physical decoder in simulation to predict friction and stiffness from multi-modal input.","The trained network allows the labeling of real-world images with physical parameters in a self-supervised manner to further train a visual network during deployment, which can densely predict the friction and stiffness from image data.","We validate our physical decoder in simulation and the real world using a quadruped ANYmal robot, outperforming an existing baseline method.","We show that our visual network can predict the physical properties in indoor and outdoor experiments while allowing fast adaptation to new environments."],"url":"http://arxiv.org/abs/2408.16567v1"}
{"created":"2024-08-29 14:34:46","title":"Approximation Algorithms for Correlated Knapsack Orienteering","abstract":"We consider the {\\em correlated knapsack orienteering} (CSKO) problem: we are given a travel budget $B$, processing-time budget $W$, finite metric space $(V,d)$ with root $\\rho\\in V$, where each vertex is associated with a job with possibly correlated random size and random reward that become known only when the job completes. Random variables are independent across different vertices. The goal is to compute a $\\rho$-rooted path of length at most $B$, in a possibly adaptive fashion, that maximizes the reward collected from jobs that processed by time $W$. To our knowledge, CSKO has not been considered before, though prior work has considered the uncorrelated problem, {\\em stochastic knapsack orienteering}, and {\\em correlated orienteering}, which features only one budget constraint on the {\\em sum} of travel-time and processing-times.   We show that the {\\em adaptivity gap of CSKO is not a constant, and is at least $\\Omega\\bigl(\\max\\sqrt{\\log{B}},\\sqrt{\\log\\log{W}}\\}\\bigr)$}. Complementing this, we devise {\\em non-adaptive} algorithms that obtain: (a) $O(\\log\\log W)$-approximation in quasi-polytime; and (b) $O(\\log W)$-approximation in polytime. We obtain similar guarantees for CSKO with cancellations, wherein a job can be cancelled before its completion time, foregoing its reward. We also consider the special case of CSKO, wherein job sizes are weighted Bernoulli distributions, and more generally where the distributions are supported on at most two points (2-CSKO). Although weighted Bernoulli distributions suffice to yield an $\\Omega(\\sqrt{\\log\\log B})$ adaptivity-gap lower bound for (uncorrelated) {\\em stochastic orienteering}, we show that they are easy instances for CSKO. We develop non-adaptive algorithms that achieve $O(1)$-approximation in polytime for weighted Bernoulli distributions, and in $(n+\\log B)^{O(\\log W)}$-time for the more general case of 2-CSKO.","sentences":["We consider the {\\em correlated knapsack orienteering} (CSKO) problem: we are given a travel budget $B$, processing-time budget $W$, finite metric space $(V,d)$ with root $\\rho\\in V$, where each vertex is associated with a job with possibly correlated random size and random reward that become known only when the job completes.","Random variables are independent across different vertices.","The goal is to compute a $\\rho$-rooted path of length at most $B$, in a possibly adaptive fashion, that maximizes the reward collected from jobs that processed by time $W$. To our knowledge, CSKO has not been considered before, though prior work has considered the uncorrelated problem, {\\em stochastic knapsack orienteering}, and {\\em correlated orienteering}, which features only one budget constraint on the {\\em sum} of travel-time and processing-times.   ","We show that the {\\em adaptivity gap of CSKO is not a constant, and is at least $\\Omega\\bigl(\\max\\sqrt{\\log{B}},\\sqrt{\\log\\log{W}}\\}\\bigr)$}.","Complementing this, we devise {\\em non-adaptive} algorithms that obtain: (a) $O(\\log\\log W)$-approximation in quasi-polytime; and (b) $O(\\log W)$-approximation in polytime.","We obtain similar guarantees for CSKO with cancellations, wherein a job can be cancelled before its completion time, foregoing its reward.","We also consider the special case of CSKO, wherein job sizes are weighted Bernoulli distributions, and more generally where the distributions are supported on at most two points (2-CSKO).","Although weighted Bernoulli distributions suffice to yield an $\\Omega(\\sqrt{\\log\\log B})$ adaptivity-gap lower bound for (uncorrelated) {\\em stochastic orienteering}, we show that they are easy instances for CSKO.","We develop non-adaptive algorithms that achieve $O(1)$-approximation in polytime for weighted Bernoulli distributions, and in $(n+\\log B)^{O(\\log W)}$-time for the more general case of 2-CSKO."],"url":"http://arxiv.org/abs/2408.16566v1"}
