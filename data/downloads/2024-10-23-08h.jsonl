{"created":"2024-10-22 17:59:57","title":"Altogether: Image Captioning via Re-aligning Alt-text","abstract":"This paper focuses on creating synthetic data to improve the quality of image captions. Existing works typically have two shortcomings. First, they caption images from scratch, ignoring existing alt-text metadata, and second, lack transparency if the captioners' training data (e.g. GPT) is unknown. In this paper, we study a principled approach Altogether based on the key idea to edit and re-align existing alt-texts associated with the images. To generate training data, we perform human annotation where annotators start with the existing alt-text and re-align it to the image content in multiple rounds, consequently constructing captions with rich visual concepts. This differs from prior work that carries out human annotation as a one-time description task solely based on images and annotator knowledge. We train a captioner on this data that generalizes the process of re-aligning alt-texts at scale. Our results show our Altogether approach leads to richer image captions that also improve text-to-image generation and zero-shot image classification tasks.","sentences":["This paper focuses on creating synthetic data to improve the quality of image captions.","Existing works typically have two shortcomings.","First, they caption images from scratch, ignoring existing alt-text metadata, and second, lack transparency if the captioners' training data (e.g. GPT) is unknown.","In this paper, we study a principled approach Altogether based on the key idea to edit and re-align existing alt-texts associated with the images.","To generate training data, we perform human annotation where annotators start with the existing alt-text and re-align it to the image content in multiple rounds, consequently constructing captions with rich visual concepts.","This differs from prior work that carries out human annotation as a one-time description task solely based on images and annotator knowledge.","We train a captioner on this data that generalizes the process of re-aligning alt-texts at scale.","Our results show our Altogether approach leads to richer image captions that also improve text-to-image generation and zero-shot image classification tasks."],"url":"http://arxiv.org/abs/2410.17251v1"}
{"created":"2024-10-22 17:59:56","title":"SpectroMotion: Dynamic 3D Reconstruction of Specular Scenes","abstract":"We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes. Previous methods extending 3DGS to model dynamic scenes have struggled to accurately represent specular surfaces. Our method addresses this limitation by introducing a residual correction technique for accurate surface normal computation during deformation, complemented by a deformable environment map that adapts to time-varying lighting conditions. We implement a coarse-to-fine training strategy that significantly enhances both scene geometry and specular color prediction. We demonstrate that our model outperforms prior methods for view synthesis of scenes containing dynamic specular objects and that it is the only existing 3DGS method capable of synthesizing photorealistic real-world dynamic specular scenes, outperforming state-of-the-art methods in rendering complex, dynamic, and specular scenes.","sentences":["We present SpectroMotion, a novel approach that combines 3D Gaussian Splatting (3DGS) with physically-based rendering (PBR) and deformation fields to reconstruct dynamic specular scenes.","Previous methods extending 3DGS to model dynamic scenes have struggled to accurately represent specular surfaces.","Our method addresses this limitation by introducing a residual correction technique for accurate surface normal computation during deformation, complemented by a deformable environment map that adapts to time-varying lighting conditions.","We implement a coarse-to-fine training strategy that significantly enhances both scene geometry and specular color prediction.","We demonstrate that our model outperforms prior methods for view synthesis of scenes containing dynamic specular objects and that it is the only existing 3DGS method capable of synthesizing photorealistic real-world dynamic specular scenes, outperforming state-of-the-art methods in rendering complex, dynamic, and specular scenes."],"url":"http://arxiv.org/abs/2410.17249v1"}
{"created":"2024-10-22 17:59:56","title":"JMMMU: A Japanese Massive Multi-discipline Multimodal Understanding Benchmark for Culture-aware Evaluation","abstract":"Accelerating research on Large Multimodal Models (LMMs) in non-English languages is crucial for enhancing user experiences across broader populations. In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale Japanese benchmark designed to evaluate LMMs on expert-level tasks based on the Japanese cultural context. To facilitate comprehensive culture-aware evaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA) subset, where the culture-independent subjects (e.g., Math) are selected and translated into Japanese, enabling one-to-one comparison with its English counterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly crafted subjects that reflect Japanese cultural context. Using the CA subset, we observe performance drop in many LMMs when evaluated in Japanese, which is purely attributable to language variation. Using the CS subset, we reveal their inadequate Japanese cultural understanding. Further, by combining both subsets, we identify that some LMMs perform well on the CA subset but not on the CS subset, exposing a shallow understanding of the Japanese language that lacks depth in cultural understanding. We hope this work will not only help advance LMM performance in Japanese but also serve as a guideline to create high-standard, culturally diverse benchmarks for multilingual LMM development. The project page is https://mmmu-japanese-benchmark.github.io/JMMMU/.","sentences":["Accelerating research on Large Multimodal Models (LMMs) in non-English languages is crucial for enhancing user experiences across broader populations.","In this paper, we introduce JMMMU (Japanese MMMU), the first large-scale Japanese benchmark designed to evaluate LMMs on expert-level tasks based on the Japanese cultural context.","To facilitate comprehensive culture-aware evaluation, JMMMU features two complementary subsets: (i) culture-agnostic (CA) subset, where the culture-independent subjects (e.g., Math) are selected and translated into Japanese, enabling one-to-one comparison with its English counterpart MMMU; and (ii) culture-specific (CS) subset, comprising newly crafted subjects that reflect Japanese cultural context.","Using the CA subset, we observe performance drop in many LMMs when evaluated in Japanese, which is purely attributable to language variation.","Using the CS subset, we reveal their inadequate Japanese cultural understanding.","Further, by combining both subsets, we identify that some LMMs perform well on the CA subset but not on the CS subset, exposing a shallow understanding of the Japanese language that lacks depth in cultural understanding.","We hope this work will not only help advance LMM performance in Japanese but also serve as a guideline to create high-standard, culturally diverse benchmarks for multilingual LMM development.","The project page is https://mmmu-japanese-benchmark.github.io/JMMMU/."],"url":"http://arxiv.org/abs/2410.17250v1"}
{"created":"2024-10-22 17:59:55","title":"HyperspectralViTs: Fast and Accurate methane detection on-board satellites","abstract":"On-board processing of hyperspectral data with machine learning models would enable unprecedented amount of autonomy for a wide range of tasks, for example methane detection or mineral identification. Methane is the second most important greenhouse gas contributor to climate change, and it's automated detection on-board of satellites using machine learning models would allow for early warning system and could enable new capabilities such as automated scheduling inside constellations of satellites. Classical methods for methane detection suffer from high false positive rates and previous deep learning models exhibit prohibitive computational requirements. We propose fast and accurate machine learning architectures which support end-to-end training with data of high spectral dimension. We evaluate our models on two tasks related to hyperspectral data processing - methane leak detection and mineral identification. With our proposed general architectures, we improve the F1 score of the previous methane detection state-of-the-art models by more than 27% on a newly created synthetic dataset and by almost 13% on the previously released large benchmark dataset. We also demonstrate that training models on the synthetic dataset improves performance of models finetuned on the dataset of real events by 6.9% in F1 score in contrast with training from scratch. On a newly created dataset for mineral identification, our models provide 3.5% improvement in the F1 score in contrast to the default versions of the models. With our proposed models we improve the inference speed by 85.19% in contrast to previous classical and deep learning approaches by removing the dependency on classically computed features. Namely, one capture from the EMIT sensor can be processed in only 30 seconds on a realistic proxy hardware used on the ION-SCV 004 satellite.","sentences":["On-board processing of hyperspectral data with machine learning models would enable unprecedented amount of autonomy for a wide range of tasks, for example methane detection or mineral identification.","Methane is the second most important greenhouse gas contributor to climate change, and it's automated detection on-board of satellites using machine learning models would allow for early warning system and could enable new capabilities such as automated scheduling inside constellations of satellites.","Classical methods for methane detection suffer from high false positive rates and previous deep learning models exhibit prohibitive computational requirements.","We propose fast and accurate machine learning architectures which support end-to-end training with data of high spectral dimension.","We evaluate our models on two tasks related to hyperspectral data processing - methane leak detection and mineral identification.","With our proposed general architectures, we improve the F1 score of the previous methane detection state-of-the-art models by more than 27% on a newly created synthetic dataset and by almost 13% on the previously released large benchmark dataset.","We also demonstrate that training models on the synthetic dataset improves performance of models finetuned on the dataset of real events by 6.9% in F1 score in contrast with training from scratch.","On a newly created dataset for mineral identification, our models provide 3.5% improvement in the F1 score in contrast to the default versions of the models.","With our proposed models we improve the inference speed by 85.19% in contrast to previous classical and deep learning approaches by removing the dependency on classically computed features.","Namely, one capture from the EMIT sensor can be processed in only 30 seconds on a realistic proxy hardware used on the ION-SCV 004 satellite."],"url":"http://arxiv.org/abs/2410.17248v1"}
{"created":"2024-10-22 17:59:53","title":"PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction","abstract":"In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information. As the idiom \"A picture is worth a thousand words\" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens. This results in significant computational costs, which grow quadratically as input image resolution increases, thereby severely impacting the efficiency of both training and inference. Previous approaches have attempted to reduce the number of image tokens either before or within the early layers of LVLMs. However, these strategies inevitably result in the loss of crucial image information, ultimately diminishing model performance. To address this challenge, we conduct an empirical study revealing that all visual tokens are necessary for LVLMs in the shallow layers, and token redundancy progressively increases in the deeper layers of the model. To this end, we propose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost their efficiency in both training and inference with neglectable performance loss. Specifically, we partition the LVLM into several stages and drop part of the image tokens at the end of each stage with a pre-defined ratio, creating pyramid-like visual tokens across model layers. The dropping is based on a lightweight similarity calculation with a negligible time overhead. Extensive experiments demonstrate that PyramidDrop can achieve a 40% training time and 55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance. Besides, the PyramidDrop could also serve as a plug-and-play strategy for inference acceleration without training, with better performance and lower inference cost than counterparts. We hope that the insights and approach introduced by PyramidDrop will inspire future research to further investigate the role of image tokens in LVLMs.","sentences":["In large vision-language models (LVLMs), images serve as inputs that carry a wealth of information.","As the idiom \"A picture is worth a thousand words\" implies, representing a single image in current LVLMs can require hundreds or even thousands of tokens.","This results in significant computational costs, which grow quadratically as input image resolution increases, thereby severely impacting the efficiency of both training and inference.","Previous approaches have attempted to reduce the number of image tokens either before or within the early layers of LVLMs.","However, these strategies inevitably result in the loss of crucial image information, ultimately diminishing model performance.","To address this challenge, we conduct an empirical study revealing that all visual tokens are necessary for LVLMs in the shallow layers, and token redundancy progressively increases in the deeper layers of the model.","To this end, we propose PyramidDrop, a visual redundancy reduction strategy for LVLMs to boost their efficiency in both training and inference with neglectable performance loss.","Specifically, we partition the LVLM into several stages and drop part of the image tokens at the end of each stage with a pre-defined ratio, creating pyramid-like visual tokens across model layers.","The dropping is based on a lightweight similarity calculation with a negligible time overhead.","Extensive experiments demonstrate that PyramidDrop can achieve a 40% training time and 55% inference FLOPs acceleration of LLaVA-NeXT with comparable performance.","Besides, the PyramidDrop could also serve as a plug-and-play strategy for inference acceleration without training, with better performance and lower inference cost than counterparts.","We hope that the insights and approach introduced by PyramidDrop will inspire future research to further investigate the role of image tokens in LVLMs."],"url":"http://arxiv.org/abs/2410.17247v1"}
{"created":"2024-10-22 17:59:49","title":"Learning Precise, Contact-Rich Manipulation through Uncalibrated Tactile Skins","abstract":"While visuomotor policy learning has advanced robotic manipulation, precisely executing contact-rich tasks remains challenging due to the limitations of vision in reasoning about physical interactions. To address this, recent work has sought to integrate tactile sensing into policy learning. However, many existing approaches rely on optical tactile sensors that are either restricted to recognition tasks or require complex dimensionality reduction steps for policy learning. In this work, we explore learning policies with magnetic skin sensors, which are inherently low-dimensional, highly sensitive, and inexpensive to integrate with robotic platforms. To leverage these sensors effectively, we present the Visuo-Skin (ViSk) framework, a simple approach that uses a transformer-based policy and treats skin sensor data as additional tokens alongside visual information. Evaluated on four complex real-world tasks involving credit card swiping, plug insertion, USB insertion, and bookshelf retrieval, ViSk significantly outperforms both vision-only and optical tactile sensing based policies. Further analysis reveals that combining tactile and visual modalities enhances policy performance and spatial generalization, achieving an average improvement of 27.5% across tasks. https://visuoskin.github.io/","sentences":["While visuomotor policy learning has advanced robotic manipulation, precisely executing contact-rich tasks remains challenging due to the limitations of vision in reasoning about physical interactions.","To address this, recent work has sought to integrate tactile sensing into policy learning.","However, many existing approaches rely on optical tactile sensors that are either restricted to recognition tasks or require complex dimensionality reduction steps for policy learning.","In this work, we explore learning policies with magnetic skin sensors, which are inherently low-dimensional, highly sensitive, and inexpensive to integrate with robotic platforms.","To leverage these sensors effectively, we present the Visuo-Skin (ViSk) framework, a simple approach that uses a transformer-based policy and treats skin sensor data as additional tokens alongside visual information.","Evaluated on four complex real-world tasks involving credit card swiping, plug insertion, USB insertion, and bookshelf retrieval, ViSk significantly outperforms both vision-only and optical tactile sensing based policies.","Further analysis reveals that combining tactile and visual modalities enhances policy performance and spatial generalization, achieving an average improvement of 27.5% across tasks.","https://visuoskin.github.io/"],"url":"http://arxiv.org/abs/2410.17246v1"}
{"created":"2024-10-22 17:59:39","title":"Towards Reliable Evaluation of Behavior Steering Interventions in LLMs","abstract":"Representation engineering methods have recently shown promise for enabling efficient steering of model behavior. However, evaluation pipelines for these methods have primarily relied on subjective demonstrations, instead of quantitative, objective metrics. We aim to take a step towards addressing this issue by advocating for four properties missing from current evaluations: (i) contexts sufficiently similar to downstream tasks should be used for assessing intervention quality; (ii) model likelihoods should be accounted for; (iii) evaluations should allow for standardized comparisons across different target behaviors; and (iv) baseline comparisons should be offered. We introduce an evaluation pipeline grounded in these criteria, offering both a quantitative and visual analysis of how effectively a given method works. We use this pipeline to evaluate two representation engineering methods on how effectively they can steer behaviors such as truthfulness and corrigibility, finding that some interventions are less effective than previously reported.","sentences":["Representation engineering methods have recently shown promise for enabling efficient steering of model behavior.","However, evaluation pipelines for these methods have primarily relied on subjective demonstrations, instead of quantitative, objective metrics.","We aim to take a step towards addressing this issue by advocating for four properties missing from current evaluations: (i) contexts sufficiently similar to downstream tasks should be used for assessing intervention quality; (ii) model likelihoods should be accounted for; (iii) evaluations should allow for standardized comparisons across different target behaviors; and (iv) baseline comparisons should be offered.","We introduce an evaluation pipeline grounded in these criteria, offering both a quantitative and visual analysis of how effectively a given method works.","We use this pipeline to evaluate two representation engineering methods on how effectively they can steer behaviors such as truthfulness and corrigibility, finding that some interventions are less effective than previously reported."],"url":"http://arxiv.org/abs/2410.17245v1"}
{"created":"2024-10-22 17:59:30","title":"Breaking the Memory Barrier: Near Infinite Batch Size Scaling for Contrastive Loss","abstract":"Contrastive loss is a powerful approach for representation learning, where larger batch sizes enhance performance by providing more negative samples to better distinguish between similar and dissimilar data. However, scaling batch sizes is constrained by the quadratic growth in GPU memory consumption, primarily due to the full instantiation of the similarity matrix. To address this, we propose a tile-based computation strategy that partitions the contrastive loss calculation into arbitrary small blocks, avoiding full materialization of the similarity matrix. Furthermore, we introduce a multi-level tiling strategy to leverage the hierarchical structure of distributed systems, employing ring-based communication at the GPU level to optimize synchronization and fused kernels at the CUDA core level to reduce I/O overhead. Experimental results show that the proposed method scales batch sizes to unprecedented levels. For instance, it enables contrastive training of a CLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB without sacrificing any accuracy. Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed. The code will be made publicly available.","sentences":["Contrastive loss is a powerful approach for representation learning, where larger batch sizes enhance performance by providing more negative samples to better distinguish between similar and dissimilar data.","However, scaling batch sizes is constrained by the quadratic growth in GPU memory consumption, primarily due to the full instantiation of the similarity matrix.","To address this, we propose a tile-based computation strategy that partitions the contrastive loss calculation into arbitrary small blocks, avoiding full materialization of the similarity matrix.","Furthermore, we introduce a multi-level tiling strategy to leverage the hierarchical structure of distributed systems, employing ring-based communication at the GPU level to optimize synchronization and fused kernels at the CUDA core level to reduce I/O overhead.","Experimental results show that the proposed method scales batch sizes to unprecedented levels.","For instance, it enables contrastive training of a CLIP-ViT-L/14 model with a batch size of 4M or 12M using 8 or 32 A800 80GB without sacrificing any accuracy.","Compared to SOTA memory-efficient solutions, it achieves a two-order-of-magnitude reduction in memory while maintaining comparable speed.","The code will be made publicly available."],"url":"http://arxiv.org/abs/2410.17243v1"}
{"created":"2024-10-22 17:58:28","title":"LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias","abstract":"We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs. We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations. Both models bypass the 3D inductive biases used in previous methods -- from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) -- addressing novel view synthesis with a fully data-driven approach. While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR. Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality. Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs). Please see our website for more details: https://haian-jin.github.io/projects/LVSM/ .","sentences":["We propose the Large View Synthesis Model (LVSM), a novel transformer-based approach for scalable and generalizable novel view synthesis from sparse-view inputs.","We introduce two architectures: (1) an encoder-decoder LVSM, which encodes input image tokens into a fixed number of 1D latent tokens, functioning as a fully learned scene representation, and decodes novel-view images from them; and (2) a decoder-only LVSM, which directly maps input images to novel-view outputs, completely eliminating intermediate scene representations.","Both models bypass the 3D inductive biases used in previous methods -- from 3D representations (e.g., NeRF, 3DGS) to network designs (e.g., epipolar projections, plane sweeps) -- addressing novel view synthesis with a fully data-driven approach.","While the encoder-decoder model offers faster inference due to its independent latent representation, the decoder-only LVSM achieves superior quality, scalability, and zero-shot generalization, outperforming previous state-of-the-art methods by 1.5 to 3.5 dB PSNR.","Comprehensive evaluations across multiple datasets demonstrate that both LVSM variants achieve state-of-the-art novel view synthesis quality.","Notably, our models surpass all previous methods even with reduced computational resources (1-2 GPUs).","Please see our website for more details: https://haian-jin.github.io/projects/LVSM/ ."],"url":"http://arxiv.org/abs/2410.17242v1"}
{"created":"2024-10-22 17:56:08","title":"SELA: Tree-Search Enhanced LLM Agents for Automated Machine Learning","abstract":"Automated Machine Learning (AutoML) approaches encompass traditional methods that optimize fixed pipelines for model selection and ensembling, as well as newer LLM-based frameworks that autonomously build pipelines. While LLM-based agents have shown promise in automating machine learning tasks, they often generate low-diversity and suboptimal code, even after multiple iterations. To overcome these limitations, we introduce Tree-Search Enhanced LLM Agents (SELA), an innovative agent-based system that leverages Monte Carlo Tree Search (MCTS) to optimize the AutoML process. By representing pipeline configurations as trees, our framework enables agents to conduct experiments intelligently and iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space. This novel approach allows SELA to discover optimal pathways based on experimental feedback, improving the overall quality of the solutions. In an extensive evaluation across 20 machine learning datasets, we compare the performance of traditional and agent-based AutoML methods, demonstrating that SELA achieves a win rate of 65% to 80% against each baseline across all datasets. These results underscore the significant potential of agent-based strategies in AutoML, offering a fresh perspective on tackling complex machine learning challenges.","sentences":["Automated Machine Learning (AutoML) approaches encompass traditional methods that optimize fixed pipelines for model selection and ensembling, as well as newer LLM-based frameworks that autonomously build pipelines.","While LLM-based agents have shown promise in automating machine learning tasks, they often generate low-diversity and suboptimal code, even after multiple iterations.","To overcome these limitations, we introduce Tree-Search Enhanced LLM Agents (SELA), an innovative agent-based system that leverages Monte Carlo Tree Search (MCTS) to optimize the AutoML process.","By representing pipeline configurations as trees, our framework enables agents to conduct experiments intelligently and iteratively refine their strategies, facilitating a more effective exploration of the machine learning solution space.","This novel approach allows SELA to discover optimal pathways based on experimental feedback, improving the overall quality of the solutions.","In an extensive evaluation across 20 machine learning datasets, we compare the performance of traditional and agent-based AutoML methods, demonstrating that SELA achieves a win rate of 65% to 80% against each baseline across all datasets.","These results underscore the significant potential of agent-based strategies in AutoML, offering a fresh perspective on tackling complex machine learning challenges."],"url":"http://arxiv.org/abs/2410.17238v1"}
{"created":"2024-10-22 17:54:45","title":"Large Language Models Empowered Personalized Web Agents","abstract":"Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience. Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents. Despite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g., user profiles and historical Web behaviors) in assisting the understanding of users' personalized instructions and executing customized actions. To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution. To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks. Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task. PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors. Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization. Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB.","sentences":["Web agents have emerged as a promising direction to automate Web task completion based on user instructions, significantly enhancing user experience.","Recently, Web agents have evolved from traditional agents to Large Language Models (LLMs)-based Web agents.","Despite their success, existing LLM-based Web agents overlook the importance of personalized data (e.g., user profiles and historical Web behaviors) in assisting the understanding of users' personalized instructions and executing customized actions.","To overcome the limitation, we first formulate the task of LLM-empowered personalized Web agents, which integrate personalized data and user instructions to personalize instruction comprehension and action execution.","To address the absence of a comprehensive evaluation benchmark, we construct a Personalized Web Agent Benchmark (PersonalWAB), featuring user instructions, personalized user data, Web functions, and two evaluation paradigms across three personalized Web tasks.","Moreover, we propose a Personalized User Memory-enhanced Alignment (PUMA) framework to adapt LLMs to the personalized Web agent task.","PUMA utilizes a memory bank with a task-specific retrieval strategy to filter relevant historical Web behaviors.","Based on the behaviors, PUMA then aligns LLMs for personalized action execution through fine-tuning and direct preference optimization.","Extensive experiments validate the superiority of PUMA over existing Web agents on PersonalWAB."],"url":"http://arxiv.org/abs/2410.17236v1"}
{"created":"2024-10-22 17:54:03","title":"Fine-Tuning Large Language Models to Appropriately Abstain with Semantic Entropy","abstract":"Large Language Models (LLMs) are known to hallucinate, whereby they generate plausible but inaccurate text. This phenomenon poses significant risks in critical applications, such as medicine or law, necessitating robust hallucination mitigation strategies. While recent works have proposed fine-tuning methods to teach LLMs to abstain from answering questions beyond their knowledge or capabilities, these methods rely on the existence of ground-truth labels or are limited to short-form responses. To address these limitations, we propose fine-tuning using semantic entropy, an uncertainty measure derived from introspection into the model which does not require external labels. We demonstrate that our approach matches or outperforms models fine-tuned using prior work and achieves strong performance for both short and long-form generations on a range of datasets.","sentences":["Large Language Models (LLMs) are known to hallucinate, whereby they generate plausible but inaccurate text.","This phenomenon poses significant risks in critical applications, such as medicine or law, necessitating robust hallucination mitigation strategies.","While recent works have proposed fine-tuning methods to teach LLMs to abstain from answering questions beyond their knowledge or capabilities, these methods rely on the existence of ground-truth labels or are limited to short-form responses.","To address these limitations, we propose fine-tuning using semantic entropy, an uncertainty measure derived from introspection into the model which does not require external labels.","We demonstrate that our approach matches or outperforms models fine-tuned using prior work and achieves strong performance for both short and long-form generations on a range of datasets."],"url":"http://arxiv.org/abs/2410.17234v1"}
{"created":"2024-10-22 17:53:34","title":"Few-shot In-Context Preference Learning Using Large Language Models","abstract":"Designing reward functions is a core component of reinforcement learning but can be challenging for truly complex behavior. Reinforcement Learning from Human Feedback (RLHF) has been used to alleviate this challenge by replacing a hand-coded reward function with a reward function learned from preferences. However, it can be exceedingly inefficient to learn these rewards as they are often learned tabula rasa. We investigate whether Large Language Models (LLMs) can reduce this query inefficiency by converting an iterative series of human preferences into code representing the rewards. We propose In-Context Preference Learning (ICPL), a method that uses the grounding of an LLM to accelerate learning reward functions from preferences. ICPL takes the environment context and task description, synthesizes a set of reward functions, and then repeatedly updates the reward functions using human rankings of videos of the resultant policies. Using synthetic preferences, we demonstrate that ICPL is orders of magnitude more efficient than RLHF and is even competitive with methods that use ground-truth reward functions instead of preferences. Finally, we perform a series of human preference-learning trials and observe that ICPL extends beyond synthetic settings and can work effectively with humans-in-the-loop. Additional information and videos are provided at https://sites.google.com/view/few-shot-icpl/home.","sentences":["Designing reward functions is a core component of reinforcement learning but can be challenging for truly complex behavior.","Reinforcement Learning from Human Feedback (RLHF) has been used to alleviate this challenge by replacing a hand-coded reward function with a reward function learned from preferences.","However, it can be exceedingly inefficient to learn these rewards as they are often learned tabula rasa.","We investigate whether Large Language Models (LLMs) can reduce this query inefficiency by converting an iterative series of human preferences into code representing the rewards.","We propose In-Context Preference Learning (ICPL), a method that uses the grounding of an LLM to accelerate learning reward functions from preferences.","ICPL takes the environment context and task description, synthesizes a set of reward functions, and then repeatedly updates the reward functions using human rankings of videos of the resultant policies.","Using synthetic preferences, we demonstrate that ICPL is orders of magnitude more efficient than RLHF and is even competitive with methods that use ground-truth reward functions instead of preferences.","Finally, we perform a series of human preference-learning trials and observe that ICPL extends beyond synthetic settings and can work effectively with humans-in-the-loop.","Additional information and videos are provided at https://sites.google.com/view/few-shot-icpl/home."],"url":"http://arxiv.org/abs/2410.17233v1"}
{"created":"2024-10-22 17:51:23","title":"Optimal Robust Estimation under Local and Global Corruptions: Stronger Adversary and Smaller Error","abstract":"Algorithmic robust statistics has traditionally focused on the contamination model where a small fraction of the samples are arbitrarily corrupted. We consider a recent contamination model that combines two kinds of corruptions: (i) small fraction of arbitrary outliers, as in classical robust statistics, and (ii) local perturbations, where samples may undergo bounded shifts on average. While each noise model is well understood individually, the combined contamination model poses new algorithmic challenges, with only partial results known. Existing efficient algorithms are limited in two ways: (i) they work only for a weak notion of local perturbations, and (ii) they obtain suboptimal error for isotropic subgaussian distributions (among others). The latter limitation led [NGS24, COLT'24] to hypothesize that improving the error might, in fact, be computationally hard. Perhaps surprisingly, we show that information theoretically optimal error can indeed be achieved in polynomial time, under an even \\emph{stronger} local perturbation model (the sliced-Wasserstein metric as opposed to the Wasserstein metric). Notably, our analysis reveals that the entire family of stability-based robust mean estimators continues to work optimally in a black-box manner for the combined contamination model. This generalization is particularly useful in real-world scenarios where the specific form of data corruption is not known in advance. We also present efficient algorithms for distribution learning and principal component analysis in the combined contamination model.","sentences":["Algorithmic robust statistics has traditionally focused on the contamination model where a small fraction of the samples are arbitrarily corrupted.","We consider a recent contamination model that combines two kinds of corruptions: (i) small fraction of arbitrary outliers, as in classical robust statistics, and (ii) local perturbations, where samples may undergo bounded shifts on average.","While each noise model is well understood individually, the combined contamination model poses new algorithmic challenges, with only partial results known.","Existing efficient algorithms are limited in two ways: (i) they work only for a weak notion of local perturbations, and (ii) they obtain suboptimal error for isotropic subgaussian distributions (among others).","The latter limitation led [NGS24, COLT'24] to hypothesize that improving the error might, in fact, be computationally hard.","Perhaps surprisingly, we show that information theoretically optimal error can indeed be achieved in polynomial time, under an even \\emph{stronger} local perturbation model (the sliced-Wasserstein metric as opposed to the Wasserstein metric).","Notably, our analysis reveals that the entire family of stability-based robust mean estimators continues to work optimally in a black-box manner for the combined contamination model.","This generalization is particularly useful in real-world scenarios where the specific form of data corruption is not known in advance.","We also present efficient algorithms for distribution learning and principal component analysis in the combined contamination model."],"url":"http://arxiv.org/abs/2410.17230v1"}
{"created":"2024-10-22 17:51:13","title":"Responsibility in a Multi-Value Strategic Setting","abstract":"Responsibility is a key notion in multi-agent systems and in creating safe, reliable and ethical AI. However, most previous work on responsibility has only considered responsibility for single outcomes. In this paper we present a model for responsibility attribution in a multi-agent, multi-value setting. We also expand our model to cover responsibility anticipation, demonstrating how considerations of responsibility can help an agent to select strategies that are in line with its values. In particular we show that non-dominated regret-minimising strategies reliably minimise an agent's expected degree of responsibility.","sentences":["Responsibility is a key notion in multi-agent systems and in creating safe, reliable and ethical AI.","However, most previous work on responsibility has only considered responsibility for single outcomes.","In this paper we present a model for responsibility attribution in a multi-agent, multi-value setting.","We also expand our model to cover responsibility anticipation, demonstrating how considerations of responsibility can help an agent to select strategies that are in line with its values.","In particular we show that non-dominated regret-minimising strategies reliably minimise an agent's expected degree of responsibility."],"url":"http://arxiv.org/abs/2410.17229v1"}
{"created":"2024-10-22 17:48:36","title":"Parallel Cluster-BFS and Applications to Shortest Paths","abstract":"Breadth-first Search (BFS) is one of the most important graph processing subroutines, especially to compute the unweighted distance. Many applications may require running BFS from multiple sources. Sequentially, when running BFS on a cluster of nearby vertices, a known optimization is to use bit-parallelism. Given a subset of vertices with size $k$ and the distance between any pair of them is no more than $d$, BFS can be applied to all of them in a total work of $O(dk/w+1)$, where $w$ is the length of a word in bits. We will refer to this approach as cluster-BFS (C-BFS). Such an approach has been studied and shown effective both in theory and in practice in the sequential setting. However, it remains unknown how this can be combined with thread-level parallelism for C-BFS.   In this paper, we focus on designing efficient parallel C-BFS based on BFS to answer unweighted distance queries. Our solution combines the strengths of bit-level parallelism and thread-level parallelism, and achieves significant speedup over the plain sequential solution. We also apply our algorithm to real-world applications. In particular, we identified another application (landmark-labeling for the approximate distance oracle) that can take advantage of parallel C-BFS. Under the same memory budget, our new solution improves accuracy and/or time on all the 18 tested graphs.","sentences":["Breadth-first Search (BFS) is one of the most important graph processing subroutines, especially to compute the unweighted distance.","Many applications may require running BFS from multiple sources.","Sequentially, when running BFS on a cluster of nearby vertices, a known optimization is to use bit-parallelism.","Given a subset of vertices with size $k$ and the distance between any pair of them is no more than $d$, BFS can be applied to all of them in a total work of $O(dk/w+1)$, where $w$ is the length of a word in bits.","We will refer to this approach as cluster-BFS (C-BFS).","Such an approach has been studied and shown effective both in theory and in practice in the sequential setting.","However, it remains unknown how this can be combined with thread-level parallelism for C-BFS.   ","In this paper, we focus on designing efficient parallel C-BFS based on BFS to answer unweighted distance queries.","Our solution combines the strengths of bit-level parallelism and thread-level parallelism, and achieves significant speedup over the plain sequential solution.","We also apply our algorithm to real-world applications.","In particular, we identified another application (landmark-labeling for the approximate distance oracle) that can take advantage of parallel C-BFS.","Under the same memory budget, our new solution improves accuracy and/or time on all the 18 tested graphs."],"url":"http://arxiv.org/abs/2410.17226v1"}
{"created":"2024-10-22 17:47:05","title":"Dhoroni: Exploring Bengali Climate Change and Environmental Views with a Multi-Perspective News Dataset and Natural Language Processing","abstract":"Climate change poses critical challenges globally, disproportionately affecting low-income countries that often lack resources and linguistic representation on the international stage. Despite Bangladesh's status as one of the most vulnerable nations to climate impacts, research gaps persist in Bengali-language studies related to climate change and NLP. To address this disparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and environmental news dataset, comprising a 2300 annotated Bangla news articles, offering multiple perspectives such as political influence, scientific/statistical data, authenticity, stance detection, and stakeholder involvement. Furthermore, we present an in-depth exploratory analysis of Dhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family for climate and environmental opinion detection in Bangla, fine-tuned on our dataset. This research contributes significantly to enhancing accessibility and analysis of climate discourse in Bengali (Bangla), addressing crucial communication and research gaps in climate-impacted regions like Bangladesh with 180 million people.","sentences":["Climate change poses critical challenges globally, disproportionately affecting low-income countries that often lack resources and linguistic representation on the international stage.","Despite Bangladesh's status as one of the most vulnerable nations to climate impacts, research gaps persist in Bengali-language studies related to climate change and NLP.","To address this disparity, we introduce Dhoroni, a novel Bengali (Bangla) climate change and environmental news dataset, comprising a 2300 annotated Bangla news articles, offering multiple perspectives such as political influence, scientific/statistical data, authenticity, stance detection, and stakeholder involvement.","Furthermore, we present an in-depth exploratory analysis of Dhoroni and introduce BanglaBERT-Dhoroni family, a novel baseline model family for climate and environmental opinion detection in Bangla, fine-tuned on our dataset.","This research contributes significantly to enhancing accessibility and analysis of climate discourse in Bengali (Bangla), addressing crucial communication and research gaps in climate-impacted regions like Bangladesh with 180 million people."],"url":"http://arxiv.org/abs/2410.17225v1"}
{"created":"2024-10-22 17:45:47","title":"Context-aware Prompt Tuning: Advancing In-Context Learning with Adversarial Methods","abstract":"Fine-tuning Large Language Models (LLMs) typically involves updating at least a few billions of parameters. A more parameter-efficient approach is Prompt Tuning (PT), which updates only a few learnable tokens, and differently, In-Context Learning (ICL) adapts the model to a new task by simply including examples in the input without any training. When applying optimization-based methods, such as fine-tuning and PT for few-shot learning, the model is specifically adapted to the small set of training examples, whereas ICL leaves the model unchanged. This distinction makes traditional learning methods more prone to overfitting; in contrast, ICL is less sensitive to the few-shot scenario. While ICL is not prone to overfitting, it does not fully extract the information that exists in the training examples. This work introduces Context-aware Prompt Tuning (CPT), a method inspired by ICL, PT, and adversarial attacks. We build on the ICL strategy of concatenating examples before the input, but we extend this by PT-like learning, refining the context embedding through iterative optimization to extract deeper insights from the training examples. We carefully modify specific context tokens, considering the unique structure of input and output formats. Inspired by adversarial attacks, we adjust the input based on the labels present in the context, focusing on minimizing, rather than maximizing, the loss. Moreover, we apply a projected gradient descent algorithm to keep token embeddings close to their original values, under the assumption that the user-provided data is inherently valuable. Our method has been shown to achieve superior accuracy across multiple classification tasks using various LLM models.","sentences":["Fine-tuning Large Language Models (LLMs) typically involves updating at least a few billions of parameters.","A more parameter-efficient approach is Prompt Tuning (PT), which updates only a few learnable tokens, and differently, In-Context Learning (ICL) adapts the model to a new task by simply including examples in the input without any training.","When applying optimization-based methods, such as fine-tuning and PT for few-shot learning, the model is specifically adapted to the small set of training examples, whereas ICL leaves the model unchanged.","This distinction makes traditional learning methods more prone to overfitting; in contrast, ICL is less sensitive to the few-shot scenario.","While ICL is not prone to overfitting, it does not fully extract the information that exists in the training examples.","This work introduces Context-aware Prompt Tuning (CPT), a method inspired by ICL, PT, and adversarial attacks.","We build on the ICL strategy of concatenating examples before the input, but we extend this by PT-like learning, refining the context embedding through iterative optimization to extract deeper insights from the training examples.","We carefully modify specific context tokens, considering the unique structure of input and output formats.","Inspired by adversarial attacks, we adjust the input based on the labels present in the context, focusing on minimizing, rather than maximizing, the loss.","Moreover, we apply a projected gradient descent algorithm to keep token embeddings close to their original values, under the assumption that the user-provided data is inherently valuable.","Our method has been shown to achieve superior accuracy across multiple classification tasks using various LLM models."],"url":"http://arxiv.org/abs/2410.17222v1"}
{"created":"2024-10-22 17:45:45","title":"Scalable spectral representations for network multiagent control","abstract":"Network Markov Decision Processes (MDPs), a popular model for multi-agent control, pose a significant challenge to efficient learning due to the exponential growth of the global state-action space with the number of agents. In this work, utilizing the exponential decay property of network dynamics, we first derive scalable spectral local representations for network MDPs, which induces a network linear subspace for the local $Q$-function of each agent. Building on these local spectral representations, we design a scalable algorithmic framework for continuous state-action network MDPs, and provide end-to-end guarantees for the convergence of our algorithm. Empirically, we validate the effectiveness of our scalable representation-based approach on two benchmark problems, and demonstrate the advantages of our approach over generic function approximation approaches to representing the local $Q$-functions.","sentences":["Network Markov Decision Processes (MDPs), a popular model for multi-agent control, pose a significant challenge to efficient learning due to the exponential growth of the global state-action space with the number of agents.","In this work, utilizing the exponential decay property of network dynamics, we first derive scalable spectral local representations for network MDPs, which induces a network linear subspace for the local $Q$-function of each agent.","Building on these local spectral representations, we design a scalable algorithmic framework for continuous state-action network MDPs, and provide end-to-end guarantees for the convergence of our algorithm.","Empirically, we validate the effectiveness of our scalable representation-based approach on two benchmark problems, and demonstrate the advantages of our approach over generic function approximation approaches to representing the local $Q$-functions."],"url":"http://arxiv.org/abs/2410.17221v1"}
{"created":"2024-10-22 17:43:39","title":"Creativity in AI: Progresses and Challenges","abstract":"Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition. Machine creativity on the other hand has been a long-standing challenge. With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities. Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges. In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity. Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations. We also discuss key questions concerning copyright and authorship issues with generative models. Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity. Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology.","sentences":["Creativity is the ability to produce novel, useful, and surprising ideas, and has been widely studied as a crucial aspect of human cognition.","Machine creativity on the other hand has been a long-standing challenge.","With the rise of advanced generative AI, there has been renewed interest and debate regarding AI's creative capabilities.","Therefore, it is imperative to revisit the state of creativity in AI and identify key progresses and remaining challenges.","In this work, we survey leading works studying the creative capabilities of AI systems, focusing on creative problem-solving, linguistic, artistic, and scientific creativity.","Our review suggests that while the latest AI models are largely capable of producing linguistically and artistically creative outputs such as poems, images, and musical pieces, they struggle with tasks that require creative problem-solving, abstract thinking and compositionality and their generations suffer from a lack of diversity, originality, long-range incoherence and hallucinations.","We also discuss key questions concerning copyright and authorship issues with generative models.","Furthermore, we highlight the need for a comprehensive evaluation of creativity that is process-driven and considers several dimensions of creativity.","Finally, we propose future research directions to improve the creativity of AI outputs, drawing inspiration from cognitive science and psychology."],"url":"http://arxiv.org/abs/2410.17218v1"}
{"created":"2024-10-22 17:41:14","title":"Hierarchical Upper Confidence Bounds for Constrained Online Learning","abstract":"The multi-armed bandit (MAB) problem is a foundational framework in sequential decision-making under uncertainty, extensively studied for its applications in areas such as clinical trials, online advertising, and resource allocation. Traditional MAB formulations, however, do not adequately capture scenarios where decisions are structured hierarchically, involve multi-level constraints, or feature context-dependent action spaces. In this paper, we introduce the hierarchical constrained bandits (HCB) framework, which extends the contextual bandit problem to incorporate hierarchical decision structures and multi-level constraints. We propose the hierarchical constrained upper confidence bound (HC-UCB) algorithm, designed to address the complexities of the HCB problem by leveraging confidence bounds within a hierarchical setting. Our theoretical analysis establishes sublinear regret bounds for HC-UCB and provides high-probability guarantees for constraint satisfaction at all hierarchical levels. Furthermore, we derive a minimax lower bound on the regret for the HCB problem, demonstrating the near-optimality of our algorithm. The results are significant for real-world applications where decision-making processes are inherently hierarchical and constrained, offering a robust and efficient solution that balances exploration and exploitation across multiple levels of decision-making.","sentences":["The multi-armed bandit (MAB) problem is a foundational framework in sequential decision-making under uncertainty, extensively studied for its applications in areas such as clinical trials, online advertising, and resource allocation.","Traditional MAB formulations, however, do not adequately capture scenarios where decisions are structured hierarchically, involve multi-level constraints, or feature context-dependent action spaces.","In this paper, we introduce the hierarchical constrained bandits (HCB) framework, which extends the contextual bandit problem to incorporate hierarchical decision structures and multi-level constraints.","We propose the hierarchical constrained upper confidence bound (HC-UCB) algorithm, designed to address the complexities of the HCB problem by leveraging confidence bounds within a hierarchical setting.","Our theoretical analysis establishes sublinear regret bounds for HC-UCB and provides high-probability guarantees for constraint satisfaction at all hierarchical levels.","Furthermore, we derive a minimax lower bound on the regret for the HCB problem, demonstrating the near-optimality of our algorithm.","The results are significant for real-world applications where decision-making processes are inherently hierarchical and constrained, offering a robust and efficient solution that balances exploration and exploitation across multiple levels of decision-making."],"url":"http://arxiv.org/abs/2410.17216v1"}
{"created":"2024-10-22 17:40:32","title":"MiniPLM: Knowledge Distillation for Pre-Training Language Models","abstract":"Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs. While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness. Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data. To address these issues, we propose MiniPLM, a KD framework for pre-training LMs by refining the training data distribution with the teacher's knowledge. For efficiency, MiniPLM performs offline teacher LM inference, allowing KD for multiple student LMs without adding training-time costs. For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families. For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the difficulty and diversity of the training data, helping student LMs acquire versatile and sophisticated knowledge. Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 widely used downstream tasks, improves the language modeling capabilities, and reduces pre-training computation. The benefit of MiniPLM extends to large pre-training scales, evidenced by the extrapolation of the scaling curves. Further analysis reveals that MiniPLM supports KD across model families and enhances the utilization of pre-training data. Our model, code, and data are available at https://github.com/thu-coai/MiniPLM.","sentences":["Knowledge distillation (KD) is widely used to train small, high-performing student language models (LMs) using large teacher LMs.","While effective in fine-tuning, KD during pre-training faces challenges in efficiency, flexibility, and effectiveness.","Existing methods either incur high computational costs due to online teacher inference, require tokenization matching between teacher and student LMs, or risk losing the difficulty and diversity of the teacher-generated training data.","To address these issues, we propose MiniPLM, a KD framework for pre-training LMs by refining the training data distribution with the teacher's knowledge.","For efficiency, MiniPLM performs offline teacher LM inference, allowing KD for multiple student LMs without adding training-time costs.","For flexibility, MiniPLM operates solely on the training corpus, enabling KD across model families.","For effectiveness, MiniPLM leverages the differences between large and small LMs to enhance the difficulty and diversity of the training data, helping student LMs acquire versatile and sophisticated knowledge.","Extensive experiments demonstrate that MiniPLM boosts the student LMs' performance on 9 widely used downstream tasks, improves the language modeling capabilities, and reduces pre-training computation.","The benefit of MiniPLM extends to large pre-training scales, evidenced by the extrapolation of the scaling curves.","Further analysis reveals that MiniPLM supports KD across model families and enhances the utilization of pre-training data.","Our model, code, and data are available at https://github.com/thu-coai/MiniPLM."],"url":"http://arxiv.org/abs/2410.17215v1"}
{"created":"2024-10-22 17:34:59","title":"Exploring Possibilities of AI-Powered Legal Assistance in Bangladesh through Large Language Modeling","abstract":"Purpose: Bangladesh's legal system struggles with major challenges like delays, complexity, high costs, and millions of unresolved cases, which deter many from pursuing legal action due to lack of knowledge or financial constraints. This research seeks to develop a specialized Large Language Model (LLM) to assist in the Bangladeshi legal system. Methods: We created UKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and scraping data on various legal acts. We fine-tuned the GPT-2 model on this dataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance in English. Results: The model was rigorously evaluated using semantic assessments, including case studies supported by expert opinions. The evaluation provided promising results, demonstrating the potential for the model to assist in legal matters within Bangladesh. Conclusion: Our work represents the first structured effort toward building an AI-based legal assistant for Bangladesh. While the results are encouraging, further refinements are necessary to improve the model's accuracy, credibility, and safety. This is a significant step toward creating a legal AI capable of serving the needs of a population of 180 million.","sentences":["Purpose: Bangladesh's legal system struggles with major challenges like delays, complexity, high costs, and millions of unresolved cases, which deter many from pursuing legal action due to lack of knowledge or financial constraints.","This research seeks to develop a specialized Large Language Model (LLM) to assist in the Bangladeshi legal system.","Methods: We created UKIL-DB-EN, an English corpus of Bangladeshi legal documents, by collecting and scraping data on various legal acts.","We fine-tuned the GPT-2 model on this dataset to develop GPT2-UKIL-EN, an LLM focused on providing legal assistance in English.","Results:","The model was rigorously evaluated using semantic assessments, including case studies supported by expert opinions.","The evaluation provided promising results, demonstrating the potential for the model to assist in legal matters within Bangladesh.","Conclusion: Our work represents the first structured effort toward building an AI-based legal assistant for Bangladesh.","While the results are encouraging, further refinements are necessary to improve the model's accuracy, credibility, and safety.","This is a significant step toward creating a legal AI capable of serving the needs of a population of 180 million."],"url":"http://arxiv.org/abs/2410.17210v1"}
{"created":"2024-10-22 17:31:37","title":"Audio-to-Score Conversion Model Based on Whisper methodology","abstract":"This thesis develops a Transformer model based on Whisper, which extracts melodies and chords from music audio and records them into ABC notation. A comprehensive data processing workflow is customized for ABC notation, including data cleansing, formatting, and conversion, and a mutation mechanism is implemented to increase the diversity and quality of training data. This thesis innovatively introduces the \"Orpheus' Score\", a custom notation system that converts music information into tokens, designs a custom vocabulary library, and trains a corresponding custom tokenizer. Experiments show that compared to traditional algorithms, the model has significantly improved accuracy and performance. While providing a convenient audio-to-score tool for music enthusiasts, this work also provides new ideas and tools for research in music information processing.","sentences":["This thesis develops a Transformer model based on Whisper, which extracts melodies and chords from music audio and records them into ABC notation.","A comprehensive data processing workflow is customized for ABC notation, including data cleansing, formatting, and conversion, and a mutation mechanism is implemented to increase the diversity and quality of training data.","This thesis innovatively introduces the \"Orpheus' Score\", a custom notation system that converts music information into tokens, designs a custom vocabulary library, and trains a corresponding custom tokenizer.","Experiments show that compared to traditional algorithms, the model has significantly improved accuracy and performance.","While providing a convenient audio-to-score tool for music enthusiasts, this work also provides new ideas and tools for research in music information processing."],"url":"http://arxiv.org/abs/2410.17209v1"}
{"created":"2024-10-22 17:28:50","title":"On Recurrence Relations of Multi-dimensional Sequences","abstract":"In this paper, we present a new algorithm for computing the linear recurrence relations of multi-dimensional sequences. Existing algorithms for computing these relations arise in computational algebra and include constructing structured matrices and computing their kernels. The challenging problem is to reduce the size of the corresponding matrices. In this paper, we show how to convert the problem of computing recurrence relations of multi-dimensional sequences into computing the orthogonal of certain ideals as subvector spaces of the dual module of polynomials. We propose an algorithm using efficient dual module computation algorithms. We present a complexity bound for this algorithm, carry on experiments using Maple implementation, and discuss the cases when using this algorithm is much faster than the existing approaches.","sentences":["In this paper, we present a new algorithm for computing the linear recurrence relations of multi-dimensional sequences.","Existing algorithms for computing these relations arise in computational algebra and include constructing structured matrices and computing their kernels.","The challenging problem is to reduce the size of the corresponding matrices.","In this paper, we show how to convert the problem of computing recurrence relations of multi-dimensional sequences into computing the orthogonal of certain ideals as subvector spaces of the dual module of polynomials.","We propose an algorithm using efficient dual module computation algorithms.","We present a complexity bound for this algorithm, carry on experiments using Maple implementation, and discuss the cases when using this algorithm is much faster than the existing approaches."],"url":"http://arxiv.org/abs/2410.17208v1"}
{"created":"2024-10-22 17:27:16","title":"EPContrast: Effective Point-level Contrastive Learning for Large-scale Point Cloud Understanding","abstract":"The acquisition of inductive bias through point-level contrastive learning holds paramount significance in point cloud pre-training. However, the square growth in computational requirements with the scale of the point cloud poses a substantial impediment to the practical deployment and execution. To address this challenge, this paper proposes an Effective Point-level Contrastive Learning method for large-scale point cloud understanding dubbed \\textbf{EPContrast}, which consists of AGContrast and ChannelContrast. In practice, AGContrast constructs positive and negative pairs based on asymmetric granularity embedding, while ChannelContrast imposes contrastive supervision between channel feature maps. EPContrast offers point-level contrastive loss while concurrently mitigating the computational resource burden. The efficacy of EPContrast is substantiated through comprehensive validation on S3DIS and ScanNetV2, encompassing tasks such as semantic segmentation, instance segmentation, and object detection. In addition, rich ablation experiments demonstrate remarkable bias induction capabilities under label-efficient and one-epoch training settings.","sentences":["The acquisition of inductive bias through point-level contrastive learning holds paramount significance in point cloud pre-training.","However, the square growth in computational requirements with the scale of the point cloud poses a substantial impediment to the practical deployment and execution.","To address this challenge, this paper proposes an Effective Point-level Contrastive Learning method for large-scale point cloud understanding dubbed \\textbf{EPContrast}, which consists of AGContrast and ChannelContrast.","In practice, AGContrast constructs positive and negative pairs based on asymmetric granularity embedding, while ChannelContrast imposes contrastive supervision between channel feature maps.","EPContrast offers point-level contrastive loss while concurrently mitigating the computational resource burden.","The efficacy of EPContrast is substantiated through comprehensive validation on S3DIS and ScanNetV2, encompassing tasks such as semantic segmentation, instance segmentation, and object detection.","In addition, rich ablation experiments demonstrate remarkable bias induction capabilities under label-efficient and one-epoch training settings."],"url":"http://arxiv.org/abs/2410.17207v1"}
{"created":"2024-10-22 17:21:28","title":"Vulnerability anti-patterns in Solidity: Increasing smart contracts security by reducing false alarms","abstract":"Turing completeness has made Ethereum smart contracts attractive to blockchain developers and attackers alike. To increase code security, many tools can now spot most known vulnerabilities$-$at the cost of production efficiency. Recent studies show false-positive ratios over 99% in state-of-the-art technologies: this makes them impractical for use in industry and have raised questions on the direction of academic research. In this work we show how integrating and extending current analyses is not only feasible, but also a next logical step in smart-contract security. We propose light-weight static checks on the morphology and dynamics of Solidity code, stemming from a developer-centric notion of vulnerability, that we use to verify the output of other tools, flag potential false alarms, and suggest verifications. Besides technical details we implemented an open-source prototype. For three top-10 vulnerabilities it flags 324 warnings of other tools as false-positives, in 60 verified de-duplicated smart contracts selected from the blockchain by the presence of true (and false) vulnerabilities. This amounts to a 92%- to 100%-reduction in the number of false-positives for these vulnerabilities.","sentences":["Turing completeness has made Ethereum smart contracts attractive to blockchain developers and attackers alike.","To increase code security, many tools can now spot most known vulnerabilities$-$at the cost of production efficiency.","Recent studies show false-positive ratios over 99% in state-of-the-art technologies: this makes them impractical for use in industry and have raised questions on the direction of academic research.","In this work we show how integrating and extending current analyses is not only feasible, but also a next logical step in smart-contract security.","We propose light-weight static checks on the morphology and dynamics of Solidity code, stemming from a developer-centric notion of vulnerability, that we use to verify the output of other tools, flag potential false alarms, and suggest verifications.","Besides technical details we implemented an open-source prototype.","For three top-10 vulnerabilities it flags 324 warnings of other tools as false-positives, in 60 verified de-duplicated smart contracts selected from the blockchain by the presence of true (and false) vulnerabilities.","This amounts to a 92%- to 100%-reduction in the number of false-positives for these vulnerabilities."],"url":"http://arxiv.org/abs/2410.17204v1"}
{"created":"2024-10-22 17:18:38","title":"One-shot Multiple Access Channel Simulation","abstract":"We consider the problem of shared randomness-assisted multiple access channel (MAC) simulation for product inputs and characterize the one-shot communication cost region via almost-matching inner and outer bounds in terms of the smooth max-information of the channel, featuring auxiliary random variables of bounded size. The achievability relies on a rejection-sampling algorithm to simulate an auxiliary channel between each sender and the decoder, and producing the final output based on the output of these intermediate channels. The converse follows via information-spectrum based arguments. To bound the cardinality of the auxiliary random variables, we employ the perturbation method from [Anantharam et al., IEEE Trans. Inf. Theory (2019)] in the one-shot setting. For the asymptotic setting and vanishing errors, our result expands to a tight single-letter rate characterization and consequently extends a special case of the simulation results of [Kurri et al., IEEE Trans. Inf. Theory (2022)] for fixed, independent and identically distributed (iid) product inputs to universal simulation for any product inputs. We broaden our discussion into the quantum realm by studying feedback simulation of quantum-to-classical (QC) MACs with product measurements [Atif et al., IEEE Trans. Inf. Theory (2022)]. For fixed product inputs and with shared randomness assistance, we give a quasi tight one-shot communication cost region with corresponding single-letter asymptotic iid expansion.","sentences":["We consider the problem of shared randomness-assisted multiple access channel (MAC) simulation for product inputs and characterize the one-shot communication cost region via almost-matching inner and outer bounds in terms of the smooth max-information of the channel, featuring auxiliary random variables of bounded size.","The achievability relies on a rejection-sampling algorithm to simulate an auxiliary channel between each sender and the decoder, and producing the final output based on the output of these intermediate channels.","The converse follows via information-spectrum based arguments.","To bound the cardinality of the auxiliary random variables, we employ the perturbation method from [Anantharam et al., IEEE Trans.","Inf.","Theory (2019)] in the one-shot setting.","For the asymptotic setting and vanishing errors, our result expands to a tight single-letter rate characterization and consequently extends a special case of the simulation results of [Kurri et al., IEEE Trans.","Inf.","Theory (2022)] for fixed, independent and identically distributed (iid) product inputs to universal simulation for any product inputs.","We broaden our discussion into the quantum realm by studying feedback simulation of quantum-to-classical (QC) MACs with product measurements","[Atif et al., IEEE Trans.","Inf.","Theory (2022)].","For fixed product inputs and with shared randomness assistance, we give a quasi tight one-shot communication cost region with corresponding single-letter asymptotic iid expansion."],"url":"http://arxiv.org/abs/2410.17198v1"}
{"created":"2024-10-22 17:15:20","title":"VoiceBench: Benchmarking LLM-Based Voice Assistants","abstract":"Building on the success of large language models (LLMs), recent advancements such as GPT-4o have enabled real-time speech interactions through LLM-based voice assistants, offering a significantly improved user experience compared to traditional text-based interactions. However, the absence of benchmarks designed to evaluate these speech interaction capabilities has hindered progress of LLM-based voice assistants development. Current evaluations focus primarily on automatic speech recognition (ASR) or general knowledge evaluation with clean speeches, neglecting the more intricate, real-world scenarios that involve diverse speaker characteristics, environmental and content factors. To address this, we introduce VoiceBench, the first benchmark designed to provide a multi-faceted evaluation of LLM-based voice assistants. VoiceBench also includes both real and synthetic spoken instructions that incorporate the above three key real-world variations. Extensive experiments reveal the limitations of current LLM-based voice assistant models and offer valuable insights for future research and development in this field.","sentences":["Building on the success of large language models (LLMs), recent advancements such as GPT-4o have enabled real-time speech interactions through LLM-based voice assistants, offering a significantly improved user experience compared to traditional text-based interactions.","However, the absence of benchmarks designed to evaluate these speech interaction capabilities has hindered progress of LLM-based voice assistants development.","Current evaluations focus primarily on automatic speech recognition (ASR) or general knowledge evaluation with clean speeches, neglecting the more intricate, real-world scenarios that involve diverse speaker characteristics, environmental and content factors.","To address this, we introduce VoiceBench, the first benchmark designed to provide a multi-faceted evaluation of LLM-based voice assistants.","VoiceBench also includes both real and synthetic spoken instructions that incorporate the above three key real-world variations.","Extensive experiments reveal the limitations of current LLM-based voice assistant models and offer valuable insights for future research and development in this field."],"url":"http://arxiv.org/abs/2410.17196v1"}
{"created":"2024-10-22 17:13:38","title":"Language Model Non-myopic Generation for Reasoning and Planning","abstract":"Large Language Models have demonstrated remarkable abilities in reasoning and planning by breaking down complex problems into sequential steps. Despite their success in various domains like mathematical problem-solving and coding, LLMs face challenges in ensuring reliable and optimal planning due to their inherent myopic nature of autoregressive decoding. This paper revisits LLM reasoning from an optimal-control perspective, proposing a novel method, Predictive-Decoding, that leverages Model Predictive Control to enhance planning accuracy. By re-weighting LLM distributions based on foresight trajectories, Predictive-Decoding aims to mitigate early errors and promote non-myopic planning. Our experiments show significant improvements in a wide range of tasks for math, coding, and agents. Furthermore, Predictive-Decoding demonstrates computational efficiency, outperforming search baselines with reduced computational resources. This study provides insights into optimizing LLM planning capabilities.","sentences":["Large Language Models have demonstrated remarkable abilities in reasoning and planning by breaking down complex problems into sequential steps.","Despite their success in various domains like mathematical problem-solving and coding, LLMs face challenges in ensuring reliable and optimal planning due to their inherent myopic nature of autoregressive decoding.","This paper revisits LLM reasoning from an optimal-control perspective, proposing a novel method, Predictive-Decoding, that leverages Model Predictive Control to enhance planning accuracy.","By re-weighting LLM distributions based on foresight trajectories, Predictive-Decoding aims to mitigate early errors and promote non-myopic planning.","Our experiments show significant improvements in a wide range of tasks for math, coding, and agents.","Furthermore, Predictive-Decoding demonstrates computational efficiency, outperforming search baselines with reduced computational resources.","This study provides insights into optimizing LLM planning capabilities."],"url":"http://arxiv.org/abs/2410.17195v1"}
{"created":"2024-10-22 17:13:34","title":"Representation Shattering in Transformers: A Synthetic Study with Knowledge Editing","abstract":"Knowledge Editing (KE) algorithms alter models' internal weights to perform targeted updates to incorrect, outdated, or otherwise unwanted factual associations. In order to better define the possibilities and limitations of these approaches, recent work has shown that applying KE can adversely affect models' factual recall accuracy and diminish their general reasoning abilities. While these studies give broad insights into the potential harms of KE algorithms, e.g., via performance evaluations on benchmarks, we argue little is understood as to why such destructive failures occur. Is it possible KE methods distort representations of concepts beyond the targeted fact, hence hampering abilities at broad? If so, what is the extent of this distortion? To take a step towards addressing such questions, we define a novel synthetic task wherein a Transformer is trained from scratch to internalize a ``structured'' knowledge graph. The structure enforces relationships between entities of the graph, such that editing a factual association has \"trickling effects\" on other entities in the graph (e.g., altering X's parent is Y to Z affects who X's siblings' parent is). Through evaluations of edited models and analysis of extracted representations, we show that KE inadvertently affects representations of entities beyond the targeted one, distorting relevant structures that allow a model to infer unseen knowledge about an entity. We call this phenomenon representation shattering and demonstrate that it results in degradation of factual recall and reasoning performance more broadly. To corroborate our findings in a more naturalistic setup, we perform preliminary experiments with a pretrained GPT-2-XL model and reproduce the representation shattering effect therein as well. Overall, our work yields a precise mechanistic hypothesis to explain why KE has adverse effects on model capabilities.","sentences":["Knowledge Editing (KE) algorithms alter models' internal weights to perform targeted updates to incorrect, outdated, or otherwise unwanted factual associations.","In order to better define the possibilities and limitations of these approaches, recent work has shown that applying KE can adversely affect models' factual recall accuracy and diminish their general reasoning abilities.","While these studies give broad insights into the potential harms of KE algorithms, e.g., via performance evaluations on benchmarks, we argue little is understood as to why such destructive failures occur.","Is it possible KE methods distort representations of concepts beyond the targeted fact, hence hampering abilities at broad?","If so, what is the extent of this distortion?","To take a step towards addressing such questions, we define a novel synthetic task wherein a Transformer is trained from scratch to internalize a ``structured'' knowledge graph.","The structure enforces relationships between entities of the graph, such that editing a factual association has \"trickling effects\" on other entities in the graph (e.g., altering X's parent is Y to Z affects who X's siblings' parent is).","Through evaluations of edited models and analysis of extracted representations, we show that KE inadvertently affects representations of entities beyond the targeted one, distorting relevant structures that allow a model to infer unseen knowledge about an entity.","We call this phenomenon representation shattering and demonstrate that it results in degradation of factual recall and reasoning performance more broadly.","To corroborate our findings in a more naturalistic setup, we perform preliminary experiments with a pretrained GPT-2-XL model and reproduce the representation shattering effect therein as well.","Overall, our work yields a precise mechanistic hypothesis to explain why KE has adverse effects on model capabilities."],"url":"http://arxiv.org/abs/2410.17194v1"}
{"created":"2024-10-22 17:13:19","title":"Emphasizing Discriminative Features for Dataset Distillation in Complex Scenarios","abstract":"Dataset distillation has demonstrated strong performance on simple datasets like CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in more complex scenarios. In this paper, we propose EDF (emphasizes the discriminative features), a dataset distillation method that enhances key discriminative regions in synthetic images using Grad-CAM activation maps. Our approach is inspired by a key observation: in simple datasets, high-activation areas typically occupy most of the image, whereas in complex scenarios, the size of these areas is much smaller. Unlike previous methods that treat all pixels equally when synthesizing images, EDF uses Grad-CAM activation maps to enhance high-activation areas. From a supervision perspective, we downplay supervision signals that have lower losses, as they contain common patterns. Additionally, to help the DD community better explore complex scenarios, we build the Complex Dataset Distillation (Comp-DD) benchmark by meticulously selecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In particular, EDF consistently outperforms SOTA results in complex scenarios, such as ImageNet-1K subsets. Hopefully, more researchers will be inspired and encouraged to improve the practicality and efficacy of DD. Our code and benchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF.","sentences":["Dataset distillation has demonstrated strong performance on simple datasets like CIFAR, MNIST, and TinyImageNet but struggles to achieve similar results in more complex scenarios.","In this paper, we propose EDF (emphasizes the discriminative features), a dataset distillation method that enhances key discriminative regions in synthetic images using Grad-CAM activation maps.","Our approach is inspired by a key observation: in simple datasets, high-activation areas typically occupy most of the image, whereas in complex scenarios, the size of these areas is much smaller.","Unlike previous methods that treat all pixels equally when synthesizing images, EDF uses Grad-CAM activation maps to enhance high-activation areas.","From a supervision perspective, we downplay supervision signals that have lower losses, as they contain common patterns.","Additionally, to help the DD community better explore complex scenarios, we build the Complex Dataset Distillation (Comp-DD) benchmark by meticulously selecting sixteen subsets, eight easy and eight hard, from ImageNet-1K. In particular, EDF consistently outperforms SOTA results in complex scenarios, such as ImageNet-1K subsets.","Hopefully, more researchers will be inspired and encouraged to improve the practicality and efficacy of DD.","Our code and benchmark will be made public at https://github.com/NUS-HPC-AI-Lab/EDF."],"url":"http://arxiv.org/abs/2410.17193v1"}
{"created":"2024-10-22 17:12:21","title":"On Functional Dimension and Persistent Pseudodimension","abstract":"For any fixed feedforward ReLU neural network architecture, it is well-known that many different parameter settings can determine the same function. It is less well-known that the degree of this redundancy is inhomogeneous across parameter space. In this work, we discuss two locally applicable complexity measures for ReLU network classes and what we know about the relationship between them: (1) the local functional dimension [14, 18], and (2) a local version of VC dimension that we call persistent pseudodimension. The former is easy to compute on finite batches of points; the latter should give local bounds on the generalization gap, which would inform an understanding of the mechanics of the double descent phenomenon [7].","sentences":["For any fixed feedforward ReLU neural network architecture, it is well-known that many different parameter settings can determine the same function.","It is less well-known that the degree of this redundancy is inhomogeneous across parameter space.","In this work, we discuss two locally applicable complexity measures for ReLU network classes and what we know about the relationship between them: (1) the local functional dimension [14, 18], and (2) a local version of VC dimension that we call persistent pseudodimension.","The former is easy to compute on finite batches of points; the latter should give local bounds on the generalization gap, which would inform an understanding of the mechanics of the double descent phenomenon [7]."],"url":"http://arxiv.org/abs/2410.17191v1"}
{"created":"2024-10-22 17:09:28","title":"Minimum-Violation Temporal Logic Planning for Heterogeneous Robots under Robot Skill Failures","abstract":"In this paper, we consider teams of robots with heterogeneous skills (e.g., sensing and manipulation) tasked with collaborative missions described by Linear Temporal Logic (LTL) formulas. These LTL-encoded tasks require robots to apply their skills to specific regions and objects in a temporal and logical order. While existing temporal logic planning algorithms can synthesize correct-by-construction paths, they typically lack reactivity to unexpected failures of robot skills, which can compromise mission performance. This paper addresses this challenge by proposing a reactive LTL planning algorithm that adapts to unexpected failures during deployment. Specifically, the proposed algorithm reassigns sub-tasks to robots based on their functioning skills and locally revises team plans to accommodate these new assignments and ensure mission completion. The main novelty of the proposed algorithm is its ability to handle cases where mission completion becomes impossible due to limited functioning robots. Instead of reporting mission failure, the algorithm strategically prioritizes the most crucial sub-tasks and locally revises the team's plans, as per user-specified priorities, to minimize mission violations. We provide theoretical conditions under which the proposed framework computes the minimum violation task reassignments and team plans. We provide numerical and hardware experiments to demonstrate the efficiency of the proposed method.","sentences":["In this paper, we consider teams of robots with heterogeneous skills (e.g., sensing and manipulation) tasked with collaborative missions described by Linear Temporal Logic (LTL) formulas.","These LTL-encoded tasks require robots to apply their skills to specific regions and objects in a temporal and logical order.","While existing temporal logic planning algorithms can synthesize correct-by-construction paths, they typically lack reactivity to unexpected failures of robot skills, which can compromise mission performance.","This paper addresses this challenge by proposing a reactive LTL planning algorithm that adapts to unexpected failures during deployment.","Specifically, the proposed algorithm reassigns sub-tasks to robots based on their functioning skills and locally revises team plans to accommodate these new assignments and ensure mission completion.","The main novelty of the proposed algorithm is its ability to handle cases where mission completion becomes impossible due to limited functioning robots.","Instead of reporting mission failure, the algorithm strategically prioritizes the most crucial sub-tasks and locally revises the team's plans, as per user-specified priorities, to minimize mission violations.","We provide theoretical conditions under which the proposed framework computes the minimum violation task reassignments and team plans.","We provide numerical and hardware experiments to demonstrate the efficiency of the proposed method."],"url":"http://arxiv.org/abs/2410.17188v1"}
{"created":"2024-10-22 17:07:26","title":"DyPNIPP: Predicting Environment Dynamics for RL-based Robust Informative Path Planning","abstract":"Informative path planning (IPP) is an important planning paradigm for various real-world robotic applications such as environment monitoring. IPP involves planning a path that can learn an accurate belief of the quantity of interest, while adhering to planning constraints. Traditional IPP methods typically require high computation time during execution, giving rise to reinforcement learning (RL) based IPP methods. However, the existing RL-based methods do not consider spatio-temporal environments which involve their own challenges due to variations in environment characteristics. In this paper, we propose DyPNIPP, a robust RL-based IPP framework, designed to operate effectively across spatio-temporal environments with varying dynamics. To achieve this, DyPNIPP incorporates domain randomization to train the agent across diverse environments and introduces a dynamics prediction model to capture and adapt the agent actions to specific environment dynamics. Our extensive experiments in a wildfire environment demonstrate that DyPNIPP outperforms existing RL-based IPP algorithms by significantly improving robustness and performing across diverse environment conditions.","sentences":["Informative path planning (IPP) is an important planning paradigm for various real-world robotic applications such as environment monitoring.","IPP involves planning a path that can learn an accurate belief of the quantity of interest, while adhering to planning constraints.","Traditional IPP methods typically require high computation time during execution, giving rise to reinforcement learning (RL) based IPP methods.","However, the existing RL-based methods do not consider spatio-temporal environments which involve their own challenges due to variations in environment characteristics.","In this paper, we propose DyPNIPP, a robust RL-based IPP framework, designed to operate effectively across spatio-temporal environments with varying dynamics.","To achieve this, DyPNIPP incorporates domain randomization to train the agent across diverse environments and introduces a dynamics prediction model to capture and adapt the agent actions to specific environment dynamics.","Our extensive experiments in a wildfire environment demonstrate that DyPNIPP outperforms existing RL-based IPP algorithms by significantly improving robustness and performing across diverse environment conditions."],"url":"http://arxiv.org/abs/2410.17186v1"}
{"created":"2024-10-22 17:04:17","title":"The Decision Problem for Regular First-Order Theories","abstract":"The classical `decision problem' asks whether a given formula of first-order logic is satisfiable. In this work we consider an extension of this problem to regular first-order theories, i.e. (infinite) regular sets of formulae. Building on the beautiful classification of syntactic classes as decidable or undecidable for the classical decision problem, we show that some classes (the EPR and Gurevich classes) which are decidable in the classical setting are undecidable for regular theories; on the other hand for each we show a subclass which remains decidable in our setting, leaving a complete classification as a challenge for future work. Finally, we observe that our problem generalises prior work on verification of uninterpreted programs, and give a semantic class of existential formulae for which the problem is decidable.","sentences":["The classical `decision problem' asks whether a given formula of first-order logic is satisfiable.","In this work we consider an extension of this problem to regular first-order theories, i.e. (infinite) regular sets of formulae.","Building on the beautiful classification of syntactic classes as decidable or undecidable for the classical decision problem, we show that some classes (the EPR and Gurevich classes) which are decidable in the classical setting are undecidable for regular theories; on the other hand for each we show a subclass which remains decidable in our setting, leaving a complete classification as a challenge for future work.","Finally, we observe that our problem generalises prior work on verification of uninterpreted programs, and give a semantic class of existential formulae for which the problem is decidable."],"url":"http://arxiv.org/abs/2410.17185v1"}
{"created":"2024-10-22 17:02:33","title":"Risk-Averse Model Predictive Control for Racing in Adverse Conditions","abstract":"Model predictive control (MPC) algorithms can be sensitive to model mismatch when used in challenging nonlinear control tasks. In particular, the performance of MPC for vehicle control at the limits of handling suffers when the underlying model overestimates the vehicle's capabilities. In this work, we propose a risk-averse MPC framework that explicitly accounts for uncertainty over friction limits and tire parameters. Our approach leverages a sample-based approximation of an optimal control problem with a conditional value at risk (CVaR) constraint. This sample-based formulation enables planning with a set of expressive vehicle dynamics models using different tire parameters. Moreover, this formulation enables efficient numerical resolution via sequential quadratic programming and GPU parallelization. Experiments on a Lexus LC 500 show that risk-averse MPC unlocks reliable performance, while a deterministic baseline that plans using a single dynamics model may lose control of the vehicle in adverse road conditions.","sentences":["Model predictive control (MPC) algorithms can be sensitive to model mismatch when used in challenging nonlinear control tasks.","In particular, the performance of MPC for vehicle control at the limits of handling suffers when the underlying model overestimates the vehicle's capabilities.","In this work, we propose a risk-averse MPC framework that explicitly accounts for uncertainty over friction limits and tire parameters.","Our approach leverages a sample-based approximation of an optimal control problem with a conditional value at risk (CVaR) constraint.","This sample-based formulation enables planning with a set of expressive vehicle dynamics models using different tire parameters.","Moreover, this formulation enables efficient numerical resolution via sequential quadratic programming and GPU parallelization.","Experiments on a Lexus LC 500 show that risk-averse MPC unlocks reliable performance, while a deterministic baseline that plans using a single dynamics model may lose control of the vehicle in adverse road conditions."],"url":"http://arxiv.org/abs/2410.17183v1"}
{"created":"2024-10-22 16:54:15","title":"Faster Approximation Algorithms for Restricted Shortest Paths in Directed Graphs","abstract":"In the restricted shortest paths problem, we are given a graph $G$ whose edges are assigned two non-negative weights: lengths and delays, a source $s$, and a delay threshold $D$. The goal is to find, for each target $t$, the length of the shortest $(s,t)$-path whose total delay is at most $D$. While this problem is known to be NP-hard [Garey and Johnson, 1979] $(1+\\varepsilon)$-approximate algorithms running in $\\tilde{O}(mn)$ time [Goel et al., INFOCOM'01; Lorenz and Raz, Oper. Res. Lett.'01] given more than twenty years ago have remained the state-of-the-art for directed graphs. An open problem posed by [Bernstein, SODA'12] -- who gave a randomized $m\\cdot n^{o(1)}$ time bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithm for undirected graphs -- asks if there is similarly an $o(mn)$ time approximation scheme for directed graphs.   We show two randomized bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithms that give an affirmative answer to the problem: one suited to dense graphs, and the other that works better for sparse graphs. On directed graphs with a quasi-polynomial weights aspect ratio, our algorithms run in time $\\tilde{O}(n^2)$ and $\\tilde{O}(mn^{3/5})$ or better, respectively. More specifically, the algorithm for sparse digraphs runs in time $\\tilde{O}(mn^{(3 - \\alpha)/5})$ for graphs with $n^{1 + \\alpha}$ edges for any real $\\alpha \\in [0,1/2]$.","sentences":["In the restricted shortest paths problem, we are given a graph $G$ whose edges are assigned two non-negative weights: lengths and delays, a source $s$, and a delay threshold $D$. The goal is to find, for each target $t$, the length of the shortest $(s,t)$-path whose total delay is at most $D$. While this problem is known to be NP-hard","[Garey and Johnson, 1979] $(1+\\varepsilon)$-approximate algorithms running in $\\tilde{O}(mn)$ time","[Goel et al., INFOCOM'01; Lorenz and Raz, Oper.","Res.","Lett.","'01] given more than twenty years ago have remained the state-of-the-art for directed graphs.","An open problem posed by [Bernstein, SODA'12] -- who gave a randomized $m\\cdot n^{o(1)}$ time bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithm for undirected graphs -- asks if there is similarly an $o(mn)$ time approximation scheme for directed graphs.   ","We show two randomized bicriteria $(1+\\varepsilon, 1+\\varepsilon)$-approximation algorithms that give an affirmative answer to the problem: one suited to dense graphs, and the other that works better for sparse graphs.","On directed graphs with a quasi-polynomial weights aspect ratio, our algorithms run in time $\\tilde{O}(n^2)$ and $\\tilde{O}(mn^{3/5})$ or better, respectively.","More specifically, the algorithm for sparse digraphs runs in time $\\tilde{O}(mn^{(3 - \\alpha)/5})$ for graphs with $n^{1 + \\alpha}$ edges for any real $\\alpha \\in [0,1/2]$."],"url":"http://arxiv.org/abs/2410.17179v1"}
{"created":"2024-10-22 16:51:36","title":"Remote Timing Attacks on Efficient Language Model Inference","abstract":"Scaling up language models has significantly increased their capabilities. But larger models are slower models, and so there is now an extensive body of work (e.g., speculative sampling or parallel decoding) that improves the (average case) efficiency of language model generation. But these techniques introduce data-dependent timing characteristics. We show it is possible to exploit these timing differences to mount a timing attack. By monitoring the (encrypted) network traffic between a victim user and a remote language model, we can learn information about the content of messages by noting when responses are faster or slower. With complete black-box access, on open source systems we show how it is possible to learn the topic of a user's conversation (e.g., medical advice vs. coding assistance) with 90%+ precision, and on production systems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between specific messages or infer the user's language. We further show that an active adversary can leverage a boosting attack to recover PII placed in messages (e.g., phone numbers or credit card numbers) for open source systems. We conclude with potential defenses and directions for future work.","sentences":["Scaling up language models has significantly increased their capabilities.","But larger models are slower models, and so there is now an extensive body of work (e.g., speculative sampling or parallel decoding) that improves the (average case) efficiency of language model generation.","But these techniques introduce data-dependent timing characteristics.","We show it is possible to exploit these timing differences to mount a timing attack.","By monitoring the (encrypted) network traffic between a victim user and a remote language model, we can learn information about the content of messages by noting when responses are faster or slower.","With complete black-box access, on open source systems we show how it is possible to learn the topic of a user's conversation (e.g., medical advice vs. coding assistance) with 90%+ precision, and on production systems like OpenAI's ChatGPT and Anthropic's Claude we can distinguish between specific messages or infer the user's language.","We further show that an active adversary can leverage a boosting attack to recover PII placed in messages (e.g., phone numbers or credit card numbers) for open source systems.","We conclude with potential defenses and directions for future work."],"url":"http://arxiv.org/abs/2410.17175v1"}
{"created":"2024-10-22 16:51:27","title":"From Attention to Activation: Unravelling the Enigmas of Large Language Models","abstract":"We study two strange phenomena in auto-regressive Transformers: (1) the dominance of the first token in attention heads; (2) the occurrence of large outlier activations in the hidden states. We find that popular large language models, such as Llama attend maximally to the first token in 98% of attention heads, a behaviour we attribute to the softmax function. To mitigate this issue, we propose a reformulation of softmax to softmax-1. Furthermore, we identify adaptive optimisers, e.g. Adam, as the primary contributor to the large outlier activations and introduce OrthoAdam, a novel optimiser that utilises orthogonal matrices to transform gradients, to address this issue. Finally, not only do our methods prevent these phenomena from occurring, but additionally, they enable Transformers to sustain their performance when quantised using basic algorithms, something that standard methods are unable to do. In summary, our methods reduce the attention proportion on the first token from 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to 3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3.","sentences":["We study two strange phenomena in auto-regressive Transformers: (1) the dominance of the first token in attention heads; (2) the occurrence of large outlier activations in the hidden states.","We find that popular large language models, such as Llama attend maximally to the first token in 98% of attention heads, a behaviour we attribute to the softmax function.","To mitigate this issue, we propose a reformulation of softmax to softmax-1.","Furthermore, we identify adaptive optimisers, e.g. Adam, as the primary contributor to the large outlier activations and introduce OrthoAdam, a novel optimiser that utilises orthogonal matrices to transform gradients, to address this issue.","Finally, not only do our methods prevent these phenomena from occurring, but additionally, they enable Transformers to sustain their performance when quantised using basic algorithms, something that standard methods are unable to do.","In summary, our methods reduce the attention proportion on the first token from 65% to 3.3%, the activation kurtosis in the hidden states from 1657 to 3.1, and perplexity penalty under 4-bit weight quantisation from 3565 to 0.3."],"url":"http://arxiv.org/abs/2410.17174v1"}
{"created":"2024-10-22 16:50:34","title":"KANICE: Kolmogorov-Arnold Networks with Interactive Convolutional Elements","abstract":"We introduce KANICE (Kolmogorov-Arnold Networks with Interactive Convolutional Elements), a novel neural architecture that combines Convolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN) principles. KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN linear layers into a CNN framework. This leverages KANs' universal approximation capabilities and ICBs' adaptive feature learning. KANICE captures complex, non-linear data relationships while enabling dynamic, context-dependent feature extraction based on the Kolmogorov-Arnold representation theorem. We evaluated KANICE on four datasets: MNIST, Fashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN hybrids, and ICB variants. KANICE consistently outperformed baseline models, achieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.   Furthermore, we introduce KANICE-mini, a compact variant designed for efficiency. A comprehensive ablation study demonstrates that KANICE-mini achieves comparable performance to KANICE with significantly fewer parameters. KANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared to KANICE's 25,432,000. This study highlights the potential of KAN-based architectures in balancing performance and computational efficiency in image classification tasks. Our work contributes to research in adaptive neural networks, integrates mathematical theorems into deep learning architectures, and explores the trade-offs between model complexity and performance, advancing computer vision and pattern recognition. The source code for this paper is publicly accessible through our GitHub repository (https://github.com/m-ferdaus/kanice).","sentences":["We introduce KANICE (Kolmogorov-Arnold Networks with Interactive Convolutional Elements), a novel neural architecture that combines Convolutional Neural Networks (CNNs) with Kolmogorov-Arnold Network (KAN) principles.","KANICE integrates Interactive Convolutional Blocks (ICBs) and KAN linear layers into a CNN framework.","This leverages KANs' universal approximation capabilities and ICBs' adaptive feature learning.","KANICE captures complex, non-linear data relationships while enabling dynamic, context-dependent feature extraction based on the Kolmogorov-Arnold representation theorem.","We evaluated KANICE on four datasets: MNIST, Fashion-MNIST, EMNIST, and SVHN, comparing it against standard CNNs, CNN-KAN hybrids, and ICB variants.","KANICE consistently outperformed baseline models, achieving 99.35% accuracy on MNIST and 90.05% on the SVHN dataset.   ","Furthermore, we introduce KANICE-mini, a compact variant designed for efficiency.","A comprehensive ablation study demonstrates that KANICE-mini achieves comparable performance to KANICE with significantly fewer parameters.","KANICE-mini reached 90.00% accuracy on SVHN with 2,337,828 parameters, compared to KANICE's 25,432,000.","This study highlights the potential of KAN-based architectures in balancing performance and computational efficiency in image classification tasks.","Our work contributes to research in adaptive neural networks, integrates mathematical theorems into deep learning architectures, and explores the trade-offs between model complexity and performance, advancing computer vision and pattern recognition.","The source code for this paper is publicly accessible through our GitHub repository (https://github.com/m-ferdaus/kanice)."],"url":"http://arxiv.org/abs/2410.17172v1"}
{"created":"2024-10-22 16:50:34","title":"Reinforcement learning on structure-conditioned categorical diffusion for protein inverse folding","abstract":"Protein inverse folding-that is, predicting an amino acid sequence that will fold into the desired 3D structure-is an important problem for structure-based protein design. Machine learning based methods for inverse folding typically use recovery of the original sequence as the optimization objective. However, inverse folding is a one-to-many problem where several sequences can fold to the same structure. Moreover, for many practical applications, it is often desirable to have multiple, diverse sequences that fold into the target structure since it allows for more candidate sequences for downstream optimizations. Here, we demonstrate that although recent inverse folding methods show increased sequence recovery, their \"foldable diversity\"-i.e. their ability to generate multiple non-similar sequences that fold into the structures consistent with the target-does not increase. To address this, we present RL-DIF, a categorical diffusion model for inverse folding that is pre-trained on sequence recovery and tuned via reinforcement learning on structural consistency. We find that RL-DIF achieves comparable sequence recovery and structural consistency to benchmark models but shows greater foldable diversity: experiments show RL-DIF can achieve an foldable diversity of 29% on CATH 4.2, compared to 23% from models trained on the same dataset. The PyTorch model weights and sampling code are available on GitHub.","sentences":["Protein inverse folding-that is, predicting an amino acid sequence that will fold into the desired 3D structure-is an important problem for structure-based protein design.","Machine learning based methods for inverse folding typically use recovery of the original sequence as the optimization objective.","However, inverse folding is a one-to-many problem where several sequences can fold to the same structure.","Moreover, for many practical applications, it is often desirable to have multiple, diverse sequences that fold into the target structure since it allows for more candidate sequences for downstream optimizations.","Here, we demonstrate that although recent inverse folding methods show increased sequence recovery, their \"foldable diversity\"-i.e.","their ability to generate multiple non-similar sequences that fold into the structures consistent with the target-does not increase.","To address this, we present RL-DIF, a categorical diffusion model for inverse folding that is pre-trained on sequence recovery and tuned via reinforcement learning on structural consistency.","We find that RL-DIF achieves comparable sequence recovery and structural consistency to benchmark models but shows greater foldable diversity: experiments show RL-DIF can achieve an foldable diversity of 29% on CATH 4.2, compared to 23% from models trained on the same dataset.","The PyTorch model weights and sampling code are available on GitHub."],"url":"http://arxiv.org/abs/2410.17173v1"}
{"created":"2024-10-22 16:50:09","title":"Impact of 3D LiDAR Resolution in Graph-based SLAM Approaches: A Comparative Study","abstract":"Simultaneous Localization and Mapping (SLAM) is a key component of autonomous systems operating in environments that require a consistent map for reliable localization. SLAM has been a widely studied topic for decades with most of the solutions being camera or LiDAR based. Early LiDAR-based approaches primarily relied on 2D data, whereas more recent frameworks use 3D data. In this work, we survey recent 3D LiDAR-based Graph-SLAM methods in urban environments, aiming to compare their strengths, weaknesses, and limitations. Additionally, we evaluate their robustness regarding the LiDAR resolution namely 64 $vs$ 128 channels. Regarding SLAM methods, we evaluate SC-LeGO-LOAM, SC-LIO-SAM, Cartographer, and HDL-Graph on real-world urban environments using the KITTI odometry dataset (a LiDAR with 64-channels only) and a new dataset (AUTONOMOS-LABS). The latter dataset, collected using instrumented vehicles driving in Berlin suburban area, comprises both 64 and 128 LiDARs. The experimental results are reported in terms of quantitative `metrics' and complemented by qualitative maps.","sentences":["Simultaneous Localization and Mapping (SLAM) is a key component of autonomous systems operating in environments that require a consistent map for reliable localization.","SLAM has been a widely studied topic for decades with most of the solutions being camera or LiDAR based.","Early LiDAR-based approaches primarily relied on 2D data, whereas more recent frameworks use 3D data.","In this work, we survey recent 3D LiDAR-based Graph-SLAM methods in urban environments, aiming to compare their strengths, weaknesses, and limitations.","Additionally, we evaluate their robustness regarding the LiDAR resolution namely 64 $vs$ 128 channels.","Regarding SLAM methods, we evaluate SC-LeGO-LOAM, SC-LIO-SAM, Cartographer, and HDL-Graph on real-world urban environments using the KITTI odometry dataset (a LiDAR with 64-channels only) and a new dataset (AUTONOMOS-LABS).","The latter dataset, collected using instrumented vehicles driving in Berlin suburban area, comprises both 64 and 128 LiDARs.","The experimental results are reported in terms of quantitative `metrics' and complemented by qualitative maps."],"url":"http://arxiv.org/abs/2410.17171v1"}
{"created":"2024-10-22 16:50:00","title":"Self-calibration for Language Model Quantization and Pruning","abstract":"Quantization and pruning are fundamental approaches for model compression, enabling efficient inference for language models. In a post-training setting, state-of-the-art quantization and pruning methods require calibration data, a small set of unlabeled examples. Conventionally, randomly sampled web text is used, aiming to reflect the model training data. However, this poses two key problems: (1) unrepresentative calibration examples can harm model performance, and (2) organizations increasingly avoid releasing model training data. In this paper, we propose self-calibration as a solution. Our approach requires no external data, instead leveraging the model itself to generate synthetic calibration data as a better approximation of the pre-training data distribution. We extensively compare the performance of self-calibration with several baselines, across a variety of models, compression methods, and tasks. Our approach proves consistently competitive in maximizing downstream task performance, frequently outperforming even using real data.","sentences":["Quantization and pruning are fundamental approaches for model compression, enabling efficient inference for language models.","In a post-training setting, state-of-the-art quantization and pruning methods require calibration data, a small set of unlabeled examples.","Conventionally, randomly sampled web text is used, aiming to reflect the model training data.","However, this poses two key problems: (1) unrepresentative calibration examples can harm model performance, and (2) organizations increasingly avoid releasing model training data.","In this paper, we propose self-calibration as a solution.","Our approach requires no external data, instead leveraging the model itself to generate synthetic calibration data as a better approximation of the pre-training data distribution.","We extensively compare the performance of self-calibration with several baselines, across a variety of models, compression methods, and tasks.","Our approach proves consistently competitive in maximizing downstream task performance, frequently outperforming even using real data."],"url":"http://arxiv.org/abs/2410.17170v1"}
{"created":"2024-10-22 16:43:21","title":"Towards Map-Agnostic Policies for Adaptive Informative Path Planning","abstract":"Robots are frequently tasked to gather relevant sensor data in unknown terrains. A key challenge for classical path planning algorithms used for autonomous information gathering is adaptively replanning paths online as the terrain is explored given limited onboard compute resources. Recently, learning-based approaches emerged that train planning policies offline and enable computationally efficient online replanning performing policy inference. These approaches are designed and trained for terrain monitoring missions assuming a single specific map representation, which limits their applicability to different terrains. To address these issues, we propose a novel formulation of the adaptive informative path planning problem unified across different map representations, enabling training and deploying planning policies in a larger variety of monitoring missions. Experimental results validate that our novel formulation easily integrates with classical non-learning-based planning approaches while maintaining their performance. Our trained planning policy performs similarly to state-of-the-art map-specifically trained policies. We validate our learned policy on unseen real-world terrain datasets.","sentences":["Robots are frequently tasked to gather relevant sensor data in unknown terrains.","A key challenge for classical path planning algorithms used for autonomous information gathering is adaptively replanning paths online as the terrain is explored given limited onboard compute resources.","Recently, learning-based approaches emerged that train planning policies offline and enable computationally efficient online replanning performing policy inference.","These approaches are designed and trained for terrain monitoring missions assuming a single specific map representation, which limits their applicability to different terrains.","To address these issues, we propose a novel formulation of the adaptive informative path planning problem unified across different map representations, enabling training and deploying planning policies in a larger variety of monitoring missions.","Experimental results validate that our novel formulation easily integrates with classical non-learning-based planning approaches while maintaining their performance.","Our trained planning policy performs similarly to state-of-the-art map-specifically trained policies.","We validate our learned policy on unseen real-world terrain datasets."],"url":"http://arxiv.org/abs/2410.17166v1"}
{"created":"2024-10-22 16:34:36","title":"Interchangeable Token Embeddings for Extendable Vocabulary and Alpha-Equivalence","abstract":"We propose a novel approach for learning interchangeable tokens in language models to obtain an extendable vocabulary that can generalize to new tokens. Our method is designed to address alpha-equivalence, the principle that renaming bound variables in a syntactic expression preserves semantics. This property arises in many formal languages such as temporal logics, in which all proposition symbols represent the same concept but are distinguishable from each other. To handle such tokens, we develop a dual-part embedding approach. The first part is shared across all interchangeable tokens, thereby enforcing that they represent the same core concept. The second part is randomly generated for each token, which enables distinguishability. We evaluate our method in a Transformer encoder-decoder model on two tasks: solving linear temporal logic formulae and copying with extendable vocabulary. Our method demonstrates promising generalization capabilities in addition to introducing a favorable inductive bias for alpha-equivalence.","sentences":["We propose a novel approach for learning interchangeable tokens in language models to obtain an extendable vocabulary that can generalize to new tokens.","Our method is designed to address alpha-equivalence, the principle that renaming bound variables in a syntactic expression preserves semantics.","This property arises in many formal languages such as temporal logics, in which all proposition symbols represent the same concept but are distinguishable from each other.","To handle such tokens, we develop a dual-part embedding approach.","The first part is shared across all interchangeable tokens, thereby enforcing that they represent the same core concept.","The second part is randomly generated for each token, which enables distinguishability.","We evaluate our method in a Transformer encoder-decoder model on two tasks: solving linear temporal logic formulae and copying with extendable vocabulary.","Our method demonstrates promising generalization capabilities in addition to introducing a favorable inductive bias for alpha-equivalence."],"url":"http://arxiv.org/abs/2410.17161v1"}
{"created":"2024-10-22 16:34:24","title":"Layered LA-MAPF: a decomposition of large agent MAPF instance to accelerate solving without compromising solvability","abstract":"Multi-Agent Path Finding (MAPF) has been widely studied in recent years. However, most existing MAPF algorithms assume that an agent occupies only a single grid in a grid-based map. This assumption limits their applicability in many real-world domains where agents have geometric shapes, rather than being point-like. Such agents, which can occupy multiple cells simultaneously, are referred to as ``large'' agents. When considering the shape and size of agents in MAPF, the computational complexity increases significantly as the number of agents grows, primarily due to the increased overhead in conflict detection between geometric agents. In this paper, we propose two types of subproblems for the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no constraints on the order of solution) and \\textbf{level} (which imposes constraints on the solution order). We introduce \\textbf{Layered LA-MAPF}, a method that decomposes a MAPF instance involving geometric agents into clusters, and then further decomposes each cluster into levels. This approach aims to reduce time complexity when solving LA-MAPF problems. Our results demonstrate the performance of our method as the number of agents increases across various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and LA-LaCAM. Experiments show that our LA-MAPF method with instance decomposition \\textbf{halves the time cost (reducing from an average of 40s to 20s) and triples the success rate (from an average of 0.27 to 0.80)} in finding a solution within 60 seconds. To facilitate further research, we have made the source code for Layered LA-MAPF publicly available at \\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}.","sentences":["Multi-Agent Path Finding (MAPF) has been widely studied in recent years.","However, most existing MAPF algorithms assume that an agent occupies only a single grid in a grid-based map.","This assumption limits their applicability in many real-world domains where agents have geometric shapes, rather than being point-like.","Such agents, which can occupy multiple cells simultaneously, are referred to as ``large'' agents.","When considering the shape and size of agents in MAPF, the computational complexity increases significantly as the number of agents grows, primarily due to the increased overhead in conflict detection between geometric agents.","In this paper, we propose two types of subproblems for the LA-MAPF (Large-Agent MAPF) problem: \\textbf{cluster} (which has no constraints on the order of solution) and \\textbf{level} (which imposes constraints on the solution order).","We introduce \\textbf{Layered LA-MAPF}, a method that decomposes a MAPF instance involving geometric agents into clusters, and then further decomposes each cluster into levels.","This approach aims to reduce time complexity when solving LA-MAPF problems.","Our results demonstrate the performance of our method as the number of agents increases across various maps, and how it accelerates LA-MAPF methods, such as LA-CBS and LA-LaCAM.","Experiments show that our LA-MAPF method with instance decomposition \\textbf{halves the time cost (reducing from an average of 40s to 20s) and triples the success rate (from an average of 0.27 to 0.80)} in finding a solution within 60 seconds.","To facilitate further research, we have made the source code for Layered LA-MAPF publicly available at \\url{https://github.com/JoeYao-bit/LayeredMAPF/algorithm/LA-MAPF}."],"url":"http://arxiv.org/abs/2410.17160v1"}
{"created":"2024-10-22 16:33:54","title":"LiNo: Advancing Recursive Residual Decomposition of Linear and Nonlinear Patterns for Robust Time Series Forecasting","abstract":"Forecasting models are pivotal in a data-driven world with vast volumes of time series data that appear as a compound of vast Linear and Nonlinear patterns. Recent deep time series forecasting models struggle to utilize seasonal and trend decomposition to separate the entangled components. Such a strategy only explicitly extracts simple linear patterns like trends, leaving the other linear modes and vast unexplored nonlinear patterns to the residual. Their flawed linear and nonlinear feature extraction models and shallow-level decomposition limit their adaptation to the diverse patterns present in real-world scenarios. Given this, we innovate Recursive Residual Decomposition by introducing explicit extraction of both linear and nonlinear patterns. This deeper-level decomposition framework, which is named LiNo, captures linear patterns using a Li block which can be a moving average kernel, and models nonlinear patterns using a No block which can be a Transformer encoder. The extraction of these two patterns is performed alternatively and recursively. To achieve the full potential of LiNo, we develop the current simple linear pattern extractor to a general learnable autoregressive model, and design a novel No block that can handle all essential nonlinear patterns. Remarkably, the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks under univariate and multivariate forecasting scenarios. Experiments show that current forecasting models can deliver more robust and precise results through this advanced Recursive Residual Decomposition. We hope this work could offer insight into designing more effective forecasting models. Code is available at this Repository: https://github.com/Levi-Ackman/LiNo.","sentences":["Forecasting models are pivotal in a data-driven world with vast volumes of time series data that appear as a compound of vast Linear and Nonlinear patterns.","Recent deep time series forecasting models struggle to utilize seasonal and trend decomposition to separate the entangled components.","Such a strategy only explicitly extracts simple linear patterns like trends, leaving the other linear modes and vast unexplored nonlinear patterns to the residual.","Their flawed linear and nonlinear feature extraction models and shallow-level decomposition limit their adaptation to the diverse patterns present in real-world scenarios.","Given this, we innovate Recursive Residual Decomposition by introducing explicit extraction of both linear and nonlinear patterns.","This deeper-level decomposition framework, which is named LiNo, captures linear patterns using a Li block which can be a moving average kernel, and models nonlinear patterns using a No block which can be a Transformer encoder.","The extraction of these two patterns is performed alternatively and recursively.","To achieve the full potential of LiNo, we develop the current simple linear pattern extractor to a general learnable autoregressive model, and design a novel No block that can handle all essential nonlinear patterns.","Remarkably, the proposed LiNo achieves state-of-the-art on thirteen real-world benchmarks under univariate and multivariate forecasting scenarios.","Experiments show that current forecasting models can deliver more robust and precise results through this advanced Recursive Residual Decomposition.","We hope this work could offer insight into designing more effective forecasting models.","Code is available at this Repository: https://github.com/Levi-Ackman/LiNo."],"url":"http://arxiv.org/abs/2410.17159v1"}
{"created":"2024-10-22 16:31:46","title":"AI Future Envisioning with PLACARD","abstract":"At EuroPLoP 2024 Mary Tedeschi led the \"AI Future Envisioning with PLACARD\" focus group in Germany. Three conference attendees joined in the room while Sridevi, Paola, and Charles co-facilitated remotely via a web conference. The participants were introduced to a Futures Studies technique with the goal of capturing envisionments of Artificial Intelligence (AI) going forward. To set an atmosphere a technology focused card game was used to make the session more interactive. To close everyone co-created a Project Action Review to recap of the event to capture learnings that has been summarized in this paper. The Focus Group was structured based on lessons learned over six earlier iterations.","sentences":["At EuroPLoP 2024 Mary Tedeschi led the \"AI Future Envisioning with PLACARD\" focus group in Germany.","Three conference attendees joined in the room while Sridevi, Paola, and Charles co-facilitated remotely via a web conference.","The participants were introduced to a Futures Studies technique with the goal of capturing envisionments of Artificial Intelligence (AI) going forward.","To set an atmosphere a technology focused card game was used to make the session more interactive.","To close everyone co-created a Project Action Review to recap of the event to capture learnings that has been summarized in this paper.","The Focus Group was structured based on lessons learned over six earlier iterations."],"url":"http://arxiv.org/abs/2410.17155v1"}
{"created":"2024-10-22 16:29:33","title":"Improving Pinterest Search Relevance Using Large Language Models","abstract":"To improve relevance scoring on Pinterest Search, we integrate Large Language Models (LLMs) into our search relevance model, leveraging carefully designed text representations to predict the relevance of Pins effectively. Our approach uses search queries alongside content representations that include captions extracted from a generative visual language model. These are further enriched with link-based text data, historically high-quality engaged queries, user-curated boards, Pin titles and Pin descriptions, creating robust models for predicting search relevance. We use a semi-supervised learning approach to efficiently scale up the amount of training data, expanding beyond the expensive human labeled data available. By utilizing multilingual LLMs, our system extends training data to include unseen languages and domains, despite initial data and annotator expertise being confined to English. Furthermore, we distill from the LLM-based model into real-time servable model architectures and features. We provide comprehensive offline experimental validation for our proposed techniques and demonstrate the gains achieved through the final deployed system at scale.","sentences":["To improve relevance scoring on Pinterest Search, we integrate Large Language Models (LLMs) into our search relevance model, leveraging carefully designed text representations to predict the relevance of Pins effectively.","Our approach uses search queries alongside content representations that include captions extracted from a generative visual language model.","These are further enriched with link-based text data, historically high-quality engaged queries, user-curated boards, Pin titles and Pin descriptions, creating robust models for predicting search relevance.","We use a semi-supervised learning approach to efficiently scale up the amount of training data, expanding beyond the expensive human labeled data available.","By utilizing multilingual LLMs, our system extends training data to include unseen languages and domains, despite initial data and annotator expertise being confined to English.","Furthermore, we distill from the LLM-based model into real-time servable model architectures and features.","We provide comprehensive offline experimental validation for our proposed techniques and demonstrate the gains achieved through the final deployed system at scale."],"url":"http://arxiv.org/abs/2410.17152v1"}
{"created":"2024-10-22 16:28:21","title":"Are Visual-Language Models Effective in Action Recognition? A Comparative Study","abstract":"Current vision-language foundation models, such as CLIP, have recently shown significant improvement in performance across various downstream tasks. However, whether such foundation models significantly improve more complex fine-grained action recognition tasks is still an open question. To answer this question and better find out the future research direction on human behavior analysis in-the-wild, this paper provides a large-scale study and insight on current state-of-the-art vision foundation models by comparing their transfer ability onto zero-shot and frame-wise action recognition tasks. Extensive experiments are conducted on recent fine-grained, human-centric action recognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU, Charades) including action classification and segmentation.","sentences":["Current vision-language foundation models, such as CLIP, have recently shown significant improvement in performance across various downstream tasks.","However, whether such foundation models significantly improve more complex fine-grained action recognition tasks is still an open question.","To answer this question and better find out the future research direction on human behavior analysis in-the-wild, this paper provides a large-scale study and insight on current state-of-the-art vision foundation models by comparing their transfer ability onto zero-shot and frame-wise action recognition tasks.","Extensive experiments are conducted on recent fine-grained, human-centric action recognition datasets (e.g., Toyota Smarthome, Penn Action, UAV-Human, TSU, Charades) including action classification and segmentation."],"url":"http://arxiv.org/abs/2410.17149v1"}
{"created":"2024-10-22 16:26:05","title":"LiNeS: Post-training Layer Scaling Prevents Forgetting and Enhances Model Merging","abstract":"Large pre-trained models exhibit impressive zero-shot performance across diverse tasks, but fine-tuning often leads to catastrophic forgetting, where improvements on a target domain degrade generalization on other tasks. To address this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a post-training editing technique designed to preserve pre-trained generalization while enhancing fine-tuned task performance. LiNeS scales parameter updates linearly based on their layer depth within the network, maintaining shallow layers close to their pre-trained values to preserve general features while allowing deeper layers to retain task-specific representations. We further extend this approach to multi-task model merging scenarios, where layer-wise scaling of merged parameters reduces negative task interference. LiNeS demonstrates significant improvements in both single-task and multi-task settings across various benchmarks in vision and natural language processing. It mitigates forgetting, enhances out-of-distribution generalization, integrates seamlessly with existing multi-task model merging baselines improving their performance across benchmarks and model sizes, and can boost generalization when merging LLM policies aligned with different rewards via RLHF. Importantly, our method is simple to implement and complementary to many existing techniques.","sentences":["Large pre-trained models exhibit impressive zero-shot performance across diverse tasks, but fine-tuning often leads to catastrophic forgetting, where improvements on a target domain degrade generalization on other tasks.","To address this challenge, we introduce LiNeS, Layer-increasing Network Scaling, a post-training editing technique designed to preserve pre-trained generalization while enhancing fine-tuned task performance.","LiNeS scales parameter updates linearly based on their layer depth within the network, maintaining shallow layers close to their pre-trained values to preserve general features while allowing deeper layers to retain task-specific representations.","We further extend this approach to multi-task model merging scenarios, where layer-wise scaling of merged parameters reduces negative task interference.","LiNeS demonstrates significant improvements in both single-task and multi-task settings across various benchmarks in vision and natural language processing.","It mitigates forgetting, enhances out-of-distribution generalization, integrates seamlessly with existing multi-task model merging baselines improving their performance across benchmarks and model sizes, and can boost generalization when merging LLM policies aligned with different rewards via RLHF.","Importantly, our method is simple to implement and complementary to many existing techniques."],"url":"http://arxiv.org/abs/2410.17146v1"}
{"created":"2024-10-22 16:26:03","title":"Can General-Purpose Large Language Models Generalize to English-Thai Machine Translation ?","abstract":"Large language models (LLMs) perform well on common tasks but struggle with generalization in low-resource and low-computation settings. We examine this limitation by testing various LLMs and specialized translation models on English-Thai machine translation and code-switching datasets. Our findings reveal that under more strict computational constraints, such as 4-bit quantization, LLMs fail to translate effectively. In contrast, specialized models, with comparable or lower computational requirements, consistently outperform LLMs. This underscores the importance of specialized models for maintaining performance under resource constraints.","sentences":["Large language models (LLMs) perform well on common tasks but struggle with generalization in low-resource and low-computation settings.","We examine this limitation by testing various LLMs and specialized translation models on English-Thai machine translation and code-switching datasets.","Our findings reveal that under more strict computational constraints, such as 4-bit quantization, LLMs fail to translate effectively.","In contrast, specialized models, with comparable or lower computational requirements, consistently outperform LLMs.","This underscores the importance of specialized models for maintaining performance under resource constraints."],"url":"http://arxiv.org/abs/2410.17145v1"}
{"created":"2024-10-22 16:19:55","title":"YOLO-TS: Real-Time Traffic Sign Detection with Enhanced Accuracy Using Optimized Receptive Fields and Anchor-Free Fusion","abstract":"Ensuring safety in both autonomous driving and advanced driver-assistance systems (ADAS) depends critically on the efficient deployment of traffic sign recognition technology. While current methods show effectiveness, they often compromise between speed and accuracy. To address this issue, we present a novel real-time and efficient road sign detection network, YOLO-TS. This network significantly improves performance by optimizing the receptive fields of multi-scale feature maps to align more closely with the size distribution of traffic signs in various datasets. Moreover, our innovative feature-fusion strategy, leveraging the flexibility of Anchor-Free methods, allows for multi-scale object detection on a high-resolution feature map abundant in contextual information, achieving remarkable enhancements in both accuracy and speed. To mitigate the adverse effects of the grid pattern caused by dilated convolutions on the detection of smaller objects, we have devised a unique module that not only mitigates this grid effect but also widens the receptive field to encompass an extensive range of spatial contextual information, thus boosting the efficiency of information usage. Evaluation on challenging public datasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existing state-of-the-art methods in terms of both accuracy and speed. The code for our method will be available.","sentences":["Ensuring safety in both autonomous driving and advanced driver-assistance systems (ADAS) depends critically on the efficient deployment of traffic sign recognition technology.","While current methods show effectiveness, they often compromise between speed and accuracy.","To address this issue, we present a novel real-time and efficient road sign detection network, YOLO-TS.","This network significantly improves performance by optimizing the receptive fields of multi-scale feature maps to align more closely with the size distribution of traffic signs in various datasets.","Moreover, our innovative feature-fusion strategy, leveraging the flexibility of Anchor-Free methods, allows for multi-scale object detection on a high-resolution feature map abundant in contextual information, achieving remarkable enhancements in both accuracy and speed.","To mitigate the adverse effects of the grid pattern caused by dilated convolutions on the detection of smaller objects, we have devised a unique module that not only mitigates this grid effect but also widens the receptive field to encompass an extensive range of spatial contextual information, thus boosting the efficiency of information usage.","Evaluation on challenging public datasets, TT100K and CCTSDB2021, demonstrates that YOLO-TS surpasses existing state-of-the-art methods in terms of both accuracy and speed.","The code for our method will be available."],"url":"http://arxiv.org/abs/2410.17144v1"}
{"created":"2024-10-22 16:18:41","title":"Towards Automated Penetration Testing: Introducing LLM Benchmark, Analysis, and Improvements","abstract":"Hacking poses a significant threat to cybersecurity, inflicting billions of dollars in damages annually. To mitigate these risks, ethical hacking, or penetration testing, is employed to identify vulnerabilities in systems and networks. Recent advancements in large language models (LLMs) have shown potential across various domains, including cybersecurity. However, there is currently no comprehensive, open, end-to-end automated penetration testing benchmark to drive progress and evaluate the capabilities of these models in security contexts. This paper introduces a novel open benchmark for LLM-based automated penetration testing, addressing this critical gap. We first evaluate the performance of LLMs, including GPT-4o and Llama 3.1-405B, using the state-of-the-art PentestGPT tool. Our findings reveal that while Llama 3.1 demonstrates an edge over GPT-4o, both models currently fall short of performing fully automated, end-to-end penetration testing. Next, we advance the state-of-the-art and present ablation studies that provide insights into improving the PentestGPT tool. Our research illuminates the challenges LLMs face in each aspect of Pentesting, e.g. enumeration, exploitation, and privilege escalation. This work contributes to the growing body of knowledge on AI-assisted cybersecurity and lays the foundation for future research in automated penetration testing using large language models.","sentences":["Hacking poses a significant threat to cybersecurity, inflicting billions of dollars in damages annually.","To mitigate these risks, ethical hacking, or penetration testing, is employed to identify vulnerabilities in systems and networks.","Recent advancements in large language models (LLMs) have shown potential across various domains, including cybersecurity.","However, there is currently no comprehensive, open, end-to-end automated penetration testing benchmark to drive progress and evaluate the capabilities of these models in security contexts.","This paper introduces a novel open benchmark for LLM-based automated penetration testing, addressing this critical gap.","We first evaluate the performance of LLMs, including GPT-4o and Llama 3.1-405B, using the state-of-the-art PentestGPT tool.","Our findings reveal that while Llama 3.1 demonstrates an edge over GPT-4o, both models currently fall short of performing fully automated, end-to-end penetration testing.","Next, we advance the state-of-the-art and present ablation studies that provide insights into improving the PentestGPT tool.","Our research illuminates the challenges LLMs face in each aspect of Pentesting, e.g. enumeration, exploitation, and privilege escalation.","This work contributes to the growing body of knowledge on AI-assisted cybersecurity and lays the foundation for future research in automated penetration testing using large language models."],"url":"http://arxiv.org/abs/2410.17141v1"}
{"created":"2024-10-22 16:10:10","title":"Trustworthy XAI and Application","abstract":"One of today's most significant and transformative technologies is the rapidly developing field of artificial intelligence (AI). Deined as a computer system that simulates human cognitive processes, AI is present in many aspects of our daily lives, from the self-driving cars on the road to the intelligence (AI) because some AI systems are so complex and opaque. With millions of parameters and layers, these system-deep neural networks in particular-make it difficult for humans to comprehend accountability, prejudice, and justice are raised by the opaqueness of its decision-making process. AI has a lot of potential, but it also comes with a lot of difficulties and moral dilemmas. In the context of explainable artificial intelligence (XAI), trust is crucial as it ensures that AI systems behave consistently, fairly, and ethically. In the present article, we explore XAI, reliable XAI, and several practical uses for reliable XAI. Once more, we go over the three main components-transparency, explainability, and trustworthiness of XAI-that we determined are pertinent in this situation. We present an overview of recent scientific studies that employ trustworthy XAI in various application fields. In the end, trustworthiness is crucial for establishing and maintaining trust between humans and AI systems, facilitating the integration of AI systems into various applications and domains for the benefit of society.","sentences":["One of today's most significant and transformative technologies is the rapidly developing field of artificial intelligence (AI).","Deined as a computer system that simulates human cognitive processes, AI is present in many aspects of our daily lives, from the self-driving cars on the road to the intelligence (AI) because some AI systems are so complex and opaque.","With millions of parameters and layers, these system-deep neural networks in particular-make it difficult for humans to comprehend accountability, prejudice, and justice are raised by the opaqueness of its decision-making process.","AI has a lot of potential, but it also comes with a lot of difficulties and moral dilemmas.","In the context of explainable artificial intelligence (XAI), trust is crucial as it ensures that AI systems behave consistently, fairly, and ethically.","In the present article, we explore XAI, reliable XAI, and several practical uses for reliable XAI.","Once more, we go over the three main components-transparency, explainability, and trustworthiness of XAI-that we determined are pertinent in this situation.","We present an overview of recent scientific studies that employ trustworthy XAI in various application fields.","In the end, trustworthiness is crucial for establishing and maintaining trust between humans and AI systems, facilitating the integration of AI systems into various applications and domains for the benefit of society."],"url":"http://arxiv.org/abs/2410.17139v1"}
{"created":"2024-10-22 16:08:09","title":"AlphaChimp: Tracking and Behavior Recognition of Chimpanzees","abstract":"Understanding non-human primate behavior is crucial for improving animal welfare, modeling social behavior, and gaining insights into both distinctly human and shared behaviors. Despite recent advances in computer vision, automated analysis of primate behavior remains challenging due to the complexity of their social interactions and the lack of specialized algorithms. Existing methods often struggle with the nuanced behaviors and frequent occlusions characteristic of primate social dynamics. This study aims to develop an effective method for automated detection, tracking, and recognition of chimpanzee behaviors in video footage. Here we show that our proposed method, AlphaChimp, an end-to-end approach that simultaneously detects chimpanzee positions and estimates behavior categories from videos, significantly outperforms existing methods in behavior recognition. AlphaChimp achieves approximately 10% higher tracking accuracy and a 20% improvement in behavior recognition compared to state-of-the-art methods, particularly excelling in the recognition of social behaviors. This superior performance stems from AlphaChimp's innovative architecture, which integrates temporal feature fusion with a Transformer-based self-attention mechanism, enabling more effective capture and interpretation of complex social interactions among chimpanzees. Our approach bridges the gap between computer vision and primatology, enhancing technical capabilities and deepening our understanding of primate communication and sociality. We release our code and models and hope this will facilitate future research in animal social dynamics. This work contributes to ethology, cognitive science, and artificial intelligence, offering new perspectives on social intelligence.","sentences":["Understanding non-human primate behavior is crucial for improving animal welfare, modeling social behavior, and gaining insights into both distinctly human and shared behaviors.","Despite recent advances in computer vision, automated analysis of primate behavior remains challenging due to the complexity of their social interactions and the lack of specialized algorithms.","Existing methods often struggle with the nuanced behaviors and frequent occlusions characteristic of primate social dynamics.","This study aims to develop an effective method for automated detection, tracking, and recognition of chimpanzee behaviors in video footage.","Here we show that our proposed method, AlphaChimp, an end-to-end approach that simultaneously detects chimpanzee positions and estimates behavior categories from videos, significantly outperforms existing methods in behavior recognition.","AlphaChimp achieves approximately 10% higher tracking accuracy and a 20% improvement in behavior recognition compared to state-of-the-art methods, particularly excelling in the recognition of social behaviors.","This superior performance stems from AlphaChimp's innovative architecture, which integrates temporal feature fusion with a Transformer-based self-attention mechanism, enabling more effective capture and interpretation of complex social interactions among chimpanzees.","Our approach bridges the gap between computer vision and primatology, enhancing technical capabilities and deepening our understanding of primate communication and sociality.","We release our code and models and hope this will facilitate future research in animal social dynamics.","This work contributes to ethology, cognitive science, and artificial intelligence, offering new perspectives on social intelligence."],"url":"http://arxiv.org/abs/2410.17136v1"}
{"created":"2024-10-22 16:06:33","title":"TELII: Temporal Event Level Inverted Indexing for Cohort Discovery on a Large Covid-19 EHR Dataset","abstract":"Cohort discovery is a crucial step in clinical research on Electronic Health Record (EHR) data. Temporal queries, which are common in cohort discovery, can be time-consuming and prone to errors when processed on large EHR datasets. In this work, we introduce TELII, a temporal event level inverted indexing method designed for cohort discovery on large EHR datasets. TELII is engineered to pre-compute and store the relations along with the time difference between events, thereby providing fast and accurate temporal query capabilities. We implemented TELII for the OPTUM de-identified COVID-19 EHR dataset, which contains data from 8.87 million patients. We demonstrate four common temporal query tasks and their implementation using TELII with a MongoDB backend. Our results show that the temporal query speed for TELII is up to 2000 times faster than that of existing non-temporal inverted indexes. TELII achieves millisecond-level response times, enabling users to quickly explore event relations and find preliminary evidence for their research questions. Not only is TELII practical and straightforward to implement, but it also offers easy adaptability to other EHR datasets. These advantages underscore TELII's potential to serve as the query engine for EHR-based applications, ensuring fast, accurate, and user-friendly query responses.","sentences":["Cohort discovery is a crucial step in clinical research on Electronic Health Record (EHR) data.","Temporal queries, which are common in cohort discovery, can be time-consuming and prone to errors when processed on large EHR datasets.","In this work, we introduce TELII, a temporal event level inverted indexing method designed for cohort discovery on large EHR datasets.","TELII is engineered to pre-compute and store the relations along with the time difference between events, thereby providing fast and accurate temporal query capabilities.","We implemented TELII for the OPTUM de-identified COVID-19 EHR dataset, which contains data from 8.87 million patients.","We demonstrate four common temporal query tasks and their implementation using TELII with a MongoDB backend.","Our results show that the temporal query speed for TELII is up to 2000 times faster than that of existing non-temporal inverted indexes.","TELII achieves millisecond-level response times, enabling users to quickly explore event relations and find preliminary evidence for their research questions.","Not only is TELII practical and straightforward to implement, but it also offers easy adaptability to other EHR datasets.","These advantages underscore TELII's potential to serve as the query engine for EHR-based applications, ensuring fast, accurate, and user-friendly query responses."],"url":"http://arxiv.org/abs/2410.17134v1"}
{"created":"2024-10-22 16:04:03","title":"Aligning Large Language Models via Self-Steering Optimization","abstract":"Automated alignment develops alignment systems with minimal human intervention. The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation. In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm that autonomously generates high-quality preference signals based on predefined principles during iterative training, eliminating the need for manual annotation. $SSO$ maintains the accuracy of signals by ensuring a consistent gap between chosen and rejected responses while keeping them both on-policy to suit the current policy model's learning capacity. $SSO$ can benefit the online and offline training of the policy model, as well as enhance the training of reward models. We validate the effectiveness of $SSO$ with two foundation models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy preference signals throughout iterative training. Without any manual annotation or external models, $SSO$ leads to significant performance improvements across six subjective or objective benchmarks. Besides, the preference data generated by $SSO$ significantly enhanced the performance of the reward model on Rewardbench. Our work presents a scalable approach to preference optimization, paving the way for more efficient and effective automated alignment.","sentences":["Automated alignment develops alignment systems with minimal human intervention.","The key to automated alignment lies in providing learnable and accurate preference signals for preference learning without human annotation.","In this paper, we introduce Self-Steering Optimization ($SSO$), an algorithm that autonomously generates high-quality preference signals based on predefined principles during iterative training, eliminating the need for manual annotation.","$SSO$ maintains the accuracy of signals by ensuring a consistent gap between chosen and rejected responses while keeping them both on-policy to suit the current policy model's learning capacity.","$SSO$ can benefit the online and offline training of the policy model, as well as enhance the training of reward models.","We validate the effectiveness of $SSO$ with two foundation models, Qwen2 and Llama3.1, indicating that it provides accurate, on-policy preference signals throughout iterative training.","Without any manual annotation or external models, $SSO$ leads to significant performance improvements across six subjective or objective benchmarks.","Besides, the preference data generated by $SSO$ significantly enhanced the performance of the reward model on Rewardbench.","Our work presents a scalable approach to preference optimization, paving the way for more efficient and effective automated alignment."],"url":"http://arxiv.org/abs/2410.17131v1"}
{"created":"2024-10-22 16:00:26","title":"PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles","abstract":"Users can divulge sensitive information to proprietary LLM providers, raising significant privacy concerns. While open-source models, hosted locally on the user's machine, alleviate some concerns, models that users can host locally are often less capable than proprietary frontier models. Toward preserving user privacy while retaining the best quality, we propose Privacy-Conscious Delegation, a novel task for chaining API-based and local models. We utilize recent public collections of user-LLM interactions to construct a natural benchmark called PUPA, which contains personally identifiable information (PII). To study potential approaches, we devise PAPILLON, a multi-stage LLM pipeline that uses prompt optimization to address a simpler version of our task. Our best pipeline maintains high response quality for 85.5% of user queries while restricting privacy leakage to only 7.5%. We still leave a large margin to the generation quality of proprietary LLMs for future work. Our data and code will be available at https://github.com/siyan-sylvia-li/PAPILLON.","sentences":["Users can divulge sensitive information to proprietary LLM providers, raising significant privacy concerns.","While open-source models, hosted locally on the user's machine, alleviate some concerns, models that users can host locally are often less capable than proprietary frontier models.","Toward preserving user privacy while retaining the best quality, we propose Privacy-Conscious Delegation, a novel task for chaining API-based and local models.","We utilize recent public collections of user-LLM interactions to construct a natural benchmark called PUPA, which contains personally identifiable information (PII).","To study potential approaches, we devise PAPILLON, a multi-stage LLM pipeline that uses prompt optimization to address a simpler version of our task.","Our best pipeline maintains high response quality for 85.5% of user queries while restricting privacy leakage to only 7.5%.","We still leave a large margin to the generation quality of proprietary LLMs for future work.","Our data and code will be available at https://github.com/siyan-sylvia-li/PAPILLON."],"url":"http://arxiv.org/abs/2410.17127v1"}
{"created":"2024-10-22 15:59:58","title":"Exploring RL-based LLM Training for Formal Language Tasks with Programmed Rewards","abstract":"Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning from Human Feedback to align large language models (LLMs) with downstream tasks. This paper investigates the feasibility of using PPO for direct reinforcement learning (RL) from explicitly programmed reward signals, as opposed to indirect learning from human feedback via an intermediary reward model. We focus on tasks expressed through formal languages, such as mathematics and programming, where explicit reward functions can be programmed to automatically assess the quality of generated outputs. We apply this approach to a sentiment alignment task, a simple arithmetic task, and a more complex game synthesis task. The sentiment alignment task replicates prior research and serves to validate our experimental setup. Our results show that pure RL-based training for the two formal language tasks is challenging, with success being limited even for the simple arithmetic task. We propose a novel batch-entropy regularization term to aid exploration, although training is not yet entirely stable. Our findings suggest that direct RL training of LLMs may be more suitable for relatively minor changes, such as alignment, than for learning new tasks altogether, even if an informative reward signal can be expressed programmatically.","sentences":["Proximal Policy Optimization (PPO) is commonly used in Reinforcement Learning from Human Feedback to align large language models (LLMs) with downstream tasks.","This paper investigates the feasibility of using PPO for direct reinforcement learning (RL) from explicitly programmed reward signals, as opposed to indirect learning from human feedback via an intermediary reward model.","We focus on tasks expressed through formal languages, such as mathematics and programming, where explicit reward functions can be programmed to automatically assess the quality of generated outputs.","We apply this approach to a sentiment alignment task, a simple arithmetic task, and a more complex game synthesis task.","The sentiment alignment task replicates prior research and serves to validate our experimental setup.","Our results show that pure RL-based training for the two formal language tasks is challenging, with success being limited even for the simple arithmetic task.","We propose a novel batch-entropy regularization term to aid exploration, although training is not yet entirely stable.","Our findings suggest that direct RL training of LLMs may be more suitable for relatively minor changes, such as alignment, than for learning new tasks altogether, even if an informative reward signal can be expressed programmatically."],"url":"http://arxiv.org/abs/2410.17126v1"}
{"created":"2024-10-22 15:49:53","title":"Learning Load Balancing with GNN in MPTCP-Enabled Heterogeneous Networks","abstract":"Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a promising paradigm of heterogeneous network (HetNet), attributed to the complementary physical properties of optical spectra and radio frequency. However, the current development of such HetNets is mostly bottlenecked by the existing transmission control protocol (TCP), which restricts the user equipment (UE) to connecting one access point (AP) at a time. While the ongoing investigation on multipath TCP (MPTCP) can bring significant benefits, it complicates the network topology of HetNets, making the existing load balancing (LB) learning models less effective. Driven by this, we propose a graph neural network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets, which results in a partial mesh topology. Such a topology can be modeled as a graph, with the channel state information and data rate requirement embedded as node features, while the LB solutions are deemed as edge labels. Compared to the conventional deep neural network (DNN), the proposed GNN-based model exhibits two key strengths: i) it can better interpret a complex network topology; and ii) it can handle various numbers of APs and UEs with a single trained model. Simulation results show that against the traditional optimisation method, the proposed learning model can achieve near-optimal throughput within a gap of 11.5%, while reducing the inference time by 4 orders of magnitude. In contrast to the DNN model, the new method can improve the network throughput by up to 21.7%, at a similar inference time level.","sentences":["Hybrid light fidelity (LiFi) and wireless fidelity (WiFi) networks are a promising paradigm of heterogeneous network (HetNet), attributed to the complementary physical properties of optical spectra and radio frequency.","However, the current development of such HetNets is mostly bottlenecked by the existing transmission control protocol (TCP), which restricts the user equipment (UE) to connecting one access point (AP) at a time.","While the ongoing investigation on multipath TCP (MPTCP) can bring significant benefits, it complicates the network topology of HetNets, making the existing load balancing (LB) learning models less effective.","Driven by this, we propose a graph neural network (GNN)-based model to tackle the LB problem for MPTCP-enabled HetNets, which results in a partial mesh topology.","Such a topology can be modeled as a graph, with the channel state information and data rate requirement embedded as node features, while the LB solutions are deemed as edge labels.","Compared to the conventional deep neural network (DNN), the proposed GNN-based model exhibits two key strengths: i) it can better interpret a complex network topology; and ii) it can handle various numbers of APs and UEs with a single trained model.","Simulation results show that against the traditional optimisation method, the proposed learning model can achieve near-optimal throughput within a gap of 11.5%, while reducing the inference time by 4 orders of magnitude.","In contrast to the DNN model, the new method can improve the network throughput by up to 21.7%, at a similar inference time level."],"url":"http://arxiv.org/abs/2410.17118v1"}
{"created":"2024-10-22 15:48:00","title":"Security and RAS in the Computing Continuum","abstract":"Security and RAS are two non-functional requirements under focus for current systems developed for the computing continuum. Due to the increased number of interconnected computer systems across the continuum, security becomes especially pervasive at all levels, from the smallest edge device to the high-performance cloud at the other end. Similarly, RAS (Reliability, Availability, and Serviceability) ensures the robustness of a system towards hardware defects. Namely, making them reliable, with high availability and design for easy service. In this paper and as a result of the Vitamin-V EU project, the authors detail the comprehensive approach to malware and hardware attack detection; as well as, the RAS features envisioned for future systems across the computing continuum.","sentences":["Security and RAS are two non-functional requirements under focus for current systems developed for the computing continuum.","Due to the increased number of interconnected computer systems across the continuum, security becomes especially pervasive at all levels, from the smallest edge device to the high-performance cloud at the other end.","Similarly, RAS (Reliability, Availability, and Serviceability) ensures the robustness of a system towards hardware defects.","Namely, making them reliable, with high availability and design for easy service.","In this paper and as a result of the Vitamin-V EU project, the authors detail the comprehensive approach to malware and hardware attack detection; as well as, the RAS features envisioned for future systems across the computing continuum."],"url":"http://arxiv.org/abs/2410.17116v1"}
{"created":"2024-10-22 15:40:44","title":"Lunar Subterra: a Self-Integrative Unit with an Automated Drilling System","abstract":"As humans venture deeper into space, the need for a lunar settlement, housing the first group of settlers, grows steadily. By means of new technologies such as in situ resource utilisation (ISRU) as well as computational design, this goal can be implemented in present years. Providing the first arrivals with an immediate underground habitat safe from radiation and other environmental constraints is of crucial importance to initialise a prolonged mission on the Moon. The project's proposal revolves around the idea of establishing a base which provides an immediately habitable space with the possibility for future expansion. Advanced construction methods and sustainable practices lay the groundwork for a permanent human presence, predominantly based on ISRU. This paper outlines a two-phase initiative aimed at the foundation of the Lunar Subterra, followed by an extension of the habitat above ground. Following our collaboration with the PoliSpace Sparc Student Association group, a Virtual Reality (VR) reproduction of the proposed habitat enabled quick iterative testing of the habitable space with the use of a Meta Quest 2 headset. This not only allowed an evaluation of the environment and its impact on human residents but also eradicated the need for tangible models to conceptualise the idea, enabling rapid user-centred design and implementation in the future of space exploration.","sentences":["As humans venture deeper into space, the need for a lunar settlement, housing the first group of settlers, grows steadily.","By means of new technologies such as in situ resource utilisation (ISRU) as well as computational design, this goal can be implemented in present years.","Providing the first arrivals with an immediate underground habitat safe from radiation and other environmental constraints is of crucial importance to initialise a prolonged mission on the Moon.","The project's proposal revolves around the idea of establishing a base which provides an immediately habitable space with the possibility for future expansion.","Advanced construction methods and sustainable practices lay the groundwork for a permanent human presence, predominantly based on ISRU.","This paper outlines a two-phase initiative aimed at the foundation of the Lunar Subterra, followed by an extension of the habitat above ground.","Following our collaboration with the PoliSpace Sparc Student Association group, a Virtual Reality (VR) reproduction of the proposed habitat enabled quick iterative testing of the habitable space with the use of a Meta Quest 2 headset.","This not only allowed an evaluation of the environment and its impact on human residents but also eradicated the need for tangible models to conceptualise the idea, enabling rapid user-centred design and implementation in the future of space exploration."],"url":"http://arxiv.org/abs/2410.17114v1"}
{"created":"2024-10-22 15:37:58","title":"A Unified Activity Detection Framework for Massive Access: Beyond the Block-Fading Paradigm","abstract":"The wireless channel changes continuously with time and frequency and the block-fading assumption, which is popular in many theoretical analyses, never holds true in practical scenarios. This discrepancy is critical for user activity detection in grant-free random access, where joint processing across multiple coherence blocks is undesirable, especially when the environment becomes more dynamic. In this paper, we develop a framework for low-dimensional approximation of the channel to capture its variations over time and frequency, and use this framework to implement robust activity detection algorithms. Furthermore, we investigate how to efficiently estimate the principal subspace that defines the low-dimensional approximation. We also examine pilot hopping as a way of exploiting time and frequency diversity in scenarios with limited channel coherence, and extend our algorithms to this case. Through numerical examples, we demonstrate a substantial performance improvement achieved by our proposed framework.","sentences":["The wireless channel changes continuously with time and frequency and the block-fading assumption, which is popular in many theoretical analyses, never holds true in practical scenarios.","This discrepancy is critical for user activity detection in grant-free random access, where joint processing across multiple coherence blocks is undesirable, especially when the environment becomes more dynamic.","In this paper, we develop a framework for low-dimensional approximation of the channel to capture its variations over time and frequency, and use this framework to implement robust activity detection algorithms.","Furthermore, we investigate how to efficiently estimate the principal subspace that defines the low-dimensional approximation.","We also examine pilot hopping as a way of exploiting time and frequency diversity in scenarios with limited channel coherence, and extend our algorithms to this case.","Through numerical examples, we demonstrate a substantial performance improvement achieved by our proposed framework."],"url":"http://arxiv.org/abs/2410.17113v1"}
{"created":"2024-10-22 15:37:46","title":"Enhancing Answer Attribution for Faithful Text Generation with Large Language Models","abstract":"The increasing popularity of Large Language Models (LLMs) in recent years has changed the way users interact with and pose questions to AI-based conversational systems. An essential aspect for increasing the trustworthiness of generated LLM answers is the ability to trace the individual claims from responses back to relevant sources that support them, the process known as answer attribution. While recent work has started exploring the task of answer attribution in LLMs, some challenges still remain. In this work, we first perform a case study analyzing the effectiveness of existing answer attribution methods, with a focus on subtasks of answer segmentation and evidence retrieval. Based on the observed shortcomings, we propose new methods for producing more independent and contextualized claims for better retrieval and attribution. The new methods are evaluated and shown to improve the performance of answer attribution components. We end with a discussion and outline of future directions for the task.","sentences":["The increasing popularity of Large Language Models (LLMs) in recent years has changed the way users interact with and pose questions to AI-based conversational systems.","An essential aspect for increasing the trustworthiness of generated LLM answers is the ability to trace the individual claims from responses back to relevant sources that support them, the process known as answer attribution.","While recent work has started exploring the task of answer attribution in LLMs, some challenges still remain.","In this work, we first perform a case study analyzing the effectiveness of existing answer attribution methods, with a focus on subtasks of answer segmentation and evidence retrieval.","Based on the observed shortcomings, we propose new methods for producing more independent and contextualized claims for better retrieval and attribution.","The new methods are evaluated and shown to improve the performance of answer attribution components.","We end with a discussion and outline of future directions for the task."],"url":"http://arxiv.org/abs/2410.17112v1"}
{"created":"2024-10-22 15:36:04","title":"Permutation Picture of Graph Combinatorial Optimization Problems","abstract":"This paper proposes a framework that formulates a wide range of graph combinatorial optimization problems using permutation-based representations. These problems include the travelling salesman problem, maximum independent set, maximum cut, and various other related problems. This work potentially opens up new avenues for algorithm design in neural combinatorial optimization, bridging the gap between discrete and continuous optimization techniques.","sentences":["This paper proposes a framework that formulates a wide range of graph combinatorial optimization problems using permutation-based representations.","These problems include the travelling salesman problem, maximum independent set, maximum cut, and various other related problems.","This work potentially opens up new avenues for algorithm design in neural combinatorial optimization, bridging the gap between discrete and continuous optimization techniques."],"url":"http://arxiv.org/abs/2410.17111v1"}
{"created":"2024-10-22 15:30:24","title":"Feature Homomorphism -- A Cryptographic Scheme For Data Verification Under Ciphertext-Only Conditions","abstract":"Privacy computing involves the extensive exchange and processing of encrypted data. For the parties involved in these interactions, how to determine the consistency of exchanged data without accessing the original data, ensuring tamper resistance, non-repudiation, quality traceability, indexing, and retrieval during the use of encrypted data, which is a key topic of achieving \"Data Availability versus Visibility\". This paper proposes a new type of homomorphism: Feature Homomorphism, and based on this feature, introduces a cryptographic scheme for data verification under ciphertext-only conditions. The proposed scheme involves designing a group of algorithms that meet the requirements outlined in this paper, including encryption/decryption algorithms and Feature Homomorphic Algorithm. This group of algorithms not only allows for the encryption and decryption of data but also ensures that the plaintext and its corresponding ciphertext, encrypted using the specified encryption algorithm, satisfy the following property: the eigenvalue of the plaintext obtained using the Feature Homomorphic Algorithm is equal to the eigenvalue of the ciphertext obtained using the same algorithm. With this group of algorithms, it is possible to verify data consistency directly by comparing the eigenvalues of the plaintext and ciphertext without accessing the original data (i.e., under ciphertext-only conditions). This can be used for tamper resistance, non-repudiation, and quality traceability. Additionally, the eigenvalue can serve as a ciphertext index, enabling searchable encryption. This scheme completes a piece of the puzzle in homomorphic encryption.   Keywords: Privacy Computing, Data Consistency, Searchable Encryption, Zero-Knowledge Proof, Feature Homomorphism","sentences":["Privacy computing involves the extensive exchange and processing of encrypted data.","For the parties involved in these interactions, how to determine the consistency of exchanged data without accessing the original data, ensuring tamper resistance, non-repudiation, quality traceability, indexing, and retrieval during the use of encrypted data, which is a key topic of achieving \"Data Availability versus Visibility\".","This paper proposes a new type of homomorphism: Feature Homomorphism, and based on this feature, introduces a cryptographic scheme for data verification under ciphertext-only conditions.","The proposed scheme involves designing a group of algorithms that meet the requirements outlined in this paper, including encryption/decryption algorithms and Feature Homomorphic Algorithm.","This group of algorithms not only allows for the encryption and decryption of data but also ensures that the plaintext and its corresponding ciphertext, encrypted using the specified encryption algorithm, satisfy the following property: the eigenvalue of the plaintext obtained using the Feature Homomorphic Algorithm is equal to the eigenvalue of the ciphertext obtained using the same algorithm.","With this group of algorithms, it is possible to verify data consistency directly by comparing the eigenvalues of the plaintext and ciphertext without accessing the original data (i.e., under ciphertext-only conditions).","This can be used for tamper resistance, non-repudiation, and quality traceability.","Additionally, the eigenvalue can serve as a ciphertext index, enabling searchable encryption.","This scheme completes a piece of the puzzle in homomorphic encryption.   ","Keywords: Privacy Computing, Data Consistency, Searchable Encryption, Zero-Knowledge Proof, Feature Homomorphism"],"url":"http://arxiv.org/abs/2410.17106v1"}
{"created":"2024-10-22 15:28:18","title":"CLAP: Concave Linear APproximation for Quadratic Graph Matching","abstract":"Solving point-wise feature correspondence in visual data is a fundamental problem in computer vision. A powerful model that addresses this challenge is to formulate it as graph matching, which entails solving a Quadratic Assignment Problem (QAP) with node-wise and edge-wise constraints. However, solving such a QAP can be both expensive and difficult due to numerous local extreme points. In this work, we introduce a novel linear model and solver designed to accelerate the computation of graph matching. Specifically, we employ a positive semi-definite matrix approximation to establish the structural attribute constraint.We then transform the original QAP into a linear model that is concave for maximization. This model can subsequently be solved using the Sinkhorn optimal transport algorithm, known for its enhanced efficiency and numerical stability compared to existing approaches. Experimental results on the widely used benchmark PascalVOC showcase that our algorithm achieves state-of-the-art performance with significantly improved efficiency. Source code: https://github.com/xmlyqing00/clap","sentences":["Solving point-wise feature correspondence in visual data is a fundamental problem in computer vision.","A powerful model that addresses this challenge is to formulate it as graph matching, which entails solving a Quadratic Assignment Problem (QAP) with node-wise and edge-wise constraints.","However, solving such a QAP can be both expensive and difficult due to numerous local extreme points.","In this work, we introduce a novel linear model and solver designed to accelerate the computation of graph matching.","Specifically, we employ a positive semi-definite matrix approximation to establish the structural attribute constraint.","We then transform the original QAP into a linear model that is concave for maximization.","This model can subsequently be solved using the Sinkhorn optimal transport algorithm, known for its enhanced efficiency and numerical stability compared to existing approaches.","Experimental results on the widely used benchmark PascalVOC showcase that our algorithm achieves state-of-the-art performance with significantly improved efficiency.","Source code: https://github.com/xmlyqing00/clap"],"url":"http://arxiv.org/abs/2410.17101v1"}
{"created":"2024-10-22 15:22:58","title":"Human-LLM Hybrid Text Answer Aggregation for Crowd Annotations","abstract":"The quality is a crucial issue for crowd annotations. Answer aggregation is an important type of solution. The aggregated answers estimated from multiple crowd answers to the same instance are the eventually collected annotations, rather than the individual crowd answers themselves. Recently, the capability of Large Language Models (LLMs) on data annotation tasks has attracted interest from researchers. Most of the existing studies mainly focus on the average performance of individual crowd workers; several recent works studied the scenarios of aggregation on categorical labels and LLMs used as label creators. However, the scenario of aggregation on text answers and the role of LLMs as aggregators are not yet well-studied. In this paper, we investigate the capability of LLMs as aggregators in the scenario of close-ended crowd text answer aggregation. We propose a human-LLM hybrid text answer aggregation method with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework. We make the experiments based on public crowdsourcing datasets. The results show the effectiveness of our approach based on the collaboration of crowd workers and LLMs.","sentences":["The quality is a crucial issue for crowd annotations.","Answer aggregation is an important type of solution.","The aggregated answers estimated from multiple crowd answers to the same instance are the eventually collected annotations, rather than the individual crowd answers themselves.","Recently, the capability of Large Language Models (LLMs) on data annotation tasks has attracted interest from researchers.","Most of the existing studies mainly focus on the average performance of individual crowd workers; several recent works studied the scenarios of aggregation on categorical labels and LLMs used as label creators.","However, the scenario of aggregation on text answers and the role of LLMs as aggregators are not yet well-studied.","In this paper, we investigate the capability of LLMs as aggregators in the scenario of close-ended crowd text answer aggregation.","We propose a human-LLM hybrid text answer aggregation method with a Creator-Aggregator Multi-Stage (CAMS) crowdsourcing framework.","We make the experiments based on public crowdsourcing datasets.","The results show the effectiveness of our approach based on the collaboration of crowd workers and LLMs."],"url":"http://arxiv.org/abs/2410.17099v1"}
{"created":"2024-10-22 15:22:53","title":"Masked Differential Privacy","abstract":"Privacy-preserving computer vision is an important emerging problem in machine learning and artificial intelligence. The prevalent methods tackling this problem use differential privacy or anonymization and obfuscation techniques to protect the privacy of individuals. In both cases, the utility of the trained model is sacrificed heavily in this process. In this work, we propose an effective approach called masked differential privacy (MaskDP), which allows for controlling sensitive regions where differential privacy is applied, in contrast to applying DP on the entire input. Our method operates selectively on the data and allows for defining non-sensitive spatio-temporal regions without DP application or combining differential privacy with other privacy techniques within data samples. Experiments on four challenging action recognition datasets demonstrate that our proposed techniques result in better utility-privacy trade-offs compared to standard differentially private training in the especially demanding $\\epsilon<1$ regime.","sentences":["Privacy-preserving computer vision is an important emerging problem in machine learning and artificial intelligence.","The prevalent methods tackling this problem use differential privacy or anonymization and obfuscation techniques to protect the privacy of individuals.","In both cases, the utility of the trained model is sacrificed heavily in this process.","In this work, we propose an effective approach called masked differential privacy (MaskDP), which allows for controlling sensitive regions where differential privacy is applied, in contrast to applying DP on the entire input.","Our method operates selectively on the data and allows for defining non-sensitive spatio-temporal regions without DP application or combining differential privacy with other privacy techniques within data samples.","Experiments on four challenging action recognition datasets demonstrate that our proposed techniques result in better utility-privacy trade-offs compared to standard differentially private training in the especially demanding $\\epsilon<1$ regime."],"url":"http://arxiv.org/abs/2410.17098v1"}
{"created":"2024-10-22 15:21:00","title":"Inferentially-Private Private Information","abstract":"Information disclosure can compromise privacy when revealed information is correlated with private information. We consider the notion of inferential privacy, which measures privacy leakage by bounding the inferential power a Bayesian adversary can gain by observing a released signal. Our goal is to devise an inferentially-private private information structure that maximizes the informativeness of the released signal, following the Blackwell ordering principle, while adhering to inferential privacy constraints. To achieve this, we devise an efficient release mechanism that achieves the inferentially-private Blackwell optimal private information structure for the setting where the private information is binary. Additionally, we propose a programming approach to compute the optimal structure for general cases given the utility function. The design of our mechanisms builds on our geometric characterization of the Blackwell-optimal disclosure mechanisms under privacy constraints, which may be of independent interest.","sentences":["Information disclosure can compromise privacy when revealed information is correlated with private information.","We consider the notion of inferential privacy, which measures privacy leakage by bounding the inferential power a Bayesian adversary can gain by observing a released signal.","Our goal is to devise an inferentially-private private information structure that maximizes the informativeness of the released signal, following the Blackwell ordering principle, while adhering to inferential privacy constraints.","To achieve this, we devise an efficient release mechanism that achieves the inferentially-private Blackwell optimal private information structure for the setting where the private information is binary.","Additionally, we propose a programming approach to compute the optimal structure for general cases given the utility function.","The design of our mechanisms builds on our geometric characterization of the Blackwell-optimal disclosure mechanisms under privacy constraints, which may be of independent interest."],"url":"http://arxiv.org/abs/2410.17095v1"}
{"created":"2024-10-22 15:14:54","title":"Science Out of Its Ivory Tower: Improving Accessibility with Reinforcement Learning","abstract":"A vast amount of scholarly work is published daily, yet much of it remains inaccessible to the general public due to dense jargon and complex language. To address this challenge in science communication, we introduce a reinforcement learning framework that fine-tunes a language model to rewrite scholarly abstracts into more comprehensible versions. Guided by a carefully balanced combination of word- and sentence-level accessibility rewards, our language model effectively substitutes technical terms with more accessible alternatives, a task which models supervised fine-tuned or guided by conventional readability measures struggle to accomplish. Our best model adjusts the readability level of scholarly abstracts by approximately six U.S. grade levels -- in other words, from a postgraduate to a high school level. This translates to roughly a 90% relative boost over the supervised fine-tuning baseline, all while maintaining factual accuracy and high-quality language. An in-depth analysis of our approach shows that balanced rewards lead to systematic modifications in the base model, likely contributing to smoother optimization and superior performance. We envision this work as a step toward bridging the gap between scholarly research and the general public, particularly younger readers and those without a college degree.","sentences":["A vast amount of scholarly work is published daily, yet much of it remains inaccessible to the general public due to dense jargon and complex language.","To address this challenge in science communication, we introduce a reinforcement learning framework that fine-tunes a language model to rewrite scholarly abstracts into more comprehensible versions.","Guided by a carefully balanced combination of word- and sentence-level accessibility rewards, our language model effectively substitutes technical terms with more accessible alternatives, a task which models supervised fine-tuned or guided by conventional readability measures struggle to accomplish.","Our best model adjusts the readability level of scholarly abstracts by approximately six U.S. grade levels -- in other words, from a postgraduate to a high school level.","This translates to roughly a 90% relative boost over the supervised fine-tuning baseline, all while maintaining factual accuracy and high-quality language.","An in-depth analysis of our approach shows that balanced rewards lead to systematic modifications in the base model, likely contributing to smoother optimization and superior performance.","We envision this work as a step toward bridging the gap between scholarly research and the general public, particularly younger readers and those without a college degree."],"url":"http://arxiv.org/abs/2410.17088v1"}
{"created":"2024-10-22 15:13:13","title":"Exploration and Persuasion","abstract":"How to incentivize self-interested agents to explore when they prefer to exploit? Consider a population of self-interested agents that make decisions under uncertainty. They \"explore\" to acquire new information and \"exploit\" this information to make good decisions. Collectively they need to balance these two objectives, but their incentives are skewed toward exploitation. This is because exploration is costly, but its benefits are spread over many agents in the future.   \"Incentivized Exploration\" addresses this issue via strategic communication. Consider a benign ``principal\" which can communicate with the agents and make recommendations, but cannot force the agents to comply. Moreover, suppose the principal can observe the agents' decisions and the outcomes of these decisions. The goal is to design a communication and recommendation policy which (i) achieves a desirable balance between exploration and exploitation, and (ii) incentivizes the agents to follow recommendations. What makes it feasible is \"information asymmetry\": the principal knows more than any one agent, as it collects information from many. It is essential that the principal does not fully reveal all its knowledge to the agents.   Incentivized exploration combines two important problems in, resp., machine learning and theoretical economics. First, if agents always follow recommendations, the principal faces a multi-armed bandit problem: essentially, design an algorithm that balances exploration and exploitation. Second, interaction with a single agent corresponds to \"Bayesian persuasion\", where a principal leverages information asymmetry to convince an agent to take a particular action. We provide a brief but self-contained introduction to each problem through the lens of incentivized exploration, solving a key special case of the former as a sub-problem of the latter.","sentences":["How to incentivize self-interested agents to explore when they prefer to exploit?","Consider a population of self-interested agents that make decisions under uncertainty.","They \"explore\" to acquire new information and \"exploit\" this information to make good decisions.","Collectively they need to balance these two objectives, but their incentives are skewed toward exploitation.","This is because exploration is costly, but its benefits are spread over many agents in the future.   ","\"Incentivized Exploration\" addresses this issue via strategic communication.","Consider a benign ``principal\" which can communicate with the agents and make recommendations, but cannot force the agents to comply.","Moreover, suppose the principal can observe the agents' decisions and the outcomes of these decisions.","The goal is to design a communication and recommendation policy which (i) achieves a desirable balance between exploration and exploitation, and (ii) incentivizes the agents to follow recommendations.","What makes it feasible is \"information asymmetry\": the principal knows more than any one agent, as it collects information from many.","It is essential that the principal does not fully reveal all its knowledge to the agents.   ","Incentivized exploration combines two important problems in, resp., machine learning and theoretical economics.","First, if agents always follow recommendations, the principal faces a multi-armed bandit problem: essentially, design an algorithm that balances exploration and exploitation.","Second, interaction with a single agent corresponds to \"Bayesian persuasion\", where a principal leverages information asymmetry to convince an agent to take a particular action.","We provide a brief but self-contained introduction to each problem through the lens of incentivized exploration, solving a key special case of the former as a sub-problem of the latter."],"url":"http://arxiv.org/abs/2410.17086v1"}
{"created":"2024-10-22 15:07:07","title":"A Survey on Deep Learning-based Gaze Direction Regression: Searching for the State-of-the-art","abstract":"In this paper, we present a survey of deep learning-based methods for the regression of gaze direction vector from head and eye images. We describe in detail numerous published methods with a focus on the input data, architecture of the model, and loss function used to supervise the model. Additionally, we present a list of datasets that can be used to train and evaluate gaze direction regression methods. Furthermore, we noticed that the results reported in the literature are often not comparable one to another due to differences in the validation or even test subsets used. To address this problem, we re-evaluated several methods on the commonly used in-the-wild Gaze360 dataset using the same validation setup. The experimental results show that the latest methods, although claiming state-of-the-art results, significantly underperform compared with some older methods. Finally, we show that the temporal models outperform the static models under static test conditions.","sentences":["In this paper, we present a survey of deep learning-based methods for the regression of gaze direction vector from head and eye images.","We describe in detail numerous published methods with a focus on the input data, architecture of the model, and loss function used to supervise the model.","Additionally, we present a list of datasets that can be used to train and evaluate gaze direction regression methods.","Furthermore, we noticed that the results reported in the literature are often not comparable one to another due to differences in the validation or even test subsets used.","To address this problem, we re-evaluated several methods on the commonly used in-the-wild Gaze360 dataset using the same validation setup.","The experimental results show that the latest methods, although claiming state-of-the-art results, significantly underperform compared with some older methods.","Finally, we show that the temporal models outperform the static models under static test conditions."],"url":"http://arxiv.org/abs/2410.17082v1"}
{"created":"2024-10-22 15:02:37","title":"Continuous Speech Tokenizer in Text To Speech","abstract":"The fusion of speech and language in the era of large language models has garnered significant attention. Discrete speech token is often utilized in text-to-speech tasks for speech compression and portability, which is convenient for joint training with text and have good compression efficiency. However, we found that the discrete speech tokenizer still suffers from information loss. Therefore, we propose a simple yet effective continuous speech tokenizer and a text-to-speech model based on continuous speech tokens. Our results show that the speech language model based on the continuous speech tokenizer has better continuity and higher estimated Mean Opinion Scores (MoS). This enhancement is attributed to better information preservation rate of the continuous speech tokenizer across both low and high frequencies in the frequency domain.","sentences":["The fusion of speech and language in the era of large language models has garnered significant attention.","Discrete speech token is often utilized in text-to-speech tasks for speech compression and portability, which is convenient for joint training with text and have good compression efficiency.","However, we found that the discrete speech tokenizer still suffers from information loss.","Therefore, we propose a simple yet effective continuous speech tokenizer and a text-to-speech model based on continuous speech tokens.","Our results show that the speech language model based on the continuous speech tokenizer has better continuity and higher estimated Mean Opinion Scores (MoS).","This enhancement is attributed to better information preservation rate of the continuous speech tokenizer across both low and high frequencies in the frequency domain."],"url":"http://arxiv.org/abs/2410.17081v1"}
{"created":"2024-10-22 14:56:50","title":"FlowTracer: A Tool for Uncovering Network Path Usage Imbalance in AI Training Clusters","abstract":"The increasing complexity of AI workloads, especially distributed Large Language Model (LLM) training, places significant strain on the networking infrastructure of parallel data centers and supercomputing systems. While Equal-Cost Multi- Path (ECMP) routing distributes traffic over parallel paths, hash collisions often lead to imbalanced network resource utilization and performance bottlenecks. This paper presents FlowTracer, a tool designed to analyze network path utilization and evaluate different routing strategies. FlowTracer aids in debugging network inefficiencies by providing detailed visibility into traffic distribution and helping to identify the root causes of performance degradation, such as issues caused by hash collisions. By offering flow-level insights, FlowTracer enables system operators to optimize routing, reduce congestion, and improve the performance of distributed AI workloads. We use a RoCEv2-enabled cluster with a leaf-spine network and 16 400-Gbps nodes to demonstrate how FlowTracer can be used to compare the flow imbalances of ECMP routing against a statically configured network. The example showcases a 30% reduction in imbalance, as measured by a new metric we introduce.","sentences":["The increasing complexity of AI workloads, especially distributed Large Language Model (LLM) training, places significant strain on the networking infrastructure of parallel data centers and supercomputing systems.","While Equal-Cost Multi- Path (ECMP) routing distributes traffic over parallel paths, hash collisions often lead to imbalanced network resource utilization and performance bottlenecks.","This paper presents FlowTracer, a tool designed to analyze network path utilization and evaluate different routing strategies.","FlowTracer aids in debugging network inefficiencies by providing detailed visibility into traffic distribution and helping to identify the root causes of performance degradation, such as issues caused by hash collisions.","By offering flow-level insights, FlowTracer enables system operators to optimize routing, reduce congestion, and improve the performance of distributed AI workloads.","We use a RoCEv2-enabled cluster with a leaf-spine network and 16 400-Gbps nodes to demonstrate how FlowTracer can be used to compare the flow imbalances of ECMP routing against a statically configured network.","The example showcases a 30% reduction in imbalance, as measured by a new metric we introduce."],"url":"http://arxiv.org/abs/2410.17078v1"}
{"created":"2024-10-22 14:52:46","title":"Combinatorial Logistic Bandits","abstract":"We introduce a novel framework called combinatorial logistic bandits (CLogB), where in each round, a subset of base arms (called the super arm) is selected, with the outcome of each base arm being binary and its expectation following a logistic parametric model. The feedback is governed by a general arm triggering process. Our study covers CLogB with reward functions satisfying two smoothness conditions, capturing application scenarios such as online content delivery, online learning to rank, and dynamic channel allocation. We first propose a simple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic exploration bonus. Under the 1-norm triggering probability modulated (TPM) smoothness condition, CLogUCB achieves a regret bound of $\\tilde{O}(d\\sqrt{\\kappa KT})$, where $\\tilde{O}$ ignores logarithmic factors, $d$ is the dimension of the feature vector, $\\kappa$ represents the nonlinearity of the logistic model, and $K$ is the maximum number of base arms a super arm can trigger. This result improves on prior work by a factor of $\\tilde{O}(\\sqrt{\\kappa})$. We then enhance CLogUCB with a variance-adaptive version, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$ under the same 1-norm TPM condition, improving another $\\tilde{O}(\\sqrt{\\kappa})$ factor. VA-CLogUCB shows even greater promise under the stronger triggering probability and variance modulated (TPVM) condition, achieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional dependency on the action-size $K$. Furthermore, we enhance the computational efficiency of VA-CLogUCB by eliminating the nonconvex optimization process when the context feature map is time-invariant while maintaining the tight $\\tilde{O}(d\\sqrt{T})$ regret. Finally, experiments on synthetic and real-world datasets demonstrate the superior performance of our algorithms compared to benchmark algorithms.","sentences":["We introduce a novel framework called combinatorial logistic bandits (CLogB), where in each round, a subset of base arms (called the super arm) is selected, with the outcome of each base arm being binary and its expectation following a logistic parametric model.","The feedback is governed by a general arm triggering process.","Our study covers CLogB with reward functions satisfying two smoothness conditions, capturing application scenarios such as online content delivery, online learning to rank, and dynamic channel allocation.","We first propose a simple yet efficient algorithm, CLogUCB, utilizing a variance-agnostic exploration bonus.","Under the 1-norm triggering probability modulated (TPM) smoothness condition, CLogUCB achieves a regret bound of $\\tilde{O}(d\\sqrt{\\kappa KT})$, where $\\tilde{O}$ ignores logarithmic factors, $d$ is the dimension of the feature vector, $\\kappa$ represents the nonlinearity of the logistic model, and $K$ is the maximum number of base arms a super arm can trigger.","This result improves on prior work by a factor of $\\tilde{O}(\\sqrt{\\kappa})$. We then enhance CLogUCB with a variance-adaptive version, VA-CLogUCB, which attains a regret bound of $\\tilde{O}(d\\sqrt{KT})$ under the same 1-norm TPM condition, improving another $\\tilde{O}(\\sqrt{\\kappa})$ factor.","VA-CLogUCB shows even greater promise under the stronger triggering probability and variance modulated (TPVM) condition, achieving a leading $\\tilde{O}(d\\sqrt{T})$ regret, thus removing the additional dependency on the action-size $K$. Furthermore, we enhance the computational efficiency of VA-CLogUCB by eliminating the nonconvex optimization process when the context feature map is time-invariant while maintaining the tight $\\tilde{O}(d\\sqrt{T})$ regret.","Finally, experiments on synthetic and real-world datasets demonstrate the superior performance of our algorithms compared to benchmark algorithms."],"url":"http://arxiv.org/abs/2410.17075v1"}
{"created":"2024-10-22 14:50:19","title":"Personalized Playback Technology: How Short Video Services Create Excellent User Experience","abstract":"Short-form video content has become increasingly popular and influential in recent years. Its concise yet engaging format aligns well with todays' fast-paced and on-the-go lifestyles, making it a dominating trend in the digital world. As one of the front runners in the short video platform space, ByteDance has been highly successful in delivering a one-of-a-kind short video experience and attracting billions of users worldwide. One key contributing factor is its advanced end-to-end personalized short video playback technology, where we pioneered and developed the new technical field over the past five years to optimize user experience. This paper introduces the major concepts and methodologies of this personalized video playback technology that distinguish it from traditional multimedia technologies. More details, including goal setting, iterative process, modeling, experimental methods and required supporting systems, are also provided to encourage deeper research in this area.","sentences":["Short-form video content has become increasingly popular and influential in recent years.","Its concise yet engaging format aligns well with todays' fast-paced and on-the-go lifestyles, making it a dominating trend in the digital world.","As one of the front runners in the short video platform space, ByteDance has been highly successful in delivering a one-of-a-kind short video experience and attracting billions of users worldwide.","One key contributing factor is its advanced end-to-end personalized short video playback technology, where we pioneered and developed the new technical field over the past five years to optimize user experience.","This paper introduces the major concepts and methodologies of this personalized video playback technology that distinguish it from traditional multimedia technologies.","More details, including goal setting, iterative process, modeling, experimental methods and required supporting systems, are also provided to encourage deeper research in this area."],"url":"http://arxiv.org/abs/2410.17073v1"}
{"created":"2024-10-22 14:47:08","title":"Delay-Constrained Grant-Free Random Access in MIMO Systems: Distributed Pilot Allocation and Power Control","abstract":"We study a delay-constrained grant-free random access system with a multi-antenna base station. The users randomly generate data packets with expiration deadlines, which are then transmitted from data queues on a first-in first-out basis. To deliver a packet, a user needs to succeed in both random access phase (sending a pilot without collision) and data transmission phase (achieving a required data rate with imperfect channel information) before the packet expires. We develop a distributed, cross-layer policy that allows the users to dynamically and independently choose their pilots and transmit powers to achieve a high effective sum throughput with fairness consideration. Our policy design involves three key components: 1) a proxy of the instantaneous data rate that depends only on macroscopic environment variables and transmission decisions, considering pilot collisions and imperfect channel estimation; 2) a quantitative, instantaneous measure of fairness within each communication round; and 3) a deep learning-based, multi-agent control framework with centralized training and distributed execution. The proposed framework benefits from an accurate, differentiable objective function for training, thereby achieving a higher sample efficiency compared with a conventional application of model-free, multi-agent reinforcement learning algorithms. The performance of the proposed approach is verified by simulations under highly dynamic and heterogeneous scenarios.","sentences":["We study a delay-constrained grant-free random access system with a multi-antenna base station.","The users randomly generate data packets with expiration deadlines, which are then transmitted from data queues on a first-in first-out basis.","To deliver a packet, a user needs to succeed in both random access phase (sending a pilot without collision) and data transmission phase (achieving a required data rate with imperfect channel information) before the packet expires.","We develop a distributed, cross-layer policy that allows the users to dynamically and independently choose their pilots and transmit powers to achieve a high effective sum throughput with fairness consideration.","Our policy design involves three key components: 1) a proxy of the instantaneous data rate that depends only on macroscopic environment variables and transmission decisions, considering pilot collisions and imperfect channel estimation; 2) a quantitative, instantaneous measure of fairness within each communication round; and 3) a deep learning-based, multi-agent control framework with centralized training and distributed execution.","The proposed framework benefits from an accurate, differentiable objective function for training, thereby achieving a higher sample efficiency compared with a conventional application of model-free, multi-agent reinforcement learning algorithms.","The performance of the proposed approach is verified by simulations under highly dynamic and heterogeneous scenarios."],"url":"http://arxiv.org/abs/2410.17068v1"}
{"created":"2024-10-22 14:46:20","title":"Neuronal Competition Groups with Supervised STDP for Spike-Based Classification","abstract":"Spike Timing-Dependent Plasticity (STDP) is a promising substitute to backpropagation for local training of Spiking Neural Networks (SNNs) on neuromorphic hardware. STDP allows SNNs to address classification tasks by combining unsupervised STDP for feature extraction and supervised STDP for classification. Unsupervised STDP is usually employed with Winner-Takes-All (WTA) competition to learn distinct patterns. However, WTA for supervised STDP classification faces unbalanced competition challenges. In this paper, we propose a method to effectively implement WTA competition in a spiking classification layer employing first-spike coding and supervised STDP training. We introduce the Neuronal Competition Group (NCG), an architecture that improves classification capabilities by promoting the learning of various patterns per class. An NCG is a group of neurons mapped to a specific class, implementing intra-class WTA and a novel competition regulation mechanism based on two-compartment thresholds. We incorporate our proposed architecture into spiking classification layers trained with state-of-the-art supervised STDP rules. On top of two different unsupervised feature extractors, we obtain significant accuracy improvements on image recognition datasets such as CIFAR-10 and CIFAR-100. We show that our competition regulation mechanism is crucial for ensuring balanced competition and improved class separation.","sentences":["Spike Timing-Dependent Plasticity (STDP) is a promising substitute to backpropagation for local training of Spiking Neural Networks (SNNs) on neuromorphic hardware.","STDP allows SNNs to address classification tasks by combining unsupervised STDP for feature extraction and supervised STDP for classification.","Unsupervised STDP is usually employed with Winner-Takes-All (WTA) competition to learn distinct patterns.","However, WTA for supervised STDP classification faces unbalanced competition challenges.","In this paper, we propose a method to effectively implement WTA competition in a spiking classification layer employing first-spike coding and supervised STDP training.","We introduce the Neuronal Competition Group (NCG), an architecture that improves classification capabilities by promoting the learning of various patterns per class.","An NCG is a group of neurons mapped to a specific class, implementing intra-class WTA and a novel competition regulation mechanism based on two-compartment thresholds.","We incorporate our proposed architecture into spiking classification layers trained with state-of-the-art supervised STDP rules.","On top of two different unsupervised feature extractors, we obtain significant accuracy improvements on image recognition datasets such as CIFAR-10 and CIFAR-100.","We show that our competition regulation mechanism is crucial for ensuring balanced competition and improved class separation."],"url":"http://arxiv.org/abs/2410.17066v1"}
{"created":"2024-10-22 14:44:47","title":"Multi Kernel Estimation based Object Segmentation","abstract":"This paper presents a novel approach for multi-kernel estimation by enhancing the KernelGAN algorithm, which traditionally estimates a single kernel for the entire image. We introduce Multi-KernelGAN, which extends KernelGAN's capabilities by estimating two distinct kernels based on object segmentation masks. Our approach is validated through three distinct methods: texture-based patch Fast Fourier Transform (FFT) calculation, detail-based segmentation, and deep learning-based object segmentation using YOLOv8 and the Segment Anything Model (SAM). Among these methods, the combination of YOLO and SAM yields the best results for kernel estimation. Experimental results demonstrate that our multi-kernel estimation technique outperforms conventional single-kernel methods in super-resolution tasks.","sentences":["This paper presents a novel approach for multi-kernel estimation by enhancing the KernelGAN algorithm, which traditionally estimates a single kernel for the entire image.","We introduce Multi-KernelGAN, which extends KernelGAN's capabilities by estimating two distinct kernels based on object segmentation masks.","Our approach is validated through three distinct methods: texture-based patch Fast Fourier Transform (FFT) calculation, detail-based segmentation, and deep learning-based object segmentation using YOLOv8 and the Segment Anything Model (SAM).","Among these methods, the combination of YOLO and SAM yields the best results for kernel estimation.","Experimental results demonstrate that our multi-kernel estimation technique outperforms conventional single-kernel methods in super-resolution tasks."],"url":"http://arxiv.org/abs/2410.17064v1"}
{"created":"2024-10-22 14:41:30","title":"Miniature magneto-oscillatory wireless sensor for magnetic field and gradient measurements","abstract":"Magneto-oscillatory devices have been recently developed as very potent wireless miniature position trackers and sensors with an exceptional accuracy and sensing distance for surgical and robotic applications. However, it is still unclear to which extend a mechanically resonating sub-millimeter magnet interacts with external magnetic fields or gradients, which induce frequency shifts of sub-mHz to several Hz and therefore affect the sensing accuracy. Here, we investigate this effect experimentally on a cantilever-based magneto-oscillatory wireless sensor (MOWS) and build an analytical model concerning magnetic and mechanical interactions. The millimeter-scale MOWS is capable to detect magnetic fields with sub-uT resolution to at least +/- 5 mT, and simultaneously detects magnetic field gradients with a resolution of 65 uT/m to at least +/- 50 mT/m. The magnetic field sensitivity allows direct calculation of mechanical device properties, and by rotation, individual contributions of the magnetic field and gradient can be analyzed. The derived model is general and can be applied to other magneto-oscillatory systems interacting with magnetic environments.","sentences":["Magneto-oscillatory devices have been recently developed as very potent wireless miniature position trackers and sensors with an exceptional accuracy and sensing distance for surgical and robotic applications.","However, it is still unclear to which extend a mechanically resonating sub-millimeter magnet interacts with external magnetic fields or gradients, which induce frequency shifts of sub-mHz to several Hz and therefore affect the sensing accuracy.","Here, we investigate this effect experimentally on a cantilever-based magneto-oscillatory wireless sensor (MOWS) and build an analytical model concerning magnetic and mechanical interactions.","The millimeter-scale MOWS is capable to detect magnetic fields with sub-uT resolution to at least +/- 5 mT, and simultaneously detects magnetic field gradients with a resolution of 65 uT/m to at least +/- 50 mT/m. The magnetic field sensitivity allows direct calculation of mechanical device properties, and by rotation, individual contributions of the magnetic field and gradient can be analyzed.","The derived model is general and can be applied to other magneto-oscillatory systems interacting with magnetic environments."],"url":"http://arxiv.org/abs/2410.17062v1"}
{"created":"2024-10-22 14:36:44","title":"Optimal Design for Reward Modeling in RLHF","abstract":"Reinforcement Learning from Human Feedback (RLHF) has become a popular approach to align language models (LMs) with human preferences. This method involves collecting a large dataset of human pairwise preferences across various text generations and using it to infer (implicitly or explicitly) a reward model. Numerous methods have been proposed to learn the reward model and align a LM with it. However, the costly process of collecting human preferences has received little attention and could benefit from theoretical insights. This paper addresses this issue and aims to formalize the reward training model in RLHF. We frame the selection of an effective dataset as a simple regret minimization task, using a linear contextual dueling bandit method. Given the potentially large number of arms, this approach is more coherent than the best-arm identification setting. We then propose an offline framework for solving this problem. Under appropriate assumptions - linearity of the reward model in the embedding space, and boundedness of the reward parameter - we derive bounds on the simple regret. Finally, we provide a lower bound that matches our upper bound up to constant and logarithmic terms. To our knowledge, this is the first theoretical contribution in this area to provide an offline approach as well as worst-case guarantees.","sentences":["Reinforcement Learning from Human Feedback (RLHF) has become a popular approach to align language models (LMs) with human preferences.","This method involves collecting a large dataset of human pairwise preferences across various text generations and using it to infer (implicitly or explicitly) a reward model.","Numerous methods have been proposed to learn the reward model and align a LM with it.","However, the costly process of collecting human preferences has received little attention and could benefit from theoretical insights.","This paper addresses this issue and aims to formalize the reward training model in RLHF.","We frame the selection of an effective dataset as a simple regret minimization task, using a linear contextual dueling bandit method.","Given the potentially large number of arms, this approach is more coherent than the best-arm identification setting.","We then propose an offline framework for solving this problem.","Under appropriate assumptions - linearity of the reward model in the embedding space, and boundedness of the reward parameter - we derive bounds on the simple regret.","Finally, we provide a lower bound that matches our upper bound up to constant and logarithmic terms.","To our knowledge, this is the first theoretical contribution in this area to provide an offline approach as well as worst-case guarantees."],"url":"http://arxiv.org/abs/2410.17055v1"}
{"created":"2024-10-22 14:31:53","title":"On the Vulnerability of Text Sanitization","abstract":"Text sanitization, which employs differential privacy to replace sensitive tokens with new ones, represents a significant technique for privacy protection. Typically, its performance in preserving privacy is evaluated by measuring the attack success rate (ASR) of reconstruction attacks, where attackers attempt to recover the original tokens from the sanitized ones. However, current reconstruction attacks on text sanitization are developed empirically, making it challenging to accurately assess the effectiveness of sanitization. In this paper, we aim to provide a more accurate evaluation of sanitization effectiveness. Inspired by the works of Palamidessi et al., we implement theoretically optimal reconstruction attacks targeting text sanitization. We derive their bounds on ASR as benchmarks for evaluating sanitization performance. For real-world applications, we propose two practical reconstruction attacks based on these theoretical findings. Our experimental results underscore the necessity of reassessing these overlooked risks. Notably, one of our attacks achieves a 46.4% improvement in ASR over the state-of-the-art baseline, with a privacy budget of epsilon=4.0 on the SST-2 dataset. Our code is available at: https://github.com/mengtong0110/On-the-Vulnerability-of-Text-Sanitization.","sentences":["Text sanitization, which employs differential privacy to replace sensitive tokens with new ones, represents a significant technique for privacy protection.","Typically, its performance in preserving privacy is evaluated by measuring the attack success rate (ASR) of reconstruction attacks, where attackers attempt to recover the original tokens from the sanitized ones.","However, current reconstruction attacks on text sanitization are developed empirically, making it challenging to accurately assess the effectiveness of sanitization.","In this paper, we aim to provide a more accurate evaluation of sanitization effectiveness.","Inspired by the works of Palamidessi et al., we implement theoretically optimal reconstruction attacks targeting text sanitization.","We derive their bounds on ASR as benchmarks for evaluating sanitization performance.","For real-world applications, we propose two practical reconstruction attacks based on these theoretical findings.","Our experimental results underscore the necessity of reassessing these overlooked risks.","Notably, one of our attacks achieves a 46.4% improvement in ASR over the state-of-the-art baseline, with a privacy budget of epsilon=4.0 on the SST-2 dataset.","Our code is available at: https://github.com/mengtong0110/On-the-Vulnerability-of-Text-Sanitization."],"url":"http://arxiv.org/abs/2410.17052v1"}
{"created":"2024-10-22 14:30:40","title":"Data-driven Coreference-based Ontology Building","abstract":"While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus. We derive coreference chains from a corpus of 30 million biomedical abstracts and construct a graph based on the string phrases within these chains, establishing connections between phrases if they co-occur within the same coreference chain. We then use the graph structure and the betweeness centrality measure to distinguish between edges denoting hierarchy, identity and noise, assign directionality to edges denoting hierarchy, and split nodes (strings) that correspond to multiple distinct concepts. The result is a rich, data-driven ontology over concepts in the biomedical domain, parts of which overlaps significantly with human-authored ontologies. We release the coreference chains and resulting ontology under a creative-commons license, along with the code.","sentences":["While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus.","We derive coreference chains from a corpus of 30 million biomedical abstracts and construct a graph based on the string phrases within these chains, establishing connections between phrases if they co-occur within the same coreference chain.","We then use the graph structure and the betweeness centrality measure to distinguish between edges denoting hierarchy, identity and noise, assign directionality to edges denoting hierarchy, and split nodes (strings) that correspond to multiple distinct concepts.","The result is a rich, data-driven ontology over concepts in the biomedical domain, parts of which overlaps significantly with human-authored ontologies.","We release the coreference chains and resulting ontology under a creative-commons license, along with the code."],"url":"http://arxiv.org/abs/2410.17051v1"}
{"created":"2024-10-22 14:30:03","title":"UnStar: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs","abstract":"The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UnSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold; first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge - something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.","sentences":["The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy.","Analogously, unlearning can potentially be achieved through anti-data samples (or anti-samples), unlearning method, and reversed loss function.","While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped.","In this paper, we introduce UnSTAR:","Unlearning with Self-Taught Anti-Sample Reasoning for large language models (LLMs).","Our contributions are threefold; first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge - something not achievable by previous works.","Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification."],"url":"http://arxiv.org/abs/2410.17050v1"}
