{"created":"2025-02-27 18:59:52","title":"Sim-to-Real Reinforcement Learning for Vision-Based Dexterous Manipulation on Humanoids","abstract":"Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited. This work investigates the key challenges in applying reinforcement learning to solve a collection of contact-rich manipulation tasks on a humanoid embodiment. We introduce novel techniques to overcome the identified challenges with empirical validation. Our main contributions include an automated real-to-sim tuning module that brings the simulated environment closer to the real world, a generalized reward design scheme that simplifies reward engineering for long-horizon contact-rich manipulation tasks, a divide-and-conquer distillation process that improves the sample efficiency of hard-exploration problems while maintaining sim-to-real performance, and a mixture of sparse and dense object representations to bridge the sim-to-real perception gap. We show promising results on three humanoid dexterous manipulation tasks, with ablation studies on each technique. Our work presents a successful approach to learning humanoid dexterous manipulation using sim-to-real reinforcement learning, achieving robust generalization and high performance without the need for human demonstration.","sentences":["Reinforcement learning has delivered promising results in achieving human- or even superhuman-level capabilities across diverse problem domains, but success in dexterous robot manipulation remains limited.","This work investigates the key challenges in applying reinforcement learning to solve a collection of contact-rich manipulation tasks on a humanoid embodiment.","We introduce novel techniques to overcome the identified challenges with empirical validation.","Our main contributions include an automated real-to-sim tuning module that brings the simulated environment closer to the real world, a generalized reward design scheme that simplifies reward engineering for long-horizon contact-rich manipulation tasks, a divide-and-conquer distillation process that improves the sample efficiency of hard-exploration problems while maintaining sim-to-real performance, and a mixture of sparse and dense object representations to bridge the sim-to-real perception gap.","We show promising results on three humanoid dexterous manipulation tasks, with ablation studies on each technique.","Our work presents a successful approach to learning humanoid dexterous manipulation using sim-to-real reinforcement learning, achieving robust generalization and high performance without the need for human demonstration."],"url":"http://arxiv.org/abs/2502.20396v1"}
{"created":"2025-02-27 18:59:32","title":"R2-T2: Re-Routing in Test-Time for Multimodal Mixture-of-Experts","abstract":"In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks. This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks. The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input. However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample. To bridge the gap, we propose a novel and efficient method \"Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample. We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces. R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters.","sentences":["In large multimodal models (LMMs), the perception of non-language modalities (e.g., visual representations) is usually not on par with the large language models (LLMs)' powerful reasoning capabilities, deterring LMMs' performance on challenging downstream tasks.","This weakness has been recently mitigated by replacing the vision encoder with a mixture-of-experts (MoE), which provides rich, multi-granularity, and diverse representations required by diverse downstream tasks.","The performance of multimodal MoE largely depends on its router, which reweights and mixes the representations of different experts for each input.","However, we find that the end-to-end trained router does not always produce the optimal routing weights for every test sample.","To bridge the gap, we propose a novel and efficient method \"Re-Routing in Test-Time(R2-T2) that locally optimizes the vector of routing weights in test-time by moving it toward those vectors of the correctly predicted samples in a neighborhood of the test sample.","We propose three R2-T2 strategies with different optimization objectives and neighbor-search spaces.","R2-T2 consistently and greatly improves state-of-the-art LMMs' performance on challenging benchmarks of diverse tasks, without training any base-model parameters."],"url":"http://arxiv.org/abs/2502.20395v1"}
{"created":"2025-02-27 18:59:29","title":"Walking the Web of Concept-Class Relationships in Incrementally Trained Interpretable Models","abstract":"Concept-based methods have emerged as a promising direction to develop interpretable neural networks in standard supervised settings. However, most works that study them in incremental settings assume either a static concept set across all experiences or assume that each experience relies on a distinct set of concepts. In this work, we study concept-based models in a more realistic, dynamic setting where new classes may rely on older concepts in addition to introducing new concepts themselves. We show that concepts and classes form a complex web of relationships, which is susceptible to degradation and needs to be preserved and augmented across experiences. We introduce new metrics to show that existing concept-based models cannot preserve these relationships even when trained using methods to prevent catastrophic forgetting, since they cannot handle forgetting at concept, class, and concept-class relationship levels simultaneously. To address these issues, we propose a novel method - MuCIL - that uses multimodal concepts to perform classification without increasing the number of trainable parameters across experiences. The multimodal concepts are aligned to concepts provided in natural language, making them interpretable by design. Through extensive experimentation, we show that our approach obtains state-of-the-art classification performance compared to other concept-based models, achieving over 2$\\times$ the classification performance in some cases. We also study the ability of our model to perform interventions on concepts, and show that it can localize visual concepts in input images, providing post-hoc interpretations.","sentences":["Concept-based methods have emerged as a promising direction to develop interpretable neural networks in standard supervised settings.","However, most works that study them in incremental settings assume either a static concept set across all experiences or assume that each experience relies on a distinct set of concepts.","In this work, we study concept-based models in a more realistic, dynamic setting where new classes may rely on older concepts in addition to introducing new concepts themselves.","We show that concepts and classes form a complex web of relationships, which is susceptible to degradation and needs to be preserved and augmented across experiences.","We introduce new metrics to show that existing concept-based models cannot preserve these relationships even when trained using methods to prevent catastrophic forgetting, since they cannot handle forgetting at concept, class, and concept-class relationship levels simultaneously.","To address these issues, we propose a novel method - MuCIL - that uses multimodal concepts to perform classification without increasing the number of trainable parameters across experiences.","The multimodal concepts are aligned to concepts provided in natural language, making them interpretable by design.","Through extensive experimentation, we show that our approach obtains state-of-the-art classification performance compared to other concept-based models, achieving over 2$\\times$ the classification performance in some cases.","We also study the ability of our model to perform interventions on concepts, and show that it can localize visual concepts in input images, providing post-hoc interpretations."],"url":"http://arxiv.org/abs/2502.20393v1"}
{"created":"2025-02-27 18:59:18","title":"Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation","abstract":"Building robotic agents capable of operating across diverse environments and object types remains a significant challenge, often requiring extensive data collection. This is particularly restrictive in robotics, where each data point must be physically executed in the real world. Consequently, there is a critical need for alternative data sources for robotics and frameworks that enable learning from such data. In this work, we present Point Policy, a new method for learning robot policies exclusively from offline human demonstration videos and without any teleoperation data. Point Policy leverages state-of-the-art vision models and policy architectures to translate human hand poses into robot poses while capturing object states through semantically meaningful key points. This approach yields a morphology-agnostic representation that facilitates effective policy learning. Our experiments on 8 real-world tasks demonstrate an overall 75% absolute improvement over prior works when evaluated in identical settings as training. Further, Point Policy exhibits a 74% gain across tasks for novel object instances and is robust to significant background clutter. Videos of the robot are best viewed at https://point-policy.github.io/.","sentences":["Building robotic agents capable of operating across diverse environments and object types remains a significant challenge, often requiring extensive data collection.","This is particularly restrictive in robotics, where each data point must be physically executed in the real world.","Consequently, there is a critical need for alternative data sources for robotics and frameworks that enable learning from such data.","In this work, we present Point Policy, a new method for learning robot policies exclusively from offline human demonstration videos and without any teleoperation data.","Point Policy leverages state-of-the-art vision models and policy architectures to translate human hand poses into robot poses while capturing object states through semantically meaningful key points.","This approach yields a morphology-agnostic representation that facilitates effective policy learning.","Our experiments on 8 real-world tasks demonstrate an overall 75% absolute improvement over prior works when evaluated in identical settings as training.","Further, Point Policy exhibits a 74% gain across tasks for novel object instances and is robust to significant background clutter.","Videos of the robot are best viewed at https://point-policy.github.io/."],"url":"http://arxiv.org/abs/2502.20391v1"}
{"created":"2025-02-27 18:59:12","title":"InterMimic: Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions","abstract":"Achieving realistic simulations of humans interacting with a wide range of objects has long been a fundamental goal. Extending physics-based motion imitation to complex human-object interactions (HOIs) is challenging due to intricate human-object coupling, variability in object geometries, and artifacts in motion capture data, such as inaccurate contacts and limited hand detail. We introduce InterMimic, a framework that enables a single policy to robustly learn from hours of imperfect MoCap data covering diverse full-body interactions with dynamic and varied objects. Our key insight is to employ a curriculum strategy -- perfect first, then scale up. We first train subject-specific teacher policies to mimic, retarget, and refine motion capture data. Next, we distill these teachers into a student policy, with the teachers acting as online experts providing direct supervision, as well as high-quality references. Notably, we incorporate RL fine-tuning on the student policy to surpass mere demonstration replication and achieve higher-quality solutions. Our experiments demonstrate that InterMimic produces realistic and diverse interactions across multiple HOI datasets. The learned policy generalizes in a zero-shot manner and seamlessly integrates with kinematic generators, elevating the framework from mere imitation to generative modeling of complex human-object interactions.","sentences":["Achieving realistic simulations of humans interacting with a wide range of objects has long been a fundamental goal.","Extending physics-based motion imitation to complex human-object interactions (HOIs) is challenging due to intricate human-object coupling, variability in object geometries, and artifacts in motion capture data, such as inaccurate contacts and limited hand detail.","We introduce InterMimic, a framework that enables a single policy to robustly learn from hours of imperfect MoCap data covering diverse full-body interactions with dynamic and varied objects.","Our key insight is to employ a curriculum strategy -- perfect first, then scale up.","We first train subject-specific teacher policies to mimic, retarget, and refine motion capture data.","Next, we distill these teachers into a student policy, with the teachers acting as online experts providing direct supervision, as well as high-quality references.","Notably, we incorporate RL fine-tuning on the student policy to surpass mere demonstration replication and achieve higher-quality solutions.","Our experiments demonstrate that InterMimic produces realistic and diverse interactions across multiple HOI datasets.","The learned policy generalizes in a zero-shot manner and seamlessly integrates with kinematic generators, elevating the framework from mere imitation to generative modeling of complex human-object interactions."],"url":"http://arxiv.org/abs/2502.20390v1"}
{"created":"2025-02-27 18:59:11","title":"LIFT-GS: Cross-Scene Render-Supervised Distillation for 3D Language Grounding","abstract":"Our approach to training 3D vision-language understanding models is to train a feedforward model that makes predictions in 3D, but never requires 3D labels and is supervised only in 2D, using 2D losses and differentiable rendering. The approach is new for vision-language understanding. By treating the reconstruction as a ``latent variable'', we can render the outputs without placing unnecessary constraints on the network architecture (e.g. can be used with decoder-only models). For training, only need images and camera pose, and 2D labels. We show that we can even remove the need for 2D labels by using pseudo-labels from pretrained 2D models. We demonstrate this to pretrain a network, and we finetune it for 3D vision-language understanding tasks. We show this approach outperforms baselines/sota for 3D vision-language grounding, and also outperforms other 3D pretraining techniques. Project page: https://liftgs.github.io.","sentences":["Our approach to training 3D vision-language understanding models is to train a feedforward model that makes predictions in 3D, but never requires 3D labels and is supervised only in 2D, using 2D losses and differentiable rendering.","The approach is new for vision-language understanding.","By treating the reconstruction as a ``latent variable'', we can render the outputs without placing unnecessary constraints on the network architecture (e.g. can be used with decoder-only models).","For training, only need images and camera pose, and 2D labels.","We show that we can even remove the need for 2D labels by using pseudo-labels from pretrained 2D models.","We demonstrate this to pretrain a network, and we finetune it for 3D vision-language understanding tasks.","We show this approach outperforms baselines/sota for 3D vision-language grounding, and also outperforms other 3D pretraining techniques.","Project page: https://liftgs.github.io."],"url":"http://arxiv.org/abs/2502.20389v1"}
{"created":"2025-02-27 18:59:08","title":"Beyond Next-Token: Next-X Prediction for Autoregressive Visual Generation","abstract":"Autoregressive (AR) modeling, known for its next-token prediction paradigm, underpins state-of-the-art language and visual generative models. Traditionally, a ``token'' is treated as the smallest prediction unit, often a discrete symbol in language or a quantized patch in vision. However, the optimal token definition for 2D image structures remains an open question. Moreover, AR models suffer from exposure bias, where teacher forcing during training leads to error accumulation at inference. In this paper, we propose xAR, a generalized AR framework that extends the notion of a token to an entity X, which can represent an individual patch token, a cell (a $k\\times k$ grouping of neighboring patches), a subsample (a non-local grouping of distant patches), a scale (coarse-to-fine resolution), or even a whole image. Additionally, we reformulate discrete token classification as \\textbf{continuous entity regression}, leveraging flow-matching methods at each AR step. This approach conditions training on noisy entities instead of ground truth tokens, leading to Noisy Context Learning, which effectively alleviates exposure bias. As a result, xAR offers two key advantages: (1) it enables flexible prediction units that capture different contextual granularity and spatial structures, and (2) it mitigates exposure bias by avoiding reliance on teacher forcing. On ImageNet-256 generation benchmark, our base model, xAR-B (172M), outperforms DiT-XL/SiT-XL (675M) while achieving 20$\\times$ faster inference. Meanwhile, xAR-H sets a new state-of-the-art with an FID of 1.24, running 2.2$\\times$ faster than the previous best-performing model without relying on vision foundation modules (\\eg, DINOv2) or advanced guidance interval sampling.","sentences":["Autoregressive (AR) modeling, known for its next-token prediction paradigm, underpins state-of-the-art language and visual generative models.","Traditionally, a ``token'' is treated as the smallest prediction unit, often a discrete symbol in language or a quantized patch in vision.","However, the optimal token definition for 2D image structures remains an open question.","Moreover, AR models suffer from exposure bias, where teacher forcing during training leads to error accumulation at inference.","In this paper, we propose xAR, a generalized AR framework that extends the notion of a token to an entity X, which can represent an individual patch token, a cell (a $k\\times k$ grouping of neighboring patches), a subsample (a non-local grouping of distant patches), a scale (coarse-to-fine resolution), or even a whole image.","Additionally, we reformulate discrete token classification as \\textbf{continuous entity regression}, leveraging flow-matching methods at each AR step.","This approach conditions training on noisy entities instead of ground truth tokens, leading to Noisy Context Learning, which effectively alleviates exposure bias.","As a result, xAR offers two key advantages: (1) it enables flexible prediction units that capture different contextual granularity and spatial structures, and (2) it mitigates exposure bias by avoiding reliance on teacher forcing.","On ImageNet-256 generation benchmark, our base model, xAR-B (172M), outperforms DiT-XL/SiT-XL (675M) while achieving 20$\\times$ faster inference.","Meanwhile, xAR-H sets a new state-of-the-art with an FID of 1.24, running 2.2$\\times$ faster than the previous best-performing model without relying on vision foundation modules (\\eg, DINOv2) or advanced guidance interval sampling."],"url":"http://arxiv.org/abs/2502.20388v1"}
{"created":"2025-02-27 18:58:30","title":"InsTaG: Learning Personalized 3D Talking Head from Few-Second Video","abstract":"Despite exhibiting impressive performance in synthesizing lifelike personalized 3D talking heads, prevailing methods based on radiance fields suffer from high demands for training data and time for each new identity. This paper introduces InsTaG, a 3D talking head synthesis framework that allows a fast learning of realistic personalized 3D talking head from few training data. Built upon a lightweight 3DGS person-specific synthesizer with universal motion priors, InsTaG achieves high-quality and fast adaptation while preserving high-level personalization and efficiency. As preparation, we first propose an Identity-Free Pre-training strategy that enables the pre-training of the person-specific model and encourages the collection of universal motion priors from long-video data corpus. To fully exploit the universal motion priors to learn an unseen new identity, we then present a Motion-Aligned Adaptation strategy to adaptively align the target head to the pre-trained field, and constrain a robust dynamic head structure under few training data. Experiments demonstrate our outstanding performance and efficiency under various data scenarios to render high-quality personalized talking heads.","sentences":["Despite exhibiting impressive performance in synthesizing lifelike personalized 3D talking heads, prevailing methods based on radiance fields suffer from high demands for training data and time for each new identity.","This paper introduces InsTaG, a 3D talking head synthesis framework that allows a fast learning of realistic personalized 3D talking head from few training data.","Built upon a lightweight 3DGS person-specific synthesizer with universal motion priors, InsTaG achieves high-quality and fast adaptation while preserving high-level personalization and efficiency.","As preparation, we first propose an Identity-Free Pre-training strategy that enables the pre-training of the person-specific model and encourages the collection of universal motion priors from long-video data corpus.","To fully exploit the universal motion priors to learn an unseen new identity, we then present a Motion-Aligned Adaptation strategy to adaptively align the target head to the pre-trained field, and constrain a robust dynamic head structure under few training data.","Experiments demonstrate our outstanding performance and efficiency under various data scenarios to render high-quality personalized talking heads."],"url":"http://arxiv.org/abs/2502.20387v1"}
{"created":"2025-02-27 18:58:04","title":"ATLAS Navigator: Active Task-driven LAnguage-embedded Gaussian Splatting","abstract":"We address the challenge of task-oriented navigation in unstructured and unknown environments, where robots must incrementally build and reason on rich, metric-semantic maps in real time. Since tasks may require clarification or re-specification, it is necessary for the information in the map to be rich enough to enable generalization across a wide range of tasks. To effectively execute tasks specified in natural language, we propose a hierarchical representation built on language-embedded Gaussian splatting that enables both sparse semantic planning that lends itself to online operation and dense geometric representation for collision-free navigation. We validate the effectiveness of our method through real-world robot experiments conducted in both cluttered indoor and kilometer-scale outdoor environments, with a competitive ratio of about 60% against privileged baselines. Experiment videos and more details can be found on our project page: https://atlasnav.github.io","sentences":["We address the challenge of task-oriented navigation in unstructured and unknown environments, where robots must incrementally build and reason on rich, metric-semantic maps in real time.","Since tasks may require clarification or re-specification, it is necessary for the information in the map to be rich enough to enable generalization across a wide range of tasks.","To effectively execute tasks specified in natural language, we propose a hierarchical representation built on language-embedded Gaussian splatting that enables both sparse semantic planning that lends itself to online operation and dense geometric representation for collision-free navigation.","We validate the effectiveness of our method through real-world robot experiments conducted in both cluttered indoor and kilometer-scale outdoor environments, with a competitive ratio of about 60% against privileged baselines.","Experiment videos and more details can be found on our project page: https://atlasnav.github.io"],"url":"http://arxiv.org/abs/2502.20386v1"}
{"created":"2025-02-27 18:56:26","title":"Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis","abstract":"Recent advancements in Web AI agents have demonstrated remarkable capabilities in addressing complex web navigation tasks. However, emerging research shows that these agents exhibit greater vulnerability compared to standalone Large Language Models (LLMs), despite both being built upon the same safety-aligned models. This discrepancy is particularly concerning given the greater flexibility of Web AI Agent compared to standalone LLMs, which may expose them to a wider range of adversarial user inputs. To build a scaffold that addresses these concerns, this study investigates the underlying factors that contribute to the increased vulnerability of Web AI agents. Notably, this disparity stems from the multifaceted differences between Web AI agents and standalone LLMs, as well as the complex signals - nuances that simple evaluation metrics, such as success rate, often fail to capture. To tackle these challenges, we propose a component-level analysis and a more granular, systematic evaluation framework. Through this fine-grained investigation, we identify three critical factors that amplify the vulnerability of Web AI agents; (1) embedding user goals into the system prompt, (2) multi-step action generation, and (3) observational capabilities. Our findings highlights the pressing need to enhance security and robustness in AI agent design and provide actionable insights for targeted defense strategies.","sentences":["Recent advancements in Web AI agents have demonstrated remarkable capabilities in addressing complex web navigation tasks.","However, emerging research shows that these agents exhibit greater vulnerability compared to standalone Large Language Models (LLMs), despite both being built upon the same safety-aligned models.","This discrepancy is particularly concerning given the greater flexibility of Web AI Agent compared to standalone LLMs, which may expose them to a wider range of adversarial user inputs.","To build a scaffold that addresses these concerns, this study investigates the underlying factors that contribute to the increased vulnerability of Web AI agents.","Notably, this disparity stems from the multifaceted differences between Web AI agents and standalone LLMs, as well as the complex signals - nuances that simple evaluation metrics, such as success rate, often fail to capture.","To tackle these challenges, we propose a component-level analysis and a more granular, systematic evaluation framework.","Through this fine-grained investigation, we identify three critical factors that amplify the vulnerability of Web AI agents; (1) embedding user goals into the system prompt, (2) multi-step action generation, and (3) observational capabilities.","Our findings highlights the pressing need to enhance security and robustness in AI agent design and provide actionable insights for targeted defense strategies."],"url":"http://arxiv.org/abs/2502.20383v1"}
{"created":"2025-02-27 18:56:01","title":"Physics-Driven Data Generation for Contact-Rich Manipulation via Trajectory Optimization","abstract":"We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks. Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters. This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters. We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms. The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input. Project website: https://lujieyang.github.io/physicsgen/.","sentences":["We present a low-cost data generation pipeline that integrates physics-based simulation, human demonstrations, and model-based planning to efficiently generate large-scale, high-quality datasets for contact-rich robotic manipulation tasks.","Starting with a small number of embodiment-flexible human demonstrations collected in a virtual reality simulation environment, the pipeline refines these demonstrations using optimization-based kinematic retargeting and trajectory optimization to adapt them across various robot embodiments and physical parameters.","This process yields a diverse, physically consistent dataset that enables cross-embodiment data transfer, and offers the potential to reuse legacy datasets collected under different hardware configurations or physical parameters.","We validate the pipeline's effectiveness by training diffusion policies from the generated datasets for challenging contact-rich manipulation tasks across multiple robot embodiments, including a floating Allegro hand and bimanual robot arms.","The trained policies are deployed zero-shot on hardware for bimanual iiwa arms, achieving high success rates with minimal human input.","Project website: https://lujieyang.github.io/physicsgen/."],"url":"http://arxiv.org/abs/2502.20382v1"}
{"created":"2025-02-27 18:55:17","title":"Waves and symbols in neuromorphic hardware: from analog signal processing to digital computing on the same computational substrate","abstract":"Neural systems use the same underlying computational substrate to carry out analog filtering and signal processing operations, as well as discrete symbol manipulation and digital computation. Inspired by the computational principles of canonical cortical microcircuits, we propose a framework for using recurrent spiking neural networks to seamlessly and robustly switch between analog signal processing and categorical and discrete computation. We provide theoretical analysis and practical neural network design tools to formally determine the conditions for inducing this switch. We demonstrate the robustness of this framework experimentally with hardware soft Winner-Take-All and mixed-feedback recurrent spiking neural networks, implemented by appropriately configuring the analog neuron and synapse circuits of a mixed-signal neuromorphic processor chip.","sentences":["Neural systems use the same underlying computational substrate to carry out analog filtering and signal processing operations, as well as discrete symbol manipulation and digital computation.","Inspired by the computational principles of canonical cortical microcircuits, we propose a framework for using recurrent spiking neural networks to seamlessly and robustly switch between analog signal processing and categorical and discrete computation.","We provide theoretical analysis and practical neural network design tools to formally determine the conditions for inducing this switch.","We demonstrate the robustness of this framework experimentally with hardware soft Winner-Take-All and mixed-feedback recurrent spiking neural networks, implemented by appropriately configuring the analog neuron and synapse circuits of a mixed-signal neuromorphic processor chip."],"url":"http://arxiv.org/abs/2502.20381v1"}
{"created":"2025-02-27 18:55:05","title":"Multi-Turn Code Generation Through Single-Step Rewards","abstract":"We address the problem of code generation from multi-turn execution feedback. Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards. We propose a simple yet scalable approach, $\\mu$Code, that solves multi-turn code generation using only single-step rewards. Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn. $\\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code. Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines. We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\\mu$Code at utilizing the execution feedback. Our code is available at https://github.com/portal-cornell/muCode.","sentences":["We address the problem of code generation from multi-turn execution feedback.","Existing methods either generate code without feedback or use complex, hierarchical reinforcement learning to optimize multi-turn rewards.","We propose a simple yet scalable approach, $\\mu$Code, that solves multi-turn code generation using only single-step rewards.","Our key insight is that code generation is a one-step recoverable MDP, where the correct code can be recovered from any intermediate code state in a single turn.","$\\mu$Code iteratively trains both a generator to provide code solutions conditioned on multi-turn execution feedback and a verifier to score the newly generated code.","Experimental evaluations show that our approach achieves significant improvements over the state-of-the-art baselines.","We provide analysis of the design choices of the reward models and policy, and show the efficacy of $\\mu$Code at utilizing the execution feedback.","Our code is available at https://github.com/portal-cornell/muCode."],"url":"http://arxiv.org/abs/2502.20380v1"}
{"created":"2025-02-27 18:53:30","title":"Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers","abstract":"By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time.","sentences":["By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training.","One common strategy uses verifiers to evaluate candidate outputs.","In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers.","We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance.","We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system.","AVs are a convenient building block for MAV since they can be easily combined without additional training.","Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers.","BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs.","Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time."],"url":"http://arxiv.org/abs/2502.20379v1"}
{"created":"2025-02-27 18:53:06","title":"Efficient Gaussian Splatting for Monocular Dynamic Scene Rendering via Sparse Time-Variant Attribute Modeling","abstract":"Rendering dynamic scenes from monocular videos is a crucial yet challenging task. The recent deformable Gaussian Splatting has emerged as a robust solution to represent real-world dynamic scenes. However, it often leads to heavily redundant Gaussians, attempting to fit every training view at various time steps, leading to slower rendering speeds. Additionally, the attributes of Gaussians in static areas are time-invariant, making it unnecessary to model every Gaussian, which can cause jittering in static regions. In practice, the primary bottleneck in rendering speed for dynamic scenes is the number of Gaussians. In response, we introduce Efficient Dynamic Gaussian Splatting (EDGS), which represents dynamic scenes via sparse time-variant attribute modeling. Our approach formulates dynamic scenes using a sparse anchor-grid representation, with the motion flow of dense Gaussians calculated via a classical kernel representation. Furthermore, we propose an unsupervised strategy to efficiently filter out anchors corresponding to static areas. Only anchors associated with deformable objects are input into MLPs to query time-variant attributes. Experiments on two real-world datasets demonstrate that our EDGS significantly improves the rendering speed with superior rendering quality compared to previous state-of-the-art methods.","sentences":["Rendering dynamic scenes from monocular videos is a crucial yet challenging task.","The recent deformable Gaussian Splatting has emerged as a robust solution to represent real-world dynamic scenes.","However, it often leads to heavily redundant Gaussians, attempting to fit every training view at various time steps, leading to slower rendering speeds.","Additionally, the attributes of Gaussians in static areas are time-invariant, making it unnecessary to model every Gaussian, which can cause jittering in static regions.","In practice, the primary bottleneck in rendering speed for dynamic scenes is the number of Gaussians.","In response, we introduce Efficient Dynamic Gaussian Splatting (EDGS), which represents dynamic scenes via sparse time-variant attribute modeling.","Our approach formulates dynamic scenes using a sparse anchor-grid representation, with the motion flow of dense Gaussians calculated via a classical kernel representation.","Furthermore, we propose an unsupervised strategy to efficiently filter out anchors corresponding to static areas.","Only anchors associated with deformable objects are input into MLPs to query time-variant attributes.","Experiments on two real-world datasets demonstrate that our EDGS significantly improves the rendering speed with superior rendering quality compared to previous state-of-the-art methods."],"url":"http://arxiv.org/abs/2502.20378v1"}
{"created":"2025-02-27 18:51:22","title":"PhantomWiki: On-Demand Datasets for Reasoning and Retrieval Evaluation","abstract":"High-quality benchmarks are essential for evaluating reasoning and retrieval capabilities of large language models (LLMs). However, curating datasets for this purpose is not a permanent solution as they are prone to data leakage and inflated performance results. To address these challenges, we propose PhantomWiki: a pipeline to generate unique, factually consistent document corpora with diverse question-answer pairs. Unlike prior work, PhantomWiki is neither a fixed dataset, nor is it based on any existing data. Instead, a new PhantomWiki instance is generated on demand for each evaluation. We vary the question difficulty and corpus size to disentangle reasoning and retrieval capabilities respectively, and find that PhantomWiki datasets are surprisingly challenging for frontier LLMs. Thus, we contribute a scalable and data leakage-resistant framework for disentangled evaluation of reasoning, retrieval, and tool-use abilities. Our code is available at https://github.com/kilian-group/phantom-wiki.","sentences":["High-quality benchmarks are essential for evaluating reasoning and retrieval capabilities of large language models (LLMs).","However, curating datasets for this purpose is not a permanent solution as they are prone to data leakage and inflated performance results.","To address these challenges, we propose PhantomWiki: a pipeline to generate unique, factually consistent document corpora with diverse question-answer pairs.","Unlike prior work, PhantomWiki is neither a fixed dataset, nor is it based on any existing data.","Instead, a new PhantomWiki instance is generated on demand for each evaluation.","We vary the question difficulty and corpus size to disentangle reasoning and retrieval capabilities respectively, and find that PhantomWiki datasets are surprisingly challenging for frontier LLMs.","Thus, we contribute a scalable and data leakage-resistant framework for disentangled evaluation of reasoning, retrieval, and tool-use abilities.","Our code is available at https://github.com/kilian-group/phantom-wiki."],"url":"http://arxiv.org/abs/2502.20377v1"}
{"created":"2025-02-27 18:51:16","title":"Tight Inversion: Image-Conditioned Inversion for Real Image Editing","abstract":"Text-to-image diffusion models offer powerful image editing capabilities. To edit real images, many methods rely on the inversion of the image into Gaussian noise. A common approach to invert an image is to gradually add noise to the image, where the noise is determined by reversing the sampling equation. This process has an inherent tradeoff between reconstruction and editability, limiting the editing of challenging images such as highly-detailed ones. Recognizing the reliance of text-to-image models inversion on a text condition, this work explores the importance of the condition choice. We show that a condition that precisely aligns with the input image significantly improves the inversion quality. Based on our findings, we introduce Tight Inversion, an inversion method that utilizes the most possible precise condition -- the input image itself. This tight condition narrows the distribution of the model's output and enhances both reconstruction and editability. We demonstrate the effectiveness of our approach when combined with existing inversion methods through extensive experiments, evaluating the reconstruction accuracy as well as the integration with various editing methods.","sentences":["Text-to-image diffusion models offer powerful image editing capabilities.","To edit real images, many methods rely on the inversion of the image into Gaussian noise.","A common approach to invert an image is to gradually add noise to the image, where the noise is determined by reversing the sampling equation.","This process has an inherent tradeoff between reconstruction and editability, limiting the editing of challenging images such as highly-detailed ones.","Recognizing the reliance of text-to-image models inversion on a text condition, this work explores the importance of the condition choice.","We show that a condition that precisely aligns with the input image significantly improves the inversion quality.","Based on our findings, we introduce Tight Inversion, an inversion method that utilizes the most possible precise condition -- the input image itself.","This tight condition narrows the distribution of the model's output and enhances both reconstruction and editability.","We demonstrate the effectiveness of our approach when combined with existing inversion methods through extensive experiments, evaluating the reconstruction accuracy as well as the integration with various editing methods."],"url":"http://arxiv.org/abs/2502.20376v1"}
{"created":"2025-02-27 18:50:51","title":"When does a predictor know its own loss?","abstract":"Given a predictor and a loss function, how well can we predict the loss that the predictor will incur on an input? This is the problem of loss prediction, a key computational task associated with uncertainty estimation for a predictor. In a classification setting, a predictor will typically predict a distribution over labels and hence have its own estimate of the loss that it will incur, given by the entropy of the predicted distribution. Should we trust this estimate? In other words, when does the predictor know what it knows and what it does not know?   In this work we study the theoretical foundations of loss prediction. Our main contribution is to establish tight connections between nontrivial loss prediction and certain forms of multicalibration, a multigroup fairness notion that asks for calibrated predictions across computationally identifiable subgroups. Formally, we show that a loss predictor that is able to improve on the self-estimate of a predictor yields a witness to a failure of multicalibration, and vice versa. This has the implication that nontrivial loss prediction is in effect no easier or harder than auditing for multicalibration. We support our theoretical results with experiments that show a robust positive correlation between the multicalibration error of a predictor and the efficacy of training a loss predictor.","sentences":["Given a predictor and a loss function, how well can we predict the loss that the predictor will incur on an input?","This is the problem of loss prediction, a key computational task associated with uncertainty estimation for a predictor.","In a classification setting, a predictor will typically predict a distribution over labels and hence have its own estimate of the loss that it will incur, given by the entropy of the predicted distribution.","Should we trust this estimate?","In other words, when does the predictor know what it knows and what it does not know?   ","In this work we study the theoretical foundations of loss prediction.","Our main contribution is to establish tight connections between nontrivial loss prediction and certain forms of multicalibration, a multigroup fairness notion that asks for calibrated predictions across computationally identifiable subgroups.","Formally, we show that a loss predictor that is able to improve on the self-estimate of a predictor yields a witness to a failure of multicalibration, and vice versa.","This has the implication that nontrivial loss prediction is in effect no easier or harder than auditing for multicalibration.","We support our theoretical results with experiments that show a robust positive correlation between the multicalibration error of a predictor and the efficacy of training a loss predictor."],"url":"http://arxiv.org/abs/2502.20375v1"}
{"created":"2025-02-27 18:41:46","title":"Constrained Generative Modeling with Manually Bridged Diffusion Models","abstract":"In this paper we describe a novel framework for diffusion-based generative modeling on constrained spaces. In particular, we introduce manual bridges, a framework that expands the kinds of constraints that can be practically used to form so-called diffusion bridges. We develop a mechanism for combining multiple such constraints so that the resulting multiply-constrained model remains a manual bridge that respects all constraints. We also develop a mechanism for training a diffusion model that respects such multiple constraints while also adapting it to match a data distribution. We develop and extend theory demonstrating the mathematical validity of our mechanisms. Additionally, we demonstrate our mechanism in constrained generative modeling tasks, highlighting a particular high-value application in modeling trajectory initializations for path planning and control in autonomous vehicles.","sentences":["In this paper we describe a novel framework for diffusion-based generative modeling on constrained spaces.","In particular, we introduce manual bridges, a framework that expands the kinds of constraints that can be practically used to form so-called diffusion bridges.","We develop a mechanism for combining multiple such constraints so that the resulting multiply-constrained model remains a manual bridge that respects all constraints.","We also develop a mechanism for training a diffusion model that respects such multiple constraints while also adapting it to match a data distribution.","We develop and extend theory demonstrating the mathematical validity of our mechanisms.","Additionally, we demonstrate our mechanism in constrained generative modeling tasks, highlighting a particular high-value application in modeling trajectory initializations for path planning and control in autonomous vehicles."],"url":"http://arxiv.org/abs/2502.20371v1"}
{"created":"2025-02-27 18:40:30","title":"Ready-to-React: Online Reaction Policy for Two-Character Interaction Generation","abstract":"This paper addresses the task of generating two-character online interactions. Previously, two main settings existed for two-character interaction generation: (1) generating one's motions based on the counterpart's complete motion sequence, and (2) jointly generating two-character motions based on specific conditions. We argue that these settings fail to model the process of real-life two-character interactions, where humans will react to their counterparts in real time and act as independent individuals. In contrast, we propose an online reaction policy, called Ready-to-React, to generate the next character pose based on past observed motions. Each character has its own reaction policy as its \"brain\", enabling them to interact like real humans in a streaming manner. Our policy is implemented by incorporating a diffusion head into an auto-regressive model, which can dynamically respond to the counterpart's motions while effectively mitigating the error accumulation throughout the generation process. We conduct comprehensive experiments using the challenging boxing task. Experimental results demonstrate that our method outperforms existing baselines and can generate extended motion sequences. Additionally, we show that our approach can be controlled by sparse signals, making it well-suited for VR and other online interactive environments.","sentences":["This paper addresses the task of generating two-character online interactions.","Previously, two main settings existed for two-character interaction generation: (1) generating one's motions based on the counterpart's complete motion sequence, and (2) jointly generating two-character motions based on specific conditions.","We argue that these settings fail to model the process of real-life two-character interactions, where humans will react to their counterparts in real time and act as independent individuals.","In contrast, we propose an online reaction policy, called Ready-to-React, to generate the next character pose based on past observed motions.","Each character has its own reaction policy as its \"brain\", enabling them to interact like real humans in a streaming manner.","Our policy is implemented by incorporating a diffusion head into an auto-regressive model, which can dynamically respond to the counterpart's motions while effectively mitigating the error accumulation throughout the generation process.","We conduct comprehensive experiments using the challenging boxing task.","Experimental results demonstrate that our method outperforms existing baselines and can generate extended motion sequences.","Additionally, we show that our approach can be controlled by sparse signals, making it well-suited for VR and other online interactive environments."],"url":"http://arxiv.org/abs/2502.20370v1"}
{"created":"2025-02-27 18:37:49","title":"Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding","abstract":"Multi-agent path planning is a critical challenge in robotics, requiring agents to navigate complex environments while avoiding collisions and optimizing travel efficiency. This work addresses the limitations of existing approaches by combining Gaussian belief propagation with path integration and introducing a novel tracking factor to ensure strict adherence to global paths. The proposed method is tested with two different global path-planning approaches: rapidly exploring random trees and a structured planner, which leverages predefined lane structures to improve coordination. A simulation environment was developed to validate the proposed method across diverse scenarios, each posing unique challenges in navigation and communication. Simulation results demonstrate that the tracking factor reduces path deviation by 28% in single-agent and 16% in multi-agent scenarios, highlighting its effectiveness in improving multi-agent coordination, especially when combined with structured global planning.","sentences":["Multi-agent path planning is a critical challenge in robotics, requiring agents to navigate complex environments while avoiding collisions and optimizing travel efficiency.","This work addresses the limitations of existing approaches by combining Gaussian belief propagation with path integration and introducing a novel tracking factor to ensure strict adherence to global paths.","The proposed method is tested with two different global path-planning approaches: rapidly exploring random trees and a structured planner, which leverages predefined lane structures to improve coordination.","A simulation environment was developed to validate the proposed method across diverse scenarios, each posing unique challenges in navigation and communication.","Simulation results demonstrate that the tracking factor reduces path deviation by 28% in single-agent and 16% in multi-agent scenarios, highlighting its effectiveness in improving multi-agent coordination, especially when combined with structured global planning."],"url":"http://arxiv.org/abs/2502.20369v1"}
{"created":"2025-02-27 18:36:37","title":"The Role of Tactile Sensing for Learning Reach and Grasp","abstract":"Stable and robust robotic grasping is essential for current and future robot applications. In recent works, the use of large datasets and supervised learning has enhanced speed and precision in antipodal grasping. However, these methods struggle with perception and calibration errors due to large planning horizons. To obtain more robust and reactive grasping motions, leveraging reinforcement learning combined with tactile sensing is a promising direction. Yet, there is no systematic evaluation of how the complexity of force-based tactile sensing affects the learning behavior for grasping tasks. This paper compares various tactile and environmental setups using two model-free reinforcement learning approaches for antipodal grasping. Our findings suggest that under imperfect visual perception, various tactile features improve learning outcomes, while complex tactile inputs complicate training.","sentences":["Stable and robust robotic grasping is essential for current and future robot applications.","In recent works, the use of large datasets and supervised learning has enhanced speed and precision in antipodal grasping.","However, these methods struggle with perception and calibration errors due to large planning horizons.","To obtain more robust and reactive grasping motions, leveraging reinforcement learning combined with tactile sensing is a promising direction.","Yet, there is no systematic evaluation of how the complexity of force-based tactile sensing affects the learning behavior for grasping tasks.","This paper compares various tactile and environmental setups using two model-free reinforcement learning approaches for antipodal grasping.","Our findings suggest that under imperfect visual perception, various tactile features improve learning outcomes, while complex tactile inputs complicate training."],"url":"http://arxiv.org/abs/2502.20367v1"}
{"created":"2025-02-27 18:35:39","title":"Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization","abstract":"Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research. This technology excels at inferring relationships within vast unstructured or semi-structured datasets. The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations. It comprises constitutions, statutes, regulations, and case law. Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research. Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations. In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency. Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia. It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery. This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI.","sentences":["Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research.","This technology excels at inferring relationships within vast unstructured or semi-structured datasets.","The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations.","It comprises constitutions, statutes, regulations, and case law.","Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research.","Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations.","In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency.","Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia.","It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery.","This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI."],"url":"http://arxiv.org/abs/2502.20364v1"}
{"created":"2025-02-27 18:32:27","title":"OpenTAD: A Unified Framework and Comprehensive Study of Temporal Action Detection","abstract":"Temporal action detection (TAD) is a fundamental video understanding task that aims to identify human actions and localize their temporal boundaries in videos. Although this field has achieved remarkable progress in recent years, further progress and real-world applications are impeded by the absence of a standardized framework. Currently, different methods are compared under different implementation settings, evaluation protocols, etc., making it difficult to assess the real effectiveness of a specific technique. To address this issue, we propose \\textbf{OpenTAD}, a unified TAD framework consolidating 16 different TAD methods and 9 standard datasets into a modular codebase. In OpenTAD, minimal effort is required to replace one module with a different design, train a feature-based TAD model in end-to-end mode, or switch between the two. OpenTAD also facilitates straightforward benchmarking across various datasets and enables fair and in-depth comparisons among different methods. With OpenTAD, we comprehensively study how innovations in different network components affect detection performance and identify the most effective design choices through extensive experiments. This study has led to a new state-of-the-art TAD method built upon existing techniques for each component. We have made our code and models available at https://github.com/sming256/OpenTAD.","sentences":["Temporal action detection (TAD) is a fundamental video understanding task that aims to identify human actions and localize their temporal boundaries in videos.","Although this field has achieved remarkable progress in recent years, further progress and real-world applications are impeded by the absence of a standardized framework.","Currently, different methods are compared under different implementation settings, evaluation protocols, etc., making it difficult to assess the real effectiveness of a specific technique.","To address this issue, we propose \\textbf{OpenTAD}, a unified TAD framework consolidating 16 different TAD methods and 9 standard datasets into a modular codebase.","In OpenTAD, minimal effort is required to replace one module with a different design, train a feature-based TAD model in end-to-end mode, or switch between the two.","OpenTAD also facilitates straightforward benchmarking across various datasets and enables fair and in-depth comparisons among different methods.","With OpenTAD, we comprehensively study how innovations in different network components affect detection performance and identify the most effective design choices through extensive experiments.","This study has led to a new state-of-the-art TAD method built upon existing techniques for each component.","We have made our code and models available at https://github.com/sming256/OpenTAD."],"url":"http://arxiv.org/abs/2502.20361v1"}
{"created":"2025-02-27 18:32:16","title":"Selfish mining under general stochastic rewards","abstract":"Selfish mining, a strategy where Proof-of-Work consensus participants selectively withhold blocks, allows miners to earn disproportionately high revenue. The vast majority of the selfish mining literature focuses exclusively on block rewards. Carlsten et al. [2016] is a notable exception, which observes that similar strategic behavior may be profitable in a zero-block-reward regime if miners are compensated with transaction fees alone. As of February 2025, neither model fully captures miner incentives. The block reward remains 3.125 BTC, yet some blocks yield significantly higher revenue. For example, congestion during the launch of the Babylon protocol in August 2024 caused transaction fees to spike from 0.14 BTC to 9.52 BTC, a $68\\times$ increase in fee rewards within two blocks. We present a framework for considering strategic behavior under more general miner reward functions that could be stochastic, variable in time, and/or ephemeral. This model can capture many existing reward sources (sometimes called Miner/Maximal Extractable Value or MEV) in blockchains today. We use our framework to examine the profitability of cutoff selfish mining strategies for any reward function identically distributed across forks. Our analysis requires a novel reward calculation technique to capture non-linearity in general rewards. We instantiate these results in a combined reward function that much more accurately represents miner incentives as they exist in Bitcoin today. This reward function includes block rewards and linear-in-time transaction fees, which have been studied in isolation. It also introduces a third random reward motivated by the aforementioned transaction fee spike. This instantiation enables us to (i) make qualitative observations, (ii) make quantitative claims, and (iii) confirm the theoretical analysis using Monte Carlo simulations.","sentences":["Selfish mining, a strategy where Proof-of-Work consensus participants selectively withhold blocks, allows miners to earn disproportionately high revenue.","The vast majority of the selfish mining literature focuses exclusively on block rewards.","Carlsten et al.","[2016] is a notable exception, which observes that similar strategic behavior may be profitable in a zero-block-reward regime if miners are compensated with transaction fees alone.","As of February 2025, neither model fully captures miner incentives.","The block reward remains 3.125 BTC, yet some blocks yield significantly higher revenue.","For example, congestion during the launch of the Babylon protocol in August 2024 caused transaction fees to spike from 0.14 BTC to 9.52 BTC, a $68\\times$ increase in fee rewards within two blocks.","We present a framework for considering strategic behavior under more general miner reward functions that could be stochastic, variable in time, and/or ephemeral.","This model can capture many existing reward sources (sometimes called Miner/Maximal Extractable Value or MEV) in blockchains today.","We use our framework to examine the profitability of cutoff selfish mining strategies for any reward function identically distributed across forks.","Our analysis requires a novel reward calculation technique to capture non-linearity in general rewards.","We instantiate these results in a combined reward function that much more accurately represents miner incentives as they exist in Bitcoin today.","This reward function includes block rewards and linear-in-time transaction fees, which have been studied in isolation.","It also introduces a third random reward motivated by the aforementioned transaction fee spike.","This instantiation enables us to (i) make qualitative observations, (ii) make quantitative claims, and (iii) confirm the theoretical analysis using Monte Carlo simulations."],"url":"http://arxiv.org/abs/2502.20360v1"}
{"created":"2025-02-27 18:32:13","title":"Evaluating the long-term viability of eye-tracking for continuous authentication in virtual reality","abstract":"Traditional authentication methods, such as passwords and biometrics, verify a user's identity only at the start of a session, leaving systems vulnerable to session hijacking. Continuous authentication, however, ensures ongoing verification by monitoring user behavior. This study investigates the long-term feasibility of eye-tracking as a behavioral biometric for continuous authentication in virtual reality (VR) environments, using data from the GazebaseVR dataset. Our approach evaluates three architectures, Transformer Encoder, DenseNet, and XGBoost, on short and long-term data to determine their efficacy in user identification tasks. Initial results indicate that both Transformer Encoder and DenseNet models achieve high accuracy rates of up to 97% in short-term settings, effectively capturing unique gaze patterns. However, when tested on data collected 26 months later, model accuracy declined significantly, with rates as low as 1.78% for some tasks. To address this, we propose periodic model updates incorporating recent data, restoring accuracy to over 95%. These findings highlight the adaptability required for gaze-based continuous authentication systems and underscore the need for model retraining to manage evolving user behavior. Our study provides insights into the efficacy and limitations of eye-tracking as a biometric for VR authentication, paving the way for adaptive, secure VR user experiences.","sentences":["Traditional authentication methods, such as passwords and biometrics, verify a user's identity only at the start of a session, leaving systems vulnerable to session hijacking.","Continuous authentication, however, ensures ongoing verification by monitoring user behavior.","This study investigates the long-term feasibility of eye-tracking as a behavioral biometric for continuous authentication in virtual reality (VR) environments, using data from the GazebaseVR dataset.","Our approach evaluates three architectures, Transformer Encoder, DenseNet, and XGBoost, on short and long-term data to determine their efficacy in user identification tasks.","Initial results indicate that both Transformer Encoder and DenseNet models achieve high accuracy rates of up to 97% in short-term settings, effectively capturing unique gaze patterns.","However, when tested on data collected 26 months later, model accuracy declined significantly, with rates as low as 1.78% for some tasks.","To address this, we propose periodic model updates incorporating recent data, restoring accuracy to over 95%.","These findings highlight the adaptability required for gaze-based continuous authentication systems and underscore the need for model retraining to manage evolving user behavior.","Our study provides insights into the efficacy and limitations of eye-tracking as a biometric for VR authentication, paving the way for adaptive, secure VR user experiences."],"url":"http://arxiv.org/abs/2502.20359v1"}
{"created":"2025-02-27 18:29:09","title":"Bridging the Creativity Understanding Gap: Small-Scale Human Alignment Enables Expert-Level Humor Ranking in LLMs","abstract":"Large Language Models (LLMs) have shown significant limitations in understanding creative content, as demonstrated by Hessel et al. (2023)'s influential work on the New Yorker Cartoon Caption Contest (NYCCC). Their study exposed a substantial gap between LLMs and humans in humor comprehension, establishing that understanding and evaluating creative content is key challenge in AI development. We revisit this challenge by decomposing humor understanding into three components and systematically improve each: enhancing visual understanding through improved annotation, utilizing LLM-generated humor reasoning and explanations, and implementing targeted alignment with human preference data. Our refined approach achieves 82.4% accuracy in caption ranking, singificantly improving upon the previous 67% benchmark and matching the performance of world-renowned human experts in this domain. Notably, while attempts to mimic subgroup preferences through various persona prompts showed minimal impact, model finetuning with crowd preferences proved remarkably effective. These findings reveal that LLM limitations in creative judgment can be effectively addressed through focused alignment to specific subgroups and individuals. Lastly, we propose the position that achieving artificial general intelligence necessitates systematic collection of human preference data across creative domains. We advocate that just as human creativity is deeply influenced by individual and cultural preferences, training LLMs with diverse human preference data may be essential for developing true creative understanding.","sentences":["Large Language Models (LLMs) have shown significant limitations in understanding creative content, as demonstrated by Hessel et al.","(2023)'s influential work on the New Yorker Cartoon Caption Contest (NYCCC).","Their study exposed a substantial gap between LLMs and humans in humor comprehension, establishing that understanding and evaluating creative content is key challenge in AI development.","We revisit this challenge by decomposing humor understanding into three components and systematically improve each: enhancing visual understanding through improved annotation, utilizing LLM-generated humor reasoning and explanations, and implementing targeted alignment with human preference data.","Our refined approach achieves 82.4% accuracy in caption ranking, singificantly improving upon the previous 67% benchmark and matching the performance of world-renowned human experts in this domain.","Notably, while attempts to mimic subgroup preferences through various persona prompts showed minimal impact, model finetuning with crowd preferences proved remarkably effective.","These findings reveal that LLM limitations in creative judgment can be effectively addressed through focused alignment to specific subgroups and individuals.","Lastly, we propose the position that achieving artificial general intelligence necessitates systematic collection of human preference data across creative domains.","We advocate that just as human creativity is deeply influenced by individual and cultural preferences, training LLMs with diverse human preference data may be essential for developing true creative understanding."],"url":"http://arxiv.org/abs/2502.20356v1"}
{"created":"2025-02-27 18:27:34","title":"The entropy profiles of a definable set over finite fields","abstract":"A definable set $X$ in the first-order language of rings defines a family of random vectors: for each finite field $\\mathbb{F}_q$, let the distribution be supported and uniform on the $\\mathbb{F}_q$-rational points of $X$. We employ results from the model theory of finite fields to show that their entropy profiles settle into one of finitely many stable asymptotic behaviors as $q$ grows. The attainable asymptotic entropy profiles and their dominant terms as functions of $q$ are computable. This generalizes a construction of Mat\\'u\\v{s} which gives an information-theoretic interpretation to algebraic matroids.","sentences":["A definable set $X$ in the first-order language of rings defines a family of random vectors: for each finite field $\\mathbb{F}_q$, let the distribution be supported and uniform on the $\\mathbb{F}_q$-rational points of $X$. We employ results from the model theory of finite fields to show that their entropy profiles settle into one of finitely many stable asymptotic behaviors as $q$ grows.","The attainable asymptotic entropy profiles and their dominant terms as functions of $q$ are computable.","This generalizes a construction of Mat\\'u\\v{s} which gives an information-theoretic interpretation to algebraic matroids."],"url":"http://arxiv.org/abs/2502.20355v1"}
{"created":"2025-02-27 18:27:30","title":"Towards Responsible AI in Education: Hybrid Recommendation System for K-12 Students Case Study","abstract":"The growth of Educational Technology (EdTech) has enabled highly personalized learning experiences through Artificial Intelligence (AI)-based recommendation systems tailored to each student needs. However, these systems can unintentionally introduce biases, potentially limiting fair access to learning resources. This study presents a recommendation system for K-12 students, combining graph-based modeling and matrix factorization to provide personalized suggestions for extracurricular activities, learning resources, and volunteering opportunities. To address fairness concerns, the system includes a framework to detect and reduce biases by analyzing feedback across protected student groups. This work highlights the need for continuous monitoring in educational recommendation systems to support equitable, transparent, and effective learning opportunities for all students.","sentences":["The growth of Educational Technology (EdTech) has enabled highly personalized learning experiences through Artificial Intelligence (AI)-based recommendation systems tailored to each student needs.","However, these systems can unintentionally introduce biases, potentially limiting fair access to learning resources.","This study presents a recommendation system for K-12 students, combining graph-based modeling and matrix factorization to provide personalized suggestions for extracurricular activities, learning resources, and volunteering opportunities.","To address fairness concerns, the system includes a framework to detect and reduce biases by analyzing feedback across protected student groups.","This work highlights the need for continuous monitoring in educational recommendation systems to support equitable, transparent, and effective learning opportunities for all students."],"url":"http://arxiv.org/abs/2502.20354v1"}
{"created":"2025-02-27 18:27:05","title":"Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison","abstract":"Scenario Description Languages (SDLs) provide structured, interpretable embeddings that represent traffic scenarios encountered by autonomous vehicles (AVs), supporting key tasks such as scenario similarity searches and edge case detection for safety analysis. This paper introduces the Trajectory-to-Action Pipeline (TAP), a scalable and automated method for extracting SDL labels from large trajectory datasets. TAP applies a rules-based cross-entropy optimization approach to learn parameters directly from data, enhancing generalization across diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD), TAP achieves 30% greater precision than Average Displacement Error (ADE) and 24% over Dynamic Time Warping (DTW) in identifying behaviorally similar trajectories. Additionally, TAP enables automated detection of unique driving behaviors, streamlining safety evaluation processes for AV testing. This work provides a foundation for scalable scenario-based AV behavior analysis, with potential extensions for integrating multi-agent contexts.","sentences":["Scenario Description Languages (SDLs) provide structured, interpretable embeddings that represent traffic scenarios encountered by autonomous vehicles (AVs), supporting key tasks such as scenario similarity searches and edge case detection for safety analysis.","This paper introduces the Trajectory-to-Action Pipeline (TAP), a scalable and automated method for extracting SDL labels from large trajectory datasets.","TAP applies a rules-based cross-entropy optimization approach to learn parameters directly from data, enhancing generalization across diverse driving contexts.","Using the Waymo Open Motion Dataset (WOMD), TAP achieves 30% greater precision than Average Displacement Error (ADE) and 24% over Dynamic Time Warping (DTW) in identifying behaviorally similar trajectories.","Additionally, TAP enables automated detection of unique driving behaviors, streamlining safety evaluation processes for AV testing.","This work provides a foundation for scalable scenario-based AV behavior analysis, with potential extensions for integrating multi-agent contexts."],"url":"http://arxiv.org/abs/2502.20353v1"}
{"created":"2025-02-27 18:22:33","title":"KEDRec-LM: A Knowledge-distilled Explainable Drug Recommendation Large Language Model","abstract":"Drug discovery is a critical task in biomedical natural language processing (NLP), yet explainable drug discovery remains underexplored. Meanwhile, large language models (LLMs) have shown remarkable abilities in natural language understanding and generation. Leveraging LLMs for explainable drug discovery has the potential to improve downstream tasks and real-world applications. In this study, we utilize open-source drug knowledge graphs, clinical trial data, and PubMed publications to construct a comprehensive dataset for the explainable drug discovery task, named \\textbf{expRxRec}. Furthermore, we introduce \\textbf{KEDRec-LM}, an instruction-tuned LLM which distills knowledge from rich medical knowledge corpus for drug recommendation and rationale generation. To encourage further research in this area, we will publicly release\\footnote{A copy is attached with this submission} both the dataset and KEDRec-LM.","sentences":["Drug discovery is a critical task in biomedical natural language processing (NLP), yet explainable drug discovery remains underexplored.","Meanwhile, large language models (LLMs) have shown remarkable abilities in natural language understanding and generation.","Leveraging LLMs for explainable drug discovery has the potential to improve downstream tasks and real-world applications.","In this study, we utilize open-source drug knowledge graphs, clinical trial data, and PubMed publications to construct a comprehensive dataset for the explainable drug discovery task, named \\textbf{expRxRec}.","Furthermore, we introduce \\textbf{KEDRec-LM}, an instruction-tuned LLM which distills knowledge from rich medical knowledge corpus for drug recommendation and rationale generation.","To encourage further research in this area, we will publicly release\\footnote{A copy is attached with this submission} both the dataset and KEDRec-LM."],"url":"http://arxiv.org/abs/2502.20350v1"}
{"created":"2025-02-27 18:19:22","title":"Improving the Efficiency of a Deep Reinforcement Learning-Based Power Management System for HPC Clusters Using Curriculum Learning","abstract":"High energy consumption remains a key challenge in high-performance computing (HPC) systems, which often feature hundreds or thousands of nodes drawing substantial power even in idle or standby modes. Although powering down unused nodes can improve energy efficiency, choosing the wrong time to do so can degrade quality of service by delaying job execution. Machine learning, in particular reinforcement learning (RL), has shown promise in determining optimal times to switch nodes on or off. In this study, we enhance the performance of a deep reinforcement learning (DRL) agent for HPC power management by integrating curriculum learning (CL), a training approach that introduces tasks with gradually increasing difficulty. Using the Batsim-py simulation framework, we compare the proposed CL-based agent to both a baseline DRL method (without CL) and the conventional fixed-time timeout strategy. Experimental results confirm that an easy-to-hard curriculum outperforms other training orders in terms of reducing wasted energy usage. The best agent achieves a 3.73% energy reduction over the baseline DRL method and a 4.66% improvement compared to the best timeout configuration (shutdown every 15 minutes of idle time). In addition, it reduces average job waiting time by 9.24% and maintains a higher job-filling rate, indicating more effective resource utilization. Sensitivity tests across various switch-on durations, power levels, and cluster sizes further reveal the agent's adaptability to changing system parameters without retraining. These findings demonstrate that curriculum learning can significantly improve DRL-based power management in HPC, balancing energy savings, quality of service, and robustness to diverse configurations.","sentences":["High energy consumption remains a key challenge in high-performance computing (HPC) systems, which often feature hundreds or thousands of nodes drawing substantial power even in idle or standby modes.","Although powering down unused nodes can improve energy efficiency, choosing the wrong time to do so can degrade quality of service by delaying job execution.","Machine learning, in particular reinforcement learning (RL), has shown promise in determining optimal times to switch nodes on or off.","In this study, we enhance the performance of a deep reinforcement learning (DRL) agent for HPC power management by integrating curriculum learning (CL), a training approach that introduces tasks with gradually increasing difficulty.","Using the Batsim-py simulation framework, we compare the proposed CL-based agent to both a baseline DRL method (without CL) and the conventional fixed-time timeout strategy.","Experimental results confirm that an easy-to-hard curriculum outperforms other training orders in terms of reducing wasted energy usage.","The best agent achieves a 3.73% energy reduction over the baseline DRL method and a 4.66% improvement compared to the best timeout configuration (shutdown every 15 minutes of idle time).","In addition, it reduces average job waiting time by 9.24% and maintains a higher job-filling rate, indicating more effective resource utilization.","Sensitivity tests across various switch-on durations, power levels, and cluster sizes further reveal the agent's adaptability to changing system parameters without retraining.","These findings demonstrate that curriculum learning can significantly improve DRL-based power management in HPC, balancing energy savings, quality of service, and robustness to diverse configurations."],"url":"http://arxiv.org/abs/2502.20348v1"}
{"created":"2025-02-27 18:17:26","title":"Equilibria and Learning in Modular Marketplaces","abstract":"We envision a marketplace where diverse entities offer specialized \"modules\" through APIs, allowing users to compose the outputs of these modules for complex tasks within a given budget. This paper studies the market design problem in such an ecosystem, where module owners strategically set prices for their APIs (to maximize their profit) and a central platform orchestrates the aggregation of module outputs at query-time. One can also think about this as a first-price procurement auction with budgets. The first observation is that if the platform's algorithm is to find the optimal set of modules then this could result in a poor outcome, in the sense that there are price equilibria which provide arbitrarily low value for the user. We show that under a suitable version of the \"bang-per-buck\" algorithm for the knapsack problem, an $\\varepsilon$-approximate equilibrium always exists, for any arbitrary $\\varepsilon > 0$. Further, our first main result shows that with this algorithm any such equilibrium provides a constant approximation to the optimal value that the buyer could get under various constraints including (i) a budget constraint and (ii) a budget and a matroid constraint. Finally, we demonstrate that these efficient equilibria can be learned through decentralized price adjustments by module owners using no-regret learning algorithms.","sentences":["We envision a marketplace where diverse entities offer specialized \"modules\" through APIs, allowing users to compose the outputs of these modules for complex tasks within a given budget.","This paper studies the market design problem in such an ecosystem, where module owners strategically set prices for their APIs (to maximize their profit) and a central platform orchestrates the aggregation of module outputs at query-time.","One can also think about this as a first-price procurement auction with budgets.","The first observation is that if the platform's algorithm is to find the optimal set of modules then this could result in a poor outcome, in the sense that there are price equilibria which provide arbitrarily low value for the user.","We show that under a suitable version of the \"bang-per-buck\" algorithm for the knapsack problem, an $\\varepsilon$-approximate equilibrium always exists, for any arbitrary $\\varepsilon > 0$.","Further, our first main result shows that with this algorithm any such equilibrium provides a constant approximation to the optimal value that the buyer could get under various constraints including (i) a budget constraint and (ii) a budget and a matroid constraint.","Finally, we demonstrate that these efficient equilibria can be learned through decentralized price adjustments by module owners using no-regret learning algorithms."],"url":"http://arxiv.org/abs/2502.20346v1"}
{"created":"2025-02-27 18:16:47","title":"Sparse Auto-Encoder Interprets Linguistic Features in Large Language Models","abstract":"Large language models (LLMs) excel in tasks that require complex linguistic abilities, such as reference disambiguation and metaphor recognition/generation. Although LLMs possess impressive capabilities, their internal mechanisms for processing and representing linguistic knowledge remain largely opaque. Previous work on linguistic mechanisms has been limited by coarse granularity, insufficient causal analysis, and a narrow focus. In this study, we present a systematic and comprehensive causal investigation using sparse auto-encoders (SAEs). We extract a wide range of linguistic features from six dimensions: phonetics, phonology, morphology, syntax, semantics, and pragmatics. We extract, evaluate, and intervene on these features by constructing minimal contrast datasets and counterfactual sentence datasets. We introduce two indices-Feature Representation Confidence (FRC) and Feature Intervention Confidence (FIC)-to measure the ability of linguistic features to capture and control linguistic phenomena. Our results reveal inherent representations of linguistic knowledge in LLMs and demonstrate the potential for controlling model outputs. This work provides strong evidence that LLMs possess genuine linguistic knowledge and lays the foundation for more interpretable and controllable language modeling in future research.","sentences":["Large language models (LLMs) excel in tasks that require complex linguistic abilities, such as reference disambiguation and metaphor recognition/generation.","Although LLMs possess impressive capabilities, their internal mechanisms for processing and representing linguistic knowledge remain largely opaque.","Previous work on linguistic mechanisms has been limited by coarse granularity, insufficient causal analysis, and a narrow focus.","In this study, we present a systematic and comprehensive causal investigation using sparse auto-encoders (SAEs).","We extract a wide range of linguistic features from six dimensions: phonetics, phonology, morphology, syntax, semantics, and pragmatics.","We extract, evaluate, and intervene on these features by constructing minimal contrast datasets and counterfactual sentence datasets.","We introduce two indices-Feature Representation Confidence (FRC) and Feature Intervention Confidence (FIC)-to measure the ability of linguistic features to capture and control linguistic phenomena.","Our results reveal inherent representations of linguistic knowledge in LLMs and demonstrate the potential for controlling model outputs.","This work provides strong evidence that LLMs possess genuine linguistic knowledge and lays the foundation for more interpretable and controllable language modeling in future research."],"url":"http://arxiv.org/abs/2502.20344v1"}
{"created":"2025-02-27 18:16:08","title":"Topology Optimization for Multi-Axis Additive Manufacturing Considering Overhang and Anisotropy","abstract":"Topology optimization produces designs with intricate geometries and complex topologies that require advanced manufacturing techniques such as additive manufacturing (AM). However, insufficient consideration of manufacturability during the optimization process often results in design modifications that compromise the optimality of the design. While multi-axis AM enhances manufacturability by enabling flexible material deposition in multiple orientations, challenges remain in addressing overhang structures, potential collisions, and material anisotropy caused by varying build orientations. To overcome these limitations, this study proposes a novel space-time topology optimization framework for multi-axis AM. The framework employs a pseudo-time field as a design variable to represent the fabrication sequence, simultaneously optimizing the density distribution and build orientations. This approach ensures that the overhang angles remain within manufacturable limits while also mitigating collisions. Moreover, by incorporating material anisotropy induced by diverse build orientations into the design process, the framework can take the scan path-dependent structural behaviors into account during the design optimization. Numerical examples demonstrate that the proposed framework effectively derives feasible and optimal designs that account for the manufacturing characteristics of multi-axis AM.","sentences":["Topology optimization produces designs with intricate geometries and complex topologies that require advanced manufacturing techniques such as additive manufacturing (AM).","However, insufficient consideration of manufacturability during the optimization process often results in design modifications that compromise the optimality of the design.","While multi-axis AM enhances manufacturability by enabling flexible material deposition in multiple orientations, challenges remain in addressing overhang structures, potential collisions, and material anisotropy caused by varying build orientations.","To overcome these limitations, this study proposes a novel space-time topology optimization framework for multi-axis AM.","The framework employs a pseudo-time field as a design variable to represent the fabrication sequence, simultaneously optimizing the density distribution and build orientations.","This approach ensures that the overhang angles remain within manufacturable limits while also mitigating collisions.","Moreover, by incorporating material anisotropy induced by diverse build orientations into the design process, the framework can take the scan path-dependent structural behaviors into account during the design optimization.","Numerical examples demonstrate that the proposed framework effectively derives feasible and optimal designs that account for the manufacturing characteristics of multi-axis AM."],"url":"http://arxiv.org/abs/2502.20343v1"}
{"created":"2025-02-27 18:10:33","title":"Safety Representations for Safer Policy Learning","abstract":"Reinforcement learning algorithms typically necessitate extensive exploration of the state space to find optimal policies. However, in safety-critical applications, the risks associated with such exploration can lead to catastrophic consequences. Existing safe exploration methods attempt to mitigate this by imposing constraints, which often result in overly conservative behaviours and inefficient learning. Heavy penalties for early constraint violations can trap agents in local optima, deterring exploration of risky yet high-reward regions of the state space. To address this, we introduce a method that explicitly learns state-conditioned safety representations. By augmenting the state features with these safety representations, our approach naturally encourages safer exploration without being excessively cautious, resulting in more efficient and safer policy learning in safety-critical scenarios. Empirical evaluations across diverse environments show that our method significantly improves task performance while reducing constraint violations during training, underscoring its effectiveness in balancing exploration with safety.","sentences":["Reinforcement learning algorithms typically necessitate extensive exploration of the state space to find optimal policies.","However, in safety-critical applications, the risks associated with such exploration can lead to catastrophic consequences.","Existing safe exploration methods attempt to mitigate this by imposing constraints, which often result in overly conservative behaviours and inefficient learning.","Heavy penalties for early constraint violations can trap agents in local optima, deterring exploration of risky yet high-reward regions of the state space.","To address this, we introduce a method that explicitly learns state-conditioned safety representations.","By augmenting the state features with these safety representations, our approach naturally encourages safer exploration without being excessively cautious, resulting in more efficient and safer policy learning in safety-critical scenarios.","Empirical evaluations across diverse environments show that our method significantly improves task performance while reducing constraint violations during training, underscoring its effectiveness in balancing exploration with safety."],"url":"http://arxiv.org/abs/2502.20341v1"}
{"created":"2025-02-27 18:08:16","title":"Thinking Slow, Fast: Scaling Inference Compute with Distilled Reasoners","abstract":"Recent advancements have demonstrated that the performance of large language models (LLMs) can be significantly enhanced by scaling computational resources at test time. A common strategy involves generating multiple Chain-of-Thought (CoT) trajectories and aggregating their outputs through various selection mechanisms. This raises a fundamental question: can models with lower complexity leverage their superior generation throughput to outperform similarly sized Transformers for a fixed computational budget? To address this question and overcome the lack of strong subquadratic reasoners, we distill pure and hybrid Mamba models from pretrained Transformers. Trained on only 8 billion tokens, our distilled models show strong performance and scaling on mathematical reasoning datasets while being much faster at inference for large batches and long sequences. Despite the zero-shot performance hit due to distillation, both pure and hybrid Mamba models can scale their coverage and accuracy performance past their Transformer teacher models under fixed time budgets, opening a new direction for scaling inference compute.","sentences":["Recent advancements have demonstrated that the performance of large language models (LLMs) can be significantly enhanced by scaling computational resources at test time.","A common strategy involves generating multiple Chain-of-Thought (CoT) trajectories and aggregating their outputs through various selection mechanisms.","This raises a fundamental question: can models with lower complexity leverage their superior generation throughput to outperform similarly sized Transformers for a fixed computational budget?","To address this question and overcome the lack of strong subquadratic reasoners, we distill pure and hybrid Mamba models from pretrained Transformers.","Trained on only 8 billion tokens, our distilled models show strong performance and scaling on mathematical reasoning datasets while being much faster at inference for large batches and long sequences.","Despite the zero-shot performance hit due to distillation, both pure and hybrid Mamba models can scale their coverage and accuracy performance past their Transformer teacher models under fixed time budgets, opening a new direction for scaling inference compute."],"url":"http://arxiv.org/abs/2502.20339v1"}
{"created":"2025-02-27 18:08:10","title":"KeBaB: $k$-mer based breaking for finding super-maximal exact matches","abstract":"Suppose we have a tool for finding super-maximal exact matches (SMEMs) and we want to use it to find all the long SMEMs between a noisy long read $P$ and a highly repetitive pangenomic reference $T$. Notice that if $L \\geq k$ and the $k$-mer $P [i..i + k - 1]$ does not occur in $T$ then no SMEM of length at least $L$ contains $P [i..i + k - 1]$. Therefore, if we have a Bloom filter for the distinct $k$-mers in $T$ and we want to find only SMEMs of length $L \\geq k$, then when given $P$ we can break it into maximal substrings consisting only of $k$-mers the filter says occur in $T$ -- which we call pseudo-SMEMs -- and search only the ones of length at least $L$. If $L$ is reasonably large and we can choose $k$ well then the Bloom filter should be small (because $T$ is highly repetitive) but the total length of the pseudo-SMEMs we search should also be small (because $P$ is noisy). Now suppose we are interested only in the longest $t$ SMEMs of length at least $L$ between $P$ and $T$. Notice that once we have found $t$ SMEMs of length at least $\\ell$ then we need only search for SMEMs of length greater than $\\ell$. Therefore, if we sort the pseudo-SMEMs into non-increasing order by length, then we can stop searching once we have found $t$ SMEMs at least as long as the next pseudo-SMEM we would search. Our preliminary experiments indicate that these two admissible heuristics may significantly speed up SMEM-finding in practice.","sentences":["Suppose we have a tool for finding super-maximal exact matches (SMEMs) and we want to use it to find all the long SMEMs between a noisy long read $P$ and a highly repetitive pangenomic reference $T$. Notice that if $L \\geq k$ and the $k$-mer $P","[i..i","+ k - 1]$ does not occur in $T$ then no SMEM of length at least $L$ contains $P","[i..i","+ k - 1]$.","Therefore, if we have a Bloom filter for the distinct $k$-mers in $T$ and we want to find only SMEMs of length $L \\geq k$, then when given $P$ we can break it into maximal substrings consisting only of $k$-mers the filter says occur in $T$ -- which we call pseudo-SMEMs -- and search only the ones of length at least $L$. If $L$ is reasonably large and we can choose $k$ well then the Bloom filter should be small (because $T$ is highly repetitive) but the total length of the pseudo-SMEMs we search should also be small (because $P$ is noisy).","Now suppose we are interested only in the longest $t$ SMEMs of length at least $L$ between $P$ and $T$. Notice that once we have found $t$ SMEMs of length at least $\\ell$ then we need only search for SMEMs of length greater than $\\ell$. Therefore, if we sort the pseudo-SMEMs into non-increasing order by length, then we can stop searching once we have found $t$ SMEMs at least as long as the next pseudo-SMEM we would search.","Our preliminary experiments indicate that these two admissible heuristics may significantly speed up SMEM-finding in practice."],"url":"http://arxiv.org/abs/2502.20338v1"}
{"created":"2025-02-27 18:05:15","title":"Expertise Is What We Want","abstract":"Clinical decision-making depends on expert reasoning, which is guided by standardized, evidence-based guidelines. However, translating these guidelines into automated clinical decision support systems risks inaccuracy and importantly, loss of nuance. We share an application architecture, the Large Language Expert (LLE), that combines the flexibility and power of Large Language Models (LLMs) with the interpretability, explainability, and reliability of Expert Systems. LLMs help address key challenges of Expert Systems, such as integrating and codifying knowledge, and data normalization. Conversely, an Expert System-like approach helps overcome challenges with LLMs, including hallucinations, atomic and inexpensive updates, and testability.   To highlight the power of the Large Language Expert (LLE) system, we built an LLE to assist with the workup of patients newly diagnosed with cancer. Timely initiation of cancer treatment is critical for optimal patient outcomes. However, increasing complexity in diagnostic recommendations has made it difficult for primary care physicians to ensure their patients have completed the necessary workup before their first visit with an oncologist. As with many real-world clinical tasks, these workups require the analysis of unstructured health records and the application of nuanced clinical decision logic. In this study, we describe the design & evaluation of an LLE system built to rapidly identify and suggest the correct diagnostic workup. The system demonstrated a high degree of clinical-level accuracy (>95%) and effectively addressed gaps identified in real-world data from breast and colon cancer patients at a large academic center.","sentences":["Clinical decision-making depends on expert reasoning, which is guided by standardized, evidence-based guidelines.","However, translating these guidelines into automated clinical decision support systems risks inaccuracy and importantly, loss of nuance.","We share an application architecture, the Large Language Expert (LLE), that combines the flexibility and power of Large Language Models (LLMs) with the interpretability, explainability, and reliability of Expert Systems.","LLMs help address key challenges of Expert Systems, such as integrating and codifying knowledge, and data normalization.","Conversely, an Expert System-like approach helps overcome challenges with LLMs, including hallucinations, atomic and inexpensive updates, and testability.   ","To highlight the power of the Large Language Expert (LLE) system, we built an LLE to assist with the workup of patients newly diagnosed with cancer.","Timely initiation of cancer treatment is critical for optimal patient outcomes.","However, increasing complexity in diagnostic recommendations has made it difficult for primary care physicians to ensure their patients have completed the necessary workup before their first visit with an oncologist.","As with many real-world clinical tasks, these workups require the analysis of unstructured health records and the application of nuanced clinical decision logic.","In this study, we describe the design & evaluation of an LLE system built to rapidly identify and suggest the correct diagnostic workup.","The system demonstrated a high degree of clinical-level accuracy (>95%) and effectively addressed gaps identified in real-world data from breast and colon cancer patients at a large academic center."],"url":"http://arxiv.org/abs/2502.20335v1"}
{"created":"2025-02-27 18:02:42","title":"Economic Censorship Games in Fraud Proofs","abstract":"Optimistic rollups rely on fraud proofs -- interactive protocols executed on Ethereum to resolve conflicting claims about the rollup's state -- to scale Ethereum securely.   To mitigate against potential censorship of protocol moves, fraud proofs grant participants a significant time window, known as the challenge period, to ensure their moves are processed on chain. Major optimistic rollups today set this period at roughly one week, mainly to guard against strong censorship that undermines Ethereum's own crypto-economic security. However, other forms of censorship are possible, and their implication on optimistic rollup security is not well understood.   This paper considers economic censorship attacks, where an attacker censors the defender's transactions by bribing block proposers. At each step, the attacker can either censor the defender -- depleting the defender's time allowance at the cost of the bribe -- or allow the current transaction through while conserving funds for future censorship.   We analyze three game theoretic models of these dynamics and determine the challenge period length required to ensure the defender's success, as a function of the number of required protocol moves and the players' available budgets.","sentences":["Optimistic rollups rely on fraud proofs -- interactive protocols executed on Ethereum to resolve conflicting claims about the rollup's state -- to scale Ethereum securely.   ","To mitigate against potential censorship of protocol moves, fraud proofs grant participants a significant time window, known as the challenge period, to ensure their moves are processed on chain.","Major optimistic rollups today set this period at roughly one week, mainly to guard against strong censorship that undermines Ethereum's own crypto-economic security.","However, other forms of censorship are possible, and their implication on optimistic rollup security is not well understood.   ","This paper considers economic censorship attacks, where an attacker censors the defender's transactions by bribing block proposers.","At each step, the attacker can either censor the defender -- depleting the defender's time allowance at the cost of the bribe -- or allow the current transaction through while conserving funds for future censorship.   ","We analyze three game theoretic models of these dynamics and determine the challenge period length required to ensure the defender's success, as a function of the number of required protocol moves and the players' available budgets."],"url":"http://arxiv.org/abs/2502.20334v1"}
{"created":"2025-02-27 18:02:15","title":"Emergent Symbolic Mechanisms Support Abstract Reasoning in Large Language Models","abstract":"Many recent studies have found evidence for emergent reasoning capabilities in large language models, but debate persists concerning the robustness of these capabilities, and the extent to which they depend on structured reasoning mechanisms. To shed light on these issues, we perform a comprehensive study of the internal mechanisms that support abstract rule induction in an open-source language model (Llama3-70B). We identify an emergent symbolic architecture that implements abstract reasoning via a series of three computations. In early layers, symbol abstraction heads convert input tokens to abstract variables based on the relations between those tokens. In intermediate layers, symbolic induction heads perform sequence induction over these abstract variables. Finally, in later layers, retrieval heads predict the next token by retrieving the value associated with the predicted abstract variable. These results point toward a resolution of the longstanding debate between symbolic and neural network approaches, suggesting that emergent reasoning in neural networks depends on the emergence of symbolic mechanisms.","sentences":["Many recent studies have found evidence for emergent reasoning capabilities in large language models, but debate persists concerning the robustness of these capabilities, and the extent to which they depend on structured reasoning mechanisms.","To shed light on these issues, we perform a comprehensive study of the internal mechanisms that support abstract rule induction in an open-source language model (Llama3-70B).","We identify an emergent symbolic architecture that implements abstract reasoning via a series of three computations.","In early layers, symbol abstraction heads convert input tokens to abstract variables based on the relations between those tokens.","In intermediate layers, symbolic induction heads perform sequence induction over these abstract variables.","Finally, in later layers, retrieval heads predict the next token by retrieving the value associated with the predicted abstract variable.","These results point toward a resolution of the longstanding debate between symbolic and neural network approaches, suggesting that emergent reasoning in neural networks depends on the emergence of symbolic mechanisms."],"url":"http://arxiv.org/abs/2502.20332v1"}
{"created":"2025-02-27 17:59:36","title":"Long-Context Inference with Retrieval-Augmented Speculative Decoding","abstract":"The emergence of long-context large language models (LLMs) offers a promising alternative to traditional retrieval-augmented generation (RAG) for processing extensive documents. However, the computational overhead of long-context inference, particularly in managing key-value (KV) caches, presents significant efficiency challenges. While Speculative Decoding (SD) traditionally accelerates inference using smaller draft models, its effectiveness diminishes substantially in long-context scenarios due to memory-bound KV cache operations. We present Retrieval-Augmented Speculative Decoding (RAPID), which leverages RAG for both accelerating and enhancing generation quality in long-context inference. RAPID introduces the RAG drafter-a draft LLM operating on shortened retrieval contexts-to speculate on the generation of long-context target LLMs. Our approach enables a new paradigm where same-scale or even larger LLMs can serve as RAG drafters while maintaining computational efficiency. To fully leverage the potentially superior capabilities from stronger RAG drafters, we develop an inference-time knowledge transfer dynamic that enriches the target distribution by RAG. Extensive experiments on the LLaMA-3.1 and Qwen2.5 backbones demonstrate that RAPID effectively integrates the strengths of both approaches, achieving significant performance improvements (e.g., from 39.33 to 42.83 on InfiniteBench for LLaMA-3.1-8B) with more than 2x speedups. Our analyses reveal that RAPID achieves robust acceleration beyond 32K context length and demonstrates superior generation quality in real-world applications.","sentences":["The emergence of long-context large language models (LLMs) offers a promising alternative to traditional retrieval-augmented generation (RAG) for processing extensive documents.","However, the computational overhead of long-context inference, particularly in managing key-value (KV) caches, presents significant efficiency challenges.","While Speculative Decoding (SD) traditionally accelerates inference using smaller draft models, its effectiveness diminishes substantially in long-context scenarios due to memory-bound KV cache operations.","We present Retrieval-Augmented Speculative Decoding (RAPID), which leverages RAG for both accelerating and enhancing generation quality in long-context inference.","RAPID introduces the RAG drafter-a draft LLM operating on shortened retrieval contexts-to speculate on the generation of long-context target LLMs.","Our approach enables a new paradigm where same-scale or even larger LLMs can serve as RAG drafters while maintaining computational efficiency.","To fully leverage the potentially superior capabilities from stronger RAG drafters, we develop an inference-time knowledge transfer dynamic that enriches the target distribution by RAG.","Extensive experiments on the LLaMA-3.1","and Qwen2.5 backbones demonstrate that RAPID effectively integrates the strengths of both approaches, achieving significant performance improvements (e.g., from 39.33 to 42.83 on InfiniteBench for LLaMA-3.1-8B) with more than 2x speedups.","Our analyses reveal that RAPID achieves robust acceleration beyond 32K context length and demonstrates superior generation quality in real-world applications."],"url":"http://arxiv.org/abs/2502.20330v1"}
{"created":"2025-02-27 17:53:16","title":"Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application","abstract":"This paper proposes a holistic framework for autonomous guidance, navigation, and task distribution among multi-drone systems operating in Global Navigation Satellite System (GNSS)-denied indoor settings. We advocate for a Deep Reinforcement Learning (DRL)-based guidance mechanism, utilising the Twin Delayed Deep Deterministic Policy Gradient algorithm. To improve the efficiency of the training process, we incorporate an Artificial Potential Field (APF)-based reward structure, enabling the agent to refine its movements, thereby promoting smoother paths and enhanced obstacle avoidance in indoor contexts. Furthermore, we tackle the issue of task distribution among cooperative UAVs through a DRL-trained Graph Convolutional Network (GCN). This GCN represents the interactions between drones and tasks, facilitating dynamic and real-time task allocation that reflects the current environmental conditions and the capabilities of the drones. Such an approach fosters effective coordination and collaboration among multiple drones during search and rescue operations or other exploratory endeavours. Lastly, to ensure precise odometry in environments lacking GNSS, we employ Light Detection And Ranging Simultaneous Localisation and Mapping complemented by a depth camera to mitigate the hallway problem. This integration offers robust localisation and mapping functionalities, thereby enhancing the systems dependability in indoor navigation. The proposed multi-drone framework not only elevates individual navigation capabilities but also optimises coordinated task allocation in complex, obstacle-laden environments. Experimental evaluations conducted in a setup tailored to meet the requirements of the NATO Sapience Autonomous Cooperative Drone Competition demonstrate the efficacy of the proposed system, yielding outstanding results and culminating in a first-place finish in the 2024 Sapience competition.","sentences":["This paper proposes a holistic framework for autonomous guidance, navigation, and task distribution among multi-drone systems operating in Global Navigation Satellite System (GNSS)-denied indoor settings.","We advocate for a Deep Reinforcement Learning (DRL)-based guidance mechanism, utilising the Twin Delayed Deep Deterministic Policy Gradient algorithm.","To improve the efficiency of the training process, we incorporate an Artificial Potential Field (APF)-based reward structure, enabling the agent to refine its movements, thereby promoting smoother paths and enhanced obstacle avoidance in indoor contexts.","Furthermore, we tackle the issue of task distribution among cooperative UAVs through a DRL-trained Graph Convolutional Network (GCN).","This GCN represents the interactions between drones and tasks, facilitating dynamic and real-time task allocation that reflects the current environmental conditions and the capabilities of the drones.","Such an approach fosters effective coordination and collaboration among multiple drones during search and rescue operations or other exploratory endeavours.","Lastly, to ensure precise odometry in environments lacking GNSS, we employ Light Detection","And","Ranging Simultaneous Localisation and Mapping complemented by a depth camera to mitigate the hallway problem.","This integration offers robust localisation and mapping functionalities, thereby enhancing the systems dependability in indoor navigation.","The proposed multi-drone framework not only elevates individual navigation capabilities but also optimises coordinated task allocation in complex, obstacle-laden environments.","Experimental evaluations conducted in a setup tailored to meet the requirements of the NATO Sapience Autonomous Cooperative Drone Competition demonstrate the efficacy of the proposed system, yielding outstanding results and culminating in a first-place finish in the 2024 Sapience competition."],"url":"http://arxiv.org/abs/2502.20326v1"}
{"created":"2025-02-27 17:50:17","title":"On Adversarial Attacks In Acoustic Drone Localization","abstract":"Multi-rotor aerial autonomous vehicles (MAVs, more widely known as \"drones\") have been generating increased interest in recent years due to their growing applicability in a vast and diverse range of fields (e.g., agriculture, commercial delivery, search and rescue). The sensitivity of visual-based methods to lighting conditions and occlusions had prompted growing study of navigation reliant on other modalities, such as acoustic sensing. A major concern in using drones in scale for tasks in non-controlled environments is the potential threat of adversarial attacks over their navigational systems, exposing users to mission-critical failures, security breaches, and compromised safety outcomes that can endanger operators and bystanders. While previous work shows impressive progress in acoustic-based drone localization, prior research in adversarial attacks over drone navigation only addresses visual sensing-based systems. In this work, we aim to compensate for this gap by supplying a comprehensive analysis of the effect of PGD adversarial attacks over acoustic drone localization. We furthermore develop an algorithm for adversarial perturbation recovery, capable of markedly diminishing the affect of such attacks in our setting. The code for reproducing all experiments will be released upon publication.","sentences":["Multi-rotor aerial autonomous vehicles (MAVs, more widely known as \"drones\") have been generating increased interest in recent years due to their growing applicability in a vast and diverse range of fields (e.g., agriculture, commercial delivery, search and rescue).","The sensitivity of visual-based methods to lighting conditions and occlusions had prompted growing study of navigation reliant on other modalities, such as acoustic sensing.","A major concern in using drones in scale for tasks in non-controlled environments is the potential threat of adversarial attacks over their navigational systems, exposing users to mission-critical failures, security breaches, and compromised safety outcomes that can endanger operators and bystanders.","While previous work shows impressive progress in acoustic-based drone localization, prior research in adversarial attacks over drone navigation only addresses visual sensing-based systems.","In this work, we aim to compensate for this gap by supplying a comprehensive analysis of the effect of PGD adversarial attacks over acoustic drone localization.","We furthermore develop an algorithm for adversarial perturbation recovery, capable of markedly diminishing the affect of such attacks in our setting.","The code for reproducing all experiments will be released upon publication."],"url":"http://arxiv.org/abs/2502.20325v1"}
{"created":"2025-02-27 17:49:01","title":"ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model","abstract":"Speech-driven 3D facial animation aims to generate realistic lip movements and facial expressions for 3D head models from arbitrary audio clips. Although existing diffusion-based methods are capable of producing natural motions, their slow generation speed limits their application potential. In this paper, we introduce a novel autoregressive model that achieves real-time generation of highly synchronized lip movements and realistic head poses and eye blinks by learning a mapping from speech to a multi-scale motion codebook. Furthermore, our model can adapt to unseen speaking styles using sample motion sequences, enabling the creation of 3D talking avatars with unique personal styles beyond the identities seen during training. Extensive evaluations and user studies demonstrate that our method outperforms existing approaches in lip synchronization accuracy and perceived quality.","sentences":["Speech-driven 3D facial animation aims to generate realistic lip movements and facial expressions for 3D head models from arbitrary audio clips.","Although existing diffusion-based methods are capable of producing natural motions, their slow generation speed limits their application potential.","In this paper, we introduce a novel autoregressive model that achieves real-time generation of highly synchronized lip movements and realistic head poses and eye blinks by learning a mapping from speech to a multi-scale motion codebook.","Furthermore, our model can adapt to unseen speaking styles using sample motion sequences, enabling the creation of 3D talking avatars with unique personal styles beyond the identities seen during training.","Extensive evaluations and user studies demonstrate that our method outperforms existing approaches in lip synchronization accuracy and perceived quality."],"url":"http://arxiv.org/abs/2502.20323v1"}
{"created":"2025-02-27 17:47:01","title":"UniTok: A Unified Tokenizer for Visual Generation and Understanding","abstract":"The representation disparity between visual generation and understanding imposes a critical gap in integrating these capabilities into a single framework. To bridge this gap, we introduce UniTok, a discrete visual tokenizer that encodes fine-grained details for generation while also capturing high-level semantics for understanding. Despite recent studies have shown that these objectives could induce loss conflicts in training, we reveal that the underlying bottleneck stems from limited representational capacity of discrete tokens. We address this by introducing multi-codebook quantization, which divides vector quantization with several independent sub-codebooks to expand the latent feature space, while avoiding training instability caused by overlarge codebooks. Our method significantly raises the upper limit of unified discrete tokenizers to match or even surpass domain-specific continuous tokenizers. For instance, UniTok achieves a remarkable rFID of 0.38 (versus 0.87 for SD-VAE) and a zero-shot accuracy of 78.6% (versus 76.2% for CLIP) on ImageNet. Our code is available at https://github.com/FoundationVision/UniTok.","sentences":["The representation disparity between visual generation and understanding imposes a critical gap in integrating these capabilities into a single framework.","To bridge this gap, we introduce UniTok, a discrete visual tokenizer that encodes fine-grained details for generation while also capturing high-level semantics for understanding.","Despite recent studies have shown that these objectives could induce loss conflicts in training, we reveal that the underlying bottleneck stems from limited representational capacity of discrete tokens.","We address this by introducing multi-codebook quantization, which divides vector quantization with several independent sub-codebooks to expand the latent feature space, while avoiding training instability caused by overlarge codebooks.","Our method significantly raises the upper limit of unified discrete tokenizers to match or even surpass domain-specific continuous tokenizers.","For instance, UniTok achieves a remarkable rFID of 0.38 (versus 0.87 for SD-VAE) and a zero-shot accuracy of 78.6% (versus 76.2% for CLIP) on ImageNet.","Our code is available at https://github.com/FoundationVision/UniTok."],"url":"http://arxiv.org/abs/2502.20321v1"}
{"created":"2025-02-27 17:45:20","title":"ACCORD: Application Context-aware Cross-layer Optimization and Resource Design for 5G/NextG Machine-centric Applications","abstract":"Recent advancements in AI and edge computing have accelerated the development of machine-centric applications (MCAs), such as smart surveillance systems. In these applications, video cameras and sensors offload inference tasks like license plate recognition and vehicle tracking to remote servers due to local computing and energy constraints. However, legacy network solutions, designed primarily for human-centric applications, struggle to reliably support these MCAs, which demand heterogeneous and fluctuating QoS (due to diverse application inference tasks), further challenged by dynamic wireless network conditions and limited spectrum resources. To tackle these challenges, we propose an Application Context-aware Cross-layer Optimization and Resource Design (ACCORD) framework. This innovative framework anticipates the evolving demands of MCAs in real time, quickly adapting to provide customized QoS and optimal performance, even for the most dynamic and unpredictable MCAs. This also leads to improved network resource management and spectrum utilization. ACCORD operates as a closed feedback-loop system between the application client and network and consists of two key components: (1) Building Application Context: It focuses on understanding the specific context of MCA requirements. Contextual factors include device capabilities, user behavior (e.g., mobility speed), and network channel conditions. (2) Cross-layer Network Parameter Configuration: Utilizing a DRL approach, this component leverages the contextual information to optimize network configuration parameters across various layers, including PHY, MAC, and RLC, as well as the application layer, to meet the desired QoS requirement in real-time. Extensive evaluation with the 3GPP-compliant MATLAB 5G toolbox demonstrates the practicality and effectiveness of our proposed ACCORD framework.","sentences":["Recent advancements in AI and edge computing have accelerated the development of machine-centric applications (MCAs), such as smart surveillance systems.","In these applications, video cameras and sensors offload inference tasks like license plate recognition and vehicle tracking to remote servers due to local computing and energy constraints.","However, legacy network solutions, designed primarily for human-centric applications, struggle to reliably support these MCAs, which demand heterogeneous and fluctuating QoS (due to diverse application inference tasks), further challenged by dynamic wireless network conditions and limited spectrum resources.","To tackle these challenges, we propose an Application Context-aware Cross-layer Optimization and Resource Design (ACCORD) framework.","This innovative framework anticipates the evolving demands of MCAs in real time, quickly adapting to provide customized QoS and optimal performance, even for the most dynamic and unpredictable MCAs.","This also leads to improved network resource management and spectrum utilization.","ACCORD operates as a closed feedback-loop system between the application client and network and consists of two key components: (1) Building Application Context: It focuses on understanding the specific context of MCA requirements.","Contextual factors include device capabilities, user behavior (e.g., mobility speed), and network channel conditions.","(2) Cross-layer Network Parameter Configuration: Utilizing a DRL approach, this component leverages the contextual information to optimize network configuration parameters across various layers, including PHY, MAC, and RLC, as well as the application layer, to meet the desired QoS requirement in real-time.","Extensive evaluation with the 3GPP-compliant MATLAB 5G toolbox demonstrates the practicality and effectiveness of our proposed ACCORD framework."],"url":"http://arxiv.org/abs/2502.20320v1"}
{"created":"2025-02-27 17:42:52","title":"Mixture of Structural-and-Textual Retrieval over Text-rich Graph Knowledge Bases","abstract":"Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge. However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation. To fill in this gap, we propose a Mixture of Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge via a Planning-Reasoning-Organizing framework. In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries. Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs. In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory. Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking. Our code is available at https://github.com/Yoega/MoR.","sentences":["Text-rich Graph Knowledge Bases (TG-KBs) have become increasingly crucial for answering queries by providing textual and structural knowledge.","However, current retrieval methods often retrieve these two types of knowledge in isolation without considering their mutual reinforcement and some hybrid methods even bypass structural retrieval entirely after neighboring aggregation.","To fill in this gap, we propose a Mixture of Structural-and-Textual Retrieval (MoR) to retrieve these two types of knowledge via a Planning-Reasoning-Organizing framework.","In the Planning stage, MoR generates textual planning graphs delineating the logic for answering queries.","Following planning graphs, in the Reasoning stage, MoR interweaves structural traversal and textual matching to obtain candidates from TG-KBs.","In the Organizing stage, MoR further reranks fetched candidates based on their structural trajectory.","Extensive experiments demonstrate the superiority of MoR in harmonizing structural and textual retrieval with insights, including uneven retrieving performance across different query logics and the benefits of integrating structural trajectories for candidate reranking.","Our code is available at https://github.com/Yoega/MoR."],"url":"http://arxiv.org/abs/2502.20317v1"}
{"created":"2025-02-27 17:42:47","title":"Multi-Scale Neighborhood Occupancy Masked Autoencoder for Self-Supervised Learning in LiDAR Point Clouds","abstract":"Masked autoencoders (MAE) have shown tremendous potential for self-supervised learning (SSL) in vision and beyond. However, point clouds from LiDARs used in automated driving are particularly challenging for MAEs since large areas of the 3D volume are empty. Consequently, existing work suffers from leaking occupancy information into the decoder and has significant computational complexity, thereby limiting the SSL pre-training to only 2D bird's eye view encoders in practice. In this work, we propose the novel neighborhood occupancy MAE (NOMAE) that overcomes the aforementioned challenges by employing masked occupancy reconstruction only in the neighborhood of non-masked voxels. We incorporate voxel masking and occupancy reconstruction at multiple scales with our proposed hierarchical mask generation technique to capture features of objects of different sizes in the point cloud. NOMAEs are extremely flexible and can be directly employed for SSL in existing 3D architectures. We perform extensive evaluations on the nuScenes and Waymo Open datasets for the downstream perception tasks of semantic segmentation and 3D object detection, comparing with both discriminative and generative SSL methods. The results demonstrate that NOMAE sets the new state-of-the-art on multiple benchmarks for multiple point cloud perception tasks.","sentences":["Masked autoencoders (MAE) have shown tremendous potential for self-supervised learning (SSL) in vision and beyond.","However, point clouds from LiDARs used in automated driving are particularly challenging for MAEs since large areas of the 3D volume are empty.","Consequently, existing work suffers from leaking occupancy information into the decoder and has significant computational complexity, thereby limiting the SSL pre-training to only 2D bird's eye view encoders in practice.","In this work, we propose the novel neighborhood occupancy MAE (NOMAE) that overcomes the aforementioned challenges by employing masked occupancy reconstruction only in the neighborhood of non-masked voxels.","We incorporate voxel masking and occupancy reconstruction at multiple scales with our proposed hierarchical mask generation technique to capture features of objects of different sizes in the point cloud.","NOMAEs are extremely flexible and can be directly employed for SSL in existing 3D architectures.","We perform extensive evaluations on the nuScenes and Waymo Open datasets for the downstream perception tasks of semantic segmentation and 3D object detection, comparing with both discriminative and generative SSL methods.","The results demonstrate that NOMAE sets the new state-of-the-art on multiple benchmarks for multiple point cloud perception tasks."],"url":"http://arxiv.org/abs/2502.20316v1"}
{"created":"2025-02-27 17:41:49","title":"LangProBe: a Language Programs Benchmark","abstract":"Composing language models (LMs) into multi-step language programs and automatically optimizing their modular prompts is now a mainstream paradigm for building AI systems, but the tradeoffs in this space have only scarcely been studied before. We introduce LangProBe, the first large-scale benchmark for evaluating the architectures and optimization strategies for language programs, with over 2000 combinations of tasks, architectures, optimizers, and choices of LMs. Using LangProBe, we are the first to study the impact of program architectures and optimizers (and their compositions together and with different models) on tradeoffs of quality and cost. We find that optimized language programs offer strong cost--quality Pareto improvement over raw calls to models, but simultaneously demonstrate that human judgment (or empirical decisions) about which compositions to pursue is still necessary for best performance. We will open source the code and evaluation data for LangProBe.","sentences":["Composing language models (LMs) into multi-step language programs and automatically optimizing their modular prompts is now a mainstream paradigm for building AI systems, but the tradeoffs in this space have only scarcely been studied before.","We introduce LangProBe, the first large-scale benchmark for evaluating the architectures and optimization strategies for language programs, with over 2000 combinations of tasks, architectures, optimizers, and choices of LMs.","Using LangProBe, we are the first to study the impact of program architectures and optimizers (and their compositions together and with different models) on tradeoffs of quality and cost.","We find that optimized language programs offer strong cost--quality Pareto improvement over raw calls to models, but simultaneously demonstrate that human judgment (or empirical decisions) about which compositions to pursue is still necessary for best performance.","We will open source the code and evaluation data for LangProBe."],"url":"http://arxiv.org/abs/2502.20315v1"}
{"created":"2025-02-27 17:41:36","title":"Adversarial Robustness in Parameter-Space Classifiers","abstract":"Implicit Neural Representations (INRs) have been recently garnering increasing interest in various research fields, mainly due to their ability to represent large, complex data in a compact and continuous manner. Past work further showed that numerous popular downstream tasks can be performed directly in the INR parameter-space. Doing so can substantially reduce the computational resources required to process the represented data in their native domain. A major difficulty in using modern machine-learning approaches, is their high susceptibility to adversarial attacks, which have been shown to greatly limit the reliability and applicability of such methods in a wide range of settings. In this work, we show that parameter-space models trained for classification are inherently robust to adversarial attacks -- without the need of any robust training. To support our claims, we develop a novel suite of adversarial attacks targeting parameter-space classifiers, and furthermore analyze practical considerations of attacking parameter-space classifiers. Code for reproducing all experiments and implementation of all proposed methods will be released upon publication.","sentences":["Implicit Neural Representations (INRs) have been recently garnering increasing interest in various research fields, mainly due to their ability to represent large, complex data in a compact and continuous manner.","Past work further showed that numerous popular downstream tasks can be performed directly in the INR parameter-space.","Doing so can substantially reduce the computational resources required to process the represented data in their native domain.","A major difficulty in using modern machine-learning approaches, is their high susceptibility to adversarial attacks, which have been shown to greatly limit the reliability and applicability of such methods in a wide range of settings.","In this work, we show that parameter-space models trained for classification are inherently robust to adversarial attacks -- without the need of any robust training.","To support our claims, we develop a novel suite of adversarial attacks targeting parameter-space classifiers, and furthermore analyze practical considerations of attacking parameter-space classifiers.","Code for reproducing all experiments and implementation of all proposed methods will be released upon publication."],"url":"http://arxiv.org/abs/2502.20314v1"}
{"created":"2025-02-27 17:39:17","title":"FlexVAR: Flexible Visual Autoregressive Modeling without Residual Prediction","abstract":"This work challenges the residual prediction paradigm in visual autoregressive modeling and presents FlexVAR, a new Flexible Visual AutoRegressive image generation paradigm. FlexVAR facilitates autoregressive learning with ground-truth prediction, enabling each step to independently produce plausible images. This simple, intuitive approach swiftly learns visual distributions and makes the generation process more flexible and adaptable. Trained solely on low-resolution images ($\\leq$ 256px), FlexVAR can: (1) Generate images of various resolutions and aspect ratios, even exceeding the resolution of the training images. (2) Support various image-to-image tasks, including image refinement, in/out-painting, and image expansion. (3) Adapt to various autoregressive steps, allowing for faster inference with fewer steps or enhancing image quality with more steps. Our 1.0B model outperforms its VAR counterpart on the ImageNet 256$\\times$256 benchmark. Moreover, when zero-shot transfer the image generation process with 13 steps, the performance further improves to 2.08 FID, outperforming state-of-the-art autoregressive models AiM/VAR by 0.25/0.28 FID and popular diffusion models LDM/DiT by 1.52/0.19 FID, respectively. When transferring our 1.0B model to the ImageNet 512$\\times$512 benchmark in a zero-shot manner, FlexVAR achieves competitive results compared to the VAR 2.3B model, which is a fully supervised model trained at 512$\\times$512 resolution.","sentences":["This work challenges the residual prediction paradigm in visual autoregressive modeling and presents FlexVAR, a new Flexible Visual AutoRegressive image generation paradigm.","FlexVAR facilitates autoregressive learning with ground-truth prediction, enabling each step to independently produce plausible images.","This simple, intuitive approach swiftly learns visual distributions and makes the generation process more flexible and adaptable.","Trained solely on low-resolution images ($\\leq$ 256px), FlexVAR can: (1) Generate images of various resolutions and aspect ratios, even exceeding the resolution of the training images.","(2) Support various image-to-image tasks, including image refinement, in/out-painting, and image expansion.","(3) Adapt to various autoregressive steps, allowing for faster inference with fewer steps or enhancing image quality with more steps.","Our 1.0B model outperforms its VAR counterpart on the ImageNet 256$\\times$256 benchmark.","Moreover, when zero-shot transfer the image generation process with 13 steps, the performance further improves to 2.08 FID, outperforming state-of-the-art autoregressive models AiM/VAR by 0.25/0.28 FID and popular diffusion models LDM/DiT by 1.52/0.19 FID, respectively.","When transferring our 1.0B model to the ImageNet 512$\\times$512 benchmark in a zero-shot manner, FlexVAR achieves competitive results compared to the VAR 2.3B model, which is a fully supervised model trained at 512$\\times$512 resolution."],"url":"http://arxiv.org/abs/2502.20313v1"}
{"created":"2025-02-27 17:35:59","title":"Adapting Automatic Speech Recognition for Accented Air Traffic Control Communications","abstract":"Effective communication in Air Traffic Control (ATC) is critical to maintaining aviation safety, yet the challenges posed by accented English remain largely unaddressed in Automatic Speech Recognition (ASR) systems. Existing models struggle with transcription accuracy for Southeast Asian-accented (SEA-accented) speech, particularly in noisy ATC environments. This study presents the development of ASR models fine-tuned specifically for Southeast Asian accents using a newly created dataset. Our research achieves significant improvements, achieving a Word Error Rate (WER) of 0.0982 or 9.82% on SEA-accented ATC speech. Additionally, the paper highlights the importance of region-specific datasets and accent-focused training, offering a pathway for deploying ASR systems in resource-constrained military operations. The findings emphasize the need for noise-robust training techniques and region-specific datasets to improve transcription accuracy for non-Western accents in ATC communications.","sentences":["Effective communication in Air Traffic Control (ATC) is critical to maintaining aviation safety, yet the challenges posed by accented English remain largely unaddressed in Automatic Speech Recognition (ASR) systems.","Existing models struggle with transcription accuracy for Southeast Asian-accented (SEA-accented) speech, particularly in noisy ATC environments.","This study presents the development of ASR models fine-tuned specifically for Southeast Asian accents using a newly created dataset.","Our research achieves significant improvements, achieving a Word Error Rate (WER) of 0.0982 or 9.82% on SEA-accented ATC speech.","Additionally, the paper highlights the importance of region-specific datasets and accent-focused training, offering a pathway for deploying ASR systems in resource-constrained military operations.","The findings emphasize the need for noise-robust training techniques and region-specific datasets to improve transcription accuracy for non-Western accents in ATC communications."],"url":"http://arxiv.org/abs/2502.20311v1"}
{"created":"2025-02-27 17:35:57","title":"EAIRA: Establishing a Methodology for Evaluating AI Models as Scientific Research Assistants","abstract":"Recent advancements have positioned AI, and particularly Large Language Models (LLMs), as transformative tools for scientific research, capable of addressing complex tasks that require reasoning, problem-solving, and decision-making. Their exceptional capabilities suggest their potential as scientific research assistants but also highlight the need for holistic, rigorous, and domain-specific evaluation to assess effectiveness in real-world scientific applications. This paper describes a multifaceted methodology for Evaluating AI models as scientific Research Assistants (EAIRA) developed at Argonne National Laboratory. This methodology incorporates four primary classes of evaluations. 1) Multiple Choice Questions to assess factual recall; 2) Open Response to evaluate advanced reasoning and problem-solving skills; 3) Lab-Style Experiments involving detailed analysis of capabilities as research assistants in controlled environments; and 4) Field-Style Experiments to capture researcher-LLM interactions at scale in a wide range of scientific domains and applications. These complementary methods enable a comprehensive analysis of LLM strengths and weaknesses with respect to their scientific knowledge, reasoning abilities, and adaptability. Recognizing the rapid pace of LLM advancements, we designed the methodology to evolve and adapt so as to ensure its continued relevance and applicability. This paper describes the methodology state at the end of February 2025. Although developed within a subset of scientific domains, the methodology is designed to be generalizable to a wide range of scientific domains.","sentences":["Recent advancements have positioned AI, and particularly Large Language Models (LLMs), as transformative tools for scientific research, capable of addressing complex tasks that require reasoning, problem-solving, and decision-making.","Their exceptional capabilities suggest their potential as scientific research assistants but also highlight the need for holistic, rigorous, and domain-specific evaluation to assess effectiveness in real-world scientific applications.","This paper describes a multifaceted methodology for Evaluating AI models as scientific Research Assistants (EAIRA) developed at Argonne National Laboratory.","This methodology incorporates four primary classes of evaluations.","1) Multiple Choice Questions to assess factual recall; 2) Open Response to evaluate advanced reasoning and problem-solving skills; 3) Lab-Style Experiments involving detailed analysis of capabilities as research assistants in controlled environments; and 4) Field-Style Experiments to capture researcher-LLM interactions at scale in a wide range of scientific domains and applications.","These complementary methods enable a comprehensive analysis of LLM strengths and weaknesses with respect to their scientific knowledge, reasoning abilities, and adaptability.","Recognizing the rapid pace of LLM advancements, we designed the methodology to evolve and adapt so as to ensure its continued relevance and applicability.","This paper describes the methodology state at the end of February 2025.","Although developed within a subset of scientific domains, the methodology is designed to be generalizable to a wide range of scientific domains."],"url":"http://arxiv.org/abs/2502.20309v1"}
{"created":"2025-02-27 17:33:51","title":"Mobius: Text to Seamless Looping Video Generation via Latent Shift","abstract":"We present Mobius, a novel method to generate seamlessly looping videos from text descriptions directly without any user annotations, thereby creating new visual materials for the multi-media presentation. Our method repurposes the pre-trained video latent diffusion model for generating looping videos from text prompts without any training. During inference, we first construct a latent cycle by connecting the starting and ending noise of the videos. Given that the temporal consistency can be maintained by the context of the video diffusion model, we perform multi-frame latent denoising by gradually shifting the first-frame latent to the end in each step. As a result, the denoising context varies in each step while maintaining consistency throughout the inference process. Moreover, the latent cycle in our method can be of any length. This extends our latent-shifting approach to generate seamless looping videos beyond the scope of the video diffusion model's context. Unlike previous cinemagraphs, the proposed method does not require an image as appearance, which will restrict the motions of the generated results. Instead, our method can produce more dynamic motion and better visual quality. We conduct multiple experiments and comparisons to verify the effectiveness of the proposed method, demonstrating its efficacy in different scenarios. All the code will be made available.","sentences":["We present Mobius, a novel method to generate seamlessly looping videos from text descriptions directly without any user annotations, thereby creating new visual materials for the multi-media presentation.","Our method repurposes the pre-trained video latent diffusion model for generating looping videos from text prompts without any training.","During inference, we first construct a latent cycle by connecting the starting and ending noise of the videos.","Given that the temporal consistency can be maintained by the context of the video diffusion model, we perform multi-frame latent denoising by gradually shifting the first-frame latent to the end in each step.","As a result, the denoising context varies in each step while maintaining consistency throughout the inference process.","Moreover, the latent cycle in our method can be of any length.","This extends our latent-shifting approach to generate seamless looping videos beyond the scope of the video diffusion model's context.","Unlike previous cinemagraphs, the proposed method does not require an image as appearance, which will restrict the motions of the generated results.","Instead, our method can produce more dynamic motion and better visual quality.","We conduct multiple experiments and comparisons to verify the effectiveness of the proposed method, demonstrating its efficacy in different scenarios.","All the code will be made available."],"url":"http://arxiv.org/abs/2502.20307v1"}
{"created":"2025-02-27 17:33:49","title":"SecureGaze: Defending Gaze Estimation Against Backdoor Attacks","abstract":"Gaze estimation models are widely used in applications such as driver attention monitoring and human-computer interaction. While many methods for gaze estimation exist, they rely heavily on data-hungry deep learning to achieve high performance. This reliance often forces practitioners to harvest training data from unverified public datasets, outsource model training, or rely on pre-trained models. However, such practices expose gaze estimation models to backdoor attacks. In such attacks, adversaries inject backdoor triggers by poisoning the training data, creating a backdoor vulnerability: the model performs normally with benign inputs, but produces manipulated gaze directions when a specific trigger is present. This compromises the security of many gaze-based applications, such as causing the model to fail in tracking the driver's attention. To date, there is no defense that addresses backdoor attacks on gaze estimation models. In response, we introduce SecureGaze, the first solution designed to protect gaze estimation models from such attacks. Unlike classification models, defending gaze estimation poses unique challenges due to its continuous output space and globally activated backdoor behavior. By identifying distinctive characteristics of backdoored gaze estimation models, we develop a novel and effective approach to reverse-engineer the trigger function for reliable backdoor detection. Extensive evaluations in both digital and physical worlds demonstrate that SecureGaze effectively counters a range of backdoor attacks and outperforms seven state-of-the-art defenses adapted from classification models.","sentences":["Gaze estimation models are widely used in applications such as driver attention monitoring and human-computer interaction.","While many methods for gaze estimation exist, they rely heavily on data-hungry deep learning to achieve high performance.","This reliance often forces practitioners to harvest training data from unverified public datasets, outsource model training, or rely on pre-trained models.","However, such practices expose gaze estimation models to backdoor attacks.","In such attacks, adversaries inject backdoor triggers by poisoning the training data, creating a backdoor vulnerability: the model performs normally with benign inputs, but produces manipulated gaze directions when a specific trigger is present.","This compromises the security of many gaze-based applications, such as causing the model to fail in tracking the driver's attention.","To date, there is no defense that addresses backdoor attacks on gaze estimation models.","In response, we introduce SecureGaze, the first solution designed to protect gaze estimation models from such attacks.","Unlike classification models, defending gaze estimation poses unique challenges due to its continuous output space and globally activated backdoor behavior.","By identifying distinctive characteristics of backdoored gaze estimation models, we develop a novel and effective approach to reverse-engineer the trigger function for reliable backdoor detection.","Extensive evaluations in both digital and physical worlds demonstrate that SecureGaze effectively counters a range of backdoor attacks and outperforms seven state-of-the-art defenses adapted from classification models."],"url":"http://arxiv.org/abs/2502.20306v1"}
{"created":"2025-02-27 17:29:46","title":"M^3Builder: A Multi-Agent System for Automated Machine Learning in Medical Imaging","abstract":"Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks. However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models. In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging. At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training. These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution. (ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data. (iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging.","sentences":["Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks.","However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models.","In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging.","At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training.","These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution.","(ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data.","(iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3.","Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging."],"url":"http://arxiv.org/abs/2502.20301v1"}
{"created":"2025-02-27 17:26:56","title":"An exploration of features to improve the generalisability of fake news detection models","abstract":"Fake news poses global risks by influencing elections and spreading misinformation, making detection critical. Existing NLP and supervised Machine Learning methods perform well under cross-validation but struggle to generalise across datasets, even within the same domain. This issue stems from coarsely labelled training data, where articles are labelled based on their publisher, introducing biases that token-based models like TF-IDF and BERT are sensitive to. While Large Language Models (LLMs) offer promise, their application in fake news detection remains limited. This study demonstrates that meaningful features can still be extracted from coarsely labelled data to improve real-world robustness. Stylistic features-lexical, syntactic, and semantic-are explored due to their reduced sensitivity to dataset biases. Additionally, novel social-monetisation features are introduced, capturing economic incentives behind fake news, such as advertisements, external links, and social media elements. The study trains on the coarsely labelled NELA 2020-21 dataset and evaluates using the manually labelled Facebook URLs dataset, a gold standard for generalisability. Results highlight the limitations of token-based models trained on biased data and contribute to the scarce evidence on LLMs like LLaMa in this field. Findings indicate that stylistic and social-monetisation features offer more generalisable predictions than token-based methods and LLMs. Statistical and permutation feature importance analyses further reveal their potential to enhance performance and mitigate dataset biases, providing a path forward for improving fake news detection.","sentences":["Fake news poses global risks by influencing elections and spreading misinformation, making detection critical.","Existing NLP and supervised Machine Learning methods perform well under cross-validation but struggle to generalise across datasets, even within the same domain.","This issue stems from coarsely labelled training data, where articles are labelled based on their publisher, introducing biases that token-based models like TF-IDF and BERT are sensitive to.","While Large Language Models (LLMs) offer promise, their application in fake news detection remains limited.","This study demonstrates that meaningful features can still be extracted from coarsely labelled data to improve real-world robustness.","Stylistic features-lexical, syntactic, and semantic-are explored due to their reduced sensitivity to dataset biases.","Additionally, novel social-monetisation features are introduced, capturing economic incentives behind fake news, such as advertisements, external links, and social media elements.","The study trains on the coarsely labelled NELA 2020-21 dataset and evaluates using the manually labelled Facebook URLs dataset, a gold standard for generalisability.","Results highlight the limitations of token-based models trained on biased data and contribute to the scarce evidence on LLMs like LLaMa in this field.","Findings indicate that stylistic and social-monetisation features offer more generalisable predictions than token-based methods and LLMs.","Statistical and permutation feature importance analyses further reveal their potential to enhance performance and mitigate dataset biases, providing a path forward for improving fake news detection."],"url":"http://arxiv.org/abs/2502.20299v1"}
{"created":"2025-02-27 17:21:18","title":"Judge a Book by its Cover: Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription","abstract":"Handwritten text recognition (HTR) remains a challenging task, particularly for multi-page documents where pages share common formatting and contextual features. While modern optical character recognition (OCR) engines are proficient with printed text, their performance on handwriting is limited, often requiring costly labeled data for fine-tuning. In this paper, we explore the use of multi-modal large language models (MLLMs) for transcribing multi-page handwritten documents in a zero-shot setting. We investigate various configurations of commercial OCR engines and MLLMs, utilizing the latter both as end-to-end transcribers and as post-processors, with and without image components. We propose a novel method, '+first page', which enhances MLLM transcription by providing the OCR output of the entire document along with just the first page image. This approach leverages shared document features without incurring the high cost of processing all images. Experiments on a multi-page version of the IAM Handwriting Database demonstrate that '+first page' improves transcription accuracy, balances cost with performance, and even enhances results on out-of-sample text by extrapolating formatting and OCR error patterns from a single page.","sentences":["Handwritten text recognition (HTR) remains a challenging task, particularly for multi-page documents where pages share common formatting and contextual features.","While modern optical character recognition (OCR) engines are proficient with printed text, their performance on handwriting is limited, often requiring costly labeled data for fine-tuning.","In this paper, we explore the use of multi-modal large language models (MLLMs) for transcribing multi-page handwritten documents in a zero-shot setting.","We investigate various configurations of commercial OCR engines and MLLMs, utilizing the latter both as end-to-end transcribers and as post-processors, with and without image components.","We propose a novel method, '+first page', which enhances MLLM transcription by providing the OCR output of the entire document along with just the first page image.","This approach leverages shared document features without incurring the high cost of processing all images.","Experiments on a multi-page version of the IAM Handwriting Database demonstrate that '+first page' improves transcription accuracy, balances cost with performance, and even enhances results on out-of-sample text by extrapolating formatting and OCR error patterns from a single page."],"url":"http://arxiv.org/abs/2502.20295v1"}
{"created":"2025-02-27 17:17:53","title":"Scalable Graph Attention-based Instance Selection via Mini-Batch Sampling and Hierarchical Hashing","abstract":"Instance selection (IS) is important in machine learning for reducing dataset size while keeping key characteristics. Current IS methods often struggle with capturing complex relationships in high-dimensional spaces and scale with large datasets. This paper introduces a graph attention-based instance selection (GAIS) method that uses attention mechanisms to identify informative instances through their structural relationships in graph representations. We present two approaches for scalable graph construction: a distance-based mini-batch sampling technique that reduces computation through strategic batch processing, and a hierarchical hashing approach that allows for efficient similarity computation through random projections. The mini-batch approach keeps class distributions through stratified sampling, while the hierarchical hashing method captures relationships at multiple granularities through single-level, multi-level, and multi-view variants. Experiments across 39 datasets show that GAIS achieves reduction rates above 96\\% while maintaining or improving model performance relative to state-of-the-art IS methods. The findings shows that the distance-based mini-batch approach offers an optimal balance of efficiency and effectiveness for large-scale datasets, while multi-view variants provide superior performance for complex, high-dimensional data, demonstrating that attention-based importance scoring can effectively identify instances crucial for maintaining decision boundaries without requiring exhaustive pairwise comparisons.","sentences":["Instance selection (IS) is important in machine learning for reducing dataset size while keeping key characteristics.","Current IS methods often struggle with capturing complex relationships in high-dimensional spaces and scale with large datasets.","This paper introduces a graph attention-based instance selection (GAIS) method that uses attention mechanisms to identify informative instances through their structural relationships in graph representations.","We present two approaches for scalable graph construction: a distance-based mini-batch sampling technique that reduces computation through strategic batch processing, and a hierarchical hashing approach that allows for efficient similarity computation through random projections.","The mini-batch approach keeps class distributions through stratified sampling, while the hierarchical hashing method captures relationships at multiple granularities through single-level, multi-level, and multi-view variants.","Experiments across 39 datasets show that GAIS achieves reduction rates above 96\\% while maintaining or improving model performance relative to state-of-the-art IS methods.","The findings shows that the distance-based mini-batch approach offers an optimal balance of efficiency and effectiveness for large-scale datasets, while multi-view variants provide superior performance for complex, high-dimensional data, demonstrating that attention-based importance scoring can effectively identify instances crucial for maintaining decision boundaries without requiring exhaustive pairwise comparisons."],"url":"http://arxiv.org/abs/2502.20293v1"}
{"created":"2025-02-27 17:17:43","title":"Visual Adaptive Prompting for Compositional Zero-Shot Learning","abstract":"Vision-Language Models (VLMs) have demonstrated impressive capabilities in learning joint representations of visual and textual data, making them powerful tools for tasks such as Compositional Zero-Shot Learning (CZSL). CZSL requires models to generalize to novel combinations of visual primitives-such as attributes and objects-that were not explicitly encountered during training. Recent works in prompting for CZSL have focused on modifying inputs for the text encoder, often using static prompts that do not change across varying visual contexts. However, these approaches struggle to fully capture varying visual contexts, as they focus on text adaptation rather than leveraging visual features for compositional reasoning. To address this, we propose Visual Adaptive Prompting System (VAPS) that leverages a learnable visual prompt repository and similarity-based retrieval mechanism within the framework of VLMs to bridge the gap between semantic and visual features. Our method introduces a dynamic visual prompt repository mechanism that selects the most relevant attribute and object prompts based on the visual features of the image. Our proposed system includes a visual prompt adapter that encourages the model to learn a more generalizable embedding space. Experiments on three CZSL benchmarks, across both closed and open-world scenarios, demonstrate state-of-the-art results.","sentences":["Vision-Language Models (VLMs) have demonstrated impressive capabilities in learning joint representations of visual and textual data, making them powerful tools for tasks such as Compositional Zero-Shot Learning (CZSL).","CZSL requires models to generalize to novel combinations of visual primitives-such as attributes and objects-that were not explicitly encountered during training.","Recent works in prompting for CZSL have focused on modifying inputs for the text encoder, often using static prompts that do not change across varying visual contexts.","However, these approaches struggle to fully capture varying visual contexts, as they focus on text adaptation rather than leveraging visual features for compositional reasoning.","To address this, we propose Visual Adaptive Prompting System (VAPS) that leverages a learnable visual prompt repository and similarity-based retrieval mechanism within the framework of VLMs to bridge the gap between semantic and visual features.","Our method introduces a dynamic visual prompt repository mechanism that selects the most relevant attribute and object prompts based on the visual features of the image.","Our proposed system includes a visual prompt adapter that encourages the model to learn a more generalizable embedding space.","Experiments on three CZSL benchmarks, across both closed and open-world scenarios, demonstrate state-of-the-art results."],"url":"http://arxiv.org/abs/2502.20292v1"}
{"created":"2025-02-27 17:15:23","title":"Gender Dynamics in Software Engineering: Insights from Research on Concurrency Bug Reproduction","abstract":"Reproducing concurrency bugs is a complex task due to their unpredictable behavior. Researchers, regardless of gender, are contributing to automating this complex task to aid software developers. While some studies have investigated gender roles in the broader software industry, limited research exists on gender representation specifically among researchers working in concurrent bug reproduction. To address this gap, in this paper, we present a literature review to assess the gender ratio in this field. We also explore potential variations in technique selection and bug-type focus across genders. Our findings indicate that female researchers are underrepresented compared to their male counterparts in this area, with a current male-to-female author ratio of 29:6. Through this study, we emphasize the importance of fostering gender equity in software engineering research, ensuring a diversity of perspectives in the development of automated bug reproduction tools.","sentences":["Reproducing concurrency bugs is a complex task due to their unpredictable behavior.","Researchers, regardless of gender, are contributing to automating this complex task to aid software developers.","While some studies have investigated gender roles in the broader software industry, limited research exists on gender representation specifically among researchers working in concurrent bug reproduction.","To address this gap, in this paper, we present a literature review to assess the gender ratio in this field.","We also explore potential variations in technique selection and bug-type focus across genders.","Our findings indicate that female researchers are underrepresented compared to their male counterparts in this area, with a current male-to-female author ratio of 29:6.","Through this study, we emphasize the importance of fostering gender equity in software engineering research, ensuring a diversity of perspectives in the development of automated bug reproduction tools."],"url":"http://arxiv.org/abs/2502.20289v1"}
{"created":"2025-02-27 17:10:54","title":"Conformal Tail Risk Control for Large Language Model Alignment","abstract":"Recent developments in large language models (LLMs) have led to their widespread usage for various tasks. The prevalence of LLMs in society implores the assurance on the reliability of their performance. In particular, risk-sensitive applications demand meticulous attention to unexpectedly poor outcomes, i.e., tail events, for instance, toxic answers, humiliating language, and offensive outputs. Due to the costly nature of acquiring human annotations, general-purpose scoring models have been created to automate the process of quantifying these tail events. This phenomenon introduces potential human-machine misalignment between the respective scoring mechanisms. In this work, we present a lightweight calibration framework for blackbox models that ensures the alignment of humans and machines with provable guarantees. Our framework provides a rigorous approach to controlling any distortion risk measure that is characterized by a weighted average of quantiles of the loss incurred by the LLM with high confidence. The theoretical foundation of our method relies on the connection between conformal risk control and a traditional family of statistics, i.e., L-statistics. To demonstrate the utility of our framework, we conduct comprehensive experiments that address the issue of human-machine misalignment.","sentences":["Recent developments in large language models (LLMs) have led to their widespread usage for various tasks.","The prevalence of LLMs in society implores the assurance on the reliability of their performance.","In particular, risk-sensitive applications demand meticulous attention to unexpectedly poor outcomes, i.e., tail events, for instance, toxic answers, humiliating language, and offensive outputs.","Due to the costly nature of acquiring human annotations, general-purpose scoring models have been created to automate the process of quantifying these tail events.","This phenomenon introduces potential human-machine misalignment between the respective scoring mechanisms.","In this work, we present a lightweight calibration framework for blackbox models that ensures the alignment of humans and machines with provable guarantees.","Our framework provides a rigorous approach to controlling any distortion risk measure that is characterized by a weighted average of quantiles of the loss incurred by the LLM with high confidence.","The theoretical foundation of our method relies on the connection between conformal risk control and a traditional family of statistics, i.e., L-statistics.","To demonstrate the utility of our framework, we conduct comprehensive experiments that address the issue of human-machine misalignment."],"url":"http://arxiv.org/abs/2502.20285v1"}
{"created":"2025-02-27 17:10:52","title":"Evaluating Human Trust in LLM-Based Planners: A Preliminary Study","abstract":"Large Language Models (LLMs) are increasingly used for planning tasks, offering unique capabilities not found in classical planners such as generating explanations and iterative refinement. However, trust--a critical factor in the adoption of planning systems--remains underexplored in the context of LLM-based planning tasks. This study bridges this gap by comparing human trust in LLM-based planners with classical planners through a user study in a Planning Domain Definition Language (PDDL) domain. Combining subjective measures, such as trust questionnaires, with objective metrics like evaluation accuracy, our findings reveal that correctness is the primary driver of trust and performance. Explanations provided by the LLM improved evaluation accuracy but had limited impact on trust, while plan refinement showed potential for increasing trust without significantly enhancing evaluation accuracy.","sentences":["Large Language Models (LLMs) are increasingly used for planning tasks, offering unique capabilities not found in classical planners such as generating explanations and iterative refinement.","However, trust--a critical factor in the adoption of planning systems--remains underexplored in the context of LLM-based planning tasks.","This study bridges this gap by comparing human trust in LLM-based planners with classical planners through a user study in a Planning Domain Definition Language (PDDL) domain.","Combining subjective measures, such as trust questionnaires, with objective metrics like evaluation accuracy, our findings reveal that correctness is the primary driver of trust and performance.","Explanations provided by the LLM improved evaluation accuracy but had limited impact on trust, while plan refinement showed potential for increasing trust without significantly enhancing evaluation accuracy."],"url":"http://arxiv.org/abs/2502.20284v1"}
{"created":"2025-02-27 17:07:32","title":"Online Meta-learning for AutoML in Real-time (OnMAR)","abstract":"Automated machine learning (AutoML) is a research area focusing on using optimisation techniques to design machine learning (ML) algorithms, alleviating the need for a human to perform manual algorithm design. Real-time AutoML enables the design process to happen while the ML algorithm is being applied to a task. Real-time AutoML is an emerging research area, as such existing real-time AutoML techniques need improvement with respect to the quality of designs and time taken to create designs. To address these issues, this study proposes an Online Meta-learning for AutoML in Real-time (OnMAR) approach. Meta-learning gathers information about the optimisation process undertaken by the ML algorithm in the form of meta-features. Meta-features are used in conjunction with a meta-learner to optimise the optimisation process. The OnMAR approach uses a meta-learner to predict the accuracy of an ML design. If the accuracy predicted by the meta-learner is sufficient, the design is used, and if the predicted accuracy is low, an optimisation technique creates a new design. A genetic algorithm (GA) is the optimisation technique used as part of the OnMAR approach. Different meta-learners (k-nearest neighbours, random forest and XGBoost) are tested. The OnMAR approach is model-agnostic (i.e. not specific to a single real-time AutoML application) and therefore evaluated on three different real-time AutoML applications, namely: composing an image clustering algorithm, configuring the hyper-parameters of a convolutional neural network, and configuring a video classification pipeline. The OnMAR approach is effective, matching or outperforming existing real-time AutoML approaches, with the added benefit of a faster runtime.","sentences":["Automated machine learning (AutoML) is a research area focusing on using optimisation techniques to design machine learning (ML) algorithms, alleviating the need for a human to perform manual algorithm design.","Real-time AutoML enables the design process to happen while the ML algorithm is being applied to a task.","Real-time AutoML is an emerging research area, as such existing real-time AutoML techniques need improvement with respect to the quality of designs and time taken to create designs.","To address these issues, this study proposes an Online Meta-learning for AutoML in Real-time (OnMAR) approach.","Meta-learning gathers information about the optimisation process undertaken by the ML algorithm in the form of meta-features.","Meta-features are used in conjunction with a meta-learner to optimise the optimisation process.","The OnMAR approach uses a meta-learner to predict the accuracy of an ML design.","If the accuracy predicted by the meta-learner is sufficient, the design is used, and if the predicted accuracy is low, an optimisation technique creates a new design.","A genetic algorithm (GA) is the optimisation technique used as part of the OnMAR approach.","Different meta-learners (k-nearest neighbours, random forest and XGBoost) are tested.","The OnMAR approach is model-agnostic (i.e. not specific to a single real-time AutoML application) and therefore evaluated on three different real-time AutoML applications, namely: composing an image clustering algorithm, configuring the hyper-parameters of a convolutional neural network, and configuring a video classification pipeline.","The OnMAR approach is effective, matching or outperforming existing real-time AutoML approaches, with the added benefit of a faster runtime."],"url":"http://arxiv.org/abs/2502.20279v1"}
{"created":"2025-02-27 17:04:00","title":"Explainable, Multi-modal Wound Infection Classification from Images Augmented with Generated Captions","abstract":"Infections in Diabetic Foot Ulcers (DFUs) can cause severe complications, including tissue death and limb amputation, highlighting the need for accurate, timely diagnosis. Previous machine learning methods have focused on identifying infections by analyzing wound images alone, without utilizing additional metadata such as medical notes. In this study, we aim to improve infection detection by introducing Synthetic Caption Augmented Retrieval for Wound Infection Detection (SCARWID), a novel deep learning framework that leverages synthetic textual descriptions to augment DFU images. SCARWID consists of two components: (1) Wound-BLIP, a Vision-Language Model (VLM) fine-tuned on GPT-4o-generated descriptions to synthesize consistent captions from images; and (2) an Image-Text Fusion module that uses cross-attention to extract cross-modal embeddings from an image and its corresponding Wound-BLIP caption. Infection status is determined by retrieving the top-k similar items from a labeled support set. To enhance the diversity of training data, we utilized a latent diffusion model to generate additional wound images. As a result, SCARWID outperformed state-of-the-art models, achieving average sensitivity, specificity, and accuracy of 0.85, 0.78, and 0.81, respectively, for wound infection classification. Displaying the generated captions alongside the wound images and infection detection results enhances interpretability and trust, enabling nurses to align SCARWID outputs with their medical knowledge. This is particularly valuable when wound notes are unavailable or when assisting novice nurses who may find it difficult to identify visual attributes of wound infection.","sentences":["Infections in Diabetic Foot Ulcers (DFUs) can cause severe complications, including tissue death and limb amputation, highlighting the need for accurate, timely diagnosis.","Previous machine learning methods have focused on identifying infections by analyzing wound images alone, without utilizing additional metadata such as medical notes.","In this study, we aim to improve infection detection by introducing Synthetic Caption Augmented Retrieval for Wound Infection Detection (SCARWID), a novel deep learning framework that leverages synthetic textual descriptions to augment DFU images.","SCARWID consists of two components: (1) Wound-BLIP, a Vision-Language Model (VLM) fine-tuned on GPT-4o-generated descriptions to synthesize consistent captions from images; and (2) an Image-Text Fusion module that uses cross-attention to extract cross-modal embeddings from an image and its corresponding Wound-BLIP caption.","Infection status is determined by retrieving the top-k similar items from a labeled support set.","To enhance the diversity of training data, we utilized a latent diffusion model to generate additional wound images.","As a result, SCARWID outperformed state-of-the-art models, achieving average sensitivity, specificity, and accuracy of 0.85, 0.78, and 0.81, respectively, for wound infection classification.","Displaying the generated captions alongside the wound images and infection detection results enhances interpretability and trust, enabling nurses to align SCARWID outputs with their medical knowledge.","This is particularly valuable when wound notes are unavailable or when assisting novice nurses who may find it difficult to identify visual attributes of wound infection."],"url":"http://arxiv.org/abs/2502.20277v1"}
{"created":"2025-02-27 17:01:23","title":"How Much is Enough? The Diminishing Returns of Tokenization Training Data","abstract":"Tokenization, a crucial initial step in natural language processing, is often assumed to benefit from larger training datasets. This paper investigates the impact of tokenizer training data sizes ranging from 1GB to 900GB. Our findings reveal diminishing returns as the data size increases, highlighting a practical limit on how much further scaling the training data can improve tokenization quality. We analyze this phenomenon and attribute the saturation effect to the constraints imposed by the pre-tokenization stage of tokenization. These results offer valuable insights for optimizing the tokenization process and highlight potential avenues for future research in tokenization algorithms.","sentences":["Tokenization, a crucial initial step in natural language processing, is often assumed to benefit from larger training datasets.","This paper investigates the impact of tokenizer training data sizes ranging from 1GB to 900GB.","Our findings reveal diminishing returns as the data size increases, highlighting a practical limit on how much further scaling the training data can improve tokenization quality.","We analyze this phenomenon and attribute the saturation effect to the constraints imposed by the pre-tokenization stage of tokenization.","These results offer valuable insights for optimizing the tokenization process and highlight potential avenues for future research in tokenization algorithms."],"url":"http://arxiv.org/abs/2502.20273v1"}
{"created":"2025-02-27 16:59:51","title":"HVI: A New color space for Low-light Image Enhancement","abstract":"Low-Light Image Enhancement (LLIE) is a crucial computer vision task that aims to restore detailed visual information from corrupted low-light images. Many existing LLIE methods are based on standard RGB (sRGB) space, which often produce color bias and brightness artifacts due to inherent high color sensitivity in sRGB. While converting the images using Hue, Saturation and Value (HSV) color space helps resolve the brightness issue, it introduces significant red and black noise artifacts. To address this issue, we propose a new color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by polarized HS maps and learnable intensity. The former enforces small distances for red coordinates to remove the red artifacts, while the latter compresses the low-light regions to remove the black artifacts. To fully leverage the chromatic and intensity information, a novel Color and Intensity Decoupling Network (CIDNet) is further introduced to learn accurate photometric mapping function under different lighting conditions in the HVI space. Comprehensive results from benchmark and ablation experiments show that the proposed HVI color space with CIDNet outperforms the state-of-the-art methods on 10 datasets. The code is available at https://github.com/Fediory/HVI-CIDNet.","sentences":["Low-Light Image Enhancement (LLIE) is a crucial computer vision task that aims to restore detailed visual information from corrupted low-light images.","Many existing LLIE methods are based on standard RGB (sRGB) space, which often produce color bias and brightness artifacts due to inherent high color sensitivity in sRGB.","While converting the images using Hue, Saturation and Value (HSV) color space helps resolve the brightness issue, it introduces significant red and black noise artifacts.","To address this issue, we propose a new color space for LLIE, namely Horizontal/Vertical-Intensity (HVI), defined by polarized HS maps and learnable intensity.","The former enforces small distances for red coordinates to remove the red artifacts, while the latter compresses the low-light regions to remove the black artifacts.","To fully leverage the chromatic and intensity information, a novel Color and Intensity Decoupling Network (CIDNet) is further introduced to learn accurate photometric mapping function under different lighting conditions in the HVI space.","Comprehensive results from benchmark and ablation experiments show that the proposed HVI color space with CIDNet outperforms the state-of-the-art methods on 10 datasets.","The code is available at https://github.com/Fediory/HVI-CIDNet."],"url":"http://arxiv.org/abs/2502.20272v1"}
{"created":"2025-02-27 16:57:05","title":"Solving Maker-Breaker Games on 5-uniform hypergraphs is PSPACE-complete","abstract":"Let $(X, \\mathcal{F})$ be a hypergraph. The Maker-Breaker game on $(X, \\mathcal{F})$ is a combinatorial game between two players, Maker and Breaker. Beginning with Maker, the players take turns claiming vertices from $X$ that have not yet been claimed. Maker wins if she manages to claim all vertices of some hyperedge $F \\in \\mathcal{F}$. Breaker wins if he claims at least one vertex in every hyperedge.   M. L. Rahman and Thomas Watson proved in 2021 that, even when only Maker-Breaker games on 6-uniform hypergraphs are considered, the decision problem of determining which player has a winning strategy is PSPACE-complete. They also showed that the problem is NL-hard when considering hypergraphs of rank 5.   In this paper, we improve the latter result by showing that deciding who wins Maker-Breaker games on 5-uniform hypergraphs is still a PSPACE-complete problem. We achieve this by polynomial transformation from the problem of solving the generalized geography game on bipartite digraphs with vertex degrees 3 or less, which is known to be PSPACE-complete.","sentences":["Let $(X, \\mathcal{F})$ be a hypergraph.","The Maker-Breaker game on $(X, \\mathcal{F})$ is a combinatorial game between two players, Maker and Breaker.","Beginning with Maker, the players take turns claiming vertices from $X$ that have not yet been claimed.","Maker wins if she manages to claim all vertices of some hyperedge $F \\in \\mathcal{F}$. Breaker wins if he claims at least one vertex in every hyperedge.   ","M. L. Rahman and Thomas Watson proved in 2021 that, even when only Maker-Breaker games on 6-uniform hypergraphs are considered, the decision problem of determining which player has a winning strategy is PSPACE-complete.","They also showed that the problem is NL-hard when considering hypergraphs of rank 5.   ","In this paper, we improve the latter result by showing that deciding who wins Maker-Breaker games on 5-uniform hypergraphs is still a PSPACE-complete problem.","We achieve this by polynomial transformation from the problem of solving the generalized geography game on bipartite digraphs with vertex degrees 3 or less, which is known to be PSPACE-complete."],"url":"http://arxiv.org/abs/2502.20271v1"}
{"created":"2025-02-27 16:55:18","title":"Large Language Models as Attribution Regularizers for Efficient Model Training","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains. However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like tabular data learning, where simpler models are often preferred due to interpretability and efficiency.   In this paper, we introduce a novel yet straightforward method for incorporating LLM-generated global task feature attributions into the training process of smaller networks. Specifically, we propose an attribution-matching regularization term that aligns the training dynamics of the smaller model with the insights provided by the LLM. By doing so, our approach yields superior performance in few-shot learning scenarios. Notably, our method requires only black-box API access to the LLM, making it easy to integrate into existing training pipelines with minimal computational overhead.   Furthermore, we demonstrate how this method can be used to address common issues in real-world datasets, such as skewness and bias. By integrating high-level knowledge from LLMs, our approach improves generalization, even when training data is limited or imbalanced. We validate its effectiveness through extensive experiments across multiple tasks, demonstrating improved learning efficiency and model robustness.","sentences":["Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains.","However, effectively leveraging their vast knowledge for training smaller downstream models remains an open challenge, especially in domains like tabular data learning, where simpler models are often preferred due to interpretability and efficiency.   ","In this paper, we introduce a novel yet straightforward method for incorporating LLM-generated global task feature attributions into the training process of smaller networks.","Specifically, we propose an attribution-matching regularization term that aligns the training dynamics of the smaller model with the insights provided by the LLM.","By doing so, our approach yields superior performance in few-shot learning scenarios.","Notably, our method requires only black-box API access to the LLM, making it easy to integrate into existing training pipelines with minimal computational overhead.   ","Furthermore, we demonstrate how this method can be used to address common issues in real-world datasets, such as skewness and bias.","By integrating high-level knowledge from LLMs, our approach improves generalization, even when training data is limited or imbalanced.","We validate its effectiveness through extensive experiments across multiple tasks, demonstrating improved learning efficiency and model robustness."],"url":"http://arxiv.org/abs/2502.20268v1"}
{"created":"2025-02-27 16:53:28","title":"On the Importance of Reward Design in Reinforcement Learning-based Dynamic Algorithm Configuration: A Case Study on OneMax with (1+($\u03bb$,$\u03bb$))-GA","abstract":"Dynamic Algorithm Configuration (DAC) has garnered significant attention in recent years, particularly in the prevalence of machine learning and deep learning algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges associated with algorithm configuration. However, making an RL agent work properly is a non-trivial task, especially in reward design, which necessitates a substantial amount of handcrafted knowledge based on domain expertise. In this work, we study the importance of reward design in the context of DAC via a case study on controlling the population size of the $(1+(\\lambda,\\lambda))$-GA optimizing OneMax. We observed that a poorly designed reward can hinder the RL agent's ability to learn an optimal policy because of a lack of exploration, leading to both scalability and learning divergence issues. To address those challenges, we propose the application of a reward shaping mechanism to facilitate enhanced exploration of the environment by the RL agent. Our work not only demonstrates the ability of RL in dynamically configuring the $(1+(\\lambda,\\lambda))$-GA, but also confirms the advantages of reward shaping in the scalability of RL agents across various sizes of OneMax problems.","sentences":["Dynamic Algorithm Configuration (DAC) has garnered significant attention in recent years, particularly in the prevalence of machine learning and deep learning algorithms.","Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges associated with algorithm configuration.","However, making an RL agent work properly is a non-trivial task, especially in reward design, which necessitates a substantial amount of handcrafted knowledge based on domain expertise.","In this work, we study the importance of reward design in the context of DAC via a case study on controlling the population size of the $(1+(\\lambda,\\lambda))$-GA optimizing OneMax.","We observed that a poorly designed reward can hinder the RL agent's ability to learn an optimal policy because of a lack of exploration, leading to both scalability and learning divergence issues.","To address those challenges, we propose the application of a reward shaping mechanism to facilitate enhanced exploration of the environment by the RL agent.","Our work not only demonstrates the ability of RL in dynamically configuring the $(1+(\\lambda,\\lambda))$-GA, but also confirms the advantages of reward shaping in the scalability of RL agents across various sizes of OneMax problems."],"url":"http://arxiv.org/abs/2502.20265v1"}
{"created":"2025-02-27 16:51:13","title":"Vector-Quantized Vision Foundation Models for Object-Centric Learning","abstract":"Decomposing visual scenes into objects, as humans do, facilitates modeling object relations and dynamics. Object-Centric Learning (OCL) achieves this by aggregating image or video feature maps into object-level feature vectors, known as \\textit{slots}. OCL's self-supervision via reconstructing the input from slots struggles with complex textures, thus many methods employ Vision Foundation Models (VFMs) to extract feature maps with better objectness. However, using VFMs merely as feature extractors does not fully unlock their potential. We propose Vector-Quantized VFMs for OCL (VQ-VFM-OCL, or VVO), where VFM features are extracted to facilitate object-level information aggregation and further quantized to strengthen supervision in reconstruction. Our VVO unifies OCL representatives into a concise architecture. Experiments demonstrate that VVO not only outperforms mainstream methods on object discovery tasks but also benefits downstream tasks like visual prediction and reasoning. The source code is available in the supplement.","sentences":["Decomposing visual scenes into objects, as humans do, facilitates modeling object relations and dynamics.","Object-Centric Learning (OCL) achieves this by aggregating image or video feature maps into object-level feature vectors, known as \\textit{slots}.","OCL's self-supervision via reconstructing the input from slots struggles with complex textures, thus many methods employ Vision Foundation Models (VFMs) to extract feature maps with better objectness.","However, using VFMs merely as feature extractors does not fully unlock their potential.","We propose Vector-Quantized VFMs for OCL (VQ-VFM-OCL, or VVO), where VFM features are extracted to facilitate object-level information aggregation and further quantized to strengthen supervision in reconstruction.","Our VVO unifies OCL representatives into a concise architecture.","Experiments demonstrate that VVO not only outperforms mainstream methods on object discovery tasks but also benefits downstream tasks like visual prediction and reasoning.","The source code is available in the supplement."],"url":"http://arxiv.org/abs/2502.20263v1"}
{"created":"2025-02-27 16:48:53","title":"Understanding the Limits of Deep Tabular Methods with Temporal Shift","abstract":"Deep tabular models have demonstrated remarkable success on i.i.d. data, excelling in a variety of structured data tasks. However, their performance often deteriorates under temporal distribution shifts, where trends and periodic patterns are present in the evolving data distribution over time. In this paper, we explore the underlying reasons for this failure in capturing temporal dependencies. We begin by investigating the training protocol, revealing a key issue in how model selection perform. While existing approaches use temporal ordering for splitting validation set, we show that even a random split can significantly improve model performance. By minimizing the time lag between training data and test time, while reducing the bias in validation, our proposed training protocol significantly improves generalization across various methods. Furthermore, we analyze how temporal data affects deep tabular representations, uncovering that these models often fail to capture crucial periodic and trend information. To address this gap, we introduce a plug-and-play temporal embedding method based on Fourier series expansion to learn and incorporate temporal patterns, offering an adaptive approach to handle temporal shifts. Our experiments demonstrate that this temporal embedding, combined with the improved training protocol, provides a more effective and robust framework for learning from temporal tabular data.","sentences":["Deep tabular models have demonstrated remarkable success on i.i.d. data, excelling in a variety of structured data tasks.","However, their performance often deteriorates under temporal distribution shifts, where trends and periodic patterns are present in the evolving data distribution over time.","In this paper, we explore the underlying reasons for this failure in capturing temporal dependencies.","We begin by investigating the training protocol, revealing a key issue in how model selection perform.","While existing approaches use temporal ordering for splitting validation set, we show that even a random split can significantly improve model performance.","By minimizing the time lag between training data and test time, while reducing the bias in validation, our proposed training protocol significantly improves generalization across various methods.","Furthermore, we analyze how temporal data affects deep tabular representations, uncovering that these models often fail to capture crucial periodic and trend information.","To address this gap, we introduce a plug-and-play temporal embedding method based on Fourier series expansion to learn and incorporate temporal patterns, offering an adaptive approach to handle temporal shifts.","Our experiments demonstrate that this temporal embedding, combined with the improved training protocol, provides a more effective and robust framework for learning from temporal tabular data."],"url":"http://arxiv.org/abs/2502.20260v1"}
{"created":"2025-02-27 16:46:23","title":"LLM as a Broken Telephone: Iterative Generation Distorts Information","abstract":"As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs. Inspired by the \"broken telephone\" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation. Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows.","sentences":["As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs.","Inspired by the \"broken telephone\" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation.","Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity.","While degradation is inevitable, it can be mitigated through strategic prompting techniques.","These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows."],"url":"http://arxiv.org/abs/2502.20258v1"}
{"created":"2025-02-27 16:43:56","title":"Do computer vision foundation models learn the low-level characteristics of the human visual system?","abstract":"Computer vision foundation models, such as DINO or OpenCLIP, are trained in a self-supervised manner on large image datasets. Analogously, substantial evidence suggests that the human visual system (HVS) is influenced by the statistical distribution of colors and patterns in the natural world, characteristics also present in the training data of foundation models. The question we address in this paper is whether foundation models trained on natural images mimic some of the low-level characteristics of the human visual system, such as contrast detection, contrast masking, and contrast constancy. Specifically, we designed a protocol comprising nine test types to evaluate the image encoders of 45 foundation and generative models. Our results indicate that some foundation models (e.g., DINO, DINOv2, and OpenCLIP), share some of the characteristics of human vision, but other models show little resemblance. Foundation models tend to show smaller sensitivity to low contrast and rather irregular responses to contrast across frequencies. The foundation models show the best agreement with human data in terms of contrast masking. Our findings suggest that human vision and computer vision may take both similar and different paths when learning to interpret images of the real world. Overall, while differences remain, foundation models trained on vision tasks start to align with low-level human vision, with DINOv2 showing the closest resemblance.","sentences":["Computer vision foundation models, such as DINO or OpenCLIP, are trained in a self-supervised manner on large image datasets.","Analogously, substantial evidence suggests that the human visual system (HVS) is influenced by the statistical distribution of colors and patterns in the natural world, characteristics also present in the training data of foundation models.","The question we address in this paper is whether foundation models trained on natural images mimic some of the low-level characteristics of the human visual system, such as contrast detection, contrast masking, and contrast constancy.","Specifically, we designed a protocol comprising nine test types to evaluate the image encoders of 45 foundation and generative models.","Our results indicate that some foundation models (e.g., DINO, DINOv2, and OpenCLIP), share some of the characteristics of human vision, but other models show little resemblance.","Foundation models tend to show smaller sensitivity to low contrast and rather irregular responses to contrast across frequencies.","The foundation models show the best agreement with human data in terms of contrast masking.","Our findings suggest that human vision and computer vision may take both similar and different paths when learning to interpret images of the real world.","Overall, while differences remain, foundation models trained on vision tasks start to align with low-level human vision, with DINOv2 showing the closest resemblance."],"url":"http://arxiv.org/abs/2502.20256v1"}
{"created":"2025-02-27 16:39:17","title":"Polynomial time classical versus quantum algorithms for representation theoretic multiplicities","abstract":"Littlewood-Richardson, Kronecker and plethysm coefficients are fundamental multiplicities of interest in Representation Theory and Algebraic Combinatorics. Determining a combinatorial interpretation for the Kronecker and plethysm coefficients is a major open problem, and prompts the consideration of their computational complexity. Recently it was shown that they behave relatively well with respect to quantum computation, and for some large families there are polynomial time quantum algorithms [Larocca,Havlicek, arXiv:2407.17649] (also [BCGHZ,arXiv:2302.11454]). In this paper we show that for many of those cases the Kronecker and plethysm coefficients can also be computed in polynomial time via classical algorithms, thereby refuting some of the conjectures in [LH24]. This vastly limits the cases in which the desired super-polynomial quantum speedup could be achieved.","sentences":["Littlewood-Richardson, Kronecker and plethysm coefficients are fundamental multiplicities of interest in Representation Theory and Algebraic Combinatorics.","Determining a combinatorial interpretation for the Kronecker and plethysm coefficients is a major open problem, and prompts the consideration of their computational complexity.","Recently it was shown that they behave relatively well with respect to quantum computation, and for some large families there are polynomial time quantum algorithms","[Larocca,Havlicek, arXiv:2407.17649] (also [BCGHZ,arXiv:2302.11454]).","In this paper we show that for many of those cases the Kronecker and plethysm coefficients can also be computed in polynomial time via classical algorithms, thereby refuting some of the conjectures in [LH24].","This vastly limits the cases in which the desired super-polynomial quantum speedup could be achieved."],"url":"http://arxiv.org/abs/2502.20253v1"}
{"created":"2025-02-27 16:35:25","title":"Enhancing 3D Gaze Estimation in the Wild using Weak Supervision with Gaze Following Labels","abstract":"Accurate 3D gaze estimation in unconstrained real-world environments remains a significant challenge due to variations in appearance, head pose, occlusion, and the limited availability of in-the-wild 3D gaze datasets. To address these challenges, we introduce a novel Self-Training Weakly-Supervised Gaze Estimation framework (ST-WSGE). This two-stage learning framework leverages diverse 2D gaze datasets, such as gaze-following data, which offer rich variations in appearances, natural scenes, and gaze distributions, and proposes an approach to generate 3D pseudo-labels and enhance model generalization. Furthermore, traditional modality-specific models, designed separately for images or videos, limit the effective use of available training data. To overcome this, we propose the Gaze Transformer (GaT), a modality-agnostic architecture capable of simultaneously learning static and dynamic gaze information from both image and video datasets. By combining 3D video datasets with 2D gaze target labels from gaze following tasks, our approach achieves the following key contributions: (i) Significant state-of-the-art improvements in within-domain and cross-domain generalization on unconstrained benchmarks like Gaze360 and GFIE, with notable cross-modal gains in video gaze estimation; (ii) Superior cross-domain performance on datasets such as MPIIFaceGaze and Gaze360 compared to frontal face methods. Code and pre-trained models will be released to the community.","sentences":["Accurate 3D gaze estimation in unconstrained real-world environments remains a significant challenge due to variations in appearance, head pose, occlusion, and the limited availability of in-the-wild 3D gaze datasets.","To address these challenges, we introduce a novel Self-Training Weakly-Supervised Gaze Estimation framework (ST-WSGE).","This two-stage learning framework leverages diverse 2D gaze datasets, such as gaze-following data, which offer rich variations in appearances, natural scenes, and gaze distributions, and proposes an approach to generate 3D pseudo-labels and enhance model generalization.","Furthermore, traditional modality-specific models, designed separately for images or videos, limit the effective use of available training data.","To overcome this, we propose the Gaze Transformer (GaT), a modality-agnostic architecture capable of simultaneously learning static and dynamic gaze information from both image and video datasets.","By combining 3D video datasets with 2D gaze target labels from gaze following tasks, our approach achieves the following key contributions: (i) Significant state-of-the-art improvements in within-domain and cross-domain generalization on unconstrained benchmarks like Gaze360 and GFIE, with notable cross-modal gains in video gaze estimation; (ii) Superior cross-domain performance on datasets such as MPIIFaceGaze and Gaze360 compared to frontal face methods.","Code and pre-trained models will be released to the community."],"url":"http://arxiv.org/abs/2502.20249v1"}
{"created":"2025-02-27 16:30:00","title":"Beyond Natural Language Perplexity: Detecting Dead Code Poisoning in Code Generation Datasets","abstract":"The increasing adoption of large language models (LLMs) for code-related tasks has raised concerns about the security of their training datasets. One critical threat is dead code poisoning, where syntactically valid but functionally redundant code is injected into training data to manipulate model behavior. Such attacks can degrade the performance of neural code search systems, leading to biased or insecure code suggestions. Existing detection methods, such as token-level perplexity analysis, fail to effectively identify dead code due to the structural and contextual characteristics of programming languages. In this paper, we propose DePA (Dead Code Perplexity Analysis), a novel line-level detection and cleansing method tailored to the structural properties of code. DePA computes line-level perplexity by leveraging the contextual relationships between code lines and identifies anomalous lines by comparing their perplexity to the overall distribution within the file. Our experiments on benchmark datasets demonstrate that DePA significantly outperforms existing methods, achieving 0.14-0.19 improvement in detection F1-score and a 44-65% increase in poisoned segment localization precision. Furthermore, DePA enhances detection speed by 0.62-23x, making it practical for large-scale dataset cleansing. Overall, by addressing the unique challenges of dead code poisoning, DePA provides a robust and efficient solution for safeguarding the integrity of code generation model training datasets.","sentences":["The increasing adoption of large language models (LLMs) for code-related tasks has raised concerns about the security of their training datasets.","One critical threat is dead code poisoning, where syntactically valid but functionally redundant code is injected into training data to manipulate model behavior.","Such attacks can degrade the performance of neural code search systems, leading to biased or insecure code suggestions.","Existing detection methods, such as token-level perplexity analysis, fail to effectively identify dead code due to the structural and contextual characteristics of programming languages.","In this paper, we propose DePA (Dead Code Perplexity Analysis), a novel line-level detection and cleansing method tailored to the structural properties of code.","DePA computes line-level perplexity by leveraging the contextual relationships between code lines and identifies anomalous lines by comparing their perplexity to the overall distribution within the file.","Our experiments on benchmark datasets demonstrate that DePA significantly outperforms existing methods, achieving 0.14-0.19 improvement in detection F1-score and a 44-65% increase in poisoned segment localization precision.","Furthermore, DePA enhances detection speed by 0.62-23x, making it practical for large-scale dataset cleansing.","Overall, by addressing the unique challenges of dead code poisoning, DePA provides a robust and efficient solution for safeguarding the integrity of code generation model training datasets."],"url":"http://arxiv.org/abs/2502.20246v1"}
{"created":"2025-02-27 16:29:14","title":"From Retrieval to Generation: Comparing Different Approaches","abstract":"Knowledge-intensive tasks, particularly open-domain question answering (ODQA), document reranking, and retrieval-augmented language modeling, require a balance between retrieval accuracy and generative flexibility. Traditional retrieval models such as BM25 and Dense Passage Retrieval (DPR), efficiently retrieve from large corpora but often lack semantic depth. Generative models like GPT-4-o provide richer contextual understanding but face challenges in maintaining factual consistency. In this work, we conduct a systematic evaluation of retrieval-based, generation-based, and hybrid models, with a primary focus on their performance in ODQA and related retrieval-augmented tasks. Our results show that dense retrievers, particularly DPR, achieve strong performance in ODQA with a top-1 accuracy of 50.17\\% on NQ, while hybrid models improve nDCG@10 scores on BEIR from 43.42 (BM25) to 52.59, demonstrating their strength in document reranking. Additionally, we analyze language modeling tasks using WikiText-103, showing that retrieval-based approaches like BM25 achieve lower perplexity compared to generative and hybrid methods, highlighting their utility in retrieval-augmented generation. By providing detailed comparisons and practical insights into the conditions where each approach excels, we aim to facilitate future optimizations in retrieval, reranking, and generative models for ODQA and related knowledge-intensive applications.","sentences":["Knowledge-intensive tasks, particularly open-domain question answering (ODQA), document reranking, and retrieval-augmented language modeling, require a balance between retrieval accuracy and generative flexibility.","Traditional retrieval models such as BM25 and Dense Passage Retrieval (DPR), efficiently retrieve from large corpora but often lack semantic depth.","Generative models like GPT-4-o provide richer contextual understanding but face challenges in maintaining factual consistency.","In this work, we conduct a systematic evaluation of retrieval-based, generation-based, and hybrid models, with a primary focus on their performance in ODQA and related retrieval-augmented tasks.","Our results show that dense retrievers, particularly DPR, achieve strong performance in ODQA with a top-1 accuracy of 50.17\\% on NQ, while hybrid models improve nDCG@10 scores on BEIR from 43.42 (BM25) to 52.59, demonstrating their strength in document reranking.","Additionally, we analyze language modeling tasks using WikiText-103, showing that retrieval-based approaches like BM25 achieve lower perplexity compared to generative and hybrid methods, highlighting their utility in retrieval-augmented generation.","By providing detailed comparisons and practical insights into the conditions where each approach excels, we aim to facilitate future optimizations in retrieval, reranking, and generative models for ODQA and related knowledge-intensive applications."],"url":"http://arxiv.org/abs/2502.20245v1"}
{"created":"2025-02-27 16:28:09","title":"The Impact of Transparency in AI Systems on Users' Data-Sharing Intentions: A Scenario-Based Experiment","abstract":"Artificial Intelligence (AI) systems are frequently employed in online services to provide personalized experiences to users based on large collections of data. However, AI systems can be designed in different ways, with black-box AI systems appearing as complex data-processing engines and white-box AI systems appearing as fully transparent data-processors. As such, it is reasonable to assume that these different design choices also affect user perception and thus their willingness to share data. To this end, we conducted a pre-registered, scenario-based online experiment with 240 participants and investigated how transparent and non-transparent data-processing entities influenced data-sharing intentions. Surprisingly, our results revealed no significant difference in willingness to share data across entities, challenging the notion that transparency increases data-sharing willingness. Furthermore, we found that a general attitude of trust towards AI has a significant positive influence, especially in the transparent AI condition, whereas privacy concerns did not significantly affect data-sharing decisions.","sentences":["Artificial Intelligence (AI) systems are frequently employed in online services to provide personalized experiences to users based on large collections of data.","However, AI systems can be designed in different ways, with black-box AI systems appearing as complex data-processing engines and white-box AI systems appearing as fully transparent data-processors.","As such, it is reasonable to assume that these different design choices also affect user perception and thus their willingness to share data.","To this end, we conducted a pre-registered, scenario-based online experiment with 240 participants and investigated how transparent and non-transparent data-processing entities influenced data-sharing intentions.","Surprisingly, our results revealed no significant difference in willingness to share data across entities, challenging the notion that transparency increases data-sharing willingness.","Furthermore, we found that a general attitude of trust towards AI has a significant positive influence, especially in the transparent AI condition, whereas privacy concerns did not significantly affect data-sharing decisions."],"url":"http://arxiv.org/abs/2502.20243v1"}
{"created":"2025-02-27 16:27:42","title":"GreenDFL: a Framework for Assessing the Sustainability of Decentralized Federated Learning Systems","abstract":"Decentralized Federated Learning (DFL) is an emerging paradigm that enables collaborative model training without centralized data aggregation, enhancing privacy and resilience. However, its sustainability remains underexplored, as energy consumption and carbon emissions vary across different system configurations. Understanding the environmental impact of DFL is crucial for optimizing its design and deployment. This study aims to assess the sustainability of DFL systems by analyzing factors that influence energy consumption and carbon emissions. Additionally, it proposes sustainability-aware optimization strategies, including a node selection algorithm and an aggregation method, to reduce the environmental footprint of DFL without compromising model performance. The proposed framework, named GreenDFL, systematically evaluates the impact of hardware accelerators, model architecture, communication medium, data distribution, network topology, and federation size on sustainability. Empirical experiments are conducted on multiple datasets using different system configurations, measuring energy consumption and carbon emissions across various phases of the DFL lifecycle. Results indicate that local training dominates energy consumption and carbon emissions, while communication has a relatively minor impact. Optimizing model complexity, using GPUs instead of CPUs, and strategically selecting participating nodes significantly improve sustainability. Additionally, deploying nodes in regions with lower carbon intensity and integrating early stopping mechanisms further reduce emissions. The proposed framework provides a comprehensive and practical computational approach for assessing the sustainability of DFL systems. Furthermore, it offers best practices for improving environmental efficiency in DFL, making sustainability considerations more actionable in real-world deployments.","sentences":["Decentralized Federated Learning (DFL) is an emerging paradigm that enables collaborative model training without centralized data aggregation, enhancing privacy and resilience.","However, its sustainability remains underexplored, as energy consumption and carbon emissions vary across different system configurations.","Understanding the environmental impact of DFL is crucial for optimizing its design and deployment.","This study aims to assess the sustainability of DFL systems by analyzing factors that influence energy consumption and carbon emissions.","Additionally, it proposes sustainability-aware optimization strategies, including a node selection algorithm and an aggregation method, to reduce the environmental footprint of DFL without compromising model performance.","The proposed framework, named GreenDFL, systematically evaluates the impact of hardware accelerators, model architecture, communication medium, data distribution, network topology, and federation size on sustainability.","Empirical experiments are conducted on multiple datasets using different system configurations, measuring energy consumption and carbon emissions across various phases of the DFL lifecycle.","Results indicate that local training dominates energy consumption and carbon emissions, while communication has a relatively minor impact.","Optimizing model complexity, using GPUs instead of CPUs, and strategically selecting participating nodes significantly improve sustainability.","Additionally, deploying nodes in regions with lower carbon intensity and integrating early stopping mechanisms further reduce emissions.","The proposed framework provides a comprehensive and practical computational approach for assessing the sustainability of DFL systems.","Furthermore, it offers best practices for improving environmental efficiency in DFL, making sustainability considerations more actionable in real-world deployments."],"url":"http://arxiv.org/abs/2502.20242v1"}
{"created":"2025-02-27 16:23:25","title":"FINEREASON: Evaluating and Improving LLMs' Deliberate Reasoning through Reflective Puzzle Solving","abstract":"Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach. Recent progress in large language models (LLMs) highlights an important shift from the \"System 1\" way of quick reactions to the \"System 2\" style of reflection-and-correction problem solving. However, current benchmarks heavily rely on the final-answer accuracy, leaving much of a model's intermediate reasoning steps unexamined. This fails to assess the model's ability to reflect and rectify mistakes within the reasoning process. To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark for fine-grained evaluation of LLMs' reasoning capabilities. Each puzzle can be decomposed into atomic steps, making it ideal for rigorous validation of intermediate correctness. Building on this, we introduce two tasks: state checking, and state transition, for a comprehensive evaluation of how models assess the current situation and plan the next move. To support broader research, we also provide a puzzle training set aimed at enhancing performance on general mathematical tasks. We show that models trained on our state checking and transition data demonstrate gains in math reasoning by up to 5.1% on GSM8K.","sentences":["Many challenging reasoning tasks require not just rapid, intuitive responses, but a more deliberate, multi-step approach.","Recent progress in large language models (LLMs) highlights an important shift from the \"System 1\" way of quick reactions to the \"System 2\" style of reflection-and-correction problem solving.","However, current benchmarks heavily rely on the final-answer accuracy, leaving much of a model's intermediate reasoning steps unexamined.","This fails to assess the model's ability to reflect and rectify mistakes within the reasoning process.","To bridge this gap, we introduce FINEREASON, a logic-puzzle benchmark for fine-grained evaluation of LLMs' reasoning capabilities.","Each puzzle can be decomposed into atomic steps, making it ideal for rigorous validation of intermediate correctness.","Building on this, we introduce two tasks: state checking, and state transition, for a comprehensive evaluation of how models assess the current situation and plan the next move.","To support broader research, we also provide a puzzle training set aimed at enhancing performance on general mathematical tasks.","We show that models trained on our state checking and transition data demonstrate gains in math reasoning by up to 5.1% on GSM8K."],"url":"http://arxiv.org/abs/2502.20238v1"}
{"created":"2025-02-27 16:22:18","title":"Teasing Apart Architecture and Initial Weights as Sources of Inductive Bias in Neural Networks","abstract":"Artificial neural networks can acquire many aspects of human knowledge from data, making them promising as models of human learning. But what those networks can learn depends upon their inductive biases -- the factors other than the data that influence the solutions they discover -- and the inductive biases of neural networks remain poorly understood, limiting our ability to draw conclusions about human learning from the performance of these systems. Cognitive scientists and machine learning researchers often focus on the architecture of a neural network as a source of inductive bias. In this paper we explore the impact of another source of inductive bias -- the initial weights of the network -- using meta-learning as a tool for finding initial weights that are adapted for specific problems. We evaluate four widely-used architectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430 different models across three tasks requiring different biases and forms of generalization. We find that meta-learning can substantially reduce or entirely eliminate performance differences across architectures and data representations, suggesting that these factors may be less important as sources of inductive bias than is typically assumed. When differences are present, architectures and data representations that perform well without meta-learning tend to meta-train more effectively. Moreover, all architectures generalize poorly on problems that are far from their meta-training experience, underscoring the need for stronger inductive biases for robust generalization.","sentences":["Artificial neural networks can acquire many aspects of human knowledge from data, making them promising as models of human learning.","But what those networks can learn depends upon their inductive biases -- the factors other than the data that influence the solutions they discover -- and the inductive biases of neural networks remain poorly understood, limiting our ability to draw conclusions about human learning from the performance of these systems.","Cognitive scientists and machine learning researchers often focus on the architecture of a neural network as a source of inductive bias.","In this paper we explore the impact of another source of inductive bias -- the initial weights of the network -- using meta-learning as a tool for finding initial weights that are adapted for specific problems.","We evaluate four widely-used architectures -- MLPs, CNNs, LSTMs, and Transformers -- by meta-training 430 different models across three tasks requiring different biases and forms of generalization.","We find that meta-learning can substantially reduce or entirely eliminate performance differences across architectures and data representations, suggesting that these factors may be less important as sources of inductive bias than is typically assumed.","When differences are present, architectures and data representations that perform well without meta-learning tend to meta-train more effectively.","Moreover, all architectures generalize poorly on problems that are far from their meta-training experience, underscoring the need for stronger inductive biases for robust generalization."],"url":"http://arxiv.org/abs/2502.20237v1"}
{"created":"2025-02-27 16:20:53","title":"Attention Distillation: A Unified Approach to Visual Characteristics Transfer","abstract":"Recent advances in generative diffusion models have shown a notable inherent understanding of image style and semantics. In this paper, we leverage the self-attention features from pretrained diffusion networks to transfer the visual characteristics from a reference to generated images. Unlike previous work that uses these features as plug-and-play attributes, we propose a novel attention distillation loss calculated between the ideal and current stylization results, based on which we optimize the synthesized image via backpropagation in latent space. Next, we propose an improved Classifier Guidance that integrates attention distillation loss into the denoising sampling process, further accelerating the synthesis and enabling a broad range of image generation applications. Extensive experiments have demonstrated the extraordinary performance of our approach in transferring the examples' style, appearance, and texture to new images in synthesis. Code is available at https://github.com/xugao97/AttentionDistillation.","sentences":["Recent advances in generative diffusion models have shown a notable inherent understanding of image style and semantics.","In this paper, we leverage the self-attention features from pretrained diffusion networks to transfer the visual characteristics from a reference to generated images.","Unlike previous work that uses these features as plug-and-play attributes, we propose a novel attention distillation loss calculated between the ideal and current stylization results, based on which we optimize the synthesized image via backpropagation in latent space.","Next, we propose an improved Classifier Guidance that integrates attention distillation loss into the denoising sampling process, further accelerating the synthesis and enabling a broad range of image generation applications.","Extensive experiments have demonstrated the extraordinary performance of our approach in transferring the examples' style, appearance, and texture to new images in synthesis.","Code is available at https://github.com/xugao97/AttentionDistillation."],"url":"http://arxiv.org/abs/2502.20235v1"}
{"created":"2025-02-27 16:20:21","title":"URL Inspection Tasks: Helping Users Detect Phishing Links in Emails","abstract":"The most widespread type of phishing attack involves email messages with links pointing to malicious content. Despite user training and the use of detection techniques, these attacks are still highly effective. Recent studies show that it is user inattentiveness, rather than lack of education, that is one of the key factors in successful phishing attacks. To this end, we develop a novel phishing defense mechanism based on URL inspection tasks: small challenges (loosely inspired by CAPTCHAs) that, to be solved, require users to interact with, and understand, the basic URL structure. We implemented and evaluated three tasks that act as ``barriers'' to visiting the website: (1) correct click-selection from a list of URLs, (2) mouse-based highlighting of the domain-name URL component, and (3) re-typing the domain-name. These tasks follow best practices in security interfaces and warning design.   We assessed the efficacy of these tasks through an extensive on-line user study with 2,673 participants from three different cultures, native languages, and alphabets. Results show that these tasks significantly decrease the rate of successful phishing attempts, compared to the baseline case. Results also showed the highest efficacy for difficult URLs, such as typo-squats, with which participants struggled the most. This highlights the importance of (1) slowing down users while focusing their attention and (2) helping them understand the URL structure (especially, the domain-name component thereof) and matching it to their intent.","sentences":["The most widespread type of phishing attack involves email messages with links pointing to malicious content.","Despite user training and the use of detection techniques, these attacks are still highly effective.","Recent studies show that it is user inattentiveness, rather than lack of education, that is one of the key factors in successful phishing attacks.","To this end, we develop a novel phishing defense mechanism based on URL inspection tasks: small challenges (loosely inspired by CAPTCHAs) that, to be solved, require users to interact with, and understand, the basic URL structure.","We implemented and evaluated three tasks that act as ``barriers'' to visiting the website: (1) correct click-selection from a list of URLs, (2) mouse-based highlighting of the domain-name URL component, and (3) re-typing the domain-name.","These tasks follow best practices in security interfaces and warning design.   ","We assessed the efficacy of these tasks through an extensive on-line user study with 2,673 participants from three different cultures, native languages, and alphabets.","Results show that these tasks significantly decrease the rate of successful phishing attempts, compared to the baseline case.","Results also showed the highest efficacy for difficult URLs, such as typo-squats, with which participants struggled the most.","This highlights the importance of (1) slowing down users while focusing their attention and (2) helping them understand the URL structure (especially, the domain-name component thereof) and matching it to their intent."],"url":"http://arxiv.org/abs/2502.20234v1"}
{"created":"2025-02-27 16:19:54","title":"Selective Use of Yannakakis' Algorithm to Improve Query Performance: Machine Learning to the Rescue","abstract":"Query optimization has played a central role in database research for decades. However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations. Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not.   In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest. More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution. Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement.","sentences":["Query optimization has played a central role in database research for decades.","However, more often than not, the proposed optimization techniques lead to a performance improvement in some, but not in all, situations.","Therefore, we urgently need a methodology for designing a decision procedure that decides for a given query whether the optimization technique should be applied or not.   ","In this work, we propose such a methodology with a focus on Yannakakis-style query evaluation as our optimization technique of interest.","More specifically, we formulate this decision problem as an algorithm selection problem and we present a Machine Learning based approach for its solution.","Empirical results with several benchmarks on a variety of database systems show that our approach indeed leads to a statistically significant performance improvement."],"url":"http://arxiv.org/abs/2502.20233v1"}
{"created":"2025-02-27 16:16:37","title":"AI Will Always Love You: Studying Implicit Biases in Romantic AI Companions","abstract":"While existing studies have recognised explicit biases in generative models, including occupational gender biases, the nuances of gender stereotypes and expectations of relationships between users and AI companions remain underexplored. In the meantime, AI companions have become increasingly popular as friends or gendered romantic partners to their users. This study bridges the gap by devising three experiments tailored for romantic, gender-assigned AI companions and their users, effectively evaluating implicit biases across various-sized LLMs. Each experiment looks at a different dimension: implicit associations, emotion responses, and sycophancy. This study aims to measure and compare biases manifested in different companion systems by quantitatively analysing persona-assigned model responses to a baseline through newly devised metrics. The results are noteworthy: they show that assigning gendered, relationship personas to Large Language Models significantly alters the responses of these models, and in certain situations in a biased, stereotypical way.","sentences":["While existing studies have recognised explicit biases in generative models, including occupational gender biases, the nuances of gender stereotypes and expectations of relationships between users and AI companions remain underexplored.","In the meantime, AI companions have become increasingly popular as friends or gendered romantic partners to their users.","This study bridges the gap by devising three experiments tailored for romantic, gender-assigned AI companions and their users, effectively evaluating implicit biases across various-sized LLMs.","Each experiment looks at a different dimension: implicit associations, emotion responses, and sycophancy.","This study aims to measure and compare biases manifested in different companion systems by quantitatively analysing persona-assigned model responses to a baseline through newly devised metrics.","The results are noteworthy: they show that assigning gendered, relationship personas to Large Language Models significantly alters the responses of these models, and in certain situations in a biased, stereotypical way."],"url":"http://arxiv.org/abs/2502.20231v1"}
{"created":"2025-02-27 16:16:26","title":"Swap Regret and Correlated Equilibria Beyond Normal-Form Games","abstract":"Swap regret is a notion that has proven itself to be central to the study of general-sum normal-form games, with swap-regret minimization leading to convergence to the set of correlated equilibria and guaranteeing non-manipulability against a self-interested opponent. However, the situation for more general classes of games -- such as Bayesian games and extensive-form games -- is less clear-cut, with multiple candidate definitions for swap-regret but no known efficiently minimizable variant of swap regret that implies analogous non-manipulability guarantees.   In this paper, we present a new variant of swap regret for polytope games that we call ``profile swap regret'', with the property that obtaining sublinear profile swap regret is both necessary and sufficient for any learning algorithm to be non-manipulable by an opponent (resolving an open problem of Mansour et al., 2022). Although we show profile swap regret is NP-hard to compute given a transcript of play, we show it is nonetheless possible to design efficient learning algorithms that guarantee at most $O(\\sqrt{T})$ profile swap regret. Finally, we explore the correlated equilibrium notion induced by low-profile-swap-regret play, and demonstrate a gap between the set of outcomes that can be implemented by this learning process and the set of outcomes that can be implemented by a third-party mediator (in contrast to the situation in normal-form games).","sentences":["Swap regret is a notion that has proven itself to be central to the study of general-sum normal-form games, with swap-regret minimization leading to convergence to the set of correlated equilibria and guaranteeing non-manipulability against a self-interested opponent.","However, the situation for more general classes of games -- such as Bayesian games and extensive-form games -- is less clear-cut, with multiple candidate definitions for swap-regret but no known efficiently minimizable variant of swap regret that implies analogous non-manipulability guarantees.   ","In this paper, we present a new variant of swap regret for polytope games that we call ``profile swap regret'', with the property that obtaining sublinear profile swap regret is both necessary and sufficient for any learning algorithm to be non-manipulable by an opponent (resolving an open problem of Mansour et al., 2022).","Although we show profile swap regret is NP-hard to compute given a transcript of play, we show it is nonetheless possible to design efficient learning algorithms that guarantee at most $O(\\sqrt{T})$ profile swap regret.","Finally, we explore the correlated equilibrium notion induced by low-profile-swap-regret play, and demonstrate a gap between the set of outcomes that can be implemented by this learning process and the set of outcomes that can be implemented by a third-party mediator (in contrast to the situation in normal-form games)."],"url":"http://arxiv.org/abs/2502.20229v1"}
{"created":"2025-02-27 16:09:04","title":"DIN-CTS: Low-Complexity Depthwise-Inception Neural Network with Contrastive Training Strategy for Deepfake Speech Detection","abstract":"In this paper, we propose a deep neural network approach for deepfake speech detection (DSD) based on a lowcomplexity Depthwise-Inception Network (DIN) trained with a contrastive training strategy (CTS). In this framework, input audio recordings are first transformed into spectrograms using Short-Time Fourier Transform (STFT) and Linear Filter (LF), which are then used to train the DIN. Once trained, the DIN processes bonafide utterances to extract audio embeddings, which are used to construct a Gaussian distribution representing genuine speech. Deepfake detection is then performed by computing the distance between a test utterance and this distribution to determine whether the utterance is fake or bonafide. To evaluate our proposed systems, we conducted extensive experiments on the benchmark dataset of ASVspoof 2019 LA. The experimental results demonstrate the effectiveness of combining the Depthwise-Inception Network with the contrastive learning strategy in distinguishing between fake and bonafide utterances. We achieved Equal Error Rate (EER), Accuracy (Acc.), F1, AUC scores of 4.6%, 95.4%, 97.3%, and 98.9% respectively using a single, low-complexity DIN with just 1.77 M parameters and 985 M FLOPS on short audio segments (4 seconds). Furthermore, our proposed system outperforms the single-system submissions in the ASVspoof 2019 LA challenge, showcasing its potential for real-time applications.","sentences":["In this paper, we propose a deep neural network approach for deepfake speech detection (DSD) based on a lowcomplexity Depthwise-Inception Network (DIN) trained with a contrastive training strategy (CTS).","In this framework, input audio recordings are first transformed into spectrograms using Short-Time Fourier Transform (STFT) and Linear Filter (LF), which are then used to train the DIN.","Once trained, the DIN processes bonafide utterances to extract audio embeddings, which are used to construct a Gaussian distribution representing genuine speech.","Deepfake detection is then performed by computing the distance between a test utterance and this distribution to determine whether the utterance is fake or bonafide.","To evaluate our proposed systems, we conducted extensive experiments on the benchmark dataset of ASVspoof 2019 LA.","The experimental results demonstrate the effectiveness of combining the Depthwise-Inception Network with the contrastive learning strategy in distinguishing between fake and bonafide utterances.","We achieved Equal Error Rate (EER), Accuracy (Acc.), F1, AUC scores of 4.6%, 95.4%, 97.3%, and 98.9% respectively using a single, low-complexity DIN with just 1.77 M parameters and 985 M FLOPS on short audio segments (4 seconds).","Furthermore, our proposed system outperforms the single-system submissions in the ASVspoof 2019 LA challenge, showcasing its potential for real-time applications."],"url":"http://arxiv.org/abs/2502.20225v1"}
{"created":"2025-02-27 16:06:30","title":"Deep Convolutional Neural Networks for Palm Fruit Maturity Classification","abstract":"To maximize palm oil yield and quality, it is essential to harvest palm fruit at the optimal maturity stage. This project aims to develop an automated computer vision system capable of accurately classifying palm fruit images into five ripeness levels. We employ deep Convolutional Neural Networks (CNNs) to classify palm fruit images based on their maturity stage. A shallow CNN serves as the baseline model, while transfer learning and fine-tuning are applied to pre-trained ResNet50 and InceptionV3 architectures. The study utilizes a publicly available dataset of over 8,000 images with significant variations, which is split into 80\\% for training and 20\\% for testing. The proposed deep CNN models achieve test accuracies exceeding 85\\% in classifying palm fruit maturity stages. This research highlights the potential of deep learning for automating palm fruit ripeness assessment, which can contribute to optimizing harvesting decisions and improving palm oil production efficiency.","sentences":["To maximize palm oil yield and quality, it is essential to harvest palm fruit at the optimal maturity stage.","This project aims to develop an automated computer vision system capable of accurately classifying palm fruit images into five ripeness levels.","We employ deep Convolutional Neural Networks (CNNs) to classify palm fruit images based on their maturity stage.","A shallow CNN serves as the baseline model, while transfer learning and fine-tuning are applied to pre-trained ResNet50 and InceptionV3 architectures.","The study utilizes a publicly available dataset of over 8,000 images with significant variations, which is split into 80\\% for training and 20\\% for testing.","The proposed deep CNN models achieve test accuracies exceeding 85\\% in classifying palm fruit maturity stages.","This research highlights the potential of deep learning for automating palm fruit ripeness assessment, which can contribute to optimizing harvesting decisions and improving palm oil production efficiency."],"url":"http://arxiv.org/abs/2502.20223v1"}
{"created":"2025-02-27 16:00:11","title":"Avat3r: Large Animatable Gaussian Reconstruction Model for High-fidelity 3D Head Avatars","abstract":"Traditionally, creating photo-realistic 3D head avatars requires a studio-level multi-view capture setup and expensive optimization during test-time, limiting the use of digital human doubles to the VFX industry or offline renderings.   To address this shortcoming, we present Avat3r, which regresses a high-quality and animatable 3D head avatar from just a few input images, vastly reducing compute requirements during inference. More specifically, we make Large Reconstruction Models animatable and learn a powerful prior over 3D human heads from a large multi-view video dataset. For better 3D head reconstructions, we employ position maps from DUSt3R and generalized feature maps from the human foundation model Sapiens. To animate the 3D head, our key discovery is that simple cross-attention to an expression code is already sufficient. Finally, we increase robustness by feeding input images with different expressions to our model during training, enabling the reconstruction of 3D head avatars from inconsistent inputs, e.g., an imperfect phone capture with accidental movement, or frames from a monocular video.   We compare Avat3r with current state-of-the-art methods for few-input and single-input scenarios, and find that our method has a competitive advantage in both tasks. Finally, we demonstrate the wide applicability of our proposed model, creating 3D head avatars from images of different sources, smartphone captures, single images, and even out-of-domain inputs like antique busts.   Project website: https://tobias-kirschstein.github.io/avat3r/","sentences":["Traditionally, creating photo-realistic 3D head avatars requires a studio-level multi-view capture setup and expensive optimization during test-time, limiting the use of digital human doubles to the VFX industry or offline renderings.   ","To address this shortcoming, we present Avat3r, which regresses a high-quality and animatable 3D head avatar from just a few input images, vastly reducing compute requirements during inference.","More specifically, we make Large Reconstruction Models animatable and learn a powerful prior over 3D human heads from a large multi-view video dataset.","For better 3D head reconstructions, we employ position maps from DUSt3R and generalized feature maps from the human foundation model Sapiens.","To animate the 3D head, our key discovery is that simple cross-attention to an expression code is already sufficient.","Finally, we increase robustness by feeding input images with different expressions to our model during training, enabling the reconstruction of 3D head avatars from inconsistent inputs, e.g., an imperfect phone capture with accidental movement, or frames from a monocular video.   ","We compare Avat3r with current state-of-the-art methods for few-input and single-input scenarios, and find that our method has a competitive advantage in both tasks.","Finally, we demonstrate the wide applicability of our proposed model, creating 3D head avatars from images of different sources, smartphone captures, single images, and even out-of-domain inputs like antique busts.   ","Project website: https://tobias-kirschstein.github.io/avat3r/"],"url":"http://arxiv.org/abs/2502.20220v1"}
{"created":"2025-02-27 15:58:42","title":"MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View multi-robot Exploration in Large-scale environments","abstract":"In multi-robot exploration, a team of mobile robot is tasked with efficiently mapping an unknown environments. While most exploration planners assume omnidirectional sensors like LiDAR, this is impractical for small robots such as drones, where lightweight, directional sensors like cameras may be the only option due to payload constraints. These sensors have a constrained field-of-view (FoV), which adds complexity to the exploration problem, requiring not only optimal robot positioning but also sensor orientation during movement. In this work, we propose MARVEL, a neural framework that leverages graph attention networks, together with novel frontiers and orientation features fusion technique, to develop a collaborative, decentralized policy using multi-agent reinforcement learning (MARL) for robots with constrained FoV. To handle the large action space of viewpoints planning, we further introduce a novel information-driven action pruning strategy. MARVEL improves multi-robot coordination and decision-making in challenging large-scale indoor environments, while adapting to various team sizes and sensor configurations (i.e., FoV and sensor range) without additional training. Our extensive evaluation shows that MARVEL's learned policies exhibit effective coordinated behaviors, outperforming state-of-the-art exploration planners across multiple metrics. We experimentally demonstrate MARVEL's generalizability in large-scale environments, of up to 90m by 90m, and validate its practical applicability through successful deployment on a team of real drone hardware.","sentences":["In multi-robot exploration, a team of mobile robot is tasked with efficiently mapping an unknown environments.","While most exploration planners assume omnidirectional sensors like LiDAR, this is impractical for small robots such as drones, where lightweight, directional sensors like cameras may be the only option due to payload constraints.","These sensors have a constrained field-of-view (FoV), which adds complexity to the exploration problem, requiring not only optimal robot positioning but also sensor orientation during movement.","In this work, we propose MARVEL, a neural framework that leverages graph attention networks, together with novel frontiers and orientation features fusion technique, to develop a collaborative, decentralized policy using multi-agent reinforcement learning (MARL) for robots with constrained FoV. To handle the large action space of viewpoints planning, we further introduce a novel information-driven action pruning strategy.","MARVEL improves multi-robot coordination and decision-making in challenging large-scale indoor environments, while adapting to various team sizes and sensor configurations (i.e., FoV and sensor range) without additional training.","Our extensive evaluation shows that MARVEL's learned policies exhibit effective coordinated behaviors, outperforming state-of-the-art exploration planners across multiple metrics.","We experimentally demonstrate MARVEL's generalizability in large-scale environments, of up to 90m by 90m, and validate its practical applicability through successful deployment on a team of real drone hardware."],"url":"http://arxiv.org/abs/2502.20217v1"}
{"created":"2025-02-27 15:55:23","title":"Topological Autoencoders++: Fast and Accurate Cycle-Aware Dimensionality Reduction","abstract":"This paper presents a novel topology-aware dimensionality reduction approach aiming at accurately visualizing the cyclic patterns present in high dimensional data. To that end, we build on the Topological Autoencoders (TopoAE) formulation. First, we provide a novel theoretical analysis of its associated loss and show that a zero loss indeed induces identical persistence pairs (in high and low dimensions) for the $0$-dimensional persistent homology (PH$^0$) of the Rips filtration. We also provide a counter example showing that this property no longer holds for a naive extension of TopoAE to PH$^d$ for $d\\ge 1$. Based on this observation, we introduce a novel generalization of TopoAE to $1$-dimensional persistent homology (PH$^1$), called TopoAE++, for the accurate generation of cycle-aware planar embeddings, addressing the above failure case. This generalization is based on the notion of cascade distortion, a new penalty term favoring an isometric embedding of the $2$-chains filling persistent $1$-cycles, hence resulting in more faithful geometrical reconstructions of the $1$-cycles in the plane. We further introduce a novel, fast algorithm for the exact computation of PH for Rips filtrations in the plane, yielding improved runtimes over previously documented topology-aware methods. Our method also achieves a better balance between the topological accuracy, as measured by the Wasserstein distance, and the visual preservation of the cycles in low dimensions. Our C++ implementation is available at https://github.com/MClemot/TopologicalAutoencodersPlusPlus.","sentences":["This paper presents a novel topology-aware dimensionality reduction approach aiming at accurately visualizing the cyclic patterns present in high dimensional data.","To that end, we build on the Topological Autoencoders (TopoAE) formulation.","First, we provide a novel theoretical analysis of its associated loss and show that a zero loss indeed induces identical persistence pairs (in high and low dimensions) for the $0$-dimensional persistent homology (PH$^0$) of the Rips filtration.","We also provide a counter example showing that this property no longer holds for a naive extension of TopoAE to PH$^d$ for $d\\ge 1$. Based on this observation, we introduce a novel generalization of TopoAE to $1$-dimensional persistent homology (PH$^1$), called TopoAE++, for the accurate generation of cycle-aware planar embeddings, addressing the above failure case.","This generalization is based on the notion of cascade distortion, a new penalty term favoring an isometric embedding of the $2$-chains filling persistent $1$-cycles, hence resulting in more faithful geometrical reconstructions of the $1$-cycles in the plane.","We further introduce a novel, fast algorithm for the exact computation of PH for Rips filtrations in the plane, yielding improved runtimes over previously documented topology-aware methods.","Our method also achieves a better balance between the topological accuracy, as measured by the Wasserstein distance, and the visual preservation of the cycles in low dimensions.","Our C++ implementation is available at https://github.com/MClemot/TopologicalAutoencodersPlusPlus."],"url":"http://arxiv.org/abs/2502.20215v1"}
{"created":"2025-02-27 15:54:14","title":"Mixture of Experts for Recognizing Depression from Interview and Reading Tasks","abstract":"Depression is a mental disorder and can cause a variety of symptoms, including psychological, physical, and social. Speech has been proved an objective marker for the early recognition of depression. For this reason, many studies have been developed aiming to recognize depression through speech. However, existing methods rely on the usage of only the spontaneous speech neglecting information obtained via read speech, use transcripts which are often difficult to obtain (manual) or come with high word-error rates (automatic), and do not focus on input-conditional computation methods. To resolve these limitations, this is the first study in depression recognition task obtaining representations of both spontaneous and read speech, utilizing multimodal fusion methods, and employing Mixture of Experts (MoE) models in a single deep neural network. Specifically, we use audio files corresponding to both interview and reading tasks and convert each audio file into log-Mel spectrogram, delta, and delta-delta. Next, the image representations of the two tasks pass through shared AlexNet models. The outputs of the AlexNet models are given as input to a multimodal fusion method. The resulting vector is passed through a MoE module. In this study, we employ three variants of MoE, namely sparsely-gated MoE and multilinear MoE based on factorization. Findings suggest that our proposed approach yields an Accuracy and F1-score of 87.00% and 86.66% respectively on the Androids corpus.","sentences":["Depression is a mental disorder and can cause a variety of symptoms, including psychological, physical, and social.","Speech has been proved an objective marker for the early recognition of depression.","For this reason, many studies have been developed aiming to recognize depression through speech.","However, existing methods rely on the usage of only the spontaneous speech neglecting information obtained via read speech, use transcripts which are often difficult to obtain (manual) or come with high word-error rates (automatic), and do not focus on input-conditional computation methods.","To resolve these limitations, this is the first study in depression recognition task obtaining representations of both spontaneous and read speech, utilizing multimodal fusion methods, and employing Mixture of Experts (MoE) models in a single deep neural network.","Specifically, we use audio files corresponding to both interview and reading tasks and convert each audio file into log-Mel spectrogram, delta, and delta-delta.","Next, the image representations of the two tasks pass through shared AlexNet models.","The outputs of the AlexNet models are given as input to a multimodal fusion method.","The resulting vector is passed through a MoE module.","In this study, we employ three variants of MoE, namely sparsely-gated MoE and multilinear MoE based on factorization.","Findings suggest that our proposed approach yields an Accuracy and F1-score of 87.00% and 86.66% respectively on the Androids corpus."],"url":"http://arxiv.org/abs/2502.20213v1"}
{"created":"2025-02-27 15:50:21","title":"DIPSER: A Dataset for In-Person Student1 Engagement Recognition in the Wild","abstract":"In this paper, a novel dataset is introduced, designed to assess student attention within in-person classroom settings. This dataset encompasses RGB camera data, featuring multiple cameras per student to capture both posture and facial expressions, in addition to smartwatch sensor data for each individual. This dataset allows machine learning algorithms to be trained to predict attention and correlate it with emotion. A comprehensive suite of attention and emotion labels for each student is provided, generated through self-reporting as well as evaluations by four different experts. Our dataset uniquely combines facial and environmental camera data, smartwatch metrics, and includes underrepresented ethnicities in similar datasets, all within in-the-wild, in-person settings, making it the most comprehensive dataset of its kind currently available.   The dataset presented offers an extensive and diverse collection of data pertaining to student interactions across different educational contexts, augmented with additional metadata from other tools. This initiative addresses existing deficiencies by offering a valuable resource for the analysis of student attention and emotion in face-to-face lessons.","sentences":["In this paper, a novel dataset is introduced, designed to assess student attention within in-person classroom settings.","This dataset encompasses RGB camera data, featuring multiple cameras per student to capture both posture and facial expressions, in addition to smartwatch sensor data for each individual.","This dataset allows machine learning algorithms to be trained to predict attention and correlate it with emotion.","A comprehensive suite of attention and emotion labels for each student is provided, generated through self-reporting as well as evaluations by four different experts.","Our dataset uniquely combines facial and environmental camera data, smartwatch metrics, and includes underrepresented ethnicities in similar datasets, all within in-the-wild, in-person settings, making it the most comprehensive dataset of its kind currently available.   ","The dataset presented offers an extensive and diverse collection of data pertaining to student interactions across different educational contexts, augmented with additional metadata from other tools.","This initiative addresses existing deficiencies by offering a valuable resource for the analysis of student attention and emotion in face-to-face lessons."],"url":"http://arxiv.org/abs/2502.20209v1"}
{"created":"2025-02-27 15:47:49","title":"4Deform: Neural Surface Deformation for Robust Shape Interpolation","abstract":"Generating realistic intermediate shapes between non-rigidly deformed shapes is a challenging task in computer vision, especially with unstructured data (e.g., point clouds) where temporal consistency across frames is lacking, and topologies are changing. Most interpolation methods are designed for structured data (i.e., meshes) and do not apply to real-world point clouds. In contrast, our approach, 4Deform, leverages neural implicit representation (NIR) to enable free topology changing shape deformation. Unlike previous mesh-based methods that learn vertex-based deformation fields, our method learns a continuous velocity field in Euclidean space. Thus, it is suitable for less structured data such as point clouds. Additionally, our method does not require intermediate-shape supervision during training; instead, we incorporate physical and geometrical constraints to regularize the velocity field. We reconstruct intermediate surfaces using a modified level-set equation, directly linking our NIR with the velocity field. Experiments show that our method significantly outperforms previous NIR approaches across various scenarios (e.g., noisy, partial, topology-changing, non-isometric shapes) and, for the first time, enables new applications like 4D Kinect sequence upsampling and real-world high-resolution mesh deformation.","sentences":["Generating realistic intermediate shapes between non-rigidly deformed shapes is a challenging task in computer vision, especially with unstructured data (e.g., point clouds) where temporal consistency across frames is lacking, and topologies are changing.","Most interpolation methods are designed for structured data (i.e., meshes) and do not apply to real-world point clouds.","In contrast, our approach, 4Deform, leverages neural implicit representation (NIR) to enable free topology changing shape deformation.","Unlike previous mesh-based methods that learn vertex-based deformation fields, our method learns a continuous velocity field in Euclidean space.","Thus, it is suitable for less structured data such as point clouds.","Additionally, our method does not require intermediate-shape supervision during training; instead, we incorporate physical and geometrical constraints to regularize the velocity field.","We reconstruct intermediate surfaces using a modified level-set equation, directly linking our NIR with the velocity field.","Experiments show that our method significantly outperforms previous NIR approaches across various scenarios (e.g., noisy, partial, topology-changing, non-isometric shapes) and, for the first time, enables new applications like 4D Kinect sequence upsampling and real-world high-resolution mesh deformation."],"url":"http://arxiv.org/abs/2502.20208v1"}
{"created":"2025-02-27 15:47:15","title":"Differentially-private frugal estimation of quantiles","abstract":"Fast and accurate estimation of quantiles on data streams coming from communication networks, Internet of Things (IoT), and alike, is at the heart of important data processing applications including statistical analysis, latency monitoring, query optimization for parallel database management systems, and more. Indeed, quantiles are more robust indicators for the underlying distribution, compared to moment-based indicators such as mean and variance. The streaming setting additionally constrains accurate tracking of quantiles, as stream items may arrive at a very high rate and must be processed as quickly as possible and discarded, being their storage usually unfeasible. Since an exact solution is only possible when data are fully stored, the goal in practical contexts is to provide an approximate solution with a provably guaranteed bound on the approximation error committed, while using a minimal amount of space. At the same time, with the increasing amount of personal and sensitive information exchanged, it is essential to design privacy protection techniques to ensure confidentiality and data integrity. In this paper we present the following differentially private streaming algorithms for frugal estimation of a quantile: DP-FRUGAL-1U-L, DP-FRUGAL-1U-G, DP-FRUGAL-1U-\\r{ho} and DP-FRUGAL-2U-SA. Frugality refers to the ability of the algorithms to provide a good approximation to the sought quantile using a modest amount of space, either one or two units of memory. We provide a theoretical analysis and extensive experimental results, in which we also compare DP-FRUGAL-1U-L with LDPQ, a recent state of the art algorithm, and show that DP-FRUGAL-1U-L outperforms LDPQ in both accuracy and speed.","sentences":["Fast and accurate estimation of quantiles on data streams coming from communication networks, Internet of Things (IoT), and alike, is at the heart of important data processing applications including statistical analysis, latency monitoring, query optimization for parallel database management systems, and more.","Indeed, quantiles are more robust indicators for the underlying distribution, compared to moment-based indicators such as mean and variance.","The streaming setting additionally constrains accurate tracking of quantiles, as stream items may arrive at a very high rate and must be processed as quickly as possible and discarded, being their storage usually unfeasible.","Since an exact solution is only possible when data are fully stored, the goal in practical contexts is to provide an approximate solution with a provably guaranteed bound on the approximation error committed, while using a minimal amount of space.","At the same time, with the increasing amount of personal and sensitive information exchanged, it is essential to design privacy protection techniques to ensure confidentiality and data integrity.","In this paper we present the following differentially private streaming algorithms for frugal estimation of a quantile: DP-FRUGAL-1U-L, DP-FRUGAL-1U-G, DP-FRUGAL-1U-\\r{ho} and DP-FRUGAL-2U-SA.","Frugality refers to the ability of the algorithms to provide a good approximation to the sought quantile using a modest amount of space, either one or two units of memory.","We provide a theoretical analysis and extensive experimental results, in which we also compare DP-FRUGAL-1U-L with LDPQ, a recent state of the art algorithm, and show that DP-FRUGAL-1U-L outperforms LDPQ in both accuracy and speed."],"url":"http://arxiv.org/abs/2502.20207v1"}
{"created":"2025-02-27 15:45:16","title":"Granite Embedding Models","abstract":"We introduce the Granite Embedding models, a family of encoder-based embedding models designed for retrieval tasks, spanning dense-retrieval and sparse retrieval architectures, with both English and Multilingual capabilities. This report provides the technical details of training these highly effective 12 layer embedding models, along with their efficient 6 layer distilled counterparts. Extensive evaluations show that the models, developed with techniques like retrieval oriented pretraining, contrastive finetuning, knowledge distillation, and model merging significantly outperform publicly available models of similar sizes on both internal IBM retrieval and search tasks, and have equivalent performance on widely used information retrieval benchmarks, while being trained on high-quality data suitable for enterprise use. We publicly release all our Granite Embedding models under the Apache 2.0 license, allowing both research and commercial use at https://huggingface.co/collections/ibm-granite.","sentences":["We introduce the Granite Embedding models, a family of encoder-based embedding models designed for retrieval tasks, spanning dense-retrieval and sparse retrieval architectures, with both English and Multilingual capabilities.","This report provides the technical details of training these highly effective 12 layer embedding models, along with their efficient 6 layer distilled counterparts.","Extensive evaluations show that the models, developed with techniques like retrieval oriented pretraining, contrastive finetuning, knowledge distillation, and model merging significantly outperform publicly available models of similar sizes on both internal IBM retrieval and search tasks, and have equivalent performance on widely used information retrieval benchmarks, while being trained on high-quality data suitable for enterprise use.","We publicly release all our Granite Embedding models under the Apache 2.0 license, allowing both research and commercial use at https://huggingface.co/collections/ibm-granite."],"url":"http://arxiv.org/abs/2502.20204v1"}
{"created":"2025-02-27 15:43:45","title":"Pricing for Routing and Flow-Control in Payment Channel Networks","abstract":"A payment channel network is a blockchain-based overlay mechanism that allows parties to transact more efficiently than directly using the blockchain. These networks are composed of payment channels that carry transactions between pairs of users. Due to its design, a payment channel cannot sustain a net flow of money in either direction indefinitely. Therefore, a payment channel network cannot serve transaction requests arbitrarily over a long period of time. We introduce \\emph{DEBT control}, a joint routing and flow-control protocol that guides a payment channel network towards an optimal operating state for any steady-state demand. In this protocol, each channel sets a price for routing transactions through it. Transacting users make flow-control and routing decisions by responding to these prices. A channel updates its price based on the net flow of money through it. The protocol is developed by formulating a network utility maximization problem and solving its dual through gradient descent. We provide convergence guarantees for the protocol and also illustrate its behavior through simulations.","sentences":["A payment channel network is a blockchain-based overlay mechanism that allows parties to transact more efficiently than directly using the blockchain.","These networks are composed of payment channels that carry transactions between pairs of users.","Due to its design, a payment channel cannot sustain a net flow of money in either direction indefinitely.","Therefore, a payment channel network cannot serve transaction requests arbitrarily over a long period of time.","We introduce \\emph{DEBT control}, a joint routing and flow-control protocol that guides a payment channel network towards an optimal operating state for any steady-state demand.","In this protocol, each channel sets a price for routing transactions through it.","Transacting users make flow-control and routing decisions by responding to these prices.","A channel updates its price based on the net flow of money through it.","The protocol is developed by formulating a network utility maximization problem and solving its dual through gradient descent.","We provide convergence guarantees for the protocol and also illustrate its behavior through simulations."],"url":"http://arxiv.org/abs/2502.20203v1"}
{"created":"2025-02-27 15:36:16","title":"Wildcat: Educational RISC-V Microprocessors","abstract":"In computer architecture courses, we usually teach RISC processors using a five-stage pipeline, neglecting alternative organizations. This design choice, rooted in the 1980s technology, may not be optimal today, and it is certainly not the easiest pipeline for education. This paper examines more straightforward pipeline organizations for RISC processors that are suitable for educational purposes and for implementing embedded processors in FPGAs and ASICs. We analyze resource costs and maximum clock frequency of various designs implemented in an FPGA, using clock frequency as a performance proxy. Additionally, we validate these results with ASIC designs synthesized using the open-source SkyWater130 process.   Contradictory to common wisdom, a longer pipeline (up to 5 stages) does not necessarily always increase the maximum clock frequency. In two FPGA and one ASIC implementation, we discovered that a four- or five-stage pipeline leads to a slower clock frequency than a three-stage implementation. The reason is that the width of the forwarding multiplexer in the execution stage increases with longer pipelines, which is on the critical path. We also argue that a 3-stage pipeline organization is more adequate for teaching a pipeline organization of a microprocessor.","sentences":["In computer architecture courses, we usually teach RISC processors using a five-stage pipeline, neglecting alternative organizations.","This design choice, rooted in the 1980s technology, may not be optimal today, and it is certainly not the easiest pipeline for education.","This paper examines more straightforward pipeline organizations for RISC processors that are suitable for educational purposes and for implementing embedded processors in FPGAs and ASICs.","We analyze resource costs and maximum clock frequency of various designs implemented in an FPGA, using clock frequency as a performance proxy.","Additionally, we validate these results with ASIC designs synthesized using the open-source SkyWater130 process.   ","Contradictory to common wisdom, a longer pipeline (up to 5 stages) does not necessarily always increase the maximum clock frequency.","In two FPGA and one ASIC implementation, we discovered that a four- or five-stage pipeline leads to a slower clock frequency than a three-stage implementation.","The reason is that the width of the forwarding multiplexer in the execution stage increases with longer pipelines, which is on the critical path.","We also argue that a 3-stage pipeline organization is more adequate for teaching a pipeline organization of a microprocessor."],"url":"http://arxiv.org/abs/2502.20197v1"}
