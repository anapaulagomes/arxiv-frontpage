{"created":"2024-10-15 17:59:44","title":"MoH: Multi-Head Attention as Mixture-of-Head Attention","abstract":"In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level. We show that multi-head attention can be expressed in the summation form. Drawing on the insight that not all attention heads hold equal significance, we propose Mixture-of-Head attention (MoH), a new architecture that treats attention heads as experts in the Mixture-of-Experts (MoE) mechanism. MoH has two significant advantages: First, MoH enables each token to select the appropriate attention heads, enhancing inference efficiency without compromising accuracy or increasing the number of parameters. Second, MoH replaces the standard summation in multi-head attention with a weighted summation, introducing flexibility to the attention mechanism and unlocking extra performance potential. Extensive experiments on ViT, DiT, and LLMs demonstrate that MoH outperforms multi-head attention by using only 50%-90% of the attention heads. Moreover, we demonstrate that pre-trained multi-head attention models, such as LLaMA3-8B, can be further continue-tuned into our MoH models. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14 benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the attention heads. We believe the proposed MoH is a promising alternative to multi-head attention and provides a strong foundation for developing advanced and efficient attention-based models.","sentences":["In this work, we upgrade the multi-head attention mechanism, the core of the Transformer model, to improve efficiency while maintaining or surpassing the previous accuracy level.","We show that multi-head attention can be expressed in the summation form.","Drawing on the insight that not all attention heads hold equal significance, we propose Mixture-of-Head attention (MoH), a new architecture that treats attention heads as experts in the Mixture-of-Experts (MoE) mechanism.","MoH has two significant advantages: First, MoH enables each token to select the appropriate attention heads, enhancing inference efficiency without compromising accuracy or increasing the number of parameters.","Second, MoH replaces the standard summation in multi-head attention with a weighted summation, introducing flexibility to the attention mechanism and unlocking extra performance potential.","Extensive experiments on ViT, DiT, and LLMs demonstrate that MoH outperforms multi-head attention by using only 50%-90% of the attention heads.","Moreover, we demonstrate that pre-trained multi-head attention models, such as LLaMA3-8B, can be further continue-tuned into our MoH models.","Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14 benchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the attention heads.","We believe the proposed MoH is a promising alternative to multi-head attention and provides a strong foundation for developing advanced and efficient attention-based models."],"url":"http://arxiv.org/abs/2410.11842v1"}
{"created":"2024-10-15 17:59:30","title":"GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation","abstract":"Large language model-based explainable recommendation (LLM-based ER) systems show promise in generating human-like explanations for recommendations. However, they face challenges in modeling user-item collaborative preferences, personalizing explanations, and handling sparse user-item interactions. To address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated Mixture of Experts framework for explainable recommendation. GaVaMoE introduces two key components: (1) a rating reconstruction module that employs Variational Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex user-item collaborative preferences, serving as a pre-trained multi-gating mechanism; and (2) a set of fine-grained expert models coupled with the multi-gating mechanism for generating highly personalized explanations. The VAE component models latent factors in user-item interactions, while the GMM clusters users with similar behaviors. Each cluster corresponds to a gate in the multi-gating mechanism, routing user-item pairs to appropriate expert models. This architecture enables GaVaMoE to generate tailored explanations for specific user types and preferences, mitigating data sparsity by leveraging user similarities. Extensive experiments on three real-world datasets demonstrate that GaVaMoE significantly outperforms existing methods in explanation quality, personalization, and consistency. Notably, GaVaMoE exhibits robust performance in scenarios with sparse user-item interactions, maintaining high-quality explanations even for users with limited historical data.","sentences":["Large language model-based explainable recommendation (LLM-based ER) systems show promise in generating human-like explanations for recommendations.","However, they face challenges in modeling user-item collaborative preferences, personalizing explanations, and handling sparse user-item interactions.","To address these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated Mixture of Experts framework for explainable recommendation.","GaVaMoE introduces two key components: (1) a rating reconstruction module that employs Variational Autoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex user-item collaborative preferences, serving as a pre-trained multi-gating mechanism; and (2) a set of fine-grained expert models coupled with the multi-gating mechanism for generating highly personalized explanations.","The VAE component models latent factors in user-item interactions, while the GMM clusters users with similar behaviors.","Each cluster corresponds to a gate in the multi-gating mechanism, routing user-item pairs to appropriate expert models.","This architecture enables GaVaMoE to generate tailored explanations for specific user types and preferences, mitigating data sparsity by leveraging user similarities.","Extensive experiments on three real-world datasets demonstrate that GaVaMoE significantly outperforms existing methods in explanation quality, personalization, and consistency.","Notably, GaVaMoE exhibits robust performance in scenarios with sparse user-item interactions, maintaining high-quality explanations even for users with limited historical data."],"url":"http://arxiv.org/abs/2410.11841v1"}
{"created":"2024-10-15 17:59:10","title":"A Hitchhiker's Guide to Scaling Law Estimation","abstract":"Scaling laws predict the loss of a target machine learning model by extrapolating from easier-to-train models with fewer parameters or smaller training sets. This provides an efficient way for practitioners and researchers alike to compare pretraining decisions involving optimizers, datasets, and model architectures. Despite the widespread use of scaling laws to model the dynamics of language model training, there has been little work on understanding how to best estimate and interpret them. We collect (and release) a large-scale dataset containing losses and downstream evaluations for 485 previously published pretrained models. We use these to estimate more than 1000 scaling laws, then derive a set of best practices for estimating scaling laws in new model families. We find that fitting scaling laws to intermediate checkpoints of training runs (and not just their final losses) substantially improves accuracy, and that -- all else equal -- estimates of performance are generally most accurate when derived from other models of similar sizes. However, because there is a significant degree of variability across model seeds, training multiple small models is sometimes more useful than training a single large one. Moreover, while different model families differ scaling behavior, they are often similar enough that a target model's behavior can be predicted from a single model with the same architecture, along with scaling parameter estimates derived from other model families.","sentences":["Scaling laws predict the loss of a target machine learning model by extrapolating from easier-to-train models with fewer parameters or smaller training sets.","This provides an efficient way for practitioners and researchers alike to compare pretraining decisions involving optimizers, datasets, and model architectures.","Despite the widespread use of scaling laws to model the dynamics of language model training, there has been little work on understanding how to best estimate and interpret them.","We collect (and release) a large-scale dataset containing losses and downstream evaluations for 485 previously published pretrained models.","We use these to estimate more than 1000 scaling laws, then derive a set of best practices for estimating scaling laws in new model families.","We find that fitting scaling laws to intermediate checkpoints of training runs (and not just their final losses) substantially improves accuracy, and that -- all else equal -- estimates of performance are generally most accurate when derived from other models of similar sizes.","However, because there is a significant degree of variability across model seeds, training multiple small models is sometimes more useful than training a single large one.","Moreover, while different model families differ scaling behavior, they are often similar enough that a target model's behavior can be predicted from a single model with the same architecture, along with scaling parameter estimates derived from other model families."],"url":"http://arxiv.org/abs/2410.11840v1"}
{"created":"2024-10-15 17:59:04","title":"High-Resolution Frame Interpolation with Patch-based Cascaded Diffusion","abstract":"Despite the recent progress, existing frame interpolation methods still struggle with processing extremely high resolution input and handling challenging cases such as repetitive textures, thin objects, and large motion. To address these issues, we introduce a patch-based cascaded pixel diffusion model for frame interpolation, HiFI, that excels in these scenarios while achieving competitive performance on standard benchmarks. Cascades, which generate a series of images from low- to high-resolution, can help significantly with large or complex motion that require both global context for a coarse solution and detailed context for high resolution output. However, contrary to prior work on cascaded diffusion models which perform diffusion on increasingly large resolutions, we use a single model that always performs diffusion at the same resolution and upsamples by processing patches of the inputs and the prior solution. We show that this technique drastically reduces memory usage at inference time and also allows us to use a single model at test time, solving both frame interpolation and spatial up-sampling, saving training cost. We show that HiFI helps significantly with high resolution and complex repeated textures that require global context. HiFI demonstrates comparable or beyond state-of-the-art performance on multiple benchmarks (Vimeo, Xiph, X-Test, SEPE-8K). On our newly introduced dataset that focuses on particularly challenging cases, HiFI also significantly outperforms other baselines on these cases. Please visit our project page for video results: https://hifi-diffusion.github.io","sentences":["Despite the recent progress, existing frame interpolation methods still struggle with processing extremely high resolution input and handling challenging cases such as repetitive textures, thin objects, and large motion.","To address these issues, we introduce a patch-based cascaded pixel diffusion model for frame interpolation, HiFI, that excels in these scenarios while achieving competitive performance on standard benchmarks.","Cascades, which generate a series of images from low- to high-resolution, can help significantly with large or complex motion that require both global context for a coarse solution and detailed context for high resolution output.","However, contrary to prior work on cascaded diffusion models which perform diffusion on increasingly large resolutions, we use a single model that always performs diffusion at the same resolution and upsamples by processing patches of the inputs and the prior solution.","We show that this technique drastically reduces memory usage at inference time and also allows us to use a single model at test time, solving both frame interpolation and spatial up-sampling, saving training cost.","We show that HiFI helps significantly with high resolution and complex repeated textures that require global context.","HiFI demonstrates comparable or beyond state-of-the-art performance on multiple benchmarks (Vimeo, Xiph, X-Test, SEPE-8K).","On our newly introduced dataset that focuses on particularly challenging cases, HiFI also significantly outperforms other baselines on these cases.","Please visit our project page for video results: https://hifi-diffusion.github.io"],"url":"http://arxiv.org/abs/2410.11838v1"}
{"created":"2024-10-15 17:58:07","title":"On the Effectiveness of Dataset Alignment for Fake Image Detection","abstract":"As latent diffusion models (LDMs) democratize image generation capabilities, there is a growing need to detect fake images. A good detector should focus on the generative models fingerprints while ignoring image properties such as semantic content, resolution, file format, etc. Fake image detectors are usually built in a data driven way, where a model is trained to separate real from fake images. Existing works primarily investigate network architecture choices and training recipes. In this work, we argue that in addition to these algorithmic choices, we also require a well aligned dataset of real/fake images to train a robust detector. For the family of LDMs, we propose a very simple way to achieve this: we reconstruct all the real images using the LDMs autoencoder, without any denoising operation. We then train a model to separate these real images from their reconstructions. The fakes created this way are extremely similar to the real ones in almost every aspect (e.g., size, aspect ratio, semantic content), which forces the model to look for the LDM decoders artifacts. We empirically show that this way of creating aligned real/fake datasets, which also sidesteps the computationally expensive denoising process, helps in building a detector that focuses less on spurious correlations, something that a very popular existing method is susceptible to. Finally, to demonstrate just how effective the alignment in a dataset can be, we build a detector using images that are not natural objects, and present promising results. Overall, our work identifies the subtle but significant issues that arise when training a fake image detector and proposes a simple and inexpensive solution to address these problems.","sentences":["As latent diffusion models (LDMs) democratize image generation capabilities, there is a growing need to detect fake images.","A good detector should focus on the generative models fingerprints while ignoring image properties such as semantic content, resolution, file format, etc.","Fake image detectors are usually built in a data driven way, where a model is trained to separate real from fake images.","Existing works primarily investigate network architecture choices and training recipes.","In this work, we argue that in addition to these algorithmic choices, we also require a well aligned dataset of real/fake images to train a robust detector.","For the family of LDMs, we propose a very simple way to achieve this: we reconstruct all the real images using the LDMs autoencoder, without any denoising operation.","We then train a model to separate these real images from their reconstructions.","The fakes created this way are extremely similar to the real ones in almost every aspect (e.g., size, aspect ratio, semantic content), which forces the model to look for the LDM decoders artifacts.","We empirically show that this way of creating aligned real/fake datasets, which also sidesteps the computationally expensive denoising process, helps in building a detector that focuses less on spurious correlations, something that a very popular existing method is susceptible to.","Finally, to demonstrate just how effective the alignment in a dataset can be, we build a detector using images that are not natural objects, and present promising results.","Overall, our work identifies the subtle but significant issues that arise when training a fake image detector and proposes a simple and inexpensive solution to address these problems."],"url":"http://arxiv.org/abs/2410.11835v1"}
{"created":"2024-10-15 17:58:04","title":"Contrastive Touch-to-Touch Pretraining","abstract":"Today's tactile sensors have a variety of different designs, making it challenging to develop general-purpose methods for processing touch signals. In this paper, we learn a unified representation that captures the shared information between different tactile sensors. Unlike current approaches that focus on reconstruction or task-specific supervision, we leverage contrastive learning to integrate tactile signals from two different sensors into a shared embedding space, using a dataset in which the same objects are probed with multiple sensors. We apply this approach to paired touch signals from GelSlim and Soft Bubble sensors. We show that our learned features provide strong pretraining for downstream pose estimation and classification tasks. We also show that our embedding enables models trained using one touch sensor to be deployed using another without additional training. Project details can be found at https://www.mmintlab.com/research/cttp/.","sentences":["Today's tactile sensors have a variety of different designs, making it challenging to develop general-purpose methods for processing touch signals.","In this paper, we learn a unified representation that captures the shared information between different tactile sensors.","Unlike current approaches that focus on reconstruction or task-specific supervision, we leverage contrastive learning to integrate tactile signals from two different sensors into a shared embedding space, using a dataset in which the same objects are probed with multiple sensors.","We apply this approach to paired touch signals from GelSlim and Soft Bubble sensors.","We show that our learned features provide strong pretraining for downstream pose estimation and classification tasks.","We also show that our embedding enables models trained using one touch sensor to be deployed using another without additional training.","Project details can be found at https://www.mmintlab.com/research/cttp/."],"url":"http://arxiv.org/abs/2410.11834v1"}
{"created":"2024-10-15 17:58:03","title":"Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions","abstract":"In reinforcement learning, off-policy actor-critic approaches like DDPG and TD3 are based on the deterministic policy gradient. Herein, the Q-function is trained from off-policy environment data and the actor (policy) is trained to maximize the Q-function via gradient ascent. We observe that in complex tasks like dexterous manipulation and restricted locomotion, the Q-value is a complex function of action, having several local optima or discontinuities. This poses a challenge for gradient ascent to traverse and makes the actor prone to get stuck at local optima. To address this, we introduce a new actor architecture that combines two simple insights: (i) use multiple actors and evaluate the Q-value maximizing action, and (ii) learn surrogates to the Q-function that are simpler to optimize with gradient-based methods. We evaluate tasks such as restricted locomotion, dexterous manipulation, and large discrete-action space recommender systems and show that our actor finds optimal actions more frequently and outperforms alternate actor architectures.","sentences":["In reinforcement learning, off-policy actor-critic approaches like DDPG and TD3 are based on the deterministic policy gradient.","Herein, the Q-function is trained from off-policy environment data and the actor (policy) is trained to maximize the Q-function via gradient ascent.","We observe that in complex tasks like dexterous manipulation and restricted locomotion, the Q-value is a complex function of action, having several local optima or discontinuities.","This poses a challenge for gradient ascent to traverse and makes the actor prone to get stuck at local optima.","To address this, we introduce a new actor architecture that combines two simple insights: (i) use multiple actors and evaluate the Q-value maximizing action, and (ii) learn surrogates to the Q-function that are simpler to optimize with gradient-based methods.","We evaluate tasks such as restricted locomotion, dexterous manipulation, and large discrete-action space recommender systems and show that our actor finds optimal actions more frequently and outperforms alternate actor architectures."],"url":"http://arxiv.org/abs/2410.11833v1"}
{"created":"2024-10-15 17:56:32","title":"CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos","abstract":"Most state-of-the-art point trackers are trained on synthetic data due to the difficulty of annotating real videos for this task. However, this can result in suboptimal performance due to the statistical gap between synthetic and real videos. In order to understand these issues better, we introduce CoTracker3, comprising a new tracking model and a new semi-supervised training recipe. This allows real videos without annotations to be used during training by generating pseudo-labels using off-the-shelf teachers. The new model eliminates or simplifies components from previous trackers, resulting in a simpler and often smaller architecture. This training scheme is much simpler than prior work and achieves better results using 1,000 times less data. We further study the scaling behaviour to understand the impact of using more real unsupervised data in point tracking. The model is available in online and offline variants and reliably tracks visible and occluded points.","sentences":["Most state-of-the-art point trackers are trained on synthetic data due to the difficulty of annotating real videos for this task.","However, this can result in suboptimal performance due to the statistical gap between synthetic and real videos.","In order to understand these issues better, we introduce CoTracker3, comprising a new tracking model and a new semi-supervised training recipe.","This allows real videos without annotations to be used during training by generating pseudo-labels using off-the-shelf teachers.","The new model eliminates or simplifies components from previous trackers, resulting in a simpler and often smaller architecture.","This training scheme is much simpler than prior work and achieves better results using 1,000 times less data.","We further study the scaling behaviour to understand the impact of using more real unsupervised data in point tracking.","The model is available in online and offline variants and reliably tracks visible and occluded points."],"url":"http://arxiv.org/abs/2410.11831v1"}
{"created":"2024-10-15 17:55:22","title":"MMFuser: Multimodal Multi-Layer Feature Fuser for Fine-Grained Vision-Language Understanding","abstract":"Despite significant advancements in Multimodal Large Language Models (MLLMs) for understanding complex human intentions through cross-modal interactions, capturing intricate image details remains challenging. Previous methods integrating multiple vision encoders to enhance visual detail introduce redundancy and computational overhead. We observe that most MLLMs utilize only the last-layer feature map of the vision encoder for visual representation, neglecting the rich fine-grained information in shallow feature maps. To address this issue, we propose \\modelname, a simple yet effective multi-layer feature fuser that efficiently integrates deep and shallow features from Vision Transformers (ViTs). Specifically, it leverages semantically aligned deep features as queries to dynamically extract missing details from shallow features, thus preserving semantic alignment while enriching the representation with fine-grained information. Applied to the LLaVA-1.5 model, \\modelname~achieves significant improvements in visual representation and benchmark performance, providing a more flexible and lightweight solution compared to multi-encoder ensemble methods. The code and model have been released at https://github.com/yuecao0119/MMFuser.","sentences":["Despite significant advancements in Multimodal Large Language Models (MLLMs) for understanding complex human intentions through cross-modal interactions, capturing intricate image details remains challenging.","Previous methods integrating multiple vision encoders to enhance visual detail introduce redundancy and computational overhead.","We observe that most MLLMs utilize only the last-layer feature map of the vision encoder for visual representation, neglecting the rich fine-grained information in shallow feature maps.","To address this issue, we propose \\modelname, a simple yet effective multi-layer feature fuser that efficiently integrates deep and shallow features from Vision Transformers (ViTs).","Specifically, it leverages semantically aligned deep features as queries to dynamically extract missing details from shallow features, thus preserving semantic alignment while enriching the representation with fine-grained information.","Applied to the LLaVA-1.5 model, \\modelname~achieves significant improvements in visual representation and benchmark performance, providing a more flexible and lightweight solution compared to multi-encoder ensemble methods.","The code and model have been released at https://github.com/yuecao0119/MMFuser."],"url":"http://arxiv.org/abs/2410.11829v1"}
{"created":"2024-10-15 17:53:25","title":"Analysis and Benchmarking of Extending Blind Face Image Restoration to Videos","abstract":"Recent progress in blind face restoration has resulted in producing high-quality restored results for static images. However, efforts to extend these advancements to video scenarios have been minimal, partly because of the absence of benchmarks that allow for a comprehensive and fair comparison. In this work, we first present a fair evaluation benchmark, in which we first introduce a Real-world Low-Quality Face Video benchmark (RFV-LQ), evaluate several leading image-based face restoration algorithms, and conduct a thorough systematical analysis of the benefits and challenges associated with extending blind face image restoration algorithms to degraded face videos. Our analysis identifies several key issues, primarily categorized into two aspects: significant jitters in facial components and noise-shape flickering between frames. To address these issues, we propose a Temporal Consistency Network (TCN) cooperated with alignment smoothing to reduce jitters and flickers in restored videos. TCN is a flexible component that can be seamlessly plugged into the most advanced face image restoration algorithms, ensuring the quality of image-based restoration is maintained as closely as possible. Extensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposed TCN and alignment smoothing operation. Project page: https://wzhouxiff.github.io/projects/FIR2FVR/FIR2FVR.","sentences":["Recent progress in blind face restoration has resulted in producing high-quality restored results for static images.","However, efforts to extend these advancements to video scenarios have been minimal, partly because of the absence of benchmarks that allow for a comprehensive and fair comparison.","In this work, we first present a fair evaluation benchmark, in which we first introduce a Real-world Low-Quality Face Video benchmark (RFV-LQ), evaluate several leading image-based face restoration algorithms, and conduct a thorough systematical analysis of the benefits and challenges associated with extending blind face image restoration algorithms to degraded face videos.","Our analysis identifies several key issues, primarily categorized into two aspects: significant jitters in facial components and noise-shape flickering between frames.","To address these issues, we propose a Temporal Consistency Network (TCN) cooperated with alignment smoothing to reduce jitters and flickers in restored videos.","TCN is a flexible component that can be seamlessly plugged into the most advanced face image restoration algorithms, ensuring the quality of image-based restoration is maintained as closely as possible.","Extensive experiments have been conducted to evaluate the effectiveness and efficiency of our proposed TCN and alignment smoothing operation.","Project page: https://wzhouxiff.github.io/projects/FIR2FVR/FIR2FVR."],"url":"http://arxiv.org/abs/2410.11828v1"}
{"created":"2024-10-15 17:52:20","title":"Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies","abstract":"Reinforcement learning combined with sim-to-real transfer offers a general framework for developing locomotion controllers for legged robots. To facilitate successful deployment in the real world, smoothing techniques, such as low-pass filters and smoothness rewards, are often employed to develop policies with smooth behaviors. However, because these techniques are non-differentiable and usually require tedious tuning of a large set of hyperparameters, they tend to require extensive manual tuning for each robotic platform. To address this challenge and establish a general technique for enforcing smooth behaviors, we propose a simple and effective method that imposes a Lipschitz constraint on a learned policy, which we refer to as Lipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint can be implemented in the form of a gradient penalty, which provides a differentiable objective that can be easily incorporated with automatic differentiation frameworks. We demonstrate that LCP effectively replaces the need for smoothing rewards or low-pass filters and can be easily integrated into training frameworks for many distinct humanoid robots. We extensively evaluate LCP in both simulation and real-world humanoid robots, producing smooth and robust locomotion controllers. All simulation and deployment code, along with complete checkpoints, is available on our project page: https://lipschitz-constrained-policy.github.io.","sentences":["Reinforcement learning combined with sim-to-real transfer offers a general framework for developing locomotion controllers for legged robots.","To facilitate successful deployment in the real world, smoothing techniques, such as low-pass filters and smoothness rewards, are often employed to develop policies with smooth behaviors.","However, because these techniques are non-differentiable and usually require tedious tuning of a large set of hyperparameters, they tend to require extensive manual tuning for each robotic platform.","To address this challenge and establish a general technique for enforcing smooth behaviors, we propose a simple and effective method that imposes a Lipschitz constraint on a learned policy, which we refer to as Lipschitz-Constrained Policies (LCP).","We show that the Lipschitz constraint can be implemented in the form of a gradient penalty, which provides a differentiable objective that can be easily incorporated with automatic differentiation frameworks.","We demonstrate that LCP effectively replaces the need for smoothing rewards or low-pass filters and can be easily integrated into training frameworks for many distinct humanoid robots.","We extensively evaluate LCP in both simulation and real-world humanoid robots, producing smooth and robust locomotion controllers.","All simulation and deployment code, along with complete checkpoints, is available on our project page: https://lipschitz-constrained-policy.github.io."],"url":"http://arxiv.org/abs/2410.11825v1"}
{"created":"2024-10-15 17:50:37","title":"KITTEN: A Knowledge-Intensive Evaluation of Image Generation on Visual Entities","abstract":"Recent advancements in text-to-image generation have significantly enhanced the quality of synthesized images. Despite this progress, evaluations predominantly focus on aesthetic appeal or alignment with text prompts. Consequently, there is limited understanding of whether these models can accurately represent a wide variety of realistic visual entities - a task requiring real-world knowledge. To address this gap, we propose a benchmark focused on evaluating Knowledge-InTensive image generaTion on real-world ENtities (i.e., KITTEN). Using KITTEN, we conduct a systematic study on the fidelity of entities in text-to-image generation models, focusing on their ability to generate a wide range of real-world visual entities, such as landmark buildings, aircraft, plants, and animals. We evaluate the latest text-to-image models and retrieval-augmented customization models using both automatic metrics and carefully-designed human evaluations, with an emphasis on the fidelity of entities in the generated images. Our findings reveal that even the most advanced text-to-image models often fail to generate entities with accurate visual details. Although retrieval-augmented models can enhance the fidelity of entity by incorporating reference images during testing, they often over-rely on these references and struggle to produce novel configurations of the entity as requested in creative text prompts.","sentences":["Recent advancements in text-to-image generation have significantly enhanced the quality of synthesized images.","Despite this progress, evaluations predominantly focus on aesthetic appeal or alignment with text prompts.","Consequently, there is limited understanding of whether these models can accurately represent a wide variety of realistic visual entities - a task requiring real-world knowledge.","To address this gap, we propose a benchmark focused on evaluating Knowledge-InTensive image generaTion on real-world ENtities (i.e., KITTEN).","Using KITTEN, we conduct a systematic study on the fidelity of entities in text-to-image generation models, focusing on their ability to generate a wide range of real-world visual entities, such as landmark buildings, aircraft, plants, and animals.","We evaluate the latest text-to-image models and retrieval-augmented customization models using both automatic metrics and carefully-designed human evaluations, with an emphasis on the fidelity of entities in the generated images.","Our findings reveal that even the most advanced text-to-image models often fail to generate entities with accurate visual details.","Although retrieval-augmented models can enhance the fidelity of entity by incorporating reference images during testing, they often over-rely on these references and struggle to produce novel configurations of the entity as requested in creative text prompts."],"url":"http://arxiv.org/abs/2410.11824v1"}
{"created":"2024-10-15 17:47:44","title":"Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws","abstract":"The composition of pretraining data is a key determinant of foundation models' performance, but there is no standard guideline for allocating a limited computational budget across different data sources. Most current approaches either rely on extensive experiments with smaller models or dynamic data adjustments that also require proxy models, both of which significantly increase the workflow complexity and computational overhead. In this paper, we introduce Adaptive Data Optimization (ADO), an algorithm that optimizes data distributions in an online fashion, concurrent with model training. Unlike existing techniques, ADO does not require external knowledge, proxy models, or modifications to the model update. Instead, ADO uses per-domain scaling laws to estimate the learning potential of each domain during training and adjusts the data mixture accordingly, making it more scalable and easier to integrate. Experiments demonstrate that ADO can achieve comparable or better performance than prior methods while maintaining computational efficiency across different computation scales, offering a practical solution for dynamically adjusting data distribution without sacrificing flexibility or increasing costs. Beyond its practical benefits, ADO also provides a new perspective on data collection strategies via scaling laws.","sentences":["The composition of pretraining data is a key determinant of foundation models' performance, but there is no standard guideline for allocating a limited computational budget across different data sources.","Most current approaches either rely on extensive experiments with smaller models or dynamic data adjustments that also require proxy models, both of which significantly increase the workflow complexity and computational overhead.","In this paper, we introduce Adaptive Data Optimization (ADO), an algorithm that optimizes data distributions in an online fashion, concurrent with model training.","Unlike existing techniques, ADO does not require external knowledge, proxy models, or modifications to the model update.","Instead, ADO uses per-domain scaling laws to estimate the learning potential of each domain during training and adjusts the data mixture accordingly, making it more scalable and easier to integrate.","Experiments demonstrate that ADO can achieve comparable or better performance than prior methods while maintaining computational efficiency across different computation scales, offering a practical solution for dynamically adjusting data distribution without sacrificing flexibility or increasing costs.","Beyond its practical benefits, ADO also provides a new perspective on data collection strategies via scaling laws."],"url":"http://arxiv.org/abs/2410.11820v1"}
{"created":"2024-10-15 17:46:31","title":"Improving Long-Text Alignment for Text-to-Image Diffusion Models","abstract":"The rapid advancement of text-to-image (T2I) diffusion models has enabled them to generate unprecedented results from given texts. However, as text inputs become longer, existing encoding methods like CLIP face limitations, and aligning the generated images with long texts becomes challenging. To tackle these issues, we propose LongAlign, which includes a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training. For segment-level encoding, long texts are divided into multiple segments and processed separately. This method overcomes the maximum input length limits of pretrained encoding models. For preference optimization, we provide decomposed CLIP-based preference models to fine-tune diffusion models. Specifically, to utilize CLIP-based preference models for T2I alignment, we delve into their scoring mechanisms and find that the preference scores can be decomposed into two components: a text-relevant part that measures T2I alignment and a text-irrelevant part that assesses other visual aspects of human preference. Additionally, we find that the text-irrelevant part contributes to a common overfitting problem during fine-tuning. To address this, we propose a reweighting strategy that assigns different weights to these two components, thereby reducing overfitting and enhancing alignment. After fine-tuning $512 \\times 512$ Stable Diffusion (SD) v1.5 for about 20 hours using our method, the fine-tuned SD outperforms stronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and Kandinsky v2.2. The code is available at https://github.com/luping-liu/LongAlign.","sentences":["The rapid advancement of text-to-image (T2I) diffusion models has enabled them to generate unprecedented results from given texts.","However, as text inputs become longer, existing encoding methods like CLIP face limitations, and aligning the generated images with long texts becomes challenging.","To tackle these issues, we propose LongAlign, which includes a segment-level encoding method for processing long texts and a decomposed preference optimization method for effective alignment training.","For segment-level encoding, long texts are divided into multiple segments and processed separately.","This method overcomes the maximum input length limits of pretrained encoding models.","For preference optimization, we provide decomposed CLIP-based preference models to fine-tune diffusion models.","Specifically, to utilize CLIP-based preference models for T2I alignment, we delve into their scoring mechanisms and find that the preference scores can be decomposed into two components: a text-relevant part that measures T2I alignment and a text-irrelevant part that assesses other visual aspects of human preference.","Additionally, we find that the text-irrelevant part contributes to a common overfitting problem during fine-tuning.","To address this, we propose a reweighting strategy that assigns different weights to these two components, thereby reducing overfitting and enhancing alignment.","After fine-tuning $512 \\times 512$ Stable Diffusion (SD) v1.5 for about 20 hours using our method, the fine-tuned SD outperforms stronger foundation models in T2I alignment, such as PixArt-$\\alpha$ and Kandinsky v2.2.","The code is available at https://github.com/luping-liu/LongAlign."],"url":"http://arxiv.org/abs/2410.11817v1"}
{"created":"2024-10-15 17:45:37","title":"Jigsaw++: Imagining Complete Shape Priors for Object Reassembly","abstract":"The automatic assembly problem has attracted increasing interest due to its complex challenges that involve 3D representation. This paper introduces Jigsaw++, a novel generative method designed to tackle the multifaceted challenges of reconstruction for the reassembly problem. Existing approach focusing primarily on piecewise information for both part and fracture assembly, often overlooking the integration of complete object prior. Jigsaw++ distinguishes itself by learning a category-agnostic shape prior of complete objects. It employs the proposed \"retargeting\" strategy that effectively leverages the output of any existing assembly method to generate complete shape reconstructions. This capability allows it to function orthogonally to the current methods. Through extensive evaluations on Breaking Bad dataset and PartNet, Jigsaw++ has demonstrated its effectiveness, reducing reconstruction errors and enhancing the precision of shape reconstruction, which sets a new direction for future reassembly model developments.","sentences":["The automatic assembly problem has attracted increasing interest due to its complex challenges that involve 3D representation.","This paper introduces Jigsaw++, a novel generative method designed to tackle the multifaceted challenges of reconstruction for the reassembly problem.","Existing approach focusing primarily on piecewise information for both part and fracture assembly, often overlooking the integration of complete object prior.","Jigsaw++ distinguishes itself by learning a category-agnostic shape prior of complete objects.","It employs the proposed \"retargeting\" strategy that effectively leverages the output of any existing assembly method to generate complete shape reconstructions.","This capability allows it to function orthogonally to the current methods.","Through extensive evaluations on Breaking Bad dataset and PartNet, Jigsaw++ has demonstrated its effectiveness, reducing reconstruction errors and enhancing the precision of shape reconstruction, which sets a new direction for future reassembly model developments."],"url":"http://arxiv.org/abs/2410.11816v1"}
{"created":"2024-10-15 17:40:48","title":"SGEdit: Bridging LLM with Text2Image Generative Model for Scene Graph-based Image Editing","abstract":"Scene graphs offer a structured, hierarchical representation of images, with nodes and edges symbolizing objects and the relationships among them. It can serve as a natural interface for image editing, dramatically improving precision and flexibility. Leveraging this benefit, we introduce a new framework that integrates large language model (LLM) with Text2Image generative model for scene graph-based image editing. This integration enables precise modifications at the object level and creative recomposition of scenes without compromising overall image integrity. Our approach involves two primary stages: 1) Utilizing a LLM-driven scene parser, we construct an image's scene graph, capturing key objects and their interrelationships, as well as parsing fine-grained attributes such as object masks and descriptions. These annotations facilitate concept learning with a fine-tuned diffusion model, representing each object with an optimized token and detailed description prompt. 2) During the image editing phase, a LLM editing controller guides the edits towards specific areas. These edits are then implemented by an attention-modulated diffusion editor, utilizing the fine-tuned model to perform object additions, deletions, replacements, and adjustments. Through extensive experiments, we demonstrate that our framework significantly outperforms existing image editing methods in terms of editing precision and scene aesthetics.","sentences":["Scene graphs offer a structured, hierarchical representation of images, with nodes and edges symbolizing objects and the relationships among them.","It can serve as a natural interface for image editing, dramatically improving precision and flexibility.","Leveraging this benefit, we introduce a new framework that integrates large language model (LLM) with Text2Image generative model for scene graph-based image editing.","This integration enables precise modifications at the object level and creative recomposition of scenes without compromising overall image integrity.","Our approach involves two primary stages: 1) Utilizing a LLM-driven scene parser, we construct an image's scene graph, capturing key objects and their interrelationships, as well as parsing fine-grained attributes such as object masks and descriptions.","These annotations facilitate concept learning with a fine-tuned diffusion model, representing each object with an optimized token and detailed description prompt.","2) During the image editing phase, a LLM editing controller guides the edits towards specific areas.","These edits are then implemented by an attention-modulated diffusion editor, utilizing the fine-tuned model to perform object additions, deletions, replacements, and adjustments.","Through extensive experiments, we demonstrate that our framework significantly outperforms existing image editing methods in terms of editing precision and scene aesthetics."],"url":"http://arxiv.org/abs/2410.11815v1"}
{"created":"2024-10-15 17:35:57","title":"Practices and Challenges of Online Love-seeking Among Deaf or Hard of Hearing People: A Case Study in China","abstract":"People who are deaf or hard of hearing (DHH) in China are increasingly exploring online platforms to connect with potential partners. This research explores the online dating experiences of DHH communities in China, an area that has not been extensively researched. We interviewed sixteen participants who have varying levels of hearing ability and love-seeking statuses to understand how they manage their identities and communicate with potential partners online. We find that DHH individuals made great efforts to navigate the rich modality features to seek love online. Participants used both algorithm-based dating apps and community-based platforms like forums and WeChat to facilitate initial encounters through text-based functions that minimized the need for auditory interaction, thus fostering a more equitable starting point. Community-based platforms were found to facilitate more in-depth communication and excelled in fostering trust and authenticity, providing a more secure environment for genuine relationships. Design recommendations are proposed to enhance the accessibility and inclusiveness of online dating platforms for DHH individuals in China. This research sheds light on the benefits and challenges of online dating for DHH individuals in China and provides guidance for platform developers and researchers to enhance user experience in this area.","sentences":["People who are deaf or hard of hearing (DHH) in China are increasingly exploring online platforms to connect with potential partners.","This research explores the online dating experiences of DHH communities in China, an area that has not been extensively researched.","We interviewed sixteen participants who have varying levels of hearing ability and love-seeking statuses to understand how they manage their identities and communicate with potential partners online.","We find that DHH individuals made great efforts to navigate the rich modality features to seek love online.","Participants used both algorithm-based dating apps and community-based platforms like forums and WeChat to facilitate initial encounters through text-based functions that minimized the need for auditory interaction, thus fostering a more equitable starting point.","Community-based platforms were found to facilitate more in-depth communication and excelled in fostering trust and authenticity, providing a more secure environment for genuine relationships.","Design recommendations are proposed to enhance the accessibility and inclusiveness of online dating platforms for DHH individuals in China.","This research sheds light on the benefits and challenges of online dating for DHH individuals in China and provides guidance for platform developers and researchers to enhance user experience in this area."],"url":"http://arxiv.org/abs/2410.11810v1"}
{"created":"2024-10-15 17:33:43","title":"NesTools: A Dataset for Evaluating Nested Tool Learning Abilities of Large Language Models","abstract":"Large language models (LLMs) combined with tool learning have gained impressive results in real-world applications. During tool learning, LLMs may call multiple tools in nested orders, where the latter tool call may take the former response as its input parameters. However, current research on the nested tool learning capabilities is still under-explored, since the existing benchmarks lack of relevant data instances. To address this problem, we introduce NesTools to bridge the current gap in comprehensive nested tool learning evaluations. NesTools comprises a novel automatic data generation method to construct large-scale nested tool calls with different nesting structures. With manual review and refinement, the dataset is in high quality and closely aligned with real-world scenarios. Therefore, NesTools can serve as a new benchmark to evaluate the nested tool learning abilities of LLMs. We conduct extensive experiments on 22 LLMs, and provide in-depth analyses with NesTools, which shows that current LLMs still suffer from the complex nested tool learning task.","sentences":["Large language models (LLMs) combined with tool learning have gained impressive results in real-world applications.","During tool learning, LLMs may call multiple tools in nested orders, where the latter tool call may take the former response as its input parameters.","However, current research on the nested tool learning capabilities is still under-explored, since the existing benchmarks lack of relevant data instances.","To address this problem, we introduce NesTools to bridge the current gap in comprehensive nested tool learning evaluations.","NesTools comprises a novel automatic data generation method to construct large-scale nested tool calls with different nesting structures.","With manual review and refinement, the dataset is in high quality and closely aligned with real-world scenarios.","Therefore, NesTools can serve as a new benchmark to evaluate the nested tool learning abilities of LLMs.","We conduct extensive experiments on 22 LLMs, and provide in-depth analyses with NesTools, which shows that current LLMs still suffer from the complex nested tool learning task."],"url":"http://arxiv.org/abs/2410.11805v1"}
{"created":"2024-10-15 17:24:58","title":"An incremental exact algorithm for the hyper-rectangular clustering problem with axis-parallel clusters","abstract":"We address the problem of clustering a set of points in $\\mathbb{R}^d$ with axis-parallel clusters. Previous exact approaches to this problem are mostly based on integer programming formulations and can only solve to optimality instances of small size. In this work we propose an adaptive exact strategy which takes advantage of the capacity to solve small instances to optimality of previous approaches. Our algorithm starts by solving an instance with a small subset of points and iteratively adds more points if these are not covered by the obtained solution. We prove that as soon as a solution covers the whole set of point from the instance, then the solution is actually an optimal solution for the original problem. We compare the efficiency of the new method against the existing ones with an exhaustive computational experimentation in which we show that the new approach is able to solve to optimality instances of higher orders of magnitude.","sentences":["We address the problem of clustering a set of points in $\\mathbb{R}^d$ with axis-parallel clusters.","Previous exact approaches to this problem are mostly based on integer programming formulations and can only solve to optimality instances of small size.","In this work we propose an adaptive exact strategy which takes advantage of the capacity to solve small instances to optimality of previous approaches.","Our algorithm starts by solving an instance with a small subset of points and iteratively adds more points if these are not covered by the obtained solution.","We prove that as soon as a solution covers the whole set of point from the instance, then the solution is actually an optimal solution for the original problem.","We compare the efficiency of the new method against the existing ones with an exhaustive computational experimentation in which we show that the new approach is able to solve to optimality instances of higher orders of magnitude."],"url":"http://arxiv.org/abs/2410.11803v1"}
{"created":"2024-10-15 17:23:49","title":"FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting","abstract":"Time Series Forecasting (TSF) is key functionality in numerous fields, including in finance, weather services, and energy management. While TSF methods are emerging these days, many of them require domain-specific data collection and model training and struggle with poor generalization performance on new domains. Foundation models aim to overcome this limitation. Pre-trained on large-scale language or time series data, they exhibit promising inferencing capabilities in new or unseen data. This has spurred a surge in new TSF foundation models. We propose a new benchmark, FoundTS, to enable thorough and fair evaluation and comparison of such models. FoundTS covers a variety of TSF foundation models, including those based on large language models and those pretrained on time series. Next, FoundTS supports different forecasting strategies, including zero-shot, few-shot, and full-shot, thereby facilitating more thorough evaluations. Finally, FoundTS offers a pipeline that standardizes evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, thereby facilitating fair evaluations. Building on this, we report on an extensive evaluation of TSF foundation models on a broad range of datasets from diverse domains and with different statistical characteristics. Specifically, we identify pros and cons and inherent limitations of existing foundation models, and we identify directions for future model design. We make our code and datasets available at https://anonymous.4open.science/r/FoundTS-C2B0.","sentences":["Time Series Forecasting (TSF) is key functionality in numerous fields, including in finance, weather services, and energy management.","While TSF methods are emerging these days, many of them require domain-specific data collection and model training and struggle with poor generalization performance on new domains.","Foundation models aim to overcome this limitation.","Pre-trained on large-scale language or time series data, they exhibit promising inferencing capabilities in new or unseen data.","This has spurred a surge in new TSF foundation models.","We propose a new benchmark, FoundTS, to enable thorough and fair evaluation and comparison of such models.","FoundTS covers a variety of TSF foundation models, including those based on large language models and those pretrained on time series.","Next, FoundTS supports different forecasting strategies, including zero-shot, few-shot, and full-shot, thereby facilitating more thorough evaluations.","Finally, FoundTS offers a pipeline that standardizes evaluation processes such as dataset splitting, loading, normalization, and few-shot sampling, thereby facilitating fair evaluations.","Building on this, we report on an extensive evaluation of TSF foundation models on a broad range of datasets from diverse domains and with different statistical characteristics.","Specifically, we identify pros and cons and inherent limitations of existing foundation models, and we identify directions for future model design.","We make our code and datasets available at https://anonymous.4open.science/r/FoundTS-C2B0."],"url":"http://arxiv.org/abs/2410.11802v1"}
{"created":"2024-10-15 17:21:07","title":"Adaptive Ankle Torque Control for Bipedal Humanoid Walking on Surfaces with Unknown Horizontal and Vertical Motion","abstract":"Achieving stable bipedal walking on surfaces with unknown motion remains a challenging control problem due to the hybrid, time-varying, partially unknown dynamics of the robot and the difficulty of accurate state and surface motion estimation. Surface motion imposes uncertainty on both system parameters and non-homogeneous disturbance in the walking robot dynamics. In this paper, we design an adaptive ankle torque controller to simultaneously address these two uncertainties and propose a step-length planner to minimize the required control torque. Typically, an adaptive controller is used for a continuous system. To apply adaptive control on a hybrid system such as a walking robot, an intermediate command profile is introduced to ensure a continuous error system. Simulations on a planar bipedal robot, along with comparisons against a baseline controller, demonstrate that the proposed approach effectively ensures stable walking and accurate tracking under unknown, time-varying disturbances.","sentences":["Achieving stable bipedal walking on surfaces with unknown motion remains a challenging control problem due to the hybrid, time-varying, partially unknown dynamics of the robot and the difficulty of accurate state and surface motion estimation.","Surface motion imposes uncertainty on both system parameters and non-homogeneous disturbance in the walking robot dynamics.","In this paper, we design an adaptive ankle torque controller to simultaneously address these two uncertainties and propose a step-length planner to minimize the required control torque.","Typically, an adaptive controller is used for a continuous system.","To apply adaptive control on a hybrid system such as a walking robot, an intermediate command profile is introduced to ensure a continuous error system.","Simulations on a planar bipedal robot, along with comparisons against a baseline controller, demonstrate that the proposed approach effectively ensures stable walking and accurate tracking under unknown, time-varying disturbances."],"url":"http://arxiv.org/abs/2410.11799v1"}
{"created":"2024-10-15 17:20:57","title":"Majorized Bayesian Persuasion and Fair Selection","abstract":"We address the fundamental problem of selection under uncertainty by modeling it from the perspective of Bayesian persuasion. In our model, a decision maker with imperfect information always selects the option with the highest expected value. We seek to achieve fairness among the options by revealing additional information to the decision maker and hence influencing its subsequent selection. To measure fairness, we adopt the notion of majorization, aiming at simultaneously approximately maximizing all symmetric, monotone, concave functions over the utilities of the options. As our main result, we design a novel information revelation policy that achieves a logarithmic-approximation to majorization in polynomial time. On the other hand, no policy, regardless of its running time, can achieve a constant-approximation to majorization. Our work is the first non-trivial majorization result in the Bayesian persuasion literature with multi-dimensional information sets.","sentences":["We address the fundamental problem of selection under uncertainty by modeling it from the perspective of Bayesian persuasion.","In our model, a decision maker with imperfect information always selects the option with the highest expected value.","We seek to achieve fairness among the options by revealing additional information to the decision maker and hence influencing its subsequent selection.","To measure fairness, we adopt the notion of majorization, aiming at simultaneously approximately maximizing all symmetric, monotone, concave functions over the utilities of the options.","As our main result, we design a novel information revelation policy that achieves a logarithmic-approximation to majorization in polynomial time.","On the other hand, no policy, regardless of its running time, can achieve a constant-approximation to majorization.","Our work is the first non-trivial majorization result in the Bayesian persuasion literature with multi-dimensional information sets."],"url":"http://arxiv.org/abs/2410.11798v1"}
{"created":"2024-10-15 17:19:46","title":"Efficient Diffusion Models: A Comprehensive Survey from Principles to Practices","abstract":"As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and multimodal generation, relying on their dense theoretical principles and reliable application practices. The remarkable success of these recent efforts on diffusion models comes largely from progressive design principles and efficient architecture, training, inference, and deployment methodologies. However, there has not been a comprehensive and in-depth review to summarize these principles and practices to help the rapid understanding and application of diffusion models. In this survey, we provide a new efficiency-oriented perspective on these existing efforts, which mainly focuses on the profound principles and efficient practices in architecture designs, model training, fast inference and reliable deployment, to guide further theoretical research, algorithm migration and model application for new scenarios in a reader-friendly way. \\url{https://github.com/ponyzym/Efficient-DMs-Survey}","sentences":["As one of the most popular and sought-after generative models in the recent years, diffusion models have sparked the interests of many researchers and steadily shown excellent advantage in various generative tasks such as image synthesis, video generation, molecule design, 3D scene rendering and multimodal generation, relying on their dense theoretical principles and reliable application practices.","The remarkable success of these recent efforts on diffusion models comes largely from progressive design principles and efficient architecture, training, inference, and deployment methodologies.","However, there has not been a comprehensive and in-depth review to summarize these principles and practices to help the rapid understanding and application of diffusion models.","In this survey, we provide a new efficiency-oriented perspective on these existing efforts, which mainly focuses on the profound principles and efficient practices in architecture designs, model training, fast inference and reliable deployment, to guide further theoretical research, algorithm migration and model application for new scenarios in a reader-friendly way.","\\url{https://github.com/ponyzym/Efficient-DMs-Survey}"],"url":"http://arxiv.org/abs/2410.11795v1"}
{"created":"2024-10-15 17:17:54","title":"OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation","abstract":"We study the problem of teaching humanoid robots manipulation skills by imitating from single video demonstrations. We introduce OKAMI, a method that generates a manipulation plan from a single RGB-D video and derives a policy for execution. At the heart of our approach is object-aware retargeting, which enables the humanoid robot to mimic the human motions in an RGB-D video while adjusting to different object locations during deployment. OKAMI uses open-world vision models to identify task-relevant objects and retarget the body motions and hand poses separately. Our experiments show that OKAMI achieves strong generalizations across varying visual and spatial conditions, outperforming the state-of-the-art baseline on open-world imitation from observation. Furthermore, OKAMI rollout trajectories are leveraged to train closed-loop visuomotor policies, which achieve an average success rate of 79.2% without the need for labor-intensive teleoperation. More videos can be found on our website https://ut-austin-rpl.github.io/OKAMI/.","sentences":["We study the problem of teaching humanoid robots manipulation skills by imitating from single video demonstrations.","We introduce OKAMI, a method that generates a manipulation plan from a single RGB-D video and derives a policy for execution.","At the heart of our approach is object-aware retargeting, which enables the humanoid robot to mimic the human motions in an RGB-D video while adjusting to different object locations during deployment.","OKAMI uses open-world vision models to identify task-relevant objects and retarget the body motions and hand poses separately.","Our experiments show that OKAMI achieves strong generalizations across varying visual and spatial conditions, outperforming the state-of-the-art baseline on open-world imitation from observation.","Furthermore, OKAMI rollout trajectories are leveraged to train closed-loop visuomotor policies, which achieve an average success rate of 79.2% without the need for labor-intensive teleoperation.","More videos can be found on our website https://ut-austin-rpl.github.io/OKAMI/."],"url":"http://arxiv.org/abs/2410.11792v1"}
{"created":"2024-10-15 17:14:26","title":"End-to-End Mathematical Modeling of Stress Communication Between Plants","abstract":"Molecular Communication (MC) is an important communication paradigm found in nature. Odor-based Molecular Communication (OMC) is a specific type of MC with promising potential and a wide range of applications. In this paper, we examine OMC communication between plants in the context of stress communication. Specifically, we explore how plants use Biological Volatile Organic Compounds (BVOCs) to convey information about the stresses they are experiencing to neighboring plants. We constructed an end-to-end mathematical model that discovers the underlying physical and biological phenomena affecting stress communication. To the best of our knowledge, this is the first study to model this end-to-end stress communication. We numerically analyzed our system under different scenarios using MATLAB. Using experimental data from the literature, we demonstrated that continuous gene regulation can approximate BVOC emissions in plants under different stress conditions. Consequently, we applied this model to these stressors and plants to accurately approximate BVOC emissions. We also investigated a modulation method that plants use to send their messages, namely Ratio Shift Keying. Upon analyzing this method, we found that it benefits plants by both enabling a multiple access channel and preventing competitor plants from obtaining the information.","sentences":["Molecular Communication (MC) is an important communication paradigm found in nature.","Odor-based Molecular Communication (OMC) is a specific type of MC with promising potential and a wide range of applications.","In this paper, we examine OMC communication between plants in the context of stress communication.","Specifically, we explore how plants use Biological Volatile Organic Compounds (BVOCs) to convey information about the stresses they are experiencing to neighboring plants.","We constructed an end-to-end mathematical model that discovers the underlying physical and biological phenomena affecting stress communication.","To the best of our knowledge, this is the first study to model this end-to-end stress communication.","We numerically analyzed our system under different scenarios using MATLAB.","Using experimental data from the literature, we demonstrated that continuous gene regulation can approximate BVOC emissions in plants under different stress conditions.","Consequently, we applied this model to these stressors and plants to accurately approximate BVOC emissions.","We also investigated a modulation method that plants use to send their messages, namely Ratio Shift Keying.","Upon analyzing this method, we found that it benefits plants by both enabling a multiple access channel and preventing competitor plants from obtaining the information."],"url":"http://arxiv.org/abs/2410.11790v1"}
{"created":"2024-10-15 17:05:25","title":"Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability","abstract":"Large Language Models (LLMs) have demonstrated impressive capabilities in a wide range of natural language processing tasks when leveraging in-context learning. To mitigate the additional computational and financial costs associated with in-context learning, several prompt compression methods have been proposed to compress the in-context learning prompts. Despite their success, these methods face challenges with transferability due to model-specific compression, or rely on external training data, such as GPT-4. In this paper, we investigate the ability of LLMs to develop a unified compression method that discretizes uninformative tokens, utilizing a self-supervised pre-training technique. By introducing a small number of parameters during the continual pre-training, the proposed Selection-p produces a probability for each input token, indicating whether to preserve or discard it. Experiments show Selection-p achieves state-of-the-art performance across numerous classification tasks, achieving compression rates of up to 10 times while experiencing only a marginal 0.8% decrease in performance. Moreover, it exhibits superior transferability to different models compared to prior work. Additionally, we further analyze how Selection-p helps maintain performance on in-context learning with long contexts.","sentences":["Large Language Models (LLMs) have demonstrated impressive capabilities in a wide range of natural language processing tasks when leveraging in-context learning.","To mitigate the additional computational and financial costs associated with in-context learning, several prompt compression methods have been proposed to compress the in-context learning prompts.","Despite their success, these methods face challenges with transferability due to model-specific compression, or rely on external training data, such as GPT-4.","In this paper, we investigate the ability of LLMs to develop a unified compression method that discretizes uninformative tokens, utilizing a self-supervised pre-training technique.","By introducing a small number of parameters during the continual pre-training, the proposed Selection-p produces a probability for each input token, indicating whether to preserve or discard it.","Experiments show Selection-p achieves state-of-the-art performance across numerous classification tasks, achieving compression rates of up to 10 times while experiencing only a marginal 0.8% decrease in performance.","Moreover, it exhibits superior transferability to different models compared to prior work.","Additionally, we further analyze how Selection-p helps maintain performance on in-context learning with long contexts."],"url":"http://arxiv.org/abs/2410.11786v1"}
{"created":"2024-10-15 17:02:32","title":"Latent BKI: Open-Dictionary Continuous Mapping in Visual-Language Latent Spaces with Quantifiable Uncertainty","abstract":"This paper introduces a novel probabilistic mapping algorithm, Latent BKI, which enables open-vocabulary mapping with quantifiable uncertainty. Traditionally, semantic mapping algorithms focus on a fixed set of semantic categories which limits their applicability for complex robotic tasks. Vision-Language (VL) models have recently emerged as a technique to jointly model language and visual features in a latent space, enabling semantic recognition beyond a predefined, fixed set of semantic classes. Latent BKI recurrently incorporates neural embeddings from VL models into a voxel map with quantifiable uncertainty, leveraging the spatial correlations of nearby observations through Bayesian Kernel Inference (BKI). Latent BKI is evaluated against similar explicit semantic mapping and VL mapping frameworks on the popular MatterPort-3D and Semantic KITTI data sets, demonstrating that Latent BKI maintains the probabilistic benefits of continuous mapping with the additional benefit of open-dictionary queries. Real-world experiments demonstrate applicability to challenging indoor environments.","sentences":["This paper introduces a novel probabilistic mapping algorithm, Latent BKI, which enables open-vocabulary mapping with quantifiable uncertainty.","Traditionally, semantic mapping algorithms focus on a fixed set of semantic categories which limits their applicability for complex robotic tasks.","Vision-Language (VL) models have recently emerged as a technique to jointly model language and visual features in a latent space, enabling semantic recognition beyond a predefined, fixed set of semantic classes.","Latent BKI recurrently incorporates neural embeddings from VL models into a voxel map with quantifiable uncertainty, leveraging the spatial correlations of nearby observations through Bayesian Kernel Inference (BKI).","Latent BKI is evaluated against similar explicit semantic mapping and VL mapping frameworks on the popular MatterPort-3D and Semantic KITTI data sets, demonstrating that Latent BKI maintains the probabilistic benefits of continuous mapping with the additional benefit of open-dictionary queries.","Real-world experiments demonstrate applicability to challenging indoor environments."],"url":"http://arxiv.org/abs/2410.11783v1"}
{"created":"2024-10-15 17:01:21","title":"G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks","abstract":"Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies. Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?} In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies. Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology. Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at $89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33\\%$ on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3\\%$ accuracy drop.","sentences":["Recent advancements in large language model (LLM)-based agents have demonstrated that collective intelligence can significantly surpass the capabilities of individual agents, primarily due to well-crafted inter-agent communication topologies.","Despite the diverse and high-performing designs available, practitioners often face confusion when selecting the most effective pipeline for their specific task: \\textit{Which topology is the best choice for my task, avoiding unnecessary communication token overhead while ensuring high-quality solution?}","In response to this dilemma, we introduce G-Designer, an adaptive, efficient, and robust solution for multi-agent deployment, which dynamically designs task-aware, customized communication topologies.","Specifically, G-Designer models the multi-agent system as a multi-agent network, leveraging a variational graph auto-encoder to encode both the nodes (agents) and a task-specific virtual node, and decodes a task-adaptive and high-performing communication topology.","Extensive experiments on six benchmarks showcase that G-Designer is: \\textbf{(1) high-performing}, achieving superior results on MMLU with accuracy at $84.50\\%$ and on HumanEval with pass@1 at $89.90\\%$; \\textbf{(2) task-adaptive}, architecting communication protocols tailored to task difficulty, reducing token consumption by up to $95.33\\%$ on HumanEval; and \\textbf{(3) adversarially robust}, defending against agent adversarial attacks with merely $0.3\\%$ accuracy drop."],"url":"http://arxiv.org/abs/2410.11782v1"}
{"created":"2024-10-15 17:00:15","title":"Language Models Encode Numbers Using Digit Representations in Base 10","abstract":"Large language models (LLMs) frequently make errors when handling even simple numerical problems, such as comparing two small numbers. A natural hypothesis is that these errors stem from how LLMs represent numbers, and specifically, whether their representations of numbers capture their numeric values. We tackle this question from the observation that LLM errors on numerical tasks are often distributed across \\textit{the digits} of the answer rather than normally around \\textit{its numeric value}. Through a series of probing experiments and causal interventions, we show that LLMs internally represent numbers with individual circular representations per-digit in base 10. This digit-wise representation, as opposed to a value representation, sheds light on the error patterns of models on tasks involving numerical reasoning and could serve as a basis for future studies on analyzing numerical mechanisms in LLMs.","sentences":["Large language models (LLMs) frequently make errors when handling even simple numerical problems, such as comparing two small numbers.","A natural hypothesis is that these errors stem from how LLMs represent numbers, and specifically, whether their representations of numbers capture their numeric values.","We tackle this question from the observation that LLM errors on numerical tasks are often distributed across \\textit{the digits} of the answer rather than normally around \\textit{its numeric value}.","Through a series of probing experiments and causal interventions, we show that LLMs internally represent numbers with individual circular representations per-digit in base 10.","This digit-wise representation, as opposed to a value representation, sheds light on the error patterns of models on tasks involving numerical reasoning and could serve as a basis for future studies on analyzing numerical mechanisms in LLMs."],"url":"http://arxiv.org/abs/2410.11781v1"}
{"created":"2024-10-15 16:57:44","title":"MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation","abstract":"Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood. In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to recognize visual objects in the preceding layers. We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations. Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (DeCo), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits. Note that DeCo is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs. We evaluate DeCo on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations. Code is available at https://github.com/zjunlp/DeCo.","sentences":["Multimodal Large Language Models (MLLMs) frequently exhibit hallucination phenomena, but the underlying reasons remain poorly understood.","In this paper, we present an empirical analysis and find that, although MLLMs incorrectly generate the objects in the final output, they are actually able to recognize visual objects in the preceding layers.","We speculate that this may be due to the strong knowledge priors of the language model suppressing the visual information, leading to hallucinations.","Motivated by this, we propose a novel dynamic correction decoding method for MLLMs (DeCo), which adaptively selects the appropriate preceding layers and proportionally integrates knowledge into the final layer to adjust the output logits.","Note that DeCo is model agnostic and can be seamlessly incorporated with various classic decoding strategies and applied to different MLLMs.","We evaluate DeCo on widely-used benchmarks, demonstrating that it can reduce hallucination rates by a large margin compared to baselines, highlighting its potential to mitigate hallucinations.","Code is available at https://github.com/zjunlp/DeCo."],"url":"http://arxiv.org/abs/2410.11779v1"}
{"created":"2024-10-15 16:57:14","title":"On the Training Convergence of Transformers for In-Context Classification","abstract":"While transformers have demonstrated impressive capacities for in-context learning (ICL) in practice, theoretical understanding of the underlying mechanism enabling transformers to perform ICL is still in its infant stage. This work aims to theoretically study the training dynamics of transformers for in-context classification tasks. We demonstrate that, for in-context classification of Gaussian mixtures under certain assumptions, a single-layer transformer trained via gradient descent converges to a globally optimal model at a linear rate. We further quantify the impact of the training and testing prompt lengths on the ICL inference error of the trained transformer. We show that when the lengths of training and testing prompts are sufficiently large, the prediction of the trained transformer approaches the Bayes-optimal classifier. Experimental results corroborate the theoretical findings.","sentences":["While transformers have demonstrated impressive capacities for in-context learning (ICL) in practice, theoretical understanding of the underlying mechanism enabling transformers to perform ICL is still in its infant stage.","This work aims to theoretically study the training dynamics of transformers for in-context classification tasks.","We demonstrate that, for in-context classification of Gaussian mixtures under certain assumptions, a single-layer transformer trained via gradient descent converges to a globally optimal model at a linear rate.","We further quantify the impact of the training and testing prompt lengths on the ICL inference error of the trained transformer.","We show that when the lengths of training and testing prompts are sufficiently large, the prediction of the trained transformer approaches the Bayes-optimal classifier.","Experimental results corroborate the theoretical findings."],"url":"http://arxiv.org/abs/2410.11778v1"}
{"created":"2024-10-15 16:56:05","title":"Random expansions of trees with bounded height","abstract":"We consider a sequence $\\mathbf{T} = (\\mathcal{T}_n : n \\in \\mathbb{N}^+)$ of trees $\\mathcal{T}_n$ where, for some $\\Delta \\in \\mathbb{N}^+$ every $\\mathcal{T}_n$ has height at most $\\Delta$ and as $n \\to \\infty$ the minimal number of children of a nonleaf tends to infinity. We can view every tree as a (first-order) $\\tau$-structure where $\\tau$ is a signature with one binary relation symbol. For a fixed (arbitrary) finite and relational signature $\\sigma \\supseteq \\tau$ we consider the set $\\mathbf{W}_n$ of expansions of $\\mathcal{T}_n$ to $\\sigma$ and a probability distribution $\\mathbb{P}_n$ on $\\mathbf{W}_n$ which is determined by a (parametrized/lifted) Probabilistic Graphical Model (PGM) $\\mathbb{G}$ which can use the information given by $\\mathcal{T}_n$.   The kind of PGM that we consider uses formulas of a many-valued logic that we call $PLA^*$ with truth values in the unit interval $[0, 1]$. We also use $PLA^*$ to express queries, or events, on $\\mathbf{W}_n$. With this setup we prove that, under some assumptions on $\\mathbf{T}$, $\\mathbb{G}$, and a (possibly quite complex) formula $\\varphi(x_1, \\ldots, x_k)$ of $PLA^*$, as $n \\to \\infty$, if $a_1, \\ldots, a_k$ are vertices of the tree $\\mathcal{T}_n$ then the value of $\\varphi(a_1, \\ldots, a_k)$ will, with high probability, be almost the same as the value of $\\psi(a_1, \\ldots, a_k)$, where $\\psi(x_1, \\ldots, x_k)$ is a ``simple'' formula the value of which can always be computed quickly (without reference to $n$), and $\\psi$ itself can be found by using only the information that defines $\\mathbf{T}$, $\\mathbb{G}$ and $\\varphi$. A corollary of this, subject to the same conditions, is a probabilistic convergence law for $PLA^*$-formulas.","sentences":["We consider a sequence $\\mathbf{T} = (\\mathcal{T}_n : n \\in \\mathbb{N}^+)$ of trees $\\mathcal{T}_n$ where, for some $\\Delta \\in \\mathbb{N}^+$ every $\\mathcal{T}_n$ has height at most $\\Delta$ and as $n \\to \\infty$ the minimal number of children of a nonleaf tends to infinity.","We can view every tree as a (first-order) $\\tau$-structure where $\\tau$ is a signature with one binary relation symbol.","For a fixed (arbitrary) finite and relational signature $\\sigma \\supseteq \\tau$ we consider the set $\\mathbf{W}_n$ of expansions of $\\mathcal{T}_n$ to $\\sigma$ and a probability distribution $\\mathbb{P}_n$ on $\\mathbf{W}_n$ which is determined by a (parametrized/lifted) Probabilistic Graphical Model (PGM) $\\mathbb{G}$ which can use the information given by $\\mathcal{T}_n$.   The kind of PGM that we consider uses formulas of a many-valued logic that we call $PLA^*$ with truth values in the unit interval $[0, 1]$. We also use $PLA^*$ to express queries, or events, on $\\mathbf{W}_n$. With this setup we prove that, under some assumptions on $\\mathbf{T}$, $\\mathbb{G}$, and a (possibly quite complex) formula $\\varphi(x_1, \\ldots, x_k)$ of $PLA^*$, as $n \\to \\infty$, if $a_1, \\ldots, a_k$ are vertices of the tree $\\mathcal{T}_n$ then the value of $\\varphi(a_1, \\ldots, a_k)$ will, with high probability, be almost the same as the value of $\\psi(a_1, \\ldots, a_k)$, where $\\psi(x_1, \\ldots, x_k)$ is a ``simple'' formula the value of which can always be computed quickly (without reference to $n$), and $\\psi$ itself can be found by using only the information that defines $\\mathbf{T}$, $\\mathbb{G}$ and $\\varphi$. A corollary of this, subject to the same conditions, is a probabilistic convergence law for $PLA^*$-formulas."],"url":"http://arxiv.org/abs/2410.11775v1"}
{"created":"2024-10-15 16:55:10","title":"Fractal Calibration for long-tailed object detection","abstract":"Real-world datasets follow an imbalanced distribution, which poses significant challenges in rare-category object detection. Recent studies tackle this problem by developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset. However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information. In contrast to them, we propose FRActal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection. FRACAL devises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space. During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes. FRACAL is a post-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models. FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages. The code will be released.","sentences":["Real-world datasets follow an imbalanced distribution, which poses significant challenges in rare-category object detection.","Recent studies tackle this problem by developing re-weighting and re-sampling methods, that utilise the class frequencies of the dataset.","However, these techniques focus solely on the frequency statistics and ignore the distribution of the classes in image space, missing important information.","In contrast to them, we propose FRActal CALibration (FRACAL): a novel post-calibration method for long-tailed object detection.","FRACAL devises a logit adjustment method that utilises the fractal dimension to estimate how uniformly classes are distributed in image space.","During inference, it uses the fractal dimension to inversely downweight the probabilities of uniformly spaced class predictions achieving balance in two axes: between frequent and rare categories, and between uniformly spaced and sparsely spaced classes.","FRACAL is a post-processing method and it does not require any training, also it can be combined with many off-the-shelf models such as one-stage sigmoid detectors and two-stage instance segmentation models.","FRACAL boosts the rare class performance by up to 8.6% and surpasses all previous methods on LVIS dataset, while showing good generalisation to other datasets such as COCO, V3Det and OpenImages.","The code will be released."],"url":"http://arxiv.org/abs/2410.11774v1"}
{"created":"2024-10-15 16:53:26","title":"Layer-wise Importance Matters: Less Memory for Better Performance in Parameter-efficient Fine-tuning of Large Language Models","abstract":"Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant popularity for adapting pre-trained Large Language Models (LLMs) to downstream tasks, primarily due to their potential to significantly reduce memory and computational overheads. However, a common limitation in most PEFT approaches is their application of a uniform architectural design across all layers. This uniformity involves identical trainable modules and ignores the varying importance of each layer, leading to sub-optimal fine-tuning results. To overcome the above limitation and obtain better performance, we develop a novel approach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent sparsity and select the most important subset of full layers with effective layer-wise importance scoring. The proposed IST is a versatile and plug-and-play technique compatible with various PEFT methods that operate on a per-layer basis. By leveraging the estimated importance scores, IST dynamically updates these selected layers in PEFT modules, leading to reduced memory demands. We further provide theoretical proof of convergence and empirical evidence of superior performance to demonstrate the advantages of IST over uniform updating strategies. Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST's capacity to enhance existing layer-based PEFT methods. Our code is available at https://github.com/Kaiseem/IST.","sentences":["Parameter-Efficient Fine-Tuning (PEFT) methods have gained significant popularity for adapting pre-trained Large Language Models (LLMs) to downstream tasks, primarily due to their potential to significantly reduce memory and computational overheads.","However, a common limitation in most PEFT approaches is their application of a uniform architectural design across all layers.","This uniformity involves identical trainable modules and ignores the varying importance of each layer, leading to sub-optimal fine-tuning results.","To overcome the above limitation and obtain better performance, we develop a novel approach, Importance-aware Sparse Tuning (IST), to fully utilize the inherent sparsity and select the most important subset of full layers with effective layer-wise importance scoring.","The proposed IST is a versatile and plug-and-play technique compatible with various PEFT methods that operate on a per-layer basis.","By leveraging the estimated importance scores, IST dynamically updates these selected layers in PEFT modules, leading to reduced memory demands.","We further provide theoretical proof of convergence and empirical evidence of superior performance to demonstrate the advantages of IST over uniform updating strategies.","Extensive experiments on a range of LLMs, PEFTs, and downstream tasks substantiate the effectiveness of our proposed method, showcasing IST's capacity to enhance existing layer-based PEFT methods.","Our code is available at https://github.com/Kaiseem/IST."],"url":"http://arxiv.org/abs/2410.11772v1"}
{"created":"2024-10-15 16:44:40","title":"Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs?","abstract":"Search-based software testing (SBST) is a widely adopted technique for testing complex systems with large input spaces, such as Deep Learning-enabled (DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization, where multiple objectives are optimized in parallel to reveal failures. However, it is important to ensure that identified failures are spread throughout the entire failure-inducing area of a search domain and not clustered in a sub-region. This ensures that identified failures are semantically diverse and reveal a wide range of underlying causes. In this paper, we present a theoretical argument explaining why testing based on Pareto optimization is inadequate for covering failure-inducing areas within a search domain. We support our argument with empirical results obtained by applying two widely used types of Pareto-based optimization techniques, namely NSGA-II (an evolutionary algorithm) and MOPSO (a swarm-based algorithm), to two DL-enabled systems: an industrial Automated Valet Parking (AVP) system and a system for classifying handwritten digits. We measure the coverage of failure-revealing test inputs in the input space using a metric that we refer to as the Coverage Inverted Distance quality indicator. Our results show that NSGA-II and MOPSO are not more effective than a na\\\"ive random search baseline in covering test inputs that reveal failures. The replication package for this study is available in a GitHub repository.","sentences":["Search-based software testing (SBST) is a widely adopted technique for testing complex systems with large input spaces, such as Deep Learning-enabled (DL-enabled) systems.","Many SBST techniques focus on Pareto-based optimization, where multiple objectives are optimized in parallel to reveal failures.","However, it is important to ensure that identified failures are spread throughout the entire failure-inducing area of a search domain and not clustered in a sub-region.","This ensures that identified failures are semantically diverse and reveal a wide range of underlying causes.","In this paper, we present a theoretical argument explaining why testing based on Pareto optimization is inadequate for covering failure-inducing areas within a search domain.","We support our argument with empirical results obtained by applying two widely used types of Pareto-based optimization techniques, namely NSGA-II (an evolutionary algorithm) and MOPSO (a swarm-based algorithm), to two DL-enabled systems: an industrial Automated Valet Parking (AVP) system and a system for classifying handwritten digits.","We measure the coverage of failure-revealing test inputs in the input space using a metric that we refer to as the Coverage Inverted Distance quality indicator.","Our results show that NSGA-II and MOPSO are not more effective than a na\\\"ive random search baseline in covering test inputs that reveal failures.","The replication package for this study is available in a GitHub repository."],"url":"http://arxiv.org/abs/2410.11769v1"}
{"created":"2024-10-15 16:44:16","title":"Evaluating Software Contribution Quality: Time-to-Modification Theory","abstract":"The durability and quality of software contributions are critical factors in the long-term maintainability of a codebase. This paper introduces the Time to Modification (TTM) Theory, a novel approach for quantifying code quality by measuring the time interval between a code segment's introduction and its first modification. TTM serves as a proxy for code durability, with longer intervals suggesting higher-quality, more stable contributions. This work builds on previous research, including the \"Time-Delta Method for Measuring Software Development Contribution Rates\" dissertation, from which it heavily borrows concepts and methodologies. By leveraging version control systems such as Git, TTM provides granular insights into the temporal stability of code at various levels ranging from individual lines to entire repositories. TTM Theory contributes to the software engineering field by offering a dynamic metric that captures the evolution of a codebase over time, complementing traditional metrics like code churn and cyclomatic complexity. This metric is particularly useful for predicting maintenance needs, optimizing developer performance assessments, and improving the sustainability of software systems. Integrating TTM into continuous integration pipelines enables real-time monitoring of code stability, helping teams identify areas of instability and reduce technical debt.","sentences":["The durability and quality of software contributions are critical factors in the long-term maintainability of a codebase.","This paper introduces the Time to Modification (TTM) Theory, a novel approach for quantifying code quality by measuring the time interval between a code segment's introduction and its first modification.","TTM serves as a proxy for code durability, with longer intervals suggesting higher-quality, more stable contributions.","This work builds on previous research, including the \"Time-Delta Method for Measuring Software Development Contribution Rates\" dissertation, from which it heavily borrows concepts and methodologies.","By leveraging version control systems such as Git, TTM provides granular insights into the temporal stability of code at various levels ranging from individual lines to entire repositories.","TTM Theory contributes to the software engineering field by offering a dynamic metric that captures the evolution of a codebase over time, complementing traditional metrics like code churn and cyclomatic complexity.","This metric is particularly useful for predicting maintenance needs, optimizing developer performance assessments, and improving the sustainability of software systems.","Integrating TTM into continuous integration pipelines enables real-time monitoring of code stability, helping teams identify areas of instability and reduce technical debt."],"url":"http://arxiv.org/abs/2410.11768v1"}
{"created":"2024-10-15 16:42:13","title":"Analyzing (In)Abilities of SAEs via Formal Languages","abstract":"Autoencoders have been used for finding interpretable and disentangled features underlying neural network representations in both image and text domains. While the efficacy and pitfalls of such methods are well-studied in vision, there is a lack of corresponding results, both qualitative and quantitative, for the text domain. We aim to address this gap by training sparse autoencoders (SAEs) on a synthetic testbed of formal languages. Specifically, we train SAEs on the hidden representations of models trained on formal languages (Dyck-2, Expr, and English PCFG) under a wide variety of hyperparameter settings, finding interpretable latents often emerge in the features learned by our SAEs. However, similar to vision, we find performance turns out to be highly sensitive to inductive biases of the training pipeline. Moreover, we show latents correlating to certain features of the input do not always induce a causal impact on model's computation. We thus argue that causality has to become a central target in SAE training: learning of causal features should be incentivized from the ground-up. Motivated by this, we propose and perform preliminary investigations for an approach that promotes learning of causally relevant features in our formal language setting.","sentences":["Autoencoders have been used for finding interpretable and disentangled features underlying neural network representations in both image and text domains.","While the efficacy and pitfalls of such methods are well-studied in vision, there is a lack of corresponding results, both qualitative and quantitative, for the text domain.","We aim to address this gap by training sparse autoencoders (SAEs) on a synthetic testbed of formal languages.","Specifically, we train SAEs on the hidden representations of models trained on formal languages (Dyck-2, Expr, and English PCFG) under a wide variety of hyperparameter settings, finding interpretable latents often emerge in the features learned by our SAEs.","However, similar to vision, we find performance turns out to be highly sensitive to inductive biases of the training pipeline.","Moreover, we show latents correlating to certain features of the input do not always induce a causal impact on model's computation.","We thus argue that causality has to become a central target in SAE training: learning of causal features should be incentivized from the ground-up.","Motivated by this, we propose and perform preliminary investigations for an approach that promotes learning of causally relevant features in our formal language setting."],"url":"http://arxiv.org/abs/2410.11767v1"}
{"created":"2024-10-15 16:39:50","title":"DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion","abstract":"The increasing adoption of Deep Neural Network (DNN)-based Digital Pre-distortion (DPD) in modern communication systems necessitates efficient hardware implementations. This paper presents DPD-NeuralEngine, an ultra-fast, tiny-area, and power-efficient DPD accelerator based on a Gated Recurrent Unit (GRU) neural network (NN). Leveraging a co-designed software and hardware approach, our 22 nm CMOS implementation operates at 2 GHz, capable of processing I/Q signals up to 250 MSps. Experimental results demonstrate a throughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W with DPD linearization performance measured in Adjacent Channel Power Ratio (ACPR) of -45.3 dBc and Error Vector Magnitude (EVM) of -39.8 dB. To our knowledge, this work represents the first AI-based DPD application-specific integrated circuit (ASIC) accelerator, achieving a power-area efficiency (PAE) of 6.6 TOPS/W/mm$^2$.","sentences":["The increasing adoption of Deep Neural Network (DNN)-based Digital Pre-distortion (DPD) in modern communication systems necessitates efficient hardware implementations.","This paper presents DPD-NeuralEngine, an ultra-fast, tiny-area, and power-efficient DPD accelerator based on a Gated Recurrent Unit (GRU) neural network (NN).","Leveraging a co-designed software and hardware approach, our 22 nm CMOS implementation operates at 2 GHz, capable of processing I/Q signals up to 250 MSps.","Experimental results demonstrate a throughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W with DPD linearization performance measured in Adjacent Channel Power Ratio (ACPR) of -45.3 dBc and Error Vector Magnitude (EVM) of -39.8 dB. To our knowledge, this work represents the first AI-based DPD application-specific integrated circuit (ASIC) accelerator, achieving a power-area efficiency (PAE) of 6.6 TOPS/W/mm$^2$."],"url":"http://arxiv.org/abs/2410.11766v1"}
{"created":"2024-10-15 16:39:38","title":"ECGN: A Cluster-Aware Approach to Graph Neural Networks for Imbalanced Classification","abstract":"Classifying nodes in a graph is a common problem. The ideal classifier must adapt to any imbalances in the class distribution. It must also use information in the clustering structure of real-world graphs. Existing Graph Neural Networks (GNNs) have not addressed both problems together. We propose the Enhanced Cluster-aware Graph Network (ECGN), a novel method that addresses these issues by integrating cluster-specific training with synthetic node generation. Unlike traditional GNNs that apply the same node update process for all nodes, ECGN learns different aggregations for different clusters. We also use the clusters to generate new minority-class nodes in a way that helps clarify the inter-class decision boundary. By combining cluster-aware embeddings with a global integration step, ECGN enhances the quality of the resulting node embeddings. Our method works with any underlying GNN and any cluster generation technique. Experimental results show that ECGN consistently outperforms its closest competitors by up to 11% on some widely studied benchmark datasets.","sentences":["Classifying nodes in a graph is a common problem.","The ideal classifier must adapt to any imbalances in the class distribution.","It must also use information in the clustering structure of real-world graphs.","Existing Graph Neural Networks (GNNs) have not addressed both problems together.","We propose the Enhanced Cluster-aware Graph Network (ECGN), a novel method that addresses these issues by integrating cluster-specific training with synthetic node generation.","Unlike traditional GNNs that apply the same node update process for all nodes, ECGN learns different aggregations for different clusters.","We also use the clusters to generate new minority-class nodes in a way that helps clarify the inter-class decision boundary.","By combining cluster-aware embeddings with a global integration step, ECGN enhances the quality of the resulting node embeddings.","Our method works with any underlying GNN and any cluster generation technique.","Experimental results show that ECGN consistently outperforms its closest competitors by up to 11% on some widely studied benchmark datasets."],"url":"http://arxiv.org/abs/2410.11765v1"}
{"created":"2024-10-15 16:35:49","title":"Octopus-Swimming-Like Robot with Soft Asymmetric Arms","abstract":"Underwater vehicles have seen significant development over the past seventy years. However, bio-inspired propulsion robots are still in their early stages and require greater interdisciplinary collaboration between biologists and roboticists. The octopus, one of the most intelligent marine animals, exhibits remarkable abilities such as camouflaging, exploring, and hunting while swimming with its arms. Although bio-inspired robotics researchers have aimed to replicate these abilities, the complexity of designing an eight-arm bionic swimming platform has posed challenges from the beginning. In this work, we propose a novel bionic robot swimming platform that combines asymmetric passive morphing arms with an umbrella-like quick-return mechanism. Using only two simple constant-speed motors, this design achieves efficient swimming by replicating octopus-like arm movements and stroke time ratios. The robot reached a peak speed of 314 mm/s during its second power stroke. This design reduces the complexity of traditional octopus-like swimming robot actuation systems while maintaining good swimming performance. It offers a more achievable and efficient platform for biologists and roboticists conducting more profound octopus-inspired robotic and biological studies.","sentences":["Underwater vehicles have seen significant development over the past seventy years.","However, bio-inspired propulsion robots are still in their early stages and require greater interdisciplinary collaboration between biologists and roboticists.","The octopus, one of the most intelligent marine animals, exhibits remarkable abilities such as camouflaging, exploring, and hunting while swimming with its arms.","Although bio-inspired robotics researchers have aimed to replicate these abilities, the complexity of designing an eight-arm bionic swimming platform has posed challenges from the beginning.","In this work, we propose a novel bionic robot swimming platform that combines asymmetric passive morphing arms with an umbrella-like quick-return mechanism.","Using only two simple constant-speed motors, this design achieves efficient swimming by replicating octopus-like arm movements and stroke time ratios.","The robot reached a peak speed of 314 mm/s during its second power stroke.","This design reduces the complexity of traditional octopus-like swimming robot actuation systems while maintaining good swimming performance.","It offers a more achievable and efficient platform for biologists and roboticists conducting more profound octopus-inspired robotic and biological studies."],"url":"http://arxiv.org/abs/2410.11764v1"}
{"created":"2024-10-15 16:33:33","title":"SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding","abstract":"Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level. The lack of large-scale instruction datasets and the gigapixel scale of whole slide images (WSIs) pose significant developmental challenges. In this paper, we present SlideChat, the first vision-language assistant capable of understanding gigapixel whole-slide images, exhibiting excellent multimodal conversational capability and response complex instruction across diverse pathology scenarios. To support its development, we created SlideInstruction, the largest instruction-following dataset for WSIs consisting of 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore, we propose SlideBench, a multimodal benchmark that incorporates captioning and VQA tasks to assess SlideChat's capabilities in varied clinical settings such as microscopy, diagnosis. Compared to both general and specialized MLLMs, SlideChat exhibits exceptional capabilities achieving state-of-the-art performance on 18 of 22 tasks. For example, it achieved an overall accuracy of 81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). We will fully release SlideChat, SlideInstruction and SlideBench as open-source resources to facilitate research and development in computational pathology.","sentences":["Despite the progress made by multimodal large language models (MLLMs) in computational pathology, they remain limited by a predominant focus on patch-level analysis, missing essential contextual information at the whole-slide level.","The lack of large-scale instruction datasets and the gigapixel scale of whole slide images (WSIs) pose significant developmental challenges.","In this paper, we present SlideChat, the first vision-language assistant capable of understanding gigapixel whole-slide images, exhibiting excellent multimodal conversational capability and response complex instruction across diverse pathology scenarios.","To support its development, we created SlideInstruction, the largest instruction-following dataset for WSIs consisting of 4.2K WSI captions and 176K VQA pairs with multiple categories.","Furthermore, we propose SlideBench, a multimodal benchmark that incorporates captioning and VQA tasks to assess SlideChat's capabilities in varied clinical settings such as microscopy, diagnosis.","Compared to both general and specialized MLLMs, SlideChat exhibits exceptional capabilities achieving state-of-the-art performance on 18 of 22 tasks.","For example, it achieved an overall accuracy of 81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB).","We will fully release SlideChat, SlideInstruction and SlideBench as open-source resources to facilitate research and development in computational pathology."],"url":"http://arxiv.org/abs/2410.11761v1"}
{"created":"2024-10-15 16:28:55","title":"LoSAM: Local Search in Additive Noise Models with Unmeasured Confounders, a Top-Down Global Discovery Approach","abstract":"We address the challenge of causal discovery in structural equation models with additive noise without imposing additional assumptions on the underlying data-generating process. We introduce local search in additive noise model (LoSAM), which generalizes an existing nonlinear method that leverages local causal substructures to the general additive noise setting, allowing for both linear and nonlinear causal mechanisms. We show that LoSAM achieves polynomial runtime, and improves runtime and efficiency by exploiting new substructures to minimize the conditioning set at each step. Further, we introduce a variant of LoSAM, LoSAM-UC, that is robust to unmeasured confounding among roots, a property that is often not satisfied by functional-causal-model-based methods. We numerically demonstrate the utility of LoSAM, showing that it outperforms existing benchmarks.","sentences":["We address the challenge of causal discovery in structural equation models with additive noise without imposing additional assumptions on the underlying data-generating process.","We introduce local search in additive noise model (LoSAM), which generalizes an existing nonlinear method that leverages local causal substructures to the general additive noise setting, allowing for both linear and nonlinear causal mechanisms.","We show that LoSAM achieves polynomial runtime, and improves runtime and efficiency by exploiting new substructures to minimize the conditioning set at each step.","Further, we introduce a variant of LoSAM, LoSAM-UC, that is robust to unmeasured confounding among roots, a property that is often not satisfied by functional-causal-model-based methods.","We numerically demonstrate the utility of LoSAM, showing that it outperforms existing benchmarks."],"url":"http://arxiv.org/abs/2410.11759v1"}
{"created":"2024-10-15 16:28:09","title":"Latent Action Pretraining from Videos","abstract":"We introduce Latent Action Pretraining for general Action models (LAPA), an unsupervised method for pretraining Vision-Language-Action (VLA) models without ground-truth robot action labels. Existing Vision-Language-Action models require action labels typically collected by human teleoperators during pretraining, which significantly limits possible data sources and scale. In this work, we propose a method to learn from internet-scale videos that do not have robot action labels. We first train an action quantization model leveraging VQ-VAE-based objective to learn discrete latent actions between image frames, then pretrain a latent VLA model to predict these latent actions from observations and task descriptions, and finally finetune the VLA on small-scale robot manipulation data to map from latent to robot actions. Experimental results demonstrate that our method significantly outperforms existing techniques that train robot manipulation policies from large-scale videos. Furthermore, it outperforms the state-of-the-art VLA model trained with robotic action labels on real-world manipulation tasks that require language conditioning, generalization to unseen objects, and semantic generalization to unseen instructions. Training only on human manipulation videos also shows positive transfer, opening up the potential for leveraging web-scale data for robotics foundation model.","sentences":["We introduce Latent Action Pretraining for general Action models (LAPA), an unsupervised method for pretraining Vision-Language-Action (VLA) models without ground-truth robot action labels.","Existing Vision-Language-Action models require action labels typically collected by human teleoperators during pretraining, which significantly limits possible data sources and scale.","In this work, we propose a method to learn from internet-scale videos that do not have robot action labels.","We first train an action quantization model leveraging VQ-VAE-based objective to learn discrete latent actions between image frames, then pretrain a latent VLA model to predict these latent actions from observations and task descriptions, and finally finetune the VLA on small-scale robot manipulation data to map from latent to robot actions.","Experimental results demonstrate that our method significantly outperforms existing techniques that train robot manipulation policies from large-scale videos.","Furthermore, it outperforms the state-of-the-art VLA model trained with robotic action labels on real-world manipulation tasks that require language conditioning, generalization to unseen objects, and semantic generalization to unseen instructions.","Training only on human manipulation videos also shows positive transfer, opening up the potential for leveraging web-scale data for robotics foundation model."],"url":"http://arxiv.org/abs/2410.11758v1"}
{"created":"2024-10-15 16:27:22","title":"Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis","abstract":"Generative AI's rapid advancement sparks interest in its cognitive abilities, especially given its capacity for tasks like language understanding and code generation. This study explores how several recent GenAI models perform on the Clock Drawing Test (CDT), a neuropsychological assessment of visuospatial planning and organization. While models create clock-like drawings, they struggle with accurate time representation, showing deficits similar to mild-severe cognitive impairment (Wechsler, 2009). Errors include numerical sequencing issues, incorrect clock times, and irrelevant additions, despite accurate rendering of clock features. Only GPT 4 Turbo and Gemini Pro 1.5 produced the correct time, scoring like healthy individuals (4/4). A follow-up clock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawing deficits stem from difficulty with numerical concepts. These findings may reflect weaknesses in visual-spatial understanding, working memory, or calculation, highlighting strengths in learned knowledge but weaknesses in reasoning. Comparing human and machine performance is crucial for understanding AI's cognitive capabilities and guiding development toward human-like cognitive functions.","sentences":["Generative AI's rapid advancement sparks interest in its cognitive abilities, especially given its capacity for tasks like language understanding and code generation.","This study explores how several recent GenAI models perform on the Clock Drawing Test (CDT), a neuropsychological assessment of visuospatial planning and organization.","While models create clock-like drawings, they struggle with accurate time representation, showing deficits similar to mild-severe cognitive impairment (Wechsler, 2009).","Errors include numerical sequencing issues, incorrect clock times, and irrelevant additions, despite accurate rendering of clock features.","Only GPT 4 Turbo and Gemini Pro 1.5 produced the correct time, scoring like healthy individuals (4/4).","A follow-up clock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawing deficits stem from difficulty with numerical concepts.","These findings may reflect weaknesses in visual-spatial understanding, working memory, or calculation, highlighting strengths in learned knowledge but weaknesses in reasoning.","Comparing human and machine performance is crucial for understanding AI's cognitive capabilities and guiding development toward human-like cognitive functions."],"url":"http://arxiv.org/abs/2410.11756v1"}
{"created":"2024-10-15 16:22:49","title":"Personas with Attitudes: Controlling LLMs for Diverse Data Annotation","abstract":"We present a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models (LLMs). We investigate the impact of injecting diverse persona descriptions into LLM prompts across two studies, exploring whether personas increase annotation diversity and whether the impacts of individual personas on the resulting annotations are consistent and controllable. Our results show that persona-prompted LLMs produce more diverse annotations than LLMs prompted without personas and that these effects are both controllable and repeatable, making our approach a suitable tool for improving data annotation in subjective NLP tasks like toxicity detection.","sentences":["We present a novel approach for enhancing diversity and control in data annotation tasks by personalizing large language models (LLMs).","We investigate the impact of injecting diverse persona descriptions into LLM prompts across two studies, exploring whether personas increase annotation diversity and whether the impacts of individual personas on the resulting annotations are consistent and controllable.","Our results show that persona-prompted LLMs produce more diverse annotations than LLMs prompted without personas and that these effects are both controllable and repeatable, making our approach a suitable tool for improving data annotation in subjective NLP tasks like toxicity detection."],"url":"http://arxiv.org/abs/2410.11745v1"}
{"created":"2024-10-15 16:21:15","title":"DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure","abstract":"While speculative decoding has recently appeared as a promising direction for accelerating the inference of large language models (LLMs), the speedup and scalability are strongly bounded by the token acceptance rate. Prevalent methods usually organize predicted tokens as independent chains or fixed token trees, which fails to generalize to diverse query distributions. In this paper, we propose DySpec, a faster speculative decoding algorithm with a novel dynamic token tree structure. We begin by bridging the draft distribution and acceptance rate from intuitive and empirical clues, and successfully show that the two variables are strongly correlated. Based on this, we employ a greedy strategy to dynamically expand the token tree at run time. Theoretically, we show that our method can achieve optimal results under mild assumptions. Empirically, DySpec yields a higher acceptance rate and speedup than fixed trees. DySpec can drastically improve the throughput and reduce the latency of token generation across various data distribution and model sizes, which significantly outperforms strong competitors, including Specinfer and Sequoia. Under low temperature setting, DySpec can improve the throughput up to 9.1$\\times$ and reduce the latency up to 9.4$\\times$ on Llama2-70B. Under high temperature setting, DySpec can also improve the throughput up to 6.21$\\times$, despite the increasing difficulty of speculating more than one token per step for draft model.","sentences":["While speculative decoding has recently appeared as a promising direction for accelerating the inference of large language models (LLMs), the speedup and scalability are strongly bounded by the token acceptance rate.","Prevalent methods usually organize predicted tokens as independent chains or fixed token trees, which fails to generalize to diverse query distributions.","In this paper, we propose DySpec, a faster speculative decoding algorithm with a novel dynamic token tree structure.","We begin by bridging the draft distribution and acceptance rate from intuitive and empirical clues, and successfully show that the two variables are strongly correlated.","Based on this, we employ a greedy strategy to dynamically expand the token tree at run time.","Theoretically, we show that our method can achieve optimal results under mild assumptions.","Empirically, DySpec yields a higher acceptance rate and speedup than fixed trees.","DySpec can drastically improve the throughput and reduce the latency of token generation across various data distribution and model sizes, which significantly outperforms strong competitors, including Specinfer and Sequoia.","Under low temperature setting, DySpec can improve the throughput up to 9.1$\\times$ and reduce the latency up to 9.4$\\times$ on Llama2-70B. Under high temperature setting, DySpec can also improve the throughput up to 6.21$\\times$, despite the increasing difficulty of speculating more than one token per step for draft model."],"url":"http://arxiv.org/abs/2410.11744v1"}
{"created":"2024-10-15 16:18:08","title":"Extensible Recursive Functions, Algebraically","abstract":"We explore recursive programming with extensible data types. Row types make the structure of data types first class, and can express a variety of type system features from subtyping to modular combination of case branches. Our goal is the modular combination of recursive types and of recursive functions over them. The most significant challenge is in recursive function calls, which may need to account for new cases in a combined type. We introduce bounded algebras, Mendler-style descriptions of recursive functions in which recursive calls can happen at larger types, and show that they provide expressive recursion over extensible data types. We formalize our approach in R$\\omega\\mu$, a small extension of an existing row type theory with support for recursive terms and types, and mechanize the metatheory of R$\\omega\\mu$ via an embedding in Agda","sentences":["We explore recursive programming with extensible data types.","Row types make the structure of data types first class, and can express a variety of type system features from subtyping to modular combination of case branches.","Our goal is the modular combination of recursive types and of recursive functions over them.","The most significant challenge is in recursive function calls, which may need to account for new cases in a combined type.","We introduce bounded algebras, Mendler-style descriptions of recursive functions in which recursive calls can happen at larger types, and show that they provide expressive recursion over extensible data types.","We formalize our approach in R$\\omega\\mu$, a small extension of an existing row type theory with support for recursive terms and types, and mechanize the metatheory of R$\\omega\\mu$ via an embedding in Agda"],"url":"http://arxiv.org/abs/2410.11742v1"}
{"created":"2024-10-15 16:17:16","title":"POLO -- Point-based, multi-class animal detection","abstract":"Automated wildlife surveys based on drone imagery and object detection technology are a powerful and increasingly popular tool in conservation biology. Most detectors require training images with annotated bounding boxes, which are tedious, expensive, and not always unambiguous to create. To reduce the annotation load associated with this practice, we develop POLO, a multi-class object detection model that can be trained entirely on point labels. POLO is based on simple, yet effective modifications to the YOLOv8 architecture, including alterations to the prediction process, training losses, and post-processing. We test POLO on drone recordings of waterfowl containing up to multiple thousands of individual birds in one image and compare it to a regular YOLOv8. Our experiments show that at the same annotation cost, POLO achieves improved accuracy in counting animals in aerial imagery.","sentences":["Automated wildlife surveys based on drone imagery and object detection technology are a powerful and increasingly popular tool in conservation biology.","Most detectors require training images with annotated bounding boxes, which are tedious, expensive, and not always unambiguous to create.","To reduce the annotation load associated with this practice, we develop POLO, a multi-class object detection model that can be trained entirely on point labels.","POLO is based on simple, yet effective modifications to the YOLOv8 architecture, including alterations to the prediction process, training losses, and post-processing.","We test POLO on drone recordings of waterfowl containing up to multiple thousands of individual birds in one image and compare it to a regular YOLOv8.","Our experiments show that at the same annotation cost, POLO achieves improved accuracy in counting animals in aerial imagery."],"url":"http://arxiv.org/abs/2410.11741v1"}
{"created":"2024-10-15 16:17:11","title":"Fuzzy Aristotelian Diagrams","abstract":"I am describing the square of opposition, in particular, and, Aristotelian Diagrams, in general. Then I describe how one can create a mathematical universe to host them. Based on this work, I introduce fuzzy Aristotelian Diagrams and describe a mathematical formulation of them. In addition, I outline the cdharacteristrics of a mathematical universe that can host them.","sentences":["I am describing the square of opposition, in particular, and, Aristotelian Diagrams, in general.","Then I describe how one can create a mathematical universe to host them.","Based on this work, I introduce fuzzy Aristotelian Diagrams and describe a mathematical formulation of them.","In addition, I outline the cdharacteristrics of a mathematical universe that can host them."],"url":"http://arxiv.org/abs/2410.11740v1"}
{"created":"2024-10-15 16:11:59","title":"Near-Field Communications for Extremely Large-Scale MIMO: A Beamspace Perspective","abstract":"Extremely large-scale multiple-input multiple-output (XL-MIMO) is regarded as one of the key techniques to enhance the performance of future wireless communications. Different from regular MIMO, the XL-MIMO shifts part of the communication region from the far field to the near field, where the spherical-wave channel model cannot be accurately approximated by the commonly-adopted planar-wave channel model. As a result, the well-explored far-field beamspace is unsuitable for near-field communications, thereby requiring the exploration of specialized near-field beamspace. In this article, we investigate the near-field communications for XL-MIMO from the perspective of beamspace. Given the spherical wavefront characteristics of the near-field channels, we first map the antenna space to the near-field beamspace with the fractional Fourier transform. Then, we divide the near-field beamspace into three parts, including high mainlobe, low mainlobe, and sidelobe, and provide a comprehensive analysis of these components. Based on the analysis, we demonstrate the advantages of the near-field beamspace over the existing methods. Finally, we point out several applications of the near-field beamspace and highlight some potential directions for future study in the near-field beamspace.","sentences":["Extremely large-scale multiple-input multiple-output (XL-MIMO) is regarded as one of the key techniques to enhance the performance of future wireless communications.","Different from regular MIMO, the XL-MIMO shifts part of the communication region from the far field to the near field, where the spherical-wave channel model cannot be accurately approximated by the commonly-adopted planar-wave channel model.","As a result, the well-explored far-field beamspace is unsuitable for near-field communications, thereby requiring the exploration of specialized near-field beamspace.","In this article, we investigate the near-field communications for XL-MIMO from the perspective of beamspace.","Given the spherical wavefront characteristics of the near-field channels, we first map the antenna space to the near-field beamspace with the fractional Fourier transform.","Then, we divide the near-field beamspace into three parts, including high mainlobe, low mainlobe, and sidelobe, and provide a comprehensive analysis of these components.","Based on the analysis, we demonstrate the advantages of the near-field beamspace over the existing methods.","Finally, we point out several applications of the near-field beamspace and highlight some potential directions for future study in the near-field beamspace."],"url":"http://arxiv.org/abs/2410.11736v1"}
{"created":"2024-10-15 16:02:08","title":"Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems","abstract":"Diffusion models have achieved excellent success in solving inverse problems due to their ability to learn strong image priors, but existing approaches require a large training dataset of images that should come from the same distribution as the test dataset. When the training and test distributions are mismatched, artifacts and hallucinations can occur in reconstructed images due to the incorrect priors. In this work, we systematically study out of distribution (OOD) problems where a known training distribution is first provided. We first study the setting where only a single measurement obtained from the unknown test distribution is available. Next we study the setting where a very small sample of data belonging to the test distribution is available, and our goal is still to reconstruct an image from a measurement that came from the test distribution. In both settings, we use a patch-based diffusion prior that learns the image distribution solely from patches. Furthermore, in the first setting, we include a self-supervised loss that helps the network output maintain consistency with the measurement. Extensive experiments show that in both settings, the patch-based method can obtain high quality image reconstructions that can outperform whole-image models and can compete with methods that have access to large in-distribution training datasets. Furthermore, we show how whole-image models are prone to memorization and overfitting, leading to artifacts in the reconstructions, while a patch-based model can resolve these issues.","sentences":["Diffusion models have achieved excellent success in solving inverse problems due to their ability to learn strong image priors, but existing approaches require a large training dataset of images that should come from the same distribution as the test dataset.","When the training and test distributions are mismatched, artifacts and hallucinations can occur in reconstructed images due to the incorrect priors.","In this work, we systematically study out of distribution (OOD) problems where a known training distribution is first provided.","We first study the setting where only a single measurement obtained from the unknown test distribution is available.","Next we study the setting where a very small sample of data belonging to the test distribution is available, and our goal is still to reconstruct an image from a measurement that came from the test distribution.","In both settings, we use a patch-based diffusion prior that learns the image distribution solely from patches.","Furthermore, in the first setting, we include a self-supervised loss that helps the network output maintain consistency with the measurement.","Extensive experiments show that in both settings, the patch-based method can obtain high quality image reconstructions that can outperform whole-image models and can compete with methods that have access to large in-distribution training datasets.","Furthermore, we show how whole-image models are prone to memorization and overfitting, leading to artifacts in the reconstructions, while a patch-based model can resolve these issues."],"url":"http://arxiv.org/abs/2410.11730v1"}
{"created":"2024-10-15 16:00:01","title":"YOLO-ELA: Efficient Local Attention Modeling for High-Performance Real-Time Insulator Defect Detection","abstract":"Existing detection methods for insulator defect identification from unmanned aerial vehicles (UAV) struggle with complex background scenes and small objects, leading to suboptimal accuracy and a high number of false positives detection. Using the concept of local attention modeling, this paper proposes a new attention-based foundation architecture, YOLO-ELA, to address this issue. The Efficient Local Attention (ELA) blocks were added into the neck part of the one-stage YOLOv8 architecture to shift the model's attention from background features towards features of insulators with defects. The SCYLLA Intersection-Over-Union (SIoU) criterion function was used to reduce detection loss, accelerate model convergence, and increase the model's sensitivity towards small insulator defects, yielding higher true positive outcomes. Due to a limited dataset, data augmentation techniques were utilized to increase the diversity of the dataset. In addition, we leveraged the transfer learning strategy to improve the model's performance. Experimental results on high-resolution UAV images show that our method achieved a state-of-the-art performance of 96.9% mAP0.5 and a real-time detection speed of 74.63 frames per second, outperforming the baseline model. This further demonstrates the effectiveness of attention-based convolutional neural networks (CNN) in object detection tasks.","sentences":["Existing detection methods for insulator defect identification from unmanned aerial vehicles (UAV) struggle with complex background scenes and small objects, leading to suboptimal accuracy and a high number of false positives detection.","Using the concept of local attention modeling, this paper proposes a new attention-based foundation architecture, YOLO-ELA, to address this issue.","The Efficient Local Attention (ELA) blocks were added into the neck part of the one-stage YOLOv8 architecture to shift the model's attention from background features towards features of insulators with defects.","The SCYLLA Intersection-Over-Union (SIoU) criterion function was used to reduce detection loss, accelerate model convergence, and increase the model's sensitivity towards small insulator defects, yielding higher true positive outcomes.","Due to a limited dataset, data augmentation techniques were utilized to increase the diversity of the dataset.","In addition, we leveraged the transfer learning strategy to improve the model's performance.","Experimental results on high-resolution UAV images show that our method achieved a state-of-the-art performance of 96.9% mAP0.5 and a real-time detection speed of 74.63 frames per second, outperforming the baseline model.","This further demonstrates the effectiveness of attention-based convolutional neural networks (CNN) in object detection tasks."],"url":"http://arxiv.org/abs/2410.11727v1"}
{"created":"2024-10-15 15:55:42","title":"Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers","abstract":"Effective trajectory generation is essential for reliable on-board spacecraft autonomy. Among other approaches, learning-based warm-starting represents an appealing paradigm for solving the trajectory generation problem, effectively combining the benefits of optimization- and data-driven methods. Current approaches for learning-based trajectory generation often focus on fixed, single-scenario environments, where key scene characteristics, such as obstacle positions or final-time requirements, remain constant across problem instances. However, practical trajectory generation requires the scenario to be frequently reconfigured, making the single-scenario approach a potentially impractical solution. To address this challenge, we present a novel trajectory generation framework that generalizes across diverse problem configurations, by leveraging high-capacity transformer neural networks capable of learning from multimodal data sources. Specifically, our approach integrates transformer-based neural network models into the trajectory optimization process, encoding both scene-level information (e.g., obstacle locations, initial and goal states) and trajectory-level constraints (e.g., time bounds, fuel consumption targets) via multimodal representations. The transformer network then generates near-optimal initial guesses for non-convex optimization problems, significantly enhancing convergence speed and performance. The framework is validated through extensive simulations and real-world experiments on a free-flyer platform, achieving up to 30% cost improvement and 80% reduction in infeasible cases with respect to traditional approaches, and demonstrating robust generalization across diverse scenario variations.","sentences":["Effective trajectory generation is essential for reliable on-board spacecraft autonomy.","Among other approaches, learning-based warm-starting represents an appealing paradigm for solving the trajectory generation problem, effectively combining the benefits of optimization- and data-driven methods.","Current approaches for learning-based trajectory generation often focus on fixed, single-scenario environments, where key scene characteristics, such as obstacle positions or final-time requirements, remain constant across problem instances.","However, practical trajectory generation requires the scenario to be frequently reconfigured, making the single-scenario approach a potentially impractical solution.","To address this challenge, we present a novel trajectory generation framework that generalizes across diverse problem configurations, by leveraging high-capacity transformer neural networks capable of learning from multimodal data sources.","Specifically, our approach integrates transformer-based neural network models into the trajectory optimization process, encoding both scene-level information (e.g., obstacle locations, initial and goal states) and trajectory-level constraints (e.g., time bounds, fuel consumption targets) via multimodal representations.","The transformer network then generates near-optimal initial guesses for non-convex optimization problems, significantly enhancing convergence speed and performance.","The framework is validated through extensive simulations and real-world experiments on a free-flyer platform, achieving up to 30% cost improvement and 80% reduction in infeasible cases with respect to traditional approaches, and demonstrating robust generalization across diverse scenario variations."],"url":"http://arxiv.org/abs/2410.11723v1"}
{"created":"2024-10-15 15:55:00","title":"RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation","abstract":"The emergence of Segment Anything (SAM) sparked research interest in the field of interactive segmentation, especially in the context of image editing tasks and speeding up data annotation. Unlike common semantic segmentation, interactive segmentation methods allow users to directly influence their output through prompts (e.g. clicks). However, click patterns in real-world interactive segmentation scenarios remain largely unexplored. Most methods rely on the assumption that users would click in the center of the largest erroneous area. Nevertheless, recent studies show that this is not always the case. Thus, methods may have poor performance in real-world deployment despite high metrics in a baseline benchmark. To accurately simulate real-user clicks, we conducted a large crowdsourcing study of click patterns in an interactive segmentation scenario and collected 475K real-user clicks. Drawing on ideas from saliency tasks, we develop a clickability model that enables sampling clicks, which closely resemble actual user inputs. Using our model and dataset, we propose RClicks benchmark for a comprehensive comparison of existing interactive segmentation methods on realistic clicks. Specifically, we evaluate not only the average quality of methods, but also the robustness w.r.t. click patterns. According to our benchmark, in real-world usage interactive segmentation models may perform worse than it has been reported in the baseline benchmark, and most of the methods are not robust. We believe that RClicks is a significant step towards creating interactive segmentation methods that provide the best user experience in real-world cases.","sentences":["The emergence of Segment Anything (SAM) sparked research interest in the field of interactive segmentation, especially in the context of image editing tasks and speeding up data annotation.","Unlike common semantic segmentation, interactive segmentation methods allow users to directly influence their output through prompts (e.g. clicks).","However, click patterns in real-world interactive segmentation scenarios remain largely unexplored.","Most methods rely on the assumption that users would click in the center of the largest erroneous area.","Nevertheless, recent studies show that this is not always the case.","Thus, methods may have poor performance in real-world deployment despite high metrics in a baseline benchmark.","To accurately simulate real-user clicks, we conducted a large crowdsourcing study of click patterns in an interactive segmentation scenario and collected 475K real-user clicks.","Drawing on ideas from saliency tasks, we develop a clickability model that enables sampling clicks, which closely resemble actual user inputs.","Using our model and dataset, we propose RClicks benchmark for a comprehensive comparison of existing interactive segmentation methods on realistic clicks.","Specifically, we evaluate not only the average quality of methods, but also the robustness w.r.t.","click patterns.","According to our benchmark, in real-world usage interactive segmentation models may perform worse than it has been reported in the baseline benchmark, and most of the methods are not robust.","We believe that RClicks is a significant step towards creating interactive segmentation methods that provide the best user experience in real-world cases."],"url":"http://arxiv.org/abs/2410.11722v1"}
{"created":"2024-10-15 15:52:45","title":"Light-Weight Fault Tolerant Attention for Large Language Model Training","abstract":"Large Language Models (LLMs) have demonstrated remarkable performance in various natural language processing tasks. However, the training of these models is computationally intensive and susceptible to faults, particularly in the attention mechanism, which is a critical component of transformer-based LLMs. In this paper, we investigate the impact of faults on LLM training, focusing on INF, NaN, and near-INF values in the computation results with systematic fault injection experiments. We observe the propagation patterns of these errors, which can trigger non-trainable states in the model and disrupt training, forcing the procedure to load from checkpoints.To mitigate the impact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault Tolerance (ABFT) technique tailored for the attention mechanism in LLMs. ATTNChecker is designed based on fault propagation patterns of LLM and incorporates performance optimization to adapt to both system reliability and model vulnerability while providing lightweight protection for fast LLM training. Evaluations on four LLMs show that ATTNChecker on average incurs on average 7% overhead on training while detecting and correcting all extreme errors. Compared with the state-of-the-art checkpoint/restore approach, ATTNChecker reduces recovery overhead by up to 49x.","sentences":["Large Language Models (LLMs) have demonstrated remarkable performance in various natural language processing tasks.","However, the training of these models is computationally intensive and susceptible to faults, particularly in the attention mechanism, which is a critical component of transformer-based LLMs.","In this paper, we investigate the impact of faults on LLM training, focusing on INF, NaN, and near-INF values in the computation results with systematic fault injection experiments.","We observe the propagation patterns of these errors, which can trigger non-trainable states in the model and disrupt training, forcing the procedure to load from checkpoints.","To mitigate the impact of these faults, we propose ATTNChecker, the first Algorithm-Based Fault Tolerance (ABFT) technique tailored for the attention mechanism in LLMs.","ATTNChecker is designed based on fault propagation patterns of LLM and incorporates performance optimization to adapt to both system reliability and model vulnerability while providing lightweight protection for fast LLM training.","Evaluations on four LLMs show that ATTNChecker on average incurs on average 7% overhead on training while detecting and correcting all extreme errors.","Compared with the state-of-the-art checkpoint/restore approach, ATTNChecker reduces recovery overhead by up to 49x."],"url":"http://arxiv.org/abs/2410.11720v1"}
{"created":"2024-10-15 15:50:53","title":"Adaptive Coordinators and Prompts on Heterogeneous Graphs for Cross-Domain Recommendations","abstract":"In the online digital world, users frequently engage with diverse items across multiple domains (e.g., e-commerce platforms, streaming services, and social media networks), forming complex heterogeneous interaction graphs. Leveraging this multi-domain information can undoubtedly enhance the performance of recommendation systems by providing more comprehensive user insights and alleviating data sparsity in individual domains. However, integrating multi-domain knowledge for the cross-domain recommendation is very hard due to inherent disparities in user behavior and item characteristics and the risk of negative transfer, where irrelevant or conflicting information from the source domains adversely impacts the target domain's performance. To address these challenges, we offer HAGO, a novel framework with $\\textbf{H}$eterogeneous $\\textbf{A}$daptive $\\textbf{G}$raph co$\\textbf{O}$rdinators, which dynamically integrate multi-domain graphs into a cohesive structure by adaptively adjusting the connections between coordinators and multi-domain graph nodes, thereby enhancing beneficial inter-domain interactions while mitigating negative transfer effects. Additionally, we develop a universal multi-domain graph pre-training strategy alongside HAGO to collaboratively learn high-quality node representations across domains. To effectively transfer the learned multi-domain knowledge to the target domain, we design an effective graph prompting method, which incorporates pre-trained embeddings with learnable prompts for the recommendation task. Our framework is compatible with various graph-based models and pre-training techniques, demonstrating broad applicability and effectiveness. Further experimental results show that our solutions outperform state-of-the-art methods in multi-domain recommendation scenarios and highlight their potential for real-world applications.","sentences":["In the online digital world, users frequently engage with diverse items across multiple domains (e.g., e-commerce platforms, streaming services, and social media networks), forming complex heterogeneous interaction graphs.","Leveraging this multi-domain information can undoubtedly enhance the performance of recommendation systems by providing more comprehensive user insights and alleviating data sparsity in individual domains.","However, integrating multi-domain knowledge for the cross-domain recommendation is very hard due to inherent disparities in user behavior and item characteristics and the risk of negative transfer, where irrelevant or conflicting information from the source domains adversely impacts the target domain's performance.","To address these challenges, we offer HAGO, a novel framework with $\\textbf{H}$eterogeneous $\\textbf{A}$daptive $\\textbf{G}$raph co$\\textbf{O}$rdinators, which dynamically integrate multi-domain graphs into a cohesive structure by adaptively adjusting the connections between coordinators and multi-domain graph nodes, thereby enhancing beneficial inter-domain interactions while mitigating negative transfer effects.","Additionally, we develop a universal multi-domain graph pre-training strategy alongside HAGO to collaboratively learn high-quality node representations across domains.","To effectively transfer the learned multi-domain knowledge to the target domain, we design an effective graph prompting method, which incorporates pre-trained embeddings with learnable prompts for the recommendation task.","Our framework is compatible with various graph-based models and pre-training techniques, demonstrating broad applicability and effectiveness.","Further experimental results show that our solutions outperform state-of-the-art methods in multi-domain recommendation scenarios and highlight their potential for real-world applications."],"url":"http://arxiv.org/abs/2410.11719v1"}
{"created":"2024-10-15 15:49:15","title":"Converging to a Lingua Franca: Evolution of Linguistic Regions and Semantics Alignment in Multilingual Large Language Models","abstract":"Large language models (LLMs) have demonstrated remarkable performance, particularly in multilingual contexts. While recent studies suggest that LLMs can transfer skills learned in one language to others, the internal mechanisms behind this ability remain unclear. We observed that the neuron activation patterns of LLMs exhibit similarities when processing the same language, revealing the existence and location of key linguistic regions. Additionally, we found that neuron activation patterns are similar when processing sentences with the same semantic meaning in different languages. This indicates that LLMs map semantically identical inputs from different languages into a \"Lingua Franca\", a common semantic latent space that allows for consistent processing across languages. This semantic alignment becomes more pronounced with training and increased model size, resulting in a more language-agnostic activation pattern. Moreover, we found that key linguistic neurons are concentrated in the first and last layers of LLMs, becoming denser in the first layers as training progresses. Experiments on BLOOM and LLaMA2 support these findings, highlighting the structural evolution of multilingual LLMs during training and scaling up. This paper provides insights into the internal workings of LLMs, offering a foundation for future improvements in their cross-lingual capabilities.","sentences":["Large language models (LLMs) have demonstrated remarkable performance, particularly in multilingual contexts.","While recent studies suggest that LLMs can transfer skills learned in one language to others, the internal mechanisms behind this ability remain unclear.","We observed that the neuron activation patterns of LLMs exhibit similarities when processing the same language, revealing the existence and location of key linguistic regions.","Additionally, we found that neuron activation patterns are similar when processing sentences with the same semantic meaning in different languages.","This indicates that LLMs map semantically identical inputs from different languages into a \"Lingua Franca\", a common semantic latent space that allows for consistent processing across languages.","This semantic alignment becomes more pronounced with training and increased model size, resulting in a more language-agnostic activation pattern.","Moreover, we found that key linguistic neurons are concentrated in the first and last layers of LLMs, becoming denser in the first layers as training progresses.","Experiments on BLOOM and LLaMA2 support these findings, highlighting the structural evolution of multilingual LLMs during training and scaling up.","This paper provides insights into the internal workings of LLMs, offering a foundation for future improvements in their cross-lingual capabilities."],"url":"http://arxiv.org/abs/2410.11718v1"}
{"created":"2024-10-15 15:47:01","title":"Parameter estimation of structural dynamics with neural operators enabled surrogate modeling","abstract":"Parameter estimation generally involves inferring the values of mathematical models derived from first principles or expert knowledge, which is challenging for complex structural systems. In this work, we present a unified deep learning-based framework for parameterization, forward modeling, and inverse modeling of structural dynamics. The parameterization is flexible and can be user-defined, including physical and/or non-physical (customized) parameters. In forward modeling, we train a neural operator for response prediction -- forming a surrogate model, which leverages the defined system parameters and excitation forces as inputs. The inverse modeling focuses on estimating system parameters. In particular, the learned forward surrogate model (which is differentiable) is utilized for preliminary parameter estimation via gradient-based optimization; to further boost the parameter estimation, we introduce a neural refinement method to mitigate ill-posed problems, which often occur in the former. The framework's effectiveness is verified numerically and experimentally, in both interpolation and extrapolation cases, indicating its capability to capture intrinsic dynamics of structural systems from both forward and inverse perspectives. Moreover, the framework's flexibility is expected to support a wide range of applications, including surrogate modeling, structural identification, damage detection, and inverse design of structural systems.","sentences":["Parameter estimation generally involves inferring the values of mathematical models derived from first principles or expert knowledge, which is challenging for complex structural systems.","In this work, we present a unified deep learning-based framework for parameterization, forward modeling, and inverse modeling of structural dynamics.","The parameterization is flexible and can be user-defined, including physical and/or non-physical (customized) parameters.","In forward modeling, we train a neural operator for response prediction -- forming a surrogate model, which leverages the defined system parameters and excitation forces as inputs.","The inverse modeling focuses on estimating system parameters.","In particular, the learned forward surrogate model (which is differentiable) is utilized for preliminary parameter estimation via gradient-based optimization; to further boost the parameter estimation, we introduce a neural refinement method to mitigate ill-posed problems, which often occur in the former.","The framework's effectiveness is verified numerically and experimentally, in both interpolation and extrapolation cases, indicating its capability to capture intrinsic dynamics of structural systems from both forward and inverse perspectives.","Moreover, the framework's flexibility is expected to support a wide range of applications, including surrogate modeling, structural identification, damage detection, and inverse design of structural systems."],"url":"http://arxiv.org/abs/2410.11712v1"}
{"created":"2024-10-15 15:46:17","title":"MTU-Bench: A Multi-granularity Tool-Use Benchmark for Large Language Models","abstract":"Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users. Recently, many tool-use benchmark datasets have been proposed. However, existing datasets have the following limitations: (1). Insufficient evaluation scenarios (e.g., only cover limited tool-use scenes). (2). Extensive evaluation costs (e.g., GPT API costs). To address these limitations, in this work, we propose a multi-granularity tool-use benchmark for large language models called MTU-Bench. For the \"multi-granularity\" property, our MTU-Bench covers five tool usage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool, multiple-turn and single-tool, multiple-turn and multiple-tool, and out-of-distribution tasks). Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics. Moreover, our MTU-Bench is collected by transforming existing high-quality datasets to simulate real-world tool usage scenarios, and we also propose an instruction dataset called MTU-Instruct data to enhance the tool-use abilities of existing LLMs. Comprehensive experimental results demonstrate the effectiveness of our MTU-Bench. Code and data will be released at https: //github.com/MTU-Bench-Team/MTU-Bench.git.","sentences":["Large Language Models (LLMs) have displayed massive improvements in reasoning and decision-making skills and can hold natural conversations with users.","Recently, many tool-use benchmark datasets have been proposed.","However, existing datasets have the following limitations: (1).","Insufficient evaluation scenarios (e.g., only cover limited tool-use scenes).","(2).","Extensive evaluation costs (e.g., GPT API costs).","To address these limitations, in this work, we propose a multi-granularity tool-use benchmark for large language models called MTU-Bench.","For the \"multi-granularity\" property, our MTU-Bench covers five tool usage scenes (i.e., single-turn and single-tool, single-turn and multiple-tool, multiple-turn and single-tool, multiple-turn and multiple-tool, and out-of-distribution tasks).","Besides, all evaluation metrics of our MTU-Bench are based on the prediction results and the ground truth without using any GPT or human evaluation metrics.","Moreover, our MTU-Bench is collected by transforming existing high-quality datasets to simulate real-world tool usage scenarios, and we also propose an instruction dataset called MTU-Instruct data to enhance the tool-use abilities of existing LLMs.","Comprehensive experimental results demonstrate the effectiveness of our MTU-Bench.","Code and data will be released at https: //github.com/MTU-Bench-Team/MTU-Bench.git."],"url":"http://arxiv.org/abs/2410.11710v1"}
{"created":"2024-10-15 15:46:03","title":"On the potential of Optimal Transport in Geospatial Data Science","abstract":"Prediction problems in geographic information science and transportation are frequently motivated by the possibility to enhance operational efficiency. Examples range from predicting car sharing demand for optimizing relocation to forecasting traffic congestion for navigation purposes. However, conventional accuracy metrics do not account for the spatial distribution of predictions errors, despite its relevance for operations. We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function. The proposed OT metric assesses the utility of spatial prediction models in terms of the relocation costs caused by prediction errors. In experiments on real and synthetic data, we demonstrate that 1) the spatial distribution of the prediction errors is relevant in many applications and can be translated to real-world costs, 2) in contrast to other metrics, OT reflects these spatial costs, and 3) OT metrics improve comparability across spatial and temporal scales. Finally, we advocate for leveraging OT as a loss function in neural networks to improve the spatial correctness of predictions. This approach not only aligns evaluation in GeoAI with operational considerations, but also signifies a step forward in refining predictions within geospatial applications. To facilitate the adoption of OT in GIS, we provide code and tutorials at https://github.com/mie-lab/geospatialOT.","sentences":["Prediction problems in geographic information science and transportation are frequently motivated by the possibility to enhance operational efficiency.","Examples range from predicting car sharing demand for optimizing relocation to forecasting traffic congestion for navigation purposes.","However, conventional accuracy metrics do not account for the spatial distribution of predictions errors, despite its relevance for operations.","We put forward Optimal Transport (OT) as a spatial evaluation metric and loss function.","The proposed OT metric assesses the utility of spatial prediction models in terms of the relocation costs caused by prediction errors.","In experiments on real and synthetic data, we demonstrate that 1) the spatial distribution of the prediction errors is relevant in many applications and can be translated to real-world costs, 2) in contrast to other metrics, OT reflects these spatial costs, and 3) OT metrics improve comparability across spatial and temporal scales.","Finally, we advocate for leveraging OT as a loss function in neural networks to improve the spatial correctness of predictions.","This approach not only aligns evaluation in GeoAI with operational considerations, but also signifies a step forward in refining predictions within geospatial applications.","To facilitate the adoption of OT in GIS, we provide code and tutorials at https://github.com/mie-lab/geospatialOT."],"url":"http://arxiv.org/abs/2410.11709v1"}
{"created":"2024-10-15 15:45:58","title":"The Age of DDoScovery: An Empirical Comparison of Industry and Academic DDoS Assessments","abstract":"Motivated by the impressive but diffuse scope of DDoS research and reporting, we undertake a multistakeholder (joint industry-academic) analysis to seek convergence across the best available macroscopic views of the relative trends in two dominant classes of attacks - direct-path attacks and reflection-amplification attacks. We first analyze 24 industry reports to extract trends and (in)consistencies across observations by commercial stakeholders in 2022. We then analyze ten data sets spanning industry and academic sources, across four years (2019-2023), to find and explain discrepancies based on data sources, vantage points, methods, and parameters. Our method includes a new approach: we share an aggregated list of DDoS targets with industry players who return the results of joining this list with their proprietary data sources to reveal gaps in visibility of the academic data sources. We use academic data sources to explore an industry-reported relative drop in spoofed reflection-amplification attacks in 2021-2022. Our study illustrates the value, but also the challenge, in independent validation of security-related properties of Internet infrastructure. Finally, we reflect on opportunities to facilitate greater common understanding of the DDoS landscape. We hope our results inform not only future academic and industry pursuits but also emerging policy efforts to reduce systemic Internet security vulnerabilities.","sentences":["Motivated by the impressive but diffuse scope of DDoS research and reporting, we undertake a multistakeholder (joint industry-academic) analysis to seek convergence across the best available macroscopic views of the relative trends in two dominant classes of attacks - direct-path attacks and reflection-amplification attacks.","We first analyze 24 industry reports to extract trends and (in)consistencies across observations by commercial stakeholders in 2022.","We then analyze ten data sets spanning industry and academic sources, across four years (2019-2023), to find and explain discrepancies based on data sources, vantage points, methods, and parameters.","Our method includes a new approach: we share an aggregated list of DDoS targets with industry players who return the results of joining this list with their proprietary data sources to reveal gaps in visibility of the academic data sources.","We use academic data sources to explore an industry-reported relative drop in spoofed reflection-amplification attacks in 2021-2022.","Our study illustrates the value, but also the challenge, in independent validation of security-related properties of Internet infrastructure.","Finally, we reflect on opportunities to facilitate greater common understanding of the DDoS landscape.","We hope our results inform not only future academic and industry pursuits but also emerging policy efforts to reduce systemic Internet security vulnerabilities."],"url":"http://arxiv.org/abs/2410.11708v1"}
{"created":"2024-10-15 15:42:30","title":"Robotic Arm Platform for Multi-View Image Acquisition and 3D Reconstruction in Minimally Invasive Surgery","abstract":"Minimally invasive surgery (MIS) offers significant benefits such as reduced recovery time and minimised patient trauma, but poses challenges in visibility and access, making accurate 3D reconstruction a significant tool in surgical planning and navigation. This work introduces a robotic arm platform for efficient multi-view image acquisition and precise 3D reconstruction in MIS settings. We adapted a laparoscope to a robotic arm and captured ex-vivo images of several ovine organs across varying lighting conditions (operating room and laparoscopic) and trajectories (spherical and laparoscopic). We employed recently released learning-based feature matchers combined with COLMAP to produce our reconstructions. The reconstructions were evaluated against high-precision laser scans for quantitative evaluation. Our results show that whilst reconstructions suffer most under realistic MIS lighting and trajectory, many versions of our pipeline achieve close to sub-millimetre accuracy with an average of 1.05 mm Root Mean Squared Error and 0.82 mm Chamfer distance. Our best reconstruction results occur with operating room lighting and spherical trajectories. Our robotic platform provides a tool for controlled, repeatable multi-view data acquisition for 3D generation in MIS environments which we hope leads to new datasets for training learning-based models.","sentences":["Minimally invasive surgery (MIS) offers significant benefits such as reduced recovery time and minimised patient trauma, but poses challenges in visibility and access, making accurate 3D reconstruction a significant tool in surgical planning and navigation.","This work introduces a robotic arm platform for efficient multi-view image acquisition and precise 3D reconstruction in MIS settings.","We adapted a laparoscope to a robotic arm and captured ex-vivo images of several ovine organs across varying lighting conditions (operating room and laparoscopic) and trajectories (spherical and laparoscopic).","We employed recently released learning-based feature matchers combined with COLMAP to produce our reconstructions.","The reconstructions were evaluated against high-precision laser scans for quantitative evaluation.","Our results show that whilst reconstructions suffer most under realistic MIS lighting and trajectory, many versions of our pipeline achieve close to sub-millimetre accuracy with an average of 1.05 mm Root Mean Squared Error and 0.82 mm Chamfer distance.","Our best reconstruction results occur with operating room lighting and spherical trajectories.","Our robotic platform provides a tool for controlled, repeatable multi-view data acquisition for 3D generation in MIS environments which we hope leads to new datasets for training learning-based models."],"url":"http://arxiv.org/abs/2410.11703v1"}
{"created":"2024-10-15 15:41:49","title":"It's Just Another Day: Unique Video Captioning by Discriminative Prompting","abstract":"Long videos contain many repeating actions, events and shots. These repetitions are frequently given identical captions, which makes it difficult to retrieve the exact desired clip using a text search. In this paper, we formulate the problem of unique captioning: Given multiple clips with the same caption, we generate a new caption for each clip that uniquely identifies it. We propose Captioning by Discriminative Prompting (CDP), which predicts a property that can separate identically captioned clips, and use it to generate unique captions. We introduce two benchmarks for unique captioning, based on egocentric footage and timeloop movies - where repeating actions are common. We demonstrate that captions generated by CDP improve text-to-video R@1 by 15% for egocentric videos and 10% in timeloop movies.","sentences":["Long videos contain many repeating actions, events and shots.","These repetitions are frequently given identical captions, which makes it difficult to retrieve the exact desired clip using a text search.","In this paper, we formulate the problem of unique captioning: Given multiple clips with the same caption, we generate a new caption for each clip that uniquely identifies it.","We propose Captioning by Discriminative Prompting (CDP), which predicts a property that can separate identically captioned clips, and use it to generate unique captions.","We introduce two benchmarks for unique captioning, based on egocentric footage and timeloop movies - where repeating actions are common.","We demonstrate that captions generated by CDP improve text-to-video R@1 by 15% for egocentric videos and 10% in timeloop movies."],"url":"http://arxiv.org/abs/2410.11702v1"}
{"created":"2024-10-15 15:39:37","title":"Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions","abstract":"Hallucinations in multimodal large language models (MLLMs) hinder their practical applications. To address this, we propose a Magnifier Prompt (MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs via extremely simple instructions. MagPrompt is based on the following two key principles, which guide the design of various effective prompts, demonstrating robustness: (1) MLLMs should focus more on the image. (2) When there are conflicts between the image and the model's inner knowledge, MLLMs should prioritize the image. MagPrompt is training-free and can be applied to open-source and closed-source models, such as GPT-4o and Gemini-pro. It performs well across many datasets and its effectiveness is comparable or even better than more complex methods like VCD. Furthermore, our prompt design principles and experimental analyses provide valuable insights into multimodal hallucination.","sentences":["Hallucinations in multimodal large language models (MLLMs) hinder their practical applications.","To address this, we propose a Magnifier Prompt (MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs via extremely simple instructions.","MagPrompt is based on the following two key principles, which guide the design of various effective prompts, demonstrating robustness: (1) MLLMs should focus more on the image.","(2) When there are conflicts between the image and the model's inner knowledge, MLLMs should prioritize the image.","MagPrompt is training-free and can be applied to open-source and closed-source models, such as GPT-4o and Gemini-pro.","It performs well across many datasets and its effectiveness is comparable or even better than more complex methods like VCD.","Furthermore, our prompt design principles and experimental analyses provide valuable insights into multimodal hallucination."],"url":"http://arxiv.org/abs/2410.11701v1"}
{"created":"2024-10-15 15:31:41","title":"AI Rules? Characterizing Reddit Community Policies Towards AI-Generated Content","abstract":"How are Reddit communities responding to AI-generated content? We explored this question through a large-scale analysis of subreddit community rules and their change over time. We collected the metadata and community rules for over 300,000 public subreddits and measured the prevalence of rules governing AI. We labeled subreddits and AI rules according to existing taxonomies from the HCI literature and a new taxonomy we developed specific to AI rules. While rules about AI are still relatively uncommon, the number of subreddits with these rules almost doubled over the course of a year. AI rules are also more common in larger subreddits and communities focused on art or celebrity topics, and less common in those focused on social support. These rules often focus on AI images and evoke, as justification, concerns about quality and authenticity. Overall, our findings illustrate the emergence of varied concerns about AI, in different community contexts.","sentences":["How are Reddit communities responding to AI-generated content?","We explored this question through a large-scale analysis of subreddit community rules and their change over time.","We collected the metadata and community rules for over 300,000 public subreddits and measured the prevalence of rules governing AI.","We labeled subreddits and AI rules according to existing taxonomies from the HCI literature and a new taxonomy we developed specific to AI rules.","While rules about AI are still relatively uncommon, the number of subreddits with these rules almost doubled over the course of a year.","AI rules are also more common in larger subreddits and communities focused on art or celebrity topics, and less common in those focused on social support.","These rules often focus on AI images and evoke, as justification, concerns about quality and authenticity.","Overall, our findings illustrate the emergence of varied concerns about AI, in different community contexts."],"url":"http://arxiv.org/abs/2410.11698v1"}
{"created":"2024-10-15 15:26:28","title":"IntGrad MT: Eliciting LLMs' Machine Translation Capabilities with Sentence Interpolation and Gradual MT","abstract":"Recent Large Language Models (LLMs) have demonstrated strong performance in translation without needing to be finetuned on additional parallel corpora. However, they still underperform for low-resource language pairs. Previous works have focused on mitigating this issue by leveraging relevant few-shot examples or external resources such as dictionaries or grammar books, making models heavily reliant on these nonparametric sources of information. In this paper, we propose a novel method named IntGrad MT that focuses on fully exploiting an LLM's inherent translation capability. IntGrad MT achieves this by constructing a chain of few-shot examples, each consisting of a source sentence and the model's own translation, that rise incrementally in difficulty. IntGrad MT employs two techniques: Sentence Interpolation, which generates a sequence of sentences that gradually change from an easy sentence to translate to a difficult one, and Gradual MT, which sequentially translates this chain using translations of earlier sentences as few-shot examples for the translation of subsequent ones. With this approach, we observe a substantial enhancement in the xCOMET scores of various LLMs for multiple languages, especially in low-resource languages such as Hindi(8.26), Swahili(7.10), Bengali(6.97) and Marathi(13.03). Our approach presents a practical way of enhancing LLMs' performance without extra training.","sentences":["Recent Large Language Models (LLMs) have demonstrated strong performance in translation without needing to be finetuned on additional parallel corpora.","However, they still underperform for low-resource language pairs.","Previous works have focused on mitigating this issue by leveraging relevant few-shot examples or external resources such as dictionaries or grammar books, making models heavily reliant on these nonparametric sources of information.","In this paper, we propose a novel method named IntGrad MT that focuses on fully exploiting an LLM's inherent translation capability.","IntGrad MT achieves this by constructing a chain of few-shot examples, each consisting of a source sentence and the model's own translation, that rise incrementally in difficulty.","IntGrad MT employs two techniques: Sentence Interpolation, which generates a sequence of sentences that gradually change from an easy sentence to translate to a difficult one, and Gradual MT, which sequentially translates this chain using translations of earlier sentences as few-shot examples for the translation of subsequent ones.","With this approach, we observe a substantial enhancement in the xCOMET scores of various LLMs for multiple languages, especially in low-resource languages such as Hindi(8.26), Swahili(7.10), Bengali(6.97) and Marathi(13.03).","Our approach presents a practical way of enhancing LLMs' performance without extra training."],"url":"http://arxiv.org/abs/2410.11693v1"}
{"created":"2024-10-15 15:24:20","title":"BlendRL: A Framework for Merging Symbolic and Neural Policy Learning","abstract":"Humans can leverage both symbolic reasoning and intuitive reactions. In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules. This disjointed approach severely limits the agents' capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms within RL agents that use mixtures of both logic and neural policies. We empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes. Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations.","sentences":["Humans can leverage both symbolic reasoning and intuitive reactions.","In contrast, reinforcement learning policies are typically encoded in either opaque systems like neural networks or symbolic systems that rely on predefined symbols and rules.","This disjointed approach severely limits the agents' capabilities, as they often lack either the flexible low-level reaction characteristic of neural agents or the interpretable reasoning of symbolic agents.","To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL framework that harmoniously integrates both paradigms within RL agents that use mixtures of both logic and neural policies.","We empirically demonstrate that BlendRL agents outperform both neural and symbolic baselines in standard Atari environments, and showcase their robustness to environmental changes.","Additionally, we analyze the interaction between neural and symbolic policies, illustrating how their hybrid use helps agents overcome each other's limitations."],"url":"http://arxiv.org/abs/2410.11689v1"}
{"created":"2024-10-15 15:24:08","title":"Visual Fixation-Based Retinal Prosthetic Simulation","abstract":"This study proposes a retinal prosthetic simulation framework driven by visual fixations, inspired by the saccade mechanism, and assesses performance improvements through end-to-end optimization in a classification task. Salient patches are predicted from input images using the self-attention map of a vision transformer to mimic visual fixations. These patches are then encoded by a trainable U-Net and simulated using the pulse2percept framework to predict visual percepts. By incorporating a learnable encoder, we aim to optimize the visual information transmitted to the retinal implant, addressing both the limited resolution of the electrode array and the distortion between the input stimuli and resulting phosphenes. The predicted percepts are evaluated using the self-supervised DINOv2 foundation model, with an optional learnable linear layer for classification accuracy. On a subset of the ImageNet validation set, the fixation-based framework achieves a classification accuracy of 87.72%, using computational parameters based on a real subject's physiological data, significantly outperforming the downsampling-based accuracy of 40.59% and approaching the healthy upper bound of 92.76%. Our approach shows promising potential for producing more semantically understandable percepts with the limited resolution available in retinal prosthetics.","sentences":["This study proposes a retinal prosthetic simulation framework driven by visual fixations, inspired by the saccade mechanism, and assesses performance improvements through end-to-end optimization in a classification task.","Salient patches are predicted from input images using the self-attention map of a vision transformer to mimic visual fixations.","These patches are then encoded by a trainable U-Net and simulated using the pulse2percept framework to predict visual percepts.","By incorporating a learnable encoder, we aim to optimize the visual information transmitted to the retinal implant, addressing both the limited resolution of the electrode array and the distortion between the input stimuli and resulting phosphenes.","The predicted percepts are evaluated using the self-supervised DINOv2 foundation model, with an optional learnable linear layer for classification accuracy.","On a subset of the ImageNet validation set, the fixation-based framework achieves a classification accuracy of 87.72%, using computational parameters based on a real subject's physiological data, significantly outperforming the downsampling-based accuracy of 40.59% and approaching the healthy upper bound of 92.76%.","Our approach shows promising potential for producing more semantically understandable percepts with the limited resolution available in retinal prosthetics."],"url":"http://arxiv.org/abs/2410.11688v1"}
{"created":"2024-10-15 15:22:38","title":"State-space models can learn in-context by gradient descent","abstract":"Deep state-space models (Deep SSMs) have shown capabilities for in-context learning on autoregressive tasks, similar to transformers. However, the architectural requirements and mechanisms enabling this in recurrent networks remain unclear. This study demonstrates that state-space model architectures can perform gradient-based learning and use it for in-context learning. We prove that a single structured state-space model layer, augmented with local self-attention, can reproduce the outputs of an implicit linear model with least squares loss after one step of gradient descent. Our key insight is that the diagonal linear recurrent layer can act as a gradient accumulator, which can be `applied' to the parameters of the implicit regression model. We validate our construction by training randomly initialized augmented SSMs on simple linear regression tasks. The empirically optimized parameters match the theoretical ones, obtained analytically from the implicit model construction. Extensions to multi-step linear and non-linear regression yield consistent results. The constructed SSM encompasses features of modern deep state-space models, with the potential for scalable training and effectiveness even in general tasks. The theoretical construction elucidates the role of local self-attention and multiplicative interactions in recurrent architectures as the key ingredients for enabling the expressive power typical of foundation models.","sentences":["Deep state-space models (Deep SSMs) have shown capabilities for in-context learning on autoregressive tasks, similar to transformers.","However, the architectural requirements and mechanisms enabling this in recurrent networks remain unclear.","This study demonstrates that state-space model architectures can perform gradient-based learning and use it for in-context learning.","We prove that a single structured state-space model layer, augmented with local self-attention, can reproduce the outputs of an implicit linear model with least squares loss after one step of gradient descent.","Our key insight is that the diagonal linear recurrent layer can act as a gradient accumulator, which can be `applied' to the parameters of the implicit regression model.","We validate our construction by training randomly initialized augmented SSMs on simple linear regression tasks.","The empirically optimized parameters match the theoretical ones, obtained analytically from the implicit model construction.","Extensions to multi-step linear and non-linear regression yield consistent results.","The constructed SSM encompasses features of modern deep state-space models, with the potential for scalable training and effectiveness even in general tasks.","The theoretical construction elucidates the role of local self-attention and multiplicative interactions in recurrent architectures as the key ingredients for enabling the expressive power typical of foundation models."],"url":"http://arxiv.org/abs/2410.11687v1"}
{"created":"2024-10-15 15:22:30","title":"A Survey of Low-shot Vision-Language Model Adaptation via Representer Theorem","abstract":"The advent of pre-trained vision-language foundation models has revolutionized the field of zero/few-shot (i.e., low-shot) image recognition. The key challenge to address under the condition of limited training data is how to fine-tune pre-trained vision-language models in a parameter-efficient manner. Previously, numerous approaches tackling this challenge have been proposed. Meantime, a few survey papers are also published to summarize these works. However, there still lacks a unified computational framework to integrate existing methods together, identify their nature and support in-depth comparison. As such, this survey paper first proposes a unified computational framework from the perspective of Representer Theorem and then derives many of the existing methods by specializing this framework. Thereafter, a comparative analysis is conducted to uncover the differences and relationships between existing methods. Based on the analyses, some possible variants to improve the existing works are presented. As a demonstration, we extend existing methods by modeling inter-class correlation between representers in reproducing kernel Hilbert space (RKHS), which is implemented by exploiting the closed-form solution of kernel ridge regression. Extensive experiments on 11 datasets are conducted to validate the effectiveness of this method. Toward the end of this paper, we discuss the limitations and provide further research directions.","sentences":["The advent of pre-trained vision-language foundation models has revolutionized the field of zero/few-shot (i.e., low-shot) image recognition.","The key challenge to address under the condition of limited training data is how to fine-tune pre-trained vision-language models in a parameter-efficient manner.","Previously, numerous approaches tackling this challenge have been proposed.","Meantime, a few survey papers are also published to summarize these works.","However, there still lacks a unified computational framework to integrate existing methods together, identify their nature and support in-depth comparison.","As such, this survey paper first proposes a unified computational framework from the perspective of Representer Theorem and then derives many of the existing methods by specializing this framework.","Thereafter, a comparative analysis is conducted to uncover the differences and relationships between existing methods.","Based on the analyses, some possible variants to improve the existing works are presented.","As a demonstration, we extend existing methods by modeling inter-class correlation between representers in reproducing kernel Hilbert space (RKHS), which is implemented by exploiting the closed-form solution of kernel ridge regression.","Extensive experiments on 11 datasets are conducted to validate the effectiveness of this method.","Toward the end of this paper, we discuss the limitations and provide further research directions."],"url":"http://arxiv.org/abs/2410.11686v1"}
{"created":"2024-10-15 15:20:49","title":"Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models","abstract":"Illusions of causality occur when people develop the belief that there is a causal connection between two variables with no supporting evidence. This cognitive bias has been proposed to underlie many societal problems including social prejudice, stereotype formation, misinformation and superstitious thinking. In this research we investigate whether large language models develop the illusion of causality in real-world settings. We evaluated and compared news headlines generated by GPT-4o-Mini, Claude-3.5-Sonnet, and Gemini-1.5-Pro to determine whether the models incorrectly framed correlations as causal relationships. In order to also measure sycophantic behavior, which occurs when a model aligns with a user's beliefs in order to look favorable even if it is not objectively correct, we additionally incorporated the bias into the prompts, observing if this manipulation increases the likelihood of the models exhibiting the illusion of causality. We found that Claude-3.5-Sonnet is the model that presents the lowest degree of causal illusion aligned with experiments on Correlation-to-Causation Exaggeration in human-written press releases. On the other hand, our findings suggest that while mimicry sycophancy increases the likelihood of causal illusions in these models, especially in GPT-4o-Mini, Claude-3.5-Sonnet remains the most robust against this cognitive bias.","sentences":["Illusions of causality occur when people develop the belief that there is a causal connection between two variables with no supporting evidence.","This cognitive bias has been proposed to underlie many societal problems including social prejudice, stereotype formation, misinformation and superstitious thinking.","In this research we investigate whether large language models develop the illusion of causality in real-world settings.","We evaluated and compared news headlines generated by GPT-4o-Mini, Claude-3.5-Sonnet, and Gemini-1.5-Pro to determine whether the models incorrectly framed correlations as causal relationships.","In order to also measure sycophantic behavior, which occurs when a model aligns with a user's beliefs in order to look favorable even if it is not objectively correct, we additionally incorporated the bias into the prompts, observing if this manipulation increases the likelihood of the models exhibiting the illusion of causality.","We found that Claude-3.5-Sonnet is the model that presents the lowest degree of causal illusion aligned with experiments on Correlation-to-Causation Exaggeration in human-written press releases.","On the other hand, our findings suggest that while mimicry sycophancy increases the likelihood of causal illusions in these models, especially in GPT-4o-Mini, Claude-3.5-Sonnet remains the most robust against this cognitive bias."],"url":"http://arxiv.org/abs/2410.11684v1"}
{"created":"2024-10-15 15:20:40","title":"Optimal Mediation Mechanisms in Bilateral Trade","abstract":"Consider a bilateral trade scenario where a seller seeks to sell an item to a buyer through a trusted mediator. The item's quality is the seller's private information, and the buyer's valuation of the item depends on both the quality and the buyer's type. The mediator, who is uninformed about the private information of both the seller and buyer, aims to design a mechanism that elicits and reveals information to facilitate communication between two agents. The mediator can also charge a fee for providing such services.   In this work, we study the problem of designing mechanisms that maximize revenue for the mediator. We formulate this mechanism design problem as an optimization problem that involves non-linear constraints. Interestingly, under the monotone hazard rate assumption, we can bypass this issue by considering a relaxed problem and showing that the solution to the relaxed problem remains optimal to the original one. In optimal mechanisms, the mediator directly recommends whether to trade after eliciting the agents' types. The mediator privately offers a price to each agent if a trade is recommended. The optimal mechanism adopts a threshold information structure, i.e., it only reveals to the agent whether the other agent's type exceeds a certain threshold. The optimal payment function of buyer is monotone decreasing to their type, which differs from most existing works. Finally, we discuss some interesting observations revealed by the optimal mechanism.","sentences":["Consider a bilateral trade scenario where a seller seeks to sell an item to a buyer through a trusted mediator.","The item's quality is the seller's private information, and the buyer's valuation of the item depends on both the quality and the buyer's type.","The mediator, who is uninformed about the private information of both the seller and buyer, aims to design a mechanism that elicits and reveals information to facilitate communication between two agents.","The mediator can also charge a fee for providing such services.   ","In this work, we study the problem of designing mechanisms that maximize revenue for the mediator.","We formulate this mechanism design problem as an optimization problem that involves non-linear constraints.","Interestingly, under the monotone hazard rate assumption, we can bypass this issue by considering a relaxed problem and showing that the solution to the relaxed problem remains optimal to the original one.","In optimal mechanisms, the mediator directly recommends whether to trade after eliciting the agents' types.","The mediator privately offers a price to each agent if a trade is recommended.","The optimal mechanism adopts a threshold information structure, i.e., it only reveals to the agent whether the other agent's type exceeds a certain threshold.","The optimal payment function of buyer is monotone decreasing to their type, which differs from most existing works.","Finally, we discuss some interesting observations revealed by the optimal mechanism."],"url":"http://arxiv.org/abs/2410.11683v1"}
{"created":"2024-10-15 15:19:58","title":"SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars","abstract":"Recent advancements in head avatar rendering using Gaussian primitives have achieved significantly high-fidelity results. Although precise head geometry is crucial for applications like mesh reconstruction and relighting, current methods struggle to capture intricate geometric details and render unseen poses due to their reliance on similarity transformations, which cannot handle stretch and shear transforms essential for detailed deformations of geometry. To address this, we propose SurFhead, a novel method that reconstructs riggable head geometry from RGB videos using 2D Gaussian surfels, which offer well-defined geometric properties, such as precise depth from fixed ray intersections and normals derived from their surface orientation, making them advantageous over 3D counterparts. SurFhead ensures high-fidelity rendering of both normals and images, even in extreme poses, by leveraging classical mesh-based deformation transfer and affine transformation interpolation. SurFhead introduces precise geometric deformation and blends surfels through polar decomposition of transformations, including those affecting normals. Our key contribution lies in bridging classical graphics techniques, such as mesh-based deformation, with modern Gaussian primitives, achieving state-of-the-art geometry reconstruction and rendering quality. Unlike previous avatar rendering approaches, SurFhead enables efficient reconstruction driven by Gaussian primitives while preserving high-fidelity geometry.","sentences":["Recent advancements in head avatar rendering using Gaussian primitives have achieved significantly high-fidelity results.","Although precise head geometry is crucial for applications like mesh reconstruction and relighting, current methods struggle to capture intricate geometric details and render unseen poses due to their reliance on similarity transformations, which cannot handle stretch and shear transforms essential for detailed deformations of geometry.","To address this, we propose SurFhead, a novel method that reconstructs riggable head geometry from RGB videos using 2D Gaussian surfels, which offer well-defined geometric properties, such as precise depth from fixed ray intersections and normals derived from their surface orientation, making them advantageous over 3D counterparts.","SurFhead ensures high-fidelity rendering of both normals and images, even in extreme poses, by leveraging classical mesh-based deformation transfer and affine transformation interpolation.","SurFhead introduces precise geometric deformation and blends surfels through polar decomposition of transformations, including those affecting normals.","Our key contribution lies in bridging classical graphics techniques, such as mesh-based deformation, with modern Gaussian primitives, achieving state-of-the-art geometry reconstruction and rendering quality.","Unlike previous avatar rendering approaches, SurFhead enables efficient reconstruction driven by Gaussian primitives while preserving high-fidelity geometry."],"url":"http://arxiv.org/abs/2410.11682v1"}
{"created":"2024-10-15 15:14:22","title":"Understanding Likelihood Over-optimisation in Direct Alignment Algorithms","abstract":"Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation (DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives to online Reinforcement Learning from Human Feedback (RLHF) algorithms such as Proximal Policy Optimisation (PPO) for aligning language models to human preferences, without the need for explicit reward modelling. These methods generally aim to increase the likelihood of generating better (preferred) completions while discouraging worse (non-preferred) ones, while staying close to the original model's behaviour. In this work, we explore the relationship between completion likelihood and model performance in state-of-the-art DAAs, and identify a critical issue of likelihood over-optimisation. Contrary to expectations, we find that higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better performance, and may even degrade it. Our analysis reveals that while higher likelihood correlates with better memorisation of factual knowledge patterns, a slightly lower completion likelihood tends to improve output diversity, thus leading to better generalisation to unseen scenarios. Moreover, we identify two key indicators that signal when over-optimised output diversity begins to harm performance: Decreasing Entropy over Top-k Tokens and Diminishing Top-k Probability Mass. Our experimental results validate that these indicators are reliable signs of declining performance under different regularisations, helping prevent over-optimisation and improve alignment with human preferences.","sentences":["Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation (DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives to online Reinforcement Learning from Human Feedback (RLHF) algorithms such as Proximal Policy Optimisation (PPO) for aligning language models to human preferences, without the need for explicit reward modelling.","These methods generally aim to increase the likelihood of generating better (preferred) completions while discouraging worse (non-preferred) ones, while staying close to the original model's behaviour.","In this work, we explore the relationship between completion likelihood and model performance in state-of-the-art DAAs, and identify a critical issue of likelihood over-optimisation.","Contrary to expectations, we find that higher likelihood of better completions and larger margins between better and worse completion likelihoods do not necessarily lead to better performance, and may even degrade it.","Our analysis reveals that while higher likelihood correlates with better memorisation of factual knowledge patterns, a slightly lower completion likelihood tends to improve output diversity, thus leading to better generalisation to unseen scenarios.","Moreover, we identify two key indicators that signal when over-optimised output diversity begins to harm performance: Decreasing Entropy over Top-k Tokens and Diminishing Top-k Probability Mass.","Our experimental results validate that these indicators are reliable signs of declining performance under different regularisations, helping prevent over-optimisation and improve alignment with human preferences."],"url":"http://arxiv.org/abs/2410.11677v1"}
{"created":"2024-10-15 15:08:57","title":"LLM-Mixer: Multiscale Mixing in LLMs for Time Series Forecasting","abstract":"Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns. This study presents LLM-Mixer, a framework that improves forecasting accuracy through the combination of multiscale time-series decomposition with pre-trained LLMs (Large Language Models). LLM-Mixer captures both short-term fluctuations and long-term trends by decomposing the data into multiple temporal resolutions and processing them with a frozen LLM, guided by a textual prompt specifically designed for time-series data. Extensive experiments conducted on multivariate and univariate datasets demonstrate that LLM-Mixer achieves competitive performance, outperforming recent state-of-the-art models across various forecasting horizons. This work highlights the potential of combining multiscale analysis and LLMs for effective and scalable time-series forecasting.","sentences":["Time series forecasting remains a challenging task, particularly in the context of complex multiscale temporal patterns.","This study presents LLM-Mixer, a framework that improves forecasting accuracy through the combination of multiscale time-series decomposition with pre-trained LLMs (Large Language Models).","LLM-Mixer captures both short-term fluctuations and long-term trends by decomposing the data into multiple temporal resolutions and processing them with a frozen LLM, guided by a textual prompt specifically designed for time-series data.","Extensive experiments conducted on multivariate and univariate datasets demonstrate that LLM-Mixer achieves competitive performance, outperforming recent state-of-the-art models across various forecasting horizons.","This work highlights the potential of combining multiscale analysis and LLMs for effective and scalable time-series forecasting."],"url":"http://arxiv.org/abs/2410.11674v1"}
{"created":"2024-10-15 15:06:13","title":"Generative Image Steganography Based on Point Cloud","abstract":"In deep steganography, the model size is usually related to the underlying mesh resolution, and a separate neural network needs to be trained as a message extractor. In this paper, we propose a generative image steganography based on point cloud representation, which represents image data as a point cloud, learns the distribution of the point cloud data, and represents it in the form of a continuous function. This method breaks through the limitation of the image resolution, and can generate images with arbitrary resolution according to the actual need, and omits the need for explicit data for image steganography. At the same time, using a fixed point cloud extractor transfers the training of the network to the point cloud data, which saves the training time and avoids the risk of exposing the steganography behavior caused by the transmission of the message extractor. Experiments prove that the steganographic images generated by the scheme have very high image quality and the accuracy of message extraction reaches more than 99%.","sentences":["In deep steganography, the model size is usually related to the underlying mesh resolution, and a separate neural network needs to be trained as a message extractor.","In this paper, we propose a generative image steganography based on point cloud representation, which represents image data as a point cloud, learns the distribution of the point cloud data, and represents it in the form of a continuous function.","This method breaks through the limitation of the image resolution, and can generate images with arbitrary resolution according to the actual need, and omits the need for explicit data for image steganography.","At the same time, using a fixed point cloud extractor transfers the training of the network to the point cloud data, which saves the training time and avoids the risk of exposing the steganography behavior caused by the transmission of the message extractor.","Experiments prove that the steganographic images generated by the scheme have very high image quality and the accuracy of message extraction reaches more than 99%."],"url":"http://arxiv.org/abs/2410.11673v1"}
{"created":"2024-10-15 15:05:41","title":"Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers","abstract":"The integrity of AI benchmarks is fundamental to accurately assess the capabilities of AI systems. The internal validity of these benchmarks - i.e., making sure they are free from confounding factors - is crucial for ensuring that they are measuring what they are designed to measure. In this paper, we explore a key issue related to internal validity: the possibility that AI systems can solve benchmarks in unintended ways, bypassing the capability being tested. This phenomenon, widely known in human and animal experiments, is often referred to as the 'Clever Hans' effect, where tasks are solved using spurious cues, often involving much simpler processes than those putatively assessed. Previous research suggests that language models can exhibit this behaviour as well. In several older Natural Language Processing (NLP) benchmarks, individual $n$-grams like \"not\" have been found to be highly predictive of the correct labels, and supervised NLP models have been shown to exploit these patterns. In this work, we investigate the extent to which simple $n$-grams extracted from benchmark instances can be combined to predict labels in modern multiple-choice benchmarks designed for LLMs, and whether LLMs might be using such $n$-gram patterns to solve these benchmarks. We show how simple classifiers trained on these $n$-grams can achieve high scores on several benchmarks, despite lacking the capabilities being tested. Additionally, we provide evidence that modern LLMs might be using these superficial patterns to solve benchmarks. This suggests that the internal validity of these benchmarks may be compromised and caution should be exercised when interpreting LLM performance results on them.","sentences":["The integrity of AI benchmarks is fundamental to accurately assess the capabilities of AI systems.","The internal validity of these benchmarks - i.e., making sure they are free from confounding factors - is crucial for ensuring that they are measuring what they are designed to measure.","In this paper, we explore a key issue related to internal validity: the possibility that AI systems can solve benchmarks in unintended ways, bypassing the capability being tested.","This phenomenon, widely known in human and animal experiments, is often referred to as the 'Clever Hans' effect, where tasks are solved using spurious cues, often involving much simpler processes than those putatively assessed.","Previous research suggests that language models can exhibit this behaviour as well.","In several older Natural Language Processing (NLP) benchmarks, individual $n$-grams like \"not\" have been found to be highly predictive of the correct labels, and supervised NLP models have been shown to exploit these patterns.","In this work, we investigate the extent to which simple $n$-grams extracted from benchmark instances can be combined to predict labels in modern multiple-choice benchmarks designed for LLMs, and whether LLMs might be using such $n$-gram patterns to solve these benchmarks.","We show how simple classifiers trained on these $n$-grams can achieve high scores on several benchmarks, despite lacking the capabilities being tested.","Additionally, we provide evidence that modern LLMs might be using these superficial patterns to solve benchmarks.","This suggests that the internal validity of these benchmarks may be compromised and caution should be exercised when interpreting LLM performance results on them."],"url":"http://arxiv.org/abs/2410.11672v1"}
{"created":"2024-10-15 15:01:57","title":"Safety Filtering While Training: Improving the Performance and Sample Efficiency of Reinforcement Learning Agents","abstract":"Reinforcement learning (RL) controllers are flexible and performant but rarely guarantee safety. Safety filters impart hard safety guarantees to RL controllers while maintaining flexibility. However, safety filters can cause undesired behaviours due to the separation between the controller and the safety filter, often degrading performance and robustness. In this paper, we propose several modifications to incorporating the safety filter in training RL controllers rather than solely applying it during evaluation. The modifications allow the RL controller to learn to account for the safety filter, improving performance. Additionally, our modifications significantly improve sample efficiency and eliminate training-time constraint violations. We verified the proposed modifications in simulated and real experiments with a Crazyflie 2.0 drone. In experiments, we show that the proposed training approaches require significantly fewer environment interactions and improve performance by up to 20% compared to standard RL training.","sentences":["Reinforcement learning (RL) controllers are flexible and performant but rarely guarantee safety.","Safety filters impart hard safety guarantees to RL controllers while maintaining flexibility.","However, safety filters can cause undesired behaviours due to the separation between the controller and the safety filter, often degrading performance and robustness.","In this paper, we propose several modifications to incorporating the safety filter in training RL controllers rather than solely applying it during evaluation.","The modifications allow the RL controller to learn to account for the safety filter, improving performance.","Additionally, our modifications significantly improve sample efficiency and eliminate training-time constraint violations.","We verified the proposed modifications in simulated and real experiments with a Crazyflie 2.0 drone.","In experiments, we show that the proposed training approaches require significantly fewer environment interactions and improve performance by up to 20% compared to standard RL training."],"url":"http://arxiv.org/abs/2410.11671v1"}
{"created":"2024-10-15 14:57:10","title":"Leveraging Structure Knowledge and Deep Models for the Detection of Abnormal Handwritten Text","abstract":"Currently, the destruction of the sequence structure in handwritten text has become one of the main bottlenecks restricting the recognition task. The typical situations include additional specific markers (the text swapping modification) and the text overlap caused by character modifications like deletion, replacement, and insertion. In this paper, we propose a two-stage detection algorithm that combines structure knowledge and deep models for the above mentioned text. Firstly, different structure prototypes are roughly located from handwritten text images. Based on the detection results of the first stage, in the second stage, we adopt different strategies. Specifically, a shape regression network trained by a novel semi-supervised contrast training strategy is introduced and the positional relationship between the characters is fully employed. Experiments on two handwritten text datasets show that the proposed method can greatly improve the detection performance. The new dataset is available at https://github.com/Wukong90.","sentences":["Currently, the destruction of the sequence structure in handwritten text has become one of the main bottlenecks restricting the recognition task.","The typical situations include additional specific markers (the text swapping modification) and the text overlap caused by character modifications like deletion, replacement, and insertion.","In this paper, we propose a two-stage detection algorithm that combines structure knowledge and deep models for the above mentioned text.","Firstly, different structure prototypes are roughly located from handwritten text images.","Based on the detection results of the first stage, in the second stage, we adopt different strategies.","Specifically, a shape regression network trained by a novel semi-supervised contrast training strategy is introduced and the positional relationship between the characters is fully employed.","Experiments on two handwritten text datasets show that the proposed method can greatly improve the detection performance.","The new dataset is available at https://github.com/Wukong90."],"url":"http://arxiv.org/abs/2410.11670v1"}
{"created":"2024-10-15 14:53:07","title":"Degradation Oriented and Regularized Network for Real-World Depth Super-Resolution","abstract":"Recently, existing RGB-guided depth super-resolution methods achieve excellent performance based on the assumption of fixed and known degradation (e.g., bicubic downsampling). However, in real-world scenarios, the captured depth often suffers from unconventional and agnostic degradation due to sensor limitations and the complexity of imaging environments (e.g., low reflective surface, illumination). Their performance significantly declines when these real degradation differ from their assumptions. To address these issues, we propose a Degradation Oriented and Regularized Network, DORNet, which pays more attention on learning degradation representation of low-resolution depth that can provide targeted guidance for depth recovery. Specifically, we first design a self-supervised Degradation Learning to model the discriminative degradation representation of low-resolution depth using routing selection-based Degradation Regularization. Then, we present a Degradation Awareness that recursively conducts multiple Degradation-Oriented Feature Transformations, each of which selectively embeds RGB information into the depth based on the learned degradation representation. Extensive experimental results on both real and synthetic datasets demonstrate that our method achieves state-of-the-art performance.","sentences":["Recently, existing RGB-guided depth super-resolution methods achieve excellent performance based on the assumption of fixed and known degradation (e.g., bicubic downsampling).","However, in real-world scenarios, the captured depth often suffers from unconventional and agnostic degradation due to sensor limitations and the complexity of imaging environments (e.g., low reflective surface, illumination).","Their performance significantly declines when these real degradation differ from their assumptions.","To address these issues, we propose a Degradation Oriented and Regularized Network, DORNet, which pays more attention on learning degradation representation of low-resolution depth that can provide targeted guidance for depth recovery.","Specifically, we first design a self-supervised Degradation Learning to model the discriminative degradation representation of low-resolution depth using routing selection-based Degradation Regularization.","Then, we present a Degradation Awareness that recursively conducts multiple Degradation-Oriented Feature Transformations, each of which selectively embeds RGB information into the depth based on the learned degradation representation.","Extensive experimental results on both real and synthetic datasets demonstrate that our method achieves state-of-the-art performance."],"url":"http://arxiv.org/abs/2410.11666v1"}
{"created":"2024-10-15 14:49:19","title":"VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models","abstract":"Accurately understanding complex visual information is crucial for visual language models (VLMs). Enhancing image resolution can improve visual perception capabilities, not only reducing hallucinations but also boosting performance in tasks that demand high resolution, such as text-rich or document analysis. In this paper, we present VisualRWKV-HD and VisualRWKV-UHD, two advancements in the VisualRWKV model family, specifically designed to process high-resolution visual inputs. For VisualRWKV-HD, we developed a lossless downsampling method to effectively integrate a high-resolution vision encoder with low-resolution encoders, without extending the input sequence length. For the VisualRWKV-UHD model, we enhanced image representation by dividing the image into four segments, which are then recombined with the original image. This technique allows the model to incorporate both high-resolution and low-resolution features, effectively balancing coarse and fine-grained information. As a result, the model supports resolutions up to 4096 x 4096 pixels, offering a more detailed and comprehensive visual processing capability. Both VisualRWKV-HD and VisualRWKV-UHD not only achieve strong results on VLM benchmarks but also show marked improvements in performance for text-rich tasks.","sentences":["Accurately understanding complex visual information is crucial for visual language models (VLMs).","Enhancing image resolution can improve visual perception capabilities, not only reducing hallucinations but also boosting performance in tasks that demand high resolution, such as text-rich or document analysis.","In this paper, we present VisualRWKV-HD and VisualRWKV-UHD, two advancements in the VisualRWKV model family, specifically designed to process high-resolution visual inputs.","For VisualRWKV-HD, we developed a lossless downsampling method to effectively integrate a high-resolution vision encoder with low-resolution encoders, without extending the input sequence length.","For the VisualRWKV-UHD model, we enhanced image representation by dividing the image into four segments, which are then recombined with the original image.","This technique allows the model to incorporate both high-resolution and low-resolution features, effectively balancing coarse and fine-grained information.","As a result, the model supports resolutions up to 4096 x 4096 pixels, offering a more detailed and comprehensive visual processing capability.","Both VisualRWKV-HD and VisualRWKV-UHD not only achieve strong results on VLM benchmarks but also show marked improvements in performance for text-rich tasks."],"url":"http://arxiv.org/abs/2410.11665v1"}
{"created":"2024-10-15 14:46:11","title":"Eliciting Textual Descriptions from Representations of Continuous Prompts","abstract":"Continuous prompts, or \"soft prompts\", are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature. Prior attempts to interpret continuous prompts relied on projecting individual prompt tokens onto the vocabulary space. However, this approach is problematic as performant prompts can yield arbitrary or contradictory text, and it interprets prompt tokens individually. In this work, we propose a new approach to interpret continuous prompts that elicits textual descriptions from their representations during model inference. Using a Patchscopes variant (Ghandeharioun et al., 2024) called InSPEcT over various tasks, we show our method often yields accurate task descriptions which become more faithful as task performance increases. Moreover, an elaborated version of InSPEcT reveals biased features in continuous prompts, whose presence correlates with biased model predictions. Providing an effective interpretability solution, InSPEcT can be leveraged to debug unwanted properties in continuous prompts and inform developers on ways to mitigate them.","sentences":["Continuous prompts, or \"soft prompts\", are a widely-adopted parameter-efficient tuning strategy for large language models, but are often less favorable due to their opaque nature.","Prior attempts to interpret continuous prompts relied on projecting individual prompt tokens onto the vocabulary space.","However, this approach is problematic as performant prompts can yield arbitrary or contradictory text, and it interprets prompt tokens individually.","In this work, we propose a new approach to interpret continuous prompts that elicits textual descriptions from their representations during model inference.","Using a Patchscopes variant (Ghandeharioun et al., 2024) called InSPEcT over various tasks, we show our method often yields accurate task descriptions which become more faithful as task performance increases.","Moreover, an elaborated version of InSPEcT reveals biased features in continuous prompts, whose presence correlates with biased model predictions.","Providing an effective interpretability solution, InSPEcT can be leveraged to debug unwanted properties in continuous prompts and inform developers on ways to mitigate them."],"url":"http://arxiv.org/abs/2410.11660v1"}
{"created":"2024-10-15 14:44:36","title":"Unveiling the Mystery of Visual Attributes of Concrete and Abstract Concepts: Variability, Nearest Neighbors, and Challenging Categories","abstract":"The visual representation of a concept varies significantly depending on its meaning and the context where it occurs; this poses multiple challenges both for vision and multimodal models. Our study focuses on concreteness, a well-researched lexical-semantic variable, using it as a case study to examine the variability in visual representations. We rely on images associated with approximately 1,000 abstract and concrete concepts extracted from two different datasets: Bing and YFCC. Our goals are: (i) evaluate whether visual diversity in the depiction of concepts can reliably distinguish between concrete and abstract concepts; (ii) analyze the variability of visual features across multiple images of the same concept through a nearest neighbor analysis; and (iii) identify challenging factors contributing to this variability by categorizing and annotating images. Our findings indicate that for classifying images of abstract versus concrete concepts, a combination of basic visual features such as color and texture is more effective than features extracted by more complex models like Vision Transformer (ViT). However, ViTs show better performances in the nearest neighbor analysis, emphasizing the need for a careful selection of visual features when analyzing conceptual variables through modalities other than text.","sentences":["The visual representation of a concept varies significantly depending on its meaning and the context where it occurs; this poses multiple challenges both for vision and multimodal models.","Our study focuses on concreteness, a well-researched lexical-semantic variable, using it as a case study to examine the variability in visual representations.","We rely on images associated with approximately 1,000 abstract and concrete concepts extracted from two different datasets: Bing and YFCC.","Our goals are: (i) evaluate whether visual diversity in the depiction of concepts can reliably distinguish between concrete and abstract concepts; (ii) analyze the variability of visual features across multiple images of the same concept through a nearest neighbor analysis; and (iii) identify challenging factors contributing to this variability by categorizing and annotating images.","Our findings indicate that for classifying images of abstract versus concrete concepts, a combination of basic visual features such as color and texture is more effective than features extracted by more complex models like Vision Transformer (ViT).","However, ViTs show better performances in the nearest neighbor analysis, emphasizing the need for a careful selection of visual features when analyzing conceptual variables through modalities other than text."],"url":"http://arxiv.org/abs/2410.11657v1"}
{"created":"2024-10-15 14:42:22","title":"Fast and Robust Hexahedral Mesh Optimization via Augmented Lagrangian, L-BFGS, and Line Search","abstract":"We present a new software package, ``HexOpt,'' for improving the quality of all-hexahedral (all-hex) meshes by maximizing the minimum mixed scaled Jacobian-Jacobian energy functional, and projecting the surface points of the all-hex meshes onto the input triangular mesh. The proposed HexOpt method takes as input a surface triangular mesh and a volumetric all-hex mesh. A constrained optimization problem is formulated to improve mesh quality using a novel function that combines Jacobian and scaled Jacobian metrics which are rectified and scaled to quadratic measures, while preserving the surface geometry. This optimization problem is solved using the augmented Lagrangian (AL) method, where the Lagrangian terms enforce the constraint that surface points must remain on the triangular mesh. Specifically, corner points stay exactly at the corner, edge points are confined to the edges, and face points are free to move across the surface. To take the advantage of the Quasi-Newton method while tackling the high-dimensional variable problem, the Limited-Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is employed. The step size for each iteration is determined by the Armijo line search. Coupled with smart Laplacian smoothing, HexOpt has demonstrated robustness and efficiency, successfully applying to 3D models and hex meshes generated by different methods without requiring any manual intervention or parameter adjustment.","sentences":["We present a new software package, ``HexOpt,'' for improving the quality of all-hexahedral (all-hex) meshes by maximizing the minimum mixed scaled Jacobian-Jacobian energy functional, and projecting the surface points of the all-hex meshes onto the input triangular mesh.","The proposed HexOpt method takes as input a surface triangular mesh and a volumetric all-hex mesh.","A constrained optimization problem is formulated to improve mesh quality using a novel function that combines Jacobian and scaled Jacobian metrics which are rectified and scaled to quadratic measures, while preserving the surface geometry.","This optimization problem is solved using the augmented Lagrangian (AL) method, where the Lagrangian terms enforce the constraint that surface points must remain on the triangular mesh.","Specifically, corner points stay exactly at the corner, edge points are confined to the edges, and face points are free to move across the surface.","To take the advantage of the Quasi-Newton method while tackling the high-dimensional variable problem, the Limited-Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) algorithm is employed.","The step size for each iteration is determined by the Armijo line search.","Coupled with smart Laplacian smoothing, HexOpt has demonstrated robustness and efficiency, successfully applying to 3D models and hex meshes generated by different methods without requiring any manual intervention or parameter adjustment."],"url":"http://arxiv.org/abs/2410.11656v1"}
{"created":"2024-10-15 14:42:18","title":"Retrieval Augmented Spelling Correction for E-Commerce Applications","abstract":"The rapid introduction of new brand names into everyday language poses a unique challenge for e-commerce spelling correction services, which must distinguish genuine misspellings from novel brand names that use unconventional spelling. We seek to address this challenge via Retrieval Augmented Generation (RAG). On this approach, product names are retrieved from a catalog and incorporated into the context used by a large language model (LLM) that has been fine-tuned to do contextual spelling correction. Through quantitative evaluation and qualitative error analyses, we find improvements in spelling correction utilizing the RAG framework beyond a stand-alone LLM. We also demonstrate the value of additional finetuning of the LLM to incorporate retrieved context.","sentences":["The rapid introduction of new brand names into everyday language poses a unique challenge for e-commerce spelling correction services, which must distinguish genuine misspellings from novel brand names that use unconventional spelling.","We seek to address this challenge via Retrieval Augmented Generation (RAG).","On this approach, product names are retrieved from a catalog and incorporated into the context used by a large language model (LLM) that has been fine-tuned to do contextual spelling correction.","Through quantitative evaluation and qualitative error analyses, we find improvements in spelling correction utilizing the RAG framework beyond a stand-alone LLM.","We also demonstrate the value of additional finetuning of the LLM to incorporate retrieved context."],"url":"http://arxiv.org/abs/2410.11655v1"}
{"created":"2024-10-15 14:41:44","title":"Transformer Layer Injection: A Novel Approach for Efficient Upscaling of Large Language Models","abstract":"In this paper, we propose Transformer Layer Injection (TLI), a novel method for efficiently upscaling large language models (LLMs) while minimizing computational costs and maintaining model performance. Model scale is a key factor in enhancing the quality of machine learning models, and TLI addresses the challenge of scaling by reducing initial loss, minimizing fine-tuning requirements, and preserving model complexity. Our approach improves upon the conventional Depth Up-Scaling (DUS) technique by injecting new layers into every set of K layers, enabling hidden representations to pass through transformer blocks with minimal disruption. We compare TLI with existing approaches, including Mixture of Experts (MoE) and DUS, and validate its efficiency through experiments on small LLMs (LLama3 1B, 3B, and 8B). Results show that TLI achieves better initialization, requires fewer training steps, and delivers superior accuracy on tasks such as KoBEST and KMCQA, with models performing effectively even without additional training. TLI is demonstrated to be both data-efficient and cost-effective, significantly outperforming existing methods. Its scalability and simplicity make it a promising solution for upscaling transformer-based models, with potential applications in scaling models from 10B to 405B parameters.","sentences":["In this paper, we propose Transformer Layer Injection (TLI), a novel method for efficiently upscaling large language models (LLMs) while minimizing computational costs and maintaining model performance.","Model scale is a key factor in enhancing the quality of machine learning models, and TLI addresses the challenge of scaling by reducing initial loss, minimizing fine-tuning requirements, and preserving model complexity.","Our approach improves upon the conventional Depth Up-Scaling (DUS) technique by injecting new layers into every set of K layers, enabling hidden representations to pass through transformer blocks with minimal disruption.","We compare TLI with existing approaches, including Mixture of Experts (MoE) and DUS, and validate its efficiency through experiments on small LLMs (LLama3 1B, 3B, and 8B).","Results show that TLI achieves better initialization, requires fewer training steps, and delivers superior accuracy on tasks such as KoBEST and KMCQA, with models performing effectively even without additional training.","TLI is demonstrated to be both data-efficient and cost-effective, significantly outperforming existing methods.","Its scalability and simplicity make it a promising solution for upscaling transformer-based models, with potential applications in scaling models from 10B to 405B parameters."],"url":"http://arxiv.org/abs/2410.11654v1"}
{"created":"2024-10-15 14:38:35","title":"RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping","abstract":"Cardiac T1 mapping can evaluate various clinical symptoms of myocardial tissue. However, there is currently a lack of effective, robust, and efficient methods for motion correction in cardiac T1 mapping. In this paper, we propose a deep learning-based and topology-preserving image registration framework for motion correction in cardiac T1 mapping. Notably, our proposed implicit consistency constraint dubbed BLOC, to some extent preserves the image topology in registration by bidirectional consistency constraint and local anti-folding constraint. To address the contrast variation issue, we introduce a weighted image similarity metric for multimodal registration of cardiac T1-weighted images. Besides, a semi-supervised myocardium segmentation network and a dual-domain attention module are integrated into the framework to further improve the performance of the registration. Numerous comparative experiments, as well as ablation studies, demonstrated the effectiveness and high robustness of our method. The results also indicate that the proposed weighted image similarity metric, specifically crafted for our network, contributes a lot to the enhancement of the motion correction efficacy, while the bidirectional consistency constraint combined with the local anti-folding constraint ensures a more desirable topology-preserving registration mapping.","sentences":["Cardiac T1 mapping can evaluate various clinical symptoms of myocardial tissue.","However, there is currently a lack of effective, robust, and efficient methods for motion correction in cardiac T1 mapping.","In this paper, we propose a deep learning-based and topology-preserving image registration framework for motion correction in cardiac T1 mapping.","Notably, our proposed implicit consistency constraint dubbed BLOC, to some extent preserves the image topology in registration by bidirectional consistency constraint and local anti-folding constraint.","To address the contrast variation issue, we introduce a weighted image similarity metric for multimodal registration of cardiac T1-weighted images.","Besides, a semi-supervised myocardium segmentation network and a dual-domain attention module are integrated into the framework to further improve the performance of the registration.","Numerous comparative experiments, as well as ablation studies, demonstrated the effectiveness and high robustness of our method.","The results also indicate that the proposed weighted image similarity metric, specifically crafted for our network, contributes a lot to the enhancement of the motion correction efficacy, while the bidirectional consistency constraint combined with the local anti-folding constraint ensures a more desirable topology-preserving registration mapping."],"url":"http://arxiv.org/abs/2410.11651v1"}
{"created":"2024-10-15 14:38:14","title":"ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices","abstract":"Deep learning models are increasingly deployed on resource-constrained edge devices for real-time data analytics. In recent years, Vision Transformer models and their variants have demonstrated outstanding performance across various computer vision tasks. However, their high computational demands and inference latency pose significant challenges for model deployment on resource-constraint edge devices. To address this issue, we propose a novel Vision Transformer splitting framework, ED-ViT, designed to execute complex models across multiple edge devices efficiently. Specifically, we partition Vision Transformer models into several sub-models, where each sub-model is tailored to handle a specific subset of data classes. To further minimize computation overhead and inference latency, we introduce a class-wise pruning technique that reduces the size of each sub-model. We conduct extensive experiments on five datasets with three model structures, demonstrating that our approach significantly reduces inference latency on edge devices and achieves a model size reduction of up to 28.9 times and 34.1 times, respectively, while maintaining test accuracy comparable to the original Vision Transformer. Additionally, we compare ED-ViT with two state-of-the-art methods that deploy CNN and SNN models on edge devices, evaluating accuracy, inference time, and overall model size. Our comprehensive evaluation underscores the effectiveness of the proposed ED-ViT framework.","sentences":["Deep learning models are increasingly deployed on resource-constrained edge devices for real-time data analytics.","In recent years, Vision Transformer models and their variants have demonstrated outstanding performance across various computer vision tasks.","However, their high computational demands and inference latency pose significant challenges for model deployment on resource-constraint edge devices.","To address this issue, we propose a novel Vision Transformer splitting framework, ED-ViT, designed to execute complex models across multiple edge devices efficiently.","Specifically, we partition Vision Transformer models into several sub-models, where each sub-model is tailored to handle a specific subset of data classes.","To further minimize computation overhead and inference latency, we introduce a class-wise pruning technique that reduces the size of each sub-model.","We conduct extensive experiments on five datasets with three model structures, demonstrating that our approach significantly reduces inference latency on edge devices and achieves a model size reduction of up to 28.9 times and 34.1 times, respectively, while maintaining test accuracy comparable to the original Vision Transformer.","Additionally, we compare ED-ViT with two state-of-the-art methods that deploy CNN and SNN models on edge devices, evaluating accuracy, inference time, and overall model size.","Our comprehensive evaluation underscores the effectiveness of the proposed ED-ViT framework."],"url":"http://arxiv.org/abs/2410.11650v1"}
{"created":"2024-10-15 14:36:05","title":"Efficient, Accurate and Stable Gradients for Neural ODEs","abstract":"Neural ODEs are a recently developed model class that combine the strong model priors of differential equations with the high-capacity function approximation of neural networks. One advantage of Neural ODEs is the potential for memory-efficient training via the continuous adjoint method. However, memory-efficient training comes at the cost of approximate gradients. Therefore, in practice, gradients are often obtained by simply backpropagating through the internal operations of the forward ODE solve - incurring high memory cost.   Interestingly, it is possible to construct algebraically reversible ODE solvers that allow for both exact gradients and the memory-efficiency of the continuous adjoint method. Unfortunately, current reversible solvers are low-order and suffer from poor numerical stability. The use of these methods in practice is therefore limited.   In this work, we present a class of algebraically reversible solvers that are both high-order and numerically stable. Moreover, any explicit numerical scheme can be made reversible by our method. This construction naturally extends to numerical schemes for Neural CDEs and SDEs.","sentences":["Neural ODEs are a recently developed model class that combine the strong model priors of differential equations with the high-capacity function approximation of neural networks.","One advantage of Neural ODEs is the potential for memory-efficient training via the continuous adjoint method.","However, memory-efficient training comes at the cost of approximate gradients.","Therefore, in practice, gradients are often obtained by simply backpropagating through the internal operations of the forward ODE solve - incurring high memory cost.   ","Interestingly, it is possible to construct algebraically reversible ODE solvers that allow for both exact gradients and the memory-efficiency of the continuous adjoint method.","Unfortunately, current reversible solvers are low-order and suffer from poor numerical stability.","The use of these methods in practice is therefore limited.   ","In this work, we present a class of algebraically reversible solvers that are both high-order and numerically stable.","Moreover, any explicit numerical scheme can be made reversible by our method.","This construction naturally extends to numerical schemes for Neural CDEs and SDEs."],"url":"http://arxiv.org/abs/2410.11648v1"}
{"created":"2024-10-15 14:33:23","title":"Measuring Spiritual Values and Bias of Large Language Models","abstract":"Large language models (LLMs) have become integral tool for users from various backgrounds. LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data. However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases. As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases. Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs. Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists. We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification). Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups. Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias.","sentences":["Large language models (LLMs) have become integral tool for users from various backgrounds.","LLMs, trained on vast corpora, reflect the linguistic and cultural nuances embedded in their pre-training data.","However, the values and perspectives inherent in this data can influence the behavior of LLMs, leading to potential biases.","As a result, the use of LLMs in contexts involving spiritual or moral values necessitates careful consideration of these underlying biases.","Our work starts with verification of our hypothesis by testing the spiritual values of popular LLMs.","Experimental results show that LLMs' spiritual values are quite diverse, as opposed to the stereotype of atheists or secularists.","We then investigate how different spiritual values affect LLMs in social-fairness scenarios e.g., hate speech identification).","Our findings reveal that different spiritual values indeed lead to different sensitivity to different hate target groups.","Furthermore, we propose to continue pre-training LLMs on spiritual texts, and empirical results demonstrate the effectiveness of this approach in mitigating spiritual bias."],"url":"http://arxiv.org/abs/2410.11647v1"}
{"created":"2024-10-15 14:33:10","title":"Feature-guided score diffusion for sampling conditional densities","abstract":"Score diffusion methods can learn probability densities from samples. The score of the noise-corrupted density is estimated using a deep neural network, which is then used to iteratively transport a Gaussian white noise density to a target density. Variants for conditional densities have been developed, but correct estimation of the corresponding scores is difficult. We avoid these difficulties by introducing an algorithm that guides the diffusion with a projected score. The projection pushes the image feature vector towards the feature vector centroid of the target class. The projected score and the feature vectors are learned by the same network. Specifically, the image feature vector is defined as the spatial averages of the channels activations in select layers of the network. Optimizing the projected score for denoising loss encourages image feature vectors of each class to cluster around their centroids. It also leads to the separations of the centroids. We show that these centroids provide a low-dimensional Euclidean embedding of the class conditional densities. We demonstrate that the algorithm can generate high quality and diverse samples from the conditioning class. Conditional generation can be performed using feature vectors interpolated between those of the training set, demonstrating out-of-distribution generalization.","sentences":["Score diffusion methods can learn probability densities from samples.","The score of the noise-corrupted density is estimated using a deep neural network, which is then used to iteratively transport a Gaussian white noise density to a target density.","Variants for conditional densities have been developed, but correct estimation of the corresponding scores is difficult.","We avoid these difficulties by introducing an algorithm that guides the diffusion with a projected score.","The projection pushes the image feature vector towards the feature vector centroid of the target class.","The projected score and the feature vectors are learned by the same network.","Specifically, the image feature vector is defined as the spatial averages of the channels activations in select layers of the network.","Optimizing the projected score for denoising loss encourages image feature vectors of each class to cluster around their centroids.","It also leads to the separations of the centroids.","We show that these centroids provide a low-dimensional Euclidean embedding of the class conditional densities.","We demonstrate that the algorithm can generate high quality and diverse samples from the conditioning class.","Conditional generation can be performed using feature vectors interpolated between those of the training set, demonstrating out-of-distribution generalization."],"url":"http://arxiv.org/abs/2410.11646v1"}
{"created":"2024-10-15 14:32:51","title":"Complementation of Emerson-Lei Automata (Technical Report)","abstract":"We give new constructions for complementing subclasses of Emerson-Lei automata using modifications of rank-based B\\\"uchi automata complementation. In particular, we propose a specialized rank-based construction for a Boolean combination of Inf acceptance conditions, which heavily relies on a novel way of a run DAG labelling enhancing the ranking functions with models of the acceptance condition. Moreover, we propose a technique for complementing generalized Rabin automata, which are structurally as concise as general Emerson-Lei automata (but can have a larger acceptance condition). The construction is modular in the sense that it combines a given complementation algorithm for a condition $\\varphi$ in a way that the resulting procedure handles conditions of the form Fin ${} \\land \\varphi$. The proposed constructions give upper bounds that are exponentially better than the state of the art for some of the classes.","sentences":["We give new constructions for complementing subclasses of Emerson-Lei automata using modifications of rank-based B\\\"uchi automata complementation.","In particular, we propose a specialized rank-based construction for a Boolean combination of Inf acceptance conditions, which heavily relies on a novel way of a run DAG labelling enhancing the ranking functions with models of the acceptance condition.","Moreover, we propose a technique for complementing generalized Rabin automata, which are structurally as concise as general Emerson-Lei automata (but can have a larger acceptance condition).","The construction is modular in the sense that it combines a given complementation algorithm for a condition $\\varphi$ in a way that the resulting procedure handles conditions of the form Fin ${} \\land \\varphi$.","The proposed constructions give upper bounds that are exponentially better than the state of the art for some of the classes."],"url":"http://arxiv.org/abs/2410.11644v1"}
{"created":"2024-10-15 14:31:54","title":"Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search","abstract":"Reinforcement learning has achieved remarkable success in perfect information games such as Go and Atari, enabling agents to compete at the highest levels against human players. However, research in reinforcement learning for imperfect information games has been relatively limited due to the more complex game structures and randomness. Traditional methods face challenges in training and improving performance in imperfect information games due to issues like inaccurate Q value estimation and reward sparsity. In this paper, we focus on Uno, an imperfect information game, and aim to address these problems by reducing Q value overestimation and reshaping reward function. We propose a novel algorithm that utilizes Monte Carlo Tree Search to improve the value estimation in Q function. Even though we choose Double Deep Q Learning as the foundational framework in this paper, our method can be generalized and used in any algorithm which needs Q value estimation, such as the Actor-Critic. Additionally, we employ Monte Carlo Tree Search to reshape the reward structure in the game environment. We compared our algorithm with several traditional methods applied to games such as Double Deep Q Learning, Deep Monte Carlo and Neural Fictitious Self Play, and the experiments demonstrate that our algorithm consistently outperforms these approaches, especially as the number of players in Uno increases, indicating a higher level of difficulty.","sentences":["Reinforcement learning has achieved remarkable success in perfect information games such as Go and Atari, enabling agents to compete at the highest levels against human players.","However, research in reinforcement learning for imperfect information games has been relatively limited due to the more complex game structures and randomness.","Traditional methods face challenges in training and improving performance in imperfect information games due to issues like inaccurate Q value estimation and reward sparsity.","In this paper, we focus on Uno, an imperfect information game, and aim to address these problems by reducing Q value overestimation and reshaping reward function.","We propose a novel algorithm that utilizes Monte Carlo Tree Search to improve the value estimation in Q function.","Even though we choose Double Deep Q Learning as the foundational framework in this paper, our method can be generalized and used in any algorithm which needs Q value estimation, such as the Actor-Critic.","Additionally, we employ Monte Carlo Tree Search to reshape the reward structure in the game environment.","We compared our algorithm with several traditional methods applied to games such as Double Deep Q Learning, Deep Monte Carlo and Neural Fictitious Self Play, and the experiments demonstrate that our algorithm consistently outperforms these approaches, especially as the number of players in Uno increases, indicating a higher level of difficulty."],"url":"http://arxiv.org/abs/2410.11642v1"}
