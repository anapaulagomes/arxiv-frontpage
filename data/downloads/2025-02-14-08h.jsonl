{"created":"2025-02-13 18:59:50","title":"Embed Any NeRF: Graph Meta-Networks for Neural Tasks on Arbitrary NeRF Architectures","abstract":"Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for representing 3D objects and scenes by encoding shape and appearance information into the weights of a neural network. Recent works have shown how such weights can be used as input to frameworks processing them to solve deep learning tasks. Yet, these frameworks can only process NeRFs with a specific, predefined architecture. In this paper, we present the first framework that can ingest NeRFs with multiple architectures and perform inference on architectures unseen at training time. We achieve this goal by training a Graph Meta-Network in a representation learning framework. Moreover, we show how a contrastive objective is conducive to obtaining an architecture-agnostic latent space. In experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates robust performance in classification and retrieval tasks that either matches or exceeds that of existing frameworks constrained to single architectures, thus providing the first architecture-agnostic method to perform tasks on NeRFs by processing their weights.","sentences":["Neural Radiance Fields (NeRFs) have emerged as a groundbreaking paradigm for representing 3D objects and scenes by encoding shape and appearance information into the weights of a neural network.","Recent works have shown how such weights can be used as input to frameworks processing them to solve deep learning tasks.","Yet, these frameworks can only process NeRFs with a specific, predefined architecture.","In this paper, we present the first framework that can ingest NeRFs with multiple architectures and perform inference on architectures unseen at training time.","We achieve this goal by training a Graph Meta-Network in a representation learning framework.","Moreover, we show how a contrastive objective is conducive to obtaining an architecture-agnostic latent space.","In experiments on both MLP-based and tri-planar NeRFs, our approach demonstrates robust performance in classification and retrieval tasks that either matches or exceeds that of existing frameworks constrained to single architectures, thus providing the first architecture-agnostic method to perform tasks on NeRFs by processing their weights."],"url":"http://arxiv.org/abs/2502.09623v1"}
{"created":"2025-02-13 18:59:47","title":"Theoretical Benefit and Limitation of Diffusion Language Model","abstract":"Diffusion language models have emerged as a promising approach for text generation. One would naturally expect this method to be an efficient replacement for autoregressive models since multiple tokens can be sampled in parallel during each diffusion step. However, its efficiency-accuracy trade-off is not yet well understood. In this paper, we present a rigorous theoretical analysis of a widely used type of diffusion language model, the Masked Diffusion Model (MDM), and find that its effectiveness heavily depends on the target evaluation metric. Under mild conditions, we prove that when using perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling steps regardless of sequence length, demonstrating that efficiency can be achieved without sacrificing performance. However, when using the sequence error rate--which is important for understanding the \"correctness\" of a sequence, such as a reasoning chain--we show that the required sampling steps must scale linearly with sequence length to obtain \"correct\" sequences, thereby eliminating MDM's efficiency advantage over autoregressive models. Our analysis establishes the first theoretical foundation for understanding the benefits and limitations of MDMs. All theoretical findings are supported by empirical studies.","sentences":["Diffusion language models have emerged as a promising approach for text generation.","One would naturally expect this method to be an efficient replacement for autoregressive models since multiple tokens can be sampled in parallel during each diffusion step.","However, its efficiency-accuracy trade-off is not yet well understood.","In this paper, we present a rigorous theoretical analysis of a widely used type of diffusion language model, the Masked Diffusion Model (MDM), and find that its effectiveness heavily depends on the target evaluation metric.","Under mild conditions, we prove that when using perplexity as the metric, MDMs can achieve near-optimal perplexity in sampling steps regardless of sequence length, demonstrating that efficiency can be achieved without sacrificing performance.","However, when using the sequence error rate--which is important for understanding the \"correctness\" of a sequence, such as a reasoning chain--we show that the required sampling steps must scale linearly with sequence length to obtain \"correct\" sequences, thereby eliminating MDM's efficiency advantage over autoregressive models.","Our analysis establishes the first theoretical foundation for understanding the benefits and limitations of MDMs.","All theoretical findings are supported by empirical studies."],"url":"http://arxiv.org/abs/2502.09622v1"}
{"created":"2025-02-13 18:59:46","title":"MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency","abstract":"Answering questions with Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), yet its impact on Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth investigation. In this paper, we introduce MME-CoT, a specialized benchmark evaluating the CoT reasoning performance of LMMs, spanning six domains: math, science, OCR, logic, space-time, and general scenes. As the first comprehensive study in this area, we propose a thorough evaluation suite incorporating three novel metrics that assess the reasoning quality, robustness, and efficiency at a fine-grained level. Leveraging curated high-quality data and a unique evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs, uncovering several key insights: 1) Models with reflection mechanism demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and demonstrating the highest quality results; 2) CoT prompting often degrades LMM performance on perception-heavy tasks, suggesting a potentially harmful overthinking behavior; and 3) Although the CoT quality is high, LMMs with reflection exhibit significant inefficiency in both normal response and self-correction phases. We hope MME-CoT serves as a foundation for advancing multimodal reasoning in LMMs. Project Page: https://mmecot.github.io/","sentences":["Answering questions with Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), yet its impact on Large Multimodal Models (LMMs) still lacks a systematic assessment and in-depth investigation.","In this paper, we introduce MME-CoT, a specialized benchmark evaluating the CoT reasoning performance of LMMs, spanning six domains: math, science, OCR, logic, space-time, and general scenes.","As the first comprehensive study in this area, we propose a thorough evaluation suite incorporating three novel metrics that assess the reasoning quality, robustness, and efficiency at a fine-grained level.","Leveraging curated high-quality data and a unique evaluation strategy, we conduct an in-depth analysis of state-of-the-art LMMs, uncovering several key insights: 1) Models with reflection mechanism demonstrate a superior CoT quality, with Kimi k1.5 outperforming GPT-4o and demonstrating the highest quality results; 2) CoT prompting often degrades LMM performance on perception-heavy tasks, suggesting a potentially harmful overthinking behavior; and 3)","Although the CoT quality is high, LMMs with reflection exhibit significant inefficiency in both normal response and self-correction phases.","We hope MME-CoT serves as a foundation for advancing multimodal reasoning in LMMs.","Project Page: https://mmecot.github.io/"],"url":"http://arxiv.org/abs/2502.09621v1"}
{"created":"2025-02-13 18:59:45","title":"Exploring the Potential of Encoder-free Architectures in 3D LMMs","abstract":"Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios. In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs). These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs). We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses. And we present the Hybrid Semantic Loss to extract high-level semantics. 2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage. This incorporates inductive bias into the LLM early layers to focus on the local details of the point clouds. To the end, we present the first Encoder-free 3D LMM, ENEL. Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the classification, captioning, and VQA tasks, respectively. Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding. The code is released at https://github.com/Ivan-Tang-3D/ENEL","sentences":["Encoder-free architectures have been preliminarily explored in the 2D visual domain, yet it remains an open question whether they can be effectively applied to 3D understanding scenarios.","In this paper, we present the first comprehensive investigation into the potential of encoder-free architectures to overcome the challenges of encoder-based 3D Large Multimodal Models (LMMs).","These challenges include the failure to adapt to varying point cloud resolutions and the point features from the encoder not meeting the semantic needs of Large Language Models (LLMs).","We identify key aspects for 3D LMMs to remove the encoder and enable the LLM to assume the role of the 3D encoder: 1) We propose the LLM-embedded Semantic Encoding strategy in the pre-training stage, exploring the effects of various point cloud self-supervised losses.","And we present the Hybrid Semantic Loss to extract high-level semantics.","2) We introduce the Hierarchical Geometry Aggregation strategy in the instruction tuning stage.","This incorporates inductive bias into the LLM early layers to focus on the local details of the point clouds.","To the end, we present the first Encoder-free 3D LMM, ENEL.","Our 7B model rivals the current state-of-the-art model, ShapeLLM-13B, achieving 55.0%, 50.92%, and 42.7% on the classification, captioning, and VQA tasks, respectively.","Our results demonstrate that the encoder-free architecture is highly promising for replacing encoder-based architectures in the field of 3D understanding.","The code is released at https://github.com/Ivan-Tang-3D/ENEL"],"url":"http://arxiv.org/abs/2502.09620v1"}
{"created":"2025-02-13 18:59:44","title":"Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights","abstract":"With the increasing numbers of publicly available models, there are probably pretrained, online models for most tasks users require. However, current model search methods are rudimentary, essentially a text-based search in the documentation, thus users cannot find the relevant models. This paper presents ProbeLog, a method for retrieving classification models that can recognize a target concept, such as \"Dog\", without access to model metadata or training data. Differently from previous probing methods, ProbeLog computes a descriptor for each output dimension (logit) of each model, by observing its responses on a fixed set of inputs (probes). Our method supports both logit-based retrieval (\"find more logits like this\") and zero-shot, text-based retrieval (\"find all logits corresponding to dogs\"). As probing-based representations require multiple costly feedforward passes through the model, we develop a method, based on collaborative filtering, that reduces the cost of encoding repositories by 3x. We demonstrate that ProbeLog achieves high retrieval accuracy, both in real-world and fine-grained search tasks and is scalable to full-size repositories.","sentences":["With the increasing numbers of publicly available models, there are probably pretrained, online models for most tasks users require.","However, current model search methods are rudimentary, essentially a text-based search in the documentation, thus users cannot find the relevant models.","This paper presents ProbeLog, a method for retrieving classification models that can recognize a target concept, such as \"Dog\", without access to model metadata or training data.","Differently from previous probing methods, ProbeLog computes a descriptor for each output dimension (logit) of each model, by observing its responses on a fixed set of inputs (probes).","Our method supports both logit-based retrieval (\"find more logits like this\") and zero-shot, text-based retrieval (\"find all logits corresponding to dogs\").","As probing-based representations require multiple costly feedforward passes through the model, we develop a method, based on collaborative filtering, that reduces the cost of encoding repositories by 3x.","We demonstrate that ProbeLog achieves high retrieval accuracy, both in real-world and fine-grained search tasks and is scalable to full-size repositories."],"url":"http://arxiv.org/abs/2502.09619v1"}
{"created":"2025-02-13 18:59:30","title":"Pitfalls of Evidence-Based AI Policy","abstract":"Nations across the world are working to govern AI. However, from a technical perspective, there is uncertainty and disagreement on the best way to do this. Meanwhile, recent debates over AI regulation have led to calls for \"evidence-based AI policy\" which emphasize holding regulatory action to a high evidentiary standard. Evidence is of irreplaceable value to policymaking. However, holding regulatory action to too high an evidentiary standard can lead to systematic neglect of certain risks. In historical policy debates (e.g., over tobacco ca. 1965 and fossil fuels ca. 1985) \"evidence-based policy\" rhetoric is also a well-precedented strategy to downplay the urgency of action, delay regulation, and protect industry interests. Here, we argue that if the goal is evidence-based AI policy, the first regulatory objective must be to actively facilitate the process of identifying, studying, and deliberating about AI risks. We discuss a set of 15 regulatory goals to facilitate this and show that Brazil, Canada, China, the EU, South Korea, the UK, and the USA all have substantial opportunities to adopt further evidence-seeking policies.","sentences":["Nations across the world are working to govern AI.","However, from a technical perspective, there is uncertainty and disagreement on the best way to do this.","Meanwhile, recent debates over AI regulation have led to calls for \"evidence-based AI policy\" which emphasize holding regulatory action to a high evidentiary standard.","Evidence is of irreplaceable value to policymaking.","However, holding regulatory action to too high an evidentiary standard can lead to systematic neglect of certain risks.","In historical policy debates (e.g., over tobacco ca. 1965 and fossil fuels ca. 1985) \"evidence-based policy\" rhetoric is also a well-precedented strategy to downplay the urgency of action, delay regulation, and protect industry interests.","Here, we argue that if the goal is evidence-based AI policy, the first regulatory objective must be to actively facilitate the process of identifying, studying, and deliberating about AI risks.","We discuss a set of 15 regulatory goals to facilitate this and show that Brazil, Canada, China, the EU, South Korea, the UK, and the USA all have substantial opportunities to adopt further evidence-seeking policies."],"url":"http://arxiv.org/abs/2502.09618v1"}
{"created":"2025-02-13 18:59:19","title":"LIFe-GoM: Generalizable Human Rendering with Learned Iterative Feedback Over Multi-Resolution Gaussians-on-Mesh","abstract":"Generalizable rendering of an animatable human avatar from sparse inputs relies on data priors and inductive biases extracted from training on large data to avoid scene-specific optimization and to enable fast reconstruction. This raises two main challenges: First, unlike iterative gradient-based adjustment in scene-specific optimization, generalizable methods must reconstruct the human shape representation in a single pass at inference time. Second, rendering is preferably computationally efficient yet of high resolution. To address both challenges we augment the recently proposed dual shape representation, which combines the benefits of a mesh and Gaussian points, in two ways. To improve reconstruction, we propose an iterative feedback update framework, which successively improves the canonical human shape representation during reconstruction. To achieve computationally efficient yet high-resolution rendering, we study a coupled-multi-resolution Gaussians-on-Mesh representation. We evaluate the proposed approach on the challenging THuman2.0, XHuman and AIST++ data. Our approach reconstructs an animatable representation from sparse inputs in less than 1s, renders views with 95.1FPS at $1024 \\times 1024$, and achieves PSNR/LPIPS*/FID of 24.65/110.82/51.27 on THuman2.0, outperforming the state-of-the-art in rendering quality.","sentences":["Generalizable rendering of an animatable human avatar from sparse inputs relies on data priors and inductive biases extracted from training on large data to avoid scene-specific optimization and to enable fast reconstruction.","This raises two main challenges: First, unlike iterative gradient-based adjustment in scene-specific optimization, generalizable methods must reconstruct the human shape representation in a single pass at inference time.","Second, rendering is preferably computationally efficient yet of high resolution.","To address both challenges we augment the recently proposed dual shape representation, which combines the benefits of a mesh and Gaussian points, in two ways.","To improve reconstruction, we propose an iterative feedback update framework, which successively improves the canonical human shape representation during reconstruction.","To achieve computationally efficient yet high-resolution rendering, we study a coupled-multi-resolution Gaussians-on-Mesh representation.","We evaluate the proposed approach on the challenging THuman2.0, XHuman and AIST++ data.","Our approach reconstructs an animatable representation from sparse inputs in less than 1s, renders views with 95.1FPS at $1024 \\times 1024$, and achieves PSNR/LPIPS*/FID of 24.65/110.82/51.27 on THuman2.0, outperforming the state-of-the-art in rendering quality."],"url":"http://arxiv.org/abs/2502.09617v1"}
{"created":"2025-02-13 18:59:15","title":"Variational Rectified Flow Matching","abstract":"We study Variational Rectified Flow Matching, a framework that enhances classic rectified flow matching by modeling multi-modal velocity vector-fields. At inference time, classic rectified flow matching 'moves' samples from a source distribution to the target distribution by solving an ordinary differential equation via integration along a velocity vector-field. At training time, the velocity vector-field is learnt by linearly interpolating between coupled samples one drawn from the source and one drawn from the target distribution randomly. This leads to ''ground-truth'' velocity vector-fields that point in different directions at the same location, i.e., the velocity vector-fields are multi-modal/ambiguous. However, since training uses a standard mean-squared-error loss, the learnt velocity vector-field averages ''ground-truth'' directions and isn't multi-modal. In contrast, variational rectified flow matching learns and samples from multi-modal flow directions. We show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational rectified flow matching leads to compelling results.","sentences":["We study Variational Rectified Flow Matching, a framework that enhances classic rectified flow matching by modeling multi-modal velocity vector-fields.","At inference time, classic rectified flow matching 'moves' samples from a source distribution to the target distribution by solving an ordinary differential equation via integration along a velocity vector-field.","At training time, the velocity vector-field is learnt by linearly interpolating between coupled samples one drawn from the source and one drawn from the target distribution randomly.","This leads to ''ground-truth'' velocity vector-fields that point in different directions at the same location, i.e., the velocity vector-fields are multi-modal/ambiguous.","However, since training uses a standard mean-squared-error loss, the learnt velocity vector-field averages ''ground-truth'' directions and isn't multi-modal.","In contrast, variational rectified flow matching learns and samples from multi-modal flow directions.","We show on synthetic data, MNIST, CIFAR-10, and ImageNet that variational rectified flow matching leads to compelling results."],"url":"http://arxiv.org/abs/2502.09616v1"}
{"created":"2025-02-13 18:59:13","title":"DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References","abstract":"We address the challenge of developing a generalizable neural tracking controller for dexterous manipulation from human references. This controller aims to manage a dexterous robot hand to manipulate diverse objects for various purposes defined by kinematic human-object interactions. Developing such a controller is complicated by the intricate contact dynamics of dexterous manipulation and the need for adaptivity, generalizability, and robustness. Current reinforcement learning and trajectory optimization methods often fall short due to their dependence on task-specific rewards or precise system models. We introduce an approach that curates large-scale successful robot tracking demonstrations, comprising pairs of human references and robot actions, to train a neural controller. Utilizing a data flywheel, we iteratively enhance the controller's performance, as well as the number and quality of successful tracking demonstrations. We exploit available tracking demonstrations and carefully integrate reinforcement learning and imitation learning to boost the controller's performance in dynamic environments. At the same time, to obtain high-quality tracking demonstrations, we individually optimize per-trajectory tracking by leveraging the learned tracking controller in a homotopy optimization method. The homotopy optimization, mimicking chain-of-thought, aids in solving challenging trajectory tracking problems to increase demonstration diversity. We showcase our success by training a generalizable neural controller and evaluating it in both simulation and real world. Our method achieves over a 10% improvement in success rates compared to leading baselines. The project website with animated results is available at https://meowuu7.github.io/DexTrack/.","sentences":["We address the challenge of developing a generalizable neural tracking controller for dexterous manipulation from human references.","This controller aims to manage a dexterous robot hand to manipulate diverse objects for various purposes defined by kinematic human-object interactions.","Developing such a controller is complicated by the intricate contact dynamics of dexterous manipulation and the need for adaptivity, generalizability, and robustness.","Current reinforcement learning and trajectory optimization methods often fall short due to their dependence on task-specific rewards or precise system models.","We introduce an approach that curates large-scale successful robot tracking demonstrations, comprising pairs of human references and robot actions, to train a neural controller.","Utilizing a data flywheel, we iteratively enhance the controller's performance, as well as the number and quality of successful tracking demonstrations.","We exploit available tracking demonstrations and carefully integrate reinforcement learning and imitation learning to boost the controller's performance in dynamic environments.","At the same time, to obtain high-quality tracking demonstrations, we individually optimize per-trajectory tracking by leveraging the learned tracking controller in a homotopy optimization method.","The homotopy optimization, mimicking chain-of-thought, aids in solving challenging trajectory tracking problems to increase demonstration diversity.","We showcase our success by training a generalizable neural controller and evaluating it in both simulation and real world.","Our method achieves over a 10% improvement in success rates compared to leading baselines.","The project website with animated results is available at https://meowuu7.github.io/DexTrack/."],"url":"http://arxiv.org/abs/2502.09614v1"}
{"created":"2025-02-13 18:59:13","title":"RigAnything: Template-Free Autoregressive Rigging for Diverse 3D Assets","abstract":"We present RigAnything, a novel autoregressive transformer-based model, which makes 3D assets rig-ready by probabilistically generating joints, skeleton topologies, and assigning skinning weights in a template-free manner. Unlike most existing auto-rigging methods, which rely on predefined skeleton template and are limited to specific categories like humanoid, RigAnything approaches the rigging problem in an autoregressive manner, iteratively predicting the next joint based on the global input shape and the previous prediction. While autoregressive models are typically used to generate sequential data, RigAnything extends their application to effectively learn and represent skeletons, which are inherently tree structures. To achieve this, we organize the joints in a breadth-first search (BFS) order, enabling the skeleton to be defined as a sequence of 3D locations and the parent index. Furthermore, our model improves the accuracy of position prediction by leveraging diffusion modeling, ensuring precise and consistent placement of joints within the hierarchy. This formulation allows the autoregressive model to efficiently capture both spatial and hierarchical relationships within the skeleton. Trained end-to-end on both RigNet and Objaverse datasets, RigAnything demonstrates state-of-the-art performance across diverse object types, including humanoids, quadrupeds, marine creatures, insects, and many more, surpassing prior methods in quality, robustness, generalizability, and efficiency. Please check our website for more details: https://www.liuisabella.com/RigAnything.","sentences":["We present RigAnything, a novel autoregressive transformer-based model, which makes 3D assets rig-ready by probabilistically generating joints, skeleton topologies, and assigning skinning weights in a template-free manner.","Unlike most existing auto-rigging methods, which rely on predefined skeleton template and are limited to specific categories like humanoid, RigAnything approaches the rigging problem in an autoregressive manner, iteratively predicting the next joint based on the global input shape and the previous prediction.","While autoregressive models are typically used to generate sequential data, RigAnything extends their application to effectively learn and represent skeletons, which are inherently tree structures.","To achieve this, we organize the joints in a breadth-first search (BFS) order, enabling the skeleton to be defined as a sequence of 3D locations and the parent index.","Furthermore, our model improves the accuracy of position prediction by leveraging diffusion modeling, ensuring precise and consistent placement of joints within the hierarchy.","This formulation allows the autoregressive model to efficiently capture both spatial and hierarchical relationships within the skeleton.","Trained end-to-end on both RigNet and Objaverse datasets, RigAnything demonstrates state-of-the-art performance across diverse object types, including humanoids, quadrupeds, marine creatures, insects, and many more, surpassing prior methods in quality, robustness, generalizability, and efficiency.","Please check our website for more details: https://www.liuisabella.com/RigAnything."],"url":"http://arxiv.org/abs/2502.09615v1"}
{"created":"2025-02-13 18:59:09","title":"Latent Radiance Fields with 3D-aware 2D Representations","abstract":"Latent 3D reconstruction has shown great promise in empowering 3D semantic understanding and 3D generation by distilling 2D features into the 3D space. However, existing approaches struggle with the domain gap between 2D feature space and 3D representations, resulting in degraded rendering performance. To address this challenge, we propose a novel framework that integrates 3D awareness into the 2D latent space. The framework consists of three stages: (1) a correspondence-aware autoencoding method that enhances the 3D consistency of 2D latent representations, (2) a latent radiance field (LRF) that lifts these 3D-aware 2D representations into 3D space, and (3) a VAE-Radiance Field (VAE-RF) alignment strategy that improves image decoding from the rendered 2D representations. Extensive experiments demonstrate that our method outperforms the state-of-the-art latent 3D reconstruction approaches in terms of synthesis performance and cross-dataset generalizability across diverse indoor and outdoor scenes. To our knowledge, this is the first work showing the radiance field representations constructed from 2D latent representations can yield photorealistic 3D reconstruction performance.","sentences":["Latent 3D reconstruction has shown great promise in empowering 3D semantic understanding and 3D generation by distilling 2D features into the 3D space.","However, existing approaches struggle with the domain gap between 2D feature space and 3D representations, resulting in degraded rendering performance.","To address this challenge, we propose a novel framework that integrates 3D awareness into the 2D latent space.","The framework consists of three stages: (1) a correspondence-aware autoencoding method that enhances the 3D consistency of 2D latent representations, (2) a latent radiance field (LRF) that lifts these 3D-aware 2D representations into 3D space, and (3) a VAE-Radiance Field (VAE-RF) alignment strategy that improves image decoding from the rendered 2D representations.","Extensive experiments demonstrate that our method outperforms the state-of-the-art latent 3D reconstruction approaches in terms of synthesis performance and cross-dataset generalizability across diverse indoor and outdoor scenes.","To our knowledge, this is the first work showing the radiance field representations constructed from 2D latent representations can yield photorealistic 3D reconstruction performance."],"url":"http://arxiv.org/abs/2502.09613v1"}
{"created":"2025-02-13 18:58:15","title":"Designing a Conditional Prior Distribution for Flow-Based Generative Models","abstract":"Flow-based generative models have recently shown impressive performance for conditional generation tasks, such as text-to-image generation. However, current methods transform a general unimodal noise distribution to a specific mode of the target data distribution. As such, every point in the initial source distribution can be mapped to every point in the target distribution, resulting in long average paths. To this end, in this work, we tap into a non-utilized property of conditional flow-based models: the ability to design a non-trivial prior distribution. Given an input condition, such as a text prompt, we first map it to a point lying in data space, representing an ``average\" data point with the minimal average distance to all data points of the same conditional mode (e.g., class). We then utilize the flow matching formulation to map samples from a parametric distribution centered around this point to the conditional target distribution. Experimentally, our method significantly improves training times and generation efficiency (FID, KID and CLIP alignment scores) compared to baselines, producing high quality samples using fewer sampling steps.","sentences":["Flow-based generative models have recently shown impressive performance for conditional generation tasks, such as text-to-image generation.","However, current methods transform a general unimodal noise distribution to a specific mode of the target data distribution.","As such, every point in the initial source distribution can be mapped to every point in the target distribution, resulting in long average paths.","To this end, in this work, we tap into a non-utilized property of conditional flow-based models: the ability to design a non-trivial prior distribution.","Given an input condition, such as a text prompt, we first map it to a point lying in data space, representing an ``average\" data point with the minimal average distance to all data points of the same conditional mode (e.g., class).","We then utilize the flow matching formulation to map samples from a parametric distribution centered around this point to the conditional target distribution.","Experimentally, our method significantly improves training times and generation efficiency (FID, KID and CLIP alignment scores) compared to baselines, producing high quality samples using fewer sampling steps."],"url":"http://arxiv.org/abs/2502.09611v1"}
{"created":"2025-02-13 18:57:20","title":"Score-of-Mixture Training: Training One-Step Generative Models Made Simple","abstract":"We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the $\\alpha$-skew Jensen-Shannon divergence. At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels. Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD). It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training. Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods.","sentences":["We propose Score-of-Mixture Training (SMT), a novel framework for training one-step generative models by minimizing a class of divergences called the $\\alpha$-skew Jensen-Shannon divergence.","At its core, SMT estimates the score of mixture distributions between real and fake samples across multiple noise levels.","Similar to consistency models, our approach supports both training from scratch (SMT) and distillation using a pretrained diffusion model, which we call Score-of-Mixture Distillation (SMD).","It is simple to implement, requires minimal hyperparameter tuning, and ensures stable training.","Experiments on CIFAR-10 and ImageNet 64x64 show that SMT/SMD are competitive with and can even outperform existing methods."],"url":"http://arxiv.org/abs/2502.09609v1"}
{"created":"2025-02-13 18:56:05","title":"Instance Segmentation of Scene Sketches Using Natural Image Priors","abstract":"Sketch segmentation involves grouping pixels within a sketch that belong to the same object or instance. It serves as a valuable tool for sketch editing tasks, such as moving, scaling, or removing specific components. While image segmentation models have demonstrated remarkable capabilities in recent years, sketches present unique challenges for these models due to their sparse nature and wide variation in styles. We introduce SketchSeg, a method for instance segmentation of raster scene sketches. Our approach adapts state-of-the-art image segmentation and object detection models to the sketch domain by employing class-agnostic fine-tuning and refining segmentation masks using depth cues. Furthermore, our method organizes sketches into sorted layers, where occluded instances are inpainted, enabling advanced sketch editing applications. As existing datasets in this domain lack variation in sketch styles, we construct a synthetic scene sketch segmentation dataset featuring sketches with diverse brush strokes and varying levels of detail. We use this dataset to demonstrate the robustness of our approach and will release it to promote further research in the field.   Project webpage: https://sketchseg.github.io/sketch-seg/","sentences":["Sketch segmentation involves grouping pixels within a sketch that belong to the same object or instance.","It serves as a valuable tool for sketch editing tasks, such as moving, scaling, or removing specific components.","While image segmentation models have demonstrated remarkable capabilities in recent years, sketches present unique challenges for these models due to their sparse nature and wide variation in styles.","We introduce SketchSeg, a method for instance segmentation of raster scene sketches.","Our approach adapts state-of-the-art image segmentation and object detection models to the sketch domain by employing class-agnostic fine-tuning and refining segmentation masks using depth cues.","Furthermore, our method organizes sketches into sorted layers, where occluded instances are inpainted, enabling advanced sketch editing applications.","As existing datasets in this domain lack variation in sketch styles, we construct a synthetic scene sketch segmentation dataset featuring sketches with diverse brush strokes and varying levels of detail.","We use this dataset to demonstrate the robustness of our approach and will release it to promote further research in the field.   ","Project webpage: https://sketchseg.github.io/sketch-seg/"],"url":"http://arxiv.org/abs/2502.09608v1"}
{"created":"2025-02-13 18:55:56","title":"Human-LLM Coevolution: Evidence from Academic Writing","abstract":"With a statistical analysis of arXiv paper abstracts, we report a marked drop in the frequency of several words previously identified as overused by ChatGPT, such as \"delve\", starting soon after they were pointed out in early 2024. The frequency of certain other words favored by ChatGPT, such as \"significant\", has instead kept increasing. These phenomena suggest that some authors of academic papers have adapted their use of large language models (LLMs), for example, by selecting outputs or applying modifications to the LLM-generated content. Such coevolution and cooperation of humans and LLMs thus introduce additional challenges to the detection of machine-generated text in real-world scenarios. Estimating the impact of LLMs on academic writing by examining word frequency remains feasible, and more attention should be paid to words that were already frequently employed, including those that have decreased in frequency.","sentences":["With a statistical analysis of arXiv paper abstracts, we report a marked drop in the frequency of several words previously identified as overused by ChatGPT, such as \"delve\", starting soon after they were pointed out in early 2024.","The frequency of certain other words favored by ChatGPT, such as \"significant\", has instead kept increasing.","These phenomena suggest that some authors of academic papers have adapted their use of large language models (LLMs), for example, by selecting outputs or applying modifications to the LLM-generated content.","Such coevolution and cooperation of humans and LLMs thus introduce additional challenges to the detection of machine-generated text in real-world scenarios.","Estimating the impact of LLMs on academic writing by examining word frequency remains feasible, and more attention should be paid to words that were already frequently employed, including those that have decreased in frequency."],"url":"http://arxiv.org/abs/2502.09606v1"}
{"created":"2025-02-13 18:55:13","title":"SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models","abstract":"We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses. Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response. This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations. The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks.","sentences":["We introduce SelfCite, a novel self-supervised approach that aligns LLMs to generate high-quality, fine-grained, sentence-level citations for the statements in their generated responses.","Instead of only relying on costly and labor-intensive annotations, SelfCite leverages a reward signal provided by the LLM itself through context ablation: If a citation is necessary, removing the cited text from the context should prevent the same response; if sufficient, retaining the cited text alone should preserve the same response.","This reward can guide the inference-time best-of-N sampling strategy to improve citation quality significantly, as well as be used in preference optimization to directly fine-tune the models for generating better citations.","The effectiveness of SelfCite is demonstrated by increasing citation F1 up to 5.3 points on the LongBench-Cite benchmark across five long-form question answering tasks."],"url":"http://arxiv.org/abs/2502.09604v1"}
{"created":"2025-02-13 18:52:36","title":"CoT-Valve: Length-Compressible Chain-of-Thought Tuning","abstract":"Chain-of-Thought significantly enhances a model's reasoning capability, but it also comes with a considerable increase in inference costs due to long chains. With the observation that the reasoning path can be easily compressed under easy tasks but struggle on hard tasks, we explore the feasibility of elastically controlling the length of reasoning paths with only one model, thereby reducing the inference overhead of reasoning models dynamically based on task difficulty. We introduce a new tuning and inference strategy named CoT-Valve, designed to allow models to generate reasoning chains of varying lengths. To achieve this, we propose to identify a direction in the parameter space that, when manipulated, can effectively control the length of generated CoT. Moreover, we show that this property is valuable for compressing the reasoning chain. We construct datasets with chains from long to short for the same questions and explore two enhanced strategies for CoT-Valve: (1) a precise length-compressible CoT tuning method, and (2) a progressive chain length compression approach. Our experiments show that CoT-Valve successfully enables controllability and compressibility of the chain and shows better performance than the prompt-based control. We applied this method to QwQ-32B-Preview, reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with only one additional incorrect answer.","sentences":["Chain-of-Thought significantly enhances a model's reasoning capability, but it also comes with a considerable increase in inference costs due to long chains.","With the observation that the reasoning path can be easily compressed under easy tasks but struggle on hard tasks, we explore the feasibility of elastically controlling the length of reasoning paths with only one model, thereby reducing the inference overhead of reasoning models dynamically based on task difficulty.","We introduce a new tuning and inference strategy named CoT-Valve, designed to allow models to generate reasoning chains of varying lengths.","To achieve this, we propose to identify a direction in the parameter space that, when manipulated, can effectively control the length of generated CoT.","Moreover, we show that this property is valuable for compressing the reasoning chain.","We construct datasets with chains from long to short for the same questions and explore two enhanced strategies for CoT-Valve: (1) a precise length-compressible CoT tuning method, and (2) a progressive chain length compression approach.","Our experiments show that CoT-Valve successfully enables controllability and compressibility of the chain and shows better performance than the prompt-based control.","We applied this method to QwQ-32B-Preview, reducing reasoning chains on GSM8K from 741 to 225 tokens with a minor performance drop (95.07% to 94.92%) and on AIME from 6827 to 4629 tokens, with only one additional incorrect answer."],"url":"http://arxiv.org/abs/2502.09601v1"}
{"created":"2025-02-13 18:52:14","title":"GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for Remote Sensing Image Analysis","abstract":"The continuous operation of Earth-orbiting satellites generates vast and ever-growing archives of Remote Sensing (RS) images. Natural language presents an intuitive interface for accessing, querying, and interpreting the data from such archives. However, existing Vision-Language Models (VLMs) are predominantly trained on web-scraped, noisy image-text data, exhibiting limited exposure to the specialized domain of RS. This deficiency results in poor performance on RS-specific tasks, as commonly used datasets often lack detailed, scientifically accurate textual descriptions and instead emphasize solely on attributes like date and location. To bridge this critical gap, we introduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and multi-modal RS image analysis. GAIA comprises of 205,150 meticulously curated RS image-text pairs, representing a diverse range of RS modalities associated to different spatial resolutions. Unlike existing vision-language datasets in RS, GAIA specifically focuses on capturing a diverse range of RS applications, providing unique information about environmental changes, natural disasters, and various other dynamic phenomena. The dataset provides a spatially and temporally balanced distribution, spanning across the globe, covering the last 25 years with a balanced temporal distribution of observations. GAIA's construction involved a two-stage process: (1) targeted web-scraping of images and accompanying text from reputable RS-related sources, and (2) generation of five high-quality, scientifically grounded synthetic captions for each image using carefully crafted prompts that leverage the advanced vision-language capabilities of GPT-4o. Our extensive experiments, including fine-tuning of CLIP and BLIP2 models, demonstrate that GAIA significantly improves performance on RS image classification, cross-modal retrieval and image captioning tasks.","sentences":["The continuous operation of Earth-orbiting satellites generates vast and ever-growing archives of Remote Sensing (RS) images.","Natural language presents an intuitive interface for accessing, querying, and interpreting the data from such archives.","However, existing Vision-Language Models (VLMs) are predominantly trained on web-scraped, noisy image-text data, exhibiting limited exposure to the specialized domain of RS.","This deficiency results in poor performance on RS-specific tasks, as commonly used datasets often lack detailed, scientifically accurate textual descriptions and instead emphasize solely on attributes like date and location.","To bridge this critical gap, we introduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and multi-modal RS image analysis.","GAIA comprises of 205,150 meticulously curated RS image-text pairs, representing a diverse range of RS modalities associated to different spatial resolutions.","Unlike existing vision-language datasets in RS, GAIA specifically focuses on capturing a diverse range of RS applications, providing unique information about environmental changes, natural disasters, and various other dynamic phenomena.","The dataset provides a spatially and temporally balanced distribution, spanning across the globe, covering the last 25 years with a balanced temporal distribution of observations.","GAIA's construction involved a two-stage process: (1) targeted web-scraping of images and accompanying text from reputable RS-related sources, and (2) generation of five high-quality, scientifically grounded synthetic captions for each image using carefully crafted prompts that leverage the advanced vision-language capabilities of GPT-4o.","Our extensive experiments, including fine-tuning of CLIP and BLIP2 models, demonstrate that GAIA significantly improves performance on RS image classification, cross-modal retrieval and image captioning tasks."],"url":"http://arxiv.org/abs/2502.09598v1"}
{"created":"2025-02-13 18:52:03","title":"Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs","abstract":"Large Language Models (LLMs) are increasingly used as chatbots, yet their ability to personalize responses to user preferences remains limited. We introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize and adhere to user preferences in a long-context conversational setting. PrefEval comprises 3,000 manually curated user preference and query pairs spanning 20 topics. PrefEval contains user personalization or preference information in both explicit and implicit forms, and evaluates LLM performance using a generation and a classification task. With PrefEval, we evaluated the aforementioned preference following capabilities of 10 open-source and proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens. We benchmark with various prompting, iterative feedback, and retrieval-augmented generation methods. Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in proactively following users' preferences during conversations. In particular, in zero-shot settings, preference following accuracy falls below 10% at merely 10 turns (~3k tokens) across most evaluated models. Even with advanced prompting and retrieval methods, preference following still deteriorates in long-context conversations. Furthermore, we show that fine-tuning on PrefEval significantly improves performance. We believe PrefEval serves as a valuable resource for measuring, understanding, and enhancing LLMs' preference following abilities, paving the way for personalized conversational agents. Our code and dataset are available at https://prefeval.github.io/.","sentences":["Large Language Models (LLMs) are increasingly used as chatbots, yet their ability to personalize responses to user preferences remains limited.","We introduce PrefEval, a benchmark for evaluating LLMs' ability to infer, memorize and adhere to user preferences in a long-context conversational setting.","PrefEval comprises 3,000 manually curated user preference and query pairs spanning 20 topics.","PrefEval contains user personalization or preference information in both explicit and implicit forms, and evaluates LLM performance using a generation and a classification task.","With PrefEval, we evaluated the aforementioned preference following capabilities of 10 open-source and proprietary LLMs in multi-session conversations with varying context lengths up to 100k tokens.","We benchmark with various prompting, iterative feedback, and retrieval-augmented generation methods.","Our benchmarking effort reveals that state-of-the-art LLMs face significant challenges in proactively following users' preferences during conversations.","In particular, in zero-shot settings, preference following accuracy falls below 10% at merely 10 turns (~3k tokens) across most evaluated models.","Even with advanced prompting and retrieval methods, preference following still deteriorates in long-context conversations.","Furthermore, we show that fine-tuning on PrefEval significantly improves performance.","We believe PrefEval serves as a valuable resource for measuring, understanding, and enhancing LLMs' preference following abilities, paving the way for personalized conversational agents.","Our code and dataset are available at https://prefeval.github.io/."],"url":"http://arxiv.org/abs/2502.09597v1"}
{"created":"2025-02-13 18:51:12","title":"KIMAs: A Configurable Knowledge Integrated Multi-Agent System","abstract":"Knowledge-intensive conversations supported by large language models (LLMs) have become one of the most popular and helpful applications that can assist people in different aspects. Many current knowledge-intensive applications are centered on retrieval-augmented generation (RAG) techniques. While many open-source RAG frameworks facilitate the development of RAG-based applications, they often fall short in handling practical scenarios complicated by heterogeneous data in topics and formats, conversational context management, and the requirement of low-latency response times. This technical report presents a configurable knowledge integrated multi-agent system, KIMAs, to address these challenges. KIMAs features a flexible and configurable system for integrating diverse knowledge sources with 1) context management and query rewrite mechanisms to improve retrieval accuracy and multi-turn conversational coherency, 2) efficient knowledge routing and retrieval, 3) simple but effective filter and reference generation mechanisms, and 4) optimized parallelizable multi-agent pipeline execution. Our work provides a scalable framework for advancing the deployment of LLMs in real-world settings. To show how KIMAs can help developers build knowledge-intensive applications with different scales and emphases, we demonstrate how we configure the system to three applications already running in practice with reliable performance.","sentences":["Knowledge-intensive conversations supported by large language models (LLMs) have become one of the most popular and helpful applications that can assist people in different aspects.","Many current knowledge-intensive applications are centered on retrieval-augmented generation (RAG) techniques.","While many open-source RAG frameworks facilitate the development of RAG-based applications, they often fall short in handling practical scenarios complicated by heterogeneous data in topics and formats, conversational context management, and the requirement of low-latency response times.","This technical report presents a configurable knowledge integrated multi-agent system, KIMAs, to address these challenges.","KIMAs features a flexible and configurable system for integrating diverse knowledge sources with 1) context management and query rewrite mechanisms to improve retrieval accuracy and multi-turn conversational coherency, 2) efficient knowledge routing and retrieval, 3) simple but effective filter and reference generation mechanisms, and 4) optimized parallelizable multi-agent pipeline execution.","Our work provides a scalable framework for advancing the deployment of LLMs in real-world settings.","To show how KIMAs can help developers build knowledge-intensive applications with different scales and emphases, we demonstrate how we configure the system to three applications already running in practice with reliable performance."],"url":"http://arxiv.org/abs/2502.09596v1"}
{"created":"2025-02-13 18:48:04","title":"Censor Dependent Variational Inference","abstract":"This paper provides a comprehensive analysis of variational inference in latent variable models for survival analysis, emphasizing the distinctive challenges associated with applying variational methods to survival data. We identify a critical weakness in the existing methodology, demonstrating how a poorly designed variational distribution may hinder the objective of survival analysis tasks--modeling time-to-event distributions. We prove that the optimal variational distribution, which perfectly bounds the log-likelihood, may depend on the censoring mechanism. To address this issue, we propose censor-dependent variational inference (CDVI), tailored for latent variable models in survival analysis. More practically, we introduce CD-CVAE, a V-structure Variational Autoencoder (VAE) designed for the scalable implementation of CDVI. Further discussion extends some existing theories and training techniques to survival analysis. Extensive experiments validate our analysis and demonstrate significant improvements in the estimation of individual survival distributions.","sentences":["This paper provides a comprehensive analysis of variational inference in latent variable models for survival analysis, emphasizing the distinctive challenges associated with applying variational methods to survival data.","We identify a critical weakness in the existing methodology, demonstrating how a poorly designed variational distribution may hinder the objective of survival analysis tasks--modeling time-to-event distributions.","We prove that the optimal variational distribution, which perfectly bounds the log-likelihood, may depend on the censoring mechanism.","To address this issue, we propose censor-dependent variational inference (CDVI), tailored for latent variable models in survival analysis.","More practically, we introduce CD-CVAE, a V-structure Variational Autoencoder (VAE) designed for the scalable implementation of CDVI.","Further discussion extends some existing theories and training techniques to survival analysis.","Extensive experiments validate our analysis and demonstrate significant improvements in the estimation of individual survival distributions."],"url":"http://arxiv.org/abs/2502.09591v1"}
{"created":"2025-02-13 18:46:44","title":"Logical forms complement probability in understanding language model (and human) performance","abstract":"With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question. This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language. We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance. Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as orthogonal factors. In addition, we show similarities and differences between the logical reasoning performances of humans and LLMs by comparing LLM and human behavioral results.","sentences":["With the increasing interest in using large language models (LLMs) for planning in natural language, understanding their behaviors becomes an important research question.","This work conducts a systematic investigation of LLMs' ability to perform logical reasoning in natural language.","We introduce a controlled dataset of hypothetical and disjunctive syllogisms in propositional and modal logic and use it as the testbed for understanding LLM performance.","Our results lead to novel insights in predicting LLM behaviors: in addition to the probability of input (Gonen et al., 2023; McCoy et al., 2024), logical forms should be considered as orthogonal factors.","In addition, we show similarities and differences between the logical reasoning performances of humans and LLMs by comparing LLM and human behavioral results."],"url":"http://arxiv.org/abs/2502.09589v1"}
{"created":"2025-02-13 18:45:56","title":"Rolling Ahead Diffusion for Traffic Scene Simulation","abstract":"Realistic driving simulation requires that NPCs not only mimic natural driving behaviors but also react to the behavior of other simulated agents. Recent developments in diffusion-based scenario generation focus on creating diverse and realistic traffic scenarios by jointly modelling the motion of all the agents in the scene. However, these traffic scenarios do not react when the motion of agents deviates from their modelled trajectories. For example, the ego-agent can be controlled by a stand along motion planner. To produce reactive scenarios with joint scenario models, the model must regenerate the scenario at each timestep based on new observations in a Model Predictive Control (MPC) fashion. Although reactive, this method is time-consuming, as one complete possible future for all NPCs is generated per simulation step. Alternatively, one can utilize an autoregressive model (AR) to predict only the immediate next-step future for all NPCs. Although faster, this method lacks the capability for advanced planning. We present a rolling diffusion based traffic scene generation model which mixes the benefits of both methods by predicting the next step future and simultaneously predicting partially noised further future steps at the same time. We show that such model is efficient compared to diffusion model based AR, achieving a beneficial compromise between reactivity and computational efficiency.","sentences":["Realistic driving simulation requires that NPCs not only mimic natural driving behaviors but also react to the behavior of other simulated agents.","Recent developments in diffusion-based scenario generation focus on creating diverse and realistic traffic scenarios by jointly modelling the motion of all the agents in the scene.","However, these traffic scenarios do not react when the motion of agents deviates from their modelled trajectories.","For example, the ego-agent can be controlled by a stand along motion planner.","To produce reactive scenarios with joint scenario models, the model must regenerate the scenario at each timestep based on new observations in a Model Predictive Control (MPC) fashion.","Although reactive, this method is time-consuming, as one complete possible future for all NPCs is generated per simulation step.","Alternatively, one can utilize an autoregressive model (AR) to predict only the immediate next-step future for all NPCs.","Although faster, this method lacks the capability for advanced planning.","We present a rolling diffusion based traffic scene generation model which mixes the benefits of both methods by predicting the next step future and simultaneously predicting partially noised further future steps at the same time.","We show that such model is efficient compared to diffusion model based AR, achieving a beneficial compromise between reactivity and computational efficiency."],"url":"http://arxiv.org/abs/2502.09587v1"}
{"created":"2025-02-13 18:42:20","title":"Differentially Private Compression and the Sensitivity of LZ77","abstract":"We initiate the study of differentially private data-compression schemes motivated by the insecurity of the popular \"Compress-Then-Encrypt\" framework. Data compression is a useful tool which exploits redundancy in data to reduce storage/bandwidth when files are stored or transmitted. However, if the contents of a file are confidential then the length of a compressed file might leak confidential information about the content of the file itself. Encrypting a compressed file does not eliminate this leakage as data encryption schemes are only designed to hide the content of confidential message instead of the length of the message. In our proposed Differentially Private Compress-Then-Encrypt framework, we add a random positive amount of padding to the compressed file to ensure that any leakage satisfies the rigorous privacy guarantee of $(\\epsilon,\\delta)$-differential privacy. The amount of padding that needs to be added depends on the sensitivity of the compression scheme to small changes in the input, i.e., to what degree can changing a single character of the input message impact the length of the compressed file. While some popular compression schemes are highly sensitive to small changes in the input, we argue that effective data compression schemes do not necessarily have high sensitivity. Our primary technical contribution is analyzing the fine-grained sensitivity of the LZ77 compression scheme (IEEE Trans. Inf. Theory 1977) which is one of the most common compression schemes used in practice. We show that the global sensitivity of the LZ77 compression scheme has the upper bound $\\mathcal{O}(W^{2/3}\\log n)$ where $W\\leq n$ denotes the size of the sliding window. When $W=n$, we show the lower bound $\\Omega(n^{2/3}\\log^{1/3}n)$ for the global sensitivity of the LZ77 compression scheme which is tight up to a sublogarithmic factor.","sentences":["We initiate the study of differentially private data-compression schemes motivated by the insecurity of the popular \"Compress-Then-Encrypt\" framework.","Data compression is a useful tool which exploits redundancy in data to reduce storage/bandwidth when files are stored or transmitted.","However, if the contents of a file are confidential then the length of a compressed file might leak confidential information about the content of the file itself.","Encrypting a compressed file does not eliminate this leakage as data encryption schemes are only designed to hide the content of confidential message instead of the length of the message.","In our proposed Differentially Private Compress-Then-Encrypt framework, we add a random positive amount of padding to the compressed file to ensure that any leakage satisfies the rigorous privacy guarantee of $(\\epsilon,\\delta)$-differential privacy.","The amount of padding that needs to be added depends on the sensitivity of the compression scheme to small changes in the input, i.e., to what degree can changing a single character of the input message impact the length of the compressed file.","While some popular compression schemes are highly sensitive to small changes in the input, we argue that effective data compression schemes do not necessarily have high sensitivity.","Our primary technical contribution is analyzing the fine-grained sensitivity of the LZ77 compression scheme (IEEE Trans.","Inf.","Theory 1977) which is one of the most common compression schemes used in practice.","We show that the global sensitivity of the LZ77 compression scheme has the upper bound $\\mathcal{O}(W^{2/3}\\log n)$ where $W\\leq n$ denotes the size of the sliding window.","When $W=n$, we show the lower bound $\\Omega(n^{2/3}\\log^{1/3}n)$ for the global sensitivity of the LZ77 compression scheme which is tight up to a sublogarithmic factor."],"url":"http://arxiv.org/abs/2502.09584v1"}
{"created":"2025-02-13 18:41:55","title":"Learning to Coordinate with Experts","abstract":"When deployed in dynamic environments, AI agents will inevitably encounter challenges that exceed their individual capabilities. Leveraging assistance from expert agents-whether human or AI-can significantly enhance safety and performance in such situations. However, querying experts is often costly, necessitating the development of agents that can efficiently request and utilize expert guidance. In this paper, we introduce a fundamental coordination problem called Learning to Yield and Request Control (YRC), where the objective is to learn a strategy that determines when to act autonomously and when to seek expert assistance. We consider a challenging practical setting in which an agent does not interact with experts during training but must adapt to novel environmental changes and expert interventions at test time. To facilitate empirical research, we introduce YRC-Bench, an open-source benchmark featuring diverse domains. YRC-Bench provides a standardized Gym-like API, simulated experts, evaluation pipeline, and implementation of competitive baselines. Towards tackling the YRC problem, we propose a novel validation approach and investigate the performance of various learning methods across diverse environments, yielding insights that can guide future research.","sentences":["When deployed in dynamic environments, AI agents will inevitably encounter challenges that exceed their individual capabilities.","Leveraging assistance from expert agents-whether human or AI-can significantly enhance safety and performance in such situations.","However, querying experts is often costly, necessitating the development of agents that can efficiently request and utilize expert guidance.","In this paper, we introduce a fundamental coordination problem called Learning to Yield and Request Control (YRC), where the objective is to learn a strategy that determines when to act autonomously and when to seek expert assistance.","We consider a challenging practical setting in which an agent does not interact with experts during training but must adapt to novel environmental changes and expert interventions at test time.","To facilitate empirical research, we introduce YRC-Bench, an open-source benchmark featuring diverse domains.","YRC-Bench provides a standardized Gym-like API, simulated experts, evaluation pipeline, and implementation of competitive baselines.","Towards tackling the YRC problem, we propose a novel validation approach and investigate the performance of various learning methods across diverse environments, yielding insights that can guide future research."],"url":"http://arxiv.org/abs/2502.09583v1"}
{"created":"2025-02-13 18:34:52","title":"Polymind: Parallel Visual Diagramming with Large Language Models to Support Prewriting Through Microtasks","abstract":"Prewriting is the process of generating and organising ideas before a first draft. It consists of a combination of informal, iterative, and semi-structured strategies such as visual diagramming, which poses a challenge for collaborating with large language models (LLMs) in a turn-taking conversational manner. We present Polymind, a visual diagramming tool that leverages multiple LLM-powered agents to support prewriting. The system features a parallel collaboration workflow in place of the turn-taking conversational interactions. It defines multiple ``microtasks'' to simulate group collaboration scenarios such as collaborative writing and group brainstorming. Instead of repetitively prompting a chatbot for various purposes, Polymind enables users to orchestrate multiple microtasks simultaneously. Users can configure and delegate customised microtasks, and manage their microtasks by specifying task requirements and toggling visibility and initiative. Our evaluation revealed that, compared to ChatGPT, users had more customizability over collaboration with Polymind, and were thus able to quickly expand personalised writing ideas during prewriting.","sentences":["Prewriting is the process of generating and organising ideas before a first draft.","It consists of a combination of informal, iterative, and semi-structured strategies such as visual diagramming, which poses a challenge for collaborating with large language models (LLMs) in a turn-taking conversational manner.","We present Polymind, a visual diagramming tool that leverages multiple LLM-powered agents to support prewriting.","The system features a parallel collaboration workflow in place of the turn-taking conversational interactions.","It defines multiple ``microtasks'' to simulate group collaboration scenarios such as collaborative writing and group brainstorming.","Instead of repetitively prompting a chatbot for various purposes, Polymind enables users to orchestrate multiple microtasks simultaneously.","Users can configure and delegate customised microtasks, and manage their microtasks by specifying task requirements and toggling visibility and initiative.","Our evaluation revealed that, compared to ChatGPT, users had more customizability over collaboration with Polymind, and were thus able to quickly expand personalised writing ideas during prewriting."],"url":"http://arxiv.org/abs/2502.09577v1"}
{"created":"2025-02-13 18:31:17","title":"Optimizing GPT for Video Understanding: Zero-Shot Performance and Prompt Engineering","abstract":"In this study, we tackle industry challenges in video content classification by exploring and optimizing GPT-based models for zero-shot classification across seven critical categories of video quality. We contribute a novel approach to improving GPT's performance through prompt optimization and policy refinement, demonstrating that simplifying complex policies significantly reduces false negatives. Additionally, we introduce a new decomposition-aggregation-based prompt engineering technique, which outperforms traditional single-prompt methods. These experiments, conducted on real industry problems, show that thoughtful prompt design can substantially enhance GPT's performance without additional finetuning, offering an effective and scalable solution for improving video classification systems across various domains in industry.","sentences":["In this study, we tackle industry challenges in video content classification by exploring and optimizing GPT-based models for zero-shot classification across seven critical categories of video quality.","We contribute a novel approach to improving GPT's performance through prompt optimization and policy refinement, demonstrating that simplifying complex policies significantly reduces false negatives.","Additionally, we introduce a new decomposition-aggregation-based prompt engineering technique, which outperforms traditional single-prompt methods.","These experiments, conducted on real industry problems, show that thoughtful prompt design can substantially enhance GPT's performance without additional finetuning, offering an effective and scalable solution for improving video classification systems across various domains in industry."],"url":"http://arxiv.org/abs/2502.09573v1"}
{"created":"2025-02-13 18:29:48","title":"DiffMS: Diffusion Generation of Molecules Conditioned on Mass Spectra","abstract":"Mass spectrometry plays a fundamental role in elucidating the structures of unknown molecules and subsequent scientific discoveries. One formulation of the structure elucidation task is the conditional $\\textit{de novo}$ generation of molecular structure given a mass spectrum. Toward a more accurate and efficient scientific discovery pipeline for small molecules, we present DiffMS, a formula-restricted encoder-decoder generative network that achieves state-of-the-art performance on this task. The encoder utilizes a transformer architecture and models mass spectra domain knowledge such as peak formulae and neutral losses, and the decoder is a discrete graph diffusion model restricted by the heavy-atom composition of a known chemical formula. To develop a robust decoder that bridges latent embeddings and molecular structures, we pretrain the diffusion decoder with fingerprint-structure pairs, which are available in virtually infinite quantities, compared to structure-spectrum pairs that number in the tens of thousands. Extensive experiments on established benchmarks show that DiffMS outperforms existing models on $\\textit{de novo}$ molecule generation. We provide several ablations to demonstrate the effectiveness of our diffusion and pretraining approaches and show consistent performance scaling with increasing pretraining dataset size. DiffMS code is publicly available at https://github.com/coleygroup/DiffMS.","sentences":["Mass spectrometry plays a fundamental role in elucidating the structures of unknown molecules and subsequent scientific discoveries.","One formulation of the structure elucidation task is the conditional $\\textit{de novo}$ generation of molecular structure given a mass spectrum.","Toward a more accurate and efficient scientific discovery pipeline for small molecules, we present DiffMS, a formula-restricted encoder-decoder generative network that achieves state-of-the-art performance on this task.","The encoder utilizes a transformer architecture and models mass spectra domain knowledge such as peak formulae and neutral losses, and the decoder is a discrete graph diffusion model restricted by the heavy-atom composition of a known chemical formula.","To develop a robust decoder that bridges latent embeddings and molecular structures, we pretrain the diffusion decoder with fingerprint-structure pairs, which are available in virtually infinite quantities, compared to structure-spectrum pairs that number in the tens of thousands.","Extensive experiments on established benchmarks show that DiffMS outperforms existing models on $\\textit{de novo}$ molecule generation.","We provide several ablations to demonstrate the effectiveness of our diffusion and pretraining approaches and show consistent performance scaling with increasing pretraining dataset size.","DiffMS code is publicly available at https://github.com/coleygroup/DiffMS."],"url":"http://arxiv.org/abs/2502.09571v1"}
{"created":"2025-02-13 18:28:17","title":"Enhancing the Utility of Higher-Order Information in Relational Learning","abstract":"Higher-order information is crucial for relational learning in many domains where relationships extend beyond pairwise interactions. Hypergraphs provide a natural framework for modeling such relationships, which has motivated recent extensions of graph neural net- work architectures to hypergraphs. However, comparisons between hypergraph architectures and standard graph-level models remain limited. In this work, we systematically evaluate a selection of hypergraph-level and graph-level architectures, to determine their effectiveness in leveraging higher-order information in relational learning. Our results show that graph-level architectures applied to hypergraph expansions often outperform hypergraph- level ones, even on inputs that are naturally parametrized as hypergraphs. As an alternative approach for leveraging higher-order information, we propose hypergraph-level encodings based on classical hypergraph characteristics. While these encodings do not significantly improve hypergraph architectures, they yield substantial performance gains when combined with graph-level models. Our theoretical analysis shows that hypergraph-level encodings provably increase the representational power of message-passing graph neural networks beyond that of their graph-level counterparts.","sentences":["Higher-order information is crucial for relational learning in many domains where relationships extend beyond pairwise interactions.","Hypergraphs provide a natural framework for modeling such relationships, which has motivated recent extensions of graph neural net- work architectures to hypergraphs.","However, comparisons between hypergraph architectures and standard graph-level models remain limited.","In this work, we systematically evaluate a selection of hypergraph-level and graph-level architectures, to determine their effectiveness in leveraging higher-order information in relational learning.","Our results show that graph-level architectures applied to hypergraph expansions often outperform hypergraph- level ones, even on inputs that are naturally parametrized as hypergraphs.","As an alternative approach for leveraging higher-order information, we propose hypergraph-level encodings based on classical hypergraph characteristics.","While these encodings do not significantly improve hypergraph architectures, they yield substantial performance gains when combined with graph-level models.","Our theoretical analysis shows that hypergraph-level encodings provably increase the representational power of message-passing graph neural networks beyond that of their graph-level counterparts."],"url":"http://arxiv.org/abs/2502.09570v1"}
{"created":"2025-02-13 18:22:31","title":"MorphNLI: A Stepwise Approach to Natural Language Inference Using Text Morphing","abstract":"We introduce MorphNLI, a modular step-by-step approach to natural language inference (NLI). When classifying the premise-hypothesis pairs into {entailment, contradiction, neutral}, we use a language model to generate the necessary edits to incrementally transform (i.e., morph) the premise into the hypothesis. Then, using an off-the-shelf NLI model we track how the entailment progresses with these atomic changes, aggregating these intermediate labels into a final output. We demonstrate the advantages of our proposed method particularly in realistic cross-domain settings, where our method always outperforms strong baselines with improvements up to 12.6% (relative). Further, our proposed approach is explainable as the atomic edits can be used to understand the overall NLI label.","sentences":["We introduce MorphNLI, a modular step-by-step approach to natural language inference (NLI).","When classifying the premise-hypothesis pairs into {entailment, contradiction, neutral}, we use a language model to generate the necessary edits to incrementally transform (i.e., morph) the premise into the hypothesis.","Then, using an off-the-shelf NLI model we track how the entailment progresses with these atomic changes, aggregating these intermediate labels into a final output.","We demonstrate the advantages of our proposed method particularly in realistic cross-domain settings, where our method always outperforms strong baselines with improvements up to 12.6% (relative).","Further, our proposed approach is explainable as the atomic edits can be used to understand the overall NLI label."],"url":"http://arxiv.org/abs/2502.09567v1"}
{"created":"2025-02-13 18:21:15","title":"Zero-shot generation of synthetic neurosurgical data with large language models","abstract":"Clinical data is fundamental to advance neurosurgical research, but access is often constrained by data availability, small sample sizes, privacy regulations, and resource-intensive preprocessing and de-identification procedures. Synthetic data offers a potential solution to challenges associated with accessing and using real-world data (RWD). This study aims to evaluate the capability of zero-shot generation of synthetic neurosurgical data with a large language model (LLM), GPT-4o, by benchmarking with the conditional tabular generative adversarial network (CTGAN). Synthetic datasets were compared to real-world neurosurgical data to assess fidelity (means, proportions, distributions, and bivariate correlations), utility (ML classifier performance on RWD), and privacy (duplication of records from RWD). The GPT-4o-generated datasets matched or exceeded CTGAN performance, despite no fine-tuning or access to RWD for pre-training. Datasets demonstrated high univariate and bivariate fidelity to RWD without directly exposing any real patient records, even at amplified sample size. Training an ML classifier on GPT-4o-generated data and testing on RWD for a binary prediction task showed an F1 score (0.706) with comparable performance to training on the CTGAN data (0.705) for predicting postoperative functional status deterioration. GPT-4o demonstrated a promising ability to generate high-fidelity synthetic neurosurgical data. These findings also indicate that data synthesized with GPT-4o can effectively augment clinical data with small sample sizes, and train ML models for prediction of neurosurgical outcomes. Further investigation is necessary to improve the preservation of distributional characteristics and boost classifier performance.","sentences":["Clinical data is fundamental to advance neurosurgical research, but access is often constrained by data availability, small sample sizes, privacy regulations, and resource-intensive preprocessing and de-identification procedures.","Synthetic data offers a potential solution to challenges associated with accessing and using real-world data (RWD).","This study aims to evaluate the capability of zero-shot generation of synthetic neurosurgical data with a large language model (LLM), GPT-4o, by benchmarking with the conditional tabular generative adversarial network (CTGAN).","Synthetic datasets were compared to real-world neurosurgical data to assess fidelity (means, proportions, distributions, and bivariate correlations), utility (ML classifier performance on RWD), and privacy (duplication of records from RWD).","The GPT-4o-generated datasets matched or exceeded CTGAN performance, despite no fine-tuning or access to RWD for pre-training.","Datasets demonstrated high univariate and bivariate fidelity to RWD without directly exposing any real patient records, even at amplified sample size.","Training an ML classifier on GPT-4o-generated data and testing on RWD for a binary prediction task showed an F1 score (0.706) with comparable performance to training on the CTGAN data (0.705) for predicting postoperative functional status deterioration.","GPT-4o demonstrated a promising ability to generate high-fidelity synthetic neurosurgical data.","These findings also indicate that data synthesized with GPT-4o can effectively augment clinical data with small sample sizes, and train ML models for prediction of neurosurgical outcomes.","Further investigation is necessary to improve the preservation of distributional characteristics and boost classifier performance."],"url":"http://arxiv.org/abs/2502.09566v1"}
{"created":"2025-02-13 18:19:20","title":"MDCrow: Automating Molecular Dynamics Workflows with Large Language Models","abstract":"Molecular dynamics (MD) simulations are essential for understanding biomolecular systems but remain challenging to automate. Recent advances in large language models (LLM) have demonstrated success in automating complex scientific tasks using LLM-based agents. In this paper, we introduce MDCrow, an agentic LLM assistant capable of automating MD workflows. MDCrow uses chain-of-thought over 40 expert-designed tools for handling and processing files, setting up simulations, analyzing the simulation outputs, and retrieving relevant information from literature and databases. We assess MDCrow's performance across 25 tasks of varying required subtasks and difficulty, and we evaluate the agent's robustness to both difficulty and prompt style. \\texttt{gpt-4o} is able to complete complex tasks with low variance, followed closely by \\texttt{llama3-405b}, a compelling open-source model. While prompt style does not influence the best models' performance, it has significant effects on smaller models.","sentences":["Molecular dynamics (MD) simulations are essential for understanding biomolecular systems but remain challenging to automate.","Recent advances in large language models (LLM) have demonstrated success in automating complex scientific tasks using LLM-based agents.","In this paper, we introduce MDCrow, an agentic LLM assistant capable of automating MD workflows.","MDCrow uses chain-of-thought over 40 expert-designed tools for handling and processing files, setting up simulations, analyzing the simulation outputs, and retrieving relevant information from literature and databases.","We assess MDCrow's performance across 25 tasks of varying required subtasks and difficulty, and we evaluate the agent's robustness to both difficulty and prompt style.","\\texttt{gpt-4o} is able to complete complex tasks with low variance, followed closely by \\texttt{llama3-405b}, a compelling open-source model.","While prompt style does not influence the best models' performance, it has significant effects on smaller models."],"url":"http://arxiv.org/abs/2502.09565v1"}
{"created":"2025-02-13 18:17:03","title":"Diffusing DeBias: a Recipe for Turning a Bug into a Feature","abstract":"Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data which, whenever containing strong spurious correlations between specific attributes and target labels, can result in unrecoverable biases in model predictions. Tackling these biases is crucial in improving model generalization and trust, especially in real-world scenarios. This paper presents Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods in model debiasing while exploiting the inherent bias-learning tendency of diffusion models. Our approach leverages conditional diffusion models to generate synthetic bias-aligned images, used to train a bias amplifier model, to be further employed as an auxiliary method in different unsupervised debiasing approaches. Our proposed method, which also tackles the common issue of training set memorization typical of this type of tech- niques, beats current state-of-the-art in multiple benchmark datasets by significant margins, demonstrating its potential as a versatile and effective tool for tackling dataset bias in deep learning applications.","sentences":["Deep learning model effectiveness in classification tasks is often challenged by the quality and quantity of training data which, whenever containing strong spurious correlations between specific attributes and target labels, can result in unrecoverable biases in model predictions.","Tackling these biases is crucial in improving model generalization and trust, especially in real-world scenarios.","This paper presents Diffusing DeBias (DDB), a novel approach acting as a plug-in for common methods in model debiasing while exploiting the inherent bias-learning tendency of diffusion models.","Our approach leverages conditional diffusion models to generate synthetic bias-aligned images, used to train a bias amplifier model, to be further employed as an auxiliary method in different unsupervised debiasing approaches.","Our proposed method, which also tackles the common issue of training set memorization typical of this type of tech- niques, beats current state-of-the-art in multiple benchmark datasets by significant margins, demonstrating its potential as a versatile and effective tool for tackling dataset bias in deep learning applications."],"url":"http://arxiv.org/abs/2502.09564v1"}
{"created":"2025-02-13 18:15:10","title":"Self-Calibrating Gaussian Splatting for Large Field of View Reconstruction","abstract":"In this paper, we present a self-calibrating framework that jointly optimizes camera parameters, lens distortion and 3D Gaussian representations, enabling accurate and efficient scene reconstruction. In particular, our technique enables high-quality scene reconstruction from Large field-of-view (FOV) imagery taken with wide-angle lenses, allowing the scene to be modeled from a smaller number of images. Our approach introduces a novel method for modeling complex lens distortions using a hybrid network that combines invertible residual networks with explicit grids. This design effectively regularizes the optimization process, achieving greater accuracy than conventional camera models. Additionally, we propose a cubemap-based resampling strategy to support large FOV images without sacrificing resolution or introducing distortion artifacts. Our method is compatible with the fast rasterization of Gaussian Splatting, adaptable to a wide variety of camera lens distortion, and demonstrates state-of-the-art performance on both synthetic and real-world datasets.","sentences":["In this paper, we present a self-calibrating framework that jointly optimizes camera parameters, lens distortion and 3D Gaussian representations, enabling accurate and efficient scene reconstruction.","In particular, our technique enables high-quality scene reconstruction from Large field-of-view (FOV) imagery taken with wide-angle lenses, allowing the scene to be modeled from a smaller number of images.","Our approach introduces a novel method for modeling complex lens distortions using a hybrid network that combines invertible residual networks with explicit grids.","This design effectively regularizes the optimization process, achieving greater accuracy than conventional camera models.","Additionally, we propose a cubemap-based resampling strategy to support large FOV images without sacrificing resolution or introducing distortion artifacts.","Our method is compatible with the fast rasterization of Gaussian Splatting, adaptable to a wide variety of camera lens distortion, and demonstrates state-of-the-art performance on both synthetic and real-world datasets."],"url":"http://arxiv.org/abs/2502.09563v1"}
{"created":"2025-02-13 18:11:34","title":"EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents","abstract":"Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. Through extensive experiments, we evaluated 13 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code is available at https://embodiedbench.github.io.","sentences":["Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks.","While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks.","To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents.","EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning.","Through extensive experiments, we evaluated 13 leading proprietary and open-source MLLMs within EmbodiedBench.","Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average.","EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents.","Our code is available at https://embodiedbench.github.io."],"url":"http://arxiv.org/abs/2502.09560v1"}
{"created":"2025-02-13 18:08:17","title":"Real-Time Fast Marching Tree for Mobile Robot Motion Planning in Dynamic Environments","abstract":"This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-time planning algorithm that features local and global path generation, multiple-query planning, and dynamic obstacle avoidance. During the search, RT-FMT quickly looks for the global solution and, in the meantime, generates local paths that can be used by the robot to start execution faster. In addition, our algorithm constantly rewires the tree to keep branches from forming inside the dynamic obstacles and to maintain the tree root near the robot, which allows the tree to be reused multiple times for different goals. Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-time Rapidly-Exploring Random Tree (RT-RRT*). We show via simulations that RT-FMT outperforms RT- RRT* in both execution cost and arrival time, in most cases. Moreover, we also demonstrate via simulation that it is worthwhile taking the local path before the global path is available in order to reduce arrival time, even though there is a small possibility of taking an inferior path.","sentences":["This paper proposes the Real-Time Fast Marching Tree (RT-FMT), a real-time planning algorithm that features local and global path generation, multiple-query planning, and dynamic obstacle avoidance.","During the search, RT-FMT quickly looks for the global solution and, in the meantime, generates local paths that can be used by the robot to start execution faster.","In addition, our algorithm constantly rewires the tree to keep branches from forming inside the dynamic obstacles and to maintain the tree root near the robot, which allows the tree to be reused multiple times for different goals.","Our algorithm is based on the planners Fast Marching Tree (FMT*) and Real-time Rapidly-Exploring Random Tree (RT-RRT*).","We show via simulations that RT-FMT outperforms RT- RRT* in both execution cost and arrival time, in most cases.","Moreover, we also demonstrate via simulation that it is worthwhile taking the local path before the global path is available in order to reduce arrival time, even though there is a small possibility of taking an inferior path."],"url":"http://arxiv.org/abs/2502.09556v1"}
{"created":"2025-02-13 18:05:12","title":"SyntheticPop: Attacking Speaker Verification Systems With Synthetic VoicePops","abstract":"Voice Authentication (VA), also known as Automatic Speaker Verification (ASV), is a widely adopted authentication method, particularly in automated systems like banking services, where it serves as a secondary layer of user authentication. Despite its popularity, VA systems are vulnerable to various attacks, including replay, impersonation, and the emerging threat of deepfake audio that mimics the voice of legitimate users. To mitigate these risks, several defense mechanisms have been proposed. One such solution, Voice Pops, aims to distinguish an individual's unique phoneme pronunciations during the enrollment process. While promising, the effectiveness of VA+VoicePop against a broader range of attacks, particularly logical or adversarial attacks, remains insufficiently explored. We propose a novel attack method, which we refer to as SyntheticPop, designed to target the phoneme recognition capabilities of the VA+VoicePop system. The SyntheticPop attack involves embedding synthetic \"pop\" noises into spoofed audio samples, significantly degrading the model's performance. We achieve an attack success rate of over 95% while poisoning 20% of the training dataset. Our experiments demonstrate that VA+VoicePop achieves 69% accuracy under normal conditions, 37% accuracy when subjected to a baseline label flipping attack, and just 14% accuracy under our proposed SyntheticPop attack, emphasizing the effectiveness of our method.","sentences":["Voice Authentication (VA), also known as Automatic Speaker Verification (ASV), is a widely adopted authentication method, particularly in automated systems like banking services, where it serves as a secondary layer of user authentication.","Despite its popularity, VA systems are vulnerable to various attacks, including replay, impersonation, and the emerging threat of deepfake audio that mimics the voice of legitimate users.","To mitigate these risks, several defense mechanisms have been proposed.","One such solution, Voice Pops, aims to distinguish an individual's unique phoneme pronunciations during the enrollment process.","While promising, the effectiveness of VA+VoicePop against a broader range of attacks, particularly logical or adversarial attacks, remains insufficiently explored.","We propose a novel attack method, which we refer to as SyntheticPop, designed to target the phoneme recognition capabilities of the VA+VoicePop system.","The SyntheticPop attack involves embedding synthetic \"pop\" noises into spoofed audio samples, significantly degrading the model's performance.","We achieve an attack success rate of over 95% while poisoning 20% of the training dataset.","Our experiments demonstrate that VA+VoicePop achieves 69% accuracy under normal conditions, 37% accuracy when subjected to a baseline label flipping attack, and just 14% accuracy under our proposed SyntheticPop attack, emphasizing the effectiveness of our method."],"url":"http://arxiv.org/abs/2502.09553v1"}
{"created":"2025-02-13 18:02:48","title":"Registration, Detection, and Deregistration: Analyzing DNS Abuse for Phishing Attacks","abstract":"Phishing continues to pose a significant cybersecurity threat. While blocklists currently serve as a primary defense, due to their reactive, passive nature, these delayed responses leave phishing websites operational long enough to harm potential victims. It is essential to address this fundamental challenge at the root, particularly in phishing domains. Domain registration presents a crucial intervention point, as domains serve as the primary gateway between users and websites. We conduct a comprehensive longitudinal analysis of 690,502 unique phishing domains, spanning a 39 month period, to examine their characteristics and behavioral patterns throughout their lifecycle-from initial registration to detection and eventual deregistration. We find that 66.1% of the domains in our dataset are maliciously registered, leveraging cost-effective TLDs and targeting brands by mimicking their domain names under alternative TLDs (e.g., .top and .tk) instead of the TLDs under which the brand domains are registered (e.g., .com and .ru). We also observe minimal improvements in detection speed for maliciously registered domains compared to compromised domains. Detection times vary widely across blocklists, and phishing domains remain accessible for an average of 11.5 days after detection, prolonging their potential impact. Our systematic investigation uncovers key patterns from registration through detection to deregistration, which could be leveraged to enhance anti-phishing active defenses at the DNS level.","sentences":["Phishing continues to pose a significant cybersecurity threat.","While blocklists currently serve as a primary defense, due to their reactive, passive nature, these delayed responses leave phishing websites operational long enough to harm potential victims.","It is essential to address this fundamental challenge at the root, particularly in phishing domains.","Domain registration presents a crucial intervention point, as domains serve as the primary gateway between users and websites.","We conduct a comprehensive longitudinal analysis of 690,502 unique phishing domains, spanning a 39 month period, to examine their characteristics and behavioral patterns throughout their lifecycle-from initial registration to detection and eventual deregistration.","We find that 66.1% of the domains in our dataset are maliciously registered, leveraging cost-effective TLDs and targeting brands by mimicking their domain names under alternative TLDs (e.g., .top and .tk) instead of the TLDs under which the brand domains are registered (e.g., .com","and .ru).","We also observe minimal improvements in detection speed for maliciously registered domains compared to compromised domains.","Detection times vary widely across blocklists, and phishing domains remain accessible for an average of 11.5 days after detection, prolonging their potential impact.","Our systematic investigation uncovers key patterns from registration through detection to deregistration, which could be leveraged to enhance anti-phishing active defenses at the DNS level."],"url":"http://arxiv.org/abs/2502.09549v1"}
{"created":"2025-02-13 17:57:05","title":"Vortex: Overcoming Memory Capacity Limitations in GPU-Accelerated Large-Scale Data Analytics","abstract":"Despite the high computational throughput of GPUs, limited memory capacity and bandwidth-limited CPU-GPU communication via PCIe links remain significant bottlenecks for accelerating large-scale data analytics workloads. This paper introduces Vortex, a GPU-accelerated framework designed for data analytics workloads that exceed GPU memory capacity. A key aspect of our framework is an optimized IO primitive that leverages all available PCIe links in multi-GPU systems for the IO demand of a single target GPU. It routes data through other GPUs to such target GPU that handles IO-intensive analytics tasks. This approach is advantageous when other GPUs are occupied with compute-bound workloads, such as popular AI applications that typically underutilize IO resources. We also introduce a novel programming model that separates GPU kernel development from IO scheduling, reducing programmer burden and enabling GPU code reuse. Additionally, we present the design of certain important query operators and discuss a late materialization technique based on GPU's zero-copy memory access. Without caching any data in GPU memory, Vortex improves the performance of the state-of-the-art GPU baseline, Proteus, by 5.7$\\times$ on average and enhances price performance by 2.5$\\times$ compared to a CPU-based DuckDB baseline.","sentences":["Despite the high computational throughput of GPUs, limited memory capacity and bandwidth-limited CPU-GPU communication via PCIe links remain significant bottlenecks for accelerating large-scale data analytics workloads.","This paper introduces Vortex, a GPU-accelerated framework designed for data analytics workloads that exceed GPU memory capacity.","A key aspect of our framework is an optimized IO primitive that leverages all available PCIe links in multi-GPU systems for the IO demand of a single target GPU.","It routes data through other GPUs to such target GPU that handles IO-intensive analytics tasks.","This approach is advantageous when other GPUs are occupied with compute-bound workloads, such as popular AI applications that typically underutilize IO resources.","We also introduce a novel programming model that separates GPU kernel development from IO scheduling, reducing programmer burden and enabling GPU code reuse.","Additionally, we present the design of certain important query operators and discuss a late materialization technique based on GPU's zero-copy memory access.","Without caching any data in GPU memory, Vortex improves the performance of the state-of-the-art GPU baseline, Proteus, by 5.7$\\times$ on average and enhances price performance by 2.5$\\times$ compared to a CPU-based DuckDB baseline."],"url":"http://arxiv.org/abs/2502.09541v1"}
{"created":"2025-02-13 17:50:58","title":"Entropy Collapse in Mobile Sensors: The Hidden Risks of Sensor-Based Security","abstract":"Mobile sensor data has been proposed for security-critical applications such as device pairing, proximity detection, and continuous authentication. However, the foundational assumption that these signals provide sufficient entropy remains under-explored. In this work, we systematically analyse the entropy of smartphone sensor data across four diverse datasets spanning multiple application contexts. Our findings reveal pervasive biases, with single-sensor mean min-entropy values ranging from 3.408-3.508 bits (S.D.=1.018-1.574), while conventional Shannon entropy is several multiples higher. We further demonstrate that correlations between sensor modalities reduce the worst-case entropy of using multiple sensors by up to approx. 75% compared to average-case Shannon entropy. This brings joint min-entropy well below 10 bits in many cases and, in the best case, yielding only approx. 24 bits of min-entropy when combining 20 sensor modalities. These results call into question the widely held assumption that adding more sensors inherently yields higher security. We ultimately caution against relying on raw sensor data as a primary source of randomness.","sentences":["Mobile sensor data has been proposed for security-critical applications such as device pairing, proximity detection, and continuous authentication.","However, the foundational assumption that these signals provide sufficient entropy remains under-explored.","In this work, we systematically analyse the entropy of smartphone sensor data across four diverse datasets spanning multiple application contexts.","Our findings reveal pervasive biases, with single-sensor mean min-entropy values ranging from 3.408-3.508 bits (S.D.=1.018-1.574), while conventional Shannon entropy is several multiples higher.","We further demonstrate that correlations between sensor modalities reduce the worst-case entropy of using multiple sensors by up to approx.","75% compared to average-case Shannon entropy.","This brings joint min-entropy well below 10 bits in many cases and, in the best case, yielding only approx.","24 bits of min-entropy when combining 20 sensor modalities.","These results call into question the widely held assumption that adding more sensors inherently yields higher security.","We ultimately caution against relying on raw sensor data as a primary source of randomness."],"url":"http://arxiv.org/abs/2502.09535v1"}
{"created":"2025-02-13 17:50:27","title":"Fast Tensor Completion via Approximate Richardson Iteration","abstract":"We study tensor completion (TC) through the lens of low-rank tensor decomposition (TD). Many TD algorithms use fast alternating minimization methods, which solve highly structured linear regression problems at each step (e.g., for CP, Tucker, and tensor-train decompositions). However, such algebraic structure is lost in TC regression problems, making direct extensions unclear. To address this, we propose a lifting approach that approximately solves TC regression problems using structured TD regression algorithms as blackbox subroutines, enabling sublinear-time methods. We theoretically analyze the convergence rate of our approximate Richardson iteration based algorithm, and we demonstrate on real-world tensors that its running time can be 100x faster than direct methods for CP completion.","sentences":["We study tensor completion (TC) through the lens of low-rank tensor decomposition (TD).","Many TD algorithms use fast alternating minimization methods, which solve highly structured linear regression problems at each step (e.g., for CP, Tucker, and tensor-train decompositions).","However, such algebraic structure is lost in TC regression problems, making direct extensions unclear.","To address this, we propose a lifting approach that approximately solves TC regression problems using structured TD regression algorithms as blackbox subroutines, enabling sublinear-time methods.","We theoretically analyze the convergence rate of our approximate Richardson iteration based algorithm, and we demonstrate on real-world tensors that its running time can be 100x faster than direct methods for CP completion."],"url":"http://arxiv.org/abs/2502.09534v1"}
{"created":"2025-02-13 17:50:23","title":"Long-Term TalkingFace Generation via Motion-Prior Conditional Diffusion Model","abstract":"Recent advances in conditional diffusion models have shown promise for generating realistic TalkingFace videos, yet challenges persist in achieving consistent head movement, synchronized facial expressions, and accurate lip synchronization over extended generations. To address these, we introduce the \\textbf{M}otion-priors \\textbf{C}onditional \\textbf{D}iffusion \\textbf{M}odel (\\textbf{MCDM}), which utilizes both archived and current clip motion priors to enhance motion prediction and ensure temporal consistency. The model consists of three key elements: (1) an archived-clip motion-prior that incorporates historical frames and a reference frame to preserve identity and context; (2) a present-clip motion-prior diffusion model that captures multimodal causality for accurate predictions of head movements, lip sync, and expressions; and (3) a memory-efficient temporal attention mechanism that mitigates error accumulation by dynamically storing and updating motion features. We also release the \\textbf{TalkingFace-Wild} dataset, a multilingual collection of over 200 hours of footage across 10 languages. Experimental results demonstrate the effectiveness of MCDM in maintaining identity and motion continuity for long-term TalkingFace generation. Code, models, and datasets will be publicly available.","sentences":["Recent advances in conditional diffusion models have shown promise for generating realistic TalkingFace videos, yet challenges persist in achieving consistent head movement, synchronized facial expressions, and accurate lip synchronization over extended generations.","To address these, we introduce the \\textbf{M}otion-priors \\textbf{C}onditional \\textbf{D}iffusion \\textbf{M}odel (\\textbf{MCDM}), which utilizes both archived and current clip motion priors to enhance motion prediction and ensure temporal consistency.","The model consists of three key elements: (1) an archived-clip motion-prior that incorporates historical frames and a reference frame to preserve identity and context; (2) a present-clip motion-prior diffusion model that captures multimodal causality for accurate predictions of head movements, lip sync, and expressions; and (3) a memory-efficient temporal attention mechanism that mitigates error accumulation by dynamically storing and updating motion features.","We also release the \\textbf{TalkingFace-Wild} dataset, a multilingual collection of over 200 hours of footage across 10 languages.","Experimental results demonstrate the effectiveness of MCDM in maintaining identity and motion continuity for long-term TalkingFace generation.","Code, models, and datasets will be publicly available."],"url":"http://arxiv.org/abs/2502.09533v1"}
{"created":"2025-02-13 17:49:30","title":"Mind the Gap! Choice Independence in Using Multilingual LLMs for Persuasive Co-Writing Tasks in Different Languages","abstract":"Recent advances in generative AI have precipitated a proliferation of novel writing assistants. These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages. However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages. Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality. Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence. In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI's performance in a second language. Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples' beliefs about LLM utilization in their donation choices. Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM. While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people's beliefs about the source of an advertisement (human versus AI) do. In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards. Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads. Our work has important implications for the design, development, integration, and adoption of multilingual LLMs as assistive agents -- particularly in writing tasks.","sentences":["Recent advances in generative AI have precipitated a proliferation of novel writing assistants.","These systems typically rely on multilingual large language models (LLMs), providing globalized workers the ability to revise or create diverse forms of content in different languages.","However, there is substantial evidence indicating that the performance of multilingual LLMs varies between languages.","Users who employ writing assistance for multiple languages are therefore susceptible to disparate output quality.","Importantly, recent research has shown that people tend to generalize algorithmic errors across independent tasks, violating the behavioral axiom of choice independence.","In this paper, we analyze whether user utilization of novel writing assistants in a charity advertisement writing task is affected by the AI's performance in a second language.","Furthermore, we quantify the extent to which these patterns translate into the persuasiveness of generated charity advertisements, as well as the role of peoples' beliefs about LLM utilization in their donation choices.","Our results provide evidence that writers who engage with an LLM-based writing assistant violate choice independence, as prior exposure to a Spanish LLM reduces subsequent utilization of an English LLM.","While these patterns do not affect the aggregate persuasiveness of the generated advertisements, people's beliefs about the source of an advertisement (human versus AI) do.","In particular, Spanish-speaking female participants who believed that they read an AI-generated advertisement strongly adjusted their donation behavior downwards.","Furthermore, people are generally not able to adequately differentiate between human-generated and LLM-generated ads.","Our work has important implications for the design, development, integration, and adoption of multilingual LLMs as assistive agents -- particularly in writing tasks."],"url":"http://arxiv.org/abs/2502.09532v1"}
{"created":"2025-02-13 17:39:28","title":"SteROI-D: System Design and Mapping for Stereo Depth Inference on Regions of Interest","abstract":"Machine learning algorithms have enabled high quality stereo depth estimation to run on Augmented and Virtual Reality (AR/VR) devices. However, high energy consumption across the full image processing stack prevents stereo depth algorithms from running effectively on battery-limited devices. This paper introduces SteROI-D, a full stereo depth system paired with a mapping methodology. SteROI-D exploits Region-of-Interest (ROI) and temporal sparsity at the system level to save energy. SteROI-D's flexible and heterogeneous compute fabric supports diverse ROIs. Importantly, we introduce a systematic mapping methodology to effectively handle dynamic ROIs, thereby maximizing energy savings. Using these techniques, our 28nm prototype SteROI-D design achieves up to 4.35x reduction in total system energy compared to a baseline ASIC.","sentences":["Machine learning algorithms have enabled high quality stereo depth estimation to run on Augmented and Virtual Reality (AR/VR) devices.","However, high energy consumption across the full image processing stack prevents stereo depth algorithms from running effectively on battery-limited devices.","This paper introduces SteROI-D, a full stereo depth system paired with a mapping methodology.","SteROI-D exploits Region-of-Interest (ROI) and temporal sparsity at the system level to save energy.","SteROI-D's flexible and heterogeneous compute fabric supports diverse ROIs.","Importantly, we introduce a systematic mapping methodology to effectively handle dynamic ROIs, thereby maximizing energy savings.","Using these techniques, our 28nm prototype SteROI-D design achieves up to 4.35x reduction in total system energy compared to a baseline ASIC."],"url":"http://arxiv.org/abs/2502.09528v1"}
{"created":"2025-02-13 17:37:42","title":"Robust Learning of Multi-index Models via Iterative Subspace Approximation","abstract":"We study the task of learning Multi-Index Models (MIMs) with label noise under the Gaussian distribution. A $K$-MIM is any function $f$ that only depends on a $K$-dimensional subspace. We focus on well-behaved MIMs with finite ranges that satisfy certain regularity properties. Our main contribution is a general robust learner that is qualitatively optimal in the Statistical Query (SQ) model. Our algorithm iteratively constructs better approximations to the defining subspace by computing low-degree moments conditional on the projection to the subspace computed thus far, and adding directions with relatively large empirical moments. This procedure efficiently finds a subspace $V$ so that $f(\\mathbf{x})$ is close to a function of the projection of $\\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional moments do not help, we prove an SQ lower bound suggesting that no efficient learner exists.   As applications, we provide faster robust learners for the following concept classes:   * {\\bf Multiclass Linear Classifiers} We give a constant-factor approximate agnostic learner with sample complexity $N = O(d) 2^{\\mathrm{poly}(K/\\epsilon)}$ and computational complexity $\\mathrm{poly}(N ,d)$. This is the first constant-factor agnostic learner for this class whose complexity is a fixed-degree polynomial in $d$.   * {\\bf Intersections of Halfspaces} We give an approximate agnostic learner for this class achieving 0-1 error $K \\tilde{O}(\\mathrm{OPT}) + \\epsilon$ with sample complexity $N=O(d^2) 2^{\\mathrm{poly}(K/\\epsilon)}$ and computational complexity $\\mathrm{poly}(N ,d)$. This is the first agnostic learner for this class with near-linear error dependence and complexity a fixed-degree polynomial in $d$.   Furthermore, we show that in the presence of random classification noise, the complexity of our algorithm scales polynomially with $1/\\epsilon$.","sentences":["We study the task of learning Multi-Index Models (MIMs) with label noise under the Gaussian distribution.","A $K$-MIM is any function $f$ that only depends on a $K$-dimensional subspace.","We focus on well-behaved MIMs with finite ranges that satisfy certain regularity properties.","Our main contribution is a general robust learner that is qualitatively optimal in the Statistical Query (SQ) model.","Our algorithm iteratively constructs better approximations to the defining subspace by computing low-degree moments conditional on the projection to the subspace computed thus far, and adding directions with relatively large empirical moments.","This procedure efficiently finds a subspace $V$ so that $f(\\mathbf{x})$ is close to a function of the projection of $\\mathbf{x}$ onto $V$. Conversely, for functions for which these conditional moments do not help, we prove an SQ lower bound suggesting that no efficient learner exists.   ","As applications, we provide faster robust learners for the following concept classes:   * {\\bf Multiclass Linear Classifiers} We give a constant-factor approximate agnostic learner with sample complexity $N = O(d) 2^{\\mathrm{poly}(K/\\epsilon)}$ and computational complexity $\\mathrm{poly}(N ,d)$.","This is the first constant-factor agnostic learner for this class whose complexity is a fixed-degree polynomial in $d$.   * {\\bf Intersections of Halfspaces} We give an approximate agnostic learner for this class achieving 0-1 error $K \\tilde{O}(\\mathrm{OPT})","+ \\epsilon$ with sample complexity $N=O(d^2) 2^{\\mathrm{poly}(K/\\epsilon)}$ and computational complexity $\\mathrm{poly}(N ,d)$.","This is the first agnostic learner for this class with near-linear error dependence and complexity a fixed-degree polynomial in $d$.   ","Furthermore, we show that in the presence of random classification noise, the complexity of our algorithm scales polynomially with $1/\\epsilon$."],"url":"http://arxiv.org/abs/2502.09525v1"}
{"created":"2025-02-13 17:36:12","title":"Forward-backward Contention Resolution Schemes for Fair Rationing","abstract":"We use contention resolution schemes (CRS) to derive algorithms for the fair rationing of a single resource when agents have stochastic demands. We aim to provide ex-ante guarantees on the level of service provided to each agent, who may measure service in different ways (Type-I, II, or III), calling for CRS under different feasibility constraints (rank-1 matroid or knapsack). We are particularly interested in two-order CRS where the agents are equally likely to arrive in a known forward order or its reverse, which is motivated by online rationing at food banks.   In particular, we derive a two-order CRS for rank-1 matroids with guarantee $1/(1+e^{-1/2})\\approx 0.622$, which we prove is tight. This improves upon the $1/2$ guarantee that is best-possible under a single order (Alaei, SIAM J. Comput. 2014), while achieving separation with the $1-1/e\\approx 0.632$ guarantee that is possible for random-order CRS (Lee and Singla, ESA 2018). Because CRS guarantees imply prophet inequalities, this also beats the two-order prophet inequality with ratio $(\\sqrt{5}-1)/2\\approx 0.618$ from (Arsenis, SODA 2021), which was tight for single-threshold policies. Rank-1 matroids suffice to provide guarantees under Type-II or III service, but Type-I service requires knapsack. Accordingly, we derive a two-order CRS for knapsack with guarantee $1/3$, improving upon the $1/(3+e^{-2})\\approx 0.319$ guarantee that is best-possible under a single order (Jiang et al., SODA 2022). To our knowledge, $1/3$ provides the best-known guarantee for knapsack CRS even in the offline setting. Finally, we provide an upper bound of $1/(2+e^{-1})\\approx 0.422$ for two-order knapsack CRS, strictly smaller than the upper bound of $(1-e^{-2})/2\\approx0.432$ for random-order knapsack CRS.","sentences":["We use contention resolution schemes (CRS) to derive algorithms for the fair rationing of a single resource when agents have stochastic demands.","We aim to provide ex-ante guarantees on the level of service provided to each agent, who may measure service in different ways (Type-I, II, or III), calling for CRS under different feasibility constraints (rank-1 matroid or knapsack).","We are particularly interested in two-order CRS where the agents are equally likely to arrive in a known forward order or its reverse, which is motivated by online rationing at food banks.   ","In particular, we derive a two-order CRS for rank-1 matroids with guarantee $1/(1+e^{-1/2})\\approx 0.622$, which we prove is tight.","This improves upon the $1/2$ guarantee that is best-possible under a single order (Alaei, SIAM J. Comput. 2014), while achieving separation with the $1-1/e\\approx 0.632$ guarantee that is possible for random-order CRS (Lee and Singla, ESA 2018).","Because CRS guarantees imply prophet inequalities, this also beats the two-order prophet inequality with ratio $(\\sqrt{5}-1)/2\\approx 0.618$ from (Arsenis, SODA 2021), which was tight for single-threshold policies.","Rank-1 matroids suffice to provide guarantees under Type-II or III service, but Type-I service requires knapsack.","Accordingly, we derive a two-order CRS for knapsack with guarantee $1/3$, improving upon the $1/(3+e^{-2})\\approx 0.319$ guarantee that is best-possible under a single order (Jiang et al., SODA 2022).","To our knowledge, $1/3$ provides the best-known guarantee for knapsack CRS even in the offline setting.","Finally, we provide an upper bound of $1/(2+e^{-1})\\approx 0.422$ for two-order knapsack CRS, strictly smaller than the upper bound of $(1-e^{-2})/2\\approx0.432$ for random-order knapsack CRS."],"url":"http://arxiv.org/abs/2502.09521v1"}
{"created":"2025-02-13 17:35:57","title":"SQ-GAN: Semantic Image Communications Using Masked Vector Quantization","abstract":"This work introduces Semantically Masked VQ-GAN (SQ-GAN), a novel approach integrating generative models to optimize image compression for semantic/task-oriented communications. SQ-GAN employs off-the-shelf semantic semantic segmentation and a new specifically developed semantic-conditioned adaptive mask module (SAMM) to selectively encode semantically significant features of the images. SQ-GAN outperforms state-of-the-art image compression schemes such as JPEG2000 and BPG across multiple metrics, including perceptual quality and semantic segmentation accuracy on the post-decoding reconstructed image, at extreme low compression rates expressed in bits per pixel.","sentences":["This work introduces Semantically Masked VQ-GAN (SQ-GAN), a novel approach integrating generative models to optimize image compression for semantic/task-oriented communications.","SQ-GAN employs off-the-shelf semantic semantic segmentation and a new specifically developed semantic-conditioned adaptive mask module (SAMM) to selectively encode semantically significant features of the images.","SQ-GAN outperforms state-of-the-art image compression schemes such as JPEG2000 and BPG across multiple metrics, including perceptual quality and semantic segmentation accuracy on the post-decoding reconstructed image, at extreme low compression rates expressed in bits per pixel."],"url":"http://arxiv.org/abs/2502.09520v1"}
{"created":"2025-02-13 17:22:50","title":"Diffusion Models for Molecules: A Survey of Methods and Tasks","abstract":"Generative tasks about molecules, including but not limited to molecule generation, are crucial for drug discovery and material design, and have consistently attracted significant attention. In recent years, diffusion models have emerged as an impressive class of deep generative models, sparking extensive research and leading to numerous studies on their application to molecular generative tasks. Despite the proliferation of related work, there remains a notable lack of up-to-date and systematic surveys in this area. Particularly, due to the diversity of diffusion model formulations, molecular data modalities, and generative task types, the research landscape is challenging to navigate, hindering understanding and limiting the area's growth. To address this, this paper conducts a comprehensive survey of diffusion model-based molecular generative methods. We systematically review the research from the perspectives of methodological formulations, data modalities, and task types, offering a novel taxonomy. This survey aims to facilitate understanding and further flourishing development in this area. The relevant papers are summarized at: https://github.com/AzureLeon1/awesome-molecular-diffusion-models.","sentences":["Generative tasks about molecules, including but not limited to molecule generation, are crucial for drug discovery and material design, and have consistently attracted significant attention.","In recent years, diffusion models have emerged as an impressive class of deep generative models, sparking extensive research and leading to numerous studies on their application to molecular generative tasks.","Despite the proliferation of related work, there remains a notable lack of up-to-date and systematic surveys in this area.","Particularly, due to the diversity of diffusion model formulations, molecular data modalities, and generative task types, the research landscape is challenging to navigate, hindering understanding and limiting the area's growth.","To address this, this paper conducts a comprehensive survey of diffusion model-based molecular generative methods.","We systematically review the research from the perspectives of methodological formulations, data modalities, and task types, offering a novel taxonomy.","This survey aims to facilitate understanding and further flourishing development in this area.","The relevant papers are summarized at: https://github.com/AzureLeon1/awesome-molecular-diffusion-models."],"url":"http://arxiv.org/abs/2502.09511v1"}
{"created":"2025-02-13 17:21:51","title":"EQ-VAE: Equivariance Regularized Latent Space for Improved Generative Image Modeling","abstract":"Latent generative models have emerged as a leading approach for high-quality image synthesis. These models rely on an autoencoder to compress images into a latent space, followed by a generative model to learn the latent distribution. We identify that existing autoencoders lack equivariance to semantic-preserving transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance. To address this, we propose EQ-VAE, a simple regularization approach that enforces equivariance in the latent space, reducing its complexity without degrading reconstruction quality. By finetuning pre-trained autoencoders with EQ-VAE, we enhance the performance of several state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT, achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning. EQ-VAE is compatible with both continuous and discrete autoencoders, thus offering a versatile enhancement for a wide range of latent generative models. Project page and code: https://eq-vae.github.io/.","sentences":["Latent generative models have emerged as a leading approach for high-quality image synthesis.","These models rely on an autoencoder to compress images into a latent space, followed by a generative model to learn the latent distribution.","We identify that existing autoencoders lack equivariance to semantic-preserving transformations like scaling and rotation, resulting in complex latent spaces that hinder generative performance.","To address this, we propose EQ-VAE, a simple regularization approach that enforces equivariance in the latent space, reducing its complexity without degrading reconstruction quality.","By finetuning pre-trained autoencoders with EQ-VAE, we enhance the performance of several state-of-the-art generative models, including DiT, SiT, REPA and MaskGIT, achieving a 7 speedup on DiT-XL/2 with only five epochs of SD-VAE fine-tuning.","EQ-VAE is compatible with both continuous and discrete autoencoders, thus offering a versatile enhancement for a wide range of latent generative models.","Project page and code: https://eq-vae.github.io/."],"url":"http://arxiv.org/abs/2502.09509v1"}
{"created":"2025-02-13 17:21:37","title":"When and How Does CLIP Enable Domain and Compositional Generalization?","abstract":"The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions. However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)? Can it generalize to unseen classes within partially seen domains (compositional generalization)? What factors affect such generalization? To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure. Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain. Through data-centric and mechanistic analyses, we find that successful generalization requires learning of shared representations already in intermediate layers and shared circuitry.","sentences":["The remarkable generalization performance of contrastive vision-language models like CLIP is often attributed to the diversity of their training distributions.","However, key questions remain unanswered: Can CLIP generalize to an entirely unseen domain when trained on a diverse mixture of domains (domain generalization)?","Can it generalize to unseen classes within partially seen domains (compositional generalization)?","What factors affect such generalization?","To answer these questions, we trained CLIP models on systematically constructed training distributions with controlled domain diversity and object class exposure.","Our experiments show that domain diversity is essential for both domain and compositional generalization, yet compositional generalization can be surprisingly weaker than domain generalization when the training distribution contains a suboptimal subset of the test domain.","Through data-centric and mechanistic analyses, we find that successful generalization requires learning of shared representations already in intermediate layers and shared circuitry."],"url":"http://arxiv.org/abs/2502.09507v1"}
{"created":"2025-02-13 17:15:26","title":"AttentionSmithy: A Modular Framework for Rapid Transformer Development and Customization","abstract":"Transformer architectures have transformed AI applications but remain complex to customize for domain experts lacking low-level implementation expertise. We introduce AttentionSmithy, a modular software package that simplifies transformer innovation by breaking down key components into reusable building blocks: attention modules, feed-forward networks, normalization layers, and positional encodings. Users can rapidly prototype and evaluate transformer variants without extensive coding. Our framework supports four positional encoding strategies and integrates with neural architecture search for automated design. We validate AttentionSmithy by replicating the original transformer under resource constraints and optimizing translation performance by combining positional encodings. Additionally, we demonstrate its adaptability in gene-specific modeling, achieving over 95% accuracy in cell type classification. These case studies highlight AttentionSmithy's potential to accelerate research across diverse fields by removing framework implementation barriers.","sentences":["Transformer architectures have transformed AI applications but remain complex to customize for domain experts lacking low-level implementation expertise.","We introduce AttentionSmithy, a modular software package that simplifies transformer innovation by breaking down key components into reusable building blocks: attention modules, feed-forward networks, normalization layers, and positional encodings.","Users can rapidly prototype and evaluate transformer variants without extensive coding.","Our framework supports four positional encoding strategies and integrates with neural architecture search for automated design.","We validate AttentionSmithy by replicating the original transformer under resource constraints and optimizing translation performance by combining positional encodings.","Additionally, we demonstrate its adaptability in gene-specific modeling, achieving over 95% accuracy in cell type classification.","These case studies highlight AttentionSmithy's potential to accelerate research across diverse fields by removing framework implementation barriers."],"url":"http://arxiv.org/abs/2502.09503v1"}
{"created":"2025-02-13 17:14:18","title":"Scalable First-order Method for Certifying Optimal k-Sparse GLMs","abstract":"This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\\ell_0$ cardinality constraint. While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems. To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework. Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program. Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity. Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems.","sentences":["This paper investigates the problem of certifying optimality for sparse generalized linear models (GLMs), where sparsity is enforced through an $\\ell_0$ cardinality constraint.","While branch-and-bound (BnB) frameworks can certify optimality by pruning nodes using dual bounds, existing methods for computing these bounds are either computationally intensive or exhibit slow convergence, limiting their scalability to large-scale problems.","To address this challenge, we propose a first-order proximal gradient algorithm designed to solve the perspective relaxation of the problem within a BnB framework.","Specifically, we formulate the relaxed problem as a composite optimization problem and demonstrate that the proximal operator of the non-smooth component can be computed exactly in log-linear time complexity, eliminating the need to solve a computationally expensive second-order cone program.","Furthermore, we introduce a simple restart strategy that enhances convergence speed while maintaining low per-iteration complexity.","Extensive experiments on synthetic and real-world datasets show that our approach significantly accelerates dual bound computations and is highly effective in providing optimality certificates for large-scale problems."],"url":"http://arxiv.org/abs/2502.09502v1"}
{"created":"2025-02-13 17:13:46","title":"Prior-Constrained Association Learning for Fine-Grained Generalized Category Discovery","abstract":"This paper addresses generalized category discovery (GCD), the task of clustering unlabeled data from potentially known or unknown categories with the help of labeled instances from each known category. Compared to traditional semi-supervised learning, GCD is more challenging because unlabeled data could be from novel categories not appearing in labeled data. Current state-of-the-art methods typically learn a parametric classifier assisted by self-distillation. While being effective, these methods do not make use of cross-instance similarity to discover class-specific semantics which are essential for representation learning and category discovery. In this paper, we revisit the association-based paradigm and propose a Prior-constrained Association Learning method to capture and learn the semantic relations within data. In particular, the labeled data from known categories provides a unique prior for the association of unlabeled data. Unlike previous methods that only adopts the prior as a pre or post-clustering refinement, we fully incorporate the prior into the association process, and let it constrain the association towards a reliable grouping outcome. The estimated semantic groups are utilized through non-parametric prototypical contrast to enhance the representation learning. A further combination of both parametric and non-parametric classification complements each other and leads to a model that outperforms existing methods by a significant margin. On multiple GCD benchmarks, we perform extensive experiments and validate the effectiveness of our proposed method.","sentences":["This paper addresses generalized category discovery (GCD), the task of clustering unlabeled data from potentially known or unknown categories with the help of labeled instances from each known category.","Compared to traditional semi-supervised learning, GCD is more challenging because unlabeled data could be from novel categories not appearing in labeled data.","Current state-of-the-art methods typically learn a parametric classifier assisted by self-distillation.","While being effective, these methods do not make use of cross-instance similarity to discover class-specific semantics which are essential for representation learning and category discovery.","In this paper, we revisit the association-based paradigm and propose a Prior-constrained Association Learning method to capture and learn the semantic relations within data.","In particular, the labeled data from known categories provides a unique prior for the association of unlabeled data.","Unlike previous methods that only adopts the prior as a pre or post-clustering refinement, we fully incorporate the prior into the association process, and let it constrain the association towards a reliable grouping outcome.","The estimated semantic groups are utilized through non-parametric prototypical contrast to enhance the representation learning.","A further combination of both parametric and non-parametric classification complements each other and leads to a model that outperforms existing methods by a significant margin.","On multiple GCD benchmarks, we perform extensive experiments and validate the effectiveness of our proposed method."],"url":"http://arxiv.org/abs/2502.09501v1"}
{"created":"2025-02-13 17:10:43","title":"Eidetic Learning: an Efficient and Provable Solution to Catastrophic Forgetting","abstract":"Catastrophic forgetting -- the phenomenon of a neural network learning a task t1 and losing the ability to perform it after being trained on some other task t2 -- is a long-standing problem for neural networks [McCloskey and Cohen, 1989]. We present a method, Eidetic Learning, that provably solves catastrophic forgetting. A network trained with Eidetic Learning -- here, an EideticNet -- requires no rehearsal or replay. We consider successive discrete tasks and show how at inference time an EideticNet automatically routes new instances without auxiliary task information. An EideticNet bears a family resemblance to the sparsely-gated Mixture-of-Experts layer Shazeer et al. [2016] in that network capacity is partitioned across tasks and the network itself performs data-conditional routing. An EideticNet is easy to implement and train, is efficient, and has time and space complexity linear in the number of parameters. The guarantee of our method holds for normalization layers of modern neural networks during both pre-training and fine-tuning. We show with a variety of network architectures and sets of tasks that EideticNets are immune to forgetting. While the practical benefits of EideticNets are substantial, we believe they can be benefit practitioners and theorists alike. The code for training EideticNets is available at \\href{https://github.com/amazon-science/eideticnet-training}{this https URL}.","sentences":["Catastrophic forgetting -- the phenomenon of a neural network learning a task t1 and losing the ability to perform it after being trained on some other task t2 -- is a long-standing problem for neural networks [McCloskey and Cohen, 1989].","We present a method, Eidetic Learning, that provably solves catastrophic forgetting.","A network trained with Eidetic Learning -- here, an EideticNet -- requires no rehearsal or replay.","We consider successive discrete tasks and show how at inference time an EideticNet automatically routes new instances without auxiliary task information.","An EideticNet bears a family resemblance to the sparsely-gated Mixture-of-Experts layer Shazeer et al.","[2016] in that network capacity is partitioned across tasks and the network itself performs data-conditional routing.","An EideticNet is easy to implement and train, is efficient, and has time and space complexity linear in the number of parameters.","The guarantee of our method holds for normalization layers of modern neural networks during both pre-training and fine-tuning.","We show with a variety of network architectures and sets of tasks that EideticNets are immune to forgetting.","While the practical benefits of EideticNets are substantial, we believe they can be benefit practitioners and theorists alike.","The code for training EideticNets is available at \\href{https://github.com/amazon-science/eideticnet-training}{this https URL}."],"url":"http://arxiv.org/abs/2502.09500v1"}
{"created":"2025-02-13 17:09:52","title":"Improve LLM-based Automatic Essay Scoring with Linguistic Features","abstract":"Automatic Essay Scoring (AES) assigns scores to student essays, reducing the grading workload for instructors. Developing a scoring system capable of handling essays across diverse prompts is challenging due to the flexibility and diverse nature of the writing task. Existing methods typically fall into two categories: supervised feature-based approaches and large language model (LLM)-based methods. Supervised feature-based approaches often achieve higher performance but require resource-intensive training. In contrast, LLM-based methods are computationally efficient during inference but tend to suffer from lower performance. This paper combines these approaches by incorporating linguistic features into LLM-based scoring. Experimental results show that this hybrid method outperforms baseline models for both in-domain and out-of-domain writing prompts.","sentences":["Automatic Essay Scoring (AES) assigns scores to student essays, reducing the grading workload for instructors.","Developing a scoring system capable of handling essays across diverse prompts is challenging due to the flexibility and diverse nature of the writing task.","Existing methods typically fall into two categories: supervised feature-based approaches and large language model (LLM)-based methods.","Supervised feature-based approaches often achieve higher performance but require resource-intensive training.","In contrast, LLM-based methods are computationally efficient during inference but tend to suffer from lower performance.","This paper combines these approaches by incorporating linguistic features into LLM-based scoring.","Experimental results show that this hybrid method outperforms baseline models for both in-domain and out-of-domain writing prompts."],"url":"http://arxiv.org/abs/2502.09497v1"}
{"created":"2025-02-13 17:03:03","title":"On Agnostic PAC Learning in the Small Error Regime","abstract":"Binary classification in the classic PAC model exhibits a curious phenomenon: Empirical Risk Minimization (ERM) learners are suboptimal in the realizable case yet optimal in the agnostic case. Roughly speaking, this owes itself to the fact that non-realizable distributions $\\mathcal{D}$ are simply more difficult to learn than realizable distributions -- even when one discounts a learner's error by $\\mathrm{err}(h^*_{\\mathcal{D}})$, the error of the best hypothesis in $\\mathcal{H}$ for $\\mathcal{D}$. Thus, optimal agnostic learners are permitted to incur excess error on (easier-to-learn) distributions $\\mathcal{D}$ for which $\\tau = \\mathrm{err}(h^*_{\\mathcal{D}})$ is small.   Recent work of Hanneke, Larsen, and Zhivotovskiy (FOCS `24) addresses this shortcoming by including $\\tau$ itself as a parameter in the agnostic error term. In this more fine-grained model, they demonstrate tightness of the error lower bound $\\tau + \\Omega \\left(\\sqrt{\\frac{\\tau (d + \\log(1 / \\delta))}{m}} + \\frac{d + \\log(1 / \\delta)}{m} \\right)$ in a regime where $\\tau > d/m$, and leave open the question of whether there may be a higher lower bound when $\\tau \\approx d/m$, with $d$ denoting $\\mathrm{VC}(\\mathcal{H})$. In this work, we resolve this question by exhibiting a learner which achieves error $c \\cdot \\tau + O \\left(\\sqrt{\\frac{\\tau (d + \\log(1 / \\delta))}{m}} + \\frac{d + \\log(1 / \\delta)}{m} \\right)$ for a constant $c \\leq 2.1$, thus matching the lower bound when $\\tau \\approx d/m$. Further, our learner is computationally efficient and is based upon careful aggregations of ERM classifiers, making progress on two other questions of Hanneke, Larsen, and Zhivotovskiy (FOCS `24). We leave open the interesting question of whether our approach can be refined to lower the constant from 2.1 to 1, which would completely settle the complexity of agnostic learning.","sentences":["Binary classification in the classic PAC model exhibits a curious phenomenon: Empirical Risk Minimization (ERM) learners are suboptimal in the realizable case yet optimal in the agnostic case.","Roughly speaking, this owes itself to the fact that non-realizable distributions $\\mathcal{D}$ are simply more difficult to learn than realizable distributions -- even when one discounts a learner's error by $\\mathrm{err}(h^*_{\\mathcal{D}})$, the error of the best hypothesis in $\\mathcal{H}$ for $\\mathcal{D}$. Thus, optimal agnostic learners are permitted to incur excess error on (easier-to-learn) distributions $\\mathcal{D}$ for which $\\tau = \\mathrm{err}(h^*_{\\mathcal{D}})$ is small.   ","Recent work of Hanneke, Larsen, and Zhivotovskiy (FOCS `24) addresses this shortcoming by including $\\tau$ itself as a parameter in the agnostic error term.","In this more fine-grained model, they demonstrate tightness of the error lower bound $\\tau + \\Omega \\left(\\sqrt{\\frac{\\tau (d + \\log(1 / \\delta))}{m}} + \\frac{d +","\\log(1 / \\delta)}{m} \\right)$ in a regime where $\\tau > d/m$, and leave open the question of whether there may be a higher lower bound when $\\tau \\approx d/m$, with $d$ denoting $\\mathrm{VC}(\\mathcal{H})$. In this work, we resolve this question by exhibiting a learner which achieves error $c \\cdot \\tau + O \\left(\\sqrt{\\frac{\\tau (d + \\log(1 / \\delta))}{m}} + \\frac{d + \\log(1 / \\delta)}{m} \\right)$ for a constant $c \\leq 2.1$, thus matching the lower bound when $\\tau \\approx d/m$. Further, our learner is computationally efficient and is based upon careful aggregations of ERM classifiers, making progress on two other questions of Hanneke, Larsen, and Zhivotovskiy (FOCS `24).","We leave open the interesting question of whether our approach can be refined to lower the constant from 2.1 to 1, which would completely settle the complexity of agnostic learning."],"url":"http://arxiv.org/abs/2502.09496v1"}
{"created":"2025-02-13 16:57:07","title":"Inverse Design with Dynamic Mode Decomposition","abstract":"We introduce a computationally efficient method for the automation of inverse design in science and engineering. Based on simple least-square regression, the underlying dynamic mode decomposition algorithm can be used to construct a low-rank subspace spanning multiple experiments in parameter space. The proposed inverse design dynamic mode composition (ID-DMD) algorithm leverages the computed low-dimensional subspace to enable fast digital design and optimization on laptop-level computing, including the potential to prescribe the dynamics themselves. Moreover, the method is robust to noise, physically interpretable, and can provide uncertainty quantification metrics. The architecture can also efficiently scale to large-scale design problems using randomized algorithms in the ID-DMD. The simplicity of the method and its implementation are highly attractive in practice, and the ID-DMD has been demonstrated to be an order of magnitude more accurate than competing methods while simultaneously being 3-5 orders faster on challenging engineering design problems ranging from structural vibrations to fluid dynamics. Due to its speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with other leading machine learning methods represents a significant advancement in data-driven methods for inverse design and optimization, promising a paradigm shift in how to approach inverse design in practice.","sentences":["We introduce a computationally efficient method for the automation of inverse design in science and engineering.","Based on simple least-square regression, the underlying dynamic mode decomposition algorithm can be used to construct a low-rank subspace spanning multiple experiments in parameter space.","The proposed inverse design dynamic mode composition (ID-DMD) algorithm leverages the computed low-dimensional subspace to enable fast digital design and optimization on laptop-level computing, including the potential to prescribe the dynamics themselves.","Moreover, the method is robust to noise, physically interpretable, and can provide uncertainty quantification metrics.","The architecture can also efficiently scale to large-scale design problems using randomized algorithms in the ID-DMD.","The simplicity of the method and its implementation are highly attractive in practice, and the ID-DMD has been demonstrated to be an order of magnitude more accurate than competing methods while simultaneously being 3-5 orders faster on challenging engineering design problems ranging from structural vibrations to fluid dynamics.","Due to its speed, robustness, interpretability, and ease-of-use, ID-DMD in comparison with other leading machine learning methods represents a significant advancement in data-driven methods for inverse design and optimization, promising a paradigm shift in how to approach inverse design in practice."],"url":"http://arxiv.org/abs/2502.09490v1"}
{"created":"2025-02-13 16:52:06","title":"Objective quantification of mood states using large language models","abstract":"Emotional states influence human behaviour and cognition, leading to diverse thought trajectories. Similarly, Large Language Models (LLMs) showcase an excellent level of response consistency across wide-ranging contexts (prompts). We leverage these parallels to establish a framework for quantifying mental states. Our approach utilises self-report questionnaires that reliably assess these states due to their inherent sensitivity to patterns of co-occurring responses. Specifically, we recruited a large sample of participants (N=422) to investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set of depressive mood states measured with participants' open-ended responses to a depression questionnaire. We show LLM responses to held-out multiple-choice questions, given participants' open-ended answers, correlate strongly (r: 0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation from mood representations. We explore a link between these representations and factor analysis. Using ridge regression, we find depression-related subspaces within LLM hidden states. We show these subspaces to be predictive of participants' \"Depression\" and \"Somatic & Emotional Distress\" factor scores, as well as suicidality severity. Overall, LLMs can provide quantitative measures of mental states. The reliability of these hinges upon how informative the questions we ask participants are. Used correctly, this approach could supplement mental state assessment in a variety of settings.","sentences":["Emotional states influence human behaviour and cognition, leading to diverse thought trajectories.","Similarly, Large Language Models (LLMs) showcase an excellent level of response consistency across wide-ranging contexts (prompts).","We leverage these parallels to establish a framework for quantifying mental states.","Our approach utilises self-report questionnaires that reliably assess these states due to their inherent sensitivity to patterns of co-occurring responses.","Specifically, we recruited a large sample of participants (N=422) to investigate how well an LLM (Mistral-7B-OpenOrca) quantifies a heterogenous set of depressive mood states measured with participants' open-ended responses to a depression questionnaire.","We show LLM responses to held-out multiple-choice questions, given participants' open-ended answers, correlate strongly (r: 0.52-0.84) with true questionnaire scores, demonstrating LLM's generalisation from mood representations.","We explore a link between these representations and factor analysis.","Using ridge regression, we find depression-related subspaces within LLM hidden states.","We show these subspaces to be predictive of participants' \"Depression\" and \"Somatic & Emotional Distress\" factor scores, as well as suicidality severity.","Overall, LLMs can provide quantitative measures of mental states.","The reliability of these hinges upon how informative the questions we ask participants are.","Used correctly, this approach could supplement mental state assessment in a variety of settings."],"url":"http://arxiv.org/abs/2502.09487v1"}
{"created":"2025-02-13 16:46:23","title":"PenTest++: Elevating Ethical Hacking with AI and Automation","abstract":"Traditional ethical hacking relies on skilled professionals and time-intensive command management, which limits its scalability and efficiency. To address these challenges, we introduce PenTest++, an AI-augmented system that integrates automation with generative AI (GenAI) to optimise ethical hacking workflows. Developed in a controlled virtual environment, PenTest++ streamlines critical penetration testing tasks, including reconnaissance, scanning, enumeration, exploitation, and documentation, while maintaining a modular and adaptable design. The system balances automation with human oversight, ensuring informed decision-making at key stages, and offers significant benefits such as enhanced efficiency, scalability, and adaptability. However, it also raises ethical considerations, including privacy concerns and the risks of AI-generated inaccuracies (hallucinations). This research underscores the potential of AI-driven systems like PenTest++ to complement human expertise in cybersecurity by automating routine tasks, enabling professionals to focus on strategic decision-making. By incorporating robust ethical safeguards and promoting ongoing refinement, PenTest++ demonstrates how AI can be responsibly harnessed to address operational and ethical challenges in the evolving cybersecurity landscape.","sentences":["Traditional ethical hacking relies on skilled professionals and time-intensive command management, which limits its scalability and efficiency.","To address these challenges, we introduce PenTest++, an AI-augmented system that integrates automation with generative AI (GenAI) to optimise ethical hacking workflows.","Developed in a controlled virtual environment, PenTest++ streamlines critical penetration testing tasks, including reconnaissance, scanning, enumeration, exploitation, and documentation, while maintaining a modular and adaptable design.","The system balances automation with human oversight, ensuring informed decision-making at key stages, and offers significant benefits such as enhanced efficiency, scalability, and adaptability.","However, it also raises ethical considerations, including privacy concerns and the risks of AI-generated inaccuracies (hallucinations).","This research underscores the potential of AI-driven systems like PenTest++ to complement human expertise in cybersecurity by automating routine tasks, enabling professionals to focus on strategic decision-making.","By incorporating robust ethical safeguards and promoting ongoing refinement, PenTest++ demonstrates how AI can be responsibly harnessed to address operational and ethical challenges in the evolving cybersecurity landscape."],"url":"http://arxiv.org/abs/2502.09484v1"}
{"created":"2025-02-13 16:45:39","title":"Standardisation of Convex Ultrasound Data Through Geometric Analysis and Augmentation","abstract":"The application of ultrasound in healthcare has seen increased diversity and importance. Unlike other medical imaging modalities, ultrasound research and development has historically lagged, particularly in the case of applications with data-driven algorithms. A significant issue with ultrasound is the extreme variability of the images, due to the number of different machines available and the possible combination of parameter settings. One outcome of this is the lack of standardised and benchmarking ultrasound datasets. The method proposed in this article is an approach to alleviating this issue of disorganisation. For this purpose, the issue of ultrasound data sparsity is examined and a novel perspective, approach, and solution is proposed; involving the extraction of the underlying ultrasound plane within the image and representing it using annulus sector geometry. An application of this methodology is proposed, which is the extraction of scan lines and the linearisation of convex planes. Validation of the robustness of the proposed method is performed on both private and public data. The impact of deformation and the invertibility of augmentation using the estimated annulus sector parameters is also studied. Keywords: Ultrasound, Annulus Sector, Augmentation, Linearisation.","sentences":["The application of ultrasound in healthcare has seen increased diversity and importance.","Unlike other medical imaging modalities, ultrasound research and development has historically lagged, particularly in the case of applications with data-driven algorithms.","A significant issue with ultrasound is the extreme variability of the images, due to the number of different machines available and the possible combination of parameter settings.","One outcome of this is the lack of standardised and benchmarking ultrasound datasets.","The method proposed in this article is an approach to alleviating this issue of disorganisation.","For this purpose, the issue of ultrasound data sparsity is examined and a novel perspective, approach, and solution is proposed; involving the extraction of the underlying ultrasound plane within the image and representing it using annulus sector geometry.","An application of this methodology is proposed, which is the extraction of scan lines and the linearisation of convex planes.","Validation of the robustness of the proposed method is performed on both private and public data.","The impact of deformation and the invertibility of augmentation using the estimated annulus sector parameters is also studied.","Keywords: Ultrasound, Annulus Sector, Augmentation, Linearisation."],"url":"http://arxiv.org/abs/2502.09482v1"}
{"created":"2025-02-13 16:36:25","title":"Learning to Predict Global Atrial Fibrillation Dynamics from Sparse Measurements","abstract":"Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all treatment with limited success in persistent AF. This may be due to our inability to map the dynamics of AF with the limited resolution and coverage provided by sequential contact mapping catheters, preventing effective patient phenotyping for personalised, targeted ablation. Here we introduce FibMap, a graph recurrent neural network model that reconstructs global AF dynamics from sparse measurements. Trained and validated on 51 non-contact whole atria recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage, achieving a 210% lower mean absolute error and an order of magnitude higher performance in tracking phase singularities compared to baseline methods. Clinical utility of FibMap is demonstrated on real-world contact mapping recordings, achieving reconstruction fidelity comparable to non-contact mapping. FibMap's state-spaces and patient-specific parameters offer insights for electrophenotyping AF. Integrating FibMap into clinical practice could enable personalised AF care and improve outcomes.","sentences":["Catheter ablation of Atrial Fibrillation (AF) consists of a one-size-fits-all treatment with limited success in persistent AF.","This may be due to our inability to map the dynamics of AF with the limited resolution and coverage provided by sequential contact mapping catheters, preventing effective patient phenotyping for personalised, targeted ablation.","Here we introduce FibMap, a graph recurrent neural network model that reconstructs global AF dynamics from sparse measurements.","Trained and validated on 51 non-contact whole atria recordings, FibMap reconstructs whole atria dynamics from 10% surface coverage, achieving a 210% lower mean absolute error and an order of magnitude higher performance in tracking phase singularities compared to baseline methods.","Clinical utility of FibMap is demonstrated on real-world contact mapping recordings, achieving reconstruction fidelity comparable to non-contact mapping.","FibMap's state-spaces and patient-specific parameters offer insights for electrophenotyping AF.","Integrating FibMap into clinical practice could enable personalised AF care and improve outcomes."],"url":"http://arxiv.org/abs/2502.09473v1"}
{"created":"2025-02-13 16:34:59","title":"Wholly-WOOD: Wholly Leveraging Diversified-quality Labels for Weakly-supervised Oriented Object Detection","abstract":"Accurately estimating the orientation of visual objects with compact rotated bounding boxes (RBoxes) has become a prominent demand, which challenges existing object detection paradigms that only use horizontal bounding boxes (HBoxes). To equip the detectors with orientation awareness, supervised regression/classification modules have been introduced at the high cost of rotation annotation. Meanwhile, some existing datasets with oriented objects are already annotated with horizontal boxes or even single points. It becomes attractive yet remains open for effectively utilizing weaker single point and horizontal annotations to train an oriented object detector (OOD). We develop Wholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging various labeling forms (Points, HBoxes, RBoxes, and their combination) in a unified fashion. By only using HBox for training, our Wholly-WOOD achieves performance very close to that of the RBox-trained counterpart on remote sensing and other areas, significantly reducing the tedious efforts on labor-intensive annotation for oriented objects. The source codes are available at https://github.com/VisionXLab/whollywood (PyTorch-based) and https://github.com/VisionXLab/whollywood-jittor (Jittor-based).","sentences":["Accurately estimating the orientation of visual objects with compact rotated bounding boxes (RBoxes) has become a prominent demand, which challenges existing object detection paradigms that only use horizontal bounding boxes (HBoxes).","To equip the detectors with orientation awareness, supervised regression/classification modules have been introduced at the high cost of rotation annotation.","Meanwhile, some existing datasets with oriented objects are already annotated with horizontal boxes or even single points.","It becomes attractive yet remains open for effectively utilizing weaker single point and horizontal annotations to train an oriented object detector (OOD).","We develop Wholly-WOOD, a weakly-supervised OOD framework, capable of wholly leveraging various labeling forms (Points, HBoxes, RBoxes, and their combination) in a unified fashion.","By only using HBox for training, our Wholly-WOOD achieves performance very close to that of the RBox-trained counterpart on remote sensing and other areas, significantly reducing the tedious efforts on labor-intensive annotation for oriented objects.","The source codes are available at https://github.com/VisionXLab/whollywood (PyTorch-based) and https://github.com/VisionXLab/whollywood-jittor (Jittor-based)."],"url":"http://arxiv.org/abs/2502.09471v1"}
{"created":"2025-02-13 16:27:23","title":"Metamorphic Testing for Pose Estimation Systems","abstract":"Pose estimation systems are used in a variety of fields, from sports analytics to livestock care. Given their potential impact, it is paramount to systematically test their behaviour and potential for failure. This is a complex task due to the oracle problem and the high cost of manual labelling necessary to build ground truth keypoints. This problem is exacerbated by the fact that different applications require systems to focus on different subjects (e.g., human versus animal) or landmarks (e.g., only extremities versus whole body and face), which makes labelled test data rarely reusable. To combat these problems we propose MET-POSE, a metamorphic testing framework for pose estimation systems that bypasses the need for manual annotation while assessing the performance of these systems under different circumstances. MET-POSE thus allows users of pose estimation systems to assess the systems in conditions that more closely relate to their application without having to label an ad-hoc test dataset or rely only on available datasets, which may not be adapted to their application domain. While we define MET-POSE in general terms, we also present a non-exhaustive list of metamorphic rules that represent common challenges in computer vision applications, as well as a specific way to evaluate these rules. We then experimentally show the effectiveness of MET-POSE by applying it to Mediapipe Holistic, a state of the art human pose estimation system, with the FLIC and PHOENIX datasets. With these experiments, we outline numerous ways in which the outputs of MET-POSE can uncover faults in pose estimation systems at a similar or higher rate than classic testing using hand labelled data, and show that users can tailor the rule set they use to the faults and level of accuracy relevant to their application.","sentences":["Pose estimation systems are used in a variety of fields, from sports analytics to livestock care.","Given their potential impact, it is paramount to systematically test their behaviour and potential for failure.","This is a complex task due to the oracle problem and the high cost of manual labelling necessary to build ground truth keypoints.","This problem is exacerbated by the fact that different applications require systems to focus on different subjects (e.g., human versus animal) or landmarks (e.g., only extremities versus whole body and face), which makes labelled test data rarely reusable.","To combat these problems we propose MET-POSE, a metamorphic testing framework for pose estimation systems that bypasses the need for manual annotation while assessing the performance of these systems under different circumstances.","MET-POSE thus allows users of pose estimation systems to assess the systems in conditions that more closely relate to their application without having to label an ad-hoc test dataset or rely only on available datasets, which may not be adapted to their application domain.","While we define MET-POSE in general terms, we also present a non-exhaustive list of metamorphic rules that represent common challenges in computer vision applications, as well as a specific way to evaluate these rules.","We then experimentally show the effectiveness of MET-POSE by applying it to Mediapipe Holistic, a state of the art human pose estimation system, with the FLIC and PHOENIX datasets.","With these experiments, we outline numerous ways in which the outputs of MET-POSE can uncover faults in pose estimation systems at a similar or higher rate than classic testing using hand labelled data, and show that users can tailor the rule set they use to the faults and level of accuracy relevant to their application."],"url":"http://arxiv.org/abs/2502.09460v1"}
{"created":"2025-02-13 16:27:03","title":"Balancing physical modeling and musical requirements: Algorithmically simulating the calls of Hyalessa maculaticollis for real-time instrumental control","abstract":"This paper presents an algorithm that simulates the calls of the Hyalessa maculaticollis cicada for musical use. Written in SuperCollider, its input parameters enable real-time control of the insect call phase, loudness, and perceived musical pitch. To this end, the anatomical mechanics of the tymbal muscles, tymbal apodeme, tymbal ribs, tymbal plate, abdominal air sac, tympana, and opercula are physically modeled. This also includes decoherence, following the hypothesis that it, in H. maculaticollis, might explain the change in timbre apparent during the final phase of a call sequence.   Overall, the algorithm seems to illustrate three main points regarding the trade-offs encountered when modeling bioacoustics for tonal use: that it may be necessary to prioritize musical requirements over realistic physical modeling at many stages of design and implementation; that the resulting adjustments may revolve around having physical modeling perceptually yield sonic events that are well-pitched, single-attack, single-source, and timbrally expressive; that the pitch-adjusted simulation of resonating bodies may fail musically precisely when it succeeds physically, by inducing the perception of different sound sources for different pitches. Audio examples are included, and the source code is structured and documented so as to support the further development of cicada bioacoustics for musical use.","sentences":["This paper presents an algorithm that simulates the calls of the Hyalessa maculaticollis cicada for musical use.","Written in SuperCollider, its input parameters enable real-time control of the insect call phase, loudness, and perceived musical pitch.","To this end, the anatomical mechanics of the tymbal muscles, tymbal apodeme, tymbal ribs, tymbal plate, abdominal air sac, tympana, and opercula are physically modeled.","This also includes decoherence, following the hypothesis that it, in H. maculaticollis, might explain the change in timbre apparent during the final phase of a call sequence.   ","Overall, the algorithm seems to illustrate three main points regarding the trade-offs encountered when modeling bioacoustics for tonal use: that it may be necessary to prioritize musical requirements over realistic physical modeling at many stages of design and implementation; that the resulting adjustments may revolve around having physical modeling perceptually yield sonic events that are well-pitched, single-attack, single-source, and timbrally expressive; that the pitch-adjusted simulation of resonating bodies may fail musically precisely when it succeeds physically, by inducing the perception of different sound sources for different pitches.","Audio examples are included, and the source code is structured and documented so as to support the further development of cicada bioacoustics for musical use."],"url":"http://arxiv.org/abs/2502.09459v1"}
{"created":"2025-02-13 16:25:16","title":"The Multilingual Mind : A Survey of Multilingual Reasoning in Language Models","abstract":"While reasoning and multilingual capabilities in Language Models (LMs) have achieved remarkable progress in recent years, their integration into a unified paradigm, multilingual reasoning, is at a nascent stage. Multilingual reasoning requires language models to handle logical reasoning across languages while addressing misalignment, biases, and challenges in low-resource settings. This survey provides the first in-depth review of multilingual reasoning in LMs. In this survey, we provide a systematic overview of existing methods that leverage LMs for multilingual reasoning, specifically outlining the challenges, motivations, and foundational aspects of applying language models to reason across diverse languages. We provide an overview of the standard data resources used for training multilingual reasoning in LMs and the evaluation benchmarks employed to assess their multilingual capabilities. Next, we analyze various state-of-the-art methods and their performance on these benchmarks. Finally, we explore future research opportunities to improve multilingual reasoning in LMs, focusing on enhancing their ability to handle diverse languages and complex reasoning tasks.","sentences":["While reasoning and multilingual capabilities in Language Models (LMs) have achieved remarkable progress in recent years, their integration into a unified paradigm, multilingual reasoning, is at a nascent stage.","Multilingual reasoning requires language models to handle logical reasoning across languages while addressing misalignment, biases, and challenges in low-resource settings.","This survey provides the first in-depth review of multilingual reasoning in LMs.","In this survey, we provide a systematic overview of existing methods that leverage LMs for multilingual reasoning, specifically outlining the challenges, motivations, and foundational aspects of applying language models to reason across diverse languages.","We provide an overview of the standard data resources used for training multilingual reasoning in LMs and the evaluation benchmarks employed to assess their multilingual capabilities.","Next, we analyze various state-of-the-art methods and their performance on these benchmarks.","Finally, we explore future research opportunities to improve multilingual reasoning in LMs, focusing on enhancing their ability to handle diverse languages and complex reasoning tasks."],"url":"http://arxiv.org/abs/2502.09457v1"}
{"created":"2025-02-13 16:19:58","title":"RTD-Conjecture and Concept Classes Induced by Graphs","abstract":"It is conjectured that the recursive teaching dimension of any finite concept class is upper-bounded by the VC-dimension of this class times a universal constant. In this paper, we confirm this conjecture for two rich families of concept classes where each class is induced by some graph $G$. For each $G$, we consider the class whose concepts represent stars in $G$ as well as the class whose concepts represent connected sets in $G$. We show that, for concept classes of this kind, the recursive teaching dimension either equals the VC-dimension or is less by $1$.","sentences":["It is conjectured that the recursive teaching dimension of any finite concept class is upper-bounded by the VC-dimension of this class times a universal constant.","In this paper, we confirm this conjecture for two rich families of concept classes where each class is induced by some graph $G$.","For each $G$, we consider the class whose concepts represent stars in $G$ as well as the class whose concepts represent connected sets in $G$. We show that, for concept classes of this kind, the recursive teaching dimension either equals the VC-dimension or is less by $1$."],"url":"http://arxiv.org/abs/2502.09453v1"}
{"created":"2025-02-13 16:17:57","title":"Spiking Neural Networks for Temporal Processing: Status Quo and Future Prospects","abstract":"Temporal processing is fundamental for both biological and artificial intelligence systems, as it enables the comprehension of dynamic environments and facilitates timely responses. Spiking Neural Networks (SNNs) excel in handling such data with high efficiency, owing to their rich neuronal dynamics and sparse activity patterns. Given the recent surge in the development of SNNs, there is an urgent need for a comprehensive evaluation of their temporal processing capabilities. In this paper, we first conduct an in-depth assessment of commonly used neuromorphic benchmarks, revealing critical limitations in their ability to evaluate the temporal processing capabilities of SNNs. To bridge this gap, we further introduce a benchmark suite consisting of three temporal processing tasks characterized by rich temporal dynamics across multiple timescales. Utilizing this benchmark suite, we perform a thorough evaluation of recently introduced SNN approaches to elucidate the current status of SNNs in temporal processing. Our findings indicate significant advancements in recently developed spiking neuron models and neural architectures regarding their temporal processing capabilities, while also highlighting a performance gap in handling long-range dependencies when compared to state-of-the-art non-spiking models. Finally, we discuss the key challenges and outline potential avenues for future research.","sentences":["Temporal processing is fundamental for both biological and artificial intelligence systems, as it enables the comprehension of dynamic environments and facilitates timely responses.","Spiking Neural Networks (SNNs) excel in handling such data with high efficiency, owing to their rich neuronal dynamics and sparse activity patterns.","Given the recent surge in the development of SNNs, there is an urgent need for a comprehensive evaluation of their temporal processing capabilities.","In this paper, we first conduct an in-depth assessment of commonly used neuromorphic benchmarks, revealing critical limitations in their ability to evaluate the temporal processing capabilities of SNNs.","To bridge this gap, we further introduce a benchmark suite consisting of three temporal processing tasks characterized by rich temporal dynamics across multiple timescales.","Utilizing this benchmark suite, we perform a thorough evaluation of recently introduced SNN approaches to elucidate the current status of SNNs in temporal processing.","Our findings indicate significant advancements in recently developed spiking neuron models and neural architectures regarding their temporal processing capabilities, while also highlighting a performance gap in handling long-range dependencies when compared to state-of-the-art non-spiking models.","Finally, we discuss the key challenges and outline potential avenues for future research."],"url":"http://arxiv.org/abs/2502.09449v1"}
{"created":"2025-02-13 16:16:54","title":"Pixel-Level Reasoning Segmentation via Multi-turn Conversations","abstract":"Existing visual perception systems focus on region-level segmentation in single-turn dialogues, relying on complex and explicit query instructions. Such systems cannot reason at the pixel level and comprehend dynamic user intent that changes over interaction. Our work tackles this issue by introducing a novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on multi-turn conversations, tracking evolving user intent via multi-turn interactions for fine-grained segmentation. To establish a benchmark for this novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k multi-turn conversational scenarios with segmentation targets. Building on PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning Segmentation framework, integrates pixel-level segmentation with robust multi-turn conversation understanding, generating pixel-grounded explanations aligned with user intent. The PRIST dataset and MIRSA framework fill the gap in pixel-level reasoning segmentation. Experimental results on the PRIST dataset demonstrate that our method outperforms current segmentation-specific baselines in terms of segmentation and LLM-based reasoning metrics. The code and data are available at: https://github.com/ccccai239/PixelRIST.","sentences":["Existing visual perception systems focus on region-level segmentation in single-turn dialogues, relying on complex and explicit query instructions.","Such systems cannot reason at the pixel level and comprehend dynamic user intent that changes over interaction.","Our work tackles this issue by introducing a novel task, Pixel-level Reasoning Segmentation (Pixel-level RS) based on multi-turn conversations, tracking evolving user intent via multi-turn interactions for fine-grained segmentation.","To establish a benchmark for this novel task, we build a Pixel-level ReasonIng Segmentation Dataset Based on Multi-Turn Conversations (PRIST), comprising 24k utterances from 8.3k multi-turn conversational scenarios with segmentation targets.","Building on PRIST, we further propose MIRAS, a Multi-turn Interactive ReAsoning Segmentation framework, integrates pixel-level segmentation with robust multi-turn conversation understanding, generating pixel-grounded explanations aligned with user intent.","The PRIST dataset and MIRSA framework fill the gap in pixel-level reasoning segmentation.","Experimental results on the PRIST dataset demonstrate that our method outperforms current segmentation-specific baselines in terms of segmentation and LLM-based reasoning metrics.","The code and data are available at: https://github.com/ccccai239/PixelRIST."],"url":"http://arxiv.org/abs/2502.09447v1"}
{"created":"2025-02-13 16:12:17","title":"Relational Conformal Prediction for Correlated Time Series","abstract":"We address the problem of uncertainty quantification in time series forecasting by exploiting observations at correlated sequences. Relational deep learning methods leveraging graph representations are among the most effective tools for obtaining point estimates from spatiotemporal data and correlated time series. However, the problem of exploiting relational structures to estimate the uncertainty of such predictions has been largely overlooked in the same context. To this end, we propose a novel distribution-free approach based on the conformal prediction framework and quantile regression. Despite the recent applications of conformal prediction to sequential data, existing methods operate independently on each target time series and do not account for relationships among them when constructing the prediction interval. We fill this void by introducing a novel conformal prediction method based on graph deep learning operators. Our method, named Conformal Relational Prediction (CoRel), does not require the relational structure (graph) to be known as a prior and can be applied on top of any pre-trained time series predictor. Additionally, CoRel includes an adaptive component to handle non-exchangeable data and changes in the input time series. Our approach provides accurate coverage and archives state-of-the-art uncertainty quantification in relevant benchmarks.","sentences":["We address the problem of uncertainty quantification in time series forecasting by exploiting observations at correlated sequences.","Relational deep learning methods leveraging graph representations are among the most effective tools for obtaining point estimates from spatiotemporal data and correlated time series.","However, the problem of exploiting relational structures to estimate the uncertainty of such predictions has been largely overlooked in the same context.","To this end, we propose a novel distribution-free approach based on the conformal prediction framework and quantile regression.","Despite the recent applications of conformal prediction to sequential data, existing methods operate independently on each target time series and do not account for relationships among them when constructing the prediction interval.","We fill this void by introducing a novel conformal prediction method based on graph deep learning operators.","Our method, named Conformal Relational Prediction (CoRel), does not require the relational structure (graph) to be known as a prior and can be applied on top of any pre-trained time series predictor.","Additionally, CoRel includes an adaptive component to handle non-exchangeable data and changes in the input time series.","Our approach provides accurate coverage and archives state-of-the-art uncertainty quantification in relevant benchmarks."],"url":"http://arxiv.org/abs/2502.09443v1"}
{"created":"2025-02-13 16:06:52","title":"Deterministic Independent Sets in the Semi-Streaming Model","abstract":"We consider the independent set problem in the semi-streaming model. For any input graph $G=(V, E)$ with $n$ vertices, an independent set is a set of vertices with no edges between any two elements. In the semi-streaming model, $G$ is presented as a stream of edges and any algorithm must use $\\tilde O(n)$ bits of memory to output a large independent set at the end of the stream.   Prior work has designed various semi-streaming algorithms for finding independent sets. Due to the hardness of finding maximum and maximal independent sets in the semi-streaming model, the focus has primarily been on finding independent sets in terms of certain parameters, such as the maximum degree $\\Delta$. In particular, there is a simple randomized algorithm that obtains independent sets of size $\\frac n{\\Delta+1}$ in expectation, which can also be achieved with high probability using more complicated algorithms. For deterministic algorithms, the best bounds are significantly weaker. In fact, the best we currently know is a straightforward algorithm that finds an $\\tilde\\Omega\\left(\\frac n{\\Delta^2}\\right)$ size independent set.   We show that this straightforward algorithm is nearly optimal by proving that any deterministic semi-streaming algorithm can only output an $\\tilde O\\left(\\frac n{\\Delta^2}\\right)$ size independent set. Our result proves a strong separation between the power of deterministic and randomized semi-streaming algorithms for the independent set problem.","sentences":["We consider the independent set problem in the semi-streaming model.","For any input graph $G=(V, E)$ with $n$ vertices, an independent set is a set of vertices with no edges between any two elements.","In the semi-streaming model, $G$ is presented as a stream of edges and any algorithm must use $\\tilde O(n)$ bits of memory to output a large independent set at the end of the stream.   ","Prior work has designed various semi-streaming algorithms for finding independent sets.","Due to the hardness of finding maximum and maximal independent sets in the semi-streaming model, the focus has primarily been on finding independent sets in terms of certain parameters, such as the maximum degree $\\Delta$.","In particular, there is a simple randomized algorithm that obtains independent sets of size $\\frac n{\\Delta+1}$ in expectation, which can also be achieved with high probability using more complicated algorithms.","For deterministic algorithms, the best bounds are significantly weaker.","In fact, the best we currently know is a straightforward algorithm that finds an $\\tilde\\Omega\\left(\\frac n{\\Delta^2}\\right)$ size independent set.   ","We show that this straightforward algorithm is nearly optimal by proving that any deterministic semi-streaming algorithm can only output an $\\tilde O\\left(\\frac n{\\Delta^2}\\right)$ size independent set.","Our result proves a strong separation between the power of deterministic and randomized semi-streaming algorithms for the independent set problem."],"url":"http://arxiv.org/abs/2502.09440v1"}
{"created":"2025-02-13 16:00:46","title":"Variable Stiffness for Robust Locomotion through Reinforcement Learning","abstract":"Reinforcement-learned locomotion enables legged robots to perform highly dynamic motions but often accompanies time-consuming manual tuning of joint stiffness. This paper introduces a novel control paradigm that integrates variable stiffness into the action space alongside joint positions, enabling grouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness (PLS) and hybrid joint-leg stiffness (HJLS). We show that variable stiffness policies, with grouping in per-leg stiffness (PLS), outperform position-based control in velocity tracking and push recovery. In contrast, HJLS excels in energy efficiency. Furthermore, our method showcases robust walking behaviour on diverse outdoor terrains by sim-to-real transfer, although the policy is sorely trained on a flat floor. Our approach simplifies design by eliminating per-joint stiffness tuning while keeping competitive results with various metrics.","sentences":["Reinforcement-learned locomotion enables legged robots to perform highly dynamic motions but often accompanies time-consuming manual tuning of joint stiffness.","This paper introduces a novel control paradigm that integrates variable stiffness into the action space alongside joint positions, enabling grouped stiffness control such as per-joint stiffness (PJS), per-leg stiffness (PLS) and hybrid joint-leg stiffness (HJLS).","We show that variable stiffness policies, with grouping in per-leg stiffness (PLS), outperform position-based control in velocity tracking and push recovery.","In contrast, HJLS excels in energy efficiency.","Furthermore, our method showcases robust walking behaviour on diverse outdoor terrains by sim-to-real transfer, although the policy is sorely trained on a flat floor.","Our approach simplifies design by eliminating per-joint stiffness tuning while keeping competitive results with various metrics."],"url":"http://arxiv.org/abs/2502.09436v1"}
{"created":"2025-02-13 15:59:57","title":"Computational techniques enabling the perception of virtual images exclusive to the retinal afterimage","abstract":"The retinal afterimage is a widely known effect in the human visual system, which has been studied and used in the context of a number of major art movements. Therefore, when considering the general role of computation in the visual arts, this begs the question whether this effect, too, may be induced using partly automated techniques. If so, it may become a computationally controllable ingredient of (interactive) visual art, and thus take its place among the many other aspects of visual perception which already have preceded it in this sense. The present moment provides additional inspiration to lay the groundwork for extending computer graphics in general with the retinal afterimage: Historically, we are in a phase where some head-mounted stereoscopic AR/VR technologies are now providing eye tracking by default, thereby allowing realtime monitoring of the processes of visual fixation that can induce the retinal afterimage. A logical starting point for general investigation is then shape display via the retinal afterimage, since shape recognition lends itself well to unambiguous reporting. Shape recognition, however, may also occur due to normal vision, which happens simultaneously. Carefully and rigorously excluding this possibility, we develop computational techniques enabling shape display exclusive to the retinal afterimage.","sentences":["The retinal afterimage is a widely known effect in the human visual system, which has been studied and used in the context of a number of major art movements.","Therefore, when considering the general role of computation in the visual arts, this begs the question whether this effect, too, may be induced using partly automated techniques.","If so, it may become a computationally controllable ingredient of (interactive) visual art, and thus take its place among the many other aspects of visual perception which already have preceded it in this sense.","The present moment provides additional inspiration to lay the groundwork for extending computer graphics in general with the retinal afterimage: Historically, we are in a phase where some head-mounted stereoscopic AR/VR technologies are now providing eye tracking by default, thereby allowing realtime monitoring of the processes of visual fixation that can induce the retinal afterimage.","A logical starting point for general investigation is then shape display via the retinal afterimage, since shape recognition lends itself well to unambiguous reporting.","Shape recognition, however, may also occur due to normal vision, which happens simultaneously.","Carefully and rigorously excluding this possibility, we develop computational techniques enabling shape display exclusive to the retinal afterimage."],"url":"http://arxiv.org/abs/2502.09435v1"}
{"created":"2025-02-13 15:56:44","title":"Redistribute Ensemble Training for Mitigating Memorization in Diffusion Models","abstract":"Diffusion models, known for their tremendous ability to generate high-quality samples, have recently raised concerns due to their data memorization behavior, which poses privacy risks. Recent methods for memory mitigation have primarily addressed the issue within the context of the text modality in cross-modal generation tasks, restricting their applicability to specific conditions. In this paper, we propose a novel method for diffusion models from the perspective of visual modality, which is more generic and fundamental for mitigating memorization. Directly exposing visual data to the model increases memorization risk, so we design a framework where models learn through proxy model parameters instead. Specially, the training dataset is divided into multiple shards, with each shard training a proxy model, then aggregated to form the final model. Additionally, practical analysis of training losses illustrates that the losses for easily memorable images tend to be obviously lower. Thus, we skip the samples with abnormally low loss values from the current mini-batch to avoid memorizing. However, balancing the need to skip memorization-prone samples while maintaining sufficient training data for high-quality image generation presents a key challenge. Thus, we propose IET-AGC+, which redistributes highly memorizable samples between shards, to mitigate these samples from over-skipping. Furthermore, we dynamically augment samples based on their loss values to further reduce memorization. Extensive experiments and analysis on four datasets show that our method successfully reduces memory capacity while maintaining performance. Moreover, we fine-tune the pre-trained diffusion models, e.g., Stable Diffusion, and decrease the memorization score by 46.7\\%, demonstrating the effectiveness of our method. Code is available in: https://github.com/liuxiao-guan/IET_AGC.","sentences":["Diffusion models, known for their tremendous ability to generate high-quality samples, have recently raised concerns due to their data memorization behavior, which poses privacy risks.","Recent methods for memory mitigation have primarily addressed the issue within the context of the text modality in cross-modal generation tasks, restricting their applicability to specific conditions.","In this paper, we propose a novel method for diffusion models from the perspective of visual modality, which is more generic and fundamental for mitigating memorization.","Directly exposing visual data to the model increases memorization risk, so we design a framework where models learn through proxy model parameters instead.","Specially, the training dataset is divided into multiple shards, with each shard training a proxy model, then aggregated to form the final model.","Additionally, practical analysis of training losses illustrates that the losses for easily memorable images tend to be obviously lower.","Thus, we skip the samples with abnormally low loss values from the current mini-batch to avoid memorizing.","However, balancing the need to skip memorization-prone samples while maintaining sufficient training data for high-quality image generation presents a key challenge.","Thus, we propose IET-AGC+, which redistributes highly memorizable samples between shards, to mitigate these samples from over-skipping.","Furthermore, we dynamically augment samples based on their loss values to further reduce memorization.","Extensive experiments and analysis on four datasets show that our method successfully reduces memory capacity while maintaining performance.","Moreover, we fine-tune the pre-trained diffusion models, e.g., Stable Diffusion, and decrease the memorization score by 46.7\\%, demonstrating the effectiveness of our method.","Code is available in: https://github.com/liuxiao-guan/IET_AGC."],"url":"http://arxiv.org/abs/2502.09434v1"}
{"created":"2025-02-13 15:55:00","title":"Dual Formulation for Non-Rectangular Lp Robust Markov Decision Processes","abstract":"We study robust Markov decision processes (RMDPs) with non-rectangular uncertainty sets, which capture interdependencies across states unlike traditional rectangular models. While non-rectangular robust policy evaluation is generally NP-hard, even in approximation, we identify a powerful class of $L_p$-bounded uncertainty sets that avoid these complexity barriers due to their structural simplicity. We further show that this class can be decomposed into infinitely many \\texttt{sa}-rectangular $L_p$-bounded sets and leverage its structural properties to derive a novel dual formulation for $L_p$ RMDPs. This formulation provides key insights into the adversary's strategy and enables the development of the first robust policy evaluation algorithms for non-rectangular RMDPs. Empirical results demonstrate that our approach significantly outperforms brute-force methods, establishing a promising foundation for future investigation into non-rectangular robust MDPs.","sentences":["We study robust Markov decision processes (RMDPs) with non-rectangular uncertainty sets, which capture interdependencies across states unlike traditional rectangular models.","While non-rectangular robust policy evaluation is generally NP-hard, even in approximation, we identify a powerful class of $L_p$-bounded uncertainty sets that avoid these complexity barriers due to their structural simplicity.","We further show that this class can be decomposed into infinitely many \\texttt{sa}-rectangular $L_p$-bounded sets and leverage its structural properties to derive a novel dual formulation for $L_p$ RMDPs.","This formulation provides key insights into the adversary's strategy and enables the development of the first robust policy evaluation algorithms for non-rectangular RMDPs.","Empirical results demonstrate that our approach significantly outperforms brute-force methods, establishing a promising foundation for future investigation into non-rectangular robust MDPs."],"url":"http://arxiv.org/abs/2502.09432v1"}
{"created":"2025-02-13 15:53:34","title":"On Usage of Non-Volatile Memory as Primary Storage for Database Management Systems","abstract":"This paper explores the implications of employing non-volatile memory (NVM) as primary storage for a data base management system (DBMS). We investigate the modifications necessary to be applied on top of a traditional relational DBMS to take advantage of NVM features. As a case study, we modify the storage engine (SE) of PostgreSQL enabling efficient use of NVM hardware. We detail the necessary changes and challenges such modifications entail and evaluate them using a comprehensive emulation platform. Results indicate that our modified SE reduces query execution time by up to 45% and 13% when compared to disk and NVM storage, with average reductions of 19% and 4%, respectively. Detailed analysis of these results shows that while our modified SE is able to access data more efficiently, data is not close to the processing units when needed for processing, incurring long latency misses that hinder the performance. To solve this, we develop a general purpose library that employs helper threads to prefetch data from NVM hardware via a simple API. Our library further improves query execution time for our modified SE when compared to disk and NVM storage by up to 54% and 17%, with average reductions of 23% and 8%, respectively.","sentences":["This paper explores the implications of employing non-volatile memory (NVM) as primary storage for a data base management system (DBMS).","We investigate the modifications necessary to be applied on top of a traditional relational DBMS to take advantage of NVM features.","As a case study, we modify the storage engine (SE) of PostgreSQL enabling efficient use of NVM hardware.","We detail the necessary changes and challenges such modifications entail and evaluate them using a comprehensive emulation platform.","Results indicate that our modified SE reduces query execution time by up to 45% and 13% when compared to disk and NVM storage, with average reductions of 19% and 4%, respectively.","Detailed analysis of these results shows that while our modified SE is able to access data more efficiently, data is not close to the processing units when needed for processing, incurring long latency misses that hinder the performance.","To solve this, we develop a general purpose library that employs helper threads to prefetch data from NVM hardware via a simple API.","Our library further improves query execution time for our modified SE when compared to disk and NVM storage by up to 54% and 17%, with average reductions of 23% and 8%, respectively."],"url":"http://arxiv.org/abs/2502.09431v1"}
{"created":"2025-02-13 15:47:45","title":"A 3D Facial Reconstruction Evaluation Methodology: Comparing Smartphone Scans with Deep Learning Based Methods Using Geometry and Morphometry Criteria","abstract":"Three-dimensional (3D) facial shape analysis has gained interest due to its potential clinical applications. However, the high cost of advanced 3D facial acquisition systems limits their widespread use, driving the development of low-cost acquisition and reconstruction methods. This study introduces a novel evaluation methodology that goes beyond traditional geometry-based benchmarks by integrating morphometric shape analysis techniques, providing a statistical framework for assessing facial morphology preservation. As a case study, we compare smartphone-based 3D scans with state-of-the-art deep learning reconstruction methods from 2D images, using high-end stereophotogrammetry models as ground truth. This methodology enables a quantitative assessment of global and local shape differences, offering a biologically meaningful validation approach for low-cost 3D facial acquisition and reconstruction techniques.","sentences":["Three-dimensional (3D) facial shape analysis has gained interest due to its potential clinical applications.","However, the high cost of advanced 3D facial acquisition systems limits their widespread use, driving the development of low-cost acquisition and reconstruction methods.","This study introduces a novel evaluation methodology that goes beyond traditional geometry-based benchmarks by integrating morphometric shape analysis techniques, providing a statistical framework for assessing facial morphology preservation.","As a case study, we compare smartphone-based 3D scans with state-of-the-art deep learning reconstruction methods from 2D images, using high-end stereophotogrammetry models as ground truth.","This methodology enables a quantitative assessment of global and local shape differences, offering a biologically meaningful validation approach for low-cost 3D facial acquisition and reconstruction techniques."],"url":"http://arxiv.org/abs/2502.09425v1"}
