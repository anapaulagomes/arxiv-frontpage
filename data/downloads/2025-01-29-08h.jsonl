{"created":"2025-01-28 18:59:49","title":"CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation","abstract":"We introduce a novel method for generating 360{\\deg} panoramas from text prompts or images. Our approach leverages recent advances in 3D generation by employing multi-view diffusion models to jointly synthesize the six faces of a cubemap. Unlike previous methods that rely on processing equirectangular projections or autoregressive generation, our method treats each face as a standard perspective image, simplifying the generation process and enabling the use of existing multi-view diffusion models. We demonstrate that these models can be adapted to produce high-quality cubemaps without requiring correspondence-aware attention layers. Our model allows for fine-grained text control, generates high resolution panorama images and generalizes well beyond its training set, whilst achieving state-of-the-art results, both qualitatively and quantitatively. Project page: https://cubediff.github.io/","sentences":["We introduce a novel method for generating 360{\\deg} panoramas from text prompts or images.","Our approach leverages recent advances in 3D generation by employing multi-view diffusion models to jointly synthesize the six faces of a cubemap.","Unlike previous methods that rely on processing equirectangular projections or autoregressive generation, our method treats each face as a standard perspective image, simplifying the generation process and enabling the use of existing multi-view diffusion models.","We demonstrate that these models can be adapted to produce high-quality cubemaps without requiring correspondence-aware attention layers.","Our model allows for fine-grained text control, generates high resolution panorama images and generalizes well beyond its training set, whilst achieving state-of-the-art results, both qualitatively and quantitatively.","Project page: https://cubediff.github.io/"],"url":"http://arxiv.org/abs/2501.17162v1"}
{"created":"2025-01-28 18:59:44","title":"SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training","abstract":"Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models. However, their roles in enhancing model generalization capabilities remain unclear. This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants. We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains. We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants. SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios. Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain. Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains. These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks.","sentences":["Supervised fine-tuning (SFT) and reinforcement learning (RL) are widely used post-training techniques for foundation models.","However, their roles in enhancing model generalization capabilities remain unclear.","This paper studies the difference between SFT and RL on generalization and memorization, focusing on text-based rule variants and visual variants.","We introduce GeneralPoints, an arithmetic reasoning card game, and adopt V-IRL, a real-world navigation environment, to assess how models trained with SFT and RL generalize to unseen variants in both textual and visual domains.","We show that RL, especially when trained with an outcome-based reward, generalizes across both rule-based textual and visual variants.","SFT, in contrast, tends to memorize training data and struggles to generalize out-of-distribution scenarios.","Further analysis reveals that RL improves the model's underlying visual recognition capabilities, contributing to its enhanced generalization in the visual domain.","Despite RL's superior generalization, we show that SFT remains essential for effective RL training; SFT stabilizes the model's output format, enabling subsequent RL to achieve its performance gains.","These findings demonstrates the capability of RL for acquiring generalizable knowledge in complex, multi-modal tasks."],"url":"http://arxiv.org/abs/2501.17161v1"}
{"created":"2025-01-28 18:59:03","title":"IC-Portrait: In-Context Matching for View-Consistent Personalized Portrait","abstract":"Existing diffusion models show great potential for identity-preserving generation. However, personalized portrait generation remains challenging due to the diversity in user profiles, including variations in appearance and lighting conditions. To address these challenges, we propose IC-Portrait, a novel framework designed to accurately encode individual identities for personalized portrait generation. Our key insight is that pre-trained diffusion models are fast learners (e.g.,100 ~ 200 steps) for in-context dense correspondence matching, which motivates the two major designs of our IC-Portrait framework. Specifically, we reformulate portrait generation into two sub-tasks: 1) Lighting-Aware Stitching: we find that masking a high proportion of the input image, e.g., 80%, yields a highly effective self-supervisory representation learning of reference image lighting. 2) View-Consistent Adaptation: we leverage a synthetic view-consistent profile dataset to learn the in-context correspondence. The reference profile can then be warped into arbitrary poses for strong spatial-aligned view conditioning. Coupling these two designs by simply concatenating latents to form ControlNet-like supervision and modeling, enables us to significantly enhance the identity preservation fidelity and stability. Extensive evaluations demonstrate that IC-Portrait consistently outperforms existing state-of-the-art methods both quantitatively and qualitatively, with particularly notable improvements in visual qualities. Furthermore, IC-Portrait even demonstrates 3D-aware relighting capabilities.","sentences":["Existing diffusion models show great potential for identity-preserving generation.","However, personalized portrait generation remains challenging due to the diversity in user profiles, including variations in appearance and lighting conditions.","To address these challenges, we propose IC-Portrait, a novel framework designed to accurately encode individual identities for personalized portrait generation.","Our key insight is that pre-trained diffusion models are fast learners (e.g.,100 ~ 200 steps) for in-context dense correspondence matching, which motivates the two major designs of our IC-Portrait framework.","Specifically, we reformulate portrait generation into two sub-tasks: 1) Lighting-Aware Stitching: we find that masking a high proportion of the input image, e.g., 80%, yields a highly effective self-supervisory representation learning of reference image lighting.","2) View-Consistent Adaptation: we leverage a synthetic view-consistent profile dataset to learn the in-context correspondence.","The reference profile can then be warped into arbitrary poses for strong spatial-aligned view conditioning.","Coupling these two designs by simply concatenating latents to form ControlNet-like supervision and modeling, enables us to significantly enhance the identity preservation fidelity and stability.","Extensive evaluations demonstrate that IC-Portrait consistently outperforms existing state-of-the-art methods both quantitatively and qualitatively, with particularly notable improvements in visual qualities.","Furthermore, IC-Portrait even demonstrates 3D-aware relighting capabilities."],"url":"http://arxiv.org/abs/2501.17159v1"}
{"created":"2025-01-28 18:53:14","title":"Scanning Trojaned Models Using Out-of-Distribution Samples","abstract":"Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications. There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks. Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method. Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training. Motivated by these challenges, our study introduces a novel scanning method named TRODO (TROjan scanning by Detection of adversarial shifts in Out-of-distribution samples). TRODO leverages the concept of \"blind spots\"--regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID). We scan for these blind spots by adversarially shifting OOD samples towards in-distribution. The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection. TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers. It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy.","sentences":["Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications.","There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks.","Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method.","Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training.","Motivated by these challenges, our study introduces a novel scanning method named TRODO (TROjan scanning by Detection of adversarial shifts in Out-of-distribution samples).","TRODO leverages the concept of \"blind spots\"--regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID).","We scan for these blind spots by adversarially shifting OOD samples towards in-distribution.","The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection.","TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers.","It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy."],"url":"http://arxiv.org/abs/2501.17151v1"}
{"created":"2025-01-28 18:52:59","title":"Cultural Differences and Perverse Incentives in Science Create a Bad Mix: Exploring Country-Level Publication Bias in Select ACM Conferences","abstract":"In the era of big science, many national governments are helping to build well-funded teams of scientists to serve nationalistic ambitions, providing financial incentives for certain outcomes for purposes other than advancing science. This in turn can impact the behavior of scientists and create distorted country-level bias in publication rates, frequency, and publication venues targeted. To that end, we have found evidence that indicates significant inequality among the publication rates of individual scientists from various countries, based on an intensive analysis of papers published in several well-known ACM conferences (HRI, IUI, KDD, CHI, SIGGRAPH, UIST, and UBICOMP) over 15 years between 2010 to 2024. Furthermore, scientists who were affiliated with the top-5 countries (in terms of research expenditure) were found to be contributing significantly more to the inequality in publication rates than others. Given evidence of certain countries aggressively pushing their scientists via $\\textit{perverse incentives}$ to publish in well-regarded publication venues and produce significant results (by any means necessary), we detected and present several examples of potential ethical problems in publications caused by such systems. Additionally, topic modeling using LDA and semantic similarity revealed that some countries are not pursuing diverse scientific topics relative to others, indicating those incentives may be limiting genuine scientific curiosity. All in all, our findings raise awareness of systems put in place by certain national governments that not only erodes the pursuit of truth through science, but also appears to be gradually undermining the integrity of the global scientific community.","sentences":["In the era of big science, many national governments are helping to build well-funded teams of scientists to serve nationalistic ambitions, providing financial incentives for certain outcomes for purposes other than advancing science.","This in turn can impact the behavior of scientists and create distorted country-level bias in publication rates, frequency, and publication venues targeted.","To that end, we have found evidence that indicates significant inequality among the publication rates of individual scientists from various countries, based on an intensive analysis of papers published in several well-known ACM conferences (HRI, IUI, KDD, CHI, SIGGRAPH, UIST, and UBICOMP) over 15 years between 2010 to 2024.","Furthermore, scientists who were affiliated with the top-5 countries (in terms of research expenditure) were found to be contributing significantly more to the inequality in publication rates than others.","Given evidence of certain countries aggressively pushing their scientists via $\\textit{perverse incentives}$ to publish in well-regarded publication venues and produce significant results (by any means necessary), we detected and present several examples of potential ethical problems in publications caused by such systems.","Additionally, topic modeling using LDA and semantic similarity revealed that some countries are not pursuing diverse scientific topics relative to others, indicating those incentives may be limiting genuine scientific curiosity.","All in all, our findings raise awareness of systems put in place by certain national governments that not only erodes the pursuit of truth through science, but also appears to be gradually undermining the integrity of the global scientific community."],"url":"http://arxiv.org/abs/2501.17150v1"}
{"created":"2025-01-28 18:51:24","title":"AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders","abstract":"Fine-grained steering of language model outputs is essential for safety and reliability. Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning. At present, there is no benchmark for making direct comparisons between these proposals. Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning. For concept detection, representation-based methods such as difference-in-means, perform the best. On both evaluations, SAEs are not competitive. We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks. Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean.","sentences":["Fine-grained steering of language model outputs is essential for safety and reliability.","Prompting and finetuning are widely used to achieve these goals, but interpretability researchers have proposed a variety of representation-based techniques as well, including sparse autoencoders (SAEs), linear artificial tomography, supervised steering vectors, linear probes, and representation finetuning.","At present, there is no benchmark for making direct comparisons between these proposals.","Therefore, we introduce AxBench, a large-scale benchmark for steering and concept detection, and report experiments on Gemma-2-2B and 9B. For steering, we find that prompting outperforms all existing methods, followed by finetuning.","For concept detection, representation-based methods such as difference-in-means, perform the best.","On both evaluations, SAEs are not competitive.","We introduce a novel weakly-supervised representational method (Rank-1 Representation Finetuning; ReFT-r1), which is competitive on both tasks while providing the interpretability advantages that prompting lacks.","Along with AxBench, we train and publicly release SAE-scale feature dictionaries for ReFT-r1 and DiffMean."],"url":"http://arxiv.org/abs/2501.17148v1"}
{"created":"2025-01-28 18:45:07","title":"FactCG: Enhancing Fact Checkers with Graph-Based Multi-Hop Data","abstract":"Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data. However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations. Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts. While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities. In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims. Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents. Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models. Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size.","sentences":["Prior research on training grounded factuality classification models to detect hallucinations in large language models (LLMs) has relied on public natural language inference (NLI) data and synthetic data.","However, conventional NLI datasets are not well-suited for document-level reasoning, which is critical for detecting LLM hallucinations.","Recent approaches to document-level synthetic data generation involve iteratively removing sentences from documents and annotating factuality using LLM-based prompts.","While effective, this method is computationally expensive for long documents and limited by the LLM's capabilities.","In this work, we analyze the differences between existing synthetic training data used in state-of-the-art models and real LLM output claims.","Based on our findings, we propose a novel approach for synthetic data generation, CG2C, that leverages multi-hop reasoning on context graphs extracted from documents.","Our fact checker model, FactCG, demonstrates improved performance with more connected reasoning, using the same backbone models.","Experiments show it even outperforms GPT-4-o on the LLM-Aggrefact benchmark with much smaller model size."],"url":"http://arxiv.org/abs/2501.17144v1"}
{"created":"2025-01-28 18:25:11","title":"ASTRAL: Automated Safety Testing of Large Language Models","abstract":"Large Language Models (LLMs) have recently gained attention due to their ability to understand and generate sophisticated human-like content. However, ensuring their safety is paramount as they might provide harmful and unsafe responses. Existing LLM testing frameworks address various safety-related concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due to unbalanced and obsolete datasets. In this paper, we present ASTRAL, a tool that automates the generation and execution of test cases (i.e., prompts) for testing the safety of LLMs. First, we introduce a novel black-box coverage criterion to generate balanced and diverse unsafe test inputs across a diverse set of safety categories as well as linguistic writing characteristics (i.e., different style and persuasive writing techniques). Second, we propose an LLM-based approach that leverages Retrieval Augmented Generation (RAG), few-shot prompting strategies and web browsing to generate up-to-date test inputs. Lastly, similar to current LLM test automation techniques, we leverage LLMs as test oracles to distinguish between safe and unsafe test outputs, allowing a fully automated testing approach. We conduct an extensive evaluation on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms other LLMs when acting as the test oracle, accurately detecting unsafe responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard); ii) the results confirm that our approach can uncover nearly twice as many unsafe LLM behaviors with the same number of test inputs compared to currently used static datasets; and iii) our black-box coverage criterion combined with web browsing can effectively guide the LLM on generating up-to-date unsafe test inputs, significantly increasing the number of unsafe LLM behaviors.","sentences":["Large Language Models (LLMs) have recently gained attention due to their ability to understand and generate sophisticated human-like content.","However, ensuring their safety is paramount as they might provide harmful and unsafe responses.","Existing LLM testing frameworks address various safety-related concerns (e.g., drugs, terrorism, animal abuse) but often face challenges due to unbalanced and obsolete datasets.","In this paper, we present ASTRAL, a tool that automates the generation and execution of test cases (i.e., prompts) for testing the safety of LLMs.","First, we introduce a novel black-box coverage criterion to generate balanced and diverse unsafe test inputs across a diverse set of safety categories as well as linguistic writing characteristics (i.e., different style and persuasive writing techniques).","Second, we propose an LLM-based approach that leverages Retrieval Augmented Generation (RAG), few-shot prompting strategies and web browsing to generate up-to-date test inputs.","Lastly, similar to current LLM test automation techniques, we leverage LLMs as test oracles to distinguish between safe and unsafe test outputs, allowing a fully automated testing approach.","We conduct an extensive evaluation on well-known LLMs, revealing the following key findings: i) GPT3.5 outperforms other LLMs when acting as the test oracle, accurately detecting unsafe responses, and even surpassing more recent LLMs (e.g., GPT-4), as well as LLMs that are specifically tailored to detect unsafe LLM outputs (e.g., LlamaGuard); ii) the results confirm that our approach can uncover nearly twice as many unsafe LLM behaviors with the same number of test inputs compared to currently used static datasets; and iii) our black-box coverage criterion combined with web browsing can effectively guide the LLM on generating up-to-date unsafe test inputs, significantly increasing the number of unsafe LLM behaviors."],"url":"http://arxiv.org/abs/2501.17132v1"}
{"created":"2025-01-28 18:23:12","title":"Scenario Understanding of Traffic Scenes Through Large Visual Language Models","abstract":"Deep learning models for autonomous driving, encompassing perception, planning, and control, depend on vast datasets to achieve their high performance. However, their generalization often suffers due to domain-specific data distributions, making an effective scene-based categorization of samples necessary to improve their reliability across diverse domains. Manual captioning, though valuable, is both labor-intensive and time-consuming, creating a bottleneck in the data annotation process. Large Visual Language Models (LVLMs) present a compelling solution by automating image analysis and categorization through contextual queries, often without requiring retraining for new categories. In this study, we evaluate the capabilities of LVLMs, including GPT-4 and LLaVA, to understand and classify urban traffic scenes on both an in-house dataset and the BDD100K. We propose a scalable captioning pipeline that integrates state-of-the-art models, enabling a flexible deployment on new datasets. Our analysis, combining quantitative metrics with qualitative insights, demonstrates the effectiveness of LVLMs to understand urban traffic scenarios and highlights their potential as an efficient tool for data-driven advancements in autonomous driving.","sentences":["Deep learning models for autonomous driving, encompassing perception, planning, and control, depend on vast datasets to achieve their high performance.","However, their generalization often suffers due to domain-specific data distributions, making an effective scene-based categorization of samples necessary to improve their reliability across diverse domains.","Manual captioning, though valuable, is both labor-intensive and time-consuming, creating a bottleneck in the data annotation process.","Large Visual Language Models (LVLMs) present a compelling solution by automating image analysis and categorization through contextual queries, often without requiring retraining for new categories.","In this study, we evaluate the capabilities of LVLMs, including GPT-4 and LLaVA, to understand and classify urban traffic scenes on both an in-house dataset and the BDD100K. We propose a scalable captioning pipeline that integrates state-of-the-art models, enabling a flexible deployment on new datasets.","Our analysis, combining quantitative metrics with qualitative insights, demonstrates the effectiveness of LVLMs to understand urban traffic scenarios and highlights their potential as an efficient tool for data-driven advancements in autonomous driving."],"url":"http://arxiv.org/abs/2501.17131v1"}
{"created":"2025-01-28 18:16:36","title":"Enhancements to P4TG: Performance, Protocols, and Automation","abstract":"The P4-based traffic generator (P4TG) is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC. The TG can generate up to 1 Tb/s of traffic and directly measures rates, packet loss, and other metrics in the data plane. Many researchers and industrial partners have used it since its publication in 2023 and new features have been requested to be incorporated into P4TG. In this work, we provide an overview of the recently added features of P4TG. These enhancements include new traffic generation capabilities including IPv6 and segment routing v6 (SRv6) support and various encapsulation protocols such as VLAN, QinQ, VxLAN, and MPLS. Further, P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 4 Tb/s. The enhancements to P4TG also provide an improved user experience facilitating automated testing based on RFC 2544, report generation, and visualization.","sentences":["The P4-based traffic generator (P4TG) is a hardware-based traffic generator (TG) running on the Intel Tofino 1 ASIC.","The TG can generate up to 1 Tb/s of traffic and directly measures rates, packet loss, and other metrics in the data plane.","Many researchers and industrial partners have used it since its publication in 2023 and new features have been requested to be incorporated into P4TG.","In this work, we provide an overview of the recently added features of P4TG.","These enhancements include new traffic generation capabilities including IPv6 and segment routing v6 (SRv6) support and various encapsulation protocols such as VLAN, QinQ, VxLAN, and MPLS.","Further, P4TG is ported to the Intel Tofino 2 platform enabling a generation capability of up to 4 Tb/s. The enhancements to P4TG also provide an improved user experience facilitating automated testing based on RFC 2544, report generation, and visualization."],"url":"http://arxiv.org/abs/2501.17127v1"}
{"created":"2025-01-28 18:16:05","title":"ECLYPSE: a Python Framework for Simulation and Emulation of the Cloud-Edge Continuum","abstract":"The Cloud-Edge continuum enhances application performance by bringing computation closer to data sources. However, it presents considerable challenges in managing resources and determining service placement, as these tasks require navigating diverse, dynamic environments characterised by fluctuating network conditions. Addressing these challenges calls for tools combining simulation and emulation of Cloud-Edge systems to rigorously assess novel application and resource management strategies. In this paper, we introduce ECLYPSE, a Python-based framework that enables the simulation and emulation of the Cloud-Edge continuum via adaptable resource allocation and service placement models. ECLYPSE features an event-driven architecture for dynamically adapting network configurations and resources. It also supports seamless transitions between simulated and emulated setups. In this work, ECLYPSE capabilities are illustrated over three use cases, showing how the framework supports rapid prototyping across diverse experimental settings.","sentences":["The Cloud-Edge continuum enhances application performance by bringing computation closer to data sources.","However, it presents considerable challenges in managing resources and determining service placement, as these tasks require navigating diverse, dynamic environments characterised by fluctuating network conditions.","Addressing these challenges calls for tools combining simulation and emulation of Cloud-Edge systems to rigorously assess novel application and resource management strategies.","In this paper, we introduce ECLYPSE, a Python-based framework that enables the simulation and emulation of the Cloud-Edge continuum via adaptable resource allocation and service placement models.","ECLYPSE features an event-driven architecture for dynamically adapting network configurations and resources.","It also supports seamless transitions between simulated and emulated setups.","In this work, ECLYPSE capabilities are illustrated over three use cases, showing how the framework supports rapid prototyping across diverse experimental settings."],"url":"http://arxiv.org/abs/2501.17126v1"}
{"created":"2025-01-28 18:15:27","title":"CoRe-Net: Co-Operational Regressor Network with Progressive Transfer Learning for Blind Radar Signal Restoration","abstract":"Real-world radar signals are frequently corrupted by various artifacts, including sensor noise, echoes, interference, and intentional jamming, differing in type, severity, and duration. This pilot study introduces a novel model, called Co-Operational Regressor Network (CoRe-Net) for blind radar signal restoration, designed to address such limitations and drawbacks. CoRe-Net replaces adversarial training with a novel cooperative learning strategy, leveraging the complementary roles of its Apprentice Regressor (AR) and Master Regressor (MR). The AR restores radar signals corrupted by various artifacts, while the MR evaluates the quality of the restoration and provides immediate and task-specific feedback, ensuring stable and efficient learning. The AR, therefore, has the advantage of both self-learning and assistive learning by the MR. The proposed model has been extensively evaluated over the benchmark Blind Radar Signal Restoration (BRSR) dataset, which simulates diverse real-world artifact scenarios. Under the fair experimental setup, this study shows that the CoRe-Net surpasses the Op-GANs over a 1 dB mean SNR improvement. To further boost the performance gain, this study proposes multi-pass restoration by cascaded CoRe-Nets trained with a novel paradigm called Progressive Transfer Learning (PTL), which enables iterative refinement, thus achieving an additional 2 dB mean SNR enhancement. Multi-pass CoRe-Net training by PTL consistently yields incremental performance improvements through successive restoration passes whilst highlighting CoRe-Net ability to handle such a complex and varying blend of artifacts.","sentences":["Real-world radar signals are frequently corrupted by various artifacts, including sensor noise, echoes, interference, and intentional jamming, differing in type, severity, and duration.","This pilot study introduces a novel model, called Co-Operational Regressor Network (CoRe-Net) for blind radar signal restoration, designed to address such limitations and drawbacks.","CoRe-Net replaces adversarial training with a novel cooperative learning strategy, leveraging the complementary roles of its Apprentice Regressor (AR) and Master Regressor (MR).","The AR restores radar signals corrupted by various artifacts, while the MR evaluates the quality of the restoration and provides immediate and task-specific feedback, ensuring stable and efficient learning.","The AR, therefore, has the advantage of both self-learning and assistive learning by the MR.","The proposed model has been extensively evaluated over the benchmark Blind Radar Signal Restoration (BRSR) dataset, which simulates diverse real-world artifact scenarios.","Under the fair experimental setup, this study shows that the CoRe-Net surpasses the Op-GANs over a 1 dB mean SNR improvement.","To further boost the performance gain, this study proposes multi-pass restoration by cascaded CoRe-Nets trained with a novel paradigm called Progressive Transfer Learning (PTL), which enables iterative refinement, thus achieving an additional 2 dB mean SNR enhancement.","Multi-pass CoRe-Net training by PTL consistently yields incremental performance improvements through successive restoration passes whilst highlighting CoRe-Net ability to handle such a complex and varying blend of artifacts."],"url":"http://arxiv.org/abs/2501.17125v1"}
{"created":"2025-01-28 18:14:55","title":"The Asymptotic Capacity of Byzantine Symmetric Private Information Retrieval and Its Consequences","abstract":"We consider the problem of finding the asymptotic capacity of symmetric private information retrieval (SPIR) with $B$ Byzantine servers. Prior to finding the capacity, a definition for the Byzantine servers is needed since in the literature there are two different definitions. In \\cite{byzantine_tpir}, where it was first defined, the Byzantine servers can send any symbol from the storage, their received queries and some independent random symbols. In \\cite{unresponsive_byzantine_1}, Byzantine servers send any random symbol independently of their storage and queries. It is clear that these definitions are not identical, especially when \\emph{symmetric} privacy is required. To that end, we define Byzantine servers, inspired by \\cite{byzantine_tpir}, as the servers that can share everything, before and after the scheme initiation. In this setting, we find an upper bound, for an infinite number of messages case, that should be satisfied for all schemes that protect against this setting and develop a scheme that achieves this upper bound. Hence, we identify the capacity of the problem.","sentences":["We consider the problem of finding the asymptotic capacity of symmetric private information retrieval (SPIR) with $B$ Byzantine servers.","Prior to finding the capacity, a definition for the Byzantine servers is needed since in the literature there are two different definitions.","In \\cite{byzantine_tpir}, where it was first defined, the Byzantine servers can send any symbol from the storage, their received queries and some independent random symbols.","In \\cite{unresponsive_byzantine_1}, Byzantine servers send any random symbol independently of their storage and queries.","It is clear that these definitions are not identical, especially when \\emph{symmetric} privacy is required.","To that end, we define Byzantine servers, inspired by \\cite{byzantine_tpir}, as the servers that can share everything, before and after the scheme initiation.","In this setting, we find an upper bound, for an infinite number of messages case, that should be satisfied for all schemes that protect against this setting and develop a scheme that achieves this upper bound.","Hence, we identify the capacity of the problem."],"url":"http://arxiv.org/abs/2501.17124v1"}
{"created":"2025-01-28 18:14:43","title":"Hybrid Deep Learning Model for Multiple Cache Side Channel Attacks Detection: A Comparative Analysis","abstract":"Cache side channel attacks are a sophisticated and persistent threat that exploit vulnerabilities in modern processors to extract sensitive information. These attacks leverage weaknesses in shared computational resources, particularly the last level cache, to infer patterns in data access and execution flows, often bypassing traditional security defenses. Such attacks are especially dangerous as they can be executed remotely without requiring physical access to the victim's device. This study focuses on a specific class of these threats: fingerprinting attacks, where an adversary monitors and analyzes the behavior of co-located processes via cache side channels. This can potentially reveal confidential information, such as encryption keys or user activity patterns. A comprehensive threat model illustrates how attackers sharing computational resources with target systems exploit these side channels to compromise sensitive data. To mitigate such risks, a hybrid deep learning model is proposed for detecting cache side channel attacks. Its performance is compared with five widely used deep learning models: Multi-Layer Perceptron, Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-Term Memory, and Gated Recurrent Unit. The experimental results demonstrate that the hybrid model achieves a detection rate of up to 99.96%. These findings highlight the limitations of existing models, the need for enhanced defensive mechanisms, and directions for future research to secure sensitive data against evolving side channel threats.","sentences":["Cache side channel attacks are a sophisticated and persistent threat that exploit vulnerabilities in modern processors to extract sensitive information.","These attacks leverage weaknesses in shared computational resources, particularly the last level cache, to infer patterns in data access and execution flows, often bypassing traditional security defenses.","Such attacks are especially dangerous as they can be executed remotely without requiring physical access to the victim's device.","This study focuses on a specific class of these threats: fingerprinting attacks, where an adversary monitors and analyzes the behavior of co-located processes via cache side channels.","This can potentially reveal confidential information, such as encryption keys or user activity patterns.","A comprehensive threat model illustrates how attackers sharing computational resources with target systems exploit these side channels to compromise sensitive data.","To mitigate such risks, a hybrid deep learning model is proposed for detecting cache side channel attacks.","Its performance is compared with five widely used deep learning models: Multi-Layer Perceptron, Convolutional Neural Network, Simple Recurrent Neural Network, Long Short-Term Memory, and Gated Recurrent Unit.","The experimental results demonstrate that the hybrid model achieves a detection rate of up to 99.96%.","These findings highlight the limitations of existing models, the need for enhanced defensive mechanisms, and directions for future research to secure sensitive data against evolving side channel threats."],"url":"http://arxiv.org/abs/2501.17123v1"}
{"created":"2025-01-28 18:07:30","title":"Histoires Morales: A French Dataset for Assessing Moral Alignment","abstract":"Aligning language models with human values is crucial, especially as they become more integrated into everyday life. While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations. Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language. To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context. We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms. Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals. To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment. We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data.","sentences":["Aligning language models with human values is crucial, especially as they become more integrated into everyday life.","While models are often adapted to user preferences, it is equally important to ensure they align with moral norms and behaviours in real-world social situations.","Despite significant progress in languages like English and Chinese, French has seen little attention in this area, leaving a gap in understanding how LLMs handle moral reasoning in this language.","To address this gap, we introduce Histoires Morales, a French dataset derived from Moral Stories, created through translation and subsequently refined with the assistance of native speakers to guarantee grammatical accuracy and adaptation to the French cultural context.","We also rely on annotations of the moral values within the dataset to ensure their alignment with French norms.","Histoires Morales covers a wide range of social situations, including differences in tipping practices, expressions of honesty in relationships, and responsibilities toward animals.","To foster future research, we also conduct preliminary experiments on the alignment of multilingual models on French and English data and the robustness of the alignment.","We find that while LLMs are generally aligned with human moral norms by default, they can be easily influenced with user-preference optimization for both moral and immoral data."],"url":"http://arxiv.org/abs/2501.17117v1"}
{"created":"2025-01-28 18:04:50","title":"Optimizing Large Language Model Training Using FP4 Quantization","abstract":"The growing computational demands of training large language models (LLMs) necessitate more efficient methods. Quantized training presents a promising solution by enabling low-bit arithmetic operations to reduce these costs. While FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge due to significant quantization errors and limited representational capacity. This work introduces the first FP4 training framework for LLMs, addressing these challenges with two key innovations: a differentiable quantization estimator for precise weight updates and an outlier clamping and compensation strategy to prevent activation collapse. To ensure stability, the framework integrates a mixed-precision training scheme and vector-wise quantization. Experimental results demonstrate that our FP4 framework achieves accuracy comparable to BF16 and FP8, with minimal degradation, scaling effectively to 13B-parameter LLMs trained on up to 100B tokens. With the emergence of next-generation hardware supporting FP4, our framework sets a foundation for efficient ultra-low precision training.","sentences":["The growing computational demands of training large language models (LLMs) necessitate more efficient methods.","Quantized training presents a promising solution by enabling low-bit arithmetic operations to reduce these costs.","While FP8 precision has demonstrated feasibility, leveraging FP4 remains a challenge due to significant quantization errors and limited representational capacity.","This work introduces the first FP4 training framework for LLMs, addressing these challenges with two key innovations: a differentiable quantization estimator for precise weight updates and an outlier clamping and compensation strategy to prevent activation collapse.","To ensure stability, the framework integrates a mixed-precision training scheme and vector-wise quantization.","Experimental results demonstrate that our FP4 framework achieves accuracy comparable to BF16 and FP8, with minimal degradation, scaling effectively to 13B-parameter LLMs trained on up to 100B tokens.","With the emergence of next-generation hardware supporting FP4, our framework sets a foundation for efficient ultra-low precision training."],"url":"http://arxiv.org/abs/2501.17116v1"}
{"created":"2025-01-28 18:04:05","title":"Evidence on the Regularisation Properties of Maximum-Entropy Reinforcement Learning","abstract":"The generalisation and robustness properties of policies learnt through Maximum-Entropy Reinforcement Learning are investigated on chaotic dynamical systems with Gaussian noise on the observable. First, the robustness under noise contamination of the agent's observation of entropy regularised policies is observed. Second, notions of statistical learning theory, such as complexity measures on the learnt model, are borrowed to explain and predict the phenomenon. Results show the existence of a relationship between entropy-regularised policy optimisation and robustness to noise, which can be described by the chosen complexity measures.","sentences":["The generalisation and robustness properties of policies learnt through Maximum-Entropy Reinforcement Learning are investigated on chaotic dynamical systems with Gaussian noise on the observable.","First, the robustness under noise contamination of the agent's observation of entropy regularised policies is observed.","Second, notions of statistical learning theory, such as complexity measures on the learnt model, are borrowed to explain and predict the phenomenon.","Results show the existence of a relationship between entropy-regularised policy optimisation and robustness to noise, which can be described by the chosen complexity measures."],"url":"http://arxiv.org/abs/2501.17115v1"}
{"created":"2025-01-28 17:59:56","title":"Unlocking Transparent Alignment Through Enhanced Inverse Constitutional AI for Principle Extraction","abstract":"Traditional methods for aligning Large Language Models (LLMs), such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), rely on implicit principles, limiting interpretability. Constitutional AI (CAI) offers an explicit, rule-based framework for guiding model outputs. Building on this, we refine the Inverse Constitutional AI (ICAI) algorithm, which extracts constitutions from preference datasets. By improving principle generation, clustering, and embedding processes, our approach enhances the accuracy and generalizability of extracted principles across synthetic and real-world datasets. While in-context alignment yields modest improvements, our results highlight the potential of these principles to foster more transparent and adaptable alignment methods, offering a promising direction for future advancements beyond traditional fine-tuning.","sentences":["Traditional methods for aligning Large Language Models (LLMs), such as Reinforcement Learning from Human Feedback (RLHF) and Direct Preference Optimization (DPO), rely on implicit principles, limiting interpretability.","Constitutional AI (CAI) offers an explicit, rule-based framework for guiding model outputs.","Building on this, we refine the Inverse Constitutional AI (ICAI) algorithm, which extracts constitutions from preference datasets.","By improving principle generation, clustering, and embedding processes, our approach enhances the accuracy and generalizability of extracted principles across synthetic and real-world datasets.","While in-context alignment yields modest improvements, our results highlight the potential of these principles to foster more transparent and adaptable alignment methods, offering a promising direction for future advancements beyond traditional fine-tuning."],"url":"http://arxiv.org/abs/2501.17112v1"}
{"created":"2025-01-28 17:44:04","title":"COS(M+O)S: Curiosity and RL-Enhanced MCTS for Exploring Story Space via Language Models","abstract":"We present COS(M+O)S, a System 2-inspired framework for open-ended plot development that systematically explores the vast space of possible story expansions, enabling a 3B-parameter language model to approach the plot quality of a 70B model on select short-story tasks. The method accomplishes this by combining Monte Carlo Tree Search (MCTS), guided by a step-level value model that rewards moderate surprisal (curiosity) while penalizing incoherence, and Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value plot expansions. This iterative reinforcement learning loop systematically explores multiple candidate plot branches, backpropagates quality signals, and adapts the policy for faster convergence, notably shifting the policy from puzzle-based Chain-of-Thought to more character-driven storytelling. In small-scale tests with short-story prompts, 67%-77% of participants favored COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our learned value function aligns. GPT-4o ratings further show that COS(M+O)S surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93). Pairwise comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no statistically significant gap from 70B. Nevertheless, absolute story quality remains modest, constrained by the small model's capacity and limited training data.","sentences":["We present COS(M+O)S, a System 2-inspired framework for open-ended plot development that systematically explores the vast space of possible story expansions, enabling a 3B-parameter language model to approach the plot quality of a 70B model on select short-story tasks.","The method accomplishes this by combining Monte Carlo Tree Search (MCTS), guided by a step-level value model that rewards moderate surprisal (curiosity) while penalizing incoherence, and Odds Ratio Preference Optimization (ORPO) to fine-tune the policy on high-value plot expansions.","This iterative reinforcement learning loop systematically explores multiple candidate plot branches, backpropagates quality signals, and adapts the policy for faster convergence, notably shifting the policy from puzzle-based Chain-of-Thought to more character-driven storytelling.","In small-scale tests with short-story prompts, 67%-77% of participants favored COS(M+O)S's highest-rated expansions over lower-rated ones, suggesting that our learned value function aligns.","GPT-4o ratings further show that COS(M+O)S surpasses naive single-pass decoding from Llama 3.2 3B by 0.59 SD, coming within 0.06 SD of Llama 3.1 70B (no significant difference, p=0.93).","Pairwise comparisons with o1 place COS(M+O)S 1.5 SD above the 3B baseline and find no statistically significant gap from 70B.","Nevertheless, absolute story quality remains modest, constrained by the small model's capacity and limited training data."],"url":"http://arxiv.org/abs/2501.17104v1"}
{"created":"2025-01-28 17:39:50","title":"Text-to-Image Generation for Vocabulary Learning Using the Keyword Method","abstract":"The 'keyword method' is an effective technique for learning vocabulary of a foreign language. It involves creating a memorable visual link between what a word means and what its pronunciation in a foreign language sounds like in the learner's native language. However, these memorable visual links remain implicit in the people's mind and are not easy to remember for a large set of words. To enhance the memorisation and recall of the vocabulary, we developed an application that combines the keyword method with text-to-image generators to externalise the memorable visual links into visuals. These visuals represent additional stimuli during the memorisation process. To explore the effectiveness of this approach we first run a pilot study to investigate how difficult it is to externalise the descriptions of mental visualisations of memorable links, by asking participants to write them down. We used these descriptions as prompts for text-to-image generator (DALL-E2) to convert them into images and asked participants to select their favourites. Next, we compared different text-to-image generators (DALL-E2, Midjourney, Stable and Latent Diffusion) to evaluate the perceived quality of the generated images by each. Despite heterogeneous results, participants mostly preferred images generated by DALL-E2, which was used also for the final study. In this study, we investigated whether providing such images enhances the retention of vocabulary being learned, compared to the keyword method only. Our results indicate that people did not encounter difficulties describing their visualisations of memorable links and that providing corresponding images significantly improves memory retention.","sentences":["The 'keyword method' is an effective technique for learning vocabulary of a foreign language.","It involves creating a memorable visual link between what a word means and what its pronunciation in a foreign language sounds like in the learner's native language.","However, these memorable visual links remain implicit in the people's mind and are not easy to remember for a large set of words.","To enhance the memorisation and recall of the vocabulary, we developed an application that combines the keyword method with text-to-image generators to externalise the memorable visual links into visuals.","These visuals represent additional stimuli during the memorisation process.","To explore the effectiveness of this approach we first run a pilot study to investigate how difficult it is to externalise the descriptions of mental visualisations of memorable links, by asking participants to write them down.","We used these descriptions as prompts for text-to-image generator (DALL-E2) to convert them into images and asked participants to select their favourites.","Next, we compared different text-to-image generators (DALL-E2, Midjourney, Stable and Latent Diffusion) to evaluate the perceived quality of the generated images by each.","Despite heterogeneous results, participants mostly preferred images generated by DALL-E2, which was used also for the final study.","In this study, we investigated whether providing such images enhances the retention of vocabulary being learned, compared to the keyword method only.","Our results indicate that people did not encounter difficulties describing their visualisations of memorable links and that providing corresponding images significantly improves memory retention."],"url":"http://arxiv.org/abs/2501.17099v1"}
{"created":"2025-01-28 17:23:45","title":"CRSet: Non-Interactive Verifiable Credential Revocation with Metadata Privacy for Issuers and Everyone Else","abstract":"Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise. Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics. For instance, exact staff fluctuation through issuance and revocation of employee IDs. We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade. Padding is used to provide deniability for issuer metrics. Issuers periodically publish this filter cascade on a decentralized storage system. Relying Parties (RPs) can download it to perform any number of revocation checks locally. Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally. At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications. We present a prototype using the Ethereum blockchain as decentralized storage. The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain. We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols. Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades.","sentences":["Like any digital certificate, Verifiable Credentials (VCs) require a way to revoke them in case of an error or key compromise.","Existing solutions for VC revocation, most prominently Bitstring Status List, are not viable for many use cases since they leak the issuer's behavior, which in turn leaks internal business metrics.","For instance, exact staff fluctuation through issuance and revocation of employee IDs.","We introduce CRSet, a revocation mechanism that allows an issuer to encode revocation information for years worth of VCs as a Bloom filter cascade.","Padding is used to provide deniability for issuer metrics.","Issuers periodically publish this filter cascade on a decentralized storage system.","Relying Parties (RPs) can download it to perform any number of revocation checks locally.","Compared to existing solutions, CRSet protects the metadata of subject, RPs, and issuer equally.","At the same time, it is non-interactive, making it work with wallet devices having limited hardware power and drop-in compatible with existing VC exchange protocols and wallet applications.","We present a prototype using the Ethereum blockchain as decentralized storage.","The recently introduced blob-carrying transactions, enabling cheaper data writes, allow us to write each CRSet directly to the chain.","We built software for issuers and RPs that we successfully tested end-to-end with an existing publicly available wallet agents and the OpenID for Verifiable Credentials protocols.","Storage and bandwidth costs paid by issuers and RP are higher than for Bitstring Status List, but still manageable at around 1 MB for an issuer issuing hundreds of thousands of VCs annually and covering decades."],"url":"http://arxiv.org/abs/2501.17089v1"}
{"created":"2025-01-28 17:22:01","title":"Mamba-Shedder: Post-Transformer Compression for Efficient Selective Structured State Space Models","abstract":"Large pre-trained models have achieved outstanding results in sequence modeling. The Transformer block and its attention mechanism have been the main drivers of the success of these models. Recently, alternative architectures, such as Selective Structured State Space Models (SSMs), have been proposed to address the inefficiencies of Transformers. This paper explores the compression of SSM-based models, particularly Mamba and its hybrids. We study the sensitivity of these models to the removal of selected components at different granularities to reduce the model size and computational overhead, thus improving their efficiency while maintaining accuracy. The proposed solutions, collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x during inference, demonstrating that model efficiency can be improved by eliminating several redundancies with minimal impact on the overall model performance. The code is available at https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning.","sentences":["Large pre-trained models have achieved outstanding results in sequence modeling.","The Transformer block and its attention mechanism have been the main drivers of the success of these models.","Recently, alternative architectures, such as Selective Structured State Space Models (SSMs), have been proposed to address the inefficiencies of Transformers.","This paper explores the compression of SSM-based models, particularly Mamba and its hybrids.","We study the sensitivity of these models to the removal of selected components at different granularities to reduce the model size and computational overhead, thus improving their efficiency while maintaining accuracy.","The proposed solutions, collectively referred to as Mamba-Shedder, achieve a speedup of up to 1.4x during inference, demonstrating that model efficiency can be improved by eliminating several redundancies with minimal impact on the overall model performance.","The code is available at https://github.com/IntelLabs/Hardware-Aware-Automated-Machine-Learning."],"url":"http://arxiv.org/abs/2501.17088v1"}
{"created":"2025-01-28 17:14:42","title":"Accelerated Training through Iterative Gradient Propagation Along the Residual Path","abstract":"Despite being the cornerstone of deep learning, backpropagation is criticized for its inherent sequentiality, which can limit the scalability of very deep models. Such models faced convergence issues due to vanishing gradient, later resolved using residual connections. Variants of these are now widely used in modern architecture. However, the computational cost of backpropagation remains a major burden, accounting for most of the training time. Taking advantage of residual-like architectural designs, we introduce Highway backpropagation, a parallelizable iterative algorithm that approximates backpropagation, by alternatively i) accumulating the gradient estimates along the residual path, and ii) backpropagating them through every layer in parallel. This algorithm is naturally derived from a decomposition of the gradient as the sum of gradients flowing through all paths and is adaptable to a diverse set of common architectures, ranging from ResNets and Transformers to recurrent neural networks. Through an extensive empirical study on a large selection of tasks and models, we evaluate Highway-BP and show that major speedups can be achieved with minimal performance degradation.","sentences":["Despite being the cornerstone of deep learning, backpropagation is criticized for its inherent sequentiality, which can limit the scalability of very deep models.","Such models faced convergence issues due to vanishing gradient, later resolved using residual connections.","Variants of these are now widely used in modern architecture.","However, the computational cost of backpropagation remains a major burden, accounting for most of the training time.","Taking advantage of residual-like architectural designs, we introduce Highway backpropagation, a parallelizable iterative algorithm that approximates backpropagation, by alternatively i) accumulating the gradient estimates along the residual path, and ii) backpropagating them through every layer in parallel.","This algorithm is naturally derived from a decomposition of the gradient as the sum of gradients flowing through all paths and is adaptable to a diverse set of common architectures, ranging from ResNets and Transformers to recurrent neural networks.","Through an extensive empirical study on a large selection of tasks and models, we evaluate Highway-BP and show that major speedups can be achieved with minimal performance degradation."],"url":"http://arxiv.org/abs/2501.17086v1"}
{"created":"2025-01-28 17:14:13","title":"Evaluating CrowdSplat: Perceived Level of Detail for Gaussian Crowds","abstract":"Efficient and realistic crowd rendering is an important element of many real-time graphics applications such as Virtual Reality (VR) and games. To this end, Levels of Detail (LOD) avatar representations such as polygonal meshes, image-based impostors, and point clouds have been proposed and evaluated. More recently, 3D Gaussian Splatting has been explored as a potential method for real-time crowd rendering. In this paper, we present a two-alternative forced choice (2AFC) experiment that aims to determine the perceived quality of 3D Gaussian avatars. Three factors were explored: Motion, LOD (i.e., #Gaussians), and the avatar height in Pixels (corresponding to the viewing distance). Participants viewed pairs of animated 3D Gaussian avatars and were tasked with choosing the most detailed one. Our findings can inform the optimization of LOD strategies in Gaussian-based crowd rendering, thereby helping to achieve efficient rendering while maintaining visual quality in real-time applications.","sentences":["Efficient and realistic crowd rendering is an important element of many real-time graphics applications such as Virtual Reality (VR) and games.","To this end, Levels of Detail (LOD) avatar representations such as polygonal meshes, image-based impostors, and point clouds have been proposed and evaluated.","More recently, 3D Gaussian Splatting has been explored as a potential method for real-time crowd rendering.","In this paper, we present a two-alternative forced choice (2AFC) experiment that aims to determine the perceived quality of 3D Gaussian avatars.","Three factors were explored: Motion, LOD (i.e., #Gaussians), and the avatar height in Pixels (corresponding to the viewing distance).","Participants viewed pairs of animated 3D Gaussian avatars and were tasked with choosing the most detailed one.","Our findings can inform the optimization of LOD strategies in Gaussian-based crowd rendering, thereby helping to achieve efficient rendering while maintaining visual quality in real-time applications."],"url":"http://arxiv.org/abs/2501.17085v1"}
{"created":"2025-01-28 17:11:36","title":"Token-by-Token Regeneration and Domain Biases: A Benchmark of LLMs on Advanced Mathematical Problem-Solving","abstract":"Large language models (LLMs) excel in many natural language tasks, yet they struggle with complex mathemat-ical problem-solving, particularly in symbolic reasoning and maintaining consistent output. This study evalu-ates 10 LLMs with 7 to 8 billion parameters using 945 competition-level problems from the MATH dataset. The focus is on their ability to generate executable Python code as a step in their reasoning process, involving over 9,450 code executions. The research introduces an evaluation framework using mistral-large-2411 to rate answers on a 5-point scale, which helps address inconsistencies in mathematical notation. It also examines the impact of regenerating output token-by-token on refining results. The findings reveal a significant 34.5% per-formance gap between the top commercial model (gpt-4o-mini, scoring 83.7%) and the least effective open-source model (open-codestral-mamba:v0.1, scoring 49.2%). This disparity is especially noticeable in complex areas like Number Theory. While token-by-token regeneration slightly improved accuracy (+0.8%) for the model llama3.1:8b, it also reduced code execution time by 36.7%, highlighting a trade-off between efficiency and precision. The study also noted a consistent trend where harder problems correlated with lower accuracy across all models. Despite using controlled execution environments, less than 1% of the generated code was unsafe, and 3.17% of problems remained unsolved after 10 attempts, suggesting that hybrid reasoning methods may be beneficial.","sentences":["Large language models (LLMs) excel in many natural language tasks, yet they struggle with complex mathemat-ical problem-solving, particularly in symbolic reasoning and maintaining consistent output.","This study evalu-ates 10 LLMs with 7 to 8 billion parameters using 945 competition-level problems from the MATH dataset.","The focus is on their ability to generate executable Python code as a step in their reasoning process, involving over 9,450 code executions.","The research introduces an evaluation framework using mistral-large-2411 to rate answers on a 5-point scale, which helps address inconsistencies in mathematical notation.","It also examines the impact of regenerating output token-by-token on refining results.","The findings reveal a significant 34.5% per-formance gap between the top commercial model (gpt-4o-mini, scoring 83.7%) and the least effective open-source model (open-codestral-mamba:v0.1, scoring 49.2%).","This disparity is especially noticeable in complex areas like Number Theory.","While token-by-token regeneration slightly improved accuracy (+0.8%) for the model llama3.1:8b, it also reduced code execution time by 36.7%, highlighting a trade-off between efficiency and precision.","The study also noted a consistent trend where harder problems correlated with lower accuracy across all models.","Despite using controlled execution environments, less than 1% of the generated code was unsafe, and 3.17% of problems remained unsolved after 10 attempts, suggesting that hybrid reasoning methods may be beneficial."],"url":"http://arxiv.org/abs/2501.17084v1"}
{"created":"2025-01-28 17:06:09","title":"Graph Transformers for inverse physics: reconstructing flows around arbitrary 2D airfoils","abstract":"We introduce a Graph Transformer framework that serves as a general inverse physics engine on meshes, demonstrated through the challenging task of reconstructing aerodynamic flow fields from sparse surface measurements. While deep learning has shown promising results in forward physics simulation, inverse problems remain particularly challenging due to their ill-posed nature and the difficulty of propagating information from limited boundary observations. Our approach addresses these challenges by combining the geometric expressiveness of message-passing neural networks with the global reasoning of Transformers, enabling efficient learning of inverse mappings from boundary conditions to complete states. We evaluate this framework on a comprehensive dataset of steady-state RANS simulations around diverse airfoil geometries, where the task is to reconstruct full pressure and velocity fields from surface pressure measurements alone. The architecture achieves high reconstruction accuracy while maintaining fast inference times. We conduct experiments and provide insights into the relative importance of local geometric processing and global attention mechanisms in mesh-based inverse problems. We also find that the framework is robust to reduced sensor coverage. These results suggest that Graph Transformers can serve as effective inverse physics engines across a broader range of applications where complete system states must be reconstructed from limited boundary observations.","sentences":["We introduce a Graph Transformer framework that serves as a general inverse physics engine on meshes, demonstrated through the challenging task of reconstructing aerodynamic flow fields from sparse surface measurements.","While deep learning has shown promising results in forward physics simulation, inverse problems remain particularly challenging due to their ill-posed nature and the difficulty of propagating information from limited boundary observations.","Our approach addresses these challenges by combining the geometric expressiveness of message-passing neural networks with the global reasoning of Transformers, enabling efficient learning of inverse mappings from boundary conditions to complete states.","We evaluate this framework on a comprehensive dataset of steady-state RANS simulations around diverse airfoil geometries, where the task is to reconstruct full pressure and velocity fields from surface pressure measurements alone.","The architecture achieves high reconstruction accuracy while maintaining fast inference times.","We conduct experiments and provide insights into the relative importance of local geometric processing and global attention mechanisms in mesh-based inverse problems.","We also find that the framework is robust to reduced sensor coverage.","These results suggest that Graph Transformers can serve as effective inverse physics engines across a broader range of applications where complete system states must be reconstructed from limited boundary observations."],"url":"http://arxiv.org/abs/2501.17081v1"}
{"created":"2025-01-28 17:03:30","title":"Learning Mean Field Control on Sparse Graphs","abstract":"Large agent networks are abundant in applications and nature and pose difficult challenges in the field of multi-agent reinforcement learning (MARL) due to their computational and theoretical complexity. While graphon mean field games and their extensions provide efficient learning algorithms for dense and moderately sparse agent networks, the case of realistic sparser graphs remains largely unsolved. Thus, we propose a novel mean field control model inspired by local weak convergence to include sparse graphs such as power law networks with coefficients above two. Besides a theoretical analysis, we design scalable learning algorithms which apply to the challenging class of graph sequences with finite first moment. We compare our model and algorithms for various examples on synthetic and real world networks with mean field algorithms based on Lp graphons and graphexes. As it turns out, our approach outperforms existing methods in many examples and on various networks due to the special design aiming at an important, but so far hard to solve class of MARL problems.","sentences":["Large agent networks are abundant in applications and nature and pose difficult challenges in the field of multi-agent reinforcement learning (MARL) due to their computational and theoretical complexity.","While graphon mean field games and their extensions provide efficient learning algorithms for dense and moderately sparse agent networks, the case of realistic sparser graphs remains largely unsolved.","Thus, we propose a novel mean field control model inspired by local weak convergence to include sparse graphs such as power law networks with coefficients above two.","Besides a theoretical analysis, we design scalable learning algorithms which apply to the challenging class of graph sequences with finite first moment.","We compare our model and algorithms for various examples on synthetic and real world networks with mean field algorithms based on Lp graphons and graphexes.","As it turns out, our approach outperforms existing methods in many examples and on various networks due to the special design aiming at an important, but so far hard to solve class of MARL problems."],"url":"http://arxiv.org/abs/2501.17079v1"}
{"created":"2025-01-28 17:02:16","title":"Induced Modularity and Community Detection for Functionally Interpretable Reinforcement Learning","abstract":"Interpretability in reinforcement learning is crucial for ensuring AI systems align with human values and fulfill the diverse related requirements including safety, robustness and fairness. Building on recent approaches to encouraging sparsity and locality in neural networks, we demonstrate how the penalisation of non-local weights leads to the emergence of functionally independent modules in the policy network of a reinforcement learning agent. To illustrate this, we demonstrate the emergence of two parallel modules for assessment of movement along the X and Y axes in a stochastic Minigrid environment. Through the novel application of community detection algorithms, we show how these modules can be automatically identified and their functional roles verified through direct intervention on the network weights prior to inference. This establishes a scalable framework for reinforcement learning interpretability through functional modularity, addressing challenges regarding the trade-off between completeness and cognitive tractability of reinforcement learning explanations.","sentences":["Interpretability in reinforcement learning is crucial for ensuring AI systems align with human values and fulfill the diverse related requirements including safety, robustness and fairness.","Building on recent approaches to encouraging sparsity and locality in neural networks, we demonstrate how the penalisation of non-local weights leads to the emergence of functionally independent modules in the policy network of a reinforcement learning agent.","To illustrate this, we demonstrate the emergence of two parallel modules for assessment of movement along the X and Y axes in a stochastic Minigrid environment.","Through the novel application of community detection algorithms, we show how these modules can be automatically identified and their functional roles verified through direct intervention on the network weights prior to inference.","This establishes a scalable framework for reinforcement learning interpretability through functional modularity, addressing challenges regarding the trade-off between completeness and cognitive tractability of reinforcement learning explanations."],"url":"http://arxiv.org/abs/2501.17077v1"}
{"created":"2025-01-28 17:01:42","title":"DINOSTAR: Deep Iterative Neural Object Detector Self-Supervised Training for Roadside LiDAR Applications","abstract":"Recent advancements in deep-learning methods for object detection in point-cloud data have enabled numerous roadside applications, fostering improvements in transportation safety and management. However, the intricate nature of point-cloud data poses significant challenges for human-supervised labeling, resulting in substantial expenditures of time and capital. This paper addresses the issue by developing an end-to-end, scalable, and self-supervised framework for training deep object detectors tailored for roadside point-cloud data. The proposed framework leverages self-supervised, statistically modeled teachers to train off-the-shelf deep object detectors, thus circumventing the need for human supervision. The teacher models follow fine-tuned set standard practices of background filtering, object clustering, bounding-box fitting, and classification to generate noisy labels. It is presented that by training the student model over the combined noisy annotations from multitude of teachers enhances its capacity to discern background/foreground more effectively and forces it to learn diverse point-cloud-representations for object categories of interest. The evaluations, involving publicly available roadside datasets and state-of-art deep object detectors, demonstrate that the proposed framework achieves comparable performance to deep object detectors trained on human-annotated labels, despite not utilizing such human-annotations in its training process.","sentences":["Recent advancements in deep-learning methods for object detection in point-cloud data have enabled numerous roadside applications, fostering improvements in transportation safety and management.","However, the intricate nature of point-cloud data poses significant challenges for human-supervised labeling, resulting in substantial expenditures of time and capital.","This paper addresses the issue by developing an end-to-end, scalable, and self-supervised framework for training deep object detectors tailored for roadside point-cloud data.","The proposed framework leverages self-supervised, statistically modeled teachers to train off-the-shelf deep object detectors, thus circumventing the need for human supervision.","The teacher models follow fine-tuned set standard practices of background filtering, object clustering, bounding-box fitting, and classification to generate noisy labels.","It is presented that by training the student model over the combined noisy annotations from multitude of teachers enhances its capacity to discern background/foreground more effectively and forces it to learn diverse point-cloud-representations for object categories of interest.","The evaluations, involving publicly available roadside datasets and state-of-art deep object detectors, demonstrate that the proposed framework achieves comparable performance to deep object detectors trained on human-annotated labels, despite not utilizing such human-annotations in its training process."],"url":"http://arxiv.org/abs/2501.17076v1"}
{"created":"2025-01-28 16:58:45","title":"DataLens: ML-Oriented Interactive Tabular Data Quality Dashboard","abstract":"Maintaining high data quality is crucial for reliable data analysis and machine learning (ML). However, existing data quality management tools often lack automation, interactivity, and integration with ML workflows. This demonstration paper introduces DataLens, a novel interactive dashboard designed to streamline and automate the data quality management process for tabular data. DataLens integrates a suite of data profiling, error detection, and repair tools, including statistical, rule-based, and ML-based methods. It features a user-in-the-loop module for interactive rule validation, data labeling, and custom rule definition, enabling domain experts to guide the cleaning process. Furthermore, DataLens implements an iterative cleaning module that automatically selects optimal cleaning tools based on downstream ML model performance. To ensure reproducibility, DataLens generates DataSheets capturing essential metadata and integrates with MLflow and Delta Lake for experiment tracking and data version control. This demonstration showcases DataLens's capabilities in effectively identifying and correcting data errors, improving data quality for downstream tasks, and promoting reproducibility in data cleaning pipelines.","sentences":["Maintaining high data quality is crucial for reliable data analysis and machine learning (ML).","However, existing data quality management tools often lack automation, interactivity, and integration with ML workflows.","This demonstration paper introduces DataLens, a novel interactive dashboard designed to streamline and automate the data quality management process for tabular data.","DataLens integrates a suite of data profiling, error detection, and repair tools, including statistical, rule-based, and ML-based methods.","It features a user-in-the-loop module for interactive rule validation, data labeling, and custom rule definition, enabling domain experts to guide the cleaning process.","Furthermore, DataLens implements an iterative cleaning module that automatically selects optimal cleaning tools based on downstream ML model performance.","To ensure reproducibility, DataLens generates DataSheets capturing essential metadata and integrates with MLflow and Delta Lake for experiment tracking and data version control.","This demonstration showcases DataLens's capabilities in effectively identifying and correcting data errors, improving data quality for downstream tasks, and promoting reproducibility in data cleaning pipelines."],"url":"http://arxiv.org/abs/2501.17074v1"}
{"created":"2025-01-28 16:55:39","title":"Context is Key in Agent Security","abstract":"Judging the safety of an action, whether taken by a human or a system, must take into account the context in which the action takes place. Deleting an email from user's mailbox may or may not be appropriate depending on email's content, user's goals, or even available space. Systems today that make these judgements -- providing security against harmful or inappropriate actions -- rely on manually-crafted policies or user confirmation for each relevant context. With the upcoming deployment of systems like generalist agents, we argue that we must rethink security designs to adapt to the scale of contexts and capabilities of these systems. As a first step, this paper explores contextual security in the domain of agents and proposes contextual security for agents (Conseca), a framework to generate just-in-time, contextual, and human-verifiable security policies.","sentences":["Judging the safety of an action, whether taken by a human or a system, must take into account the context in which the action takes place.","Deleting an email from user's mailbox may or may not be appropriate depending on email's content, user's goals, or even available space.","Systems today that make these judgements -- providing security against harmful or inappropriate actions -- rely on manually-crafted policies or user confirmation for each relevant context.","With the upcoming deployment of systems like generalist agents, we argue that we must rethink security designs to adapt to the scale of contexts and capabilities of these systems.","As a first step, this paper explores contextual security in the domain of agents and proposes contextual security for agents (Conseca), a framework to generate just-in-time, contextual, and human-verifiable security policies."],"url":"http://arxiv.org/abs/2501.17070v1"}
{"created":"2025-01-28 16:40:40","title":"EdgeMLOps: Operationalizing ML models with Cumulocity IoT and thin-edge.io for Visual quality Inspection","abstract":"This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and thin-edge.io for deploying and managing machine learning models on resource-constrained edge devices. We address the challenges of model optimization, deployment, and lifecycle management in edge environments. The framework's efficacy is demonstrated through a visual quality inspection (VQI) use case where images of assets are processed on edge devices, enabling real-time condition updates within an asset management system. Furthermore, we evaluate the performance benefits of different quantization methods, specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating significant inference time reductions compared to FP32 precision. Our results highlight the potential of EdgeMLOps to enable efficient and scalable AI deployments at the edge for industrial applications.","sentences":["This paper introduces EdgeMLOps, a framework leveraging Cumulocity IoT and thin-edge.io for deploying and managing machine learning models on resource-constrained edge devices.","We address the challenges of model optimization, deployment, and lifecycle management in edge environments.","The framework's efficacy is demonstrated through a visual quality inspection (VQI) use case where images of assets are processed on edge devices, enabling real-time condition updates within an asset management system.","Furthermore, we evaluate the performance benefits of different quantization methods, specifically static and dynamic signed-int8, on a Raspberry Pi 4, demonstrating significant inference time reductions compared to FP32 precision.","Our results highlight the potential of EdgeMLOps to enable efficient and scalable AI deployments at the edge for industrial applications."],"url":"http://arxiv.org/abs/2501.17062v1"}
{"created":"2025-01-28 16:38:13","title":"The sorrows of a smooth digraph: the first hardness criterion for infinite directed graph-colouring problems","abstract":"Two major milestones on the road to the full complexity dichotomy for finite-domain constraint satisfaction problems were Bulatov's proof of the dichotomy for conservative templates, and the structural dichotomy for smooth digraphs of algebraic length 1 due to Barto, Kozik, and Niven. We lift the combined scenario to the infinite, and prove that any smooth digraph of algebraic length 1 pp-constructs, together with pairs of orbits of an oligomorphic subgroup of its automorphism group, every finite structure -- and hence its conservative graph-colouring problem is NP-hard -- unless the digraph has a pseudo-loop, i.e. an edge within an orbit. We thereby overcome, for the first time, previous obstacles to lifting structural results for digraphs in this context from finite to $\\omega$-categorical structures; the strongest lifting results hitherto not going beyond a generalisation of the Hell-Ne\\v{s}et\\v{r}il theorem for undirected graphs. As a consequence, we obtain a new algebraic invariant of arbitrary $\\omega$-categorical structures enriched by pairs of orbits which fail to pp-construct some finite structure.","sentences":["Two major milestones on the road to the full complexity dichotomy for finite-domain constraint satisfaction problems were Bulatov's proof of the dichotomy for conservative templates, and the structural dichotomy for smooth digraphs of algebraic length 1 due to Barto, Kozik, and Niven.","We lift the combined scenario to the infinite, and prove that any smooth digraph of algebraic length 1 pp-constructs, together with pairs of orbits of an oligomorphic subgroup of its automorphism group, every finite structure -- and hence its conservative graph-colouring problem is NP-hard -- unless the digraph has a pseudo-loop, i.e. an edge within an orbit.","We thereby overcome, for the first time, previous obstacles to lifting structural results for digraphs in this context from finite to $\\omega$-categorical structures; the strongest lifting results hitherto not going beyond a generalisation of the Hell-Ne\\v{s}et\\v{r}il theorem for undirected graphs.","As a consequence, we obtain a new algebraic invariant of arbitrary $\\omega$-categorical structures enriched by pairs of orbits which fail to pp-construct some finite structure."],"url":"http://arxiv.org/abs/2501.17060v1"}
{"created":"2025-01-28 16:36:05","title":"Channel Estimation for XL-MIMO Systems with Decentralized Baseband Processing: Integrating Local Reconstruction with Global Refinement","abstract":"In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology. Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance. To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement. Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem. To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy. In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU). Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem. To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain. Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity.","sentences":["In this paper, we investigate the channel estimation problem for extremely large-scale multiple-input multiple-output (XL-MIMO) systems with a hybrid analog-digital architecture, implemented within a decentralized baseband processing (DBP) framework with a star topology.","Existing centralized and fully decentralized channel estimation methods face limitations due to excessive computational complexity or degraded performance.","To overcome these challenges, we propose a novel two-stage channel estimation scheme that integrates local sparse reconstruction with global fusion and refinement.","Specifically, in the first stage, by exploiting the sparsity of channels in the angular-delay domain, the local reconstruction task is formulated as a sparse signal recovery problem.","To solve it, we develop a graph neural networks-enhanced sparse Bayesian learning (SBL-GNNs) algorithm, which effectively captures dependencies among channel coefficients, significantly improving estimation accuracy.","In the second stage, the local estimates from the local processing units (LPUs) are aligned into a global angular domain for fusion at the central processing unit (CPU).","Based on the aggregated observations, the channel refinement is modeled as a Bayesian denoising problem.","To efficiently solve it, we devise a variational message passing algorithm that incorporates a Markov chain-based hierarchical sparse prior, effectively leveraging both the sparsity and the correlations of the channels in the global angular-delay domain.","Simulation results validate the effectiveness and superiority of the proposed SBL-GNNs algorithm over existing methods, demonstrating improved estimation performance and reduced computational complexity."],"url":"http://arxiv.org/abs/2501.17059v1"}
{"created":"2025-01-28 16:25:10","title":"Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal Video Grounding","abstract":"In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding (WSTVG). It is a multimodal task aimed at localizing specific subjects spatio-temporally based on textual queries without bounding box supervision. Motivated by recent advancements in multi-modal foundation models for grounding tasks, we first explore the potential of state-of-the-art object detection models for WSTVG. Despite their robust zero-shot capabilities, our adaptation reveals significant limitations, including inconsistent temporal predictions, inadequate understanding of complex queries, and challenges in adapting to difficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), a novel approach which is designed to overcome these limitations. CoSPaL integrates three core components: (1) Tubelet Phrase Grounding (TPG), which introduces spatio-temporal prediction by linking textual queries to tubelets; (2) Contextual Referral Grounding (CRG), which improves comprehension of complex queries by extracting contextual information to refine object identification over time; and (3) Self-Paced Scene Understanding (SPS), a training paradigm that progressively increases task difficulty, enabling the model to adapt to complex scenarios by transitioning from coarse to fine-grained understanding.","sentences":["In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding (WSTVG).","It is a multimodal task aimed at localizing specific subjects spatio-temporally based on textual queries without bounding box supervision.","Motivated by recent advancements in multi-modal foundation models for grounding tasks, we first explore the potential of state-of-the-art object detection models for WSTVG.","Despite their robust zero-shot capabilities, our adaptation reveals significant limitations, including inconsistent temporal predictions, inadequate understanding of complex queries, and challenges in adapting to difficult scenarios.","We propose CoSPaL (Contextual Self-Paced Learning), a novel approach which is designed to overcome these limitations.","CoSPaL integrates three core components: (1) Tubelet Phrase Grounding (TPG), which introduces spatio-temporal prediction by linking textual queries to tubelets; (2) Contextual Referral Grounding (CRG), which improves comprehension of complex queries by extracting contextual information to refine object identification over time; and (3) Self-Paced Scene Understanding (SPS), a training paradigm that progressively increases task difficulty, enabling the model to adapt to complex scenarios by transitioning from coarse to fine-grained understanding."],"url":"http://arxiv.org/abs/2501.17053v1"}
{"created":"2025-01-28 16:13:19","title":"How Linguistics Learned to Stop Worrying and Love the Language Models","abstract":"Language models can produce fluent, grammatical text. Nonetheless, some maintain that language models don't really learn language and also that, even if they did, that would not be informative for the study of human learning and processing. On the other side, there have been claims that the success of LMs obviates the need for studying linguistic theory and structure. We argue that both extremes are wrong. LMs can contribute to fundamental questions about linguistic structure, language processing, and learning. They force us to rethink arguments about learning and are informative for major questions in linguistic theory. But they do not replace linguistic structure and theory. We offer an optimistic take on the relationship between language models and linguistics.","sentences":["Language models can produce fluent, grammatical text.","Nonetheless, some maintain that language models don't really learn language and also that, even if they did, that would not be informative for the study of human learning and processing.","On the other side, there have been claims that the success of LMs obviates the need for studying linguistic theory and structure.","We argue that both extremes are wrong.","LMs can contribute to fundamental questions about linguistic structure, language processing, and learning.","They force us to rethink arguments about learning and are informative for major questions in linguistic theory.","But they do not replace linguistic structure and theory.","We offer an optimistic take on the relationship between language models and linguistics."],"url":"http://arxiv.org/abs/2501.17047v1"}
{"created":"2025-01-28 16:09:34","title":"Synthesizing 3D Abstractions by Inverting Procedural Buildings with Transformers","abstract":"We generate abstractions of buildings, reflecting the essential aspects of their geometry and structure, by learning to invert procedural models. We first build a dataset of abstract procedural building models paired with simulated point clouds and then learn the inverse mapping through a transformer. Given a point cloud, the trained transformer then infers the corresponding abstracted building in terms of a programmatic language description. This approach leverages expressive procedural models developed for gaming and animation, and thereby retains desirable properties such as efficient rendering of the inferred abstractions and strong priors for regularity and symmetry. Our approach achieves good reconstruction accuracy in terms of geometry and structure, as well as structurally consistent inpainting.","sentences":["We generate abstractions of buildings, reflecting the essential aspects of their geometry and structure, by learning to invert procedural models.","We first build a dataset of abstract procedural building models paired with simulated point clouds and then learn the inverse mapping through a transformer.","Given a point cloud, the trained transformer then infers the corresponding abstracted building in terms of a programmatic language description.","This approach leverages expressive procedural models developed for gaming and animation, and thereby retains desirable properties such as efficient rendering of the inferred abstractions and strong priors for regularity and symmetry.","Our approach achieves good reconstruction accuracy in terms of geometry and structure, as well as structurally consistent inpainting."],"url":"http://arxiv.org/abs/2501.17044v1"}
{"created":"2025-01-28 16:03:52","title":"Enhanced Retrieval of Long Documents: Leveraging Fine-Grained Block Representations with Large Language Models","abstract":"In recent years, large language models (LLMs) have demonstrated exceptional power in various domains, including information retrieval. Most of the previous practices involve leveraging these models to create a single embedding for each query, each passage, or each document individually, a strategy exemplified and used by the Retrieval-Augmented Generation (RAG) framework. While this method has proven effective, we argue that it falls short in fully capturing the nuanced intricacies of document-level texts due to its reliance on a relatively coarse-grained representation. To address this limitation, we introduce a novel, fine-grained approach aimed at enhancing the accuracy of relevance scoring for long documents. Our methodology firstly segments a long document into blocks, each of which is embedded using an LLM, for matching with the query representation. When calculating the relevance score, we aggregate the query-block relevance scores through a weighted sum method, yielding a comprehensive score for the query with the entire document. Despite its apparent simplicity, our experimental findings reveal that this approach outperforms standard representation methods and achieves a significant reduction in embedding generation latency. Moreover, by carefully optimizing pairwise loss functions, superior performances have been achieved.","sentences":["In recent years, large language models (LLMs) have demonstrated exceptional power in various domains, including information retrieval.","Most of the previous practices involve leveraging these models to create a single embedding for each query, each passage, or each document individually, a strategy exemplified and used by the Retrieval-Augmented Generation (RAG) framework.","While this method has proven effective, we argue that it falls short in fully capturing the nuanced intricacies of document-level texts due to its reliance on a relatively coarse-grained representation.","To address this limitation, we introduce a novel, fine-grained approach aimed at enhancing the accuracy of relevance scoring for long documents.","Our methodology firstly segments a long document into blocks, each of which is embedded using an LLM, for matching with the query representation.","When calculating the relevance score, we aggregate the query-block relevance scores through a weighted sum method, yielding a comprehensive score for the query with the entire document.","Despite its apparent simplicity, our experimental findings reveal that this approach outperforms standard representation methods and achieves a significant reduction in embedding generation latency.","Moreover, by carefully optimizing pairwise loss functions, superior performances have been achieved."],"url":"http://arxiv.org/abs/2501.17039v1"}
{"created":"2025-01-28 15:59:01","title":"Standardised schema and taxonomy for AI incident databases in critical digital infrastructure","abstract":"The rapid deployment of Artificial Intelligence (AI) in critical digital infrastructure introduces significant risks, necessitating a robust framework for systematically collecting AI incident data to prevent future incidents. Existing databases lack the granularity as well as the standardized structure required for consistent data collection and analysis, impeding effective incident management. This work proposes a standardized schema and taxonomy for AI incident databases, addressing these challenges by enabling detailed and structured documentation of AI incidents across sectors. Key contributions include developing a unified schema, introducing new fields such as incident severity, causes, and harms caused, and proposing a taxonomy for classifying AI incidents in critical digital infrastructure. The proposed solution facilitates more effective incident data collection and analysis, thus supporting evidence-based policymaking, enhancing industry safety measures, and promoting transparency. This work lays the foundation for a coordinated global response to AI incidents, ensuring trust, safety, and accountability in using AI across regions.","sentences":["The rapid deployment of Artificial Intelligence (AI) in critical digital infrastructure introduces significant risks, necessitating a robust framework for systematically collecting AI incident data to prevent future incidents.","Existing databases lack the granularity as well as the standardized structure required for consistent data collection and analysis, impeding effective incident management.","This work proposes a standardized schema and taxonomy for AI incident databases, addressing these challenges by enabling detailed and structured documentation of AI incidents across sectors.","Key contributions include developing a unified schema, introducing new fields such as incident severity, causes, and harms caused, and proposing a taxonomy for classifying AI incidents in critical digital infrastructure.","The proposed solution facilitates more effective incident data collection and analysis, thus supporting evidence-based policymaking, enhancing industry safety measures, and promoting transparency.","This work lays the foundation for a coordinated global response to AI incidents, ensuring trust, safety, and accountability in using AI across regions."],"url":"http://arxiv.org/abs/2501.17037v1"}
{"created":"2025-01-28 15:52:51","title":"Challenges in Ensuring AI Safety in DeepSeek-R1 Models: The Shortcomings of Reinforcement Learning Strategies","abstract":"Large Language Models (LLMs) have achieved remarkable progress in reasoning, alignment, and task-specific performance. However, ensuring harmlessness in these systems remains a critical challenge, particularly in advanced models like DeepSeek-R1. This paper examines the limitations of Reinforcement Learning (RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and compares it with Supervised Fine-Tuning (SFT). While RL improves reasoning capabilities, it faces challenges such as reward hacking, generalization failures, language mixing, and high computational costs. We propose hybrid training approaches combining RL and SFT to achieve robust harmlessness reduction. Usage recommendations and future directions for deploying DeepSeek-R1 responsibly are also presented.","sentences":["Large Language Models (LLMs) have achieved remarkable progress in reasoning, alignment, and task-specific performance.","However, ensuring harmlessness in these systems remains a critical challenge, particularly in advanced models like DeepSeek-R1.","This paper examines the limitations of Reinforcement Learning (RL) as the primary approach for reducing harmful outputs in DeepSeek-R1 and compares it with Supervised Fine-Tuning (SFT).","While RL improves reasoning capabilities, it faces challenges such as reward hacking, generalization failures, language mixing, and high computational costs.","We propose hybrid training approaches combining RL and SFT to achieve robust harmlessness reduction.","Usage recommendations and future directions for deploying DeepSeek-R1 responsibly are also presented."],"url":"http://arxiv.org/abs/2501.17030v1"}
{"created":"2025-01-28 15:49:51","title":"Approach Towards Semi-Automated Certification for Low Criticality ML-Enabled Airborne Applications","abstract":"As Machine Learning (ML) makes its way into aviation, ML enabled systems including low criticality systems require a reliable certification process to ensure safety and performance. Traditional standards, like DO 178C, which are used for critical software in aviation, do not fully cover the unique aspects of ML. This paper proposes a semi automated certification approach, specifically for low criticality ML systems, focusing on data and model validation, resilience assessment, and usability assurance while integrating manual and automated processes. Key aspects include structured classification to guide certification rigor on system attributes, an Assurance Profile that consolidates evaluation outcomes into a confidence measure the ML component, and methodologies for integrating human oversight into certification activities. Through a case study with a YOLOv8 based object detection system designed to classify military and civilian vehicles in real time for reconnaissance and surveillance aircraft, we show how this approach supports the certification of ML systems in low criticality airborne applications.","sentences":["As Machine Learning (ML) makes its way into aviation, ML enabled systems including low criticality systems require a reliable certification process to ensure safety and performance.","Traditional standards, like DO 178C, which are used for critical software in aviation, do not fully cover the unique aspects of ML.","This paper proposes a semi automated certification approach, specifically for low criticality ML systems, focusing on data and model validation, resilience assessment, and usability assurance while integrating manual and automated processes.","Key aspects include structured classification to guide certification rigor on system attributes, an Assurance Profile that consolidates evaluation outcomes into a confidence measure the ML component, and methodologies for integrating human oversight into certification activities.","Through a case study with a YOLOv8 based object detection system designed to classify military and civilian vehicles in real time for reconnaissance and surveillance aircraft, we show how this approach supports the certification of ML systems in low criticality airborne applications."],"url":"http://arxiv.org/abs/2501.17028v1"}
{"created":"2025-01-28 15:43:46","title":"Mitigating Omitted Variable Bias in Empirical Software Engineering","abstract":"Omitted variable bias occurs when a statistical model leaves out variables that are relevant determinants of the effects under study. This results in the model attributing the missing variables' effect to some of the included variables -- hence over- or under-estimating the latter's true effect. Omitted variable bias presents a significant threat to the validity of empirical research, particularly in non-experimental studies such as those prevalent in empirical software engineering.   This paper illustrates the impact of omitted variable bias on two case studies in the software engineering domain, and uses them to present methods to investigate the possible presence of omitted variable bias, to estimate its impact, and to mitigate its drawbacks. The analysis techniques we present are based on causal structural models of the variables of interest, which provide a practical, intuitive summary of the key relations among variables.   This paper demonstrates a sequence of analysis steps that inform the design and execution of any empirical study in software engineering. An important observation is that it pays off to invest effort investigating omitted variable bias before actually executing an empirical study, because this effort can lead to a more solid study design, and to a significant reduction in its threats to validity.","sentences":["Omitted variable bias occurs when a statistical model leaves out variables that are relevant determinants of the effects under study.","This results in the model attributing the missing variables' effect to some of the included variables -- hence over- or under-estimating the latter's true effect.","Omitted variable bias presents a significant threat to the validity of empirical research, particularly in non-experimental studies such as those prevalent in empirical software engineering.   ","This paper illustrates the impact of omitted variable bias on two case studies in the software engineering domain, and uses them to present methods to investigate the possible presence of omitted variable bias, to estimate its impact, and to mitigate its drawbacks.","The analysis techniques we present are based on causal structural models of the variables of interest, which provide a practical, intuitive summary of the key relations among variables.   ","This paper demonstrates a sequence of analysis steps that inform the design and execution of any empirical study in software engineering.","An important observation is that it pays off to invest effort investigating omitted variable bias before actually executing an empirical study, because this effort can lead to a more solid study design, and to a significant reduction in its threats to validity."],"url":"http://arxiv.org/abs/2501.17026v1"}
{"created":"2025-01-28 15:41:54","title":"Automated Refactoring of Non-Idiomatic Python Code: A Differentiated Replication with LLMs","abstract":"In the Python ecosystem, the adoption of idiomatic constructs has been fostered because of their expressiveness, increasing productivity and even efficiency, despite controversial arguments concerning familiarity or understandability issues. Recent research contributions have proposed approaches -- based on static code analysis and transformation -- to automatically identify and enact refactoring opportunities of non-idiomatic code into idiomatic ones. Given the potential recently offered by Large Language Models (LLMs) for code-related tasks, in this paper, we present the results of a replication study in which we investigate GPT-4 effectiveness in recommending and suggesting idiomatic refactoring actions. Our results reveal that GPT-4 not only identifies idiomatic constructs effectively but frequently exceeds the benchmark in proposing refactoring actions where the existing baseline failed. A manual analysis of a random sample shows the correctness of the obtained recommendations. Our findings underscore the potential of LLMs to achieve tasks where, in the past, implementing recommenders based on complex code analyses was required.","sentences":["In the Python ecosystem, the adoption of idiomatic constructs has been fostered because of their expressiveness, increasing productivity and even efficiency, despite controversial arguments concerning familiarity or understandability issues.","Recent research contributions have proposed approaches -- based on static code analysis and transformation -- to automatically identify and enact refactoring opportunities of non-idiomatic code into idiomatic ones.","Given the potential recently offered by Large Language Models (LLMs) for code-related tasks, in this paper, we present the results of a replication study in which we investigate GPT-4 effectiveness in recommending and suggesting idiomatic refactoring actions.","Our results reveal that GPT-4 not only identifies idiomatic constructs effectively but frequently exceeds the benchmark in proposing refactoring actions where the existing baseline failed.","A manual analysis of a random sample shows the correctness of the obtained recommendations.","Our findings underscore the potential of LLMs to achieve tasks where, in the past, implementing recommenders based on complex code analyses was required."],"url":"http://arxiv.org/abs/2501.17024v1"}
{"created":"2025-01-28 15:39:07","title":"Mobile Manipulation Instruction Generation from Multiple Images with Automatic Metric Enhancement","abstract":"We consider the problem of generating free-form mobile manipulation instructions based on a target object image and receptacle image. Conventional image captioning models are not able to generate appropriate instructions because their architectures are typically optimized for single-image. In this study, we propose a model that handles both the target object and receptacle to generate free-form instruction sentences for mobile manipulation tasks. Moreover, we introduce a novel training method that effectively incorporates the scores from both learning-based and n-gram based automatic evaluation metrics as rewards. This method enables the model to learn the co-occurrence relationships between words and appropriate paraphrases. Results demonstrate that our proposed method outperforms baseline methods including representative multimodal large language models on standard automatic evaluation metrics. Moreover, physical experiments reveal that using our method to augment data on language instructions improves the performance of an existing multimodal language understanding model for mobile manipulation.","sentences":["We consider the problem of generating free-form mobile manipulation instructions based on a target object image and receptacle image.","Conventional image captioning models are not able to generate appropriate instructions because their architectures are typically optimized for single-image.","In this study, we propose a model that handles both the target object and receptacle to generate free-form instruction sentences for mobile manipulation tasks.","Moreover, we introduce a novel training method that effectively incorporates the scores from both learning-based and n-gram based automatic evaluation metrics as rewards.","This method enables the model to learn the co-occurrence relationships between words and appropriate paraphrases.","Results demonstrate that our proposed method outperforms baseline methods including representative multimodal large language models on standard automatic evaluation metrics.","Moreover, physical experiments reveal that using our method to augment data on language instructions improves the performance of an existing multimodal language understanding model for mobile manipulation."],"url":"http://arxiv.org/abs/2501.17022v1"}
{"created":"2025-01-28 15:37:45","title":"On Oblivious Transfer Capacity of Noisy Multiple Access Channel","abstract":"This work investigates the problem of Oblivious Transfer (OT) over a noisy Multiple Access Channel (MAC) involving two non-colluding senders and a single receiver. The channel model is characterized by correlations among the parties, with the parties assumed to be either honest-but-curious or, in the receiver's case, potentially malicious. We propose a multiparty protocol for honest-but-curious parties where the general MAC is reduced to a certain correlation. In scenarios where the receiver is malicious, the protocol achieves an achievable rate region.","sentences":["This work investigates the problem of Oblivious Transfer (OT) over a noisy Multiple Access Channel (MAC) involving two non-colluding senders and a single receiver.","The channel model is characterized by correlations among the parties, with the parties assumed to be either honest-but-curious or, in the receiver's case, potentially malicious.","We propose a multiparty protocol for honest-but-curious parties where the general MAC is reduced to a certain correlation.","In scenarios where the receiver is malicious, the protocol achieves an achievable rate region."],"url":"http://arxiv.org/abs/2501.17021v1"}
{"created":"2025-01-28 15:32:41","title":"Six-Degree-of-Freedom Motion Emulation for Data-Driven Modeling of Underwater Vehicles","abstract":"This article presents a collaborative research effort aimed at developing a novel six-degree-of-freedom (6-DOF) motion platform for the empirical characterization of hydrodynamic forces crucial for the control and stability of surface and subsurface vehicles. Traditional experimental methods, such as the Planar Motion Mechanism (PMM), are limited by the number of simultaneously articulated DOFs and are limited to single-frequency testing, making such systems impractical for resolving frequency-dependent added mass or damping matrices. The 6 DOF platform, termed a hexapod, overcomes these limitations by offering enhanced maneuverability and the ability to test broad-banded frequency spectra in multiple degrees of freedom in a single experiment.","sentences":["This article presents a collaborative research effort aimed at developing a novel six-degree-of-freedom (6-DOF) motion platform for the empirical characterization of hydrodynamic forces crucial for the control and stability of surface and subsurface vehicles.","Traditional experimental methods, such as the Planar Motion Mechanism (PMM), are limited by the number of simultaneously articulated DOFs and are limited to single-frequency testing, making such systems impractical for resolving frequency-dependent added mass or damping matrices.","The 6 DOF platform, termed a hexapod, overcomes these limitations by offering enhanced maneuverability and the ability to test broad-banded frequency spectra in multiple degrees of freedom in a single experiment."],"url":"http://arxiv.org/abs/2501.17018v1"}
{"created":"2025-01-28 15:26:25","title":"Revisit Mixture Models for Multi-Agent Simulation: Experimental Study within a Unified Framework","abstract":"Simulation plays a crucial role in assessing autonomous driving systems, where the generation of realistic multi-agent behaviors is a key aspect. In multi-agent simulation, the primary challenges include behavioral multimodality and closed-loop distributional shifts. In this study, we revisit mixture models for generating multimodal agent behaviors, which can cover the mainstream methods including continuous mixture models and GPT-like discrete models. Furthermore, we introduce a closed-loop sample generation approach tailored for mixture models to mitigate distributional shifts. Within the unified mixture model~(UniMM) framework, we recognize critical configurations from both model and data perspectives. We conduct a systematic examination of various model configurations, including positive component matching, continuous regression, prediction horizon, and the number of components. Moreover, our investigation into the data configuration highlights the pivotal role of closed-loop samples in achieving realistic simulations. To extend the benefits of closed-loop samples across a broader range of mixture models, we further address the shortcut learning and off-policy learning issues. Leveraging insights from our exploration, the distinct variants proposed within the UniMM framework, including discrete, anchor-free, and anchor-based models, all achieve state-of-the-art performance on the WOSAC benchmark.","sentences":["Simulation plays a crucial role in assessing autonomous driving systems, where the generation of realistic multi-agent behaviors is a key aspect.","In multi-agent simulation, the primary challenges include behavioral multimodality and closed-loop distributional shifts.","In this study, we revisit mixture models for generating multimodal agent behaviors, which can cover the mainstream methods including continuous mixture models and GPT-like discrete models.","Furthermore, we introduce a closed-loop sample generation approach tailored for mixture models to mitigate distributional shifts.","Within the unified mixture model~(UniMM) framework, we recognize critical configurations from both model and data perspectives.","We conduct a systematic examination of various model configurations, including positive component matching, continuous regression, prediction horizon, and the number of components.","Moreover, our investigation into the data configuration highlights the pivotal role of closed-loop samples in achieving realistic simulations.","To extend the benefits of closed-loop samples across a broader range of mixture models, we further address the shortcut learning and off-policy learning issues.","Leveraging insights from our exploration, the distinct variants proposed within the UniMM framework, including discrete, anchor-free, and anchor-based models, all achieve state-of-the-art performance on the WOSAC benchmark."],"url":"http://arxiv.org/abs/2501.17015v1"}
{"created":"2025-01-28 15:25:56","title":"Network Slice-based Low-Altitude Intelligent Network for Advanced Air Mobility","abstract":"Advanced Air Mobility (AAM) is transforming transportation systems by extending them into near-ground airspace, offering innovative solutions to mobility challenges. In this space, electric vertical take-off and landing vehicles (eVTOLs) perform a variety of tasks to improve aviation safety and efficiency, such as collaborative computing and perception. However, eVTOLs face constraints such as compacted shape and restricted onboard computing resources. These limitations necessitate task offloading to nearby high-performance base stations (BSs) for timely processing. Unfortunately, the high mobility of eVTOLs, coupled with their restricted flight airlines and heterogeneous resource management creates significant challenges in dynamic task offloading. To address these issues, this paper introduces a novel network slice-based Low-Altitude Intelligent Network (LAIN) framework for eVTOL tasks. By leveraging advanced network slicing technologies from 5G/6G, the proposed framework dynamically adjusts communication bandwidth, beam alignment, and computing resources to meet fluctuating task demands. Specifically, the framework includes an access pairing method to pre-schedule optimal eVTOL-BS-slice assignments, a pre-assessment algorithm to avoid resource waste, and a deep reinforcement learning-based slice orchestration mechanism to optimize resource allocation and lifecycle management. Simulation results demonstrate that the proposed framework outperforms existing benchmarks in terms of resource allocation efficiency and operational/violation costs across varying eVTOL velocities. This work provides valuable insights into intelligent network slicing for future AAM transportation systems.","sentences":["Advanced Air Mobility (AAM) is transforming transportation systems by extending them into near-ground airspace, offering innovative solutions to mobility challenges.","In this space, electric vertical take-off and landing vehicles (eVTOLs) perform a variety of tasks to improve aviation safety and efficiency, such as collaborative computing and perception.","However, eVTOLs face constraints such as compacted shape and restricted onboard computing resources.","These limitations necessitate task offloading to nearby high-performance base stations (BSs) for timely processing.","Unfortunately, the high mobility of eVTOLs, coupled with their restricted flight airlines and heterogeneous resource management creates significant challenges in dynamic task offloading.","To address these issues, this paper introduces a novel network slice-based Low-Altitude Intelligent Network (LAIN) framework for eVTOL tasks.","By leveraging advanced network slicing technologies from 5G/6G, the proposed framework dynamically adjusts communication bandwidth, beam alignment, and computing resources to meet fluctuating task demands.","Specifically, the framework includes an access pairing method to pre-schedule optimal eVTOL-BS-slice assignments, a pre-assessment algorithm to avoid resource waste, and a deep reinforcement learning-based slice orchestration mechanism to optimize resource allocation and lifecycle management.","Simulation results demonstrate that the proposed framework outperforms existing benchmarks in terms of resource allocation efficiency and operational/violation costs across varying eVTOL velocities.","This work provides valuable insights into intelligent network slicing for future AAM transportation systems."],"url":"http://arxiv.org/abs/2501.17014v1"}
{"created":"2025-01-28 15:25:48","title":"How an AI-ready National Data Library would help UK science","abstract":"In this paper, we provide a technical vision for key enabling elements for the architecture of the UK National Data Library (NDL) with a strong focus on building it as an AI-ready data infrastructure through standardised vocabularies, automated analysis tools, and interoperability services. We follow the ODI Multilayer Interoperability Framework (MIF) for data stewardship, covering central socio-technical aspects for the NDL including user-centric approaches to service design and governance.","sentences":["In this paper, we provide a technical vision for key enabling elements for the architecture of the UK National Data Library (NDL) with a strong focus on building it as an AI-ready data infrastructure through standardised vocabularies, automated analysis tools, and interoperability services.","We follow the ODI Multilayer Interoperability Framework (MIF) for data stewardship, covering central socio-technical aspects for the NDL including user-centric approaches to service design and governance."],"url":"http://arxiv.org/abs/2501.17013v1"}
{"created":"2025-01-28 15:17:36","title":"MIDI-GPT: A Controllable Generative Model for Computer-Assisted Multitrack Music Composition","abstract":"We present and release MIDI-GPT, a generative system based on the Transformer architecture that is designed for computer-assisted music composition workflows. MIDI-GPT supports the infilling of musical material at the track and bar level, and can condition generation on attributes including: instrument type, musical style, note density, polyphony level, and note duration. In order to integrate these features, we employ an alternative representation for musical material, creating a time-ordered sequence of musical events for each track and concatenating several tracks into a single sequence, rather than using a single time-ordered sequence where the musical events corresponding to different tracks are interleaved. We also propose a variation of our representation allowing for expressiveness. We present experimental results that demonstrate that MIDI-GPT is able to consistently avoid duplicating the musical material it was trained on, generate music that is stylistically similar to the training dataset, and that attribute controls allow enforcing various constraints on the generated material. We also outline several real-world applications of MIDI-GPT, including collaborations with industry partners that explore the integration and evaluation of MIDI-GPT into commercial products, as well as several artistic works produced using it.","sentences":["We present and release MIDI-GPT, a generative system based on the Transformer architecture that is designed for computer-assisted music composition workflows.","MIDI-GPT supports the infilling of musical material at the track and bar level, and can condition generation on attributes including: instrument type, musical style, note density, polyphony level, and note duration.","In order to integrate these features, we employ an alternative representation for musical material, creating a time-ordered sequence of musical events for each track and concatenating several tracks into a single sequence, rather than using a single time-ordered sequence where the musical events corresponding to different tracks are interleaved.","We also propose a variation of our representation allowing for expressiveness.","We present experimental results that demonstrate that MIDI-GPT is able to consistently avoid duplicating the musical material it was trained on, generate music that is stylistically similar to the training dataset, and that attribute controls allow enforcing various constraints on the generated material.","We also outline several real-world applications of MIDI-GPT, including collaborations with industry partners that explore the integration and evaluation of MIDI-GPT into commercial products, as well as several artistic works produced using it."],"url":"http://arxiv.org/abs/2501.17011v1"}
{"created":"2025-01-28 15:17:32","title":"New Quantum MDS Codes with Flexible Parameters from Hermitian Self-Orthogonal GRS Codes","abstract":"Let $q$ be a prime power.   Let $\\lambda>1$ be a divisor of $q-1$, and let $\\tau>1$ and $\\rho>1$ be divisors of $q+1$.   Under certain conditions we prove that there exists an MDS stabilizer quantum code with length   $n=\\lambda \\tau \\sigma$ where $2\\le \\sigma \\le \\rho$.   This is a flexible construction, which   includes new MDS parameters not known before.","sentences":["Let $q$ be a prime power.   ","Let $\\lambda>1$ be a divisor of $q-1$, and let $\\tau>1$ and $\\rho>1$ be divisors of $q+1$.   Under certain conditions we prove that there exists an MDS stabilizer quantum code with length   $n=\\lambda \\tau \\sigma$ where $2\\le \\sigma \\le \\rho$.   This is a flexible construction, which   includes new MDS parameters not known before."],"url":"http://arxiv.org/abs/2501.17010v1"}
{"created":"2025-01-28 15:00:45","title":"Using Sustainability Impact Scores for Software Architecture Evaluation","abstract":"For future regulatory compliance, organizations must assess and report on the state of sustainability in terms of its impacts over time. Sustainability, being a multidimensional concern, is complex to quantify. This complexity further increases with the interdependencies of the quality concerns across different sustainability dimensions. The research literature lacks a holistic way to evaluate sustainability at the software architecture level. With this study, our aim is to identify quality attribute (QA) trade-offs at the software architecture level and quantify the related sustainability impact. To this aim we present an improved version of the Sustainability Impact Score (SIS), building on our previous work. The SIS facilitates the identification and quantification of trade-offs in terms of their sustainability impact, leveraging a risk- and importance-based prioritization mechanism. To evaluate our approach, we apply it to an industrial case study involving a multi-model framework for integrated decision-making in the energy sector. Our study reveals that technical quality concerns have significant, often unrecognized impacts across sustainability dimensions. The SIS coupled with QA trade-offs can help practitioners make informed decisions that align with their sustainability goals. Early evaluations can help organizations mitigate sustainability risks by taking preventive actions.","sentences":["For future regulatory compliance, organizations must assess and report on the state of sustainability in terms of its impacts over time.","Sustainability, being a multidimensional concern, is complex to quantify.","This complexity further increases with the interdependencies of the quality concerns across different sustainability dimensions.","The research literature lacks a holistic way to evaluate sustainability at the software architecture level.","With this study, our aim is to identify quality attribute (QA) trade-offs at the software architecture level and quantify the related sustainability impact.","To this aim we present an improved version of the Sustainability Impact Score (SIS), building on our previous work.","The SIS facilitates the identification and quantification of trade-offs in terms of their sustainability impact, leveraging a risk- and importance-based prioritization mechanism.","To evaluate our approach, we apply it to an industrial case study involving a multi-model framework for integrated decision-making in the energy sector.","Our study reveals that technical quality concerns have significant, often unrecognized impacts across sustainability dimensions.","The SIS coupled with QA trade-offs can help practitioners make informed decisions that align with their sustainability goals.","Early evaluations can help organizations mitigate sustainability risks by taking preventive actions."],"url":"http://arxiv.org/abs/2501.17004v1"}
{"created":"2025-01-28 14:58:50","title":"Covert Adversarial Actuators in Finite MDPs","abstract":"We consider a Markov decision process (MDP) in which actions prescribed by the controller are executed by a separate actuator, which may behave adversarially. At each time step, the controller selects and transmits an action to the actuator; however, the actuator may deviate from the intended action to degrade the control reward. Given that the controller observes only the sequence of visited states, we investigate whether the actuator can covertly deviate from the controller's policy to minimize its reward without being detected. We establish conditions for covert adversarial behavior over an infinite time horizon and formulate an optimization problem to determine the optimal adversarial policy under these conditions. Additionally, we derive the asymptotic error exponents for detection in two scenarios: (1) a binary hypothesis testing framework, where the actuator either follows the prescribed policy or a known adversarial strategy, and (2) a composite hypothesis testing framework, where the actuator may employ any stationary policy. For the latter case, we also propose an optimization problem to maximize the adversary's performance.","sentences":["We consider a Markov decision process (MDP) in which actions prescribed by the controller are executed by a separate actuator, which may behave adversarially.","At each time step, the controller selects and transmits an action to the actuator; however, the actuator may deviate from the intended action to degrade the control reward.","Given that the controller observes only the sequence of visited states, we investigate whether the actuator can covertly deviate from the controller's policy to minimize its reward without being detected.","We establish conditions for covert adversarial behavior over an infinite time horizon and formulate an optimization problem to determine the optimal adversarial policy under these conditions.","Additionally, we derive the asymptotic error exponents for detection in two scenarios: (1) a binary hypothesis testing framework, where the actuator either follows the prescribed policy or a known adversarial strategy, and (2) a composite hypothesis testing framework, where the actuator may employ any stationary policy.","For the latter case, we also propose an optimization problem to maximize the adversary's performance."],"url":"http://arxiv.org/abs/2501.17002v1"}
{"created":"2025-01-28 14:52:16","title":"Large Language Models for Code Generation: The Practitioners Perspective","abstract":"Large Language Models (LLMs) have emerged as coding assistants, capable of generating source code from natural language prompts. With the increasing adoption of LLMs in software development, academic research and industry based projects are developing various tools, benchmarks, and metrics to evaluate the effectiveness of LLM-generated code. However, there is a lack of solutions evaluated through empirically grounded methods that incorporate practitioners perspectives to assess functionality, syntax, and accuracy in real world applications. To address this gap, we propose and develop a multi-model unified platform to generate and execute code based on natural language prompts. We conducted a survey with 60 software practitioners from 11 countries across four continents working in diverse professional roles and domains to evaluate the usability, performance, strengths, and limitations of each model. The results present practitioners feedback and insights into the use of LLMs in software development, including their strengths and weaknesses, key aspects overlooked by benchmarks and metrics, and a broader understanding of their practical applicability. These findings can help researchers and practitioners make informed decisions for systematically selecting and using LLMs in software development projects. Future research will focus on integrating more diverse models into the proposed system, incorporating additional case studies, and conducting developer interviews for deeper empirical insights into LLM-driven software development.","sentences":["Large Language Models (LLMs) have emerged as coding assistants, capable of generating source code from natural language prompts.","With the increasing adoption of LLMs in software development, academic research and industry based projects are developing various tools, benchmarks, and metrics to evaluate the effectiveness of LLM-generated code.","However, there is a lack of solutions evaluated through empirically grounded methods that incorporate practitioners perspectives to assess functionality, syntax, and accuracy in real world applications.","To address this gap, we propose and develop a multi-model unified platform to generate and execute code based on natural language prompts.","We conducted a survey with 60 software practitioners from 11 countries across four continents working in diverse professional roles and domains to evaluate the usability, performance, strengths, and limitations of each model.","The results present practitioners feedback and insights into the use of LLMs in software development, including their strengths and weaknesses, key aspects overlooked by benchmarks and metrics, and a broader understanding of their practical applicability.","These findings can help researchers and practitioners make informed decisions for systematically selecting and using LLMs in software development projects.","Future research will focus on integrating more diverse models into the proposed system, incorporating additional case studies, and conducting developer interviews for deeper empirical insights into LLM-driven software development."],"url":"http://arxiv.org/abs/2501.16998v1"}
{"created":"2025-01-28 14:52:10","title":"MAUCell: An Adaptive Multi-Attention Framework for Video Frame Prediction","abstract":"Temporal sequence modeling stands as the fundamental foundation for video prediction systems and real-time forecasting operations as well as anomaly detection applications. The achievement of accurate predictions through efficient resource consumption remains an ongoing issue in contemporary temporal sequence modeling. We introduce the Multi-Attention Unit (MAUCell) which combines Generative Adversarial Networks (GANs) and spatio-temporal attention mechanisms to improve video frame prediction capabilities. Our approach implements three types of attention models to capture intricate motion sequences. A dynamic combination of these attention outputs allows the model to reach both advanced decision accuracy along with superior quality while remaining computationally efficient. The integration of GAN elements makes generated frames appear more true to life therefore the framework creates output sequences which mimic real-world footage. The new design system maintains equilibrium between temporal continuity and spatial accuracy to deliver reliable video prediction. Through a comprehensive evaluation methodology which merged the perceptual LPIPS measurement together with classic tests MSE, MAE, SSIM and PSNR exhibited enhancing capabilities than contemporary approaches based on direct benchmark tests of Moving MNIST, KTH Action, and CASIA-B (Preprocessed) datasets. Our examination indicates that MAUCell shows promise for operational time requirements. The research findings demonstrate how GANs work best with attention mechanisms to create better applications for predicting video sequences.","sentences":["Temporal sequence modeling stands as the fundamental foundation for video prediction systems and real-time forecasting operations as well as anomaly detection applications.","The achievement of accurate predictions through efficient resource consumption remains an ongoing issue in contemporary temporal sequence modeling.","We introduce the Multi-Attention Unit (MAUCell) which combines Generative Adversarial Networks (GANs) and spatio-temporal attention mechanisms to improve video frame prediction capabilities.","Our approach implements three types of attention models to capture intricate motion sequences.","A dynamic combination of these attention outputs allows the model to reach both advanced decision accuracy along with superior quality while remaining computationally efficient.","The integration of GAN elements makes generated frames appear more true to life therefore the framework creates output sequences which mimic real-world footage.","The new design system maintains equilibrium between temporal continuity and spatial accuracy to deliver reliable video prediction.","Through a comprehensive evaluation methodology which merged the perceptual LPIPS measurement together with classic tests MSE, MAE, SSIM and PSNR exhibited enhancing capabilities than contemporary approaches based on direct benchmark tests of Moving MNIST, KTH Action, and CASIA-B (Preprocessed) datasets.","Our examination indicates that MAUCell shows promise for operational time requirements.","The research findings demonstrate how GANs work best with attention mechanisms to create better applications for predicting video sequences."],"url":"http://arxiv.org/abs/2501.16997v1"}
{"created":"2025-01-28 14:46:38","title":"FedEFM: Federated Endovascular Foundation Model with Unseen Data","abstract":"In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks. However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data. Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks. Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy. This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention. To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework. Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance. Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain.","sentences":["In endovascular surgery, the precise identification of catheters and guidewires in X-ray images is essential for reducing intervention risks.","However, accurately segmenting catheter and guidewire structures is challenging due to the limited availability of labeled data.","Foundation models offer a promising solution by enabling the collection of similar domain data to train models whose weights can be fine-tuned for downstream tasks.","Nonetheless, large-scale data collection for training is constrained by the necessity of maintaining patient privacy.","This paper proposes a new method to train a foundation model in a decentralized federated learning setting for endovascular intervention.","To ensure the feasibility of the training, we tackle the unseen data issue using differentiable Earth Mover's Distance within a knowledge distillation framework.","Once trained, our foundation model's weights provide valuable initialization for downstream tasks, thereby enhancing task-specific performance.","Intensive experiments show that our approach achieves new state-of-the-art results, contributing to advancements in endovascular intervention and robotic-assisted endovascular surgery, while addressing the critical issue of data sharing in the medical domain."],"url":"http://arxiv.org/abs/2501.16992v1"}
{"created":"2025-01-28 14:28:55","title":"Modulating CNN Features with Pre-Trained ViT Representations for Open-Vocabulary Object Detection","abstract":"Owing to large-scale image-text contrastive training, pre-trained vision language model (VLM) like CLIP shows superior open-vocabulary recognition ability. Most existing open-vocabulary object detectors attempt to utilize the pre-trained VLM to attain generative representation. F-ViT uses the pre-trained visual encoder as the backbone network and freezes it during training. However, the frozen backbone doesn't benefit from the labeled data to strengthen the representation. Therefore, we propose a novel two-branch backbone network design, named as ViT-Feature-Modulated Multi-Scale Convolutional network (VMCNet). VMCNet consists of a trainable convolutional branch, a frozen pre-trained ViT branch and a feature modulation module. The trainable CNN branch could be optimized with labeled data while the frozen pre-trained ViT branch could keep the representation ability derived from large-scale pre-training. Then, the proposed feature modulation module could modulate the multi-scale CNN features with the representations from ViT branch. With the proposed mixed structure, detector is more likely to discover novel categories. Evaluated on two popular benchmarks, our method boosts the detection performance on novel category and outperforms the baseline. On OV-COCO, the proposed method achieves 44.3 AP$_{50}^{\\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$ with ViT-L/14. On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and 38.4 mAP$_{r}$.","sentences":["Owing to large-scale image-text contrastive training, pre-trained vision language model (VLM) like CLIP shows superior open-vocabulary recognition ability.","Most existing open-vocabulary object detectors attempt to utilize the pre-trained VLM to attain generative representation.","F-ViT uses the pre-trained visual encoder as the backbone network and freezes it during training.","However, the frozen backbone doesn't benefit from the labeled data to strengthen the representation.","Therefore, we propose a novel two-branch backbone network design, named as ViT-Feature-Modulated Multi-Scale Convolutional network (VMCNet).","VMCNet consists of a trainable convolutional branch, a frozen pre-trained ViT branch and a feature modulation module.","The trainable CNN branch could be optimized with labeled data while the frozen pre-trained ViT branch could keep the representation ability derived from large-scale pre-training.","Then, the proposed feature modulation module could modulate the multi-scale CNN features with the representations from ViT branch.","With the proposed mixed structure, detector is more likely to discover novel categories.","Evaluated on two popular benchmarks, our method boosts the detection performance on novel category and outperforms the baseline.","On OV-COCO, the proposed method achieves 44.3 AP$_{50}^{\\mathrm{novel}}$ with ViT-B/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$ with ViT-L/14.","On OV-LVIS, VMCNet with ViT-B/16 and ViT-L/14 reaches 27.8 and 38.4 mAP$_{r}$."],"url":"http://arxiv.org/abs/2501.16981v1"}
{"created":"2025-01-28 14:17:58","title":"An Automata-theoretic Basis for Specification and Type Checking of Multiparty Protocols","abstract":"We propose the Automata-based Multiparty Protocols framework (AMP) for top-down protocol development. The framework features a new very general formalism for global protocol specifications called Protocol State Machines (PSMs), Communicating State Machines (CSMs) as specifications for local participants, and a type system to check a $\\pi$-calculus with session interleaving and delegation against the CSM specification. Moreover, we define a large class of PSMs, called \"tame\", for which we provide a sound and complete PSPACE projection operation that computes a CSM describing the same protocol as a given PSM if one exists. We propose these components as a backwards-compatible new backend for frameworks in the style of Multiparty Session Types. In comparison to the latter, AMP offers a considerable improvement in expressivity, decoupling of the various components (e.g. projection and typing), and robustness (thanks to the complete projection).","sentences":["We propose the Automata-based Multiparty Protocols framework (AMP) for top-down protocol development.","The framework features a new very general formalism for global protocol specifications called Protocol State Machines (PSMs), Communicating State Machines (CSMs) as specifications for local participants, and a type system to check a $\\pi$-calculus with session interleaving and delegation against the CSM specification.","Moreover, we define a large class of PSMs, called \"tame\", for which we provide a sound and complete PSPACE projection operation that computes a CSM describing the same protocol as a given PSM if one exists.","We propose these components as a backwards-compatible new backend for frameworks in the style of Multiparty Session Types.","In comparison to the latter, AMP offers a considerable improvement in expressivity, decoupling of the various components (e.g. projection and typing), and robustness (thanks to the complete projection)."],"url":"http://arxiv.org/abs/2501.16977v1"}
{"created":"2025-01-28 14:15:42","title":"Over-Tokenized Transformer: Vocabulary is Generally Worth Scaling","abstract":"Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored. In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance. Specifically, our approach scales up input vocabularies to leverage multi-gram tokens. Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size. Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost. Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs.","sentences":["Tokenization is a fundamental component of large language models (LLMs), yet its influence on model scaling and performance is not fully explored.","In this paper, we introduce Over-Tokenized Transformers, a novel framework that decouples input and output vocabularies to improve language modeling performance.","Specifically, our approach scales up input vocabularies to leverage multi-gram tokens.","Through extensive experiments, we uncover a log-linear relationship between input vocabulary size and training loss, demonstrating that larger input vocabularies consistently enhance model performance, regardless of model size.","Using a large input vocabulary, we achieve performance comparable to double-sized baselines with no additional cost.","Our findings highlight the importance of tokenization in scaling laws and provide practical insight for tokenizer design, paving the way for more efficient and powerful LLMs."],"url":"http://arxiv.org/abs/2501.16975v1"}
{"created":"2025-01-28 14:14:02","title":"Towards Open-Source and Modular Space Systems with ATMOS","abstract":"In the near future, autonomous space systems will compose a large number of the spacecraft being deployed. Their tasks will involve autonomous rendezvous and proximity operations with large structures, such as inspections or assembly of orbiting space stations and maintenance and human-assistance tasks over shared workspaces. To promote replicable and reliable scientific results for autonomous control of spacecraft, we present the design of a space systems laboratory based on open-source and modular software and hardware. The simulation software provides a software-in-the-loop (SITL) architecture that seamlessly transfers simulated results to the ATMOS platforms, developed for testing of multi-agent autonomy schemes for microgravity. The manuscript presents the KTH space systems laboratory facilities and the ATMOS platform as open-source hardware and software contributions. Preliminary results showcase SITL and real testing.","sentences":["In the near future, autonomous space systems will compose a large number of the spacecraft being deployed.","Their tasks will involve autonomous rendezvous and proximity operations with large structures, such as inspections or assembly of orbiting space stations and maintenance and human-assistance tasks over shared workspaces.","To promote replicable and reliable scientific results for autonomous control of spacecraft, we present the design of a space systems laboratory based on open-source and modular software and hardware.","The simulation software provides a software-in-the-loop (SITL) architecture that seamlessly transfers simulated results to the ATMOS platforms, developed for testing of multi-agent autonomy schemes for microgravity.","The manuscript presents the KTH space systems laboratory facilities and the ATMOS platform as open-source hardware and software contributions.","Preliminary results showcase SITL and real testing."],"url":"http://arxiv.org/abs/2501.16973v1"}
{"created":"2025-01-28 14:13:17","title":"RODEO: Robust Outlier Detection via Exposing Adaptive Out-of-Distribution Samples","abstract":"In recent years, there have been significant improvements in various forms of image outlier detection. However, outlier detection performance under adversarial settings lags far behind that in standard settings. This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features. To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection. More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples. We leverage a text-to-image model to achieve this goal. We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains. Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings.","sentences":["In recent years, there have been significant improvements in various forms of image outlier detection.","However, outlier detection performance under adversarial settings lags far behind that in standard settings.","This is due to the lack of effective exposure to adversarial scenarios during training, especially on unseen outliers, leading to detection models failing to learn robust features.","To bridge this gap, we introduce RODEO, a data-centric approach that generates effective outliers for robust outlier detection.","More specifically, we show that incorporating outlier exposure (OE) and adversarial training can be an effective strategy for this purpose, as long as the exposed training outliers meet certain characteristics, including diversity, and both conceptual differentiability and analogy to the inlier samples.","We leverage a text-to-image model to achieve this goal.","We demonstrate both quantitatively and qualitatively that our adaptive OE method effectively generates ``diverse'' and ``near-distribution'' outliers, leveraging information from both text and image domains.","Moreover, our experimental results show that utilizing our synthesized outliers significantly enhances the performance of the outlier detector, particularly in adversarial settings."],"url":"http://arxiv.org/abs/2501.16971v1"}
{"created":"2025-01-28 14:12:32","title":"What Really Matters for Learning-based LiDAR-Camera Calibration","abstract":"Calibration is an essential prerequisite for the accurate data fusion of LiDAR and camera sensors. Traditional calibration techniques often require specific targets or suitable scenes to obtain reliable 2D-3D correspondences. To tackle the challenge of target-less and online calibration, deep neural networks have been introduced to solve the problem in a data-driven manner. While previous learning-based methods have achieved impressive performance on specific datasets, they still struggle in complex real-world scenarios. Most existing works focus on improving calibration accuracy but overlook the underlying mechanisms. In this paper, we revisit the development of learning-based LiDAR-Camera calibration and encourage the community to pay more attention to the underlying principles to advance practical applications. We systematically analyze the paradigm of mainstream learning-based methods, and identify the critical limitations of regression-based methods with the widely used data generation pipeline. Our findings reveal that most learning-based methods inadvertently operate as retrieval networks, focusing more on single-modality distributions rather than cross-modality correspondences. We also investigate how the input data format and preprocessing operations impact network performance and summarize the regression clues to inform further improvements.","sentences":["Calibration is an essential prerequisite for the accurate data fusion of LiDAR and camera sensors.","Traditional calibration techniques often require specific targets or suitable scenes to obtain reliable 2D-3D correspondences.","To tackle the challenge of target-less and online calibration, deep neural networks have been introduced to solve the problem in a data-driven manner.","While previous learning-based methods have achieved impressive performance on specific datasets, they still struggle in complex real-world scenarios.","Most existing works focus on improving calibration accuracy but overlook the underlying mechanisms.","In this paper, we revisit the development of learning-based LiDAR-Camera calibration and encourage the community to pay more attention to the underlying principles to advance practical applications.","We systematically analyze the paradigm of mainstream learning-based methods, and identify the critical limitations of regression-based methods with the widely used data generation pipeline.","Our findings reveal that most learning-based methods inadvertently operate as retrieval networks, focusing more on single-modality distributions rather than cross-modality correspondences.","We also investigate how the input data format and preprocessing operations impact network performance and summarize the regression clues to inform further improvements."],"url":"http://arxiv.org/abs/2501.16969v1"}
{"created":"2025-01-28 14:08:57","title":"Heterogeneity-aware Personalized Federated Learning via Adaptive Dual-Agent Reinforcement Learning","abstract":"Federated Learning (FL) empowers multiple clients to collaboratively train machine learning models without sharing local data, making it highly applicable in heterogeneous Internet of Things (IoT) environments. However, intrinsic heterogeneity in clients' model architectures and computing capabilities often results in model accuracy loss and the intractable straggler problem, which significantly impairs training effectiveness. To tackle these challenges, this paper proposes a novel Heterogeneity-aware Personalized Federated Learning method, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms. HAPFL optimizes the training process by incorporating three strategic components: 1) An RL-based heterogeneous model allocation mechanism. The parameter server employs a Proximal Policy Optimization (PPO)-based RL agent to adaptively allocate appropriately sized, differentiated models to clients based on their performance, effectively mitigating performance disparities. 2) An RL-based training intensity adjustment scheme. The parameter server leverages another PPO-based RL agent to dynamically fine-tune the training intensity for each client to further enhance training efficiency and reduce straggling latency. 3) A knowledge distillation-based mutual learning mechanism. Each client deploys both a heterogeneous local model and a homogeneous lightweight model named LiteModel, where these models undergo mutual learning through knowledge distillation. This uniform LiteModel plays a pivotal role in aggregating and sharing global knowledge, significantly enhancing the effectiveness of personalized local training. Experimental results across multiple benchmark datasets demonstrate that HAPFL not only achieves high accuracy but also substantially reduces the overall training time by 20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared to existing solutions.","sentences":["Federated Learning (FL) empowers multiple clients to collaboratively train machine learning models without sharing local data, making it highly applicable in heterogeneous Internet of Things (IoT) environments.","However, intrinsic heterogeneity in clients' model architectures and computing capabilities often results in model accuracy loss and the intractable straggler problem, which significantly impairs training effectiveness.","To tackle these challenges, this paper proposes a novel Heterogeneity-aware Personalized Federated Learning method, named HAPFL, via multi-level Reinforcement Learning (RL) mechanisms.","HAPFL optimizes the training process by incorporating three strategic components: 1) An RL-based heterogeneous model allocation mechanism.","The parameter server employs a Proximal Policy Optimization (PPO)-based RL agent to adaptively allocate appropriately sized, differentiated models to clients based on their performance, effectively mitigating performance disparities.","2) An RL-based training intensity adjustment scheme.","The parameter server leverages another PPO-based RL agent to dynamically fine-tune the training intensity for each client to further enhance training efficiency and reduce straggling latency.","3) A knowledge distillation-based mutual learning mechanism.","Each client deploys both a heterogeneous local model and a homogeneous lightweight model named LiteModel, where these models undergo mutual learning through knowledge distillation.","This uniform LiteModel plays a pivotal role in aggregating and sharing global knowledge, significantly enhancing the effectiveness of personalized local training.","Experimental results across multiple benchmark datasets demonstrate that HAPFL not only achieves high accuracy but also substantially reduces the overall training time by 20.9%-40.4% and decreases straggling latency by 19.0%-48.0% compared to existing solutions."],"url":"http://arxiv.org/abs/2501.16966v1"}
{"created":"2025-01-28 14:07:52","title":"Few Edges Are Enough: Few-Shot Network Attack Detection with Graph Neural Networks","abstract":"Detecting cyberattacks using Graph Neural Networks (GNNs) has seen promising results recently. Most of the state-of-the-art models that leverage these techniques require labeled examples, hard to obtain in many real-world scenarios. To address this issue, unsupervised learning and Self-Supervised Learning (SSL) have emerged as interesting approaches to reduce the dependency on labeled data. Nonetheless, these methods tend to yield more anomalous detection algorithms rather than effective attack detection systems. This paper introduces Few Edges Are Enough (FEAE), a GNN-based architecture trained with SSL and Few-Shot Learning (FSL) to better distinguish between false positive anomalies and actual attacks. To maximize the potential of few-shot examples, our model employs a hybrid self-supervised objective that combines the advantages of contrastive-based and reconstruction-based SSL. By leveraging only a minimal number of labeled attack events, represented as attack edges, FEAE achieves competitive performance on two well-known network datasets compared to both supervised and unsupervised methods. Remarkably, our experimental results unveil that employing only 1 malicious event for each attack type in the dataset is sufficient to achieve substantial improvements. FEAE not only outperforms self-supervised GNN baselines but also surpasses some supervised approaches on one of the datasets.","sentences":["Detecting cyberattacks using Graph Neural Networks (GNNs) has seen promising results recently.","Most of the state-of-the-art models that leverage these techniques require labeled examples, hard to obtain in many real-world scenarios.","To address this issue, unsupervised learning and Self-Supervised Learning (SSL) have emerged as interesting approaches to reduce the dependency on labeled data.","Nonetheless, these methods tend to yield more anomalous detection algorithms rather than effective attack detection systems.","This paper introduces Few Edges Are Enough (FEAE), a GNN-based architecture trained with SSL and Few-Shot Learning (FSL) to better distinguish between false positive anomalies and actual attacks.","To maximize the potential of few-shot examples, our model employs a hybrid self-supervised objective that combines the advantages of contrastive-based and reconstruction-based SSL.","By leveraging only a minimal number of labeled attack events, represented as attack edges, FEAE achieves competitive performance on two well-known network datasets compared to both supervised and unsupervised methods.","Remarkably, our experimental results unveil that employing only 1 malicious event for each attack type in the dataset is sufficient to achieve substantial improvements.","FEAE not only outperforms self-supervised GNN baselines but also surpasses some supervised approaches on one of the datasets."],"url":"http://arxiv.org/abs/2501.16964v1"}
{"created":"2025-01-28 14:05:06","title":"UEFI Memory Forensics: A Framework for UEFI Threat Analysis","abstract":"Modern computing systems rely on the Unified Extensible Firmware Interface (UEFI), which has replaced the traditional BIOS as the firmware standard for the modern boot process. Despite the advancements, UEFI is increasingly targeted by threat actors seeking to exploit its execution environment and take advantage of its persistence mechanisms. While some security-related analysis of UEFI components has been performed--primarily via debugging and runtime behavior testing--to the best of our knowledge, no prior study has specifically addressed capturing and analyzing volatile UEFI runtime memory to detect malicious exploitation during the pre-OS phase. This gap in UEFI forensic tools limits the ability to conduct in-depth security analyses in pre-OS environments. Such a gap is especially surprising, given that memory forensics is widely regarded as foundational to modern incident response, reflected by the popularity of above-OS memory analysis frameworks, such as Rekall, Volatility, and MemProcFS. To address the lack of below-OS memory forensics, we introduce a framework for UEFI memory forensics. The proposed framework consists of two primary components: UefiMemDump, a memory acquisition tool, and UEFIDumpAnalysis, an extendable collection of analysis modules capable of detecting malicious activities such as function pointer hooking, inline hooking, and malicious image loading. Our proof-of-concept implementation demonstrates our framework's ability to detect modern UEFI threats, such as ThunderStrike, CosmicStrand, and Glupteba bootkits. By providing an open-source solution, our work enables researchers and practitioners to investigate firmware-level threats, develop additional analysis modules, and advance overall below-OS security through UEFI memory analysis.","sentences":["Modern computing systems rely on the Unified Extensible Firmware Interface (UEFI), which has replaced the traditional BIOS as the firmware standard for the modern boot process.","Despite the advancements, UEFI is increasingly targeted by threat actors seeking to exploit its execution environment and take advantage of its persistence mechanisms.","While some security-related analysis of UEFI components has been performed--primarily via debugging and runtime behavior testing--to the best of our knowledge, no prior study has specifically addressed capturing and analyzing volatile UEFI runtime memory to detect malicious exploitation during the pre-OS phase.","This gap in UEFI forensic tools limits the ability to conduct in-depth security analyses in pre-OS environments.","Such a gap is especially surprising, given that memory forensics is widely regarded as foundational to modern incident response, reflected by the popularity of above-OS memory analysis frameworks, such as Rekall, Volatility, and MemProcFS.","To address the lack of below-OS memory forensics, we introduce a framework for UEFI memory forensics.","The proposed framework consists of two primary components: UefiMemDump, a memory acquisition tool, and UEFIDumpAnalysis, an extendable collection of analysis modules capable of detecting malicious activities such as function pointer hooking, inline hooking, and malicious image loading.","Our proof-of-concept implementation demonstrates our framework's ability to detect modern UEFI threats, such as ThunderStrike, CosmicStrand, and Glupteba bootkits.","By providing an open-source solution, our work enables researchers and practitioners to investigate firmware-level threats, develop additional analysis modules, and advance overall below-OS security through UEFI memory analysis."],"url":"http://arxiv.org/abs/2501.16962v1"}
{"created":"2025-01-28 14:04:49","title":"Instantiation-based Formalization of Logical Reasoning Tasks using Language Models and Logical Solvers","abstract":"Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems. We introduce Semantic Self-Verification (SSV), a novel approach that addresses the key challenge in combining language models with the rigor of logical solvers: to accurately formulate the reasoning problem from natural language to the formal language of the solver. SSV uses a consistency-based approach to produce strong abstract formalizations of problems using concrete instantiations that are generated by the model and verified by the solver. In addition to significantly advancing the overall reasoning accuracy over the state-of-the-art, a key novelty that this approach presents is a feature of verification that has near-perfect precision over a significant coverage of cases, as we demonstrate on open reasoning benchmarks. We propose such *near-certain reasoning* as a new approach to reduce the need for manual verification in many cases, taking us closer to more dependable and autonomous AI reasoning systems.","sentences":["Robustness of reasoning remains a significant challenge for large language models, and addressing it is essential for the practical applicability of AI-driven reasoning systems.","We introduce Semantic Self-Verification (SSV), a novel approach that addresses the key challenge in combining language models with the rigor of logical solvers: to accurately formulate the reasoning problem from natural language to the formal language of the solver.","SSV uses a consistency-based approach to produce strong abstract formalizations of problems using concrete instantiations that are generated by the model and verified by the solver.","In addition to significantly advancing the overall reasoning accuracy over the state-of-the-art, a key novelty that this approach presents is a feature of verification that has near-perfect precision over a significant coverage of cases, as we demonstrate on open reasoning benchmarks.","We propose such *near-certain reasoning* as a new approach to reduce the need for manual verification in many cases, taking us closer to more dependable and autonomous AI reasoning systems."],"url":"http://arxiv.org/abs/2501.16961v1"}
